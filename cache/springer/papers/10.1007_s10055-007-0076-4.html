<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Towards the development of a virtual environment-based training system"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="In this paper, we discuss the development of Virtual Training Studio (VTS), a virtual environment-based training system that allows training supervisors to create training instructions and allows..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/11/4.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Towards the development of a virtual environment-based training system for mechanical assembly operations"/>

    <meta name="dc.source" content="Virtual Reality 2007 11:4"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2007-04-26"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2007 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="In this paper, we discuss the development of Virtual Training Studio (VTS), a virtual environment-based training system that allows training supervisors to create training instructions and allows trainees to learn assembly operations in a virtual environment. Our system is mainly focused on the cognitive side of training so that trainees can learn to recognize parts, remember assembly sequences, and correctly orient the parts during assembly operations. Our system enables users to train using the following three training modes: (1) Interactive Simulation, (2) 3D Animation, and (3) Video. Implementing these training modes required us to develop several new system features. This paper presents an overview of the VTS system and describes a few main features of the system. We also report user test results that show how people train using our system. The user test results indicate that the system is able to support a wide variety of training preferences and works well to support training for assembly operations."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2007-04-26"/>

    <meta name="prism.volume" content="11"/>

    <meta name="prism.number" content="4"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="189"/>

    <meta name="prism.endingPage" content="206"/>

    <meta name="prism.copyright" content="2007 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-007-0076-4"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-007-0076-4"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-007-0076-4.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-007-0076-4"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Towards the development of a virtual environment-based training system for mechanical assembly operations"/>

    <meta name="citation_volume" content="11"/>

    <meta name="citation_issue" content="4"/>

    <meta name="citation_publication_date" content="2007/10"/>

    <meta name="citation_online_date" content="2007/04/26"/>

    <meta name="citation_firstpage" content="189"/>

    <meta name="citation_lastpage" content="206"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-007-0076-4"/>

    <meta name="DOI" content="10.1007/s10055-007-0076-4"/>

    <meta name="citation_doi" content="10.1007/s10055-007-0076-4"/>

    <meta name="description" content="In this paper, we discuss the development of Virtual Training Studio (VTS), a virtual environment-based training system that allows training supervisors to"/>

    <meta name="dc.creator" content="John E. Brough"/>

    <meta name="dc.creator" content="Maxim Schwartz"/>

    <meta name="dc.creator" content="Satyandra K. Gupta"/>

    <meta name="dc.creator" content="Davinder K. Anand"/>

    <meta name="dc.creator" content="Robert Kavetsky"/>

    <meta name="dc.creator" content="Ralph Pettersen"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Abe N, Zhang JY, Tanaka K, Taki H (1996) A training system using virtual machines for teaching assembling/disassembling operations to novices. In: Proceedings of IEEE international conference on systems man and cybernetics, 1996, pp 2096&#8211;2101"/>

    <meta name="citation_reference" content="Banerjee A, Cecil J (2003) A virtual reality based decision support framework for manufacturing simulation. In: Computers and Information in Engineering Conference (Paper CIE-48296), Chicago, Illinois, September 2003"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Syst Man Cybern; citation_title=Using the operator function model and ofmspert as the basis for an intelligent tutoring system: towards a tutor/aid paradigm for operators of supervisory control systems.; citation_author=RW Chu, CM Mitchell, PM Jones; citation_volume=25; citation_issue=7; citation_publication_date=1995; citation_pages=1054-1075; citation_doi=10.1109/21.391287; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Ind; citation_title=Development of an internet virtual layout system for improving workplace safety; citation_author=VG Duffy, FF Wu, P Ng; citation_volume=50; citation_issue=2; citation_publication_date=2003; citation_pages=207-230; citation_doi=10.1016/S0166-3615(02)00121-5; citation_id=CR4"/>

    <meta name="citation_reference" content="citation_journal_title=Ergonomics; citation_title=Responding to a fire emergency in a virtual environment: different patterns of action for different situations.; citation_author=L Gamberini, P Cottone, A Spagnolli, D Varotto, G Mantovani; citation_volume=46; citation_issue=8; citation_publication_date=2003; citation_pages=842-858; citation_doi=10.1080/0014013031000111266; citation_id=CR5"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Aided Des; citation_title=Prototyping and design for assembly analysis using multi-modal virtual environments.; citation_author=R Gupta, D Whitney, D Zeltzer; citation_volume=29; citation_issue=8; citation_publication_date=1997; citation_pages=585-597; citation_doi=10.1016/S0010-4485(96)00093-0; citation_id=CR6"/>

    <meta name="citation_reference" content="Hodges M (1998) Virtual reality in training. Comput Graph World 21(8)"/>

    <meta name="citation_reference" content="Jayaram U, Tirumali H, Jayaram S (2000) A tool/part/human interaction model for assembly in virtual environments. Computers and Information in Engineering Conference, Baltimore, MD, September 2000"/>

    <meta name="citation_reference" content="Jayaram U, Jayaram S, DeChenne C, Jun Kim Y (2004) Case studies using immersive virtual assembly in industry. Computers and Information in Engineering Conference, Salt Lake City, UT, September 2004"/>

    <meta name="citation_reference" content="citation_journal_title=Am J Surg; citation_title=Spatial ability, experience, and skill in laparoscopic surgery.; citation_author=MM Keehner, F Tendick, MV Meng, HP Anwar, M Hegarty, ML Stoller, QY Duh; citation_volume=188; citation_issue=1; citation_publication_date=2004; citation_pages=71-75; citation_doi=10.1016/j.amjsurg.2003.12.059; citation_id=CR10"/>

    <meta name="citation_reference" content="Kim C, Vance J (2003) Using vps (voxmap pointshell) as the basis for interaction in a virtual assembly environment. Computers and Information in Engineering Conference, Chicago, Illinois, September 2003"/>

    <meta name="citation_reference" content="citation_journal_title=Lect Notes Comput Sci; citation_title=Opening the door to non-programmers: authoring intelligent tutor behaviour by demonstration.; citation_author=KR Koedinger, V Aleven, N Heffernan, B McLaren, M Hockenberry; citation_volume=3220; citation_publication_date=2004; citation_pages=162-174; citation_doi=10.1007/978-3-540-30139-4_16; citation_id=CR12"/>

    <meta name="citation_reference" content="Mikchevitch A, Leon JC, Gouskov A (2003) Numerical modelling of flexible components for assembly path planning using a virtual reality environment. Computers and Information in Engineering Conference, Chicago, Illinois, September 2003"/>

    <meta name="citation_reference" content="citation_journal_title=Springer Lect Notes Comput Sci; citation_title=A collaborative virtual environment for the simulation of temporal bone surgery. Medical image computing and computer-assisted intervention.; citation_author=D Morris, C Sewell, N Blevins, F Barbagli, K Salisbury; citation_volume=3217; citation_publication_date=2004; citation_pages=319-327; citation_doi=10.1007/978-3-540-30136-3_40; citation_id=CR14"/>

    <meta name="citation_reference" content="citation_journal_title=Educ Technol Res Dev; citation_title=Productivity tools for simulation-centered training development.; citation_author=A Munro, DM Towne; citation_volume=40; citation_issue=4; citation_publication_date=1992; citation_pages=65-80; citation_doi=10.1007/BF02296900; citation_id=CR15"/>

    <meta name="citation_reference" content="citation_journal_title=Proc Lect Notes Comput Sci; citation_title=Vincent: an autonomous pedagogical agent for on-the-job training.; citation_author=A Paiva, I Machado; citation_volume=1452; citation_publication_date=1998; citation_pages=584-593; citation_doi=10.1007/3-540-68716-5_64; citation_id=CR16"/>

    <meta name="citation_reference" content="Peng X, Chi X, Ochoa JA, Leu MC (2003) Bone surgery simulation with virtual reality. Computers and Information in Engineering Conference, Chicago, Illinois, September 2003"/>

    <meta name="citation_reference" content="citation_journal_title=Appl Artif Intell; citation_title=Animated agents for procedural training in virtual reality: perception, cognition and motor control.; citation_author=J Rickel, WL Johnson; citation_volume=13; citation_issue=4&#8211;5; citation_publication_date=1999; citation_pages=343-382; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=Proc Inst Mech Eng J Eng Manuf; citation_title=The generation and practical use of plans for manual assembly using immersive virtual reality.; citation_author=JM Ritchie, RG Dewar, J Simmons; citation_volume=213; citation_issue=5; citation_publication_date=1999; citation_pages=461-474; citation_id=CR19"/>

    <meta name="citation_reference" content="citation_journal_title=Aviat Space Environ Med; citation_title=Preflight virtual reality training as a countermeasure for space motion sickness and disorientation.; citation_author=KJ Stroud, DL Harm, DM Klaus; citation_volume=76; citation_issue=4; citation_publication_date=2005; citation_pages=352-356; citation_id=CR20"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=A virtual environment testbed for training laparoscopic surgical skills.; citation_author=F Tendick, M Downes, T Goktekin, MC Cavusoglu, D Feygin, XL Wu, R Eyal, M Hegarty, LW Way; citation_volume=9; citation_issue=3; citation_publication_date=2000; citation_pages=236-255; citation_doi=10.1162/105474600566772; citation_id=CR21"/>

    <meta name="citation_reference" content="Wan H, Gao S, Peng Q, Dai G, Zhang F (2004) MIVAS: a multi-modal immersive virtual assembly system. Computers and Information in Engineering Conference, Salt Lake City, UT, September 2004"/>

    <meta name="citation_author" content="John E. Brough"/>

    <meta name="citation_author_institution" content="Center for Energetic Concepts Development, Mechanical Engineering Department, University of Maryland, College Park, USA"/>

    <meta name="citation_author" content="Maxim Schwartz"/>

    <meta name="citation_author_institution" content="Center for Energetic Concepts Development, Mechanical Engineering Department, University of Maryland, College Park, USA"/>

    <meta name="citation_author" content="Satyandra K. Gupta"/>

    <meta name="citation_author_email" content="skgupta@eng.umd.edu"/>

    <meta name="citation_author_institution" content="Center for Energetic Concepts Development, Mechanical Engineering Department, University of Maryland, College Park, USA"/>

    <meta name="citation_author" content="Davinder K. Anand"/>

    <meta name="citation_author_institution" content="Center for Energetic Concepts Development, Mechanical Engineering Department, University of Maryland, College Park, USA"/>

    <meta name="citation_author" content="Robert Kavetsky"/>

    <meta name="citation_author_institution" content="Indian Head Division, Naval Surface Warfare Center, Indian Head, USA"/>

    <meta name="citation_author" content="Ralph Pettersen"/>

    <meta name="citation_author_institution" content="Indian Head Division, Naval Surface Warfare Center, Indian Head, USA"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-007-0076-4&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2007/10/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-007-0076-4"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Towards the development of a virtual environment-based training system for mechanical assembly operations"/>
        <meta property="og:description" content="In this paper, we discuss the development of Virtual Training Studio (VTS), a virtual environment-based training system that allows training supervisors to create training instructions and allows trainees to learn assembly operations in a virtual environment. Our system is mainly focused on the cognitive side of training so that trainees can learn to recognize parts, remember assembly sequences, and correctly orient the parts during assembly operations. Our system enables users to train using the following three training modes: (1) Interactive Simulation, (2) 3D Animation, and (3) Video. Implementing these training modes required us to develop several new system features. This paper presents an overview of the VTS system and describes a few main features of the system. We also report user test results that show how people train using our system. The user test results indicate that the system is able to support a wide variety of training preferences and works well to support training for assembly operations."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Towards the development of a virtual environment-based training system for mechanical assembly operations | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-007-0076-4","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Virtual Environment, Motion Sickness, Rocket Motor, Head Mount Display, Interactive Simulation","kwrd":["Virtual_Environment","Motion_Sickness","Rocket_Motor","Head_Mount_Display","Interactive_Simulation"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-007-0076-4","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-007-0076-4","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=76;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-007-0076-4">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Towards the development of a virtual environment-based training system for mechanical assembly operations
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-007-0076-4.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-007-0076-4.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2007-04-26" itemprop="datePublished">26 April 2007</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Towards the development of a virtual environment-based training system for mechanical assembly operations</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-John_E_-Brough" data-author-popup="auth-John_E_-Brough">John E. Brough</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Maryland" /><meta itemprop="address" content="grid.164295.d, 0000000109417177, Center for Energetic Concepts Development, Mechanical Engineering Department, University of Maryland, College Park, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Maxim-Schwartz" data-author-popup="auth-Maxim-Schwartz">Maxim Schwartz</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Maryland" /><meta itemprop="address" content="grid.164295.d, 0000000109417177, Center for Energetic Concepts Development, Mechanical Engineering Department, University of Maryland, College Park, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Satyandra_K_-Gupta" data-author-popup="auth-Satyandra_K_-Gupta" data-corresp-id="c1">Satyandra K. Gupta<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Maryland" /><meta itemprop="address" content="grid.164295.d, 0000000109417177, Center for Energetic Concepts Development, Mechanical Engineering Department, University of Maryland, College Park, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Davinder_K_-Anand" data-author-popup="auth-Davinder_K_-Anand">Davinder K. Anand</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Maryland" /><meta itemprop="address" content="grid.164295.d, 0000000109417177, Center for Energetic Concepts Development, Mechanical Engineering Department, University of Maryland, College Park, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Robert-Kavetsky" data-author-popup="auth-Robert-Kavetsky">Robert Kavetsky</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Naval Surface Warfare Center" /><meta itemprop="address" content="grid.462643.1, 0000000406187179, Indian Head Division, Naval Surface Warfare Center, Indian Head, USA" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Ralph-Pettersen" data-author-popup="auth-Ralph-Pettersen">Ralph Pettersen</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Naval Surface Warfare Center" /><meta itemprop="address" content="grid.462643.1, 0000000406187179, Indian Head Division, Naval Surface Warfare Center, Indian Head, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 11</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">189</span>–<span itemprop="pageEnd">206</span>(<span data-test="article-publication-year">2007</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">874 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">68 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-007-0076-4/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>In this paper, we discuss the development of Virtual Training Studio (VTS), a virtual environment-based training system that allows training supervisors to create training instructions and allows trainees to learn assembly operations in a virtual environment. Our system is mainly focused on the cognitive side of training so that trainees can learn to recognize parts, remember assembly sequences, and correctly orient the parts during assembly operations. Our system enables users to train using the following three training modes: (1) Interactive Simulation, (2) 3D Animation, and (3) Video. Implementing these training modes required us to develop several new system features. This paper presents an overview of the VTS system and describes a few main features of the system. We also report user test results that show how people train using our system. The user test results indicate that the system is able to support a wide variety of training preferences and works well to support training for assembly operations.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>The workforce in most industries requires continued training and update. Current training methods, for the most part, involve a combination of paper-based manuals, DVD/video-based instructions and/or hands on master-apprentice training. Due to the rapid influx of new and changing technologies and their associated complexities, accelerated training is a necessity in order to maintain an advanced and educated workforce. We believe that existing training methods can be further improved in terms of cost, effectiveness, time expenditure and quality through the use of digital technologies such as virtual environments (VE). The advent of personal virtual environments offers many new possibilities for creating accelerated training technologies.</p><p>Our exploratory studies indicated that people preferred to utilize the virtual environment differently, for training purposes, based on the task at hand and the individual training styles of the user. We found that sometimes it is useful to get 3D visual clues from 3D animation and sometimes it is useful to see images of real parts. Sometimes practicing assembly tasks in the virtual environment helps facilitate training and aids in transferring that knowledge to real life. To meet this requirement, we have developed a system that supports three different training modes. Developing these training modes and providing the ability to seamlessly switch between them required us to develop several new features.</p><p>The virtual environment based training system we have developed is called Virtual Training Studio (VTS). The VTS aims to improve existing training methods through the use of a Virtual Environment based multi-media training infrastructure that allows users to learn using different modes of instruction presentation while focusing mainly on cognitive aspects of training as opposed to highly realistic physics based simulations. The VTS is composed of the following three modules: Virtual Workspace, Virtual Author and Virtual Mentor. Virtual Workspace provides the underlying VE multi-modal infrastructure. It provides the platform for the other two modules to function and integrates the hardware and software into a cohesive package. Virtual Author is a component of the VTS that allows non-programmers to quickly create new tutorials. Virtual Mentor is a module, running on top of the Virtual Workspace, which checks for user errors, assists users in the training process and provides additional details to further clarify the action required.</p><p>This paper provides an overview of VTS system. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0076-4#Sec3">3</a> discusses system goals, system design, and rationale behind design decisions. Our system has a number of unique features not found in other VR based training systems. These features were needed to support the multimodal nature of our system involving 3D animation mode, interactive simulation mode and video mode. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0076-4#Sec8">4</a> describes some of these features in detail. We also conducted detailed studies to assess the system performance. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0076-4#Sec14">5</a> describes main findings from these studies.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Related work</h2><div class="c-article-section__content" id="Sec2-content"><p>The topics directly related to this paper can be classified into the following categories:</p><ul class="u-list-style-bullet">
                  <li>
                    <p><i>Simulation of spatial manipulation tasks in virtual environments</i> A significant amount of recent research on virtual environments has been dedicated to simulation of spatial manipulation tasks in the context of mechanical design, assembly planning and assembly evaluation. The primary focus on this work is development of new algorithms and software to support real-time and accurate collision detection, physics based modelling, and assembly path planning. A paper by Jayaram et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Jayaram U, Jayaram S, DeChenne C, Jun Kim Y (2004) Case studies using immersive virtual assembly in industry. Computers and Information in Engineering Conference, Salt Lake City, UT, September 2004" href="/article/10.1007/s10055-007-0076-4#ref-CR9" id="ref-link-section-d2630e387">2004</a>) describes several case studies in the use of virtual assembly in industry. A paper by Wan et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Wan H, Gao S, Peng Q, Dai G, Zhang F (2004) MIVAS: a multi-modal immersive virtual assembly system. Computers and Information in Engineering Conference, Salt Lake City, UT, September 2004" href="/article/10.1007/s10055-007-0076-4#ref-CR22" id="ref-link-section-d2630e390">2004</a>) describes a multi-modal immersive virtual assembly system. Gupta et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Gupta R, Whitney D, Zeltzer D (1997) Prototyping and design for assembly analysis using multi-modal virtual environments. Comput Aided Des 29(8):585–597" href="/article/10.1007/s10055-007-0076-4#ref-CR6" id="ref-link-section-d2630e393">1997</a>) describe a system for prototyping and design for assembly analysis using multi-modal virtual environments. Mikchevitch et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Mikchevitch A, Leon JC, Gouskov A (2003) Numerical modelling of flexible components for assembly path planning using a virtual reality environment. Computers and Information in Engineering Conference, Chicago, Illinois, September 2003" href="/article/10.1007/s10055-007-0076-4#ref-CR13" id="ref-link-section-d2630e396">2003</a>) describe how to model of flexible components for assembly path planning. Banerjee and Cecil (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Banerjee A, Cecil J (2003) A virtual reality based decision support framework for manufacturing simulation. In: Computers and Information in Engineering Conference (Paper CIE-48296), Chicago, Illinois, September 2003" href="/article/10.1007/s10055-007-0076-4#ref-CR2" id="ref-link-section-d2630e399">2003</a>) describe a virtual reality based decision support framework for manufacturing simulations. Another focus in this area is the development of new interfaces for humans to interact with the virtual environments (Jayaram et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Jayaram U, Tirumali H, Jayaram S (2000) A tool/part/human interaction model for assembly in virtual environments. Computers and Information in Engineering Conference, Baltimore, MD, September 2000" href="/article/10.1007/s10055-007-0076-4#ref-CR8" id="ref-link-section-d2630e403">2000</a>; Kim and Vance <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Kim C, Vance J (2003) Using vps (voxmap pointshell) as the basis for interaction in a virtual assembly environment. Computers and Information in Engineering Conference, Chicago, Illinois, September 2003" href="/article/10.1007/s10055-007-0076-4#ref-CR11" id="ref-link-section-d2630e406">2003</a>).</p>
                  </li>
                  <li>
                    <p><i>Tutorial authoring by interactive demonstration</i> Researchers have used interactive demonstrations as a means for conveniently creating tutorials. An example of this type of authoring tool is the Cognitive Tutor Authoring Tool (CTAT) (Koedinger et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Koedinger KR, Aleven V, Heffernan N, McLaren B, Hockenberry M (2004) Opening the door to non-programmers: authoring intelligent tutor behaviour by demonstration. Lect Notes Comput Sci 3220:162–174" href="/article/10.1007/s10055-007-0076-4#ref-CR12" id="ref-link-section-d2630e417">2004</a>). CTAT builds math tutorials by demonstration. Author performs a scenario using a windows based GUI while system records the procedure. Author must also manually demonstrate all alternative correct and incorrect solution paths. Another example of this type of authoring tool is RIDES (Munro and Towne <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Munro A, Towne DM (1992) Productivity tools for simulation-centered training development. Educ Technol Res Dev 40(4):65–80" href="/article/10.1007/s10055-007-0076-4#ref-CR15" id="ref-link-section-d2630e420">1992</a>), which can train amongst other things, nurses to use medical equipment. In simple mode RIDES allows an author to ‘record’ a procedure that students must learn, simply by carrying out the procedure in a window based user interface. VIVIDS is a more advanced descendent of RIDES which can build lessons for use in Virtual Reality and employs an autonomous agent that can observe and critique student actions. Another example of virtual authoring is a system called UVAVU (Ritchie et al <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Ritchie JM, Dewar RG, Simmons J (1999) The generation and practical use of plans for manual assembly using immersive virtual reality. Proc Inst Mech Eng J Eng Manuf 213(5):461–474" href="/article/10.1007/s10055-007-0076-4#ref-CR19" id="ref-link-section-d2630e423">1999</a>), which generates assembly sequences by observing an author perform an assembly in a virtual environment. UVAVU makes use of known information about final part locations within the assembly to perform snap-ons upon collision during the author’s demonstration. Testing conducted with UVAVU showed that assembly plans produced in virtual reality were similar to those produced in a real environment.</p>
                  </li>
                  <li>
                    <p><i>Real-time error detection and feedback generation in training sessions</i> This area of research involves developing techniques to detect errors made by trainees during training sessions and generating hints to provide them with meaningful feedback. An example of a system that uses these techniques is Georgia Tech Visual and Inspectable Tutor and Assistant (Chu et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Chu RW, Mitchell CM, Jones PM (1995) Using the operator function model and ofmspert as the basis for an intelligent tutoring system: towards a tutor/aid paradigm for operators of supervisory control systems. IEEE Trans Syst Man Cybern 25(7):1054–1075" href="/article/10.1007/s10055-007-0076-4#ref-CR3" id="ref-link-section-d2630e434">1995</a>), a tutoring system designed to teach satellite control and monitoring operations. Lessons can be assigned one of many styles of tutoring ranging from demonstration via animation with little control of the lesson by the user to system monitoring of trainee progress with only occasional intervention by the system. In effect the tutor “fades” as the trainee progresses through the curriculum. Each lesson specifies performance requirements, which the student must satisfy to proceed to the next lesson. Another example of this type of system is Steve (Rickel and Johnson <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Rickel J, Johnson WL (1999) Animated agents for procedural training in virtual reality: perception, cognition and motor control. Appl Artif Intell 13(4–5):343–382" href="/article/10.1007/s10055-007-0076-4#ref-CR18" id="ref-link-section-d2630e437">1999</a>), an animated agent who helps students learn to perform procedural, physical tasks in a virtual environment. Steve can demonstrate tasks, monitor students and provide basic feedback when prompted by trainee. Steve signals mistakes with shaking of the head and saying “No”. Yet another good example is a system designed by Abe et al (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Abe N, Zhang JY, Tanaka K, Taki H (1996) A training system using virtual machines for teaching assembling/disassembling operations to novices. In: Proceedings of IEEE international conference on systems man and cybernetics, 1996, pp 2096–2101" href="/article/10.1007/s10055-007-0076-4#ref-CR1" id="ref-link-section-d2630e440">1996</a>), which teaches novices assembly/disassembly operations on mechanical parts inside a virtual environment by showing a technical illustration to trainees with lines representing assembly paths. The hand motions of trainees are tracked and errors are detected. Trainees are alerted when they grasp wrong parts or move parts in the wrong direction. Paiva and Machado (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Paiva A, Machado I (1998) Vincent: an autonomous pedagogical agent for on-the-job training. Proc Lect Notes Comput Sci 1452:584–593" href="/article/10.1007/s10055-007-0076-4#ref-CR16" id="ref-link-section-d2630e443">1998</a>) describe a pedagogical agent for training. Monitoring errors and user actions in spatial manipulation tasks and providing highly descriptive feedback will require us to develop new types of algorithms.</p>
                  </li>
                  <li>
                    <p><i>Use of virtual environment in training</i> Researchers have explored the use of virtual environment in training applications. A significant amount of research in this field is devoted to teaching of motor skills. Representative areas where VE-based training research has received recent attention is in the medical field where VE based surgery training is growing (Peng et al <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Peng X, Chi X, Ochoa JA, Leu MC (2003) Bone surgery simulation with virtual reality. Computers and Information in Engineering Conference, Chicago, Illinois, September 2003" href="/article/10.1007/s10055-007-0076-4#ref-CR17" id="ref-link-section-d2630e454">2003</a>; Morris et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Morris D, Sewell C, Blevins N, Barbagli F, Salisbury K (2004) A collaborative virtual environment for the simulation of temporal bone surgery. Medical image computing and computer-assisted intervention. Springer Lect Notes Comput Sci 3217:319–327" href="/article/10.1007/s10055-007-0076-4#ref-CR14" id="ref-link-section-d2630e457">2004</a>; Tendick et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Tendick F, Downes M, Goktekin T, Cavusoglu MC, Feygin D, Wu XL, Eyal R, Hegarty M, Way LW (2000) A virtual environment testbed for training laparoscopic surgical skills. Presence Teleoperators Virtual Environ 9(3):236–255" href="/article/10.1007/s10055-007-0076-4#ref-CR21" id="ref-link-section-d2630e460">2000</a>; Keehner et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Keehner MM, Tendick F, Meng MV, Anwar HP, Hegarty M, Stoller ML, Duh QY (2004) Spatial ability, experience, and skill in laparoscopic surgery. Am J Surg 188(1):71–75" href="/article/10.1007/s10055-007-0076-4#ref-CR10" id="ref-link-section-d2630e463">2004</a>) and in areas where mistakes in the assembly process are dangerous or expensive (Hodges <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Hodges M (1998) Virtual reality in training. Comput Graph World 21(8)" href="/article/10.1007/s10055-007-0076-4#ref-CR7" id="ref-link-section-d2630e466">1998</a>; Gamberini et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Gamberini L, Cottone P, Spagnolli A, Varotto D, Mantovani G (2003) Responding to a fire emergency in a virtual environment: different patterns of action for different situations. Ergonomics 46(8):842–858" href="/article/10.1007/s10055-007-0076-4#ref-CR5" id="ref-link-section-d2630e470">2003</a>; Duffy et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Duffy VG, Wu FF, Ng P (2003) Development of an internet virtual layout system for improving workplace safety. Comput Ind 50(2):207–230" href="/article/10.1007/s10055-007-0076-4#ref-CR4" id="ref-link-section-d2630e473">2003</a>). VE-based training is also finding use in preflight training operations to simulate certain aspects of microgravity and to be an effective countermeasure for space motion sickness and spatial disorientation (Stroud et al <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Stroud KJ, Harm DL, Klaus DM (2005) Preflight virtual reality training as a countermeasure for space motion sickness and disorientation. Aviat Space Environ Med 76(4):352–356" href="/article/10.1007/s10055-007-0076-4#ref-CR20" id="ref-link-section-d2630e476">2005</a>).</p>
                  </li>
                </ul>
                     </div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">System overview</h2><div class="c-article-section__content" id="Sec3-content"><h3 class="c-article__sub-heading" id="Sec4">Overview of virtual training studio</h3><p>The VTS system has two main goals. The first goal is to ensure that virtual environment based instructions for training personnel in manufacturing industry can be created quickly so that an overall training cost reduction can potentially be realized by the use of our system. The second goal is to accelerate the training process for the trainees through the use of adaptive, multi-modal instructions. With this system, training supervisors have the option of using a wide variety of multi-media options such as 3D animations, videos, text, audio, and interactive simulations to create training instructions. The virtual environment enables workers to practice instructions using interactive simulation and hence reduces the need for practicing with physical components. Our system is mainly geared toward cognitive skills: training workers to recognize parts, learn assembly sequences, and correctly orient the parts in space for assembly. The VTS was designed to be an affordable Personal Virtual Environment (PVE) for training. We developed a low cost wand design and use an off the shelf head mounted display (HMD). The level of physics based modelling that has been implemented as well as the hardware selected reflects this design decision. The VTS system architecture is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig1">1</a>.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Virtual Training Studio architecture</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The user interacts with the tutorial using a Head Mounted Display (HMD) and a wireless wand. Four optical trackers (infrared cameras) and two gyroscopes are used to track the position and orientation of the user and the wand. The wand consists of an off the shelf wireless presenter, an infrared LED, and a wireless gyroscope. Inside the Virtual Reality environment, the user can manipulate the parts and the buttons using a virtual laser pointer, which is controlled by the wireless wand. A wireless gyroscope and another infrared LED are mounted on the HMD. The cameras track the two LEDs and use triangulation to return the <i>x</i>, <i>y</i>, <i>z</i>, positions. Use of haptics and gloves was avoided in order to keep the cost of the system down. After user testing with a glove-based version of the system, utilizing 2 5DT DataGloves, we made the decision to create a wand based system due to the complications of the user interface in the use of gloves and the simplicity and user friendliness of the wand interface. The glove-based interface, when integrated with our system, forced users to memorize some gestures, caused excessive arm and body movement. These problems could have been overcome by use of a more expensive glove. But we decided against it to reduce the system cost.</p><p>The software infrastructure of the VTS was built using a combination of programming languages: C/C++, Python, OpenGl. Additionally, a number of libraries were used: WoldViz’s Vizard for general purpose loading and transformation of VRML models, ColDet for collision detection, Gnu Triangulated Surface library (GTS) for segmentation and wxPython for the Graphical User Interface. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig2">2</a> shows the software infrastructure.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Software infrastructure and libraries of the VTS</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig3">3</a> shows a screenshot of the VTS environment as the user would see it through the HMD and Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig4">4</a> shows a photograph of a user immersed in the virtual environment.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig3_HTML.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig3_HTML.jpg" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>VTS environment as the user would see it through the HMD</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig4_HTML.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig4_HTML.jpg" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>A user interacting with VTS</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec5">Virtual workspace</h3><p>The goal of this component of the VTS is to provide the basic infrastructure for multimodal training and to incorporate the appropriate level of physics-based modelling consistent with the operation of a low cost PVE. Virtual Workspace houses the necessary framework to allow manipulation of objects, collision detection, execution of animations, and it integrates the hardware with the software to provide the user an intuitive, easy to use interface to the virtual environment. Virtual Workspace also acts as the platform for the Virtual Author and the Virtual Mentor. A major new feature of the Virtual Workspace is dynamic generation of animations. This feature is described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0076-4#Sec11">4.3</a>. The current version of the Virtual Workspace places the user in a furnished room with a table at the center and a projector screen on one of the walls. Parts used in the tutorial are placed on the table, while video as well as text instructions are displayed on the projector screen. The user interacts with the VE using a single wand, represented in the VE as a virtual laser pointer, to pick up, move and rotate objects and to click on buttons located on the control panel at the front of the room. The implementation of the Virtual Workspace also includes the option to interact with the VE through a desktop personal computer (PC) interface. Virtual Workspace offers three primary modes of training: 3D Animation Mode which allows users to view the entire assembly via animations, Interactive Simulation Mode which is a fully user driven mode that allows users to manually perform the assembly tasks and Video Mode which allows users to view the entire assembly via video clips. Trainees can switch between these modes at any time with the click of a button. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig3">3</a> shows a screen shot of the control panel in the Virtual Workspace.</p><h3 class="c-article__sub-heading" id="Sec6">Virtual author</h3><p>The goal of the Virtual Author is to enable the user to quickly create a VE-based tutorial without performing any programming. The current version of the Virtual Author is PC-based. The Virtual Author package includes a ProEngineer (ProE) plug-in written in ProE Toolkit, which allows an engineer to load an assembly into ProE and export it to the file formats used in the VTS—VRML, STL, XML. The instructor then loads an XML file representing an assembly into the PC-based Virtual Author. The authoring process is divided into three phases. In the first phase, the author begins with a complete assembly and detaches parts and subassemblies from it, creating an assembly/disassembly sequence. In the process of doing this, the instructor also declares symmetries and specifies the symmetry types. Each time a part or subassembly is detached, Virtual Author creates a final marker and an insertion marker. The insertion marker is an abstract point just outside of the container assembly which represents the position at which the trainee will have to place the attaching part before activating the animation which completes the assembly. The insertion marker also has orientation information associated with it. The final marker represents the final location of the attaching subassembly within the container subassembly. In the second phase the instructor arranges the parts on a table. In the third and final phase, the instructor plays back the generated assembly/disassembly sequence via animation. During this final phase, the partial set of text instructions is generated automatically by combining data about collision detection and part motion. Another very important feature, which resides in the Virtual Author, is segmentation and extraction of axes discussed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0076-4#Sec13">4.5</a>. The module also has the ability to generate 2D images, for use as visual aids in the paper-based manual, from screenshots of the assembly process captured during the tutorial creation. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig5">5</a> shows a screenshot of Virtual Author in the final replay phase. Nozzle assembly is being animated into its final location within cartridge case. Notice the generated text instructions in the bottom window. The text instruction shown belongs to the previous step as the current step is still being animated in the figure.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Screenshot of Virtual Author in the final replay phase</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec7">Virtual mentor</h3><p>The goal of the Virtual Mentor is to simulate the classical master-apprentice training model by monitoring the actions of the user in the Virtual Workspace and assisting the user at appropriate times to enhance the trainee’s understanding of the assembly/disassembly process. If users make repeated errors, then the system will attempt to clarify instructions by adaptively changing the level of detail and inserting targeted training sessions. The instruction level of detail will be changed by regulating the detail of text/audio instructions and regulating the detail level of visual aids such as arrows, highlights, and animations. The current version of the Virtual Mentor performs the following tasks:</p><ul class="u-list-style-bullet">
                    <li>
                      <p>Error detection and presentation of very specific error messages.</p>
                    </li>
                    <li>
                      <p>Handling symmetries during interactive simulation.</p>
                    </li>
                    <li>
                      <p>Extensive logging.</p>
                    </li>
                    <li>
                      <p>Testing.</p>
                    </li>
                  </ul><p>In the most interactive mode, called Interactive Simulation, the user first positions and orients a part so that the interfaces align and the components can be assembled. The user can then click on a “Complete” button. If the part is positioned and oriented correctly near the insertion marker, allowing for a certain margin for error, the assembly of the part is completed via animation. If the orientation or position of the part is incorrect, an error message is given and the user must realign the part so that assembly can be completed. In this manual mode, Virtual Mentor must check for alternate orientations and insertion positions based on the symmetries that were specified in the Virtual Author. This feature is described in detail in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0076-4#Sec9">4.1</a>.</p><p>The extensive logging that the Virtual Mentor currently performs is the first step toward an adaptive Virtual Mentor that adjusts the level of detail and provides dynamic, performance-based hints. This is described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0076-4#Sec12">4.4</a>. Currently, the analysis of the logs and adapting of instructions is performed interactively by the user. Adapting of instructions or annotation of ambiguous instructions is done by analysing the logs. Ongoing work, however, aims to achieve a higher level of automation in this area. Error detection is described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0076-4#Sec10">4.2</a>.</p></div></div></section><section aria-labelledby="Sec8"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Technical approach behind novel system features</h2><div class="c-article-section__content" id="Sec8-content"><h3 class="c-article__sub-heading" id="Sec9">Handling symmetries and multiple clones</h3><p>According to the case studies and the system testing conducted to date (discussed in detail in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0076-4#Sec14">5</a>), interactive simulation, which involves manual assembly, turned out to be a popular system capability amongst users. As will be shown in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0076-4#Sec14">5</a>, only one of thirty participants in the latest case study completed the training in the tutorials by using only animations and not using interactive simulation. We believe that an important aspect of a well-designed interactive simulation is the proper handling of symmetries. This allows a user to place a part that is symmetric in some way at one of the alternate insertion locations as it could be done in real life without the system giving an error. It also allows the user to use one of many clones of a part in the assembly process at a particular step without the system requiring the use of a particular clone. We believe that proper implementation of symmetries speeds up the training process by not forcing the user to attempt various correct insertion locations or orientations until the user finally uses specifically those that were declared during assembly sequence declaration.</p><p>In real world mechanical assemblies very often there are parts that are highly symmetric along certain planes. Such symmetries often mean that there is more than one correct insertion position and insertion orientation. The challenge of this problem is that the system is not aware of any symmetries and the only information it has access to is the <i>single position</i> and <i>single orientation</i> of each part within the overall assembly. The challenge for VTS is to find out what type symmetries exist and to calculate other possible positions and orientations during interactive simulation.</p><p>The Virtual Mentor is responsible for enforcing correct attachments and insertions involving part/assembly symmetries, though the Virtual Author is used to declare and categorize the symmetries. When creating tutorials via the Virtual Author described earlier, the instructor specifies for each part that exhibits symmetry the <i>main symmetry axis</i> of the part. The instructor also specifies the number of different permissible orientations around this axis. We call this type of symmetry type A. In addition to this information, the instructor declares a second type of symmetry for each step, which we call type B. In type B symmetry, the instructor specifies one <i>secondary symmetry axis</i> which is perpendicular to the main symmetry axis and also specifies a sub-type. The specified assembly sub-type informs the system how it should handle the Type B symmetry at that particular step. The current version of the Virtual Mentor simplifies the problem by allowing only one alternate attachment location for the part being attached to an assembly. Sub-types for symmetry type B in the current version are:</p><ul class="u-list-style-bullet">
                    <li>
                      <p>Subtype B1: Allow primary position and primary orientation only.</p>
                    </li>
                    <li>
                      <p>Subtype B2: No alternate position allowed, but alternate orientation for primary position is allowed.</p>
                    </li>
                    <li>
                      <p>Subtype B3: Alternate position allowed but with primary orientation only (no alternate orientation for primary position).</p>
                    </li>
                    <li>
                      <p>Subtype B4: All combinations of (alternate/primary) positions and orientations are allowed.</p>
                    </li>
                    <li>
                      <p>Subtype B5: Alternate position allowed but with alternate orientation only (no alternate orientation for primary position).</p>
                    </li>
                  </ul><p>“Alternate orientation” means that the part may be rotated 180 degrees around the secondary axis specified for symmetry type B.</p><p>We came up with a computationally simple method to handle placement of parts at alternate locations. Our current method causes the animation to always attach parts to their unique, designated locations and orientations, which were declared during instructor’s assembly sequence specification. This strategy simulates the placement of parts at their alternate locations and orientations, by rotating, swapping, and repositioning parts in a way that is least noticeable to the trainee before activating the animation mechanism, which is part of the Virtual Workspace infrastructure.</p><p>Upon loading all the parts, Virtual Author automatically detects and marks identical parts. It does this by comparing the number of vertices and the bounding boxes of the parts. At the end of interactive simulation, right before the animation that completes the step is activated, the system swaps clones depending on which clone was originally the designated attachment part for that particular step. This strategy once again allows the Virtual Workspace animation to always attach parts to their unique, designated locations and orientations.</p><p>After the check for clones is made, the Virtual Mentor checks if the position of the released part is close enough to the ideal position(s) relative to the receiving assembly. The correct position for the attaching part depends on the sub-type of symmetry type B. For sub-type B5, for instance, there are two allowed positions—primary and alternate. The primary position is specified by the instructor explicitly via Virtual Author. Virtual Mentor automatically ascertains the alternate position for sub-type B5 by first drawing a vector from the primary insertion location to the final location and then doubling that vector. A marker is placed at the tip of this vector. Virtual Mentor then checks if the released part is close to the alternate position. If all checks are passed for subtype B5, the Virtual Mentor eventually flips the receiving assembly/part 180° around the instructor specified secondary axis before passing control to the Virtual Workspace animation generating mechanism. In most cases the trainee does not notice this rotation. An example of type B5 symmetry is the attachment of a cap to a cylinder.</p><p>The final check that the Virtual Mentor makes is the correctness of rotation around the primary symmetry axis. If the placement is correct, the Virtual Mentor rotates the attaching part in increments based on the number of permissible orientations. For example, if this number is three then the increment is 120°. If the number is 4 then the increment is 90°. The system must rotate in these increments to make sure the user does not notice a change in rotation. By rotating in these increments, Virtual Mentor takes advantage of the attaching part’s symmetry to conceal the rotation. The reason why the attaching assembly must be rotated at all is because without such “setup rotation” the animation will be forced to rotate the part until it reaches its designated orientation within the assembly, slowing down the training in the process.</p><p>The two tutorials used in the latest case study contain twelve steps involving symmetries out of a total of 19 steps. Three steps out of nineteen also involve the use of clones. During the case study we observed users placing symmetric assemblies and parts at both their primary and alternate locations. Virtual Mentor demonstrated 100% accuracy in detecting alternate correct placements and allowing users to proceed. One such case that we observed was step three of the ejection seat rocket tutorial in which one of the users had to place cartridge propellant grain into a cartridge case. The propellant grain was cylindrical while the case was a tube. The user placed the cartridge propellant grain on the other side of the cartridge case, which was not the original insertion location declared in the Virtual Author. Virtual Mentor correctly gave the user a success message and correctly animated the propellant grain going into the case from the alternate location. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig6">6</a> shows a screenshot of the placement of the propellant grain at its alternate location relative to the case and the Virtual Mentor’s response.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig6_HTML.jpg?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig6_HTML.jpg" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Placement of a part at its alternate location</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec10">Error detection</h3><p>Detailed and precise error messages are important in the quick diagnosis and resolution of a problem, like an incorrect assembly attempt. In order to provide detailed error messages and helpful hints in the event of a mistake, the system must first determine exactly what type of error was made. The current version of the Virtual Mentor is capable of detecting four types of error:</p><ul class="u-list-style-bullet">
                    <li>
                      <p>Incorrect part used for the given step in the process.</p>
                    </li>
                    <li>
                      <p>Part was placed at an incorrect position.</p>
                    </li>
                    <li>
                      <p>Primary axis of the part is not correctly aligned.</p>
                    </li>
                    <li>
                      <p>Part is not correctly rotated around the primary axis of the part.</p>
                    </li>
                  </ul><p>Whenever the Virtual Mentor gives the third or fourth errors to the user it draws the primary axis through the part which the trainee attempted to assemble to another part or subassembly. This way the trainee knows exactly the axis to which the Virtual Mentor refers.</p><p>In the process of testing our system using volunteers we observed that when trainees paid attention to the text error messages they, on average, more quickly corrected their mistakes in order to complete the step. Trainees who, for whatever reason, did not pay attention to the text errors took significantly longer on average to correct their mistakes.</p><p>For the two tutorials used in the latest case study Virtual Mentor reported a total of 146 errors during training. While monitoring the training of each trainee in VTS, no error detection or error classification mistakes on the part of Virtual Mentor were observed.</p><h3 class="c-article__sub-heading" id="Sec11">Dynamic animations</h3><p>As we mentioned in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0076-4#Sec9">4.1</a> interactive simulation proved to be a powerful and popular capability of VTS. An important aspect of interactive simulation is animation. Users place one part near another and signal to the system to complete the assembly. If placement is correct, the system takes over and completes the assembly using animation. Many virtual environments utilize static animations where all the information about the animation is generated only once and stored in volatile or non-volatile memory. The positions and paths of the objects cannot be altered in static animations. For our system, it was necessary for the animation to be dynamic because the trainees are given the freedom to place parts anywhere prior to activation of the animation. For dynamic animations it is necessary to perform some re-planning each time the animation is activated.</p><p>The Virtual Workspace is responsible for generating dynamic animations. The Virtual Workspace allows two forms of animation. In the first type, the attaching part is first gradually rotated until it matches the orientation of the entry marker. The attaching part is then gradually translated to the position of the entry marker. Finally, the attaching part is gradually translated to the position of the final marker. In the second form of animation, the Virtual Workspace follows the same procedure as the first except for translating the part to its insertion location. Instead of drawing a direct route, the Virtual Workspace first translates the part along the <i>Y</i>-axis (top-down) until the part’s <i>Y</i> component matches the <i>Y</i> component of the insertion marker. Then the part is gradually translated along the <i>Z</i>-axis (forward-back) and finally along the <i>X</i>-axis until the part reaches its insertion location.</p><p>We discovered that using the second animation method allows us to decrease the chance of collisions without using a more computationally expensive path planning algorithm (as long as the room is along the standard <i>X</i>, <i>Y</i>, <i>Z</i>, axes and the front of the room is at the positive <i>Z</i>). The instructor can use the second animation method to reduce chance of collisions during animations by placing parts on the table in a certain arrangement. Instructor can further reduce chance of collisions during animations by requiring the Virtual Workspace to reset the positions of the parts to certain default positions on the table prior to beginning the animation, in effect making the animation static instead of dynamic. However, realizing the importance of sophisticated path planning for our application, an efficient and robust path planning algorithm is currently in development.</p><p>One of the cases we observed during usability testing shows the effectiveness of dynamic animations. In step five of the airplane engine tutorial a trainee was attempting to place the glow plug in the center of the cylinder head. The trainee correctly positioned the glow plug above the cylinder head but oriented it upside down. After signalling to the Virtual Mentor to complete the assembly, the trainee received an error message. Unable to determine their mistake, the trainee pressed the “Hint” button for the first time and the glow plug flashed momentarily. At this point, the user knew that they had selected the correct part but was still unable to determine their error. The trainee then pressed the “Hint” button a second time. At this point, Virtual Mentor activated a high detail hint (discussed in the next Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0076-4#Sec12">4.4</a>) by creating a translucent clone of the glow plug and activated the Virtual Workspace dynamic animation mechanism. The clone of the glow plug was then animated to the correct position by gradually rotating 180° and moving to the ideal insertion location. At the end of the animation the clone disappeared leaving the original glow plug in the incorrect position. After viewing an animation of the correct position and orientation, the trainee was able to complete the step correctly. Without such a dynamic animation, all parts would be reset to certain default positions and orientations before animation could begin and the hint function would not be as effective due to the sudden change in perspective.</p><h3 class="c-article__sub-heading" id="Sec12">Annotation of ambiguous instructions</h3><p>Our testing and the results of the case studies of the early versions of the system revealed that for some steps the interactively generated instructions were ambiguous or not specific enough. In one such example users had to attach a cap to a nozzle. Many attempted to attach the cap to the wrong side of the nozzle because they did not notice a small relief machined into one of the faces of the nozzle, allowing the cap to fit snugly. After one such round of user testing, we interactively inserted more detailed tutorial instructions in the form of more detailed text, more detailed audio instructions and additional visual aids such as arrows. The arrows were used to point out certain features of parts that many users overlooked leading them to make assembly mistakes, i.e. the relief machined in the nozzle. After a second round of similar testing, there was a very significant decrease in the number of user mistakes. This example is depicted in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig7">7</a>.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig7_HTML.jpg?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig7_HTML.jpg" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Use of visual hints to highlight details</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>It soon became clear to us that very often only a small amount of user testing was necessary to reveal ambiguities in the tutorials, which the trainers believed were clear. It also became apparent that different steps of a tutorial often required different levels of detail, depending on the complexity of the part or the step. Too little detail on some steps led to confusion and an increase in the number of errors. Too much detail on simpler steps would cause trainees to become desensitized to details in all steps which would lead to errors in the more complex steps. Too many high detail instructions also unnecessarily slowed down the training. This realization led us to begin the practice of starting with low detail tutorials and adding more details after testing. We also implemented some rudimentary variable detail hints. The first time a user pushes a “Hint” button for example Virtual Mentor offers a low detail hint by flashing the part the trainee must pick up next. The second time the user pushes the “Hint” button, Virtual Mentor offers the ghost animation described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0076-4#Sec11">4.3</a>. Our case studies have shown that these techniques reduced the occurrence of errors. In the latest case study, low detail hints were activated 86 times while high detail hints were activated 52 times.</p><h3 class="c-article__sub-heading" id="Sec13">Segmentation and extraction of axes</h3><p>As we mentioned in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0076-4#Sec6">3.3</a>, in the first phase of the Virtual Author the instructor loads a complete assembly and detaches parts and subassemblies from it to declare an assembly sequence as well as the primary insertion locations and orientations. During the disassembly, the instructor must select an axis along which a part is moved out of the assembly. The insertion location, in the current version of the system, must reside somewhere on this axis just outside of the containing assembly. The system must present the right set of axes to the user to allow proper disassembly. Presenting the default <i>x</i>, <i>y</i>, <i>z</i> axes of the assembly being taken apart may work for some assemblies but not for others. In order to generate the right set of axes that will allow correct detachment of all parts the system must analyze the surfaces of the assembly and return axes that are parallel to the normal vectors of the biggest planar surfaces or parallel to the axes of cylindrical surfaces.</p><p>To accomplish these tasks, we have implemented segmentation of part geometries and extraction of axes of planar and cylindrical patches. To extract axes of parts used in the VE tutorial, the system performs segmentation on all the parts. Segmentation allows us to divide a single geometry into a set of surfaces and then extract axes and normals for certain types of surfaces. Current version of the algorithm classifies all extracted surfaces into three categories: planar, cylindrical, and curved. Axes are calculated for planar and cylindrical surfaces. Surfaces which the system has determined do not fall in the planar or cylindrical category are placed in the curved category. Axes of the generic curved patches are not extracted. Segmentation and classification is conducted in three stages. In the first stage, the algorithm calculates angles between all adjacent facets and places all adjacent, coplanar facets into planar groups. In the second stage, the algorithm visits all planar groups, which represent small planar patches, and combines certain adjacent planar groups into larger curved groups based on a set of heuristics. The heuristics are based on the area of a planar patch relative to total part area, area of planar patches relative to area of neighboring planar patches, and angles between neighboring planar patches. In the final stage the algorithm visits all curved patches which were created in the previous stage and labels some of them as cylindrical based on certain characteristics. If at least 90% of the surface area of a curved patch belongs to facets which share a common axis, then the curved patch is redesignated as cylindrical. By common axis we mean an axis which is perpendicular to the normals of a set of planar surfaces. Once the cylindrical surface is discovered the system uses the common axis belonging to most of the surface area as the axis of the patch. The axis of a planar patch is simply the normal of the surface. A flow chart depicting this process is presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig8">8</a>.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig8_HTML.gif?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig8_HTML.gif" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Flow chart showing the three phases of part segmentation</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig9">9</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig10">10</a> show how two parts were segmented into patches. The part in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig9">9</a>, a model airplane engine piston, has 12 planar patches, 6 cylinder-like patches and 0 generic rounded patches. The segmentation algorithm produced 13 planar patches, 6 cylinder-like patches and 1 generic rounded patch. The part in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig10">10</a>, a parachute deployment device (PDD) cartridge, has 4 planar patches, 2 cylinder-like patches and 1 generic rounded patch. The segmentation algorithm produced 4 planar patches, 2 cylinder-like patches and 1 generic rounded patch. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig11">11</a> shows the sequence declaration phase of Virtual Author where a tutorial for the ejection seat rocket is being built. The axis shown can be used by the instructor to extract parts from the main assembly. The axis was generated dynamically based on the geometries of selected parts.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig9_HTML.gif?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig9_HTML.gif" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Segmentation performed on model airplane engine piston. Each surface has a different <i>color</i>. Surface types are listed in <i>left</i> window</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig10_HTML.gif?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig10_HTML.gif" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Segmentation performed on a parachute deployment device cartridge. Each surface has a different <i>color</i>. Surface types are listed in <i>left</i> window</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig11_HTML.gif?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig11_HTML.gif" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Part extraction axis generated by Virtual Author. Since the user clicked on a cylindrical part, only one axis was generated</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        </div></div></section><section aria-labelledby="Sec14"><div class="c-article-section" id="Sec14-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec14">System testing and results</h2><div class="c-article-section__content" id="Sec14-content"><p>We conducted a detailed user study involving 30 subjects<sup><a href="#Fn1"><span class="u-visually-hidden">Footnote </span>1</a></sup> and two tutorials to assess performance of our system. Thirty subjects were selected from three different groups: ten undergraduate engineering students, ten graduate engineering students and ten working engineers. The purpose of this study was to gather large amounts of data from each user and mine this data to gain a better understanding of how people were training in the VTS. Also of interest was which features and training modes were most used, how long people were training and user response through pre and post-training questionnaires.</p><p>The structure of the study allowed it to be broken up into two parts: Training Session I and Training Session II. This was done for two reasons. First it allowed the test subjects to not dedicate a single 3-h block of time to complete the study. Second it provided a natural stopping point for the subjects to be interviewed about their performance in training session I before beginning training session II. Both training sessions consisted of surveys, question and answer, training in the VTS and real life testing. The data logging system, set to collect every 0.5 s, was activated for each tutorial and during the VE testing sessions. This information included modes and functions being used, time and errors.</p><p>The first tutorial created for use in this study was based on a small military rocket motor that is a component of an ejection seat release mechanism. The tutorial taught the proper assembly of the rocket motor from beginning to end. The assembly consisted of nine steps and ten components with varying geometric complexity. This device was selected because most test subjects would not have experience in assembling devices similar to this and its part count and step count were in the desired range so that the amount of time subjects were committing to the study was manageable. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig12">12</a> shows a screen shot of the rocket motor parts in the virtual environment. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig13">13</a> is a photograph of the actual device. Parts in the virtual environment were augmented in size for easier manipulation and viewing of feature details. A properly scaled quarter was placed on the table with the parts to give a sense of true sizes.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig12_HTML.jpg?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig12_HTML.jpg" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Screen shot of the rocket motor used in the first tutorial</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-13"><figure><figcaption><b id="Fig13" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 13</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/13" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig13_HTML.jpg?as=webp"></source><img aria-describedby="figure-13-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig13_HTML.jpg" alt="figure13" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-13-desc"><p>Photograph of the actual rocket motor used in physical testing</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/13" data-track-dest="link:Figure13 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The second tutorial created for use in this study was based on a small, single cylinder (0.60 cubic in. displacement) model airplane engine. The tutorial taught the proper assembly of the airplane engine from beginning to end. The assembly consisted of ten steps and 11 components with varying geometric complexity. This device was selected because it is similar in difficulty to the rocket tutorial and because most test subjects would not have experience in assembling devices similar to this. Also, its part count and step count were close to the rocket tutorial so the amount of time that subjects were committing to the study was manageable. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig14">14</a> shows a screen shot of the model airplane engine parts in the virtual environment. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig15">15</a> is a photograph of the actual device.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-14"><figure><figcaption><b id="Fig14" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 14</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/14" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig14_HTML.jpg?as=webp"></source><img aria-describedby="figure-14-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig14_HTML.jpg" alt="figure14" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-14-desc"><p>Screen shot of the model airplane engine used in the second tutorial. As two objects collide they become translucent</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/14" data-track-dest="link:Figure14 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-15"><figure><figcaption><b id="Fig15" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 15</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/15" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig15_HTML.jpg?as=webp"></source><img aria-describedby="figure-15-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig15_HTML.jpg" alt="figure15" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-15-desc"><p>Photograph of the actual model airplane engine used in physical testing. For physical testing this device was partially assembled to match the VE tutorial consisting of ten steps</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/15" data-track-dest="link:Figure15 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The following is a step by step description of the procedures followed in the first training session, which demonstrated the assembly of the rocket motor. The process is summarized in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig16">16</a>.</p><ol class="u-list-style-none">
                  <li>
                    <span class="u-custom-list-number">1.</span>
                    
                      <p>To begin the discussion of the study the subjects were explained the various forms of training that are available in industry and academic settings. The subjects were then asked to fill out one survey and one set of questionnaires. This was done before the study began to avoid any potential influence on the subjects’ opinions and establish a baseline. The survey presented each subject with a sample training scenario and a set of seven learning modes and asked them to rank order the learning modes from 1 to 7, one being their most preferred method of learning and seven being their least preferred method of learning.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">2.</span>
                    
                      <p>The subjects were then asked to fill out a questionnaire that gathered information about their current knowledge of virtual reality and virtual reality based training. It also inquired about video game experience and if the subject had ever had a virtual reality experience before.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">3.</span>
                    
                      <p>Each subject was then given the same introduction to the Virtual Training Studio consisting of an explanation of the purpose of the system and a description of current and potential applications of the system. The function of the individual hardware components was explained along with a quick overview of the software being used.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">4.</span>
                    
                      <p>The subject was then given a quick overview of the wand and asked to enter the virtual environment and participate in an interactive wand training session to familiarize him or her with the controls.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">5.</span>
                    
                      <p>The subject was asked several questions to verify their knowledge of the wand interface. The subject was required to know all of the functions before moving on to the first tutorial.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">6.</span>
                    
                      <p>A short training demonstration was given to show each subject how to use the modes and features available to them.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">7.</span>
                    
                      <p>Prior to entering the virtual environment to begin the first training session, subjects were explained the goals of the study and how they would be tested after completing the training so that they could tailor their learning as they saw fit. The training session was completely free form and user driven to allow each subject to develop their own training process without any outside assistance. The 25 min training session was broken up into two parts so that the potential for VR related motion sickness was minimized. The first part was a 15 min session and the second part lasted 10 min. If the subject was comfortable with their knowledge of the process after the first part, the second part was not required. Again, this decision was up to the individual knowing that it would be necessary for them to pass two tests upon completion.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">8.</span>
                    
                      <p>Upon completion of the training session, each subject was asked to fill out a series of questions relating to their likes and dislikes about training in the virtual environment, specific information about the some of the modes and features and whether or not they felt that they could perform the operation in real life as a result of their training.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">9.</span>
                    
                      <p>Two tests were created to verify that the users were learning in the virtual environment. The first test was a virtual environment test that consisted of three steps. The subject had to perform those steps in the virtual environment without any help. In order to successfully complete the test, the subject was required to analyze the state of assembly of the rocket and based on the parts remaining on the table, correctly perform the next step without any instructions, animations, video or audio help. Once the step was completed correctly, the system automatically jumped to the next selected step and the process continued until all three steps were completed successfully or the 5 min time limit was reached. During this testing in the virtual environment the system carried out detection and logging of errors. Each time the subject performed an incorrect placement of one subassembly relative to another and signalled for the animation to take over, the subject would hear a buzz and get a text error message on the virtual projector screen.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">10.</span>
                    
                      <p>Once the VE test was complete, the subject was asked complete a second test to verify learning. The subject was asked to assemble the real device from his/her memory without any outside assistance. There was no time limit on this test, the only requirement was that the exact order of steps was followed and the parts were of course assembled correctly. No tools needed to be used to assemble the device. The subject just had to demonstrate correct sequence and part placement.</p>
                    
                  </li>
                </ol><p>The following is a step by step description of the procedures followed in the second training session, which demonstrated the assembly of a model airplane engine. The process is summarized in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig17">17</a>.</p><ol class="u-list-style-none">
                  <li>
                    <span class="u-custom-list-number">1.</span>
                    
                      <p>Before beginning training on the second tutorial, each subject was asked how they planned to train in this tutorial based on their performance in training session I. They were instructed that they were not required to follow their proposed training path if it was not working for them, but they would have to explain why they deviated from it in the post-training questionnaire.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">2.</span>
                    
                      <p>As before the 25 min training session was broken up into two parts with the second part being optional.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">3.</span>
                    
                      <p>Upon completion of the training session, each subject was asked to fill out a series of questions relating to their likes and dislikes about training in the virtual environment.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">4.</span>
                    
                      <p>Two tests were again used to verify that the users were learning in the virtual environment. The first test, as before was a virtual environment test consisting of three steps. Again, in order to successfully complete the test, the subject was required to analyze the state of assembly of the engine and based on the parts remaining on the table, determine and correctly perform the next step without any instructions, animations, video or audio help.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">5.</span>
                    
                      <p>Once the VE test was complete, the subject was asked complete the second test to verify learning. As before, the subject was asked to assemble the real device from his/her memory without any outside assistance. There was no time limit on this test. The only requirement was that the exact order of steps was followed and the parts were assembled correctly. Again tools were not needed for the assembly of the device.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">6.</span>
                    
                      <p>In the first training session, the subjects were asked to fill out a survey where they rank ordered learning preferences based on a sample scenario. Each subject was again asked to fill out this survey upon completion of the training to see if there was any change in their preferences as a result of being exposed to the Virtual Training Studio.</p>
                    
                  </li>
                </ol><p>The main findings of the study were as follows:</p><ol class="u-list-style-none">
                  <li>
                    <span class="u-custom-list-number">1.</span>
                    
                      <p>During the first study involving a rocket motor, overall 94.4% steps were performed correctly by the users during the physical demonstration after completing the training. During the second study involving a model airplane engine, overall 97.3% steps were performed correctly by the users during the physical demonstration after completing the training. None of the users tested during these two studies had assembled either a rocket motor or a model airplane engine similar to the ones used in these experiments prior to participating in this study. These results clearly show that our system can be successfully used for training of assembly operations.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">2.</span>
                    
                      <p>Users show different preferences for training modes based on the task at hand and individual training styles (i.e. different people chose to train differently on the same task).</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">3.</span>
                    
                      <p>All three main training modes were used during the studies. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig18">18</a> shows that 94% of the subjects used interactive simulation while 81% used the 3D animation mode and 18% used the video mode. (Note: the percentages will not sum to 100% because subjects were allowed to use more than one training method.)</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">4.</span>
                    
                      <p>Certain task characteristics make certain training modes more popular. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig19">19</a> shows that video mode and hint use were, on average, used more often on steps where the geometry or the part orientation was considered complex. Interactive simulation and 3D animation were very close to a 50–50 distribution but still slightly favoring the more complex steps.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">5.</span>
                    
                      <p>All three training modes work satisfactorily during user studies and users are able to successfully learn using them. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig20">20</a> shows that the use of the three modes varied little between the tutorials. Had there been significant problems with any one mode, we believe trainees would have used it much less in the second tutorial.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">6.</span>
                    
                      <p>Users are able to seamlessly switch back and forth between training modes and utilize multiple training modes on the same task. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0076-4#Fig21">21</a> shows the training path that users chose. Two of the most popular training paths were completing the assembly in 3D animation and then trying to complete it again using the interactive simulation mode (3D-IS) and alternating between 3D animation and interactive simulation for each step (3D/IS).</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">7.</span>
                    
                      <p>Novel features that have been implemented to support training modes and switching back and forth between modes have satisfactory computational performance for assembly tasks requiring ten steps or less. Training time was virtually unaffected by the fraction of time it takes to switch between modes or to check for errors during interactive simulation. Average training time for each tutorial is shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-007-0076-4#Tab1">1</a>.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">8.</span>
                    
                      <p>Our implementation of VR based training system matches or exceeds users’ expectations in most cases. Pre- and post-training questionnaires allowed us to capture users’ likes and dislikes of the VTS. When asked to rank order 7 training methods used for manufacturing processes before being exposed to VTS, the average ranking for the VR based method was 3. After being exposed and allowed to train in the VTS, that average rank improved to 2, just behind master-apprentice style training. The results from this survey are shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-007-0076-4#Tab2">2</a>.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">9.</span>
                    
                      <p>Subjects that are not prone to VR-induced motion sickness are, on average, able to learn 10-step assembly sequences within 17.4 min training sessions. These training sessions did not have any adverse effect on the subjects.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">10.</span>
                    
                      <p>The wand-based interface is an effective user interface for tasks where the primary objective is cognitive learning as opposed to motor skill development. This interface is significantly less expensive than a haptics type of interface.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">11.</span>
                    
                      <p>The average training time for a simple step was 90 s while the average training time for a complex step was 116 s, a 29% increase.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">12.</span>
                    
                      <p>As people get more experienced (i.e. move from the first tutorial to the second tutorial) with our system they tend to utilize the wand rotation feature more often. This is primarily due to gaining familiarity with the VTS and the wand rotation feature. This results in an average per step time reduction from 108 s per step on the rocket tutorial to 101 s on the airplane engine tutorial, a reduction of 6.5%.</p>
                    
                  </li>
                </ol><p>The results of the case study will be used to update and improve the VTS to better suit actual users of the system. Further case studies are necessary (and being planned) to analyze each feature in depth and gain a thorough understanding of each mode and feature’s effect on the overall function and performance of the VTS. The importance of continued collection and expansion of this knowledge, just like in any computer system interacting with humans, is absolutely imperative for further system improvements and so that the VTS will be able to accommodate all training types at many levels of knowledge and still remain effective for all users.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-16"><figure><figcaption><b id="Fig16" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 16</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/16" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig16_HTML.gif?as=webp"></source><img aria-describedby="figure-16-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig16_HTML.gif" alt="figure16" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-16-desc"><p>Protocol for Training Session I</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/16" data-track-dest="link:Figure16 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-17"><figure><figcaption><b id="Fig17" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 17</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/17" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig17_HTML.gif?as=webp"></source><img aria-describedby="figure-17-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig17_HTML.gif" alt="figure17" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-17-desc"><p>Protocol for Training Session II</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/17" data-track-dest="link:Figure17 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-18"><figure><figcaption><b id="Fig18" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 18</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/18" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig18_HTML.gif?as=webp"></source><img aria-describedby="figure-18-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig18_HTML.gif" alt="figure18" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-18-desc"><p>Average learning mode usage. Interactive simulation and 3D animation are highly utilized by the case study subjects</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/18" data-track-dest="link:Figure18 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-19"><figure><figcaption><b id="Fig19" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 19</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/19" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig19_HTML.gif?as=webp"></source><img aria-describedby="figure-19-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig19_HTML.gif" alt="figure19" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-19-desc"><p>Learning mode usage by step complexity, simple or complex aggregated for both tutorials</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/19" data-track-dest="link:Figure19 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-20"><figure><figcaption><b id="Fig20" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 20</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/20" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig20_HTML.gif?as=webp"></source><img aria-describedby="figure-20-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig20_HTML.gif" alt="figure20" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-20-desc"><p>Learning mode usage by tutorial, illustrating very little variation between the tutorials</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/20" data-track-dest="link:Figure20 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-21"><figure><figcaption><b id="Fig21" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 21</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/21" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig21_HTML.gif?as=webp"></source><img aria-describedby="figure-21-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0076-4/MediaObjects/10055_2007_76_Fig21_HTML.gif" alt="figure21" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-21-desc"><p>Preferred training paths illustrating the ability to switch training modes</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0076-4/figures/21" data-track-dest="link:Figure21 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Number of steps of particular type and average training time for each tutorial</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-007-0076-4/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Results of a survey ranking various learning methods before and after VTS training</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-007-0076-4/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     </div></div></section><section aria-labelledby="Sec15"><div class="c-article-section" id="Sec15-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec15">Conclusions</h2><div class="c-article-section__content" id="Sec15-content"><p>This paper describes the design and implementation of a set of key features within Virtual Training Studio as well as the user study that was performed to test the training effectiveness of the system. Some of the key features of the VTS are handling of symmetries and clones, error detection, dynamic animations, annotation of ambiguous instructions, automatic generation of text instructions from motion, and part segmentation and extraction of axes. Our most recent user study allowed us to verify that these key features worked effectively in supporting multiple modes of the VTS. The user study has also shown that the VTS can be successfully used to train operators to learn assembly operations, judging by the high physical test success rates of undergraduate students, graduate students, and professional engineers. Our concept of multimodal instructions seemed to be especially effective because most trainees preferred to switch between modes many times during training. In the process of conducting the latest user study we also discovered how people actually train using the virtual environment. Our study reports what system features are used by people and in what training scenarios they are used.</p><p>We foresee a number benefits from the use of the Virtual Training Studio. First, we believe that the number of personnel required to become trainers will be reduced, since the system will perform the bulk of the training. Second, the system will provide a convenient mechanism for depositing assembly process knowledge into a central repository for later retrieval by trainees, trainers and managers. Third, the VTS will assist instructors in the creation of VE based tutorials and paper based documentation by generating an instruction set from the animation sequence and by providing a convenient way of generating 2D illustrations. Fourth, the system will provide an affordable Personal Virtual Environment. Finally, we believe that the most important benefits will be an accelerated learning process as well as a reduced probability of worker error.</p><p>We have a number of ideas for the future direction of the VTS. We plan to redesign the environment of the VTS in a way that will reduce occurrence of motion sickness. This, we believe, can be done by creating a more ergonomic work cell that reduces the head and body motion of the trainees. We also intend to implement more sophisticated physics-based modelling. Additionally, we intend to add support for alternative hardware configurations. One example of that is the use of an HMD for stereoscopic visualization with a mouse and joystick user interface, allowing for a lower cost setup. Finally, we plan to improve the design of the VTS to support more complex assemblies.</p></div></div></section>
                        
                    

                    <section aria-labelledby="notes"><div class="c-article-section" id="notes-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="notes">Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1"><span class="c-article-footnote--listed__index">1.</span><div class="c-article-footnote--listed__content"><p>Overall 35 subjects participated in the study. Five users did not complete study due to motion sickness. Hence the data for these five subjects was discarded. We only used data for 30 subjects who successfully completed the study.</p></div></li></ol></div></div></section><section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">Reference</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Abe N, Zhang JY, Tanaka K, Taki H (1996) A training system using virtual machines for teaching assembling/disa" /><p class="c-article-references__text" id="ref-CR1">Abe N, Zhang JY, Tanaka K, Taki H (1996) A training system using virtual machines for teaching assembling/disassembling operations to novices. In: Proceedings of IEEE international conference on systems man and cybernetics, 1996, pp 2096–2101</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Banerjee A, Cecil J (2003) A virtual reality based decision support framework for manufacturing simulation. In" /><p class="c-article-references__text" id="ref-CR2">Banerjee A, Cecil J (2003) A virtual reality based decision support framework for manufacturing simulation. In: Computers and Information in Engineering Conference (Paper CIE-48296), Chicago, Illinois, September 2003</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RW. Chu, CM. Mitchell, PM. Jones, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Chu RW, Mitchell CM, Jones PM (1995) Using the operator function model and ofmspert as the basis for an intell" /><p class="c-article-references__text" id="ref-CR3">Chu RW, Mitchell CM, Jones PM (1995) Using the operator function model and ofmspert as the basis for an intelligent tutoring system: towards a tutor/aid paradigm for operators of supervisory control systems. IEEE Trans Syst Man Cybern 25(7):1054–1075</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F21.391287" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Using%20the%20operator%20function%20model%20and%20ofmspert%20as%20the%20basis%20for%20an%20intelligent%20tutoring%20system%3A%20towards%20a%20tutor%2Faid%20paradigm%20for%20operators%20of%20supervisory%20control%20systems.&amp;journal=IEEE%20Trans%20Syst%20Man%20Cybern&amp;volume=25&amp;issue=7&amp;pages=1054-1075&amp;publication_year=1995&amp;author=Chu%2CRW&amp;author=Mitchell%2CCM&amp;author=Jones%2CPM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="VG. Duffy, FF. Wu, P. Ng, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Duffy VG, Wu FF, Ng P (2003) Development of an internet virtual layout system for improving workplace safety. " /><p class="c-article-references__text" id="ref-CR4">Duffy VG, Wu FF, Ng P (2003) Development of an internet virtual layout system for improving workplace safety. Comput Ind 50(2):207–230</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0166-3615%2802%2900121-5" aria-label="View reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Development%20of%20an%20internet%20virtual%20layout%20system%20for%20improving%20workplace%20safety&amp;journal=Comput%20Ind&amp;volume=50&amp;issue=2&amp;pages=207-230&amp;publication_year=2003&amp;author=Duffy%2CVG&amp;author=Wu%2CFF&amp;author=Ng%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Gamberini, P. Cottone, A. Spagnolli, D. Varotto, G. Mantovani, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Gamberini L, Cottone P, Spagnolli A, Varotto D, Mantovani G (2003) Responding to a fire emergency in a virtual" /><p class="c-article-references__text" id="ref-CR5">Gamberini L, Cottone P, Spagnolli A, Varotto D, Mantovani G (2003) Responding to a fire emergency in a virtual environment: different patterns of action for different situations. Ergonomics 46(8):842–858</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F0014013031000111266" aria-label="View reference 5">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Responding%20to%20a%20fire%20emergency%20in%20a%20virtual%20environment%3A%20different%20patterns%20of%20action%20for%20different%20situations.&amp;journal=Ergonomics&amp;volume=46&amp;issue=8&amp;pages=842-858&amp;publication_year=2003&amp;author=Gamberini%2CL&amp;author=Cottone%2CP&amp;author=Spagnolli%2CA&amp;author=Varotto%2CD&amp;author=Mantovani%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Gupta, D. Whitney, D. Zeltzer, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Gupta R, Whitney D, Zeltzer D (1997) Prototyping and design for assembly analysis using multi-modal virtual en" /><p class="c-article-references__text" id="ref-CR6">Gupta R, Whitney D, Zeltzer D (1997) Prototyping and design for assembly analysis using multi-modal virtual environments. Comput Aided Des 29(8):585–597</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0010-4485%2896%2900093-0" aria-label="View reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Prototyping%20and%20design%20for%20assembly%20analysis%20using%20multi-modal%20virtual%20environments.&amp;journal=Comput%20Aided%20Des&amp;volume=29&amp;issue=8&amp;pages=585-597&amp;publication_year=1997&amp;author=Gupta%2CR&amp;author=Whitney%2CD&amp;author=Zeltzer%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hodges M (1998) Virtual reality in training. Comput Graph World 21(8)" /><p class="c-article-references__text" id="ref-CR7">Hodges M (1998) Virtual reality in training. Comput Graph World 21(8)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Jayaram U, Tirumali H, Jayaram S (2000) A tool/part/human interaction model for assembly in virtual environmen" /><p class="c-article-references__text" id="ref-CR8">Jayaram U, Tirumali H, Jayaram S (2000) A tool/part/human interaction model for assembly in virtual environments. Computers and Information in Engineering Conference, Baltimore, MD, September 2000</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Jayaram U, Jayaram S, DeChenne C, Jun Kim Y (2004) Case studies using immersive virtual assembly in industry. " /><p class="c-article-references__text" id="ref-CR9">Jayaram U, Jayaram S, DeChenne C, Jun Kim Y (2004) Case studies using immersive virtual assembly in industry. Computers and Information in Engineering Conference, Salt Lake City, UT, September 2004</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MM. Keehner, F. Tendick, MV. Meng, HP. Anwar, M. Hegarty, ML. Stoller, QY. Duh, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Keehner MM, Tendick F, Meng MV, Anwar HP, Hegarty M, Stoller ML, Duh QY (2004) Spatial ability, experience, an" /><p class="c-article-references__text" id="ref-CR10">Keehner MM, Tendick F, Meng MV, Anwar HP, Hegarty M, Stoller ML, Duh QY (2004) Spatial ability, experience, and skill in laparoscopic surgery. Am J Surg 188(1):71–75</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.amjsurg.2003.12.059" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatial%20ability%2C%20experience%2C%20and%20skill%20in%20laparoscopic%20surgery.&amp;journal=Am%20J%20Surg&amp;volume=188&amp;issue=1&amp;pages=71-75&amp;publication_year=2004&amp;author=Keehner%2CMM&amp;author=Tendick%2CF&amp;author=Meng%2CMV&amp;author=Anwar%2CHP&amp;author=Hegarty%2CM&amp;author=Stoller%2CML&amp;author=Duh%2CQY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kim C, Vance J (2003) Using vps (voxmap pointshell) as the basis for interaction in a virtual assembly environ" /><p class="c-article-references__text" id="ref-CR11">Kim C, Vance J (2003) Using vps (voxmap pointshell) as the basis for interaction in a virtual assembly environment. Computers and Information in Engineering Conference, Chicago, Illinois, September 2003</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="KR. Koedinger, V. Aleven, N. Heffernan, B. McLaren, M. Hockenberry, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Koedinger KR, Aleven V, Heffernan N, McLaren B, Hockenberry M (2004) Opening the door to non-programmers: auth" /><p class="c-article-references__text" id="ref-CR12">Koedinger KR, Aleven V, Heffernan N, McLaren B, Hockenberry M (2004) Opening the door to non-programmers: authoring intelligent tutor behaviour by demonstration. Lect Notes Comput Sci 3220:162–174</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2F978-3-540-30139-4_16" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Opening%20the%20door%20to%20non-programmers%3A%20authoring%20intelligent%20tutor%20behaviour%20by%20demonstration.&amp;journal=Lect%20Notes%20Comput%20Sci&amp;volume=3220&amp;pages=162-174&amp;publication_year=2004&amp;author=Koedinger%2CKR&amp;author=Aleven%2CV&amp;author=Heffernan%2CN&amp;author=McLaren%2CB&amp;author=Hockenberry%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mikchevitch A, Leon JC, Gouskov A (2003) Numerical modelling of flexible components for assembly path planning" /><p class="c-article-references__text" id="ref-CR13">Mikchevitch A, Leon JC, Gouskov A (2003) Numerical modelling of flexible components for assembly path planning using a virtual reality environment. Computers and Information in Engineering Conference, Chicago, Illinois, September 2003</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Morris, C. Sewell, N. Blevins, F. Barbagli, K. Salisbury, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Morris D, Sewell C, Blevins N, Barbagli F, Salisbury K (2004) A collaborative virtual environment for the simu" /><p class="c-article-references__text" id="ref-CR14">Morris D, Sewell C, Blevins N, Barbagli F, Salisbury K (2004) A collaborative virtual environment for the simulation of temporal bone surgery. Medical image computing and computer-assisted intervention. Springer Lect Notes Comput Sci 3217:319–327</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2F978-3-540-30136-3_40" aria-label="View reference 14">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20collaborative%20virtual%20environment%20for%20the%20simulation%20of%20temporal%20bone%20surgery.%20Medical%20image%20computing%20and%20computer-assisted%20intervention.&amp;journal=Springer%20Lect%20Notes%20Comput%20Sci&amp;volume=3217&amp;pages=319-327&amp;publication_year=2004&amp;author=Morris%2CD&amp;author=Sewell%2CC&amp;author=Blevins%2CN&amp;author=Barbagli%2CF&amp;author=Salisbury%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Munro, DM. Towne, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Munro A, Towne DM (1992) Productivity tools for simulation-centered training development. Educ Technol Res Dev" /><p class="c-article-references__text" id="ref-CR15">Munro A, Towne DM (1992) Productivity tools for simulation-centered training development. Educ Technol Res Dev 40(4):65–80</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2FBF02296900" aria-label="View reference 15">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Productivity%20tools%20for%20simulation-centered%20training%20development.&amp;journal=Educ%20Technol%20Res%20Dev&amp;volume=40&amp;issue=4&amp;pages=65-80&amp;publication_year=1992&amp;author=Munro%2CA&amp;author=Towne%2CDM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Paiva, I. Machado, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Paiva A, Machado I (1998) Vincent: an autonomous pedagogical agent for on-the-job training. Proc Lect Notes Co" /><p class="c-article-references__text" id="ref-CR16">Paiva A, Machado I (1998) Vincent: an autonomous pedagogical agent for on-the-job training. Proc Lect Notes Comput Sci 1452:584–593</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2F3-540-68716-5_64" aria-label="View reference 16">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Vincent%3A%20an%20autonomous%20pedagogical%20agent%20for%20on-the-job%20training.&amp;journal=Proc%20Lect%20Notes%20Comput%20Sci&amp;volume=1452&amp;pages=584-593&amp;publication_year=1998&amp;author=Paiva%2CA&amp;author=Machado%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Peng X, Chi X, Ochoa JA, Leu MC (2003) Bone surgery simulation with virtual reality. Computers and Information" /><p class="c-article-references__text" id="ref-CR17">Peng X, Chi X, Ochoa JA, Leu MC (2003) Bone surgery simulation with virtual reality. Computers and Information in Engineering Conference, Chicago, Illinois, September 2003</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Rickel, WL. Johnson, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Rickel J, Johnson WL (1999) Animated agents for procedural training in virtual reality: perception, cognition " /><p class="c-article-references__text" id="ref-CR18">Rickel J, Johnson WL (1999) Animated agents for procedural training in virtual reality: perception, cognition and motor control. Appl Artif Intell 13(4–5):343–382</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Animated%20agents%20for%20procedural%20training%20in%20virtual%20reality%3A%20perception%2C%20cognition%20and%20motor%20control.&amp;journal=Appl%20Artif%20Intell&amp;volume=13&amp;issue=4%E2%80%935&amp;pages=343-382&amp;publication_year=1999&amp;author=Rickel%2CJ&amp;author=Johnson%2CWL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JM. Ritchie, RG. Dewar, J. Simmons, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Ritchie JM, Dewar RG, Simmons J (1999) The generation and practical use of plans for manual assembly using imm" /><p class="c-article-references__text" id="ref-CR19">Ritchie JM, Dewar RG, Simmons J (1999) The generation and practical use of plans for manual assembly using immersive virtual reality. Proc Inst Mech Eng J Eng Manuf 213(5):461–474</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20generation%20and%20practical%20use%20of%20plans%20for%20manual%20assembly%20using%20immersive%20virtual%20reality.&amp;journal=Proc%20Inst%20Mech%20Eng%20J%20Eng%20Manuf&amp;volume=213&amp;issue=5&amp;pages=461-474&amp;publication_year=1999&amp;author=Ritchie%2CJM&amp;author=Dewar%2CRG&amp;author=Simmons%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="KJ. Stroud, DL. Harm, DM. Klaus, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Stroud KJ, Harm DL, Klaus DM (2005) Preflight virtual reality training as a countermeasure for space motion si" /><p class="c-article-references__text" id="ref-CR20">Stroud KJ, Harm DL, Klaus DM (2005) Preflight virtual reality training as a countermeasure for space motion sickness and disorientation. Aviat Space Environ Med 76(4):352–356</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Preflight%20virtual%20reality%20training%20as%20a%20countermeasure%20for%20space%20motion%20sickness%20and%20disorientation.&amp;journal=Aviat%20Space%20Environ%20Med&amp;volume=76&amp;issue=4&amp;pages=352-356&amp;publication_year=2005&amp;author=Stroud%2CKJ&amp;author=Harm%2CDL&amp;author=Klaus%2CDM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="F. Tendick, M. Downes, T. Goktekin, MC. Cavusoglu, D. Feygin, XL. Wu, R. Eyal, M. Hegarty, LW. Way, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Tendick F, Downes M, Goktekin T, Cavusoglu MC, Feygin D, Wu XL, Eyal R, Hegarty M, Way LW (2000) A virtual env" /><p class="c-article-references__text" id="ref-CR21">Tendick F, Downes M, Goktekin T, Cavusoglu MC, Feygin D, Wu XL, Eyal R, Hegarty M, Way LW (2000) A virtual environment testbed for training laparoscopic surgical skills. Presence Teleoperators Virtual Environ 9(3):236–255</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474600566772" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20virtual%20environment%20testbed%20for%20training%20laparoscopic%20surgical%20skills.&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=9&amp;issue=3&amp;pages=236-255&amp;publication_year=2000&amp;author=Tendick%2CF&amp;author=Downes%2CM&amp;author=Goktekin%2CT&amp;author=Cavusoglu%2CMC&amp;author=Feygin%2CD&amp;author=Wu%2CXL&amp;author=Eyal%2CR&amp;author=Hegarty%2CM&amp;author=Way%2CLW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Wan H, Gao S, Peng Q, Dai G, Zhang F (2004) MIVAS: a multi-modal immersive virtual assembly system. Computers " /><p class="c-article-references__text" id="ref-CR22">Wan H, Gao S, Peng Q, Dai G, Zhang F (2004) MIVAS: a multi-modal immersive virtual assembly system. Computers and Information in Engineering Conference, Salt Lake City, UT, September 2004</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-007-0076-4-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgments</h2><div class="c-article-section__content" id="Ack1-content"><p>This research is supported in parts by the Center for Energetic Concepts Development at the University of Maryland and Naval Surface Warfare Center at Indian Head.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Center for Energetic Concepts Development, Mechanical Engineering Department, University of Maryland, College Park, USA</p><p class="c-article-author-affiliation__authors-list">John E. Brough, Maxim Schwartz, Satyandra K. Gupta &amp; Davinder K. Anand</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Indian Head Division, Naval Surface Warfare Center, Indian Head, USA</p><p class="c-article-author-affiliation__authors-list">Robert Kavetsky &amp; Ralph Pettersen</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-John_E_-Brough"><span class="c-article-authors-search__title u-h3 js-search-name">John E. Brough</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;John E.+Brough&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=John E.+Brough" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22John E.+Brough%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Maxim-Schwartz"><span class="c-article-authors-search__title u-h3 js-search-name">Maxim Schwartz</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Maxim+Schwartz&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Maxim+Schwartz" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Maxim+Schwartz%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Satyandra_K_-Gupta"><span class="c-article-authors-search__title u-h3 js-search-name">Satyandra K. Gupta</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Satyandra K.+Gupta&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Satyandra K.+Gupta" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Satyandra K.+Gupta%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Davinder_K_-Anand"><span class="c-article-authors-search__title u-h3 js-search-name">Davinder K. Anand</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Davinder K.+Anand&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Davinder K.+Anand" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Davinder K.+Anand%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Robert-Kavetsky"><span class="c-article-authors-search__title u-h3 js-search-name">Robert Kavetsky</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Robert+Kavetsky&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Robert+Kavetsky" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Robert+Kavetsky%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Ralph-Pettersen"><span class="c-article-authors-search__title u-h3 js-search-name">Ralph Pettersen</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Ralph+Pettersen&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Ralph+Pettersen" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ralph+Pettersen%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-007-0076-4/email/correspondent/c1/new">Satyandra K. Gupta</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Towards%20the%20development%20of%20a%20virtual%20environment-based%20training%20system%20for%20mechanical%20assembly%20operations&amp;author=John%20E.%20Brough%20et%20al&amp;contentID=10.1007%2Fs10055-007-0076-4&amp;publication=1359-4338&amp;publicationDate=2007-04-26&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Brough, J.E., Schwartz, M., Gupta, S.K. <i>et al.</i> Towards the development of a virtual environment-based training system for mechanical assembly operations.
                    <i>Virtual Reality</i> <b>11, </b>189–206 (2007). https://doi.org/10.1007/s10055-007-0076-4</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-007-0076-4.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-07-31">31 July 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2007-03-16">16 March 2007</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2007-04-26">26 April 2007</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2007-10">October 2007</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-007-0076-4" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-007-0076-4</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Virtual Environment</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Motion Sickness</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Rocket Motor</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Head Mount Display</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Interactive Simulation</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-007-0076-4.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=76;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

