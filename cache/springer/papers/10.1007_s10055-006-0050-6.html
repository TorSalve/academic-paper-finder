<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Factors influencing flow of object focussed collaboration in collabora"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Creativity is believed to be helped by an uncluttered state of mind known as flow and as the trend grows towards less immersive displays to produce an uncluttered workplace, we ask the question..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/10/2.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Factors influencing flow of object focussed collaboration in collaborative virtual environments"/>

    <meta name="dc.source" content="Virtual Reality 2006 10:2"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2006-09-21"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2006 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Creativity is believed to be helped by an uncluttered state of mind known as flow and as the trend grows towards less immersive displays to produce an uncluttered workplace, we ask the question &#8220;Does immersion matter to the flow of distributed group work?&#8221;. The aim of this work is to study the impact of level of immersion on workflow and presence during object focussed distributed group work, and to discuss the relevance of these and other factors to supporting flow and creativity. This is approached through a comprehensive literature survey and significant new results. The study attempts to introduce a breadth of factors and relationships as opposed to proving a hypothesis and thus takes a wide qualitative rather than deep quantitative approach to testing and analysis."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2006-09-21"/>

    <meta name="prism.volume" content="10"/>

    <meta name="prism.number" content="2"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="119"/>

    <meta name="prism.endingPage" content="133"/>

    <meta name="prism.copyright" content="2006 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-006-0050-6"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-006-0050-6"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-006-0050-6.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-006-0050-6"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Factors influencing flow of object focussed collaboration in collaborative virtual environments"/>

    <meta name="citation_volume" content="10"/>

    <meta name="citation_issue" content="2"/>

    <meta name="citation_publication_date" content="2006/10"/>

    <meta name="citation_online_date" content="2006/09/21"/>

    <meta name="citation_firstpage" content="119"/>

    <meta name="citation_lastpage" content="133"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-006-0050-6"/>

    <meta name="DOI" content="10.1007/s10055-006-0050-6"/>

    <meta name="citation_doi" content="10.1007/s10055-006-0050-6"/>

    <meta name="description" content="Creativity is believed to be helped by an uncluttered state of mind known as flow and as the trend grows towards less immersive displays to produce an uncl"/>

    <meta name="dc.creator" content="David Roberts"/>

    <meta name="dc.creator" content="Ilona Heldal"/>

    <meta name="dc.creator" content="Oliver Otto"/>

    <meta name="dc.creator" content="Robin Wolff"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Benford SD et al (1995) User embodiment in collaborative virtual environments. In: CHI&#8217;95. ACM Press, Denver"/>

    <meta name="citation_reference" content="Bente G, Kraemer NC (2002) Virtual gestures: analyzing social presence effects of computer-mediated and computer-generated nonverbal behaviour. In: Fifth annual international workshop PRESENCE 2002. Porto, pp 233&#8211;244"/>

    <meta name="citation_reference" content="citation_title=Virtual environments standards and terminology; citation_inbook_title=Handbook of virtual environments. Design, implementation, and applications; citation_publication_date=2002; citation_pages=15-27; citation_id=CR3; citation_author=RA Blade; citation_author=ML Padgett; citation_publisher=Lawrence Erlbaum Associates"/>

    <meta name="citation_reference" content="Brogni A, Slater M, Steed A (2003) More breaks less presence. In: Presence 2003, The 6th annual international workshop on presence. Aalborg, Denmark"/>

    <meta name="citation_reference" content="citation_title=Creativity: flow and the psychology of discovery and invention; citation_publication_date=1996; citation_id=CR5; citation_author=M Csikszentmihalyi; citation_publisher=Harper Perennial"/>

    <meta name="citation_reference" content="citation_title=Information technologies; citation_inbook_title=Handbook of organizational communication; citation_publication_date=1987; citation_pages=420-442; citation_id=CR6; citation_author=MJ Culnan; citation_publisher=Sage Publication"/>

    <meta name="citation_reference" content="Fencott C (1999) Content and creativity in virtual environment design. In: Proceedings of virtual systems and multimedia &#8216;99. University of Abertay"/>

    <meta name="citation_reference" content="Fjeld M et al (2002) Physical and virtual tools: activity theory applied to the design of groupware. Computer supported cooperative work 11, pp 153&#8211;180"/>

    <meta name="citation_reference" content="Garau M et al (2001) The impact of eye gaze on communication using humanoid avatars. In CHI &#8216;01: Proceedings of the SIGCHI conference on human factors in computing systems. ACM Press, New York, pp 309&#8211;316"/>

    <meta name="citation_reference" content="Goffman E (1986) Frame analysis: an essay on the organization of experience. Northeastern University Press, Boston, xviii, [4], 586 s"/>

    <meta name="citation_reference" content="citation_title=Telepresence, time delay and adaptation; citation_inbook_title=Pictorial communication in virtual and real environments; citation_publication_date=1991; citation_pages=231-246; citation_id=CR11; citation_author=R Held; citation_author=N Durlach; citation_publisher=Taylor &amp; Francis"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Telepresence; citation_author=RM Held, NI Durlach; citation_volume=1; citation_issue=1; citation_publication_date=1992; citation_pages=109-112; citation_id=CR12"/>

    <meta name="citation_reference" content="Heldal I (2004) Usability development for collaborative virtual environments. In: VIRART workshop: designing and evaluating virtual reality systems. Nottingham"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Successes and failures in copresent situations; citation_author=I Heldal; citation_volume=14; citation_issue=5; citation_publication_date=2005; citation_pages=563-579; citation_doi=10.1162/105474605774918679; citation_id=CR14"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Comput Human Interact(ToCHI); citation_title=Object-focused interaction in collaborative virtual environments; citation_author=J Hindmarsh; citation_volume=7; citation_issue=4; citation_publication_date=2000; citation_pages=477-509; citation_doi=10.1145/365058.365088; citation_id=CR15"/>

    <meta name="citation_reference" content="Monk A (2003) Common ground in electronically mediated communication: clarks theory of language use. In: Carroll J (ed) HCI models, theories and frameworks. Morgan Kaufmann, San Francisco, pp 263&#8211;290"/>

    <meta name="citation_reference" content="Nardi B, Whittaker S (2002) The role of face-to-face communication in distributed work. MIT Press, Cambridge, pp 83&#8211;112"/>

    <meta name="citation_reference" content="Nilsson A et al (2002) The long-term uses of shared virtual environments: an exploratory study. In: Schroeder R (ed) The social life of avatars. Springer, London"/>

    <meta name="citation_reference" content="Norman D (1998) The invisible computer. Why good products can fail, the personal computer is so complex, and information appliances ate the solution. The MIT Press, London. 0262140659"/>

    <meta name="citation_reference" content="Poston T, Serra L (1996) Dextrous virtual work. Communications of the ACM, pp 37&#8211;45"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Virtual reality as communication tool: a socio-cognitive analysis; citation_author=G Riva; citation_volume=8; citation_issue=4; citation_publication_date=1999; citation_pages=462-468; citation_doi=10.1162/105474699566341; citation_id=CR21"/>

    <meta name="citation_reference" content="Roberts D et al (2004) Supporting social human communication between distributed walk-in displays. In: VRST &#8216;04: ACM symposium on virtual reality software and technology, pp 81&#8211;88"/>

    <meta name="citation_reference" content="Roberts D et al (2005) Reducing fragmentation in telecollaboration by using IPT interfaces. In: IPT-EGVE workshop: Eurographics Association, Switzerland, pp 211&#8211;216"/>

    <meta name="citation_reference" content="citation_title=Presence in virtual environments; citation_inbook_title=Handbook of virtual environments. Design, implementation, and applications; citation_publication_date=2002; citation_pages=791-806; citation_id=CR24; citation_author=W Sadowski; citation_author=K Stanney; citation_publisher=Lawrence Erlbaum Associates"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graphics; citation_title=Collaborating in networked immersive spaces: as good as being there together?; citation_author=R Schroeder; citation_volume=25; citation_issue=5; citation_publication_date=2001; citation_pages=781-788; citation_doi=10.1016/S0097-8493(01)00120-0; citation_id=CR25"/>

    <meta name="citation_reference" content="citation_title=Communication technology and group communication; citation_inbook_title=The handbook of group communication theory and research; citation_publication_date=1999; citation_pages=431-472; citation_id=CR26; citation_author=CR Scott; citation_publisher=Sage"/>

    <meta name="citation_reference" content="Shneiderman B (2002) Leonardo&#8217;s laptop: human needs and the new computing technologies: MIT Press, Cambridge. 0262194767"/>

    <meta name="citation_reference" content="citation_title=The social psychology of telecommunications; citation_publication_date=1976; citation_id=CR28; citation_author=J Short; citation_author=E Williams; citation_author=B Christie; citation_publisher=Wiley"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=A virtual presence counter; citation_author=M Slater, A Steed; citation_volume=9; citation_issue=5; citation_publication_date=2000; citation_pages=413-434; citation_doi=10.1162/105474600566925; citation_id=CR29"/>

    <meta name="citation_reference" content="citation_journal_title=Presence: Teleoperators Virtual Environ; citation_title=A framework for immersive virtual environments (FIVE): Speculations on the role of presence in virtual environments; citation_author=M Slater, S Wilbur; citation_volume=6; citation_issue=6; citation_publication_date=1997; citation_pages=603-606; citation_id=CR30"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Depth of Presence in Virtual Environments; citation_author=M Slater, M Usoh, A Steed; citation_volume=3; citation_issue=2; citation_publication_date=1994; citation_pages=130-144; citation_id=CR31"/>

    <meta name="citation_reference" content="Slater M et al (1996) Immersion, presence and performance in virtual environments: An experiment with tri-dimensional chess. In VRST &#8216;96: Proceedings of the ACM symposium on virtual reality software and technology, pp 163&#8211;172"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Human factors issues in virtual reality: a review of the literature; citation_author=KM Stanney, RR Mourant, RS Kennedy; citation_volume=7; citation_issue=4; citation_publication_date=1998; citation_pages=327-351; citation_doi=10.1162/105474698565767; citation_id=CR33"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Systematic usability evaluation and design issues for collaborative virtual environments; citation_author=J Tromp, A Steed, J Wilson; citation_volume=10; citation_issue=3; citation_publication_date=2003; citation_pages=241-267; citation_doi=10.1162/105474603765879512; citation_id=CR34"/>

    <meta name="citation_reference" content="Vass M, Carroll JM, Shaffer CA (2002) Supporting creativity in problem solving environments. In: Proceedings of the fourth creativity &amp; cognition conference. AMC Press, Leicestershire, pp 31&#8211;37"/>

    <meta name="citation_reference" content="citation_title=Time effects in computer-mediated groups: past, present, and future; citation_inbook_title=Distributed work; citation_publication_date=2002; citation_pages=235-257; citation_id=CR36; citation_author=JB Walther; citation_publisher=MIT Press"/>

    <meta name="citation_reference" content="Wilson JR (2003) If VR has changed, then have its human factors? In: Waard Dd et al (eds) Human factors in the age of virtual reality, Shaker Publishing, Maastrich, pp 9&#8211;30"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Measuring presence in virtual environments: a presence questionnaire; citation_author=BG Witmer, MJ Singer; citation_volume=7; citation_issue=3; citation_publication_date=1998; citation_pages=225-240; citation_doi=10.1162/105474698565686; citation_id=CR38"/>

    <meta name="citation_author" content="David Roberts"/>

    <meta name="citation_author_email" content="david_roberts_cve@yahoo.co.uk"/>

    <meta name="citation_author_institution" content="The University of Salford, Salford, UK"/>

    <meta name="citation_author" content="Ilona Heldal"/>

    <meta name="citation_author_institution" content="Chalmers University, Gothenburg, Sweden"/>

    <meta name="citation_author" content="Oliver Otto"/>

    <meta name="citation_author_institution" content="The University of Salford, Salford, UK"/>

    <meta name="citation_author" content="Robin Wolff"/>

    <meta name="citation_author_institution" content="The University of Salford, Salford, UK"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-006-0050-6&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2006/10/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-006-0050-6"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Factors influencing flow of object focussed collaboration in collaborative virtual environments"/>
        <meta property="og:description" content="Creativity is believed to be helped by an uncluttered state of mind known as flow and as the trend grows towards less immersive displays to produce an uncluttered workplace, we ask the question “Does immersion matter to the flow of distributed group work?”. The aim of this work is to study the impact of level of immersion on workflow and presence during object focussed distributed group work, and to discuss the relevance of these and other factors to supporting flow and creativity. This is approached through a comprehensive literature survey and significant new results. The study attempts to introduce a breadth of factors and relationships as opposed to proving a hypothesis and thus takes a wide qualitative rather than deep quantitative approach to testing and analysis."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Factors influencing flow of object focussed collaboration in collaborative virtual environments | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-006-0050-6","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Task Performance, Video Conferencing, Object Manipulation, Subjective Impression, Head Mount Display","kwrd":["Task_Performance","Video_Conferencing","Object_Manipulation","Subjective_Impression","Head_Mount_Display"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-006-0050-6","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-006-0050-6","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=50;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-006-0050-6">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Factors influencing flow of object focussed collaboration in collaborative virtual environments
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-006-0050-6.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-006-0050-6.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2006-09-21" itemprop="datePublished">21 September 2006</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Factors influencing flow of object focussed collaboration in collaborative virtual environments</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-David-Roberts" data-author-popup="auth-David-Roberts" data-corresp-id="c1">David Roberts<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="The University of Salford" /><meta itemprop="address" content="grid.8752.8, 0000000404605971, The University of Salford, Salford, UK" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Ilona-Heldal" data-author-popup="auth-Ilona-Heldal">Ilona Heldal</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Chalmers University" /><meta itemprop="address" content="grid.5371.0, 0000000107756028, Chalmers University, Gothenburg, Sweden" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Oliver-Otto" data-author-popup="auth-Oliver-Otto">Oliver Otto</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="The University of Salford" /><meta itemprop="address" content="grid.8752.8, 0000000404605971, The University of Salford, Salford, UK" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Robin-Wolff" data-author-popup="auth-Robin-Wolff">Robin Wolff</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="The University of Salford" /><meta itemprop="address" content="grid.8752.8, 0000000404605971, The University of Salford, Salford, UK" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 10</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">119</span>–<span itemprop="pageEnd">133</span>(<span data-test="article-publication-year">2006</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">210 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">11 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-006-0050-6/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Creativity is believed to be helped by an uncluttered state of mind known as flow and as the trend grows towards less immersive displays to produce an uncluttered workplace, we ask the question “Does immersion matter to the flow of distributed group work?”. The aim of this work is to study the impact of level of immersion on workflow and presence during object focussed distributed group work, and to discuss the relevance of these and other factors to supporting flow and creativity. This is approached through a comprehensive literature survey and significant new results. The study attempts to introduce a breadth of factors and relationships as opposed to proving a hypothesis and thus takes a wide qualitative rather than deep quantitative approach to testing and analysis.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Creativity is helped by a clear state of mind but does technology designed to integrate into an uncluttered workplace best support distributed collaboration uncluttered by technical hindrances? A desire to create an uncluttered workspace is driving a trend towards less immersive flat screen displays. However, a wealth of research points to immersion not only being a perquisite for presence and thus co-presence, but also significantly improving workflow when compared to desktop interfaces. This begs the question: does immersion matter to the flow of distributed group work? Creativity typically has focus and we discuss the factors that impact on the seamlessness of object focussed collaboration in computer supported distributed group work. This section introduces technical and social factors of group-coherence in distributed work, explains why collaborative virtual environments (CVE) are well suited to supporting object focused interaction, describes the relationship between creativity, flow and presence, and the impact of level of immersion on workflow and co-presence. New results bridge the gap left by previous studies that either compared various high immersion displays, such as head mounted displays (HMD) and CAVEs or polar extremes of CAVEs and desktops, by comparing step-into, reach-into and look-into levels of immersion. Furthermore we attempt to build a rounder picture, complementing the extensive literature survey with what we believe within this area to be an unprecedented breadth of complementary measures within one experiment. Measures include conversational analysis, observations, task performance, and subjective impression on different characteristics of creativity defined by Csikszentmihalyi (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Csikszentmihalyi M (1996) Creativity: flow and the psychology of discovery and invention. Harper Perennial, New York" href="/article/10.1007/s10055-006-0050-6#ref-CR5" id="ref-link-section-d64722e326">1996</a>). By applying the method introduced by Tromp (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Tromp J, Steed A, Wilson J (2003) Systematic usability evaluation and design issues for collaborative virtual environments. Presence Teleoperators Virtual Environ 10(3):241–267" href="/article/10.1007/s10055-006-0050-6#ref-CR34" id="ref-link-section-d64722e329">2003</a>) and Heldal et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Heldal I et al (2005) Successes and failures in copresent situations. Presence Teleoperators Virtual Environ 14(5):563–579" href="/article/10.1007/s10055-006-0050-6#ref-CR14" id="ref-link-section-d64722e332">2005</a>) on observing patterns in activities that support or disturb the flow of seamless interaction, we can present what is happening between the participants during collaboration.</p><h3 class="c-article__sub-heading" id="Sec2">Group coherence in distributed work</h3><p>The benefits of distributed teamwork have been well championed, and measures for its quality introduced (Short et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1976" title="Short J, Williams E, Christie B (1976) The social psychology of telecommunications. Wiley, New York" href="/article/10.1007/s10055-006-0050-6#ref-CR28" id="ref-link-section-d64722e342">1976</a>), such as “social presence”, the users’ subjective sense of being present in a social setting with another person. However, access to technology is necessary but not sufficient for fruitful distributed collaboration. The underlying content and a network of social and technical relationships, have a great impact on the quality of work and experiences (Norman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Norman D (1998) The invisible computer. Why good products can fail, the personal computer is so complex, and information appliances ate the solution. The MIT Press, London. 0262140659" href="/article/10.1007/s10055-006-0050-6#ref-CR19" id="ref-link-section-d64722e345">1998</a>; Scott <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Scott CR (1999) Communication technology and group communication. In: Frey LR (ed) The handbook of group communication theory and research. Sage, Thousand Oaks, pp 431–472" href="/article/10.1007/s10055-006-0050-6#ref-CR26" id="ref-link-section-d64722e348">1999</a>). An attention shift from technology to human needs has been called for (Shneiderman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Shneiderman B (2002) Leonardo’s laptop: human needs and the new computing technologies: MIT Press, Cambridge. 0262194767" href="/article/10.1007/s10055-006-0050-6#ref-CR27" id="ref-link-section-d64722e351">2002</a>). Many social factors play a role, for example, how well people know each other. Common ground, team spirit and a sense of belonging are needed in order to build trust and consensus (Culnan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Culnan MJ (1987) Information technologies. In: Jablin F et al (ed) Handbook of organizational communication. Sage Publication, Beverly Hills, pp 420–442" href="/article/10.1007/s10055-006-0050-6#ref-CR6" id="ref-link-section-d64722e354">1987</a>; Monk <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Monk A (2003) Common ground in electronically mediated communication: clarks theory of language use. In: Carroll J (ed) HCI models, theories and frameworks. Morgan Kaufmann, San Francisco, pp 263–290" href="/article/10.1007/s10055-006-0050-6#ref-CR16" id="ref-link-section-d64722e358">2003</a>)—and these qualities are hard to support through communication media. Group coherence relies on underlying social activities that establish common ground for mutual understanding and building of trust, and is influenced by the participants social (Scott <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Scott CR (1999) Communication technology and group communication. In: Frey LR (ed) The handbook of group communication theory and research. Sage, Thousand Oaks, pp 431–472" href="/article/10.1007/s10055-006-0050-6#ref-CR26" id="ref-link-section-d64722e361">1999</a>) and cultural context (Riva <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Riva G (1999) Virtual reality as communication tool: a socio-cognitive analysis. Presence Teleoperators Virtual Environ 8(4):462–468" href="/article/10.1007/s10055-006-0050-6#ref-CR21" id="ref-link-section-d64722e364">1999</a>), and the context of the environment (Goffman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1986" title="Goffman E (1986) Frame analysis: an essay on the organization of experience. Northeastern University Press, Boston, xviii, [4], 586 s" href="/article/10.1007/s10055-006-0050-6#ref-CR10" id="ref-link-section-d64722e367">1986</a>; Nilsson et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Nilsson A et al (2002) The long-term uses of shared virtual environments: an exploratory study. In: Schroeder R (ed) The social life of avatars. Springer, London" href="/article/10.1007/s10055-006-0050-6#ref-CR18" id="ref-link-section-d64722e370">2002</a>). Social prerequisites are often interweaved with technical ones (Norman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Norman D (1998) The invisible computer. Why good products can fail, the personal computer is so complex, and information appliances ate the solution. The MIT Press, London. 0262140659" href="/article/10.1007/s10055-006-0050-6#ref-CR19" id="ref-link-section-d64722e373">1998</a>; Shneiderman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Shneiderman B (2002) Leonardo’s laptop: human needs and the new computing technologies: MIT Press, Cambridge. 0262194767" href="/article/10.1007/s10055-006-0050-6#ref-CR27" id="ref-link-section-d64722e377">2002</a>) and social communication can be useful in creatively overcoming deficiencies in the technology (Fjeld et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Fjeld M et al (2002) Physical and virtual tools: activity theory applied to the design of groupware. Computer supported cooperative work 11, pp 153–180" href="/article/10.1007/s10055-006-0050-6#ref-CR8" id="ref-link-section-d64722e380">2002</a>). Traditional technologies ranging phones, email, CSCW and video conferencing can each support specific levels of social activity, but are not generally sufficient to build more complex social relationships, such as trust. There is still a general need for people to physically meet (Nardi and Whittaker <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Nardi B, Whittaker S (2002) The role of face-to-face communication in distributed work. MIT Press, Cambridge, pp 83–112" href="/article/10.1007/s10055-006-0050-6#ref-CR17" id="ref-link-section-d64722e383">2002</a>). Ad hoc groups must sometimes handle decisions in organisations through a medium with little time to become accustom to it or to working together, having negative consequences on group coherence. The impact of the media on group behaviour diminishes as people become accustomed to adapting to its characteristics (Walther <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Walther JB (2002) Time effects in computer-mediated groups: past, present, and future. In: Hinds P, Kiesler S (eds) Distributed work. MIT Press, Cambridge, pp 235–257" href="/article/10.1007/s10055-006-0050-6#ref-CR36" id="ref-link-section-d64722e386">2002</a>). For example, computer screens are often covered with finger marks, even though the mouse pointer is more accurate (Poston and Serra <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Poston T, Serra L (1996) Dextrous virtual work. Communications of the ACM, pp 37–45" href="/article/10.1007/s10055-006-0050-6#ref-CR20" id="ref-link-section-d64722e389">1996</a>, p39). Finally, it must be remembered that distributed technologies may cross not only distance but also cultural boundaries, context and location dependent values.</p><h3 class="c-article__sub-heading" id="Sec3">Object focussed interaction in collaborative virtual environments</h3><p>We argue that CVEs are presently unique in supporting the faithful communication of attention, and focus of action and to some extent emotion, with respect to shared objects, across a distributed team. Video conferencing can show the appearance of people, but it is often hard to see what they are looking at. This is because participants look through 2D video windows into each other’s rooms. In contrast, CVEs traditionally represent people as 3D cartoon-like characters, called avatars, that can freely move around and interact with objects and each other in a shared virtual space. Avatars can thus support some level of social interaction by representing focus of attention, basic activity and emotions (Heldal et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Heldal I et al (2005) Successes and failures in copresent situations. Presence Teleoperators Virtual Environ 14(5):563–579" href="/article/10.1007/s10055-006-0050-6#ref-CR14" id="ref-link-section-d64722e400">2005</a>). The impact of avatar representation and gestures on collaboration (Benford et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Benford SD et al (1995) User embodiment in collaborative virtual environments. In: CHI’95. ACM Press, Denver" href="/article/10.1007/s10055-006-0050-6#ref-CR1" id="ref-link-section-d64722e403">1995</a>; Bente and Kraemer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Bente G, Kraemer NC (2002) Virtual gestures: analyzing social presence effects of computer-mediated and computer-generated nonverbal behaviour. In: Fifth annual international workshop PRESENCE 2002. Porto, pp 233–244" href="/article/10.1007/s10055-006-0050-6#ref-CR2" id="ref-link-section-d64722e406">2002</a>) and their use in object focussed collaboration (Hindmarsh et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Hindmarsh J et al (2000) Object-focused interaction in collaborative virtual environments. ACM Trans Comput Human Interact(ToCHI) 7(4):477–509" href="/article/10.1007/s10055-006-0050-6#ref-CR15" id="ref-link-section-d64722e409">2000</a>) have been studied. Some immersive interfaces, such as a CAVE or HMD, allow people to see from the perspective of their avatar’s eyes and for the movement of the avatar to follow that of the owner. Thus, remote participants appear to share the same space as the local user, and can thus better represent attention through orientation, gaze and gesture. We propose that through greater reliability in communicating the focus of attention, activity and emotion, immersive CVEs are likely to lead to a smoother object focussed workflow. Specifically we are interested in examining the impact of level of immersion and will do this later by examining the impact of varying the interface to a CVE on smoothness of workflow and feeling of co-presence.</p><p>Video conferencing does have some advantages over CVEs. For example, avatars do not represent the live appearance of a person and are in many ways less life-like than a video representation. 3D reconstruction offers the potential to capture the best of both worlds by allowing people to be captured and remotely represented in 3D video, but as yet does not support the freedom of movement and viewpoint offered by immersive CVEs.</p><p>We now look at the factors that impact on experience and work within CVEs. Key factors such as presence, immersion, involvement, navigation and performance, which are important for the increased overall experience in single-user virtual environments, have relevance to CVEs (Witmer and Singer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Witmer BG, Singer MJ (1998) Measuring presence in virtual environments: a presence questionnaire. Presence Teleoperators Virtual Environ 7(3):225–240" href="/article/10.1007/s10055-006-0050-6#ref-CR38" id="ref-link-section-d64722e417">1998</a>; Slater and Wilbur <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Slater M, Wilbur S (1997) A framework for immersive virtual environments (FIVE): Speculations on the role of presence in virtual environments. Presence: Teleoperators Virtual Environ 6(6):603–606" href="/article/10.1007/s10055-006-0050-6#ref-CR30" id="ref-link-section-d64722e420">1997</a>; Stanney et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Stanney KM, Mourant RR, Kennedy RS (1998) Human factors issues in virtual reality: a review of the literature. Presence Teleoperators Virtual Environ 7(4):327–351" href="/article/10.1007/s10055-006-0050-6#ref-CR33" id="ref-link-section-d64722e423">1998</a>; Held and Durlach (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Held RM, Durlach NI (1992) Telepresence. Presence Teleoperators Virtual Environ 1(1):109–112" href="/article/10.1007/s10055-006-0050-6#ref-CR12" id="ref-link-section-d64722e426">1992</a>). Intuitiveness of the technology is an important requirement (Blade and Padgett <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Blade RA, Padgett ML (2002) Virtual environments standards and terminology. In: Stanney KM (ed) Handbook of virtual environments. Design, implementation, and applications. Lawrence Erlbaum Associates, London, pp 15–27" href="/article/10.1007/s10055-006-0050-6#ref-CR3" id="ref-link-section-d64722e429">2002</a>). It is commonly recognised that beside performance, presence has a special importance in these environments (Slater et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Slater M et al (1996) Immersion, presence and performance in virtual environments: An experiment with tri-dimensional chess. In VRST ‘96: Proceedings of the ACM symposium on virtual reality software and technology, pp 163–172" href="/article/10.1007/s10055-006-0050-6#ref-CR32" id="ref-link-section-d64722e433">1996</a>). Presence refers to the extent to which the user experiences being in a place other than the one where they are physically present (Held and Durlach <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Held R, Durlach N (1991) Telepresence, time delay and adaptation. In: Ellis SR, Kaiser MK, Grunwald AC (eds) Pictorial communication in virtual and real environments. Taylor &amp; Francis, London pp 231–246" href="/article/10.1007/s10055-006-0050-6#ref-CR11" id="ref-link-section-d64722e436">1991</a>). Hence, hiding the technology, so that people can interact naturally with the simulation, significantly increases engagement, motivation, enjoyment, and creativity. The relationships between presence, overall experience and user performance are uncertain (Wilson <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Wilson JR (2003) If VR has changed, then have its human factors? In: Waard Dd et al (eds) Human factors in the age of virtual reality, Shaker Publishing, Maastrich, pp 9–30" href="/article/10.1007/s10055-006-0050-6#ref-CR37" id="ref-link-section-d64722e439">2003</a>). Correlations between them (Witmer and Singer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Witmer BG, Singer MJ (1998) Measuring presence in virtual environments: a presence questionnaire. Presence Teleoperators Virtual Environ 7(3):225–240" href="/article/10.1007/s10055-006-0050-6#ref-CR38" id="ref-link-section-d64722e442">1998</a>) and the dependency on what is measured (Sadowski and Stanney <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Sadowski W, Stanney K (2002) Presence in virtual environments. In: Stanney KM (ed) Handbook of virtual environments. Design, implementation, and applications. Lawrence Erlbaum Associates, London, pp 791–806" href="/article/10.1007/s10055-006-0050-6#ref-CR24" id="ref-link-section-d64722e445">2002</a>; Slater and Steed <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Slater M, Steed A (2000) A virtual presence counter. Presence Teleoperators Virtual Environ 9(5):413–434" href="/article/10.1007/s10055-006-0050-6#ref-CR29" id="ref-link-section-d64722e448">2000</a>) have been reported. Correlations between presence and the collaborative sense of presence, co-presence (Slater et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Slater M, Usoh M, Steed A (1994) Depth of Presence in Virtual Environments. Presence Teleoperators Virtual Environ 3(2):130–144" href="/article/10.1007/s10055-006-0050-6#ref-CR31" id="ref-link-section-d64722e452">1994</a>) are context dependent (Heldal <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Heldal I (2004) Usability development for collaborative virtual environments. In: VIRART workshop: designing and evaluating virtual reality systems. Nottingham" href="/article/10.1007/s10055-006-0050-6#ref-CR13" id="ref-link-section-d64722e455">2004</a>) and those within the context of creative problem solving remain largely unstudied.</p><h3 class="c-article__sub-heading" id="Sec4">Creativity, flow and presence</h3><p>We now consider lessons learnt from studying creativity and how they relate to CVEs and the feelings of presence and co-presence. Creativity has been strongly linked to a state of mind known as flow. Eight dimensions of flow have been defined (Csikszentmihalyi <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Csikszentmihalyi M (1996) Creativity: flow and the psychology of discovery and invention. Harper Perennial, New York" href="/article/10.1007/s10055-006-0050-6#ref-CR5" id="ref-link-section-d64722e466">1996</a>): (1) clear objectives with immediate feedback, (2) skills suited to challenges, (3) action and awareness merge, (4) allowing high concentration, (5) sense of control, (6) loss of self-consciousness, (7) altered sense of time, which usually seems to pass faster, and (8) autotelic experience. Social interaction, in terms of the building of trust, can be related to the sixth dimension “No worry of failure” for problem solving (Vass et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Vass M, Carroll JM, Shaffer CA (2002) Supporting creativity in problem solving environments. In: Proceedings of the fourth creativity &amp; cognition conference. AMC Press, Leicestershire, pp 31–37" href="/article/10.1007/s10055-006-0050-6#ref-CR35" id="ref-link-section-d64722e469">2002</a>). The seventh dimension has been used in questionnaires for measuring presence (Witmer and Singer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Witmer BG, Singer MJ (1998) Measuring presence in virtual environments: a presence questionnaire. Presence Teleoperators Virtual Environ 7(3):225–240" href="/article/10.1007/s10055-006-0050-6#ref-CR38" id="ref-link-section-d64722e472">1998</a>). We argue that flow of collaboration is likely to be helped by seamless and natural multi resource conversations, and that technology factors may impact on the support for this in distributed team work.</p><p>Factors that determine presence include (Garau et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Garau M et al (2001) The impact of eye gaze on communication using humanoid avatars. In CHI ‘01: Proceedings of the SIGCHI conference on human factors in computing systems. ACM Press, New York, pp 309–316" href="/article/10.1007/s10055-006-0050-6#ref-CR9" id="ref-link-section-d64722e478">2001</a>): (1) the extent of fidelity and sensory information, (2) the match between sensors and displays, (3) content, and (4) user characteristics. Many of these can be directly related to determinants for flow. Another flow that contributes to increased experiences in CVEs is continuous workflow. This can be maintained by avoiding or decreasing disturbances from the surroundings, that cause breaks in presence (Brogni et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Brogni A, Slater M, Steed A (2003) More breaks less presence. In: Presence 2003, The 6th annual international workshop on presence. Aalborg, Denmark" href="/article/10.1007/s10055-006-0050-6#ref-CR4" id="ref-link-section-d64722e481">2003</a>).</p><p>Flow can be impacted by the way in which people handle unexpected events. Presence requires the building of a conceptual map, that is grounded in the experience of sureties, and even of plausible surprises, but is weakened by shocks (Fencott <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Fencott C (1999) Content and creativity in virtual environment design. In: Proceedings of virtual systems and multimedia ‘99. University of Abertay" href="/article/10.1007/s10055-006-0050-6#ref-CR7" id="ref-link-section-d64722e487">1999</a>): creativity must be combined with knowledge of social and technical context in the design of content for VEs to provide challenge in handling sureties, interest in handling surprises and support in handling shocks. We postulate, however, that flow requires the transition between handling these disruptions to be seamless.</p><h3 class="c-article__sub-heading" id="Sec5">Impact of the level of immersion on flow of conversation</h3><p>Flow in general is beneficial to creativity and we argue that CVEs used for creative problem solving should support an uninterrupted flow of collaboration, seamless in the sense that the flow of conversation and work are not hampered by the technology. We earlier explained how characteristics of immersive CVEs lend this technology to supporting uninterrupted workflow during object focussed collaboration. We now consider the effect of the interface to the 3D environment, that is, the difference between looking into, looking and reaching into, and actually being within a shared 3D space. Several recent studies have used immersive projection technology (IPT) to interface to CVEs and have found them to be very effective (Heldal et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Heldal I et al (2005) Successes and failures in copresent situations. Presence Teleoperators Virtual Environ 14(5):563–579" href="/article/10.1007/s10055-006-0050-6#ref-CR14" id="ref-link-section-d64722e499">2005</a>; Schroeder et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Schroeder R et al (2001) Collaborating in networked immersive spaces: as good as being there together? Comput Graphics 25(5):781–788" href="/article/10.1007/s10055-006-0050-6#ref-CR25" id="ref-link-section-d64722e502">2001</a>; Roberts et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Roberts D et al (2004) Supporting social human communication between distributed walk-in displays. In: VRST ‘04: ACM symposium on virtual reality software and technology, pp 81–88" href="/article/10.1007/s10055-006-0050-6#ref-CR22" id="ref-link-section-d64722e505">2004</a>). When compared to desktop displays, linked IPTs have been shown to improve capabilities, impact on role, increase feelings of contribution and collaboration and increase task performance (Heldal et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Heldal I et al (2005) Successes and failures in copresent situations. Presence Teleoperators Virtual Environ 14(5):563–579" href="/article/10.1007/s10055-006-0050-6#ref-CR14" id="ref-link-section-d64722e508">2005</a>; Roberts et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Roberts D et al (2004) Supporting social human communication between distributed walk-in displays. In: VRST ‘04: ACM symposium on virtual reality software and technology, pp 81–88" href="/article/10.1007/s10055-006-0050-6#ref-CR22" id="ref-link-section-d64722e511">2004</a>). We suspect that these improvements come from a set of factors, including field of view, visibility of self within the simulation, motion tracking and its remote representation through avatars within a shared space. That together, encourage people to consciously and subconsciously use their body in a natural way to observe and interact with the environment and avatars within it.</p><p>A well known study by Hindmarsh et al. (Hindmarsh et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Hindmarsh J et al (2000) Object-focused interaction in collaborative virtual environments. ACM Trans Comput Human Interact(ToCHI) 7(4):477–509" href="/article/10.1007/s10055-006-0050-6#ref-CR15" id="ref-link-section-d64722e517">2000</a>) demonstrated that the combination of a limited field of view and unnatural control of viewpoint, typical of desktop CVEs, made it hard for participants to see what each other are looking or pointing at, and that this led to collaborators spending significant time repairing broken conversations. Recent studies with linked IPTs have reported not noticing this phenomena (Heldal et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Heldal I et al (2005) Successes and failures in copresent situations. Presence Teleoperators Virtual Environ 14(5):563–579" href="/article/10.1007/s10055-006-0050-6#ref-CR14" id="ref-link-section-d64722e520">2005</a>; Roberts et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Roberts D et al (2004) Supporting social human communication between distributed walk-in displays. In: VRST ‘04: ACM symposium on virtual reality software and technology, pp 81–88" href="/article/10.1007/s10055-006-0050-6#ref-CR22" id="ref-link-section-d64722e523">2004</a>), although the experiments were not designed to isolate it. We previously reconstructed Hindmarsh’s experiment, this time comparing paired desktops to paired IPTs. We found that task performance was always better in the immersive setting and that the scale of improvement was proportional to the area surrounded by the pair of users and the shared object (Roberts et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Roberts D et al (2005) Reducing fragmentation in telecollaboration by using IPT interfaces. In: IPT-EGVE workshop: Eurographics Association, Switzerland, pp 211–216" href="/article/10.1007/s10055-006-0050-6#ref-CR23" id="ref-link-section-d64722e526">2005</a>). We observed, but did not measure, a correlation between this improvement in task performance and improvements in the flow of verbal and non-verbal communication. The experiment described in this article aims to rectify this by measuring the impact of level of immersion on workflow and presence. However, we have devised a more challenging task that requires closer object focused collaboration.</p></div></div></section><section aria-labelledby="Sec6"><div class="c-article-section" id="Sec6-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec6">Experimentation</h2><div class="c-article-section__content" id="Sec6-content"><p>We now describe experiments designed to obtain structured evidence for a better understanding of the impact of level of immersion has on workflow and presence within a team engaged in object focussed collaboration. In particular we wish to investigate interruptions both to object manipulation and to object focussed conversations, and how these correlate to task performance, and perceived co-presence and creativity. Specifically we attempt to bridge the gap left by previous studies by comparing intermediate rather than similar or opposing levels of immersion. A wide qualitative, as opposed to a deep quantitative, approach has been adopted, in search of a basic understanding rather than isolation of factors to prove a hypothesis. We believe the breadth of complementary analysis to be unprecedented in a single study of this kind and hope that the results will lead others to undertake more focussed quantitative studies that answer some of the questions introduced by this study.</p><p>We begin with a preliminary test between two step-into displays that uses conversational analysis alone to gauge seamlessness of conversation. A more comprehensive study is then undertaken using a variety of measures across asymmetric pairs of displays. A Simple, yet intrinsically challenging, task was devised, which reuses a simple construction environment used in related studies (Roberts et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Roberts D et al (2004) Supporting social human communication between distributed walk-in displays. In: VRST ‘04: ACM symposium on virtual reality software and technology, pp 81–88" href="/article/10.1007/s10055-006-0050-6#ref-CR22" id="ref-link-section-d64722e540">2004</a>). The tasks require a pair of participants to work together to build a simple structure, needing to agree on methodology and roles and to overcome difficulties along the way. Three variations of task are used for the asymmetrically paired displays, so that the same pair of subjects can try a new, yet similar, task experiencing each display technology. In order to motivate and challenge the subjects, each trial was limited to ten minutes, in which the participants had to complete the task as far as possible.</p><h3 class="c-article__sub-heading" id="Sec7">The task</h3><p>The subjects were given three simple construction tasks that build (a) a horizontal square; (b) a vertical triangle; and (c) a vertical H, as shown in the screenshots in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0050-6#Fig1">1</a>. The materials are wooden beams, metal joiners and screws. Screws fix beams and joiners together. Tools are used to drill holes and tighten screws. To complete the task, tools and materials had to be shared in various scenarios of shared object manipulation, distinct in the method of sharing attributes. Scenarios include planning, passing of objects, carrying objects and assembly.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>The three tasks. <b>a</b> Horizontal square. <b>b</b> Vertical triangle. <b>c</b> Vertical H</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>The simulation of gravity prohibited leaving materials in thin air and made the beams too heavy to lift alone. The <i>only</i> task a single person could undertake was to fetch a tool, screws or joiner. <i>Moving</i> and <i>positioning</i> beams or structures, and <i>building</i> all required teamwork. For example, one participant had to hold a joiner in place, so that another participant could fix it with a screw.</p><h3 class="c-article__sub-heading" id="Sec8">Measures</h3><p>Measures include <i>task completion</i>, <i>conversational analysis, disturbances</i>, and <i>subjective impression</i> of the subjects. The initial test, with the symmetric high immersion display pair, only used conversational analysis, whereas the latter more comprehensive asymmetric display pair tests used all of the following methods.</p><p>
                  <i>Task Completion</i> measured the percentage of necessary sub-tasks, such as carrying beam or fixing two beams, completed with the time limit.</p><p>
                  <i>Conversational analysis</i> describes in detail both verbal and non-verbal communication between the participants. Logs were built up from video evidence and observations taken during the trials. As each pair was distributed, videos of each needed to be synchronised and watched side by side, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0050-6#Fig2">2</a>. At least two analysts watched the videos, often several times, and compared notes to build up the detailed logs. Videos were watched again when it was necessary to iron out discrepancies.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>View of <b>a</b> local and remote participants in respective step-into displays; <b>b</b> synchronised videos used in conversational analysis</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>
                  <i>Disturbances</i> The cause and duration of disturbances in workflow arising from the technology was recorded during conversational analysis.</p><p>
                  <i>Subjective impressions</i> A questionnaire measured the participants’ impressions of smoothness and naturalness of object manipulation, object focussed conversation, co-presence and creativity. The subjects were asked to rate their agreement between 1 and 7 for 30 statements that tested the primary questions from various angles. The questionnaire is too long to reproduce in full, but questions that revealed important results are documented in the next section.</p><h3 class="c-article__sub-heading" id="Sec10">Level of immersion</h3><p>Previous related experiments have compared high levels of immersion, such as in CAVEs and HMDs as oposed to lower levels as with desktops. This trial attempts to fill the gap by comparing the distinct levels of visual immersion: look-into, reach-into and step-into, Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0050-6#Fig3">3</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0050-6#Fig4">4</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0050-6#Fig5">5</a>. For these we respectively used a single screen display (Trace, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0050-6#Fig6">6</a>), a two screened L-shaped workbench (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0050-6#Fig7">7</a>), and two CAVE-like displays (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0050-6#Fig8">8</a>). All of the displays were back projected. All incorporated motion tracking, but each of a distinct technology: IR camera-based (Vicon), ultrasonic/gyroscopic (Intersense IS900), and magnetic (Ascension Flock of Birds), respectively.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Trace: resolution of 1024 × 768; FOV 100°; optical tracking of head and joystick (hand)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Workbench: resolution of 1024 × 768; FOV 120°; ultrasonic tracking of head and joystick (hand)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>CAVE; resolution of 1024 × 768; FOV 160°–270°; magnetic tracking of head and hand (separate joystick)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig6_HTML.jpg?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig6_HTML.jpg" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Trace display</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig7_HTML.jpg?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig7_HTML.jpg" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Workbench display</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig8_HTML.jpg?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig8_HTML.jpg" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>CAVE-like display</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>The test conditions are shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-006-0050-6#Tab1">1</a>.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Display combination during the user trials</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-006-0050-6/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Each display supported audio communication. After each rotation to assess each display, the subjects were asked to answer the questionnaire. All three displays are located in one building in the University of Salford, England, with the second walk-in display located in Chalmers, Sweden.</p><h3 class="c-article__sub-heading" id="Sec11">Subjects</h3><p>Test subjects were students aged in their twenties and of various nationalities, voluntary and familiar with immersive CVEs. The symmetric display pair trials used three pairs of subjects whereas the subsequent asymmetric display pair trials used four.</p><h3 class="c-article__sub-heading" id="Sec12">Platform</h3><p>The CVE software platform used in this experiment was our own creation ICE, Immersive Collaborative Virtual Environment. ICE has become our default test bed CVE, partly because of its general high performance in comparison to the well known alternatives, but also because it has a highly configurable event handler designed specifically to cope with the complex event traffic created during immersive object focussed activities.</p></div></div></section><section aria-labelledby="Sec13"><div class="c-article-section" id="Sec13-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec13">Results</h2><div class="c-article-section__content" id="Sec13-content"><p>We now present results along with analysis. Note that the results have been ordered to maximise clarity rather than in the order they were gained.</p><h3 class="c-article__sub-heading" id="Sec14">Task performance</h3><p>The following diagram in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0050-6#Fig9">9</a> documents the results of 12 asymmetric display sessions.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig9_HTML.gif?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig9_HTML.gif" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Percentage of task completed after each 10-min session</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>One can see that success of the task seems to improve with level of immersion. This is in face of the concern that although each trail introduced a new task, the skill level of the subjects might reasonably be expected to increase each trial. When using the W&lt;-&gt;C display combination, the subjects managed to complete the task to more than 80% within the allowed 10 min.</p><h3 class="c-article__sub-heading" id="Sec15">Conversational analysis</h3><p>An analysis of the conversations between the subjects during the initial symmetric CAVE configuration sessions has shown that the flow of conversation is smooth most of the time, alternating naturally between the pair, while they coordinate their actions. Breaks in workflow, but not conversation, were usually caused by fumbling with the manipulation of objects, which appeared to be due to the lack of feeling of touch. It was observed that a combination of verbal and non-verbal communication was used to help each other out when problems occurred. In order to demonstrate the smoothness of conversation we now reproduce the log of an entire typical session. It is noticeable that nuances of verbal and non-verbal communication are used with great effect to discuss and demonstrate desired positioning.</p><ul class="u-list-style-none">
                    <li>
                      <p>C1: (walks in one direction to fetch a joiner) WHILE C2: (walks in the other to fetch the drill)</p>
                    </li>
                    <li>
                      <p>C1: (takes the joiner to the upright beam that he wants to fix it on and stands looking round him to find where C2 has gone) WHILE C2: (glances over to C1 and walks towards him)</p>
                    </li>
                    <li>
                      <p>C2: (overshoots C1), gazes back and adjusts his body to face him. As he adjusts he drops the drill). “I’ve dropped it, haven’t I?”</p>
                    </li>
                    <li>
                      <p>C2: (turns to look for drill) WHILE C1: (glances over and then returns his gaze to the joiner)</p>
                    </li>
                    <li>
                      <p>C2: (quickly picks up the drill and steps over to drill a hole)</p>
                    </li>
                    <li>
                      <p>C2: “OK er” (pause) “just going to get a screw” (walks away and comes back with a screw) WHILE C1: (just stands still holding the joiner in place)</p>
                    </li>
                    <li>
                      <p>C1: (returns and tries to insert screw) &lt;Expletive&gt; (bends to pick the dropped screw from the floor)</p>
                    </li>
                    <li>
                      <p>C1: “Try to put it somewhere on the end like” (pointing to the desired location)</p>
                    </li>
                    <li>
                      <p>C2: (places the screw in position pointed to by C1) “About here right?” (and leaving the screw in place lowers his arm while stepping back and looking at C1 for confirmation)</p>
                    </li>
                    <li>
                      <p>C1: “Yeh Okay doke”</p>
                    </li>
                    <li>
                      <p>C2 (fetches a screwdriver and fixes the screw in place)</p>
                    </li>
                    <li>
                      <p>C1: “cool” (steps back and inspects the job from various perspectives)</p>
                    </li>
                    <li>
                      <p>C2: “OK shall I get the next T-joiner then”</p>
                    </li>
                    <li>
                      <p>C1: “Yeh Okay doke”</p>
                    </li>
                    <li>
                      <p>C1: (gets the drill) WHILE C2 (gets the joiner)</p>
                    </li>
                    <li>
                      <p>C1: (holds the joiner up to the beam “is that about right?”)</p>
                    </li>
                    <li>
                      <p>C2 “What about this height here?” (holds up his hand out to indicate height)</p>
                    </li>
                    <li>
                      <p>C1: (drills holes and then moves off to get screw and screwdriver, returns and fixes the joint)</p>
                    </li>
                    <li>
                      <p>C1 (screws) “Okay doke, that’s it” (steps back) “Beautiful”</p>
                    </li>
                    <li>
                      <p>C2: (steps back to look)</p>
                    </li>
                    <li>
                      <p>C2: “Nice bit of alignment work there” &lt;laughs&gt; WHILE C1: (posture becomes considerably more animated) “They’re sort of the same height” &lt;laughs&gt;</p>
                    </li>
                  </ul><p>We now look at the conversations during the trials between asymmetric pairs of displays. As with the symmetric CAVE trials, places and objects were referenced through a combination of speech, pointing and moving to location.. For example in the Trace&lt;-&gt;Workbench configuration:</p><ul class="u-list-style-none">
                    <li>
                      <p>T: “We need to get those metal joiners to fix them, or something” (moves over to the material stack)</p>
                    </li>
                    <li>
                      <p>W: (follows and picks one up)</p>
                    </li>
                    <li>
                      <p>T: “So, what are we supposed to do with them?” (moves back and rotates to look at W)</p>
                    </li>
                    <li>
                      <p>W: (carries a joiner to a beam and tries to align it) “See that? Dill a hole and bolt it, what do you think?”</p>
                    </li>
                    <li>
                      <p>T: (moves to joiners, has problems picking one up; then moves over to see what W does) “Ah, I see. Yeah, looks okay”</p>
                    </li>
                    <li>
                      <p>W: “So, if I get a drill and you get the...” (moves over to the tools)</p>
                    </li>
                    <li>
                      <p>T: “...the bolt” (moves over to tools and completes the partner’s sentence)</p>
                    </li>
                  </ul><p>The flow of conversation was more fragmented than in the CAVE&lt;-&gt;CAVE trials. When using the Workbench or Trace the subjects often had to re-orientate themselves, as they lost sight of the remote partner. This regularly occurred when trying to locate a partner after concentrating on work with an object. As a CAVE-like display offers a wide FOV, those subjects simply looked from one side to the other, while on a Trace or Workbench with limited FOV, the subjects had to use the joystick to move back and forth and to rotate in an appropriate direction, which sometimes resulted in overshooting the target. For example (C&lt;-&gt;W):</p><ul class="u-list-style-none">
                    <li>
                      <p>C: “I’ll hold it up there and you can drill a hole” (picks up joiner)</p>
                    </li>
                    <li>
                      <p>W: “Yeah” (turns over to find drill; overshoots it) “Woo...”</p>
                    </li>
                    <li>
                      <p>C: (grabs joiner on left screen, walks over to other side of display and holds it next to a beam facing the right screen) “Okay...”</p>
                    </li>
                    <li>
                      <p>W: “I have a bit problems picking up the drill” (moves back, rotates and tries from other angle) “Have I got it right?”</p>
                    </li>
                    <li>
                      <p>C: (looks down to floor and watches how W picks it up) “There you go” (still holding a joiner in place)</p>
                    </li>
                    <li>
                      <p>W: “Ya, got it now” (turns around with joystick) “Where are you?” (looks at a pile of materials ) “I lost you... Were are you? Ah, here we go.” (sees C’s joiner in far left corner of display, tries to position drill, rotates hand) “Woo” (drills hole in joiner and moves over to get screw)</p>
                    </li>
                  </ul><p>Reinforcing findings of previous related work, we could observe that most of the time, the more immersed subjects took the lead during the tasks, moving quickly and precisely across the virtual scene, while the less-immersed subjects were following and often asking for confirmation for their actions. For example (T&lt;-&gt;W):</p><ul class="u-list-style-none">
                    <li>
                      <p>T: “Okay, screw is there” (drops it next to a joiner between T and W)</p>
                    </li>
                    <li>
                      <p>W: “It’s not in, is it?” (moves head to look around joiner)</p>
                    </li>
                    <li>
                      <p>T: (laughs) “Oh dear!” (picks it up and moves back and forth with joystick to reposition screw) “Is that in? Looks strange to me”</p>
                    </li>
                  </ul><p>And another example (C&lt;-&gt;W):</p><ul class="u-list-style-none">
                    <li>
                      <p>W: (tries to position his joiner)</p>
                    </li>
                    <li>
                      <p>C: do you want me to line it up for you? (goes ahead and manipulates it)</p>
                    </li>
                    <li>
                      <p>W: is it not...? (moves back and watches C) ah, ok.</p>
                    </li>
                  </ul>
                <h3 class="c-article__sub-heading" id="Sec16">Disturbances</h3><p>The conversational analysis showed that many interruptions arose from difficulties in manipulating objects and delay while people reoriented to be able to see an object, place or partner. The total time spent on these interruptions in each task was clearly proportional to the immersivness of the interface. Despite these disturbances, the conversation (both verbal and non-verbal) continued smoothly and was often used to help people out of these difficulties.</p><p>Subjects on the Trace and Workbench, but not CAVE, were seen to frequently lose sight of the remote partner and the objects. They had to use the joystick to re-orientate themselves to identify what their partner was pointing at. The following Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-006-0050-6#Tab2">2</a> shows the amount of extra time spent resulting from FOV issues. This includes time wasted by display invoked changes in behaviour while looking for objects, turning around to follow the partner, moving backwards for better overview of the scene, re-orienting themselves, problems aligning large objects, and subjects moving close to the display wall to look over the edge. The values do not include time wasted waiting for the partner on the other display, and can thus be considered optimistic. The results of this study have to be taken in the context of the application characteristics. For example, the beams were larger than the FOV of the two smaller displays and neither of these displays reached the floor, making picking objects from ground level unintuitive.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Extra time spent due to problems with FOV</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-006-0050-6/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>More interruptions were noticed in object manipulation than in object focussed collaboration, particularly by Trace users, to some extent by Workbench users, and in only one out of four of the CAVE condition, which correlates with the findings in conversational analysis and task performance. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-006-0050-6#Tab3">3</a> summarises approximate timing of observed interruptions during picking up, placing and aligning objects. The results demonstrate clearly the effect of level of immersion on the time ‘wasted’ due to limitations in the display type.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Extra time spent due to problems during object manipulation</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-006-0050-6/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <h3 class="c-article__sub-heading" id="Sec17">Subjective impressions</h3><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec18">Creativity and enjoyment</h4><p>The first set of questions in the questionnaire tries to understand how participants enjoyed their experience in the virtual environment, felt creative and how the interface may have hinder their creativity. The questions and their mean values (over all completed questionnaires, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0050-6#Fig10">10</a>) are as follows: </p><ul class="u-list-style-bullet">
                      <li>
                        <p>Q1: Think about some earlier time (that is, not today) when you enjoyed working with: (a) a creative problem; (b) someone on a creative problem. To what extent did you enjoy collaboration today?</p>
                      </li>
                      <li>
                        <p>Q2: To what extent did you feel that your own creativity was supported by the technical interface?</p>
                      </li>
                      <li>
                        <p>Q3: To what extent did you feel that the team creativity was supported by: (a) the technical interface?; (b) the conversation?; and (c) the non-verbal communication (gestures, pointing, information about the partner)?</p>
                      </li>
                      <li>
                        <p>Q11: Was the experience worthwhile in relation to: (a) solving the task?; (b) experiencing the CVE technology?; and (c) collaborating with your partner?</p>
                      </li>
                    </ul><p>The highest immersivity combination, Cave to Workbench, from the perspective of the CAVE user, is seen as superior in supporting creativity (Q2, Q3a), more enjoyable (Q1a and b) and slightly more worthwhile (Q11a and b). The Trace to CAVE combination, from the perspective of the Trace user, is seen as superior in supporting non-verbal communication (Q3c) and worth of collaborating with partner (Q11c). The role of the interface on the conversation supporting creativity has no clear winner (Q3b). The lowest immersivity combination of Trace and Workbench is seen from both perspectives as generally offering a lower level of support. In summary it appears that the CAVE is perceived as offering superior support for creativity and its enjoyment and CAVE users are perceived as easier to collaborate with. The latter is interestingly most noticeable when seen from perspective of the lowest immersion user. The lowest immersivity combination of Trace and Workbench, and interestingly the Workbench to CAVE configuration, are generally perceived as inferior.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig10_HTML.gif?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig10_HTML.gif" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Mean values of responses to support for creativity and enjoyment</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec19">Presence and task performance</h4><p>We were also concerned about user’s perception of presence, co-presence, and personal and team performance. The questions below looked at these difficult to measure parameters from various angles and the mean values are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0050-6#Fig11">11</a> before discussing and summarising them.</p><ul class="u-list-style-bullet">
                      <li>
                        <p>Q9: Were there moments when you forgot the surrounding: (a) physical as opposed to simulated environment?; (b) the interface technologies and used these intuitively?; (c) that your partner was not located in the same place?</p>
                      </li>
                      <li>
                        <p>Q13: Did you feel: (a) present in the simulated environment as in “a real place you visited”, in a way that you forgot the physical experimental environment around you?; (b) that together with your partner you experienced the environment as “a real place you visited”?</p>
                      </li>
                      <li>
                        <p>Q14: To what extent did you feel that the technology influences caused breaks: (a) in presence?; and (b) in problem solving?</p>
                      </li>
                      <li>
                        <p>Q15: To what extent did you feel that the social influences on the flow of conversation hindered: (a) your feeling of presence?; and (b) task performance?</p>
                      </li>
                      <li>
                        <p>Q16: To what extent did you feel that the social influences on the flow of conversation supported: (a) presence in the environment?; and (b) task performance?</p>
                      </li>
                    </ul><p>These set of results show clearer correlations and trends than those in other categories. The simple presence and co-presence questions Q9 and Q13 yield very similar results that, in general, create an order for the support for presence and co-presence from high to low as follows: Cave-&gt;Workbench, Workbench-&gt;Trace, (Cave-&gt;Trace or Trace-&gt;Cave), Workbench-&gt;Cave, Trace-&gt;Workbench. Only small differences in breaks of presence and problem solving were noted and pattern of perceived display influences were largely similar with the only notable difference being that with the Cave-&gt;Workbench configuration, breaks in presence were found to be lower than the norm whereas breaks in task performance were higher. Social factors on the flow of conversation are seen to have an equal and positive impact on presence and task performance, with small and consistent differences seen between display types, Q16 and reinforced by counter question. These social factors are seen to be much more of a help than a hindrance.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig11_HTML.gif?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig11_HTML.gif" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Mean values of responses to presence and task performance</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec20">Social influences</h4><p>Some of the following results have been reported above, but are reported here again in the context of social influences. The mean values of the responses are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0050-6#Fig12">12</a>.</p><ul class="u-list-style-bullet">
                      <li>
                        <p>Q15: To what extent did you feel that the social influences on the flow of conversation hindered: (a) your feeling of presence?; and (b) task performance?</p>
                      </li>
                      <li>
                        <p>Q16: To what extent did you feel that the social influences on the flow of conversation supported: (a) presence in the environment?; and (b) task performance?</p>
                      </li>
                      <li>
                        <p>Q17: To what extent did you feel that social influences on the flow of collaboration in general supported creativity?</p>
                      </li>
                    </ul><p>Three of the four CAVE conditions are seen as superior to the fourth and all Trace&lt;-&gt;Workbench configurations. This level of support for presence and task performance is perceived as broadly similar to that for creativity, comparing Q16 and Q17, with the exception that the two workbench conditions are seen to have more impact on creativity than they do on presence and task performance.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig12_HTML.gif?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig12_HTML.gif" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Mean values of responses to social influences</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec21">Technical influences</h4><p>As various immersive technologies were used in this trial it was of interest us how participants judge the influences of this technology on their collaboration and interaction. The responses are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0050-6#Fig13">13</a>.</p><ul class="u-list-style-bullet">
                      <li>
                        <p>Q12: To what extent did you feel that:
</p><ol class="u-list-style-none">
                            <li>
                              <span class="u-custom-list-number">(a)</span>
                              
                                <p>conversation flowed naturally, without focusing on interfaces?</p>
                              
                            </li>
                            <li>
                              <span class="u-custom-list-number">(b)</span>
                              
                                <p>non-verbal communication could help you solving the task?</p>
                              
                            </li>
                            <li>
                              <span class="u-custom-list-number">(c)</span>
                              
                                <p>technical setting supported the flow of non-verbal communication (gestures etc.)?</p>
                              
                            </li>
                            <li>
                              <span class="u-custom-list-number">(d)</span>
                              
                                <p>the interface was intuitive in its support for non-verbal communication?</p>
                              
                            </li>
                            <li>
                              <span class="u-custom-list-number">(e)</span>
                              
                                <p>the interaction with objects was intuitive?</p>
                              
                            </li>
                            <li>
                              <span class="u-custom-list-number">(f)</span>
                              
                                <p>you and your partner worked together to solve the task?</p>
                              
                            </li>
                            <li>
                              <span class="u-custom-list-number">(g)</span>
                              
                                <p>to what extent did you feel that you and your partner worked together to overcome problems with the interface?</p>
                              
                            </li>
                            <li>
                              <span class="u-custom-list-number">(h)</span>
                              
                                <p>you and your partner worked together to overcome problems with the manipulating objects?</p>
                              
                            </li>
                          </ol>
                        
                      </li>
                    </ul>
                    <ul class="u-list-style-bullet">
                      <li>
                        <p>Q18: to what extent the interface interrupted you in relation to: (a) the smoothness with object manipulation?; and (b) object focussed conversation?</p>
                      </li>
                    </ul><p>Trace users perceived a higher collaboration with their partners (Q12 f, g and h), but felt that they suffered more from interruptions in object interaction (Q18 a), and that the interface was less suited to supporting non-verbal communication (Q12 c and d). In general, the higher users perceived the flow of conversation, the lower importance they associated with non-verbal communication (Q12 a and b). Interactions with objects were seen as more intuitive for CAVE conditions than Workbench conditions (Q12 e). More interruptions were noticed in object manipulation than in object focussed collaboration, particularly by Trace users, to some extent by Workbench users and in only one out of four of the CAVE conditions.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-13"><figure><figcaption><b id="Fig13" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 13</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/13" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig13_HTML.gif?as=webp"></source><img aria-describedby="figure-13-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0050-6/MediaObjects/10055_2006_50_Fig13_HTML.gif" alt="figure13" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-13-desc"><p>Mean values of responses to technical influences</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0050-6/figures/13" data-track-dest="link:Figure13 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <p>In summary, subjective impressions painted a much more complex and sometimes conflicting picture, but revealed some clear trends. The impact of the technology on social influences on the flow of conversation was seen as more positive than negative, but little difference was perceived between display types. The level of support for presence and task performance was perceived as broadly similar to that for creativity. In general the impression of the CAVE was more favourable, both as a local and remote interface. However, the Trace was often perceived as offering better support than the Workbench, especially when connected to the CAVE. A general observation given in different words by each and every subject concluded that working in the CAVE-like display was much more fun than with the other display types.</p></div></div></section><section aria-labelledby="Sec22"><div class="c-article-section" id="Sec22-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec22">Discussion</h2><div class="c-article-section__content" id="Sec22-content"><p>We now discuss the results within the context of relevant emerging trends in distributed collaborative working environments.</p><p>The results of the experimentation demonstrated that immersion matters and that higher immersion in the entire setting is beneficial. The conversational analysis showed that although the interface induced many problems in object manipulation and orientation towards objects, people were able to carry on with the task. The total time spent on these interruptions in each task was clearly proportional to the degree of immersion of the interface. Despite these disturbances, verbal and non-verbal conversation continued smoothly and was often used to help people out of these difficulties. Task performance was found to increase with level of immersion and the difference was largely accounted for by the above interruptions. Subjective impressions painted a more complex and sometimes conflicting picture, but some trends were revealed. The level of support for presence and task performance was perceived as broadly similar to that for creativity. In general the impression of the CAVE was more favourable. The impact of the technology on social influences on the flow of conversation was seen as more positive than negative, but little difference in the impact upon this was perceived between display types. Answers to most questions scored highly when the CAVE was the local interface. It was notable that questions about the partner’s role generally scored higher when the remote interface was the CAVE. However, the Trace was often perceived as offering better support than the Workbench, especially when connected to the CAVE. More interruptions were noticed in object manipulation than in object focussed collaboration, particularly by Trace users, to some extent by Workbench users, and in only one out of four of the CAVE condition, which correlates with the findings in conversational analysis and task performance. Task performance was found to increase with level of immersion and the difference was largely accounted for by the above interruptions. Observations found that object manipulation was easier when the hand was tracked directly rather than holding a tracked joystick, and when the display can show objects on the ground when close to them. Furthermore, finding an object, person or place, and orientating to it is far easier when natural glance, rather than manual view orientation, is used. The CAVE was the only display in this trial to have these characteristics.</p><p>Studying asymmetric combinations of displays across the three levels of immersion was useful in itself, as ad hoc connections of heterogeneous facilities are likely to become common place in the future. The experimentation reinforced the findings of previous work to show that asymmetry of paired displays changes roles and behaviour and extended this by showing that the same is true for intermediate as well as opposed levels of immersion. This introduces the question of how to address this for ad hoc connections? Do people need to be aware of the characteristics and limitations of the remote interface and how can this be represented? Would it be, for example, beneficial or politically correct, to represent users of lower immersive devices in wheel chairs to intuitively demonstrate the delay they will have in turning. There is a danger of information overload by informing about a partner’s technological and even social characteristics, however, information about network delays, and the ability to choose an embodiment that says something of who you are, have proved useful and are now common place in network games.</p><p>In an ideal world, we would have tested symmetric display configurations for each level, but did not have access to sufficient resources at the time of the study. Similarly, it would have been preferable to take the full set of measures for the symmetric step-into display trial, but problems of access and availability of test subjects prohibited this. The trials were short and we have already described how familiarity with the technology reduces the impact it has on human behaviour and task performance. To some extent this problem was reduced by using test subjects that were familiar with using immersive CVEs. We have previously found that it takes about three fifteen minute sessions to bring people to a high level of competency in similar tasks and interfaces. All the test subjects had at least this level of experience. However we still observed that the real expert users, those who had developed the application, were considerably more adept at using it.</p><p>A desire to better integrate visualisation technology into the workspace is driving the current trend towards general adoption of less immersive flat screen look-into displays. The findings of this study suggest that such displays may be ill suited to object focussed collaboration across a distributed group. Thus when connected together, such workspaces may not be able to support the collaborative aspects of flow likely to be important in group creativity. However, typical step-into displays, such as CAVEs, cannot easily be incorporated in most working environments. Hence an important challenge is to capture the winning qualities of step-into displays in configurations that fit unobtrusively within everyday environments. Our results suggest that surrounding the user to allow people to follow what each other are doing, and haptic interfaces for object manipulation are of prime importance in supporting seamless workflow. A combination of modular, mobile and flexible displays, integrated with wireless haptic gloves offers one potential solution.</p><p>We have demonstrated that awareness of what others are doing and talking about is useful in object focussed collaboration and that immersion plays a role in the efficiency of keeping track of others interest. Non-verbal resources, such as location, orientation, pointing and head gaze, were all used effectively in the symmetric highly immersive setting. However, we have not considered the key interactional resource of eye-gaze. Eye gaze is important in the management of interaction: speakers have resources for eliciting co-participants’ gaze and for directing the visual attention of others (gaze deixis); speakers’ talk may be responsive to recipients’ gaze direction, and determine whether others are paying attention; gaze may be used alongside talk in accomplishing addressing and referring and prompting another speaker; gaze is used in handling objects; finally gaze may be used to propose courses of action. CVE systems do not normally track eye-gaze, and the few that have, restricted the movement of participants through seating them facing a screen with limited field of view. Similar seating restrictions are needed to support communicational eye-gaze in today’s video conferencing. Research is needed to support and study communicational eye gaze between people as they move around a shared virtual space.</p><p>This study has focussed on immersive CVE technology, which has spatial characteristics fundamentally better supporting, than those of 2D video conferencing, object focussed collaboration. Motion tracked avatars are an important aspect of this; however, typical avatars do not faithfully represent appearance. Thus, it might be easier to gauge someone’s emotions over a video link, but harder to gauge the cause. 3D video reconstruction offers the potential to provide the best of both worlds, but the technology needs to mature before it can achieve this. A key issue is how to support seamless changes in viewpoint, so that people can walk round each other keeping eye-contact. This is complicated by difficulties in placing cameras at eye level surrounding the user, without degradation of the visual image. Another issue is a communicating sufficient level of detail within the real time constraints of conversation. The impact of level of detail and latency on conversation are, for that matter, yet to be deeply studied or understood.</p></div></div></section><section aria-labelledby="Sec23"><div class="c-article-section" id="Sec23-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec23">Conclusion</h2><div class="c-article-section__content" id="Sec23-content"><p>A trend towards more ambitious and multi-disciplinary design projects, as well as more distributed and collaborative ways of working, are driving the need for technology to better support creative group work. To consider interaction that supports creativity, and the factors that impact upon this in distributed collaborative environments, are desirable and achievable goals for the near future. This article attempted to set the seeds for such research, building on a wealth of knowledge and experience of distributed collaborative environments and by providing important new results. The extensive literature study attempted to show a balanced and comprehensive picture of factors that are likely to be of relevance. Within this we explained the relevance of flow to creativity and that workflow and co-presence are possible perquisites of flow for collaborative distributed working. New experimentation looked to discover relationships between level of immersion, workflow, co-presence and creativity. Specifically, we aimed to bridge the gap left by previous studies in two ways: comparing intermediate rather than opposed levels of immersion; and using a more complete set of complementary measures. Objective measurements demonstrated a clear relationship between immersion, workflow and co-presence. Subjective measurements indicated that the level of support for presence and task performance was perceived as broadly similar to that for creativity, and that the highest level of immersion was generally beneficial, but that the two lower levels both had strengths and weaknesses.</p><p>The results demonstrate that <i>immersion matters to the flow of distributed group work</i>, and this finding has implications on the trend towards less immersive devices, driven by the worthy desire to better integrate visualisation into the workplace. In the rush to increase flow by uncluttering the workspace, we may be inadvertently reducing flow by cluttering distributed team work with technology-induced hindrances to workflow. The integration of immerging technologies, such as modular, multi-modal displays, free-viewpoint 3D reconstruction, and the support for fine detail communicational resources, such as eye-gaze, offer the potential to address this issue, and thus substantially improve support for group creativity in ad-hoc connections of workspaces.</p></div></div></section><section aria-labelledby="Sec24"><div class="c-article-section" id="Sec24-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec24">Further work</h2><div class="c-article-section__content" id="Sec24-content"><p>We are building a new facility, with help from the BBC, to study the integration, and use in distributed group work, of modular multi-modal displays and free-viewpoint surround 3D reconstruction. To study the importance of eye-gaze, we are embarking on a two year collaborative project between the universities of Salford, Reading, UCL and Roehampton, which will integrate eye-tacking into CAVE-like facilities at three of the sites and study its impact in three way and object focussed collaborations.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Benford SD et al (1995) User embodiment in collaborative virtual environments. In: CHI’95. ACM Press, Denver" /><p class="c-article-references__text" id="ref-CR1">Benford SD et al (1995) User embodiment in collaborative virtual environments. In: CHI’95. ACM Press, Denver</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bente G, Kraemer NC (2002) Virtual gestures: analyzing social presence effects of computer-mediated and comput" /><p class="c-article-references__text" id="ref-CR2">Bente G, Kraemer NC (2002) Virtual gestures: analyzing social presence effects of computer-mediated and computer-generated nonverbal behaviour. In: Fifth annual international workshop PRESENCE 2002. Porto, pp 233–244</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="RA. Blade, ML. Padgett, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Blade RA, Padgett ML (2002) Virtual environments standards and terminology. In: Stanney KM (ed) Handbook of vi" /><p class="c-article-references__text" id="ref-CR3">Blade RA, Padgett ML (2002) Virtual environments standards and terminology. In: Stanney KM (ed) Handbook of virtual environments. Design, implementation, and applications. Lawrence Erlbaum Associates, London, pp 15–27</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Handbook%20of%20virtual%20environments.%20Design%2C%20implementation%2C%20and%20applications&amp;pages=15-27&amp;publication_year=2002&amp;author=Blade%2CRA&amp;author=Padgett%2CML">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Brogni A, Slater M, Steed A (2003) More breaks less presence. In: Presence 2003, The 6th annual international " /><p class="c-article-references__text" id="ref-CR4">Brogni A, Slater M, Steed A (2003) More breaks less presence. In: Presence 2003, The 6th annual international workshop on presence. Aalborg, Denmark</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="M. Csikszentmihalyi, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Csikszentmihalyi M (1996) Creativity: flow and the psychology of discovery and invention. Harper Perennial, Ne" /><p class="c-article-references__text" id="ref-CR5">Csikszentmihalyi M (1996) Creativity: flow and the psychology of discovery and invention. Harper Perennial, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Creativity%3A%20flow%20and%20the%20psychology%20of%20discovery%20and%20invention&amp;publication_year=1996&amp;author=Csikszentmihalyi%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="MJ. Culnan, " /><meta itemprop="datePublished" content="1987" /><meta itemprop="headline" content="Culnan MJ (1987) Information technologies. In: Jablin F et al (ed) Handbook of organizational communication. S" /><p class="c-article-references__text" id="ref-CR6">Culnan MJ (1987) Information technologies. In: Jablin F et al (ed) Handbook of organizational communication. Sage Publication, Beverly Hills, pp 420–442</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Handbook%20of%20organizational%20communication&amp;pages=420-442&amp;publication_year=1987&amp;author=Culnan%2CMJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fencott C (1999) Content and creativity in virtual environment design. In: Proceedings of virtual systems and " /><p class="c-article-references__text" id="ref-CR7">Fencott C (1999) Content and creativity in virtual environment design. In: Proceedings of virtual systems and multimedia ‘99. University of Abertay</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fjeld M et al (2002) Physical and virtual tools: activity theory applied to the design of groupware. Computer " /><p class="c-article-references__text" id="ref-CR8">Fjeld M et al (2002) Physical and virtual tools: activity theory applied to the design of groupware. Computer supported cooperative work 11, pp 153–180</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Garau M et al (2001) The impact of eye gaze on communication using humanoid avatars. In CHI ‘01: Proceedings o" /><p class="c-article-references__text" id="ref-CR9">Garau M et al (2001) The impact of eye gaze on communication using humanoid avatars. In CHI ‘01: Proceedings of the SIGCHI conference on human factors in computing systems. ACM Press, New York, pp 309–316</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Goffman E (1986) Frame analysis: an essay on the organization of experience. Northeastern University Press, Bo" /><p class="c-article-references__text" id="ref-CR10">Goffman E (1986) Frame analysis: an essay on the organization of experience. Northeastern University Press, Boston, xviii, [4], 586 s</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="R. Held, N. Durlach, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="Held R, Durlach N (1991) Telepresence, time delay and adaptation. In: Ellis SR, Kaiser MK, Grunwald AC (eds) P" /><p class="c-article-references__text" id="ref-CR11">Held R, Durlach N (1991) Telepresence, time delay and adaptation. In: Ellis SR, Kaiser MK, Grunwald AC (eds) Pictorial communication in virtual and real environments. Taylor &amp; Francis, London pp 231–246</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Pictorial%20communication%20in%20virtual%20and%20real%20environments&amp;pages=231-246&amp;publication_year=1991&amp;author=Held%2CR&amp;author=Durlach%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RM. Held, NI. Durlach, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Held RM, Durlach NI (1992) Telepresence. Presence Teleoperators Virtual Environ 1(1):109–112" /><p class="c-article-references__text" id="ref-CR12">Held RM, Durlach NI (1992) Telepresence. Presence Teleoperators Virtual Environ 1(1):109–112</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Telepresence&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=1&amp;issue=1&amp;pages=109-112&amp;publication_year=1992&amp;author=Held%2CRM&amp;author=Durlach%2CNI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Heldal I (2004) Usability development for collaborative virtual environments. In: VIRART workshop: designing a" /><p class="c-article-references__text" id="ref-CR13">Heldal I (2004) Usability development for collaborative virtual environments. In: VIRART workshop: designing and evaluating virtual reality systems. Nottingham</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="I. Heldal, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Heldal I et al (2005) Successes and failures in copresent situations. Presence Teleoperators Virtual Environ 1" /><p class="c-article-references__text" id="ref-CR14">Heldal I et al (2005) Successes and failures in copresent situations. Presence Teleoperators Virtual Environ 14(5):563–579</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474605774918679" aria-label="View reference 14">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Successes%20and%20failures%20in%20copresent%20situations&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=14&amp;issue=5&amp;pages=563-579&amp;publication_year=2005&amp;author=Heldal%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Hindmarsh, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Hindmarsh J et al (2000) Object-focused interaction in collaborative virtual environments. ACM Trans Comput Hu" /><p class="c-article-references__text" id="ref-CR15">Hindmarsh J et al (2000) Object-focused interaction in collaborative virtual environments. ACM Trans Comput Human Interact(ToCHI) 7(4):477–509</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F365058.365088" aria-label="View reference 15">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Object-focused%20interaction%20in%20collaborative%20virtual%20environments&amp;journal=ACM%20Trans%20Comput%20Human%20Interact%28ToCHI%29&amp;volume=7&amp;issue=4&amp;pages=477-509&amp;publication_year=2000&amp;author=Hindmarsh%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Monk A (2003) Common ground in electronically mediated communication: clarks theory of language use. In: Carro" /><p class="c-article-references__text" id="ref-CR16">Monk A (2003) Common ground in electronically mediated communication: clarks theory of language use. In: Carroll J (ed) HCI models, theories and frameworks. Morgan Kaufmann, San Francisco, pp 263–290</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Nardi B, Whittaker S (2002) The role of face-to-face communication in distributed work. MIT Press, Cambridge, " /><p class="c-article-references__text" id="ref-CR17">Nardi B, Whittaker S (2002) The role of face-to-face communication in distributed work. MIT Press, Cambridge, pp 83–112</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Nilsson A et al (2002) The long-term uses of shared virtual environments: an exploratory study. In: Schroeder " /><p class="c-article-references__text" id="ref-CR18">Nilsson A et al (2002) The long-term uses of shared virtual environments: an exploratory study. In: Schroeder R (ed) The social life of avatars. Springer, London</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Norman D (1998) The invisible computer. Why good products can fail, the personal computer is so complex, and i" /><p class="c-article-references__text" id="ref-CR19">Norman D (1998) The invisible computer. Why good products can fail, the personal computer is so complex, and information appliances ate the solution. The MIT Press, London. 0262140659</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Poston T, Serra L (1996) Dextrous virtual work. Communications of the ACM, pp 37–45" /><p class="c-article-references__text" id="ref-CR20">Poston T, Serra L (1996) Dextrous virtual work. Communications of the ACM, pp 37–45</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Riva, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Riva G (1999) Virtual reality as communication tool: a socio-cognitive analysis. Presence Teleoperators Virtua" /><p class="c-article-references__text" id="ref-CR21">Riva G (1999) Virtual reality as communication tool: a socio-cognitive analysis. Presence Teleoperators Virtual Environ 8(4):462–468</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474699566341" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20as%20communication%20tool%3A%20a%20socio-cognitive%20analysis&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=8&amp;issue=4&amp;pages=462-468&amp;publication_year=1999&amp;author=Riva%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Roberts D et al (2004) Supporting social human communication between distributed walk-in displays. In: VRST ‘0" /><p class="c-article-references__text" id="ref-CR22">Roberts D et al (2004) Supporting social human communication between distributed walk-in displays. In: VRST ‘04: ACM symposium on virtual reality software and technology, pp 81–88</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Roberts D et al (2005) Reducing fragmentation in telecollaboration by using IPT interfaces. In: IPT-EGVE works" /><p class="c-article-references__text" id="ref-CR23">Roberts D et al (2005) Reducing fragmentation in telecollaboration by using IPT interfaces. In: IPT-EGVE workshop: Eurographics Association, Switzerland, pp 211–216</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="W. Sadowski, K. Stanney, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Sadowski W, Stanney K (2002) Presence in virtual environments. In: Stanney KM (ed) Handbook of virtual environ" /><p class="c-article-references__text" id="ref-CR24">Sadowski W, Stanney K (2002) Presence in virtual environments. In: Stanney KM (ed) Handbook of virtual environments. Design, implementation, and applications. Lawrence Erlbaum Associates, London, pp 791–806</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Handbook%20of%20virtual%20environments.%20Design%2C%20implementation%2C%20and%20applications&amp;pages=791-806&amp;publication_year=2002&amp;author=Sadowski%2CW&amp;author=Stanney%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Schroeder, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Schroeder R et al (2001) Collaborating in networked immersive spaces: as good as being there together? Comput " /><p class="c-article-references__text" id="ref-CR25">Schroeder R et al (2001) Collaborating in networked immersive spaces: as good as being there together? Comput Graphics 25(5):781–788</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0097-8493%2801%2900120-0" aria-label="View reference 25">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Collaborating%20in%20networked%20immersive%20spaces%3A%20as%20good%20as%20being%20there%20together%3F&amp;journal=Comput%20Graphics&amp;volume=25&amp;issue=5&amp;pages=781-788&amp;publication_year=2001&amp;author=Schroeder%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="CR. Scott, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Scott CR (1999) Communication technology and group communication. In: Frey LR (ed) The handbook of group commu" /><p class="c-article-references__text" id="ref-CR26">Scott CR (1999) Communication technology and group communication. In: Frey LR (ed) The handbook of group communication theory and research. Sage, Thousand Oaks, pp 431–472</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20handbook%20of%20group%20communication%20theory%20and%20research&amp;pages=431-472&amp;publication_year=1999&amp;author=Scott%2CCR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Shneiderman B (2002) Leonardo’s laptop: human needs and the new computing technologies: MIT Press, Cambridge. " /><p class="c-article-references__text" id="ref-CR27">Shneiderman B (2002) Leonardo’s laptop: human needs and the new computing technologies: MIT Press, Cambridge. 0262194767</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="J. Short, E. Williams, B. Christie, " /><meta itemprop="datePublished" content="1976" /><meta itemprop="headline" content="Short J, Williams E, Christie B (1976) The social psychology of telecommunications. Wiley, New York" /><p class="c-article-references__text" id="ref-CR28">Short J, Williams E, Christie B (1976) The social psychology of telecommunications. Wiley, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20social%20psychology%20of%20telecommunications&amp;publication_year=1976&amp;author=Short%2CJ&amp;author=Williams%2CE&amp;author=Christie%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Slater, A. Steed, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Slater M, Steed A (2000) A virtual presence counter. Presence Teleoperators Virtual Environ 9(5):413–434" /><p class="c-article-references__text" id="ref-CR29">Slater M, Steed A (2000) A virtual presence counter. Presence Teleoperators Virtual Environ 9(5):413–434</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474600566925" aria-label="View reference 29">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20virtual%20presence%20counter&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=9&amp;issue=5&amp;pages=413-434&amp;publication_year=2000&amp;author=Slater%2CM&amp;author=Steed%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Slater, S. Wilbur, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Slater M, Wilbur S (1997) A framework for immersive virtual environments (FIVE): Speculations on the role of p" /><p class="c-article-references__text" id="ref-CR30">Slater M, Wilbur S (1997) A framework for immersive virtual environments (FIVE): Speculations on the role of presence in virtual environments. Presence: Teleoperators Virtual Environ 6(6):603–606</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20framework%20for%20immersive%20virtual%20environments%20%28FIVE%29%3A%20Speculations%20on%20the%20role%20of%20presence%20in%20virtual%20environments&amp;journal=Presence%3A%20Teleoperators%20Virtual%20Environ&amp;volume=6&amp;issue=6&amp;pages=603-606&amp;publication_year=1997&amp;author=Slater%2CM&amp;author=Wilbur%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Slater, M. Usoh, A. Steed, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Slater M, Usoh M, Steed A (1994) Depth of Presence in Virtual Environments. Presence Teleoperators Virtual Env" /><p class="c-article-references__text" id="ref-CR31">Slater M, Usoh M, Steed A (1994) Depth of Presence in Virtual Environments. Presence Teleoperators Virtual Environ 3(2):130–144</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Depth%20of%20Presence%20in%20Virtual%20Environments&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=3&amp;issue=2&amp;pages=130-144&amp;publication_year=1994&amp;author=Slater%2CM&amp;author=Usoh%2CM&amp;author=Steed%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Slater M et al (1996) Immersion, presence and performance in virtual environments: An experiment with tri-dime" /><p class="c-article-references__text" id="ref-CR32">Slater M et al (1996) Immersion, presence and performance in virtual environments: An experiment with tri-dimensional chess. In VRST ‘96: Proceedings of the ACM symposium on virtual reality software and technology, pp 163–172</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="KM. Stanney, RR. Mourant, RS. Kennedy, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Stanney KM, Mourant RR, Kennedy RS (1998) Human factors issues in virtual reality: a review of the literature." /><p class="c-article-references__text" id="ref-CR33">Stanney KM, Mourant RR, Kennedy RS (1998) Human factors issues in virtual reality: a review of the literature. Presence Teleoperators Virtual Environ 7(4):327–351</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474698565767" aria-label="View reference 33">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20factors%20issues%20in%20virtual%20reality%3A%20a%20review%20of%20the%20literature&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=7&amp;issue=4&amp;pages=327-351&amp;publication_year=1998&amp;author=Stanney%2CKM&amp;author=Mourant%2CRR&amp;author=Kennedy%2CRS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Tromp, A. Steed, J. Wilson, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Tromp J, Steed A, Wilson J (2003) Systematic usability evaluation and design issues for collaborative virtual " /><p class="c-article-references__text" id="ref-CR34">Tromp J, Steed A, Wilson J (2003) Systematic usability evaluation and design issues for collaborative virtual environments. Presence Teleoperators Virtual Environ 10(3):241–267</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474603765879512" aria-label="View reference 34">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Systematic%20usability%20evaluation%20and%20design%20issues%20for%20collaborative%20virtual%20environments&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=10&amp;issue=3&amp;pages=241-267&amp;publication_year=2003&amp;author=Tromp%2CJ&amp;author=Steed%2CA&amp;author=Wilson%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Vass M, Carroll JM, Shaffer CA (2002) Supporting creativity in problem solving environments. In: Proceedings o" /><p class="c-article-references__text" id="ref-CR35">Vass M, Carroll JM, Shaffer CA (2002) Supporting creativity in problem solving environments. In: Proceedings of the fourth creativity &amp; cognition conference. AMC Press, Leicestershire, pp 31–37</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="JB. Walther, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Walther JB (2002) Time effects in computer-mediated groups: past, present, and future. In: Hinds P, Kiesler S " /><p class="c-article-references__text" id="ref-CR36">Walther JB (2002) Time effects in computer-mediated groups: past, present, and future. In: Hinds P, Kiesler S (eds) Distributed work. MIT Press, Cambridge, pp 235–257</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 36 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Distributed%20work&amp;pages=235-257&amp;publication_year=2002&amp;author=Walther%2CJB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Wilson JR (2003) If VR has changed, then have its human factors? In: Waard Dd et al (eds) Human factors in the" /><p class="c-article-references__text" id="ref-CR37">Wilson JR (2003) If VR has changed, then have its human factors? In: Waard Dd et al (eds) Human factors in the age of virtual reality, Shaker Publishing, Maastrich, pp 9–30</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="BG. Witmer, MJ. Singer, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Witmer BG, Singer MJ (1998) Measuring presence in virtual environments: a presence questionnaire. Presence Tel" /><p class="c-article-references__text" id="ref-CR38">Witmer BG, Singer MJ (1998) Measuring presence in virtual environments: a presence questionnaire. Presence Teleoperators Virtual Environ 7(3):225–240</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474698565686" aria-label="View reference 38">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 38 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Measuring%20presence%20in%20virtual%20environments%3A%20a%20presence%20questionnaire&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=7&amp;issue=3&amp;pages=225-240&amp;publication_year=1998&amp;author=Witmer%2CBG&amp;author=Singer%2CMJ">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-006-0050-6-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgments</h2><div class="c-article-section__content" id="Ack1-content"><p>We would like to thank Anthony Steed from UCL and Ralph Schroeder from the Oxford Internet Institute for many valuable discussions and experimentation that led up to this work. HEFCE for funding the infrastructure used at Salford in these tests and for funding new infrastructure to support the future work on integration of modular multi-modal display displays and 3D reconstruction. We would also like to thank EPSRC for funding the further work into communicational eye-gaze.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">The University of Salford, Salford, UK</p><p class="c-article-author-affiliation__authors-list">David Roberts, Oliver Otto &amp; Robin Wolff</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Chalmers University, Gothenburg, Sweden</p><p class="c-article-author-affiliation__authors-list">Ilona Heldal</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-David-Roberts"><span class="c-article-authors-search__title u-h3 js-search-name">David Roberts</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;David+Roberts&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=David+Roberts" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22David+Roberts%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Ilona-Heldal"><span class="c-article-authors-search__title u-h3 js-search-name">Ilona Heldal</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Ilona+Heldal&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Ilona+Heldal" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ilona+Heldal%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Oliver-Otto"><span class="c-article-authors-search__title u-h3 js-search-name">Oliver Otto</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Oliver+Otto&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Oliver+Otto" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Oliver+Otto%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Robin-Wolff"><span class="c-article-authors-search__title u-h3 js-search-name">Robin Wolff</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Robin+Wolff&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Robin+Wolff" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Robin+Wolff%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-006-0050-6/email/correspondent/c1/new">David Roberts</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Factors%20influencing%20flow%20of%20object%20focussed%20collaboration%20in%20collaborative%20virtual%20environments&amp;author=David%20Roberts%20et%20al&amp;contentID=10.1007%2Fs10055-006-0050-6&amp;publication=1359-4338&amp;publicationDate=2006-09-21&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Roberts, D., Heldal, I., Otto, O. <i>et al.</i> Factors influencing flow of object focussed collaboration in collaborative virtual environments.
                    <i>Virtual Reality</i> <b>10, </b>119–133 (2006). https://doi.org/10.1007/s10055-006-0050-6</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-006-0050-6.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-03-03">03 March 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-07-31">31 July 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-09-21">21 September 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-10">October 2006</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-006-0050-6" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-006-0050-6</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Task Performance</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Video Conferencing</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Object Manipulation</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Subjective Impression</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Head Mount Display</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-006-0050-6.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=50;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

