<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Medical imaging and virtual reality: a personal perspective"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="The evolution of medical imaging, and concomitantly virtual reality (VR) technology, especially over the past 2&#8211;3 decades, has significantly accelerated the use of multi-modality images and..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/12/4.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Medical imaging and virtual reality: a personal perspective"/>

    <meta name="dc.source" content="Virtual Reality 2008 12:4"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2008-11-21"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2008 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="The evolution of medical imaging, and concomitantly virtual reality (VR) technology, especially over the past 2&#8211;3 decades, has significantly accelerated the use of multi-modality images and VR instrumentation in guiding medical procedures, including surgery. The imaging capabilities have not only increased in variety of modalities (CT, MRI, PET, ultrasound, etc.), but also in dimensions and resolution. It is becoming more common to talk about 3D, 4D and even 5D images produced by modern imaging modalities. However, a relatively unexploited potential and capability of this increase in multimodality, multidimensional image data is the synergistic fusion of these datasets into a unified form that describes more accurately and extensively the complex nature of human anatomy, physiology, biology and pathology. The assist in achieving this potential, through realistic simulation, training, rehearsal and delivery of surgery and other interventional procedures by use of VR technology, has been increasingly evident, particularly in education. This paper attempts an overview of this potential, describing the evolution of medical imaging systems and VR that has lead to development of powerful computational techniques to fuse, visualize, analyze and use these images for advanced use in medical practice. This overview is based primarily on the author&#8217;s experience, opinion and perspective, explaining the preponderance of citations to his own work. A brief history of medical imaging and VR, a description of current imaging systems, and a summary of important image processing methods used in image-guided interventions will be given. Examples of use of these methods on several types of multidimensional image datasets will be illustrated, and several examples of real clinical applications described using 3D, 4D and 5D fused image datasets and VR technology for image-guided interventions, image-guided surgery, and image-guided therapy. Finally, the paper will discuss some barriers to progress and provide some prognostic views on the promising future of image-guided medical procedures and surgical interventions."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2008-11-21"/>

    <meta name="prism.volume" content="12"/>

    <meta name="prism.number" content="4"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="235"/>

    <meta name="prism.endingPage" content="257"/>

    <meta name="prism.copyright" content="2008 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-008-0104-z"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-008-0104-z"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-008-0104-z.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-008-0104-z"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Medical imaging and virtual reality: a personal perspective"/>

    <meta name="citation_volume" content="12"/>

    <meta name="citation_issue" content="4"/>

    <meta name="citation_publication_date" content="2008/12"/>

    <meta name="citation_online_date" content="2008/11/21"/>

    <meta name="citation_firstpage" content="235"/>

    <meta name="citation_lastpage" content="257"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-008-0104-z"/>

    <meta name="DOI" content="10.1007/s10055-008-0104-z"/>

    <meta name="citation_doi" content="10.1007/s10055-008-0104-z"/>

    <meta name="description" content="The evolution of medical imaging, and concomitantly virtual reality (VR) technology, especially over the past 2&#8211;3 decades, has significantly accelera"/>

    <meta name="dc.creator" content="Richard A. Robb"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Akay MA, Marsh A (2001) Information technologies in medicine, vol 1. Wiley, New York"/>

    <meta name="citation_reference" content="Augustine KE, Huddleston PM, Holmes III DR, Shridharanni SM, Robb RA (2008) Optimization of spine surgery planning with 3D image templating tools. Proc. SPIE&#8211;Medical Imaging 2008, San Diego, CA, 16&#8211;21 February"/>

    <meta name="citation_reference" content="Brinkmann BJ, Robb RA, O&#8217;Brien TJ, Sharbough FW (1997) Localization, correlation, and visualization of electroencephalographic surface electrodes and brain anatomy in epilepsy studies. Proc. SPIE&#8211;The International Society for Optical Engineering 3033:159&#8211;169"/>

    <meta name="citation_reference" content="Brinkmann BH, Robb RA, O&#8217;Brien TJ, O&#8217;Connor MK, Mullan BP (1998) Multimodality imaging for epilepsy diagnosis and surgical focus localization: three-dimensional image correlation and dual isotope SPECT. Proc. of medical image computing and computer-assisted intervention&#8211;MICCAI 1998, Cambridge, MA, 1496:1087&#8211;1098"/>

    <meta name="citation_reference" content="citation_journal_title=J Nucl Med; citation_title=Quantitative and clinical analysis of SPECT image registration for epilepsy studies; citation_author=BH Brinkmann, TJ O&#8217;Brien, S Aharon, MK O&#8217;Connor, BP Mullan, DP Hanson, RA Robb; citation_volume=40; citation_issue=7; citation_publication_date=1999; citation_pages=1098-1105; citation_id=CR5"/>

    <meta name="citation_reference" content="citation_title=Virtual reality technology; citation_publication_date=1994; citation_id=CR6; citation_author=G Burdea; citation_author=P Coiffet; citation_publisher=Wiley"/>

    <meta name="citation_reference" content="Cameron BM, Robb RA (2004) Patient-specific dynamic geometric models from sequential volumetric time series image data. Proceedings of medicine meets virtual reality 12. In: Westwood JD, Haluck RS, Hoffman HM, Mogel GT, Phillips R, Robb RA (eds) IOS Press, Amsterdam, Netherlands, 98:40&#8211;45"/>

    <meta name="citation_reference" content="citation_journal_title=Clin Orthop; citation_title=Virtual-reality-assisted interventional procedures; citation_author=BM Cameron, RA Robb; citation_volume=442; citation_publication_date=2006; citation_pages=63-73; citation_id=CR8"/>

    <meta name="citation_reference" content="Cameron BM, Holmes III, DR, Rettmann ME, Robb RA (2008) Patient specific physical anatomy models. Proc. medicine meets virtual reality 16&#8212;parallel, combinatorial, convergent: nextmed by design, In: Westwood JD, Haluck RS, Hoffman HM, Mogel GT, Phillips R, Robb RA, Vosburgh KG (eds) IOS Press, Amsterdam, Netherlands, 132:68&#8211;73"/>

    <meta name="citation_reference" content="Camp J, Robb RA (1999) Realistic visualization for surgery simulation using dynamic volume texture mapping and model deformation. Proc. SPIE&#8211;The International Society for Optical Engineering, 3661:24&#8211;31"/>

    <meta name="citation_reference" content="IEEE computer graphics and applications: virtual reality. November/December 2001"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Med Imaging Graph; citation_title=Quantitative characterization of lung disease; citation_author=CR Haider, BJ Bartholmai, DR Holmes, JJ Camp, RA Robb; citation_volume=29; citation_issue=7; citation_publication_date=2005; citation_pages=555-563; citation_doi=10.1016/j.compmedimag.2005.04.004; citation_id=CR11"/>

    <meta name="citation_reference" content="Harris SS, Robb RA (2003) Piecewise registration for point-to-surface mapping of cardiac data. Proc. SPIE&#8211;Medical Imaging 2003, physiology and function: methods, systems and applications, 5031:146&#8211;153."/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Medical Imaging MI; citation_title=A new method for shaded surface display of biological and medical images; citation_author=PB Heffernan, RA Robb; citation_volume=-4; citation_publication_date=1985; citation_pages=26-38; citation_id=CR13"/>

    <meta name="citation_reference" content="Holmes III DR, Rettmann M, Cameron B, Camp J, Robb RA (2008) Developing patient-specific anatomic models for validation of cardiac ablation guidance procedures. Proc. SPIE&#8211;Medical Imaging 2008, San Diego, California, February 16&#8211;21"/>

    <meta name="citation_reference" content="Holmes III DR, Robb RA (2000) Trans-urethral ultrasound (TUUS) imaging for visualization and analysis of the prostate and associated tissues. Proc. SPIE&#8211;medical imaging 2000: image display and visualization 3976:22&#8211;27"/>

    <meta name="citation_reference" content="Khurana VG, Cameron BM, Bates LM, Robb RA (1999a) Virtual frontiers, part 1: fundamental concepts and recent advances in virtual reality technology. In: Fisher III WS (ed) Perspectives in neurological surgery. Thieme Publishing, New York 10(2):113&#8211;127"/>

    <meta name="citation_reference" content="Khurana VG, Bates LM, Meyer FB, Robb RA (1999b) Virtual frontiers, part 2: role of virtual reality technology in neurosurgery. In: Fisher III WS (ed) Perspectives in neurological surgery. Thieme Publishing, New York 10(2):113&#8211;127"/>

    <meta name="citation_reference" content="Lepard KO, Robb RA (1996) Shape-based segmentation and characterization of biomedical images. Proc. SPIE&#8211;the international society for optical engineering, vol 2710"/>

    <meta name="citation_reference" content="Lin W, Robb RA (2000) A 5-D model for accurate representation and visualization of dynamic cardiac structures. Proc. SPIE&#8211;Biomedical Diagnostic, Guidance, and Surgical Assist Systems II, 3911:322&#8211;329 "/>

    <meta name="citation_reference" content="citation_journal_title=J Bone Miner Res; citation_title=Structural determinants of vertebral fracture risk; citation_author=LJ Melton, BL Riggs, TM Keaveny, SJ Achenbach, PF Hoffman, JJ Camp, PA Rouleau, ML Bouxsein, S Amin, EJ Atkinson, RA Robb, S Khosla; citation_volume=22; citation_issue=12; citation_publication_date=2007; citation_pages=1885-1892; citation_doi=10.1359/jbmr.070728; citation_id=CR21"/>

    <meta name="citation_reference" content="Packer DL, Asirvatham S, Seward JB, Breen JF, Robb RA (2004) Imaging of the cardiac and thoracic veins. Chap. 8. In: Chen, Haissaguerre, Zipes (eds) Thoracic vein arrhythmias: mechanisms and treatments. Prepress Projects, Ltd., Scotland"/>

    <meta name="citation_reference" content="Rajagopalan S, Robb RA (2006) Fourier-domain based datacentric performance ranking of competing medical image processing algorithms. Proc. SPIE&#8211;medical imaging 2006, San Diego, CA, 11&#8211;16 February"/>

    <meta name="citation_reference" content="Rettmann ME, Holmes III DR, Su Y, Cameron BM, Packer DL, Robb RA (2006) An integrated system for real-time image guided cardiac catheter ablation. Proc. medicine meets virtual reality 14. In:Westwood JD, Haluck RS, Hoffmann HM, Mogel GT, Phillips R, Robb RA, Vosburgh KG (eds) IOS Press, Amsterdam, Netherlands, 119:455&#8211;460"/>

    <meta name="citation_reference" content="Rettmann ME, Holmes III DR, Camp JJ, Packer DL, Robb RA (2008) Validation of semi-automatic segmentation of the left atrium. Proc. SPIE&#8211;medical imaging 2008, San Diego, CA, 16&#8211;21 February"/>

    <meta name="citation_reference" content="citation_journal_title=Mayo Clin Proc; citation_title=Quantitative imaging of the structure and function of the heart, lungs, and circulation; citation_author=EL Ritman, RA Robb, SA Johnson, PA Chevalier, BK Gilbert, JF Greenleaf, RE Sturm, EH Wood; citation_volume=53; citation_publication_date=1978; citation_pages=3-11; citation_id=CR26"/>

    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Three-dimensional imaging of heart, lungs, and circulation; citation_author=EL Ritman, JH Kinsey, RA Robb, BK Gilbert, LD Harris, EH Wood; citation_volume=210; citation_publication_date=1980; citation_pages=273-280; citation_doi=10.1126/science.7423187; citation_id=CR27"/>

    <meta name="citation_reference" content="Robb RA (1971) Computer-aided contour determination and dynamic display of individual cardiac chambers from digitized serial angiocardiographic film. In: Heintzen PH (ed) Roentgen-, cine-, and videodensitometry. Fundamentals and application for blood flow and heart volume determination. Georg Thieme Verlag, Stuttgart, pp 170&#8211;178"/>

    <meta name="citation_reference" content="citation_journal_title=Annu Rev Biophys Bioeng; citation_title=X-ray computed tomography: from basic principles to applications; citation_author=RA Robb; citation_volume=11; citation_publication_date=1982; citation_pages=177-201; citation_doi=10.1146/annurev.bb.11.060182.001141; citation_id=CR29"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Medical Imaging, MI; citation_title=The dynamic spatial reconstructor: an X-ray video-fluoroscopic CT scanner for dynamic volume imaging of moving organs; citation_author=RA Robb; citation_volume=-1; citation_issue=1; citation_publication_date=1982b; citation_pages=22-23; citation_id=CR30"/>

    <meta name="citation_reference" content="citation_title=Three-dimensional biomedical imaging&#8212;principles and practice; citation_publication_date=1995; citation_id=CR31; citation_author=RA Robb; citation_publisher=VCH Publishers"/>

    <meta name="citation_reference" content="citation_title=Biomedical imaging, visualization and analysis; citation_publication_date=1999; citation_id=CR32; citation_author=RA Robb; citation_publisher=Wiley"/>

    <meta name="citation_reference" content="citation_journal_title=Parallel Comput; citation_title=Visualization in biomedical computing; citation_author=RA Robb; citation_volume=25; citation_publication_date=1999; citation_pages=2067-2110; citation_doi=10.1016/S0167-8191(99)00076-9; citation_id=CR33"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Med Imaging Graph; citation_title=Virtual endoscopy: development and evaluation using the visible human datasets; citation_author=RA Robb; citation_volume=24; citation_publication_date=2000; citation_pages=133-151; citation_doi=10.1016/S0895-6111(00)00014-8; citation_id=CR34"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE TMI; citation_title=The biomedical imaging resource at mayo clinic; citation_author=RA Robb; citation_volume=20; citation_issue=9; citation_publication_date=2001; citation_pages=854-867; citation_id=CR35"/>

    <meta name="citation_reference" content="Robb RA (2001b) Virtual reality in medicine and biology. In: Akay M, Marsh A (eds) Information technologies in medicine: medical simulation and education. Wiley, New York, vol 1, Chap. 1, pp 3&#8211;31"/>

    <meta name="citation_reference" content="Robb RA (2002a) The virtualization of medicine: a decade of pitfalls and progress. Medicine meets virtual reality 02/10. In: Westwood JD, Hoffman HM, Robb RA, Stredney D (eds) IOS Press Amsterdam, Netherlands, vol 85, pp 31&#8211;37"/>

    <meta name="citation_reference" content="citation_journal_title=J Visualization; citation_title=Virtual reality in medicine: a personal perspective; citation_author=RA Robb; citation_volume=5; citation_issue=4; citation_publication_date=2002; citation_pages=317-326; citation_doi=10.1007/BF03182346; citation_id=CR39"/>

    <meta name="citation_reference" content="Robb RA (2005) Image processing for anatomy and physiology: fusion of form and function. Proceedings of sixth annual national forum on biomedical imaging and oncology, NCI/NEMA/DCTD, Bethesda, MD, 7&#8211;8 April"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Medical Imaging; citation_title=Interactive display and analysis of 3-D medical images; citation_author=RA Robb, C Barillot; citation_volume=8; citation_issue=3; citation_publication_date=1989; citation_pages=217-226; citation_doi=10.1109/42.34710; citation_id=CR41"/>

    <meta name="citation_reference" content="Robb RA, Hanson DP (1995) The ANALYZETM software system for visualization and analysis in surgery simulation. In: Lavall&#233;e S, Taylor R, Burdea G, M&#246;sges R (eds) Computer integrated surgery. MIT Press, Cambridge, pp 175&#8211;190"/>

    <meta name="citation_reference" content="citation_journal_title=Radiology; citation_title=High-speed synchronous volume computed tomography of the heart; citation_author=RA Robb, EL Ritman; citation_volume=133; citation_publication_date=1979; citation_pages=655-661; citation_id=CR43"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Biomed Res; citation_title=Three-dimensional visualization of the intact thorax and contents: a technique for cross-sectional reconstruction from multiplanar X-ray views; citation_author=RA Robb, JF Greenleaf, EL Ritman, SA Johnson, JD Sjostrand, GT Herman, EH Wood; citation_volume=7; citation_publication_date=1974; citation_pages=395-419; citation_doi=10.1016/0010-4809(74)90015-9; citation_id=CR44"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Nuclear Science; citation_title=The DSR: a high-speed three-dimensional X-ray computed tomography system for dynamic spatial reconstruction of the heart and circulation; citation_author=RA Robb, EL Ritman, BK Gilbert, JH Kinsey, LD Harris, EH Wood; citation_volume=NS-26; citation_issue=2; citation_publication_date=1979; citation_pages=2713-2717; citation_doi=10.1109/TNS.1979.4330520; citation_id=CR45"/>

    <meta name="citation_reference" content="citation_journal_title=Computer; citation_title=Computer-aided surgery planning and rehearsal at Mayo Clinic; citation_author=RA Robb, DP Hanson, JJ Camp; citation_volume=29; citation_issue=1; citation_publication_date=1996; citation_pages=39-47; citation_doi=10.1109/2.481435; citation_id=CR46"/>

    <meta name="citation_reference" content="Robb RA, Cameron BM, Aharon S (1997) Efficient shape-based algorithms for modeling patient specific anatomy from 3D medical images: applications in virtual endoscopy and surgery. Proceedings of shape modeling and applications, pp 97&#8211;108, Aizu-Wakamatsu, Japan, 3&#8211;6 March"/>

    <meta name="citation_reference" content="citation_title=Cybersurgery: advanced technologies for surgical practice; citation_publication_date=1998; citation_id=CR48; citation_author=R Satava; citation_publisher=Wiley"/>

    <meta name="citation_reference" content="citation_journal_title=PRESENCE; citation_title=Virtual endoscopy: applications of 3-D visualization to medical diagnosis; citation_author=RM Satava, RA Robb; citation_volume=6; citation_issue=2; citation_publication_date=1997; citation_pages=179-197; citation_id=CR49"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Aided Surg; citation_title=Seed localization and TRUS-fluoroscopy fusion for intraoperative prostate brachytherapy dosimetry; citation_author=Y Su, BJ Davis, KM Furutani, MG Herman, RA Robb; citation_volume=12; citation_issue=1; citation_publication_date=2007; citation_pages=25-34; citation_doi=10.1080/10929080601168239; citation_id=CR50"/>

    <meta name="citation_reference" content="Wu QR, Bourland JD, Robb RA (1996) Morphology guided radiotherapy treatment planning and optimization. Proc. SPIE&#8211;The International Society for Optical Engineering, 2707:180&#8211;189"/>

    <meta name="citation_reference" content="citation_journal_title=Acad Radiol; citation_title=High resolution multi-detector CT aided tissue analysis and quantification of lung fibrosis; citation_author=VA Zavaletta, BJ Bartholmai, RA Robb; citation_volume=14; citation_publication_date=2007; citation_pages=772-787; citation_doi=10.1016/j.acra.2007.03.009; citation_id=CR52"/>

    <meta name="citation_author" content="Richard A. Robb"/>

    <meta name="citation_author_email" content="robb.richard@mayo.edu"/>

    <meta name="citation_author_institution" content="Mayo Clinic College of Medicine, Rochester, USA"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-008-0104-z&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2008/12/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-008-0104-z"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Medical imaging and virtual reality: a personal perspective"/>
        <meta property="og:description" content="The evolution of medical imaging, and concomitantly virtual reality (VR) technology, especially over the past 2–3 decades, has significantly accelerated the use of multi-modality images and VR instrumentation in guiding medical procedures, including surgery. The imaging capabilities have not only increased in variety of modalities (CT, MRI, PET, ultrasound, etc.), but also in dimensions and resolution. It is becoming more common to talk about 3D, 4D and even 5D images produced by modern imaging modalities. However, a relatively unexploited potential and capability of this increase in multimodality, multidimensional image data is the synergistic fusion of these datasets into a unified form that describes more accurately and extensively the complex nature of human anatomy, physiology, biology and pathology. The assist in achieving this potential, through realistic simulation, training, rehearsal and delivery of surgery and other interventional procedures by use of VR technology, has been increasingly evident, particularly in education. This paper attempts an overview of this potential, describing the evolution of medical imaging systems and VR that has lead to development of powerful computational techniques to fuse, visualize, analyze and use these images for advanced use in medical practice. This overview is based primarily on the author’s experience, opinion and perspective, explaining the preponderance of citations to his own work. A brief history of medical imaging and VR, a description of current imaging systems, and a summary of important image processing methods used in image-guided interventions will be given. Examples of use of these methods on several types of multidimensional image datasets will be illustrated, and several examples of real clinical applications described using 3D, 4D and 5D fused image datasets and VR technology for image-guided interventions, image-guided surgery, and image-guided therapy. Finally, the paper will discuss some barriers to progress and provide some prognostic views on the promising future of image-guided medical procedures and surgical interventions."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Medical imaging and virtual reality: a personal perspective | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-008-0104-z","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Multi-modality imaging, Multi-dimensional imaging, Image fusion, Image visualization, Image modeling, Evolution of imaging, Virtual reality technology","kwrd":["Multi-modality_imaging","Multi-dimensional_imaging","Image_fusion","Image_visualization","Image_modeling","Evolution_of_imaging","Virtual_reality_technology"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-008-0104-z","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-008-0104-z","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=104;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-008-0104-z">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Medical imaging and virtual reality: a personal perspective
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-008-0104-z.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-008-0104-z.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2008-11-21" itemprop="datePublished">21 November 2008</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Medical imaging and virtual reality: a personal perspective</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Richard_A_-Robb" data-author-popup="auth-Richard_A_-Robb" data-corresp-id="c1">Richard A. Robb<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Mayo Clinic College of Medicine" /><meta itemprop="address" content="grid.66875.3a, 000000040459167X, Mayo Clinic College of Medicine, Rochester, MN, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 12</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">235</span>–<span itemprop="pageEnd">257</span>(<span data-test="article-publication-year">2008</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">722 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">4 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">0 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-008-0104-z/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>The evolution of medical imaging, and concomitantly virtual reality (VR) technology, especially over the past 2–3 decades, has significantly accelerated the use of multi-modality images and VR instrumentation in guiding medical procedures, including surgery. The imaging capabilities have not only increased in variety of modalities (CT, MRI, PET, ultrasound, etc.), but also in dimensions and resolution. It is becoming more common to talk about 3D, 4D and even 5D images produced by modern imaging modalities. However, a relatively unexploited potential and capability of this increase in multimodality, multidimensional image data is the synergistic fusion of these datasets into a unified form that describes more accurately and extensively the complex nature of human anatomy, physiology, biology and pathology. The assist in achieving this potential, through realistic simulation, training, rehearsal and delivery of surgery and other interventional procedures by use of VR technology, has been increasingly evident, particularly in education. This paper attempts an overview of this potential, describing the evolution of medical imaging systems and VR that has lead to development of powerful computational techniques to fuse, visualize, analyze and use these images for advanced use in medical practice. This overview is based primarily on the author’s experience, opinion and perspective, explaining the preponderance of citations to his own work. A brief history of medical imaging and VR, a description of current imaging systems, and a summary of important image processing methods used in image-guided interventions will be given. Examples of use of these methods on several types of multidimensional image datasets will be illustrated, and several examples of real clinical applications described using 3D, 4D and 5D fused image datasets and VR technology for image-guided interventions, image-guided surgery, and image-guided therapy. Finally, the paper will discuss some barriers to progress and provide some prognostic views on the promising future of image-guided medical procedures and surgical interventions.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><h3 class="c-article__sub-heading" id="Sec2">Medical imaging</h3><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig1">1</a> summarizes milestones in the history of medical imaging, extending back more than 700 years to the 1300s when anatomy dissection theaters were in vogue. In such theaters, the live patient or cadavers were opened up for direct visualization of internal organs and structures. This, of course, was the epitome of invasiveness in surgery. Modern medical imaging (Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999a" title="Robb RA (1999a) Biomedical imaging, visualization and analysis. Wiley, New York" href="/article/10.1007/s10055-008-0104-z#ref-CR32" id="ref-link-section-d91735e293">1999a</a>) really began with the discovery of the X-ray by Roentgen in 1895. An important contribution was made in 1917 by a contemporary mathematician named Radon who developed the mathematics for computed tomography, which is used in one form or another in virtually all modern tomographic scanning systems. The use of radiography accelerated throughout the early 20th Century, and by the 1940s “dynamic X-rays” called fluoroscopy were developed and used. In the 1950s, nuclear medicine imaging techniques were developed. Arguably the greatest revolution in modern medical imaging came in the early 1970s with the advent of the “CAT” scanner which heralded the era of true digital imaging. These images were based on computational methods applied to numeric recordings of X-ray absorption from many angles of view through the body, using formulas based on Radon’s inversion mathematics (Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1982a" title="Robb RA (1982a) X-ray computed tomography: from basic principles to applications. Annu Rev Biophys Bioeng 11:177–201" href="/article/10.1007/s10055-008-0104-z#ref-CR29" id="ref-link-section-d91735e296">1982a</a>). In the past three decades, dynamic spatial reconstruction capabilities have been developed and demonstrated, and currently modern CT, MRI, PET, SPECT and other scanning modalities provide high resolution, fast volume imaging capabilities.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Some milestones in the 700-year history of medical imaging</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-008-0104-z#Tab1">1</a> summarizes the dimensionality of modern medical images beginning with the early modern X-ray images produced by Roentgen. Two-dimensional images are basically projections of 3D objects onto 2D recording media (X-ray sheets or TV monitors). Current imaging systems obtain true spatial 3D anatomy in the <i>x</i>, <i>y</i> and <i>z</i> dimensions and even 4D images when 3D anatomy is imaged rapidly over time. The current highest practical dimensionality is 5D, where the three spatial dimensions plus time are supplemented by synchronous functional information (an exciting example of such dimensionality will be illustrated later). There is no mathematical or physical principle limiting dimensionality to 5D when, in fact, multiple functional parameters all relating to the same object through time can be obtained and combined together to create a “hyper-image”, such as a vector image or a tensor image. These functions may not always be entirely independent of one another, but if they exhibit sufficient orthogonality they indeed can be characterized as <i>n</i>-dimensional. An example would be a 3D heart beating through time with several measures of function at each myocardial muscle point: such functional measures could be electrical activity, pressure, temperature, elasticity, diffusion, etc.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 The evolving image dimensions</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-008-0104-z/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig2">2</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig3">3</a> document the author’s early involvement with 3D medical imaging in the 1960s and 1970s. He developed methods (Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1971" title="Robb RA (1971) Computer-aided contour determination and dynamic display of individual cardiac chambers from digitized serial angiocardiographic film. In: Heintzen PH (ed) Roentgen-, cine-, and videodensitometry. Fundamentals and application for blood flow and heart volume determination. Georg Thieme Verlag, Stuttgart, pp 170–178" href="/article/10.1007/s10055-008-0104-z#ref-CR28" id="ref-link-section-d91735e476">1971</a>) in the 1960s to digitize cine-angiograms of contrast-filled chambers of the heart and convert them to alpha-numeric displays for computer representation, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig2">2</a>. He developed border-detection algorithms for the dye-filled, high-contrast ventricles to dynamically measure changing volumes and muscle dynamics throughout the cardiac cycle. Even at that early stage, he became interested in 3D cardiac volumes using biplane digital cine-angiographic images and borders algorithmically determined in orthogonal planes. Wire frame representations of the 3D ventricular cavities were created. This early work led to the author’s involvement in development of dynamic 3D cardiac imaging in the early 1970s at Mayo Clinic (Robb et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1974" title="Robb RA, Greenleaf JF, Ritman EL, Johnson SA, Sjostrand JD, Herman GT, Wood EH (1974) Three-dimensional visualization of the intact thorax and contents: a technique for cross-sectional reconstruction from multiplanar X-ray views. Comput Biomed Res 7:395–419" href="/article/10.1007/s10055-008-0104-z#ref-CR44" id="ref-link-section-d91735e482">1974</a>; Ritman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1978" title="Ritman EL, Robb RA, Johnson SA, Chevalier PA, Gilbert BK, Greenleaf JF, Sturm RE, Wood EH (1978) Quantitative imaging of the structure and function of the heart, lungs, and circulation. Mayo Clin Proc 53:3–11" href="/article/10.1007/s10055-008-0104-z#ref-CR26" id="ref-link-section-d91735e486">1978</a>; Robb et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1979" title="Robb RA, Ritman EL, Gilbert BK, Kinsey JH, Harris LD, Wood EH (1979) The DSR: a high-speed three-dimensional X-ray computed tomography system for dynamic spatial reconstruction of the heart and circulation. IEEE Transactions on Nuclear Science NS-26(2):2713–2717" href="/article/10.1007/s10055-008-0104-z#ref-CR45" id="ref-link-section-d91735e489">1979</a>). Prototype scanning systems were developed for multi-angular fluoroscopic rendering of the chest cavity and the beating heart. Using gated imaging techniques, 3D reconstructions of the beating heart could be determined (Robb and Ritman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1979" title="Robb RA, Ritman EL (1979) High-speed synchronous volume computed tomography of the heart. Radiology 133:655–661" href="/article/10.1007/s10055-008-0104-z#ref-CR43" id="ref-link-section-d91735e492">1979</a>). These early prototype systems evolved into a true dynamic volume imaging system called the Mayo Dynamic Spatial Reconstructor, illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig3">3</a> (Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1982b" title="Robb RA (1982b) The dynamic spatial reconstructor: an X-ray video-fluoroscopic CT scanner for dynamic volume imaging of moving organs. IEEE Transactions on Medical Imaging, MI-1(1):22–23" href="/article/10.1007/s10055-008-0104-z#ref-CR30" id="ref-link-section-d91735e498">1982b</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Early dynamic “2½ D” imaging using digitized biplane angiograms</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Dynamic volume imaging: The Mayo DSR (c. 1975–1998)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The DSR system was the first multi-source, multi-detector, real-time 4D CT imaging system ever developed to produce true dynamic visualizations of the beating heart. It performed body volume scans of 120–240 slices per volume image at rates up to 30 volume images per second. The spatial resolution was isotropic at approximately 1mm<sup>3</sup>. With this device, cross sections of the beating heart or breathing lungs could be obtained at 1 mm adjacent intervals over the entire anatomic extent of the heart or the lungs at instant-to-instant points throughout the cardiac and/or respiratory cycles. Even though medical imaging systems have begun to approach this combination of high spatial and temporal resolution, the DSR remains unique in its high temporal and spatial resolution imaging capabilities (Ritman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1980" title="Ritman EL, Kinsey JH, Robb RA, Gilbert BK, Harris LD, Wood EH (1980) Three-dimensional imaging of heart, lungs, and circulation. Science 210:273–280" href="/article/10.1007/s10055-008-0104-z#ref-CR27" id="ref-link-section-d91735e543">1980</a>).</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig4">4</a> illustrates the data and process flow, forward and backward, common to most modern medical imaging systems and applications. Images are initially acquired by a CT, MR, PET or other scanner, involving different kinds of sources, detectors, scan geometries and so forth, and the images are often reconstructed online with the system. Either raw or reconstructed images are then passed along for image processing, which often includes preconditioning of the images for further use by the intended application. These important image processing steps include enhancement filtering, anatomic and/or feature segmentation, registration of inter-modality or intra-modality images, fusing these images into cohesive vector images, volume rendering, etc. The results of such processing are then used by physicians, surgeons, scientists, engineers in particular applications. These often involve viewing for diagnostic and interpretive processes, but additionally for making quantitative measurements and using these measurements and images to guide interventional procedures and treatment of disease and trauma. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig5">5</a> illustrates several current modern volume image acquisition systems and examples of the image data they produce, in particular CT, MRI, PET and ultrasound (Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Robb RA (1995) Three-dimensional biomedical imaging—principles and practice. VCH Publishers, New York" href="/article/10.1007/s10055-008-0104-z#ref-CR31" id="ref-link-section-d91735e556">1995</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Flowchart for medical imaging</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Current dynamic volume imaging systems</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec3">Virtual reality</h3><p>The impact of VR in medicine has been an evolutionary culmination of digression and progression that has resulted in some success and useful contributions and some wasted time and resources. However, facts are in evidence that in the past 15 years or so there has been remarkable intrusion by advanced technology into the world of medicine and healthcare, including virtual reality technology. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-008-0104-z#Tab2">2</a> summarizes but a few of the more obvious and egregious pitfalls and only some of the generally acclaimed progress of VR in medicine during the past 15 years (Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002a" title="Robb RA (2002a) The virtualization of medicine: a decade of pitfalls and progress. Medicine meets virtual reality 02/10. In: Westwood JD, Hoffman HM, Robb RA, Stredney D (eds) IOS Press Amsterdam, Netherlands, vol 85, pp 31–37" href="/article/10.1007/s10055-008-0104-z#ref-CR38" id="ref-link-section-d91735e606">2002a</a>).</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Some problems and progress of VR in medicine</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-008-0104-z/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Virtual reality has a relatively short history (Burdea and Coiffet <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Burdea G, Coiffet P (1994) Virtual reality technology. Wiley, New York" href="/article/10.1007/s10055-008-0104-z#ref-CR6" id="ref-link-section-d91735e861">1994</a>). One reasonable starting point coincides in the early 1960s with the development of the “Sensorama Simulator”. This device placed the user in a surrounding visual and audio field to provoke a sense of immersion in the scene. The device was marginally successful as an oddity in the entertainment industry. More significant and useful developments followed this nascent stage. To mention a few, the development of the first head-mounted display in 1966, and in the early 1970s the development of high resolution screens for generating realistic scenes in flight simulation. The military rapidly adapted this technology in flight simulators, developing flight helmets and other interactive simulators to train pilots and other military personnel. A great amount of this work was unpublished. Other contributions to VR came in the early 1980s with the development of LCD-based head-mounted displays and in 1982 the first VR system, called VIVED or “Virtual Visualization Environmental Display”. This system consisted of a mini-computer, a graphics system, and a magnetic non-contact tracker. Feedback devices also began to appear in the 1980s, including the first sensory gloves. In the late 1980s another system called VIEW for “Virtual Interface Environment Workstation” was developed incorporating 3D virtual sound and some of the very first surface renderings instead of wire frame graphics.</p><p>Medical VR began in the very late 1980s (Akay and Marsh <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Akay MA, Marsh A (2001) Information technologies in medicine, vol 1. Wiley, New York" href="/article/10.1007/s10055-008-0104-z#ref-CR1" id="ref-link-section-d91735e867">2001</a>). In 1989, the first simulated surgery procedure for doing tendon transplants was published. In 1991 an abdominal surgery simulator was reported, and in 1993 detailed graphics of highly realistic images of the human torso, including deformable models, was published. The advent of the Visible Human Dataset from the National Library of Medicine in 1994 generated a large number of efforts to produce more realistic simulations of a variety of medical procedures. A hysteroscopy simulator using haptics was developed and published in 1995. Virtual endoscopy had its beginnings in the middle 1990s with simultaneous developments by several groups. By the late 1990s, a wide array of VR devices and systems were being developed for and used in medicine. Haptic input–output devices, tracking and navigation instruments, and high resolution head-mounted displays permit trainers and surgeons to perform highly realistic surgical simulations and rehearsals. More recently, incorporation of realistic physical properties into deformable models, ultrahigh resolution displays, more sensitive haptic devices and intelligent mapping of physiological properties onto anatomy have moved virtual reality into the mainstream of medical technology research, and useful clinical applications have begun to appear (Satava <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Satava R (1998) Cybersurgery: advanced technologies for surgical practice. Wiley, New York" href="/article/10.1007/s10055-008-0104-z#ref-CR48" id="ref-link-section-d91735e870">1998</a>).</p><p>Interactive visualization and virtual reality technology have opened new realms in the practice of medicine. Virtual reality refers to a human–computer interface that facilitates highly interactive visualization and control of computer generated 3D scenes and their related components with sufficient detail and speed so as to evoke sensorial experience similar to that of real experience. VR technology permits computed 3D and 4D images obtained from medical and biologic imaging systems to be faithfully transformed into patient-specific anatomic models, with physical and functional properties added as appropriate, providing interaction with and manipulation of the realistic models with intuitive immediacy similar to and sometimes indistinguishable from that of real objects, all employed in specific clinical tasks and applications. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig6">6</a> illustrates this paradigm for deriving clinical applications from patient-specific body scans. In medical VR, the viewer can “enter” the body to take up any viewpoint, anatomic objects can be dynamic—either in response to viewer actions or to illustrate normal or abnormal function—and other senses can be synergistically engaged, such as touch and hearing (or even smell) to enrich the simulation. Applications extend across a vast range of scale from individual molecules and cells through the varieties of tissue to organs and organ systems, including functional attributes of these systems, such as biophysical and physiological properties (Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001a" title="Robb RA (2001a) The biomedical imaging resource at mayo clinic. IEEE TMI 20(9):854–867" href="/article/10.1007/s10055-008-0104-z#ref-CR35" id="ref-link-section-d91735e879">2001a</a>). Medical applications include anatomy instruction, enhanced diagnosis, and treatment planning, rehearsal and surgical execution. The greatest potential for revolutionary innovation in the teaching and practice of medicine and biology lies in dynamic, fully immersive, multisensory fusion of real and virtual information data streams. Although this technology is still being refined, vastly increased computational capabilities have facilitated major advances, and there are several practical applications involving varying levels of interactivity, immersion and sensory experiences that are now possible (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference IEEE computer graphics and applications" title="IEEE computer graphics and applications: virtual reality. November/December 2001" href="/article/10.1007/s10055-008-0104-z#ref-CR10" id="ref-link-section-d91735e882">IEEE computer graphics and applications</a>). These applications will have a significant impact on medicine and biology now and in the near future. These applications require an intimate and immediate union of patient-specific images and models with other real-world, real-time data. It may well be that the ultimate value of VR in medicine will derive more from the sensory enhancement or augmentation of real experience than from the simulation of normally-sensed reality. This variant of VR is often referred to as AR (augmented reality) or sometimes MR (mixed reality).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Visualization paradigm for virtualization (computer modeling) of advanced high spatial and temporal resolution volume images of the body for clinical applications. Future scanning systems will provide image data for every region of the body, ranging in size from cells to organs. Functional properties and physical characteristics will be fused with these anatomic and micro structures to provide rapid and accurate analysis of structure-to-function relationships, including expression of cell function at the organ level, connecting specific micro-cellular level mechanisms and/or abnormalities with specific diseases and malfunctions at the macro-organ level. Such capabilities will provide synchronous detection, differentiation and treatment of disease that will become the evolutionary successor of current image-guided diagnosis and therapy</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>In spite of numerous “fits and starts”, progress has been sufficient to deploy VR technology in the operating or procedure room to provide the physician or surgeon with online, intra-operative access to and viewing of 5D volume images of the anatomic regions of interest, along with associated physiological functions, all translated faithfully to the patient on the procedure table. Preoperative volume image data and models can be fused with real-time data in the procedure room to provide enhanced visualizations of dynamic functional processes as well as anatomy, to make online measurements and generally to manipulate, control and guide interventional procedures (Cameron and Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Cameron BM, Robb RA (2006) Virtual-reality-assisted interventional procedures. Clin Orthop 442:63–73" href="/article/10.1007/s10055-008-0104-z#ref-CR8" id="ref-link-section-d91735e907">2006</a>). Accurate tracking devices for reliable interactive navigation in such procedures have only recently become available. In the past, magnetic trackers were seriously compromised by the “unfriendly” metallic environment in the procedure room, and often required the physician to be tethered to the device. Free-standing optical and very recent metal-immune magnetic tracking/navigation systems are now providing working solutions. Not withstanding the pitfalls, current VR-based capabilities have largely dispelled the formative notion that virtual reality must include three inseparable components, namely: (1) immersion, (2) interaction and (3) imagination. Participants in modern VR environments no longer need to “suspend disbelief” to make VR useful. Immersion and interaction are readily achieved by advanced technology which render the simulations and environments so realistic and responsive as to minimize or negate the need for imagination or conscious effort to suspend disbelief (Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001b" title="Robb RA (2001b) Virtual reality in medicine and biology. In: Akay M, Marsh A (eds) Information technologies in medicine: medical simulation and education. Wiley, New York, vol 1, Chap. 1, pp 3–31" href="/article/10.1007/s10055-008-0104-z#ref-CR36" id="ref-link-section-d91735e910">2001b</a>). VR techniques have also evolved to a threefold stratification of types. First, <i>simulated reality</i> which involves an imitation or a model of real objects and procedures. Examples of simulated reality in medicine are virtual endoscopy (Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Robb RA (2000) Virtual endoscopy: development and evaluation using the visible human datasets. Comput Med Imaging Graph 24:133–151" href="/article/10.1007/s10055-008-0104-z#ref-CR34" id="ref-link-section-d91735e916">2000</a>; Satava and Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Satava RM, Robb RA (1997) Virtual endoscopy: applications of 3-D visualization to medical diagnosis. PRESENCE 6(2):179–197" href="/article/10.1007/s10055-008-0104-z#ref-CR49" id="ref-link-section-d91735e919">1997</a>) and virtual surgery planning (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig7">7</a>). The second stratification is <i>augmented reality</i>, which is a fusion of simulated and real-time data. Image-guided surgery and computer-aided interventions are examples of augmented reality (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig8">8</a>). Fully <i>synthetic reality</i> refers to an optimized, totally artificial, yet absolutely faithful, environment and procedures and tools that replace or significantly augment actual procedures.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig7_HTML.jpg?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig7_HTML.jpg" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Virtual endoscopic views within various anatomic structures within the body. Such views can be obtained for any region for the body from rapid 3D volume scans</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig8_HTML.jpg?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig8_HTML.jpg" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Augmented reality wherein live video image of craniotomy (<i>left</i>) are registered and fused with computed 3-D images of tumor and cerebral vessels during neurosurgery. Such visualizations provide useful navigation and tumor targeting, and accurate cytoreduction margins during an operation</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Examples of optimized synthetic reality are telepresence surgery and robot manipulator performers (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig9">9</a>). Implementation of systems using VR technology include planning, rehearsal, and execution phases, and may encompass all three types of VR (Khurana et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999a" title="Khurana VG, Cameron BM, Bates LM, Robb RA (1999a) Virtual frontiers, part 1: fundamental concepts and recent advances in virtual reality technology. In: Fisher III WS (ed) Perspectives in neurological surgery. Thieme Publishing, New York 10(2):113–127" href="/article/10.1007/s10055-008-0104-z#ref-CR17" id="ref-link-section-d91735e981">1999a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Khurana VG, Bates LM, Meyer FB, Robb RA (1999b) Virtual frontiers, part 2: role of virtual reality technology in neurosurgery. In: Fisher III WS (ed) Perspectives in neurological surgery. Thieme Publishing, New York 10(2):113–127" href="/article/10.1007/s10055-008-0104-z#ref-CR18" id="ref-link-section-d91735e984">b</a>) (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig10">10</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig9_HTML.jpg?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig9_HTML.jpg" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Synthetic reality allows surgery to be realistically planned, rehearsed and/or remotely conducted using highly interactive visualization, haptic and robotic controls, such as possible with this two-handed haptic and 3D visualization system (courtesy of Dr. Naoki Suzuki, Jikei University, Tokyo)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig10_HTML.gif?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig10_HTML.gif" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Diagram of steps/phases of computer/image-assisted surgical or clinical procedures, proceeding from preoperative planning on a workstation (<i>top</i>), to rehearsal on patient-specific data using immersive displays and tactile manipulation devices (<i>center</i>), to real-time fusion of actual and virtual objects during execution of the interventional procedure (<i>bottom</i>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Over the past couple of decades a taxonomy of generations of virtual anatomy and functions has evolved, marking at least five generations, as shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-008-0104-z#Tab3">3</a>.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Taxonomy of generations of virtual anatomy and functions</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-008-0104-z/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The first generation of VR anatomy actually started in the 1960s and 1970s, involving 3D geometric shape representation of body and organs and other anatomy. This generation contributed to an early major pitfall in VR, at least in medicine. Wire frame drawings and rigid modules were “neat”, but not really useful. Often oversimplified geometries were used to represent even complex body shapes. To compound the problem, the models were displayed on low-resolution 2D displays. The hype surrounding artificial intelligence and expert systems in the 1960s and 1970s also mislead many who looked to this “new science” to make up for the shortcomings of simplistic biologic models. It was the wrong solution to the wrong problem. The second generation added more sophistication to these models, providing elastic properties, which permitted tissue deformations and kinematics. Initially, this was too crude for medical applications, but these capabilities became sufficiently realistic to be useful in the late 1980s and early 1990s; this was progress. Then physiology and even more complex physical properties were added to the simulations and anatomic models to more accurately depict structure and function, providing realistic and useful visualization of both anatomy and physiology, simultaneously (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig11">11</a>). High resolution, high performance graphic displays, along with true volume rendering, stereoscopic and immersive display formats, significantly advanced the usefulness of these higher order models. More recently, microanatomy models and cellular mechanics simulations have been possible with the advent of 3D microscopic imaging systems in the 1990s (e.g., confocal microscopy and optical coherence tomography). Highly detailed simulations for study of cells and organelles and other microstructures and their functions have been developed (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig12">12</a>). Virtual endoscopic fly-throughs along the conduction pathways can be produced, beginning at the gross anatomy level for spatial context, proceeding to finer and finer resolutions through magnification of field of view, and ending in virtual exploration within single cells; more exciting progress. The future generation, the direction where virtual anatomy and function must eventually go, is to accurately represent in simulations biochemistry and metabolic functions at the molecular level. Such capabilities will permit study and understanding of fundamental biologic processes and systems, such as the endocrine and immune systems. We have not yet reached this stage of sophistication.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig11_HTML.jpg?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig11_HTML.jpg" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Example of fusion and multi-object rendering. Image volume fusion (MR and SPECT) provides a useful visualization for examining the anatomy and function of the brain. In this case, the region of the brain causing epileptic seizures is <i>highlighted</i>
                                    </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig12_HTML.jpg?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig12_HTML.jpg" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Synthesis of cell models into gross anatomic framework. <i>Upper left panel</i> shows gross anatomy of spine and dorsal root at centimeter scale. <i>Upper right panel</i> shows magnified view of synthesized conductance pathway through dorsal root toward mesenteric ganglia. <i>Lower panels</i> show two groups of neurons within ganglia at micrometer scale. The individual neurons are modeled and rendered from confocal microscope data</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Arguably one of the greatest pitfalls experienced by researchers and practitioners in medical VR early in the past decade or so has been the relative isolation of workers in the field, and lack of communication among them. Another pitfall was the false notion, at least originally, that sufficiently realistic simulations without validation could augment medical procedures in ways that would be acceptable to physicians. Much work was done in the early days of medical VR with unrealistic models based on analytical geometry rather than true anatomical geometry, and with artificial textures applied and no physical properties included. Even though such primitive efforts could be expected at the beginning, they were often promoted as useful without validation for way too long, to the detriment of the field. Because of such fallacious efforts, VR in medicine became unfairly stereotyped as “science fiction”; a waste of time in terms of making any positive contribution to the practice of medicine.</p><p>However, as the years have marched on, more and more reports on practical applications and careful evaluations of VR methods and devices in medicine have penetrated the scene. This author believes this has been a good thing, rendering the field more inclusive of clinicians; an important goal that has become marginalized. Scientists and engineers can occupy hours and days sharing their theories and gadgets, but dialog with physicians is eventually essential if these are ever to be useful. Innovative technology and clever ideas are still an important part of the VR research and development, but the applications “promised” for several years are now being delivered; a welcome trend.</p><p>In the early 1990s, computer graphics played a large part in the VR publications, and there were virtually no clinical applications. Presentations consisted largely of innovative VR tools and how they might be used clinically, but no real bridges were built. Descriptions of software packages for producing 3D visualizations and renderings were common. Although the potential was obvious, no “Killer App” had yet emerged in published reports. This lack of a validated, clinically useful application insured that progress toward a realization of the promise of VR in medicine would languish for a period of time, in spite of a continuing stream of “neat new stuff”. In the mid 1990s, a wider variety of VR technologies and approaches began to emerge, and included working systems that showed real promise in clinical applications. For example, surgery training, planning and rehearsal systems, rehabilitation applications and virtual endoscopy were potentially valuable VR-based procedures and tools that were beginning to have a measurable impact on the practice of medicine. “Killer Apps” were on their way. The published themes symbolized the advances in development of VR in medicine that were being made in the field, and many papers were presented with proven VR technology and clinical applications, including immersive displays, haptics, robotics, high precision manipulators, telemedicine, telepathology, virtual biopsy, and augmented reality in the operating room. This trend migrated moderately away from the original theme of cutting edge science only. Again, this author contends this is good, logical and should continue on balance. By the year 2000, papers were appearing on multidimensional approaches, biointelligence, advanced deformations of models, data fusion, realistic mapping of structure and function, all established the meeting again as a forum for exposition of state-of-the-art technology and its promise in medicine. A retrospective look at the field, such as this, also tempts a prospective look at the future of virtual reality in medicine. This overview finds itself in the saddle of these two perspectives (Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002b" title="Robb RA (2002b) Virtual reality in medicine: a personal perspective. J Visualization 5(4):317–326" href="/article/10.1007/s10055-008-0104-z#ref-CR39" id="ref-link-section-d91735e1246">2002b</a>).</p></div></div></section><section aria-labelledby="Sec4"><div class="c-article-section" id="Sec4-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec4">Methods</h2><div class="c-article-section__content" id="Sec4-content"><p>Several common image processing methods needed and used for surgical applications and image-guided interventions are listed in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-008-0104-z#Tab4">4</a>. These include volume rendering, anatomy and pathology segmentation, registration of multi-modality images, synergistic fusion of multimodality images into composite images, anatomic and physiologic models derived from the images and quantitative analysis of the information captured in the images (Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999a" title="Robb RA (1999a) Biomedical imaging, visualization and analysis. Wiley, New York" href="/article/10.1007/s10055-008-0104-z#ref-CR32" id="ref-link-section-d91735e1261">1999a</a>). Several examples of these image processing methods are included in the next several figures.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 Image processing used in image-guided interventions</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-008-0104-z/tables/4"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig13">13</a> illustrates the process of volume image rendering where a stack of scanned raw data or cross sections are rendered into 3D volume images for display on high performance computers (Heffernan and Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1985" title="Heffernan PB, Robb RA (1985) A new method for shaded surface display of biological and medical images. IEEE Transactions on Medical Imaging MI-4:26–38" href="/article/10.1007/s10055-008-0104-z#ref-CR13" id="ref-link-section-d91735e1340">1985</a>; Robb and Barillot <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1989" title="Robb RA, Barillot C (1989) Interactive display and analysis of 3-D medical images. IEEE Transactions on Medical Imaging 8(3):217–226" href="/article/10.1007/s10055-008-0104-z#ref-CR41" id="ref-link-section-d91735e1343">1989</a>; Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999b" title="Robb RA (1999b) Visualization in biomedical computing. Parallel Comput 25:2067–2110" href="/article/10.1007/s10055-008-0104-z#ref-CR33" id="ref-link-section-d91735e1346">1999b</a>). Volume rendering can be performed very rapidly on modern computers, even PCs, using a variety of parameters, including transparency to see through tissues to view the surfaces of interior structures. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig14">14</a> is an example of several volume renderings from a modern CT scanners (helical scan, multi-detector) that show photo-realistic rendering of anatomic tissues.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-13"><figure><figcaption><b id="Fig13" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 13</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/13" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig13_HTML.gif?as=webp"></source><img aria-describedby="figure-13-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig13_HTML.gif" alt="figure13" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-13-desc"><p>Volume image rendering</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/13" data-track-dest="link:Figure13 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-14"><figure><figcaption><b id="Fig14" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 14</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/14" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig14_HTML.gif?as=webp"></source><img aria-describedby="figure-14-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig14_HTML.gif" alt="figure14" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-14-desc"><p>Realistic tissue volume rendering</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/14" data-track-dest="link:Figure14 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig15">15</a> illustrates two types of volume image segmentation: spatial segmentation and feature segmentation (Lepard and Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Lepard KO, Robb RA (1996) Shape-based segmentation and characterization of biomedical images. Proc. SPIE–the international society for optical engineering, vol 2710" href="/article/10.1007/s10055-008-0104-z#ref-CR19" id="ref-link-section-d91735e1395">1996</a>). Spatial segmentation is generally concerned with finding the borders or surfaces of internal anatomic structures and isolating these surfaces from the rest of the dataset for further visualization and analysis. Feature segmentation, (sometimes called tissue typing) uses multimodality images to discriminate similar features in volume images and classify these into common tissue properties that might be representative of normal and abnormal anatomy and/or pathology. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig16">16</a> is an example of volume image registration (Harris and Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Harris SS, Robb RA (2003) Piecewise registration for point-to-surface mapping of cardiac data. Proc. SPIE–Medical Imaging 2003, physiology and function: methods, systems and applications, 5031:146–153." href="/article/10.1007/s10055-008-0104-z#ref-CR12" id="ref-link-section-d91735e1401">2003</a>; Camp and Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Camp J, Robb RA (1999) Realistic visualization for surgery simulation using dynamic volume texture mapping and model deformation. Proc. SPIE–The International Society for Optical Engineering, 3661:24–31" href="/article/10.1007/s10055-008-0104-z#ref-CR9" id="ref-link-section-d91735e1404">1999</a>) of intra-modality (MRI), of inter-modality (MRI, PET) and of preoperative segmented images registered with real images in the procedure room (shown at the lower right).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-15"><figure><figcaption><b id="Fig15" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 15</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/15" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig15_HTML.gif?as=webp"></source><img aria-describedby="figure-15-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig15_HTML.gif" alt="figure15" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-15-desc"><p>Volume image segmentation for spatial anatomy and feature analysis</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/15" data-track-dest="link:Figure15 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-16"><figure><figcaption><b id="Fig16" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 16</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/16" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig16_HTML.gif?as=webp"></source><img aria-describedby="figure-16-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig16_HTML.gif" alt="figure16" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-16-desc"><p>Multimodality image registration</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/16" data-track-dest="link:Figure16 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig17">17</a> illustrates the fusion of multimodality images (Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Robb RA (2005) Image processing for anatomy and physiology: fusion of form and function. Proceedings of sixth annual national forum on biomedical imaging and oncology, NCI/NEMA/DCTD, Bethesda, MD, 7–8 April" href="/article/10.1007/s10055-008-0104-z#ref-CR40" id="ref-link-section-d91735e1450">2005</a>) into a co-registered image. T1 and T2 weighted MRI images and a CT image of the same patient are registered and fused together to create a synergistic “vector image”, as shown in the lower right. Each voxel in the fused image is a vector comprised of the numeric value of the tissue at that point associated with the T1, T2 and CT images, respectively. Volume image fusion can be represented in a variety of ways; in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig10">10</a> each of the three values at one point are mapped into an R-G-B display. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig18">18</a> illustrates another way to display fused images: structure-to-structure (skull and brain from CT and MRI, respectively), structure-to-function (PET imaging of brain metabolism onto the anatomy provided by MRI) and virtual to physical (where, e.g., preoperative MR images obtained and segmented to delineate the tumor and vessel beds, are registered and fused with a real optical image of the patient’s brain during neurosurgery).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-17"><figure><figcaption><b id="Fig17" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 17</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/17" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig17_HTML.jpg?as=webp"></source><img aria-describedby="figure-17-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig17_HTML.jpg" alt="figure17" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-17-desc"><p>Fusion of multimodality images</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/17" data-track-dest="link:Figure17 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-18"><figure><figcaption><b id="Fig18" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 18</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/18" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig18_HTML.gif?as=webp"></source><img aria-describedby="figure-18-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig18_HTML.gif" alt="figure18" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-18-desc"><p>Volume image fusion types</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/18" data-track-dest="link:Figure18 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig19">19</a> illustrates the process of volume modeling using 3D scan images and demonstrates the powerful capability to obtain patient-specific models that are geometrically, texturally and functionally accurate in representing the patient’s anatomy, physiology and pathology (Robb et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Robb RA, Cameron BM, Aharon S (1997) Efficient shape-based algorithms for modeling patient specific anatomy from 3D medical images: applications in virtual endoscopy and surgery. Proceedings of shape modeling and applications, pp 97–108, Aizu-Wakamatsu, Japan, 3–6 March" href="/article/10.1007/s10055-008-0104-z#ref-CR47" id="ref-link-section-d91735e1503">1997</a>; Cameron and Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Cameron BM, Robb RA (2004) Patient-specific dynamic geometric models from sequential volumetric time series image data. Proceedings of medicine meets virtual reality 12. In: Westwood JD, Haluck RS, Hoffman HM, Mogel GT, Phillips R, Robb RA (eds) IOS Press, Amsterdam, Netherlands, 98:40–45" href="/article/10.1007/s10055-008-0104-z#ref-CR7" id="ref-link-section-d91735e1506">2004</a>; Cameron et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Cameron BM, Holmes III, DR, Rettmann ME, Robb RA (2008) Patient specific physical anatomy models. Proc. medicine meets virtual reality 16—parallel, combinatorial, convergent: nextmed by design, In: Westwood JD, Haluck RS, Hoffman HM, Mogel GT, Phillips R, Robb RA, Vosburgh KG (eds) IOS Press, Amsterdam, Netherlands, 132:68–73" href="/article/10.1007/s10055-008-0104-z#ref-CR14" id="ref-link-section-d91735e1509">2008</a>). A variety of functional parameters can be parametrically added to volume anatomy models. These include kinetics, elasticity, electrical, absorption, diffusion, flow, pressure, temperature, viscosity, strain, etc. Such parameters can be mapped onto the anatomy to provide integrated representations of structure and function of any region of the body for which anatomical and functional data are captured. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig20">20</a> indicates that such models are truly possible and can be 3D, 4D or 5D in extent (Lin and Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Lin W, Robb RA (2000) A 5-D model for accurate representation and visualization of dynamic cardiac structures. Proc. SPIE–Biomedical Diagnostic, Guidance, and Surgical Assist Systems II, 3911:322–329 " href="/article/10.1007/s10055-008-0104-z#ref-CR20" id="ref-link-section-d91735e1516">2000</a>). The upper figure illustrates CT scan data rendered for virtual colonoscopy. An inset shows a polyp with blood-filled microvessels texture-mapped onto the luminal surface of the colon. This illustrates micro-vascularity and blood pools that might indicate metastatic potential of the polyp. The lower image is one frame from a 3D beating heart, i.e., a 4D model. The inset shows the mapping of electrophysiology data recorded during the cardiac cycle onto the left ventricular endocardial surface, essentially rendering this as a 5D model.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-19"><figure><figcaption><b id="Fig19" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 19</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/19" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig19_HTML.jpg?as=webp"></source><img aria-describedby="figure-19-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig19_HTML.jpg" alt="figure19" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-19-desc"><p>Patient-specific volume image modeling (<i>top images</i> courtesy of Professor Naoki Suzuki)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/19" data-track-dest="link:Figure19 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-20"><figure><figcaption><b id="Fig20" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 20</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/20" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig20_HTML.gif?as=webp"></source><img aria-describedby="figure-20-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig20_HTML.gif" alt="figure20" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-20-desc"><p>Three, four and five dimensional anatomy/function models</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/20" data-track-dest="link:Figure20 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Often the most important purpose of volume imaging and volume modeling is to make accurate and useful measurements (Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999a" title="Robb RA (1999a) Biomedical imaging, visualization and analysis. Wiley, New York" href="/article/10.1007/s10055-008-0104-z#ref-CR32" id="ref-link-section-d91735e1562">1999a</a>; Rajagopalan and Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Rajagopalan S, Robb RA (2006) Fourier-domain based datacentric performance ranking of competing medical image processing algorithms. Proc. SPIE–medical imaging 2006, San Diego, CA, 11–16 February" href="/article/10.1007/s10055-008-0104-z#ref-CR23" id="ref-link-section-d91735e1565">2006</a>). Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig21">21</a> shows (upper left and right) quantitative analysis of volume images in preoperative planning for repair of a brain aneurysm and for resection of a brain tumor delicately located in the language and motor control regions of the brain. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig14">14</a> also illustrates parametric mapping of lung parenchyma motion (bottom left) throughout the respiratory cycle to quantitatively describe the effect of diffuse lung disease on normal lung motion. Finally, from virtual colonoscopy, the size and vascularity of polyps in the colon can be determined and used to stage diagnosis and therapy in colon cancer. These important image processing, visualization and analysis methods are applied to multidimensional, multispectral images to provide advanced, heretofore impossible, applications in medical procedures and surgical interactions.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-21"><figure><figcaption><b id="Fig21" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 21</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/21" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig21_HTML.jpg?as=webp"></source><img aria-describedby="figure-21-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig21_HTML.jpg" alt="figure21" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-21-desc"><p>Volume image analysis for quantitative measurement in 3D</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/21" data-track-dest="link:Figure21 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     </div></div></section><section aria-labelledby="Sec5"><div class="c-article-section" id="Sec5-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec5">Results (real applications)</h2><div class="c-article-section__content" id="Sec5-content"><p>The following examples of clinical applications of multidimensional, multispectral image fusion and visualization in image-guided interventions will be illustrated:</p><ul class="u-list-style-bullet">
                  <li>
                    <p>Craniofacial surgery</p>
                  </li>
                  <li>
                    <p>Neurosurgery</p>
                  </li>
                  <li>
                    <p>Therapy planning and response assessment</p>
                  </li>
                  <li>
                    <p>Sinus surgery</p>
                  </li>
                  <li>
                    <p>Orthopedic surgery</p>
                  </li>
                  <li>
                    <p>Detection, quantification and assessment of pulmonary disease</p>
                  </li>
                  <li>
                    <p>Virtual colonoscopy</p>
                  </li>
                  <li>
                    <p>Prostate cancer brachytherapy</p>
                  </li>
                  <li>
                    <p>Treatment of cardiac arrhythmias</p>
                  </li>
                  <li>
                    <p>Segmentation of conjoined twins</p>
                  </li>
                </ul>
                     <p>Craniofacial surgeons were early adopters of 3D imaging (Robb et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Robb RA, Hanson DP, Camp JJ (1996) Computer-aided surgery planning and rehearsal at Mayo Clinic. Computer 29(1):39–47" href="/article/10.1007/s10055-008-0104-z#ref-CR46" id="ref-link-section-d91735e1657">1996</a>). Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig22">22</a> illustrates the use of 3D CT scanning to repair a facial fracture by using mirror imaging to design a patient-specific implant to fill the fracture void. The implant size and shape are completely modeled on the image workstation and the model parameters sent to a milling machine to produce the prosthesis. The implant is then taken into the operating room and placed into the patient. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig23">23</a> illustrates another early example of use of 3D imaging where CT and MR 3D scans of the brain of a patient with brain cancer are registered and fused and used to preoperatively plan the approach and margins for resection of a deep-seated brain tumor (Robb and Hanson <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Robb RA, Hanson DP (1995) The ANALYZETM software system for visualization and analysis in surgery simulation. In: Lavallée S, Taylor R, Burdea G, Mösges R (eds) Computer integrated surgery. MIT Press, Cambridge, pp 175–190" href="/article/10.1007/s10055-008-0104-z#ref-CR42" id="ref-link-section-d91735e1666">1995</a>). Furthermore, these preoperative scans can be registered to the physical patient during the surgery to facilitate navigation during the operation and to provide visualization of the actual patient’s anatomy combined with the preoperative underlying anatomy, including the tumor and adjacent blood vessels.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-22"><figure><figcaption><b id="Fig22" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 22</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/22" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig22_HTML.gif?as=webp"></source><img aria-describedby="figure-22-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig22_HTML.gif" alt="figure22" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-22-desc"><p>Image-guided craniofacial surgery</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/22" data-track-dest="link:Figure22 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-23"><figure><figcaption><b id="Fig23" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 23</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/23" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig23_HTML.gif?as=webp"></source><img aria-describedby="figure-23-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig23_HTML.gif" alt="figure23" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-23-desc"><p>Image-guided neurosurgery for removal of brain tumor</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/23" data-track-dest="link:Figure23 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig24">24</a> illustrates a more recent example of advanced image processing to provide image-guided neurosurgery for treatment of severe epilepsy (Brinkmann et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Brinkmann BJ, Robb RA, O’Brien TJ, Sharbough FW (1997) Localization, correlation, and visualization of electroencephalographic surface electrodes and brain anatomy in epilepsy studies. Proc. SPIE–The International Society for Optical Engineering 3033:159–169" href="/article/10.1007/s10055-008-0104-z#ref-CR3" id="ref-link-section-d91735e1712">1997</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Brinkmann BH, Robb RA, O’Brien TJ, O’Connor MK, Mullan BP (1998) Multimodality imaging for epilepsy diagnosis and surgical focus localization: three-dimensional image correlation and dual isotope SPECT. Proc. of medical image computing and computer-assisted intervention–MICCAI 1998, Cambridge, MA, 1496:1087–1098" href="/article/10.1007/s10055-008-0104-z#ref-CR4" id="ref-link-section-d91735e1715">1998</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Brinkmann BH, O’Brien TJ, Aharon S, O’Connor MK, Mullan BP, Hanson DP, Robb RA (1999) Quantitative and clinical analysis of SPECT image registration for epilepsy studies. J Nucl Med 40(7):1098–1105" href="/article/10.1007/s10055-008-0104-z#ref-CR5" id="ref-link-section-d91735e1718">1999</a>). Unlike a brain tumor, the focus of epileptic disease in the brain cannot be visualized using conventional CT, MR, PET or any other type of medical imaging. However, since the brain excitation can be tagged by nuclear imaging, a procedure was developed by our laboratory to show the region of the brain causing the epileptic seizure. The technique is called SISCOM for “Subtraction Inter-ictal SPECT Co-Registered MRI”. It essentially consists of a SPECT volume scan of the patient’s brain before and just after a seizure (bottom left). These two images are registered and subtracted, highlighting the focal nidus of the seizure in the difference image (top left). But this does not reveal the target in the context of the brain anatomy, so an MRI scan of the patient’s brain is also conducted, and the SPECT difference image is registered and fused with the MRI scan to show the exact anatomic location of the seizure focus (top center and right). This then can be used as a guide for navigating surgically to the region of cortical tissue in the brain to be removed to eliminate the seizure activity (bottom right). This technique is currently used routinely at Mayo Clinic and other large medical centers and is very effective in improving outcomes, reduced procedure times with less morbidity and at lower cost. The method is a significant advance in the treatment of debilitating epilepsy when medications and other forms of treatment simply do not work.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-24"><figure><figcaption><b id="Fig24" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 24</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/24" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig24_HTML.jpg?as=webp"></source><img aria-describedby="figure-24-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig24_HTML.jpg" alt="figure24" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-24-desc"><p>Image-guided neurosurgery for treatment of epilepsy</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/24" data-track-dest="link:Figure24 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig25">25</a> illustrates the application of multidimensional imaging to therapy planning and monitoring (Wu et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Wu QR, Bourland JD, Robb RA (1996) Morphology guided radiotherapy treatment planning and optimization. Proc. SPIE–The International Society for Optical Engineering, 2707:180–189" href="/article/10.1007/s10055-008-0104-z#ref-CR51" id="ref-link-section-d91735e1745">1996</a>). Such therapy might be radiation and/or pharmaceutical treatment for tumors in the body. Multidimensional CT, MR and PET imaging can be fused together showing anatomy and functional take-up of radiotracers to identify tumors and mark progress in tumor reduction throughout the course of treatment. Such imaging can be accurate enough to guide dose painting, that is, to provide radiation selectively to the most sensitive regions and to avoid radiation to adjacent critical structures, thus maximizing the overall effectiveness of treatment. Measuring volumes and contouring shapes of tumors that can be obtained from fused MRI, CT and molecular imaging scans can also be used to assess the quality of treatment and to optimally modify dosage during the treatment. Another application of image guidance in surgical procedures is illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig26">26</a>. This figure illustrates a head CT scan of a patient who is undergoing an uncinectomy for removal of tissue blocking sinus passages. The resolution of high resolution CT scans is sufficient to very accurately pre-plan and guide the resection of these tissues during the surgical process.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-25"><figure><figcaption><b id="Fig25" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 25</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/25" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig25_HTML.gif?as=webp"></source><img aria-describedby="figure-25-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig25_HTML.gif" alt="figure25" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-25-desc"><p>Image-guided therapy planning and treatment response assessment</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/25" data-track-dest="link:Figure25 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-26"><figure><figcaption><b id="Fig26" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 26</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/26" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig26_HTML.jpg?as=webp"></source><img aria-describedby="figure-26-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig26_HTML.jpg" alt="figure26" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-26-desc"><p>Image-guided sinus surgery</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/26" data-track-dest="link:Figure26 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig27">27</a> illustrates applications of multidimensional volume imaging in orthopedic surgery (Melton et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Melton LJIII, Riggs BL, Keaveny TM, Achenbach SJ, Hoffman PF, Camp JJ, Rouleau PA, Bouxsein ML, Amin S, Atkinson EJ, Robb RA, Khosla S (2007) Structural determinants of vertebral fracture risk. J Bone Miner Res 22(12):1885–1892" href="/article/10.1007/s10055-008-0104-z#ref-CR21" id="ref-link-section-d91735e1794">2007</a>; Augustine et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Augustine KE, Huddleston PM, Holmes III DR, Shridharanni SM, Robb RA (2008) Optimization of spine surgery planning with 3D image templating tools. Proc. SPIE–Medical Imaging 2008, San Diego, CA, 16–21 February" href="/article/10.1007/s10055-008-0104-z#ref-CR2" id="ref-link-section-d91735e1797">2008</a>). Preoperative full volume CT scans can be used to plan spinal surgery, including precise insertion of pedicle screws into diseased or damaged vertebral bodies. Volume image scanning of the pelvic region can be used to guide implantation of joint prostheses using digital templates, registered and matched to the patient’s anatomy. Visualization of bones, blood vessels, soft tissues, all selectively chosen to highlight regions of interest, can be used to assess trauma and fractures to help plan orthopedic repair. Such repair can also be guided by images during the operative phase. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig28">28</a> illustrates several applications of volume imaging in assessment and quantitative treatment of pulmonary diseases. Parametric mapping of classified tissues in segmented lung volumes can be used to define the location, extent and distribution of diffuse diseases like emphysema (Haider et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Haider CR, Bartholmai BJ, Holmes III DR, Camp JJ, Robb RA (2005) Quantitative characterization of lung disease. Comput Med Imaging Graph 29(7):555–563" href="/article/10.1007/s10055-008-0104-z#ref-CR11" id="ref-link-section-d91735e1803">2005</a>; Zavaletta et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Zavaletta VA, Bartholmai BJ, Robb RA (2007) High resolution multi-detector CT aided tissue analysis and quantification of lung fibrosis. Acad Radiol 14:772–787" href="/article/10.1007/s10055-008-0104-z#ref-CR52" id="ref-link-section-d91735e1807">2007</a>). Individual solitary nodules in the lungs can be imaged and their immediate environment segmented to study vascular adjacency to help determine if surgery would be safe or if radiation treatment would be more effective in order not to inadvertently damage blood supply to critical adjacent tissue. Virtual bronchoscopy can be performed from volume CT scans of the chest, looking for lesions, abnormalities and associated structures, even outside of the bronchial tree, in either a screening mode or a preoperative planning mode.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-27"><figure><figcaption><b id="Fig27" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 27</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/27" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig27_HTML.gif?as=webp"></source><img aria-describedby="figure-27-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig27_HTML.gif" alt="figure27" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-27-desc"><p>Image-guided orthopedic surgery</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/27" data-track-dest="link:Figure27 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-28"><figure><figcaption><b id="Fig28" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 28</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/28" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig28_HTML.jpg?as=webp"></source><img aria-describedby="figure-28-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig28_HTML.jpg" alt="figure28" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-28-desc"><p>Volume imaging and analysis in pulmonary diseases</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/28" data-track-dest="link:Figure28 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig29">29</a> illustrates use of virtual endoscopy visualizing the colon for lesions and polyps (Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001a" title="Robb RA (2001a) The biomedical imaging resource at mayo clinic. IEEE TMI 20(9):854–867" href="/article/10.1007/s10055-008-0104-z#ref-CR35" id="ref-link-section-d91735e1852">2001a</a>). High resolution volume CT scans can be segmented, and the entire large bowel viewed in 3D to detect polyps or other abnormalities. These structures can be measured for size and shape characteristics. Tissue texture analysis can be applied to such scans to assess the vascularity of such polyps to help determine their metastatic potential. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig30">30</a> illustrates an example of image guidance in treatment of prostate cancer via brachytherapy. In this procedure, radioactive seeds are placed into the prostate gland in an attempt to irradiate and kill the cancer cells, but to spare the normal prostate tissues. This is clearly a guidance and localization problem, and we have developed a new transurethral ultrasound (TUUS) device to image the radioactive seeds with high resolution and reconstruct them in 3D from the registered fluoroscopic and ultrasound images (Holmes and Robb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Holmes III DR, Robb RA (2000) Trans-urethral ultrasound (TUUS) imaging for visualization and analysis of the prostate and associated tissues. Proc. SPIE–medical imaging 2000: image display and visualization 3976:22–27" href="/article/10.1007/s10055-008-0104-z#ref-CR16" id="ref-link-section-d91735e1858">2000</a>; Su et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Su Y, Davis BJ, Furutani KM, Herman MG, Robb RA (2007) Seed localization and TRUS-fluoroscopy fusion for intraoperative prostate brachytherapy dosimetry. Comput Aided Surg 12(1):25–34" href="/article/10.1007/s10055-008-0104-z#ref-CR50" id="ref-link-section-d91735e1861">2007</a>). The reconstruction can indicate hot or cold spots in the prostate that can be rectified during the procedure. 3D dosimetry can be calculated and compared with the preoperative plan. This online dosimetry is possible because of the accurate reconstruction of the seeds using TUUS, and eliminates the need to move the patient for a CT scan to estimate the dose distribution and validate the plan.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-29"><figure><figcaption><b id="Fig29" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 29</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/29" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig29_HTML.gif?as=webp"></source><img aria-describedby="figure-29-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig29_HTML.gif" alt="figure29" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-29-desc"><p>Image-guided (virtual) colonoscopy</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/29" data-track-dest="link:Figure29 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-30"><figure><figcaption><b id="Fig30" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 30</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/30" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig30_HTML.jpg?as=webp"></source><img aria-describedby="figure-30-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig30_HTML.jpg" alt="figure30" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-30-desc"><p>Image-guided prostate cancer brachytherapy for intra-operative dosimetry</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/30" data-track-dest="link:Figure30 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>An example of a true 5D image-guided treatment application will next be described and illustrated in some detail (Packer et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Packer DL, Asirvatham S, Seward JB, Breen JF, Robb RA (2004) Imaging of the cardiac and thoracic veins. Chap. 8. In: Chen, Haissaguerre, Zipes (eds) Thoracic vein arrhythmias: mechanisms and treatments. Prepress Projects, Ltd., Scotland" href="/article/10.1007/s10055-008-0104-z#ref-CR22" id="ref-link-section-d91735e1904">2004</a>; Rettmann et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Rettmann ME, Holmes III DR, Su Y, Cameron BM, Packer DL, Robb RA (2006) An integrated system for real-time image guided cardiac catheter ablation. Proc. medicine meets virtual reality 14. In:Westwood JD, Haluck RS, Hoffmann HM, Mogel GT, Phillips R, Robb RA, Vosburgh KG (eds) IOS Press, Amsterdam, Netherlands, 119:455–460" href="/article/10.1007/s10055-008-0104-z#ref-CR24" id="ref-link-section-d91735e1907">2006</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Rettmann ME, Holmes III DR, Camp JJ, Packer DL, Robb RA (2008) Validation of semi-automatic segmentation of the left atrium. Proc. SPIE–medical imaging 2008, San Diego, CA, 16–21 February" href="/article/10.1007/s10055-008-0104-z#ref-CR25" id="ref-link-section-d91735e1910">2008</a>; Holmes III et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Holmes III DR, Rettmann M, Cameron B, Camp J, Robb RA (2008) Developing patient-specific anatomic models for validation of cardiac ablation guidance procedures. Proc. SPIE–Medical Imaging 2008, San Diego, California, February 16–21" href="/article/10.1007/s10055-008-0104-z#ref-CR15" id="ref-link-section-d91735e1913">2008</a>). This application involves most of the important image processing methods and VR technology required to make dynamic volume images truly useful in image-guided intervention. In this example, the disease is cardiac arrhythmias, with particular focus on atrial fibrillation. In atrial fibrillation (AF), the atria of the heart beat rapidly, irregularly and spontaneously. This is a common disease, especially in the elderly, which may be life threatening. Over 5% of the population over 60 years of age suffers from AF, and the incidence is increasing. AF often does not respond to medication or pacemakers. When pharmacologic and pacemaking treatment is not effective, open heart surgery is sometimes considered and can be highly effective, but it is costly, has high risk and morbidity, and requires extended hospital time. For these reasons it is often considered a last option. Cardiac catheter ablation procedures have become the primary initial choice of therapy in AF. In this technique, RF energy is delivered via catheter to regions of the endocardial surface to produce lesions intended to block aberrant electrical pathways causing the arrhythmia. The primary problem in catheter-based cardiac ablation is accurate navigation and localization. What is needed is the capability to visualize the catheter position, the 3D intra-cardiac anatomy and fused regional electrophysiologic function, all accurately registered together in real time during the procedure. Such an approach requires a 5D system that integrates and fuses the multiple signals and displays them in real time for precise guidance during the procedure.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig31">31</a> shows the conceptual design for a 5D system that integrates all of the anatomy and functional information in real time during a cardiac ablation procedure to guide the cardiologist to exactly localize and ablate the offending tissue. Central to the concept is a 5D model of the patient-specific heart used to guide the procedure. A prototype system has been developed based on distributed data processing by multiple servers and database-driven queuing to realize real-time signal synchronization and integration. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig32">32</a> shows the flow of system operations and processing that integrates the dynamic display of real cardiac function mapped onto real cardiac anatomy to guide the catheter ablation in real time. This involves preoperative image collection of the volume containing the heart with a high resolution, high-speed CT scanner, followed by anatomic segmentation of the cardiac chambers of interest, primarily the left atrium. Electrophysiological recordings are mapped onto this segmented anatomy through a process of registration and fusion. This provides the data for a 5D cardiac model that shows the moving anatomy throughout the cardiac cycle as well as the dynamic distribution of electrical activity on the surface. During the cardiac cycle, this model serves as the prime visualization for intra-operative guidance, including intra-operative imaging (e.g., ultrasound). That is, the dynamic model precisely guides the cardiologist via the 5D cardiac model to the location causing the arrhythmia, and the intra-operative imaging shows the ablation catheter in 3D relationship to the target for accurate ablation.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-31"><figure><figcaption><b id="Fig31" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 31</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/31" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig31_HTML.gif?as=webp"></source><img aria-describedby="figure-31-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig31_HTML.gif" alt="figure31" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-31-desc"><p>Conceptual design of “5DEP” image-guided cardiac ablation system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/31" data-track-dest="link:Figure31 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-32"><figure><figcaption><b id="Fig32" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 32</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/32" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig32_HTML.gif?as=webp"></source><img aria-describedby="figure-32-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig32_HTML.gif" alt="figure32" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-32-desc"><p>5DEP system procedure flow</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/32" data-track-dest="link:Figure32 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The required registration and mapping is done throughout the cardiac cycle, providing a 5D cardiac model, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig33">33</a>. The dynamic electrophysiology patterns are mapped onto the chamber walls and these mappings can dynamically reveal activation patterns of contraction. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig34">34</a> illustrates intra-operative imaging. The dynamic ultrasound images are registered to the anatomic model and to the electrophysiology map, providing dynamic visualization of catheter location relative to the endocardial surfaces during the procedure.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-33"><figure><figcaption><b id="Fig33" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 33</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/33" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig33_HTML.gif?as=webp"></source><img aria-describedby="figure-33-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig33_HTML.gif" alt="figure33" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-33-desc"><p>5D cardiac models showing anatomy, and electrophysiology mapping throughout the cardiac cycle</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/33" data-track-dest="link:Figure33 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-34"><figure><figcaption><b id="Fig34" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 34</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/34" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig34_HTML.gif?as=webp"></source><img aria-describedby="figure-34-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig34_HTML.gif" alt="figure34" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-34-desc"><p>Intra-operative imaging with ultrasound registered to CT model</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/34" data-track-dest="link:Figure34 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Using virtual cardioscopy, as illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig35">35</a>, the cardiologist can navigate the ablation catheter directly to the offending location of the arrhythmia with much greater precision than with fluoroscopy. Using the fused anatomy/function image (i.e., the 5D model), the cardiologist can ablate exactly the tissue target, and watch the electrophysiological pattern return to normal sinus rhythm, indicating that the ablation has been successful. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig36">36</a> illustrates the graphical user interface of the system. This is a real-time update interface so that dynamic visualization of the beating heart 5D model, navigation of the ablating catheter, and pointing of the catheter exactly at the target can all be integrated and visualized in real time.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-35"><figure><figcaption><b id="Fig35" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 35</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/35" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig35_HTML.gif?as=webp"></source><img aria-describedby="figure-35-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig35_HTML.gif" alt="figure35" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-35-desc"><p>Ablation guidance using virtual cardioscopic display of 5D model</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/35" data-track-dest="link:Figure35 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-36"><figure><figcaption><b id="Fig36" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 36</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/36" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig36_HTML.gif?as=webp"></source><img aria-describedby="figure-36-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig36_HTML.gif" alt="figure36" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-36-desc"><p>Interactive visualization of real-time cardiac model, EP point mapping and catheter tracking</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/36" data-track-dest="link:Figure36 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig37">37</a> shows the overall prototype 5DEP system. The 5DEP computer and interface is shown in the middle and the electrophysiological mapping system shown on either side of this 5D image-guided cardiac ablation system.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-37"><figure><figcaption><b id="Fig37" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 37</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/37" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig37_HTML.gif?as=webp"></source><img aria-describedby="figure-37-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig37_HTML.gif" alt="figure37" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-37-desc"><p>Prototype 5DEP image-guided cardiac ablation system developed at Mayo Clinic</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/37" data-track-dest="link:Figure37 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>A recent case of conjoined twins at the Mayo Clinic involved twin girls joined from the chest to the abdomen. Several organs were fused and/or tangled together, including the pancreases, livers and intestines. The two hearts were overlapping and out of normal position. Of particular concern was the shared blood supply to the joint liver, as well as a shared common bile duct. Comprehensive imaging studies were conducted to provide details of anatomic structures as well as perfusion of the blood supply to the liver. A joint contrast-enhanced CT scan, where the babies were simultaneously injected with the contrast agent, helped delineate regions of the liver that were separately and jointly perfused. CT cholangiography was performed for visualization of the gall bladders, livers, and bile ducts. Anatomic structures were segmented from the imaging studies, spatially registered and fused to create comprehensive 3D anatomic and functional visualizations. The top left panel in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig38">38</a> illustrates both skeletal structures, the two hearts (red and blue), the joined liver (dark red), entangled intestines (yellow), and gall bladders (green). Each heart, along with the associated vessels, was segmented from the individual contrast-enhanced CT scans. The liver and gall bladders are produced from the cholangiogram, and the intestines and bony structures came from the dual-injection CT scan. All segmented anatomy from the different imaging procedures was registered to a single volume to create this combined display.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-38"><figure><figcaption><b id="Fig38" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 38</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/38" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig38_HTML.jpg?as=webp"></source><img aria-describedby="figure-38-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0104-z/MediaObjects/10055_2008_104_Fig38_HTML.jpg" alt="figure38" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-38-desc"><p><i>Top left</i> Segmented 3D anatomic structures of conjoined twins. Shown are two hearts (<i>red and blue</i>), the liver (<i>dark red</i>), intestines (<i>yellow</i>), two gall bladders (<i>green</i>). <i>Top right</i> detailed view of blood vessel supply to liver. <i>Bottom left</i> perfusion map of liver, blood supply from one baby in <i>red</i>, other baby in <i>blue</i>, joint perfusion in <i>yellow</i>. <i>Bottom right</i> photograph of life-size physical model of liver produced from 3D CT segmentation</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0104-z/figures/38" data-track-dest="link:Figure38 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The top right panel of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0104-z#Fig38">38</a> shows a more detailed view of the liver with the combined blood supply, where the vessels from one baby are colored in red and the vessels from the other baby are blue. The gall bladders and ducts of the biliary system (in green) can also be clearly seen. A major objective of the surgical planning was to determine optimal bisection of the joint liver. The bottom left panel is a perfusion map of the liver where red indicates regions of the liver perfused by one baby, blue indicates regions perfused by the other baby, and yellow represents regions perfused by both babies. This jointly perfused region provided an essential guide for dividing the liver to provide each baby with a viable organ. In order to provide additional visualization aids to the surgeons, life-size physical models were constructed of select anatomy from the 3D segmented data. A photograph of the physical model of the liver is shown in the bottom right panel. These visualizations and physical models were utilized primarily in the preplanning phases; however, it is entirely feasible to incorporate them into the surgical procedure for guidance.</p></div></div></section><section aria-labelledby="Sec6"><div class="c-article-section" id="Sec6-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec6">Discussion</h2><div class="c-article-section__content" id="Sec6-content"><p>The applications illustrated in the last section indicate the rapid progress and powerful potential of using multimodality fused images and VR technology in diagnosing and treating disease, including navigating accurately in surgical operations and for guiding medical procedures for more accurate, timely and safe interventions. However, there are some continuing barriers to progress which are summarized and discussed in the next several tables.</p><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-008-0104-z#Tab5">5</a> indicates three major barriers to progress: standards, technology and validation.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 Some barriers to progress</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-008-0104-z/tables/5"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-008-0104-z#Tab6">6</a> addresses the importance of standards in software, hardware and data. The more reliable and open these standards are, and the more we can migrate to plug-and-play interfaces to incorporate new technologies rapidly, keeping latency low so as not to interfere with timing and precision of medical procedures, and to share data ubiquitously across the software/hardware platforms, then real advances are going to take place rapidly in image-guided interventions. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-008-0104-z#Tab6">6</a> also suggests that it’s critical not to neglect the importance of the user interface that manages these technologies and capabilities and connects the intuitively to the practitioner.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-6"><figure><figcaption class="c-article-table__figcaption"><b id="Tab6" data-test="table-caption">Table 6 Software, hardware and data standards needed</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-008-0104-z/tables/6"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-008-0104-z#Tab7">7</a> summarizes the needs for continuing improvements in technology performance, including resolution, interactivity, processing, and management. This includes continuous improvement in resolution and performance of image acquisition devices and data processing algorithms. In particular, improved capabilities for data management, better tools, and more comprehensive databases are required, as the medical datasets being generated by modern medical scanners are becoming much larger.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-7"><figure><figcaption class="c-article-table__figcaption"><b id="Tab7" data-test="table-caption">Table 7 Technology improvement needed</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-008-0104-z/tables/7"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>A significant contributor to pitfalls and progress in medical VR over the last decade has been developments (or not) in medical imaging. The field of medical imaging enjoyed continued improvements in resolution, speed and differential clinical applications in the past 20 years. However, issues of image latency, interactivity, and validation have proven challenging. The speed of image acquisition and computation has almost followed Moore’s Law (doubling of performance/output every 18 months) over the last decade. The amount of detail that can now be presented at interactive rates, even near real-time rates, is several-fold higher than available in 1990. There has been similar improvement in the photo-realistic quality of the images used in simulations and augmented reality scenarios and in the sensory responsiveness and interactivity of the systems. Even so, this increase does not obey Moore’s formula. Improvement has often been slow and fraught with difficulties. Similarly, although there has been great progress in data processing, e.g., multimodality registration, volume rendering, and quantitative measurement, image segmentation and classification is still the Achilles heel in achieving practical routine use of medical images. Even though medical images have improved significantly in quality, they are still relatively “noisy” in terms of absolute and reproducible quantitative representation of bodily tissue properties, making methods for automatic, rapid and reproducible segmentation of desired features from medical image scans very difficult. There are some niche successes for certain algorithms, modalities and tissue types, but the “Killer App” in image segmentation has yet to be developed. When it is, Moore’s Law may well be applicable to the rate of progress that will ensue.</p><p>What is needed to avoid some of the pitfalls and blind alleys that have occurred in the past is a concerted effort on due diligence. The needs and requirements for augmenting or replacing certain clinical tasks with virtual reality technology needs more attention. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-008-0104-z#Tab8">8</a> summarizes some needs and requirements for successful translation of new technology to routine applications of clinical procedures based on new technology.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-8"><figure><figcaption class="c-article-table__figcaption"><b id="Tab8" data-test="table-caption">Table 8 Needs and requirements for successful transfer of new technology to routine clinical practice</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-008-0104-z/tables/8"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Proposed new methods should be based on real clinical needs and align with the expectations of physicians. The method(s) should be relevant to problems without satisfactory current solutions and that have distinct promise to improve outcomes. Safety of the equipment and procedures needs to be documented and demonstrated. Reliability, accuracy, ease of use, modularity, and versatility of the method or procedure are all important factors to consider and document. Lack of comprehensive software toolkits for rapid prototyping and testing of VR methods, procedures and devices has impeded progress. Conversely, recent availability of such resources has significantly empowered the field and moved it forward. One must consider several practical issues commonly associated with new methodology, including the training of new users and the maintenance of new systems and/or devices. Conformance to existing standards or development of new standards is often crucial to success. Standards in VR have been slow to develop, but emerging conventions (e.g., VRML) are promising. Validation and evaluation are critical, as is careful assessment of cost versus benefit. Without question, one of the greatest pitfalls and inhibitors to reduction to practice and routine use of new methods and technologies involving imaging and virtual reality in medicine has been the lack of adequate scientific and clinical validation. The general approach to validation that scientists routinely take is a necessary but not sufficient first step, involving a sequence of mathematical simulations, phantom studies and testing on synthetic data derived from real data. Such evaluation can quantitatively characterize the performance and error margins of a new method. Such results should then be compared to ground truth or gold standards, if available, and multiple trials and comparisons conducted with existing standard methods targeted for replacement.</p><p>In addition to this scientific validation, scientists must interact with physicians who are expert in the specific clinical application, and consider an additional set of both objective and subjective factors for evaluating new methods. These are indicated in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-008-0104-z#Tab9">9</a>.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-9"><figure><figcaption class="c-article-table__figcaption"><b id="Tab9" data-test="table-caption">Table 9 Considerations for validating new technology for clinical applications</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-008-0104-z/tables/9"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The last item in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-008-0104-z#Tab9">9</a>, exclusivity value, involves determination of absolutely unique feature(s) of a new method that has compelling merit, i.e., no other method can produce the useful measure or effect. In such cases, efforts to get the new method into routine use should be greatly accelerated.</p><p>Current and future VR medical research will continue to focus in four main areas: (1) devices and instrumentation, (2) algorithm development, (3) modeling and simulation and (4) application prototyping. Many projects that have been initiated in the last decade will continue into the next decade, including virtual surgery, virtual endoscopy, image-guided diagnosis and treatment, virtual histology and pathology, robotics, manipulations, telepresence, performance assessment, etc. These are predicted to have an ever-increasing positive impact on medicine and healthcare. We will move toward the future successfully the same as we have done in the past, through a synergistic combination of ideas and tools. Ideas alone are not worth much. Tools that have not been based on good ideas are not worth much. But good ideas and good tools together are the key to future success, and what a bright future it is. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-008-0104-z#Tab10">10</a> indicates some of the developments that can be expected in the upcoming decade or two; progress toward realizing fully non-invasive real-time diagnosis and treatment made possible through VR-related technologies.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-10"><figure><figcaption class="c-article-table__figcaption"><b id="Tab10" data-test="table-caption">Table 10 Future technology for minimally-invasive, real-time, synchronous diagnosis and treatment</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-008-0104-z/tables/10"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Multidimensional dynamic displays, image gloves for hands-free navigation in virtual space, and voice control will epitomize next generation MR and greatly enhance medical procedures. Intelligent rooms and clothing that perform real-time tracking and monitoring will provide comprehensive and instantaneous input for informed, even automated, decision making. Special high precision robots remotely controllable will establish for good telemedicine and teletherapy. Moore’s law will continue to apply to computers through at least the next decade, although an asymptote in computational performance may be approached within the next couple of decades (not really, DNA computers will maintain the slope!). Real-time model generation capabilities and programming computers in natural language will be possible, and super computers will, in fact, be micro- or even nano-computers, and used both outside and inside the body. Intelligent diagnostic and/or therapeutic probes will be introduced into the body and either pre-programmed or externally controlled to proceed to the anatomic site of interest; “seek and destroy” nanobots! Eventually, we will have the kind of totally non-invasive real-time technology that we only see in Star Wars and Star Trek movies, devices that simultaneously perform diagnosis and treatment, sort of “one-stop shopping” healthcare. Satava’s “Door to the Future” (Robb et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1974" title="Robb RA, Greenleaf JF, Ritman EL, Johnson SA, Sjostrand JD, Herman GT, Wood EH (1974) Three-dimensional visualization of the intact thorax and contents: a technique for cross-sectional reconstruction from multiplanar X-ray views. Comput Biomed Res 7:395–419" href="/article/10.1007/s10055-008-0104-z#ref-CR44" id="ref-link-section-d91735e2828">1974</a>) may be such a device, but this author believes it will be a collection of devices much smaller than a door, more like highly-tuned transmitters-receivers the size of flashlights.</p><p>There will be a continuum in development of real-time, minimally-invasive and non-invasive technologies that will provide synchronous diagnosis and treatment of disease. New imaging modalities will evolve, especially at the molecular and biochemical levels that will dramatically improve and impact the use of images in the diagnosis and treatment of disease. More intelligent instruments and robots will be developed, such as nanobots that will explore the body in intelligent ways to find disease, to treat it, and monitor treatment for a time before establishing a cure and moving on. Smarter apparel and operating rooms with full body sensing and tool tracking will become commonplace. Computers will become more powerful and even smaller, and we will be able to speak to them in natural language, receiving real-time response to our requests and commands. Ultimately, there will be a seamless, real-time integration and fusion of structure and function ranging in scale from macro- to micro-resolutions all through the body. Such fusions are going to provide powerful, heretofore impossible, capabilities in our ability to effectively diagnose, treat and cure disease. Eventually these significant capabilities will lead not only to cure but also to prevention of disease, extension of healthy years, and vastly improved quality of life.</p><p>A few brief comments in closing; one of the pitfalls that any progressive age enjoys and suffers is that there are more false prophets than true pioneers (I firmly assert to be neither). We have to more expediently discern those really useful tasks from those that are destined to be useless, and not give heed to those voices that are “full of sound and fury, signifying nothing” (Shakespear’s Hamlet). At any given moment in history, it may be challenging to discern the false prophet from the true pioneer. John Lawton said “The irony of the information age is that it has given new responsibility to uninformed opinion.” I agree with this. We indeed are in the Age of Information, for better and for worse! One might even refer to it as the Age of Information Overload, so enormous is the magnitude and ready accessibility of the information. We are not well poised to take maximum advantage of the available. To compensate, some short cuts are taken by the false prophets, resulting in deductions that are not substantiated by good, hard facts and experimentation; again, that “V” word, validation. The cost of new technology should not be the driving nor limiting factor to future progress. It is important, but if the cost of developing and proving a new technology can be demonstrated with high probability to improve and impact positively healthcare and eventually reduce costs, then fortitude and foresight must prevail to make the required capital investment. There is ample room in the field for true pioneers and visionaries, indeed they are always needed, but there is also need for rational practitioners who exercise common sense and are committed to reduction to practice. As Carl Popper said “I hold it to be morally wrong not to believe in reality”. The degree to which advanced imaging and virtual reality will ultimately be successful in improving healthcare and advancing the state-of-the-art in medicine will surely be commensurate with the degree to which we understand reality and are sensitive to it. The reason for this is simple: the object of medicine is the patient, and the patient is real.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Akay MA, Marsh A (2001) Information technologies in medicine, vol 1. Wiley, New York" /><p class="c-article-references__text" id="ref-CR1">Akay MA, Marsh A (2001) Information technologies in medicine, vol 1. Wiley, New York</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Augustine KE, Huddleston PM, Holmes III DR, Shridharanni SM, Robb RA (2008) Optimization of spine surgery plan" /><p class="c-article-references__text" id="ref-CR2">Augustine KE, Huddleston PM, Holmes III DR, Shridharanni SM, Robb RA (2008) Optimization of spine surgery planning with 3D image templating tools. Proc. SPIE–Medical Imaging 2008, San Diego, CA, 16–21 February</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Brinkmann BJ, Robb RA, O’Brien TJ, Sharbough FW (1997) Localization, correlation, and visualization of electro" /><p class="c-article-references__text" id="ref-CR3">Brinkmann BJ, Robb RA, O’Brien TJ, Sharbough FW (1997) Localization, correlation, and visualization of electroencephalographic surface electrodes and brain anatomy in epilepsy studies. Proc. SPIE–The International Society for Optical Engineering 3033:159–169</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Brinkmann BH, Robb RA, O’Brien TJ, O’Connor MK, Mullan BP (1998) Multimodality imaging for epilepsy diagnosis " /><p class="c-article-references__text" id="ref-CR4">Brinkmann BH, Robb RA, O’Brien TJ, O’Connor MK, Mullan BP (1998) Multimodality imaging for epilepsy diagnosis and surgical focus localization: three-dimensional image correlation and dual isotope SPECT. Proc. of medical image computing and computer-assisted intervention–MICCAI 1998, Cambridge, MA, 1496:1087–1098</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="BH. Brinkmann, TJ. O’Brien, S. Aharon, MK. O’Connor, BP. Mullan, DP. Hanson, RA. Robb, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Brinkmann BH, O’Brien TJ, Aharon S, O’Connor MK, Mullan BP, Hanson DP, Robb RA (1999) Quantitative and clinica" /><p class="c-article-references__text" id="ref-CR5">Brinkmann BH, O’Brien TJ, Aharon S, O’Connor MK, Mullan BP, Hanson DP, Robb RA (1999) Quantitative and clinical analysis of SPECT image registration for epilepsy studies. J Nucl Med 40(7):1098–1105</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Quantitative%20and%20clinical%20analysis%20of%20SPECT%20image%20registration%20for%20epilepsy%20studies&amp;journal=J%20Nucl%20Med&amp;volume=40&amp;issue=7&amp;pages=1098-1105&amp;publication_year=1999&amp;author=Brinkmann%2CBH&amp;author=O%E2%80%99Brien%2CTJ&amp;author=Aharon%2CS&amp;author=O%E2%80%99Connor%2CMK&amp;author=Mullan%2CBP&amp;author=Hanson%2CDP&amp;author=Robb%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="G. Burdea, P. Coiffet, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Burdea G, Coiffet P (1994) Virtual reality technology. Wiley, New York" /><p class="c-article-references__text" id="ref-CR6">Burdea G, Coiffet P (1994) Virtual reality technology. Wiley, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20technology&amp;publication_year=1994&amp;author=Burdea%2CG&amp;author=Coiffet%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cameron BM, Robb RA (2004) Patient-specific dynamic geometric models from sequential volumetric time series im" /><p class="c-article-references__text" id="ref-CR7">Cameron BM, Robb RA (2004) Patient-specific dynamic geometric models from sequential volumetric time series image data. Proceedings of medicine meets virtual reality 12. In: Westwood JD, Haluck RS, Hoffman HM, Mogel GT, Phillips R, Robb RA (eds) IOS Press, Amsterdam, Netherlands, 98:40–45</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="BM. Cameron, RA. Robb, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Cameron BM, Robb RA (2006) Virtual-reality-assisted interventional procedures. Clin Orthop 442:63–73" /><p class="c-article-references__text" id="ref-CR8">Cameron BM, Robb RA (2006) Virtual-reality-assisted interventional procedures. Clin Orthop 442:63–73</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual-reality-assisted%20interventional%20procedures&amp;journal=Clin%20Orthop&amp;volume=442&amp;pages=63-73&amp;publication_year=2006&amp;author=Cameron%2CBM&amp;author=Robb%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cameron BM, Holmes III, DR, Rettmann ME, Robb RA (2008) Patient specific physical anatomy models. Proc. medici" /><p class="c-article-references__text" id="ref-CR14">Cameron BM, Holmes III, DR, Rettmann ME, Robb RA (2008) Patient specific physical anatomy models. Proc. medicine meets virtual reality 16—parallel, combinatorial, convergent: nextmed by design, In: Westwood JD, Haluck RS, Hoffman HM, Mogel GT, Phillips R, Robb RA, Vosburgh KG (eds) IOS Press, Amsterdam, Netherlands, 132:68–73</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Camp J, Robb RA (1999) Realistic visualization for surgery simulation using dynamic volume texture mapping and" /><p class="c-article-references__text" id="ref-CR9">Camp J, Robb RA (1999) Realistic visualization for surgery simulation using dynamic volume texture mapping and model deformation. Proc. SPIE–The International Society for Optical Engineering, 3661:24–31</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="IEEE computer graphics and applications: virtual reality. November/December 2001" /><p class="c-article-references__text" id="ref-CR10">IEEE computer graphics and applications: virtual reality. November/December 2001</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="CR. Haider, BJ. Bartholmai, DR. Holmes, JJ. Camp, RA. Robb, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Haider CR, Bartholmai BJ, Holmes III DR, Camp JJ, Robb RA (2005) Quantitative characterization of lung disease" /><p class="c-article-references__text" id="ref-CR11">Haider CR, Bartholmai BJ, Holmes III DR, Camp JJ, Robb RA (2005) Quantitative characterization of lung disease. Comput Med Imaging Graph 29(7):555–563</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.compmedimag.2005.04.004" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Quantitative%20characterization%20of%20lung%20disease&amp;journal=Comput%20Med%20Imaging%20Graph&amp;volume=29&amp;issue=7&amp;pages=555-563&amp;publication_year=2005&amp;author=Haider%2CCR&amp;author=Bartholmai%2CBJ&amp;author=Holmes%2CDR&amp;author=Camp%2CJJ&amp;author=Robb%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Harris SS, Robb RA (2003) Piecewise registration for point-to-surface mapping of cardiac data. Proc. SPIE–Medi" /><p class="c-article-references__text" id="ref-CR12">Harris SS, Robb RA (2003) Piecewise registration for point-to-surface mapping of cardiac data. Proc. SPIE–Medical Imaging 2003, physiology and function: methods, systems and applications, 5031:146–153.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="PB. Heffernan, RA. Robb, " /><meta itemprop="datePublished" content="1985" /><meta itemprop="headline" content="Heffernan PB, Robb RA (1985) A new method for shaded surface display of biological and medical images. IEEE Tr" /><p class="c-article-references__text" id="ref-CR13">Heffernan PB, Robb RA (1985) A new method for shaded surface display of biological and medical images. IEEE Transactions on Medical Imaging MI-4:26–38</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20new%20method%20for%20shaded%20surface%20display%20of%20biological%20and%20medical%20images&amp;journal=IEEE%20Transactions%20on%20Medical%20Imaging%20MI&amp;volume=-4&amp;pages=26-38&amp;publication_year=1985&amp;author=Heffernan%2CPB&amp;author=Robb%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Holmes III DR, Rettmann M, Cameron B, Camp J, Robb RA (2008) Developing patient-specific anatomic models for v" /><p class="c-article-references__text" id="ref-CR15">Holmes III DR, Rettmann M, Cameron B, Camp J, Robb RA (2008) Developing patient-specific anatomic models for validation of cardiac ablation guidance procedures. Proc. SPIE–Medical Imaging 2008, San Diego, California, February 16–21</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Holmes III DR, Robb RA (2000) Trans-urethral ultrasound (TUUS) imaging for visualization and analysis of the p" /><p class="c-article-references__text" id="ref-CR16">Holmes III DR, Robb RA (2000) Trans-urethral ultrasound (TUUS) imaging for visualization and analysis of the prostate and associated tissues. Proc. SPIE–medical imaging 2000: image display and visualization 3976:22–27</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Khurana VG, Cameron BM, Bates LM, Robb RA (1999a) Virtual frontiers, part 1: fundamental concepts and recent a" /><p class="c-article-references__text" id="ref-CR17">Khurana VG, Cameron BM, Bates LM, Robb RA (1999a) Virtual frontiers, part 1: fundamental concepts and recent advances in virtual reality technology. In: Fisher III WS (ed) Perspectives in neurological surgery. Thieme Publishing, New York 10(2):113–127</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Khurana VG, Bates LM, Meyer FB, Robb RA (1999b) Virtual frontiers, part 2: role of virtual reality technology " /><p class="c-article-references__text" id="ref-CR18">Khurana VG, Bates LM, Meyer FB, Robb RA (1999b) Virtual frontiers, part 2: role of virtual reality technology in neurosurgery. In: Fisher III WS (ed) Perspectives in neurological surgery. Thieme Publishing, New York 10(2):113–127</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lepard KO, Robb RA (1996) Shape-based segmentation and characterization of biomedical images. Proc. SPIE–the i" /><p class="c-article-references__text" id="ref-CR19">Lepard KO, Robb RA (1996) Shape-based segmentation and characterization of biomedical images. Proc. SPIE–the international society for optical engineering, vol 2710</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lin W, Robb RA (2000) A 5-D model for accurate representation and visualization of dynamic cardiac structures." /><p class="c-article-references__text" id="ref-CR20">Lin W, Robb RA (2000) A 5-D model for accurate representation and visualization of dynamic cardiac structures. Proc. SPIE–Biomedical Diagnostic, Guidance, and Surgical Assist Systems II, 3911:322–329 </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="LJ. Melton, BL. Riggs, TM. Keaveny, SJ. Achenbach, PF. Hoffman, JJ. Camp, PA. Rouleau, ML. Bouxsein, S. Amin, EJ. Atkinson, RA. Robb, S. Khosla, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Melton LJIII, Riggs BL, Keaveny TM, Achenbach SJ, Hoffman PF, Camp JJ, Rouleau PA, Bouxsein ML, Amin S, Atkins" /><p class="c-article-references__text" id="ref-CR21">Melton LJIII, Riggs BL, Keaveny TM, Achenbach SJ, Hoffman PF, Camp JJ, Rouleau PA, Bouxsein ML, Amin S, Atkinson EJ, Robb RA, Khosla S (2007) Structural determinants of vertebral fracture risk. J Bone Miner Res 22(12):1885–1892</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1359%2Fjbmr.070728" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Structural%20determinants%20of%20vertebral%20fracture%20risk&amp;journal=J%20Bone%20Miner%20Res&amp;volume=22&amp;issue=12&amp;pages=1885-1892&amp;publication_year=2007&amp;author=Melton%2CLJ&amp;author=Riggs%2CBL&amp;author=Keaveny%2CTM&amp;author=Achenbach%2CSJ&amp;author=Hoffman%2CPF&amp;author=Camp%2CJJ&amp;author=Rouleau%2CPA&amp;author=Bouxsein%2CML&amp;author=Amin%2CS&amp;author=Atkinson%2CEJ&amp;author=Robb%2CRA&amp;author=Khosla%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Packer DL, Asirvatham S, Seward JB, Breen JF, Robb RA (2004) Imaging of the cardiac and thoracic veins. Chap. " /><p class="c-article-references__text" id="ref-CR22">Packer DL, Asirvatham S, Seward JB, Breen JF, Robb RA (2004) Imaging of the cardiac and thoracic veins. Chap. 8. In: Chen, Haissaguerre, Zipes (eds) Thoracic vein arrhythmias: mechanisms and treatments. Prepress Projects, Ltd., Scotland</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rajagopalan S, Robb RA (2006) Fourier-domain based datacentric performance ranking of competing medical image " /><p class="c-article-references__text" id="ref-CR23">Rajagopalan S, Robb RA (2006) Fourier-domain based datacentric performance ranking of competing medical image processing algorithms. Proc. SPIE–medical imaging 2006, San Diego, CA, 11–16 February</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rettmann ME, Holmes III DR, Su Y, Cameron BM, Packer DL, Robb RA (2006) An integrated system for real-time ima" /><p class="c-article-references__text" id="ref-CR24">Rettmann ME, Holmes III DR, Su Y, Cameron BM, Packer DL, Robb RA (2006) An integrated system for real-time image guided cardiac catheter ablation. Proc. medicine meets virtual reality 14. In:Westwood JD, Haluck RS, Hoffmann HM, Mogel GT, Phillips R, Robb RA, Vosburgh KG (eds) IOS Press, Amsterdam, Netherlands, 119:455–460</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rettmann ME, Holmes III DR, Camp JJ, Packer DL, Robb RA (2008) Validation of semi-automatic segmentation of th" /><p class="c-article-references__text" id="ref-CR25">Rettmann ME, Holmes III DR, Camp JJ, Packer DL, Robb RA (2008) Validation of semi-automatic segmentation of the left atrium. Proc. SPIE–medical imaging 2008, San Diego, CA, 16–21 February</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EL. Ritman, RA. Robb, SA. Johnson, PA. Chevalier, BK. Gilbert, JF. Greenleaf, RE. Sturm, EH. Wood, " /><meta itemprop="datePublished" content="1978" /><meta itemprop="headline" content="Ritman EL, Robb RA, Johnson SA, Chevalier PA, Gilbert BK, Greenleaf JF, Sturm RE, Wood EH (1978) Quantitative " /><p class="c-article-references__text" id="ref-CR26">Ritman EL, Robb RA, Johnson SA, Chevalier PA, Gilbert BK, Greenleaf JF, Sturm RE, Wood EH (1978) Quantitative imaging of the structure and function of the heart, lungs, and circulation. Mayo Clin Proc 53:3–11</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Quantitative%20imaging%20of%20the%20structure%20and%20function%20of%20the%20heart%2C%20lungs%2C%20and%20circulation&amp;journal=Mayo%20Clin%20Proc&amp;volume=53&amp;pages=3-11&amp;publication_year=1978&amp;author=Ritman%2CEL&amp;author=Robb%2CRA&amp;author=Johnson%2CSA&amp;author=Chevalier%2CPA&amp;author=Gilbert%2CBK&amp;author=Greenleaf%2CJF&amp;author=Sturm%2CRE&amp;author=Wood%2CEH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EL. Ritman, JH. Kinsey, RA. Robb, BK. Gilbert, LD. Harris, EH. Wood, " /><meta itemprop="datePublished" content="1980" /><meta itemprop="headline" content="Ritman EL, Kinsey JH, Robb RA, Gilbert BK, Harris LD, Wood EH (1980) Three-dimensional imaging of heart, lungs" /><p class="c-article-references__text" id="ref-CR27">Ritman EL, Kinsey JH, Robb RA, Gilbert BK, Harris LD, Wood EH (1980) Three-dimensional imaging of heart, lungs, and circulation. Science 210:273–280</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1126%2Fscience.7423187" aria-label="View reference 27">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Three-dimensional%20imaging%20of%20heart%2C%20lungs%2C%20and%20circulation&amp;journal=Science&amp;volume=210&amp;pages=273-280&amp;publication_year=1980&amp;author=Ritman%2CEL&amp;author=Kinsey%2CJH&amp;author=Robb%2CRA&amp;author=Gilbert%2CBK&amp;author=Harris%2CLD&amp;author=Wood%2CEH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Robb RA (1971) Computer-aided contour determination and dynamic display of individual cardiac chambers from di" /><p class="c-article-references__text" id="ref-CR28">Robb RA (1971) Computer-aided contour determination and dynamic display of individual cardiac chambers from digitized serial angiocardiographic film. In: Heintzen PH (ed) Roentgen-, cine-, and videodensitometry. Fundamentals and application for blood flow and heart volume determination. Georg Thieme Verlag, Stuttgart, pp 170–178</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Robb, " /><meta itemprop="datePublished" content="1982" /><meta itemprop="headline" content="Robb RA (1982a) X-ray computed tomography: from basic principles to applications. Annu Rev Biophys Bioeng 11:1" /><p class="c-article-references__text" id="ref-CR29">Robb RA (1982a) X-ray computed tomography: from basic principles to applications. Annu Rev Biophys Bioeng 11:177–201</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1146%2Fannurev.bb.11.060182.001141" aria-label="View reference 29">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=X-ray%20computed%20tomography%3A%20from%20basic%20principles%20to%20applications&amp;journal=Annu%20Rev%20Biophys%20Bioeng&amp;volume=11&amp;pages=177-201&amp;publication_year=1982&amp;author=Robb%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Robb, " /><meta itemprop="datePublished" content="1982b" /><meta itemprop="headline" content="Robb RA (1982b) The dynamic spatial reconstructor: an X-ray video-fluoroscopic CT scanner for dynamic volume i" /><p class="c-article-references__text" id="ref-CR30">Robb RA (1982b) The dynamic spatial reconstructor: an X-ray video-fluoroscopic CT scanner for dynamic volume imaging of moving organs. IEEE Transactions on Medical Imaging, MI-1(1):22–23</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20dynamic%20spatial%20reconstructor%3A%20an%20X-ray%20video-fluoroscopic%20CT%20scanner%20for%20dynamic%20volume%20imaging%20of%20moving%20organs&amp;journal=IEEE%20Transactions%20on%20Medical%20Imaging%2C%20MI&amp;volume=-1&amp;issue=1&amp;pages=22-23&amp;publication_year=1982b&amp;author=Robb%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="RA. Robb, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Robb RA (1995) Three-dimensional biomedical imaging—principles and practice. VCH Publishers, New York" /><p class="c-article-references__text" id="ref-CR31">Robb RA (1995) Three-dimensional biomedical imaging—principles and practice. VCH Publishers, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Three-dimensional%20biomedical%20imaging%E2%80%94principles%20and%20practice&amp;publication_year=1995&amp;author=Robb%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="RA. Robb, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Robb RA (1999a) Biomedical imaging, visualization and analysis. Wiley, New York" /><p class="c-article-references__text" id="ref-CR32">Robb RA (1999a) Biomedical imaging, visualization and analysis. Wiley, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Biomedical%20imaging%2C%20visualization%20and%20analysis&amp;publication_year=1999&amp;author=Robb%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Robb, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Robb RA (1999b) Visualization in biomedical computing. Parallel Comput 25:2067–2110" /><p class="c-article-references__text" id="ref-CR33">Robb RA (1999b) Visualization in biomedical computing. Parallel Comput 25:2067–2110</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0167-8191%2899%2900076-9" aria-label="View reference 33">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Visualization%20in%20biomedical%20computing&amp;journal=Parallel%20Comput&amp;volume=25&amp;pages=2067-2110&amp;publication_year=1999&amp;author=Robb%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Robb, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Robb RA (2000) Virtual endoscopy: development and evaluation using the visible human datasets. Comput Med Imag" /><p class="c-article-references__text" id="ref-CR34">Robb RA (2000) Virtual endoscopy: development and evaluation using the visible human datasets. Comput Med Imaging Graph 24:133–151</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0895-6111%2800%2900014-8" aria-label="View reference 34">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20endoscopy%3A%20development%20and%20evaluation%20using%20the%20visible%20human%20datasets&amp;journal=Comput%20Med%20Imaging%20Graph&amp;volume=24&amp;pages=133-151&amp;publication_year=2000&amp;author=Robb%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Robb, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Robb RA (2001a) The biomedical imaging resource at mayo clinic. IEEE TMI 20(9):854–867" /><p class="c-article-references__text" id="ref-CR35">Robb RA (2001a) The biomedical imaging resource at mayo clinic. IEEE TMI 20(9):854–867</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20biomedical%20imaging%20resource%20at%20mayo%20clinic&amp;journal=IEEE%20TMI&amp;volume=20&amp;issue=9&amp;pages=854-867&amp;publication_year=2001&amp;author=Robb%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Robb RA (2001b) Virtual reality in medicine and biology. In: Akay M, Marsh A (eds) Information technologies in" /><p class="c-article-references__text" id="ref-CR36">Robb RA (2001b) Virtual reality in medicine and biology. In: Akay M, Marsh A (eds) Information technologies in medicine: medical simulation and education. Wiley, New York, vol 1, Chap. 1, pp 3–31</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Robb RA (2002a) The virtualization of medicine: a decade of pitfalls and progress. Medicine meets virtual real" /><p class="c-article-references__text" id="ref-CR38">Robb RA (2002a) The virtualization of medicine: a decade of pitfalls and progress. Medicine meets virtual reality 02/10. In: Westwood JD, Hoffman HM, Robb RA, Stredney D (eds) IOS Press Amsterdam, Netherlands, vol 85, pp 31–37</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Robb, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Robb RA (2002b) Virtual reality in medicine: a personal perspective. J Visualization 5(4):317–326" /><p class="c-article-references__text" id="ref-CR39">Robb RA (2002b) Virtual reality in medicine: a personal perspective. J Visualization 5(4):317–326</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2FBF03182346" aria-label="View reference 38">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 38 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20in%20medicine%3A%20a%20personal%20perspective&amp;journal=J%20Visualization&amp;volume=5&amp;issue=4&amp;pages=317-326&amp;publication_year=2002&amp;author=Robb%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Robb RA (2005) Image processing for anatomy and physiology: fusion of form and function. Proceedings of sixth " /><p class="c-article-references__text" id="ref-CR40">Robb RA (2005) Image processing for anatomy and physiology: fusion of form and function. Proceedings of sixth annual national forum on biomedical imaging and oncology, NCI/NEMA/DCTD, Bethesda, MD, 7–8 April</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Robb, C. Barillot, " /><meta itemprop="datePublished" content="1989" /><meta itemprop="headline" content="Robb RA, Barillot C (1989) Interactive display and analysis of 3-D medical images. IEEE Transactions on Medica" /><p class="c-article-references__text" id="ref-CR41">Robb RA, Barillot C (1989) Interactive display and analysis of 3-D medical images. IEEE Transactions on Medical Imaging 8(3):217–226</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F42.34710" aria-label="View reference 40">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 40 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Interactive%20display%20and%20analysis%20of%203-D%20medical%20images&amp;journal=IEEE%20Transactions%20on%20Medical%20Imaging&amp;volume=8&amp;issue=3&amp;pages=217-226&amp;publication_year=1989&amp;author=Robb%2CRA&amp;author=Barillot%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Robb RA, Hanson DP (1995) The ANALYZETM software system for visualization and analysis in surgery simulation. " /><p class="c-article-references__text" id="ref-CR42">Robb RA, Hanson DP (1995) The ANALYZE<sup>TM</sup> software system for visualization and analysis in surgery simulation. In: Lavallée S, Taylor R, Burdea G, Mösges R (eds) Computer integrated surgery. MIT Press, Cambridge, pp 175–190</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Robb, EL. Ritman, " /><meta itemprop="datePublished" content="1979" /><meta itemprop="headline" content="Robb RA, Ritman EL (1979) High-speed synchronous volume computed tomography of the heart. Radiology 133:655–66" /><p class="c-article-references__text" id="ref-CR43">Robb RA, Ritman EL (1979) High-speed synchronous volume computed tomography of the heart. Radiology 133:655–661</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 42 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=High-speed%20synchronous%20volume%20computed%20tomography%20of%20the%20heart&amp;journal=Radiology&amp;volume=133&amp;pages=655-661&amp;publication_year=1979&amp;author=Robb%2CRA&amp;author=Ritman%2CEL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Robb, JF. Greenleaf, EL. Ritman, SA. Johnson, JD. Sjostrand, GT. Herman, EH. Wood, " /><meta itemprop="datePublished" content="1974" /><meta itemprop="headline" content="Robb RA, Greenleaf JF, Ritman EL, Johnson SA, Sjostrand JD, Herman GT, Wood EH (1974) Three-dimensional visual" /><p class="c-article-references__text" id="ref-CR44">Robb RA, Greenleaf JF, Ritman EL, Johnson SA, Sjostrand JD, Herman GT, Wood EH (1974) Three-dimensional visualization of the intact thorax and contents: a technique for cross-sectional reconstruction from multiplanar X-ray views. Comput Biomed Res 7:395–419</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2F0010-4809%2874%2990015-9" aria-label="View reference 43">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 43 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Three-dimensional%20visualization%20of%20the%20intact%20thorax%20and%20contents%3A%20a%20technique%20for%20cross-sectional%20reconstruction%20from%20multiplanar%20X-ray%20views&amp;journal=Comput%20Biomed%20Res&amp;volume=7&amp;pages=395-419&amp;publication_year=1974&amp;author=Robb%2CRA&amp;author=Greenleaf%2CJF&amp;author=Ritman%2CEL&amp;author=Johnson%2CSA&amp;author=Sjostrand%2CJD&amp;author=Herman%2CGT&amp;author=Wood%2CEH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Robb, EL. Ritman, BK. Gilbert, JH. Kinsey, LD. Harris, EH. Wood, " /><meta itemprop="datePublished" content="1979" /><meta itemprop="headline" content="Robb RA, Ritman EL, Gilbert BK, Kinsey JH, Harris LD, Wood EH (1979) The DSR: a high-speed three-dimensional X" /><p class="c-article-references__text" id="ref-CR45">Robb RA, Ritman EL, Gilbert BK, Kinsey JH, Harris LD, Wood EH (1979) The DSR: a high-speed three-dimensional X-ray computed tomography system for dynamic spatial reconstruction of the heart and circulation. IEEE Transactions on Nuclear Science NS-26(2):2713–2717</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTNS.1979.4330520" aria-label="View reference 44">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 44 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20DSR%3A%20a%20high-speed%20three-dimensional%20X-ray%20computed%20tomography%20system%20for%20dynamic%20spatial%20reconstruction%20of%20the%20heart%20and%20circulation&amp;journal=IEEE%20Transactions%20on%20Nuclear%20Science&amp;volume=NS-26&amp;issue=2&amp;pages=2713-2717&amp;publication_year=1979&amp;author=Robb%2CRA&amp;author=Ritman%2CEL&amp;author=Gilbert%2CBK&amp;author=Kinsey%2CJH&amp;author=Harris%2CLD&amp;author=Wood%2CEH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Robb, DP. Hanson, JJ. Camp, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Robb RA, Hanson DP, Camp JJ (1996) Computer-aided surgery planning and rehearsal at Mayo Clinic. Computer 29(1" /><p class="c-article-references__text" id="ref-CR46">Robb RA, Hanson DP, Camp JJ (1996) Computer-aided surgery planning and rehearsal at Mayo Clinic. Computer 29(1):39–47</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F2.481435" aria-label="View reference 45">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 45 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Computer-aided%20surgery%20planning%20and%20rehearsal%20at%20Mayo%20Clinic&amp;journal=Computer&amp;volume=29&amp;issue=1&amp;pages=39-47&amp;publication_year=1996&amp;author=Robb%2CRA&amp;author=Hanson%2CDP&amp;author=Camp%2CJJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Robb RA, Cameron BM, Aharon S (1997) Efficient shape-based algorithms for modeling patient specific anatomy fr" /><p class="c-article-references__text" id="ref-CR47">Robb RA, Cameron BM, Aharon S (1997) Efficient shape-based algorithms for modeling patient specific anatomy from 3D medical images: applications in virtual endoscopy and surgery. Proceedings of shape modeling and applications, pp 97–108, Aizu-Wakamatsu, Japan, 3–6 March</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="R. Satava, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Satava R (1998) Cybersurgery: advanced technologies for surgical practice. Wiley, New York" /><p class="c-article-references__text" id="ref-CR48">Satava R (1998) Cybersurgery: advanced technologies for surgical practice. Wiley, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 47 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Cybersurgery%3A%20advanced%20technologies%20for%20surgical%20practice&amp;publication_year=1998&amp;author=Satava%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RM. Satava, RA. Robb, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Satava RM, Robb RA (1997) Virtual endoscopy: applications of 3-D visualization to medical diagnosis. PRESENCE " /><p class="c-article-references__text" id="ref-CR49">Satava RM, Robb RA (1997) Virtual endoscopy: applications of 3-D visualization to medical diagnosis. PRESENCE 6(2):179–197</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 48 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20endoscopy%3A%20applications%20of%203-D%20visualization%20to%20medical%20diagnosis&amp;journal=PRESENCE&amp;volume=6&amp;issue=2&amp;pages=179-197&amp;publication_year=1997&amp;author=Satava%2CRM&amp;author=Robb%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. Su, BJ. Davis, KM. Furutani, MG. Herman, RA. Robb, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Su Y, Davis BJ, Furutani KM, Herman MG, Robb RA (2007) Seed localization and TRUS-fluoroscopy fusion for intra" /><p class="c-article-references__text" id="ref-CR50">Su Y, Davis BJ, Furutani KM, Herman MG, Robb RA (2007) Seed localization and TRUS-fluoroscopy fusion for intraoperative prostate brachytherapy dosimetry. Comput Aided Surg 12(1):25–34</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F10929080601168239" aria-label="View reference 49">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 49 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Seed%20localization%20and%20TRUS-fluoroscopy%20fusion%20for%20intraoperative%20prostate%20brachytherapy%20dosimetry&amp;journal=Comput%20Aided%20Surg&amp;volume=12&amp;issue=1&amp;pages=25-34&amp;publication_year=2007&amp;author=Su%2CY&amp;author=Davis%2CBJ&amp;author=Furutani%2CKM&amp;author=Herman%2CMG&amp;author=Robb%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Wu QR, Bourland JD, Robb RA (1996) Morphology guided radiotherapy treatment planning and optimization. Proc. S" /><p class="c-article-references__text" id="ref-CR51">Wu QR, Bourland JD, Robb RA (1996) Morphology guided radiotherapy treatment planning and optimization. Proc. SPIE–The International Society for Optical Engineering, 2707:180–189</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="VA. Zavaletta, BJ. Bartholmai, RA. Robb, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Zavaletta VA, Bartholmai BJ, Robb RA (2007) High resolution multi-detector CT aided tissue analysis and quanti" /><p class="c-article-references__text" id="ref-CR52">Zavaletta VA, Bartholmai BJ, Robb RA (2007) High resolution multi-detector CT aided tissue analysis and quantification of lung fibrosis. Acad Radiol 14:772–787</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.acra.2007.03.009" aria-label="View reference 51">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 51 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=High%20resolution%20multi-detector%20CT%20aided%20tissue%20analysis%20and%20quantification%20of%20lung%20fibrosis&amp;journal=Acad%20Radiol&amp;volume=14&amp;pages=772-787&amp;publication_year=2007&amp;author=Zavaletta%2CVA&amp;author=Bartholmai%2CBJ&amp;author=Robb%2CRA">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-008-0104-z-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgments</h2><div class="c-article-section__content" id="Ack1-content"><p>The author is grateful for the many talents and contributions of his colleagues in the Mayo Biomedical Imaging Resource, with whom he has been privileged to work for many years, and for the expertise and interests of many physicians, surgeons and healthcare practitioners at Mayo Clinic and other institutions with whom he has been fortunate to collaborate during his entire professional career. Portions of the reported work have been funded by NIH grants: NIBIB EB0283, NIDDK DK68055, NHLBI HR46158, NCI CA107933, NIAMS AR27065, and NIAMS AR 056212.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Mayo Clinic College of Medicine, Rochester, MN, USA</p><p class="c-article-author-affiliation__authors-list">Richard A. Robb</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Richard_A_-Robb"><span class="c-article-authors-search__title u-h3 js-search-name">Richard A. Robb</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Richard A.+Robb&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Richard A.+Robb" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Richard A.+Robb%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-008-0104-z/email/correspondent/c1/new">Richard A. Robb</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Medical%20imaging%20and%20virtual%20reality%3A%20a%20personal%20perspective&amp;author=Richard%20A.%20Robb&amp;contentID=10.1007%2Fs10055-008-0104-z&amp;publication=1359-4338&amp;publicationDate=2008-11-21&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Robb, R.A. Medical imaging and virtual reality: a personal perspective.
                    <i>Virtual Reality</i> <b>12, </b>235–257 (2008). https://doi.org/10.1007/s10055-008-0104-z</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-008-0104-z.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-09-27">27 September 2008</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-10-26">26 October 2008</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-11-21">21 November 2008</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-12">December 2008</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-008-0104-z" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-008-0104-z</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Multi-modality imaging</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Multi-dimensional imaging</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Image fusion</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Image visualization</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Image modeling</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Evolution of imaging</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Virtual reality technology</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-008-0104-z.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=104;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

