<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Designing presence for real locomotion in immersive virtual environmen"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="This paper describes a framework for designing systems for real locomotion in virtual environments (VEs) in order to achieve an intense sense of presence. The main outcome of the present research..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/19/3.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Designing presence for real locomotion in immersive virtual environments: an affordance-based experiential approach"/>

    <meta name="dc.source" content="Virtual Reality 2015 19:3"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2015-07-10"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2015 Springer-Verlag London"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="This paper describes a framework for designing systems for real locomotion in virtual environments (VEs) in order to achieve an intense sense of presence. The main outcome of the present research is a list of design features that the virtual reality technology should have in order to achieve such a goal. To identify these features, an approach based on the combination of two design strategies was followed. The first was based on the theory of affordances and was utilized to design a generic VE in which the affordances of the corresponding real environment could be evoked. The second was the experiential design applied to VEs and was utilized to create an experience of locomotion corresponding to that achievable in a real environment. These design strategies were chosen because of their potential to enhance the sense of presence. The proposed list of features can be utilized as an instrument that allows VE designers to evaluate the maturity of their systems and to pinpoint directions for future developments. A survey analysis was performed using the proposed framework, which involved three case studies to determine how many features of the proposed framework were present and their status. The result of such analysis represented a measure of the completeness of the systems design, of the affordances provided to the user, and a prediction of the sense of presence."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2015-07-10"/>

    <meta name="prism.volume" content="19"/>

    <meta name="prism.number" content="3"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="277"/>

    <meta name="prism.endingPage" content="290"/>

    <meta name="prism.copyright" content="2015 Springer-Verlag London"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-015-0267-3"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-015-0267-3"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-015-0267-3.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-015-0267-3"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Designing presence for real locomotion in immersive virtual environments: an affordance-based experiential approach"/>

    <meta name="citation_volume" content="19"/>

    <meta name="citation_issue" content="3"/>

    <meta name="citation_publication_date" content="2015/11"/>

    <meta name="citation_online_date" content="2015/07/10"/>

    <meta name="citation_firstpage" content="277"/>

    <meta name="citation_lastpage" content="290"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-015-0267-3"/>

    <meta name="DOI" content="10.1007/s10055-015-0267-3"/>

    <meta name="citation_doi" content="10.1007/s10055-015-0267-3"/>

    <meta name="description" content="This paper describes a framework for designing systems for real locomotion in virtual environments (VEs) in order to achieve an intense sense of presence. "/>

    <meta name="dc.creator" content="Luca Turchet"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Barfield W, Zeltzer D, Sheridan T, Slater M (1995) Presence and performance within virtual environments. In: Virtual environments and advanced interface design pp 473&#8211;513"/>

    <meta name="citation_reference" content="Biocca F, Inque Y, Polinsky H, Lee A, Tang A (2002) Visual cues and virtual touch: role of visual stimuli and intersensory integration in cross-modal haptic illusions and the sense of presence. In: Proceedings of presence, pp 410&#8211;428"/>

    <meta name="citation_reference" content="citation_journal_title=Displays; citation_title=Exploiting perceptual limitations and illusions to support walking through virtual environments in confined physical spaces; citation_author=G Bruder, F Steinicke, B Bolte, P Wieland, H Frenz, M Lappe; citation_volume=34; citation_issue=2; citation_publication_date=2012; citation_pages=132-141; citation_doi=10.1016/j.displa.2012.10.007; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_title=The handbook of multisensory processes; citation_publication_date=2004; citation_id=CR4; citation_author=G Calvert; citation_author=C Spence; citation_author=B Stein; citation_publisher=MIT press"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Improving presence theory through experiential design; citation_author=D Chertoff, S Schatz, R McDaniel, C Bowers; citation_volume=17; citation_issue=4; citation_publication_date=2008; citation_pages=405-413; citation_doi=10.1162/pres.17.4.405; citation_id=CR5"/>

    <meta name="citation_reference" content="Chertoff DB, Goldiez B, LaViola JJ (2010) Virtual experience test: a virtual environment evaluation questionnaire. In: Proceedings the IEEE virtual reality conference, pp 103&#8211;110"/>

    <meta name="citation_reference" content="Dinh H, Walker N, Hodges L, Song C, Kobayashi A (1999) Evaluating the importance of multi-sensory input on memory and the sense of presence in virtual environments. In: IEEE virtual reality conference, pp 222&#8211;228"/>

    <meta name="citation_reference" content="Fajen B (2013) Affordance perception and the visual control of locomotion. In: Human walking in virtual environments. Springer, New York, pp 79&#8211;98"/>

    <meta name="citation_reference" content="citation_journal_title=Ecol Psychol; citation_title=Haptic and visual perception of an affordance for upright posture; citation_author=P Fitzpatrick, C Carello, R Schmidt, D Corey; citation_volume=6; citation_issue=4; citation_publication_date=1994; citation_pages=265-287; citation_doi=10.1207/s15326969eco0604_2; citation_id=CR9"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=The reality of experience: Gibson&#8217;s way; citation_author=J Flach, J Holden; citation_volume=7; citation_issue=1; citation_publication_date=1998; citation_pages=90-95; citation_doi=10.1162/105474698565550; citation_id=CR10"/>

    <meta name="citation_reference" content="Frissen I, Campos J, Sreenivasa M, Ernst M (2013) Enabling unconstrained omnidirectional walking through virtual environments: an overview of the cyberwalk project. In: Human walking in virtual environments. Springer, New York, pp 113&#8211;144"/>

    <meta name="citation_reference" content="Fr&#246;hlich J, Wachsmuth I (2013) The visual, the auditory and the haptic&#8212;a user study on combining modalities in virtual worlds. In: Shumaker R (ed) Virtual, augmented and mixed reality. Designing and developing virtual and augmented environments, Lecture Notes in Computer Science, vol 8021. Springer, New York, pp 159&#8211;168"/>

    <meta name="citation_reference" content="Gaver W (1991) Technology affordances. In: Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, New York, pp 79&#8211;84"/>

    <meta name="citation_reference" content="Gibson J (1979) The ecological approach to visual perception. Houghton Miffin, New York"/>

    <meta name="citation_reference" content="Giordano B, Bresin R (2006) Walking and playing: What&#8217;s the origin of emotional expressiveness in music? In: Proceedings of the 9th international conference on music perception &amp; cognition, p 436"/>

    <meta name="citation_reference" content="citation_journal_title=J Acoust Soc Am; citation_title=Identification of walked-upon materials in auditory, kinesthetic, haptic and audio-haptic conditions; citation_author=B Giordano, Y Visell, HY Yao, V Hayward, J Cooperstock, S McAdams; citation_volume=131; citation_publication_date=2012; citation_pages=4002-4012; citation_doi=10.1121/1.3699205; citation_id=CR16"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Visual Comput Graph; citation_title=Dynamic affordances in embodied interactive systems: the role of display and mode of locomotion; citation_author=T Grechkin, J Plumert, J Kearney; citation_volume=20; citation_issue=4; citation_publication_date=2014; citation_pages=596-605; citation_doi=10.1109/TVCG.2014.18; citation_id=CR17"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Evoking affordances in virtual environments via sensory-stimuli substitution; citation_author=D Gross, K Stanney, L Cohn; citation_volume=14; citation_issue=4; citation_publication_date=2005; citation_pages=482-491; citation_doi=10.1162/105474605774785244; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=Behav Inf Technol; citation_title=Cognitive, physical, sensory, and functional affordances in interaction design; citation_author=R Hartson; citation_volume=22; citation_issue=5; citation_publication_date=2003; citation_pages=315-338; citation_doi=10.1080/01449290310001592587; citation_id=CR19"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=The binding problem in presence research; citation_author=M Harvey, M Sanchez-Vives; citation_volume=14; citation_issue=5; citation_publication_date=2005; citation_pages=616-621; citation_doi=10.1162/105474605774918714; citation_id=CR20"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Being there: the subjective experience of presence; citation_author=C Heeter; citation_volume=1; citation_issue=2; citation_publication_date=1992; citation_pages=262-271; citation_id=CR21"/>

    <meta name="citation_reference" content="Heeter C (1995) Communication research on consumer vr. Communication in the age of virtual reality, pp 191&#8211;218"/>

    <meta name="citation_reference" content="citation_title=The sonification handbook; citation_publication_date=2011; citation_id=CR23; citation_publisher=Logos Publishing House"/>

    <meta name="citation_reference" content="Hollerbach J (2002) Locomotion interfaces. In: Handbook of virtual environments: design, implementation, and applications, pp 239&#8211;254"/>

    <meta name="citation_reference" content="Hollerbach J, Xu Y, Christensen R, Jacobsen S (2000) Design specifications for the second generation sarcos treadport locomotion interface. In: Haptics symposium, proceedings of the ASME dynamic systems and control division, vol&#160;69, pp 1293&#8211;1298"/>

    <meta name="citation_reference" content="citation_journal_title=J Virtual Real Broadcast; citation_title=Simulating wind and warmth in virtual reality: conception, realization and evaluation for a cave environment; citation_author=F H&#252;lsmann, N Mattar, J Fr&#246;hlich, I Wachsmuth; citation_volume=11; citation_issue=10; citation_publication_date=2014; citation_pages=1-20; citation_id=CR26"/>

    <meta name="citation_reference" content="Kulkarni S, Fisher C, Pardyjak E, Minor M, Hollerbach J (2009) Wind display device for locomotion interface in a virtual environment. In: Proceedings of IEEE World haptics conference. IEEE, pp 184&#8211;189"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Mechatron; citation_title=Design, sensing, and control of a scaled wind tunnel for atmospheric display; citation_author=S Kulkarni, M Minor, M Deaver, E Pardyjak, J Hollerbach; citation_volume=17; citation_issue=4; citation_publication_date=2012; citation_pages=635-645; citation_doi=10.1109/TMECH.2011.2113353; citation_id=CR28"/>

    <meta name="citation_reference" content="Larsson P, V&#228;ljam&#228;e A, V&#228;stfj&#228;ll D, Tajadura-Jim&#233;nez A, Kleiner M (2010) Auditory-induced presence in mixed reality environments and related technology. In: The engineering of mixed reality systems. Springer, New York, pp 143&#8211;163"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Why presence occurs: evolutionary psychology, media equation, and presence; citation_author=K Lee; citation_volume=13; citation_issue=4; citation_publication_date=2004; citation_pages=494-505; citation_doi=10.1162/1054746041944830; citation_id=CR30"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Reality; citation_title=Afforded actions as a behavioral assessment of physical presence in virtual environments; citation_author=J Lepecq, L Bringoux, J Pergandi, T Coyle, D Mestre; citation_volume=13; citation_issue=3; citation_publication_date=2009; citation_pages=141-151; citation_doi=10.1007/s10055-009-0118-1; citation_id=CR31"/>

    <meta name="citation_reference" content="citation_journal_title=J Acoust Soc Am; citation_title=Perception of acoustic source characteristics: walking sounds; citation_author=XF Li, RJ Logan, RE Pastore; citation_volume=90; citation_issue=6; citation_publication_date=1991; citation_pages=3036-3049; citation_doi=10.1121/1.401778; citation_id=CR32"/>

    <meta name="citation_reference" content="citation_journal_title=Res Eng Design; citation_title=Affordance based design: a relational theory for design; citation_author=J Maier, G Fadel; citation_volume=20; citation_issue=1; citation_publication_date=2009; citation_pages=13-27; citation_doi=10.1007/s00163-008-0060-3; citation_id=CR33"/>

    <meta name="citation_reference" content="citation_journal_title=Res Eng Design; citation_title=Affordance-based design methods for innovative design, redesign and reverse engineering; citation_author=J Maier, G Fadel; citation_volume=20; citation_issue=4; citation_publication_date=2009; citation_pages=225-239; citation_doi=10.1007/s00163-009-0064-7; citation_id=CR34"/>

    <meta name="citation_reference" content="M&#228;kel&#228; K, Hakulinen J, Turunen M (2003) The use of walking sounds in supporting awareness. In: Proceedings of ICAD, pp 144&#8211;147"/>

    <meta name="citation_reference" content="Marchal M, L&#233;cuyer A, Cirio G, Bonnet L, Emily M (2010) Walking up and down in immersive virtual worlds: novel interactive techniques based on visual feedback. In: IEEE symposium on 3D user interfaces, pp 19&#8211;26"/>

    <meta name="citation_reference" content="citation_journal_title=J Exp Psychol Hum Percept Perform; citation_title=Eyeheight-scaled information about affordances: a study of sitting and stair climbing; citation_author=LS Mark; citation_volume=13; citation_issue=3; citation_publication_date=1987; citation_pages=361-370; citation_doi=10.1037/0096-1523.13.3.361; citation_id=CR37"/>

    <meta name="citation_reference" content="citation_journal_title=Graph Interface; citation_title=Affordances: clarifying and evolving a concept; citation_author=J McGrenere, W Ho; citation_volume=2000; citation_publication_date=2000; citation_pages=179-186; citation_id=CR38"/>

    <meta name="citation_reference" content="citation_journal_title=PsychNology J; citation_title=A multimodal architecture for simulating natural interactive walking in virtual environments; citation_author=R Nordahl, S Serafin, L Turchet, N Nilsson; citation_volume=9; citation_issue=3; citation_publication_date=2012; citation_pages=245-268; citation_id=CR39"/>

    <meta name="citation_reference" content="citation_journal_title=J Exp Psychol Hum Percept Perform; citation_title=The relevance of action in perceiving affordances: perception of catchableness of fly balls; citation_author=R Oudejans, C Michaels, F Bakker, M Doln&#233;; citation_volume=22; citation_issue=4; citation_publication_date=1996; citation_pages=879; citation_doi=10.1037/0096-1523.22.4.879; citation_id=CR40"/>

    <meta name="citation_reference" content="citation_journal_title=Atten Percept Psychophys; citation_title=Auditory event perception: the source-perception loop for posture in human gait; citation_author=R Pastore, J Flint, J Gaston, M Solomon; citation_volume=70; citation_issue=1; citation_publication_date=2008; citation_pages=13-29; citation_doi=10.3758/PP.70.1.13; citation_id=CR41"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Visual Comput Graphics; citation_title=The design and evaluation of a large-scale real-walking locomotion interface; citation_author=T Peck, H Fuchs, M Whitton; citation_volume=18; citation_issue=7; citation_publication_date=2012; citation_pages=1053-1067; citation_doi=10.1109/TVCG.2011.289; citation_id=CR42"/>

    <meta name="citation_reference" content="citation_title=The experience economy; citation_publication_date=2011; citation_id=CR43; citation_author=J Pine; citation_author=J Gilmore; citation_publisher=Harvard Business Press"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Spatial presence and emotions during video game playing: Does it matter with whom you play?; citation_author=N Ravaja, T Saari, M Turpeinen, J Laarni, M Salminen, M Kivikangas; citation_volume=15; citation_issue=4; citation_publication_date=2006; citation_pages=381-392; citation_doi=10.1162/pres.15.4.381; citation_id=CR44"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=Perceiving affordances in virtual reality: influence of person and environmental properties in perception of standing on virtual grounds; citation_author=T Regia-Corte, M Marchal, G Cirio, A L&#233;cuyer; citation_volume=17; citation_issue=1; citation_publication_date=2013; citation_pages=1-12; citation_doi=10.1007/s10055-012-0216-3; citation_id=CR45"/>

    <meta name="citation_reference" content="citation_journal_title=CyberPsychol Behav; citation_title=Affective interactions using virtual reality: the link between presence and emotions; citation_author=G Riva, F Mantovani, C Capideville, A Preziosa, F Morganti, D Villani, A Gaggioli, C Botella, M Alca&#241;iz; citation_volume=10; citation_issue=1; citation_publication_date=2007; citation_pages=45-56; citation_doi=10.1089/cpb.2006.9993; citation_id=CR46"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Comput Human Interact; citation_title=The benefits of using a walking interface to navigate virtual environments; citation_author=R Ruddle, S Lessels; citation_volume=16; citation_issue=1; citation_publication_date=2009; citation_pages=5; citation_doi=10.1145/1502800.1502805; citation_id=CR47"/>

    <meta name="citation_reference" content="citation_journal_title=Commun Theory; citation_title=A new conception of spatial presence: once again, with feeling; citation_author=T Schubert; citation_volume=19; citation_issue=2; citation_publication_date=2009; citation_pages=161-187; citation_doi=10.1111/j.1468-2885.2009.01340.x; citation_id=CR48"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Presence and the sixth sense; citation_author=M Slater; citation_volume=11; citation_issue=4; citation_publication_date=2002; citation_pages=435-439; citation_doi=10.1162/105474602760204327; citation_id=CR49"/>

    <meta name="citation_reference" content="citation_journal_title=Philos Trans R Soc B Biol Sci; citation_title=Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments; citation_author=M Slater; citation_volume=364; citation_issue=1535; citation_publication_date=2009; citation_pages=3549-3557; citation_doi=10.1098/rstb.2009.0138; citation_id=CR50"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Comput Human Interact; citation_title=Taking steps: the influence of a walking technique on presence in virtual reality; citation_author=M Slater, M Usoh, A Steed; citation_volume=2; citation_issue=3; citation_publication_date=1995; citation_pages=201-219; citation_doi=10.1145/210079.210084; citation_id=CR51"/>

    <meta name="citation_reference" content="citation_journal_title=Anuario de Psicologia; citation_title=How we experience immersive virtual environments: the concept of presence and its measurement; citation_author=M Slater, B Lotto, MM Arnold, MV Sanchez-Vives; citation_volume=40; citation_issue=2; citation_publication_date=2009; citation_pages=193-210; citation_id=CR52"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Appl Percept; citation_title=Cyberwalk: enabling unconstrained omnidirectional walking through virtual environments; citation_author=J Souman, P Robuffo Giordano, M Schwaiger, I Frissen, T Th&#252;mmel, H Ulbrich, A Luca, H B&#252;lthoff, M Ernst; citation_volume=8; citation_issue=4; citation_publication_date=2011; citation_pages=25; citation_id=CR53"/>

    <meta name="citation_reference" content="citation_journal_title=Front Robot AI; citation_title=How to build an embodiment lab: achieving body representation illusions in virtual reality; citation_author=B Spanlang, J Normand, D Borland, K Kilteni, E Giannopoulos, A Pomes, M Gonzalez-Franco, D P&#233;rez Marcos, J Arroyo Palacios, X Muncunill, M Slater; citation_volume=1; citation_publication_date=2014; citation_pages=9; citation_doi=10.3389/frobt.2014.00009; citation_id=CR54"/>

    <meta name="citation_reference" content="citation_journal_title=Acoust Sci Technol; citation_title=Audiovisual multisensory integration; citation_author=C Spence; citation_volume=28; citation_issue=2; citation_publication_date=2007; citation_pages=61-70; citation_doi=10.1250/ast.28.61; citation_id=CR55"/>

    <meta name="citation_reference" content="citation_journal_title=Atten Percept Psychophys; citation_title=Crossmodal correspondences: a tutorial review; citation_author=C Spence; citation_volume=73; citation_issue=4; citation_publication_date=2011; citation_pages=971-995; citation_doi=10.3758/s13414-010-0073-7; citation_id=CR56"/>

    <meta name="citation_reference" content="citation_title=Human walking in virtual environments: perception, technology, and applications; citation_publication_date=2013; citation_id=CR57; citation_author=F Steinicke; citation_author=Y Visell; citation_author=J Campos; citation_author=A L&#233;cuyer; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Appl Acoust; citation_title=Custom made wireless systems for footstep sounds synthesis; citation_author=L Turchet; citation_volume=83; citation_publication_date=2014; citation_pages=22-31; citation_doi=10.1016/j.apacoust.2014.03.005; citation_id=CR58"/>

    <meta name="citation_reference" content="citation_journal_title=Appl Acoust; citation_title=Semantic congruence in audio-haptic simulation of footsteps; citation_author=L Turchet, S Serafin; citation_volume=75; citation_issue=1; citation_publication_date=2014; citation_pages=59-66; citation_doi=10.1016/j.apacoust.2013.06.016; citation_id=CR59"/>

    <meta name="citation_reference" content="Turchet L, Nordahl R, Berrezag A, Dimitrov S, Hayward V, Serafin S (2010) Audio-haptic physically based simulation of walking on different grounds. In: Proceedings of IEEE international workshop on multimedia signal processing, IEEE Press, pp 269&#8211;273"/>

    <meta name="citation_reference" content="Turchet L, Nilsson N, Serafin S (2012) Inside the boundaries of the physical world: audio-haptic feedback as support for the navigation in virtual environments. Haptics: Perception, Devices, Mobility, and Communication, vol 7282. Lecture Notes in Computer Science, Springer, Berlin, pp 577&#8211;588"/>

    <meta name="citation_reference" content="Usoh M, Arthur K, Whitton M, Bastos R, Steed A, Slater M, Brooks Jr F (1999) Walking 
                    
                      
                    
                    $$&gt;$$
                    
                      
                        
                      
                    
                  walking-in-place
                    
                      
                    
                    $$&gt;$$
                    
                      
                        
                      
                    
                   flying, in virtual environments. In: Proceedings of the 26th annual conference on computer graphics and interactive techniques, pp 359&#8211;364"/>

    <meta name="citation_reference" content="citation_title=Perfumery: the psychology and biology of fragrance; citation_publication_date=1988; citation_id=CR63; citation_publisher=Chapman &amp; Hall"/>

    <meta name="citation_reference" content="citation_title=Fragrance: the psychology and biology of perfume; citation_publication_date=1992; citation_id=CR64; citation_publisher=Chapman &amp; Hall"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Haptics; citation_title=Touch is everywhere: floor surfaces as ambient haptic interfaces; citation_author=Y Visell, A Law, JR Cooperstock; citation_volume=2; citation_publication_date=2009; citation_pages=148-159; citation_doi=10.1109/TOH.2009.31; citation_id=CR65"/>

    <meta name="citation_reference" content="citation_journal_title=J Exp Psychol Hum Percept Perform; citation_title=Perceiving affordances: visual guidance of stair climbing; citation_author=W Warren; citation_volume=10; citation_issue=5; citation_publication_date=1984; citation_pages=683; citation_doi=10.1037/0096-1523.10.5.683; citation_id=CR66"/>

    <meta name="citation_reference" content="citation_journal_title=J Exp Psychol Hum Percept Perform; citation_title=Visual guidance of walking through apertures: body-scaled information for affordances; citation_author=W Warren, S Whang; citation_volume=13; citation_issue=3; citation_publication_date=1987; citation_pages=371-383; citation_doi=10.1037/0096-1523.13.3.371; citation_id=CR67"/>

    <meta name="citation_reference" content="Yanagida Y, Kawato S, Noma H, Tomono A, Tesutani N (2004) Projection based olfactory display with nose tracking. In: IEEE virtual reality conference, IEEE, pp 43&#8211;50"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Presence as being-in-the-world; citation_author=P Zahorik, R Jenison; citation_volume=7; citation_issue=1; citation_publication_date=1998; citation_pages=78-89; citation_doi=10.1162/105474698565541; citation_id=CR69"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Visual Comput Graph; citation_title=Comparison of path visualizations and cognitive measures relative to travel technique in a virtual environment; citation_author=C Zanbaka, B Lok, S Babu, A Ulinski, L Hodges; citation_volume=11; citation_issue=6; citation_publication_date=2005; citation_pages=694-705; citation_doi=10.1109/TVCG.2005.92; citation_id=CR70"/>

    <meta name="citation_reference" content="Zanotto D, Turchet L, Boggs E, Agrawal S (2014) Solesound: towards a novel portable system for audio-tactile underfoot feedback. In: Proceedings of the 5th IEEE international conference on biomedical robotics and biomechatronics, IEEE, pp 193&#8211;198"/>

    <meta name="citation_author" content="Luca Turchet"/>

    <meta name="citation_author_email" content="tur@create.aau.dk"/>

    <meta name="citation_author_institution" content="Department of Architecture, Design and Media Technology, Aalborg University Copenhagen, Copenhagen, Denmark"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-015-0267-3&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2015/11/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-015-0267-3"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Designing presence for real locomotion in immersive virtual environments: an affordance-based experiential approach"/>
        <meta property="og:description" content="This paper describes a framework for designing systems for real locomotion in virtual environments (VEs) in order to achieve an intense sense of presence. The main outcome of the present research is a list of design features that the virtual reality technology should have in order to achieve such a goal. To identify these features, an approach based on the combination of two design strategies was followed. The first was based on the theory of affordances and was utilized to design a generic VE in which the affordances of the corresponding real environment could be evoked. The second was the experiential design applied to VEs and was utilized to create an experience of locomotion corresponding to that achievable in a real environment. These design strategies were chosen because of their potential to enhance the sense of presence. The proposed list of features can be utilized as an instrument that allows VE designers to evaluate the maturity of their systems and to pinpoint directions for future developments. A survey analysis was performed using the proposed framework, which involved three case studies to determine how many features of the proposed framework were present and their status. The result of such analysis represented a measure of the completeness of the systems design, of the affordances provided to the user, and a prediction of the sense of presence."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Designing presence for real locomotion in immersive virtual environments: an affordance-based experiential approach | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-015-0267-3","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Affordance, Experiential design, Locomotion interfaces, Virtual environments, Presence","kwrd":["Affordance","Experiential_design","Locomotion_interfaces","Virtual_environments","Presence"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-015-0267-3","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-015-0267-3","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=267;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-015-0267-3">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Designing presence for real locomotion in immersive virtual environments: an affordance-based experiential approach
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-015-0267-3.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-015-0267-3.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2015-07-10" itemprop="datePublished">10 July 2015</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Designing presence for real locomotion in immersive virtual environments: an affordance-based experiential approach</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Luca-Turchet" data-author-popup="auth-Luca-Turchet" data-corresp-id="c1">Luca Turchet<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Aalborg University Copenhagen" /><meta itemprop="address" content="grid.5117.2, 000000010742471X, Department of Architecture, Design and Media Technology, Aalborg University Copenhagen, A.C. Meyers Vænge 15, 2450, Copenhagen, Denmark" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 19</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">277</span>–<span itemprop="pageEnd">290</span>(<span data-test="article-publication-year">2015</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">707 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">8 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">1 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-015-0267-3/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>This paper describes a framework for designing systems for real locomotion in virtual environments (VEs) in order to achieve an intense sense of presence. The main outcome of the present research is a list of design features that the virtual reality technology should have in order to achieve such a goal. To identify these features, an approach based on the combination of two design strategies was followed. The first was based on the theory of affordances and was utilized to design a generic VE in which the affordances of the corresponding real environment could be evoked. The second was the experiential design applied to VEs and was utilized to create an experience of locomotion corresponding to that achievable in a real environment. These design strategies were chosen because of their potential to enhance the sense of presence. The proposed list of features can be utilized as an instrument that allows VE designers to evaluate the maturity of their systems and to pinpoint directions for future developments. A survey analysis was performed using the proposed framework, which involved three case studies to determine how many features of the proposed framework were present and their status. The result of such analysis represented a measure of the completeness of the systems design, of the affordances provided to the user, and a prediction of the sense of presence.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>In the last decades, much research has been done to design technology to allow users to navigate virtual environments (VEs) by means of real locomotion (i.e., the user’s act of physically moving from place to place), in particular real walking (Steinicke et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Steinicke F, Visell Y, Campos J, Lécuyer A (2013) Human walking in virtual environments: perception, technology, and applications. Springer, New York" href="/article/10.1007/s10055-015-0267-3#ref-CR57" id="ref-link-section-d18127e329">2013</a>). Various studies have provided evidence that real walking is the optimal interaction technique for navigation of immersive VEs since it produces a higher sense of immersion, increases naturalness, and improves task performance compared to other solutions (Slater et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Slater M, Usoh M, Steed A (1995) Taking steps: the influence of a walking technique on presence in virtual reality. ACM Trans Comput Human Interact 2(3):201–219" href="/article/10.1007/s10055-015-0267-3#ref-CR51" id="ref-link-section-d18127e332">1995</a>; Usoh et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Usoh M, Arthur K, Whitton M, Bastos R, Steed A, Slater M, Brooks Jr F (1999) Walking &#xA;                    &#xA;                      &#xA;                    &#xA;                    $$&gt;$$&#xA;                    &#xA;                      &#xA;                        &gt;&#xA;                      &#xA;                    &#xA;                  walking-in-place&#xA;                    &#xA;                      &#xA;                    &#xA;                    $$&gt;$$&#xA;                    &#xA;                      &#xA;                        &gt;&#xA;                      &#xA;                    &#xA;                   flying, in virtual environments. In: Proceedings of the 26th annual conference on computer graphics and interactive techniques, pp 359–364" href="/article/10.1007/s10055-015-0267-3#ref-CR62" id="ref-link-section-d18127e335">1999</a>; Zanbaka et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Zanbaka C, Lok B, Babu S, Ulinski A, Hodges L (2005) Comparison of path visualizations and cognitive measures relative to travel technique in a virtual environment. IEEE Trans Visual Comput Graph 11(6):694–705" href="/article/10.1007/s10055-015-0267-3#ref-CR70" id="ref-link-section-d18127e338">2005</a>; Ruddle and Lessels <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Ruddle R, Lessels S (2009) The benefits of using a walking interface to navigate virtual environments. ACM Trans Comput Human Interact 16(1):5" href="/article/10.1007/s10055-015-0267-3#ref-CR47" id="ref-link-section-d18127e341">2009</a>; Peck et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Peck T, Fuchs H, Whitton M (2012) The design and evaluation of a large-scale real-walking locomotion interface. IEEE Trans Visual Comput Graphics 18(7):1053–1067" href="/article/10.1007/s10055-015-0267-3#ref-CR42" id="ref-link-section-d18127e345">2012</a>).</p><p>Several technological solutions have been developed with the goal of providing users navigating the VE with sensory stimulations capable of producing a sensory flow that could lead to the same percept experienced during walking in the corresponding real environment [for recent review, see (Steinicke et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Steinicke F, Visell Y, Campos J, Lécuyer A (2013) Human walking in virtual environments: perception, technology, and applications. Springer, New York" href="/article/10.1007/s10055-015-0267-3#ref-CR57" id="ref-link-section-d18127e351">2013</a>)]. More generally, virtual reality (VR) technology aims to allow users to experience a reality different from the one they physically inhabit. This subjective experience of “being there” inside the virtual world is referred to as “presence” (Heeter <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Heeter C (1992) Being there: the subjective experience of presence. Presence Teleoperators Virtual Environ 1(2):262–271" href="/article/10.1007/s10055-015-0267-3#ref-CR21" id="ref-link-section-d18127e354">1992</a>). Slater and colleagues considered presence as “the propensity of people to respond to virtually generated sensory data as if they were real” (Slater et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Slater M, Lotto B, Arnold MM, Sanchez-Vives MV (2009) How we experience immersive virtual environments: the concept of presence and its measurement. Anuario de Psicologia 40(2):193–210" href="/article/10.1007/s10055-015-0267-3#ref-CR52" id="ref-link-section-d18127e357">2009</a>). They suggested that a user, experiencing an intense sense of presence in a virtual environment, would exhibit physiological and behavioral responses comparable to those produced while experiencing a similar real-world environment. In a subsequent work, Slater argued that users tend to respond realistically to situations and events portrayed within an immersive VE when both “place illusion” and “plausibility illusion” occur (Slater <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Slater M (2009) Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments. Philos Trans R Soc B Biol Sci 364(1535):3549–3557" href="/article/10.1007/s10055-015-0267-3#ref-CR50" id="ref-link-section-d18127e360">2009</a>). The former is the illusion of being in a place despite the sure knowledge of not being there. The latter is the illusion that what is apparently happening is really happening despite the sure knowledge that is not.</p><p>To achieve such illusions during the navigation of VEs by means of real locomotion, system design concepts are needed. Although several recommendations have been proposed to implement systems for real locomotion in VEs (Steinicke et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Steinicke F, Visell Y, Campos J, Lécuyer A (2013) Human walking in virtual environments: perception, technology, and applications. Springer, New York" href="/article/10.1007/s10055-015-0267-3#ref-CR57" id="ref-link-section-d18127e366">2013</a>), limited attention has been devoted to guidelines specifically defined to achieve an intense sense of presence. The objective of this paper is to address these guidelines. For this purpose, a framework is proposed, which encompasses both an ecological design based on Gibson’s theory of affordances (Gibson <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1979" title="Gibson J (1979) The ecological approach to visual perception. Houghton Miffin, New York" href="/article/10.1007/s10055-015-0267-3#ref-CR14" id="ref-link-section-d18127e369">1979</a>), and a holistic design based on experiential design (Pine and Gilmore <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Pine J, Gilmore J (2011) The experience economy. Harvard Business Press, Boston" href="/article/10.1007/s10055-015-0267-3#ref-CR43" id="ref-link-section-d18127e372">2011</a>; Chertoff et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Chertoff D, Schatz S, McDaniel R, Bowers C (2008) Improving presence theory through experiential design. Presence Teleoperators Virtual Environ 17(4):405–413" href="/article/10.1007/s10055-015-0267-3#ref-CR5" id="ref-link-section-d18127e375">2008</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Chertoff DB, Goldiez B, LaViola JJ (2010) Virtual experience test: a virtual environment evaluation questionnaire. In: Proceedings the IEEE virtual reality conference, pp 103–110" href="/article/10.1007/s10055-015-0267-3#ref-CR6" id="ref-link-section-d18127e378">2010</a>).</p><p>On the one hand, for a VE to be meaningful in the ecological sense, users must be provided with coherent relations between perception and action. Nevertheless, the ecological validity of a VE is largely contingent on designers’ accurate understanding of the nature of its affordances. Interestingly, research has demonstrated that affordances of a real environment are perceived in body-scaled terms (e.g., height, width, leg length, running speed), thus indicating that individuals perceive the properties of the environment in relation to themselves (Warren <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1984" title="Warren W (1984) Perceiving affordances: visual guidance of stair climbing. J Exp Psychol Hum Percept Perform 10(5):683" href="/article/10.1007/s10055-015-0267-3#ref-CR66" id="ref-link-section-d18127e384">1984</a>; Mark <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Mark LS (1987) Eyeheight-scaled information about affordances: a study of sitting and stair climbing. J Exp Psychol Hum Percept Perform 13(3):361–370" href="/article/10.1007/s10055-015-0267-3#ref-CR37" id="ref-link-section-d18127e387">1987</a>; Warren and Whang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Warren W, Whang S (1987) Visual guidance of walking through apertures: body-scaled information for affordances. J Exp Psychol Hum Percept Perform 13(3):371–383" href="/article/10.1007/s10055-015-0267-3#ref-CR67" id="ref-link-section-d18127e390">1987</a>; Oudejans et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Oudejans R, Michaels C, Bakker F, Dolné M (1996) The relevance of action in perceiving affordances: perception of catchableness of fly balls. J Exp Psychol Hum Percept Perform 22(4):879" href="/article/10.1007/s10055-015-0267-3#ref-CR40" id="ref-link-section-d18127e393">1996</a>; Fajen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Fajen B (2013) Affordance perception and the visual control of locomotion. In: Human walking in virtual environments. Springer, New York, pp 79–98" href="/article/10.1007/s10055-015-0267-3#ref-CR8" id="ref-link-section-d18127e396">2013</a>). On the other hand, designing the experience of the user requires the understanding of all the factors involved in the user’s interaction with the VE, not only those related to the sensory stimulation, but also those related, for example, to cognitive and affective aspects. These considerations motivate the research reported in the present study. By combining the ecological approach with the experiential one, this work attempts to answer both the need to integrate a comprehensive theory of locomotion perception into VE design and the call of Chertoff et al. to: “begin to explore the holistic experience of participating in mediated environments” (Chertoff et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Chertoff D, Schatz S, McDaniel R, Bowers C (2008) Improving presence theory through experiential design. Presence Teleoperators Virtual Environ 17(4):405–413" href="/article/10.1007/s10055-015-0267-3#ref-CR5" id="ref-link-section-d18127e400">2008</a>).</p><p>The main outcome of the present research is a list of design features that VR technology should have for the purpose of achieving strong place and plausibility illusions during real locomotion in a generic VE. Such a list can be utilized as an instrument that allows VE designers to evaluate what aspects of their technology need to be further developed, such that future iterations can be improved.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Affordances in VR</h2><div class="c-article-section__content" id="Sec2-content"><p>The ecological approach to perception and action has been considered as promising for designing VEs capable of providing a realistic experience (Flach and Holden <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Flach J, Holden J (1998) The reality of experience: Gibson’s way. Presence Teleoperators Virtual Environ 7(1):90–95" href="/article/10.1007/s10055-015-0267-3#ref-CR10" id="ref-link-section-d18127e415">1998</a>; Zahorik and Jenison <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Zahorik P, Jenison R (1998) Presence as being-in-the-world. Presence Teleoperators Virtual Environ 7(1):78–89" href="/article/10.1007/s10055-015-0267-3#ref-CR69" id="ref-link-section-d18127e418">1998</a>; Gross et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Gross D, Stanney K, Cohn L (2005) Evoking affordances in virtual environments via sensory-stimuli substitution. Presence Teleoperators Virtual Environ 14(4):482–491" href="/article/10.1007/s10055-015-0267-3#ref-CR18" id="ref-link-section-d18127e421">2005</a>; Schubert <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Schubert T (2009) A new conception of spatial presence: once again, with feeling. Commun Theory 19(2):161–187" href="/article/10.1007/s10055-015-0267-3#ref-CR48" id="ref-link-section-d18127e424">2009</a>). 
However, so far only a handful of studies have investigated the role of affordances in VR contexts and in particular in locomotion in VE (Fajen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Fajen B (2013) Affordance perception and the visual control of locomotion. In: Human walking in virtual environments. Springer, New York, pp 79–98" href="/article/10.1007/s10055-015-0267-3#ref-CR8" id="ref-link-section-d18127e427">2013</a>). With the aim of providing guidelines to VE designers for generating more ecologically valid designs, Gross et al. presented a conceptual model for evoking affordances in VEs via sensory substitution schemes (Gross et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Gross D, Stanney K, Cohn L (2005) Evoking affordances in virtual environments via sensory-stimuli substitution. Presence Teleoperators Virtual Environ 14(4):482–491" href="/article/10.1007/s10055-015-0267-3#ref-CR18" id="ref-link-section-d18127e431">2005</a>). In addition, they argued that for the realization of affordances in VE, sufficiency in sensory stimulation, perception of body stature, and action possibilities are required.</p><p>Lepecq et al. asserted that the degree of place illusion in a VE can be evaluated by its actual affordances for action (Lepecq et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lepecq J, Bringoux L, Pergandi J, Coyle T, Mestre D (2009) Afforded actions as a behavioral assessment of physical presence in virtual environments. Virtual Reality 13(3):141–151" href="/article/10.1007/s10055-015-0267-3#ref-CR31" id="ref-link-section-d18127e437">2009</a>). To test such a hypothesis, they performed an experiment in which subjects were asked to walk straight through a virtual aperture of variable widths with a self-selected speed. Shoulders positions and rotations during walking through the aperture were measured based on the use of reflective markers. The analysis of the collected data showed that subjects exhibited in the VE the basic behavioral properties already observed in corresponding real environments for the same task of walking through a real aperture (Warren and Whang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Warren W, Whang S (1987) Visual guidance of walking through apertures: body-scaled information for affordances. J Exp Psychol Hum Percept Perform 13(3):371–383" href="/article/10.1007/s10055-015-0267-3#ref-CR67" id="ref-link-section-d18127e440">1987</a>). Their study, therefore, suggested that every afforded action could be a potential tool for sensorimotor assessment of place illusion in a VE. Along the same line, Regia-Corte et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Regia-Corte T, Marchal M, Cirio G, Lécuyer A (2013) Perceiving affordances in virtual reality: influence of person and environmental properties in perception of standing on virtual grounds. Virtual Real 17(1):1–12" href="/article/10.1007/s10055-015-0267-3#ref-CR45" id="ref-link-section-d18127e443">2013</a>) studied the perception of affordances in VEs considering the case of standing on a slanted surface with different textures (woody or icy). Results showed that subjects were capable of exploiting virtual information about surface friction in order to judge whether a slanted surface supported an upright stance. More importantly, subjects’ evaluations were comparable to those reported in previous studies conducted in real environments (Fitzpatrick et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Fitzpatrick P, Carello C, Schmidt R, Corey D (1994) Haptic and visual perception of an affordance for upright posture. Ecol Psychol 6(4):265–287" href="/article/10.1007/s10055-015-0267-3#ref-CR9" id="ref-link-section-d18127e446">1994</a>). It is important to consider that affordances in VEs have been proved to be profoundly affected by the properties of the utilized interfaces (Grechkin et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Grechkin T, Plumert J, Kearney J (2014) Dynamic affordances in embodied interactive systems: the role of display and mode of locomotion. IEEE Trans Visual Comput Graph 20(4):596–605" href="/article/10.1007/s10055-015-0267-3#ref-CR17" id="ref-link-section-d18127e449">2014</a>).</p></div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Experiential design</h2><div class="c-article-section__content" id="Sec3-content"><p>Experiential design (ED) is an approach used in marketing to create strategically compelling and memorable experiences (Pine and Gilmore <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Pine J, Gilmore J (2011) The experience economy. Harvard Business Press, Boston" href="/article/10.1007/s10055-015-0267-3#ref-CR43" id="ref-link-section-d18127e460">2011</a>). It consists of the process of creating a desired consumers’ experience. Such a process leverages the consumers’ previous experience stored in memory in order to create positive associations between it and the product. Five dimensions of the experience are considered in a holistic framework: sensory (i.e., sensorial stimulations), cognitive (i.e., tasks), affective (i.e., emotional connections), active (i.e., sense of agency), and relational (i.e., social aspects). By designing such a holistic experience, the consumers can create meaningful emotional and social connections to a product: They can recall episodic memories about the designed experience, and if they enjoyed the artifacts of that experience, will build positive associations with the product. Therefore, a fundamental tenet of ED is considering how previous experiences can be integrated into new experiences. When consumers are subjected to new experiences, they use experiences stored in memory to make new decisions and process new information.</p><p>In the context of VR, ED has been proposed as a method to enhance presence in VEs (Chertoff et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Chertoff D, Schatz S, McDaniel R, Bowers C (2008) Improving presence theory through experiential design. Presence Teleoperators Virtual Environ 17(4):405–413" href="/article/10.1007/s10055-015-0267-3#ref-CR5" id="ref-link-section-d18127e466">2008</a>). Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0267-3#Tab1">1</a> (middle column) reports the five dimensions of ED applied toward VEs, as illustrated in Chertoff et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Chertoff DB, Goldiez B, LaViola JJ (2010) Virtual experience test: a virtual environment evaluation questionnaire. In: Proceedings the IEEE virtual reality conference, pp 103–110" href="/article/10.1007/s10055-015-0267-3#ref-CR6" id="ref-link-section-d18127e472">2010</a>). By designing a holistic experience in which all these dimensions are integrated, a user can fill the information not provided by the VE by recalling his previous experience. According to Slater, this process has the potential to increase the user’s sense of presence (Slater <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Slater M (2002) Presence and the sixth sense. Presence Teleoperators Virtual Environ 11(4):435–439" href="/article/10.1007/s10055-015-0267-3#ref-CR49" id="ref-link-section-d18127e475">2002</a>). As a consequence, better performances can be achieved (Barfield et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Barfield W, Zeltzer D, Sheridan T, Slater M (1995) Presence and performance within virtual environments. In: Virtual environments and advanced interface design pp 473–513" href="/article/10.1007/s10055-015-0267-3#ref-CR1" id="ref-link-section-d18127e478">1995</a>). The enhancement of the sense of presence theorized in Chertoff et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Chertoff D, Schatz S, McDaniel R, Bowers C (2008) Improving presence theory through experiential design. Presence Teleoperators Virtual Environ 17(4):405–413" href="/article/10.1007/s10055-015-0267-3#ref-CR5" id="ref-link-section-d18127e482">2008</a>) was experimentally confirmed in the study reported in Chertoff et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference (2010" title="Chertoff DB, Goldiez B, LaViola JJ (2010) Virtual experience test: a virtual environment evaluation questionnaire. In: Proceedings the IEEE virtual reality conference, pp 103–110" href="/article/10.1007/s10055-015-0267-3#ref-CR6" id="ref-link-section-d18127e485">(2010</a>). Participants were asked to interact with a commercial video game configured in order to utilize the dimensions of ED in different ways and to complete presence questionnaires. Results showed a significant increase in presence for the game configurations that made better use of the five dimensions in the design process. The same study presented and validated the virtual experience test, a questionnaire based upon the five dimensions of ED. The validation proved its effective usage to measure holistic VE experiences and showed that non-sensory components of experience are also related to presence. Inspired by the description of the dimensions reported in Chertoff et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Chertoff DB, Goldiez B, LaViola JJ (2010) Virtual experience test: a virtual environment evaluation questionnaire. In: Proceedings the IEEE virtual reality conference, pp 103–110" href="/article/10.1007/s10055-015-0267-3#ref-CR6" id="ref-link-section-d18127e488">2010</a>), the right column in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0267-3#Tab1">1</a> reports the author’s application of the ED dimensions toward locomotion in VEs.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Dimensions of experiential design</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-015-0267-3/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     </div></div></section><section aria-labelledby="Sec4"><div class="c-article-section" id="Sec4-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec4">Affordance-based experiential design</h2><div class="c-article-section__content" id="Sec4-content"><p>Taken together, the studies reported in Gross et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Gross D, Stanney K, Cohn L (2005) Evoking affordances in virtual environments via sensory-stimuli substitution. Presence Teleoperators Virtual Environ 14(4):482–491" href="/article/10.1007/s10055-015-0267-3#ref-CR18" id="ref-link-section-d18127e650">2005</a>), Lepecq et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lepecq J, Bringoux L, Pergandi J, Coyle T, Mestre D (2009) Afforded actions as a behavioral assessment of physical presence in virtual environments. Virtual Reality 13(3):141–151" href="/article/10.1007/s10055-015-0267-3#ref-CR31" id="ref-link-section-d18127e653">2009</a>), and Regia-Corte et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Regia-Corte T, Marchal M, Cirio G, Lécuyer A (2013) Perceiving affordances in virtual reality: influence of person and environmental properties in perception of standing on virtual grounds. Virtual Real 17(1):1–12" href="/article/10.1007/s10055-015-0267-3#ref-CR45" id="ref-link-section-d18127e656">2013</a>) indicated that affordances can be evoked in VEs and that their perception in the synthetic world can be influenced by both environmental and body properties. Starting from those findings, the concept of affordances was applied to the design of locomotion interfaces for immersive VEs. The first design objective was to evoke in a VE the affordances of the corresponding real environment.</p><p>The underlying methodology used in this work is that of affordance-based design (ABD) developed by Maier and Fadel (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009a" title="Maier J, Fadel G (2009a) Affordance based design: a relational theory for design. Res Eng Design 20(1):13–27" href="/article/10.1007/s10055-015-0267-3#ref-CR33" id="ref-link-section-d18127e662">2009a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Maier J, Fadel G (2009b) Affordance-based design methods for innovative design, redesign and reverse engineering. Res Eng Design 20(4):225–239" href="/article/10.1007/s10055-015-0267-3#ref-CR34" id="ref-link-section-d18127e665">b</a>). Such an approach describes and explains the relationships between users and designed artifacts and allows designers to analyze concepts with respect to desired and undesired affordances in early phases of the design process. In more detail, the proposed design aimed to avoid hidden affordances (i.e., actions that are possible but are not perceived as such by actors) and false affordances (i.e., actions that are not possible but are perceived by actors as possible), as defined in Gaver (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Gaver W (1991) Technology affordances. In: Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, New York, pp 79–84" href="/article/10.1007/s10055-015-0267-3#ref-CR13" id="ref-link-section-d18127e668">1991</a>): Particular attention was indeed devoted to the identification of the ideal set of user’s valid actions that have the potential to occur in the VE. The term “valid actions” is here intended according to the definition given by Slater as “the actions that a participant can take that can result in changes in perception or changes to the environment” (Slater <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Slater M (2009) Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments. Philos Trans R Soc B Biol Sci 364(1535):3549–3557" href="/article/10.1007/s10055-015-0267-3#ref-CR50" id="ref-link-section-d18127e671">2009</a>). In addition, the design took into account the guidelines proposed in McGrenere and Ho (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="McGrenere J, Ho W (2000) Affordances: clarifying and evolving a concept. Graph Interface 2000:179–186" href="/article/10.1007/s10055-015-0267-3#ref-CR38" id="ref-link-section-d18127e674">2000</a>), Hartson (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Hartson R (2003) Cognitive, physical, sensory, and functional affordances in interaction design. Behav Inf Technol 22(5):315–338" href="/article/10.1007/s10055-015-0267-3#ref-CR19" id="ref-link-section-d18127e678">2003</a>), and Gross et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Gross D, Stanney K, Cohn L (2005) Evoking affordances in virtual environments via sensory-stimuli substitution. Presence Teleoperators Virtual Environ 14(4):482–491" href="/article/10.1007/s10055-015-0267-3#ref-CR18" id="ref-link-section-d18127e681">2005</a>).</p><p>The reason to adopt the ABD is that it should allow users to readily perceive which are the possible actions during the real locomotion in a VE, as well as to exploit the same skills acquired via real-world actions associated with locomotion (Flach and Holden <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Flach J, Holden J (1998) The reality of experience: Gibson’s way. Presence Teleoperators Virtual Environ 7(1):90–95" href="/article/10.1007/s10055-015-0267-3#ref-CR10" id="ref-link-section-d18127e687">1998</a>; Gross et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Gross D, Stanney K, Cohn L (2005) Evoking affordances in virtual environments via sensory-stimuli substitution. Presence Teleoperators Virtual Environ 14(4):482–491" href="/article/10.1007/s10055-015-0267-3#ref-CR18" id="ref-link-section-d18127e690">2005</a>). A VE in which all the affordances of the corresponding real environment are evoked would produce a high degree of place illusion (Lepecq et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lepecq J, Bringoux L, Pergandi J, Coyle T, Mestre D (2009) Afforded actions as a behavioral assessment of physical presence in virtual environments. Virtual Reality 13(3):141–151" href="/article/10.1007/s10055-015-0267-3#ref-CR31" id="ref-link-section-d18127e693">2009</a>). In addition, if the involved VR technology is capable of sufficiently stimulating the senses (Gross et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Gross D, Stanney K, Cohn L (2005) Evoking affordances in virtual environments via sensory-stimuli substitution. Presence Teleoperators Virtual Environ 14(4):482–491" href="/article/10.1007/s10055-015-0267-3#ref-CR18" id="ref-link-section-d18127e696">2005</a>), then strong plausibility illusions would occur.</p><p>On the other hand, ED provides a framework that can be applied to the design of VEs. Such a framework can complement ABD. As suggested by the results reported in Chertoff et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Chertoff DB, Goldiez B, LaViola JJ (2010) Virtual experience test: a virtual environment evaluation questionnaire. In: Proceedings the IEEE virtual reality conference, pp 103–110" href="/article/10.1007/s10055-015-0267-3#ref-CR6" id="ref-link-section-d18127e702">2010</a>), the design of a VE should be conceived considering a user’s holistic experience. Therefore, that holistic approach was applied to the design of locomotion interfaces for immersive VEs. The second design objective was thus to create an experience of locomotion corresponding to that achievable in a real environment.</p><p>To achieve the two objectives described above, a methodology to guide the design process was defined. It consisted of the following steps:</p><ol class="u-list-style-none">
                  <li>
                    <span class="u-custom-list-number">1.</span>
                    
                      <p>Identification of the affordances associated with locomotion in real environments that should be realized by the VR technology;</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">2.</span>
                    
                      <p>Identification of general objectives defining the user’s experience of locomotion in VEs;</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">3.</span>
                    
                      <p>Identification of features that VR technology should have in order to realize both the affordances determined in the first step and the content of the experience described in the second step;</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">4.</span>
                    
                      <p>Identification of the means to realize the features defined in the third step.</p>
                    
                  </li>
                </ol><p>The whole design process was conceived to be applied to a user’s locomotion experience in a VE as general as possible. Therefore, specific VR contexts (e.g., rehabilitation) are not the target. Nevertheless, by keeping general the scenario, such specific contexts are included. In the reminder of this section, the first three steps are addressed. The fourth step will be addressed in future research.</p><h3 class="c-article__sub-heading" id="Sec5">Affordance identification</h3><p>Two elements were considered to identify affordances associated with locomotion in real environments: the environment and the individual’s body. As far as the environment-related affordances are concerned, they were identified in the following categories:</p><p>
                           <i>Foot–floor interactions</i>: The floor affords different types of interactions by means of the actor’s feet. It affords an actor to produce steps, slip, brush the feet on it, interact with heel and toes as well as with different dynamics (e.g., strong or soft impacts), and, depending on the compliance of the surface material, sink.</p><p>
                           <i>Navigability</i>: The environment affords an actor to perform various navigation possibilities, such as to walk, jump, run, sprint, or limp; to slip, stumble, or fall down; to start and stop the locomotion at any time; to change the locomotion direction; to perform endless locomotion; to perform locomotion at different speeds; to climb or climb down.</p><p>
                           <i>Sensing</i>: As a result of the individual’s locomotion, the environment affords an immediate and synchronized multimodal feedback as well as changes in landscape, soundscape, weather conditions (e.g., temperature, humidity), and odors. It also affords movements of objects/organisms along tridimensional trajectories.</p><p>As far as the body-related affordances are concerned, they were identified in the following categories:</p><p>
                           <i>Body ownership</i>: The body affords to be perceived through visual cues (e.g., seeing the feet), auditory cues (e.g., footstep sounds or the sounds resulting from the rubbing of the clothes), as well as vestibular cues (e.g., perceiving the position of the feet).</p><p>
                           <i>Body wearability</i>: The body affords to wear clothes and shoes.</p><p>
                           <i>Body physiology</i>: The body affords to see and hear from a certain height from the ground. This depends on the stature and body posture (e.g., upright, stooped) to move toward one direction while gazing at another; to move with a specific pace that depends on the individual’s anthropomorphic features (e.g., gender, weight, leg length), locomotion style, and eventually presence of impairments.</p><p>It is interesting to notice the relations between the identified categories of affordances. For example, the affordances in the foot–floor interaction are related to the navigability affordances offered by the geometry of the environment. For instance, an environment affording walking actions affords steps. Similarly, the affordances of the body wearability are related to all the other affordances categories. For instance, the fact that the body affords to wear a specific type of shoe is linked to the possibility of perceiving the body as well as the environment through specific footstep sounds, which in turn are also related to the types of interactions afforded by the floor. Those sounds are perceived according to the affordances given by the users anthropomorphic features. Moreover, that particular type of shoes can affect the speed of navigation.</p><h3 class="c-article__sub-heading" id="Sec6">Designing the user’s experience</h3><p>The design of the user’s experience of real locomotion in a VE produced the following objectives according to the five dimensions of ED:</p><p>
                           <i>Sensory</i>: The user is provided with sufficient as well as temporally, spatially, and semantically congruent multisensory stimuli representing his/her own body, the environment, and the interaction of his/her body with the environment.</p><p>
                           <i>Cognitive</i>: The user is free to move and perceives his/her body during locomotion. He/she perceives that the environment reacts to his/her action in a way consistent with real-world interactions, as well as that the environment produces events that are in agreement with expectations based on his/her prior experience.</p><p>
                           <i>Affective</i>: During locomotion, the user can express through his/her body movements, his/her emotions. The environment is effective in inducing an emotional state (including the neutral state where no particular emotion is induced).</p><p>
                           <i>Active</i>: During locomotion, the user can perceive his/her own anthropomorphic features (e.g., stature, gender, weight), footwear, clothes, and body posture.</p><p>
                           <i>Relational</i>: The user can interact with other agents (animals, humans, other users) if present in the environment and perceives that his/her interaction with those agents is consistent with real-world interactions.</p><p>At the basis of the identification of these objectives, there were several results from both presence and perception research. Specifically, from the former, results concerning the causes for which presence occurs were taken into account (Lee <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Lee K (2004) Why presence occurs: evolutionary psychology, media equation, and presence. Presence Teleoperators Virtual Environ 13(4):494–505" href="/article/10.1007/s10055-015-0267-3#ref-CR30" id="ref-link-section-d18127e848">2004</a>; Harvey and Sanchez-Vives <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Harvey M, Sanchez-Vives M (2005) The binding problem in presence research. Presence Teleoperators Virtual Environ 14(5):616–621" href="/article/10.1007/s10055-015-0267-3#ref-CR20" id="ref-link-section-d18127e851">2005</a>). From the latter, results concerning multisensory perception, especially those related to locomotion in real and virtual environments, were considered (Steinicke et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Steinicke F, Visell Y, Campos J, Lécuyer A (2013) Human walking in virtual environments: perception, technology, and applications. Springer, New York" href="/article/10.1007/s10055-015-0267-3#ref-CR57" id="ref-link-section-d18127e854">2013</a>).</p><p>As far as the sensory dimension is concerned, on the one hand, the listed objectives were motivated by results indicating the importance of providing stimuli from different sensory modalities on the sense of presence in VEs (Dinh et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Dinh H, Walker N, Hodges L, Song C, Kobayashi A (1999) Evaluating the importance of multi-sensory input on memory and the sense of presence in virtual environments. In: IEEE virtual reality conference, pp 222–228" href="/article/10.1007/s10055-015-0267-3#ref-CR7" id="ref-link-section-d18127e860">1999</a>; Biocca et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Biocca F, Inque Y, Polinsky H, Lee A, Tang A (2002) Visual cues and virtual touch: role of visual stimuli and intersensory integration in cross-modal haptic illusions and the sense of presence. In: Proceedings of presence, pp 410–428" href="/article/10.1007/s10055-015-0267-3#ref-CR2" id="ref-link-section-d18127e863">2002</a>; Larsson et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Larsson P, Väljamäe A, Västfjäll D, Tajadura-Jiménez A, Kleiner M (2010) Auditory-induced presence in mixed reality environments and related technology. In: The engineering of mixed reality systems. Springer, New York, pp 143–163" href="/article/10.1007/s10055-015-0267-3#ref-CR29" id="ref-link-section-d18127e866">2010</a>; Fröhlich and Wachsmuth <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Fröhlich J, Wachsmuth I (2013) The visual, the auditory and the haptic—a user study on combining modalities in virtual worlds. In: Shumaker R (ed) Virtual, augmented and mixed reality. Designing and developing virtual and augmented environments, Lecture Notes in Computer Science, vol 8021. Springer, New York, pp 159–168" href="/article/10.1007/s10055-015-0267-3#ref-CR12" id="ref-link-section-d18127e869">2013</a>). On the other hand, those objectives were derived from the fact that temporal, spatial, and semantic coherences are important factors for multisensory integration (Spence <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Spence C (2007) Audiovisual multisensory integration. Acoust Sci Technol 28(2):61–70" href="/article/10.1007/s10055-015-0267-3#ref-CR55" id="ref-link-section-d18127e872">2007</a>; Calvert et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Calvert G, Spence C, Stein B (2004) The handbook of multisensory processes. MIT press, Cambridge" href="/article/10.1007/s10055-015-0267-3#ref-CR4" id="ref-link-section-d18127e876">2004</a>): Incoherence between stimuli provided to different sensory modalities affects negatively their binding into a unitary percept and this results in breaks in presence (Harvey and Sanchez-Vives <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Harvey M, Sanchez-Vives M (2005) The binding problem in presence research. Presence Teleoperators Virtual Environ 14(5):616–621" href="/article/10.1007/s10055-015-0267-3#ref-CR20" id="ref-link-section-d18127e879">2005</a>). In addition, the objective of rendering the user’s body was supported by the importance of the feeling of body ownership for the sense of presence, as highlighted in Slater (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Slater M (2009) Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments. Philos Trans R Soc B Biol Sci 364(1535):3549–3557" href="/article/10.1007/s10055-015-0267-3#ref-CR50" id="ref-link-section-d18127e882">2009</a>) and Spanlang et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Spanlang B, Normand J, Borland D, Kilteni K, Giannopoulos E, Pomes A, Gonzalez-Franco M, Pérez Marcos D, Arroyo Palacios J, Muncunill X, Slater M (2014) How to build an embodiment lab: achieving body representation illusions in virtual reality. Front Robot AI 1:9" href="/article/10.1007/s10055-015-0267-3#ref-CR54" id="ref-link-section-d18127e885">2014</a>).</p><p>The objectives resulting from the cognitive dimension were also supported by results motivating the objectives of the sensory dimension. Particular attention was devoted to the semantic congruence, especially for the case of foot–floor interactions (Giordano et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Giordano B, Visell Y, Yao HY, Hayward V, Cooperstock J, McAdams S (2012) Identification of walked-upon materials in auditory, kinesthetic, haptic and audio-haptic conditions. J Acoust Soc Am 131:4002–4012" href="/article/10.1007/s10055-015-0267-3#ref-CR16" id="ref-link-section-d18127e891">2012</a>; Turchet and Serafin <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Turchet L, Serafin S (2014) Semantic congruence in audio-haptic simulation of footsteps. Appl Acoust 75(1):59–66" href="/article/10.1007/s10055-015-0267-3#ref-CR59" id="ref-link-section-d18127e894">2014</a>). In addition, cross-modal correspondences between stimulus features in different sensory modalities were taken into account as a factor relevant for multisensory integration [for a review, see (Spence <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Spence C (2011) Crossmodal correspondences: a tutorial review. Atten Percept Psychophys 73(4):971–995" href="/article/10.1007/s10055-015-0267-3#ref-CR56" id="ref-link-section-d18127e897">2011</a>)] and, therefore, related to presence (Harvey and Sanchez-Vives <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Harvey M, Sanchez-Vives M (2005) The binding problem in presence research. Presence Teleoperators Virtual Environ 14(5):616–621" href="/article/10.1007/s10055-015-0267-3#ref-CR20" id="ref-link-section-d18127e900">2005</a>).</p><p>Regarding the affective dimension, firstly the listed objectives were based on the results indicating the relationship between presence and emotions (Riva et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Riva G, Mantovani F, Capideville C, Preziosa A, Morganti F, Villani D, Gaggioli A, Botella C, Alcañiz M (2007) Affective interactions using virtual reality: the link between presence and emotions. CyberPsychol Behav 10(1):45–56" href="/article/10.1007/s10055-015-0267-3#ref-CR46" id="ref-link-section-d18127e906">2007</a>), and between presence and sense of arousal (Heeter <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Heeter C (1995) Communication research on consumer vr. Communication in the age of virtual reality, pp 191–218" href="/article/10.1007/s10055-015-0267-3#ref-CR22" id="ref-link-section-d18127e909">1995</a>). Secondly, they were motivated by results reported in Giordano and Bresin (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Giordano B, Bresin R (2006) Walking and playing: What’s the origin of emotional expressiveness in music? In: Proceedings of the 9th international conference on music perception &amp; cognition, p 436" href="/article/10.1007/s10055-015-0267-3#ref-CR15" id="ref-link-section-d18127e912">2006</a>), which investigated the auditory recognition of walks performed with different emotional intentions. Such findings showed that strong similarities were present between walking and musical expression of emotions with respect to acoustical variables such as temporal evolution and sound level. Thirdly, they were supported by findings that showed how properties of the environment are capable of altering a person’s emotional state [for example, odors can produce changes in the mood state (Van Toller and Dodd <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Van Toller S, Dodd G (eds) (1988) Perfumery: the psychology and biology of fragrance. Chapman &amp; Hall, London" href="/article/10.1007/s10055-015-0267-3#ref-CR63" id="ref-link-section-d18127e915">1988</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Van Toller S, Dodd G (eds) (1992) Fragrance: the psychology and biology of perfume. Chapman &amp; Hall, London" href="/article/10.1007/s10055-015-0267-3#ref-CR64" id="ref-link-section-d18127e918">1992</a>)].</p><p>The objectives related to the active dimension, on the one hand, were supported by results showing that footstep sounds convey information about the gender (Li et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Li XF, Logan RJ, Pastore RE (1991) Perception of acoustic source characteristics: walking sounds. J Acoust Soc Am 90(6):3036–3049" href="/article/10.1007/s10055-015-0267-3#ref-CR32" id="ref-link-section-d18127e925">1991</a>), the footwear sole hardness (Giordano and Bresin <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Giordano B, Bresin R (2006) Walking and playing: What’s the origin of emotional expressiveness in music? In: Proceedings of the 9th international conference on music perception &amp; cognition, p 436" href="/article/10.1007/s10055-015-0267-3#ref-CR15" id="ref-link-section-d18127e928">2006</a>), the identity of a person (Mäkelä et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Mäkelä K, Hakulinen J, Turunen M (2003) The use of walking sounds in supporting awareness. In: Proceedings of ICAD, pp 144–147" href="/article/10.1007/s10055-015-0267-3#ref-CR35" id="ref-link-section-d18127e931">2003</a>), and even his/her body posture (e.g., upright, stooped) (Pastore et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Pastore R, Flint J, Gaston J, Solomon M (2008) Auditory event perception: the source-perception loop for posture in human gait. Atten Percept Psychophys 70(1):13–29" href="/article/10.1007/s10055-015-0267-3#ref-CR41" id="ref-link-section-d18127e934">2008</a>). On the other hand, they were supported by results indicating that affordances of an environment are perceived in body-scaled terms (Warren <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1984" title="Warren W (1984) Perceiving affordances: visual guidance of stair climbing. J Exp Psychol Hum Percept Perform 10(5):683" href="/article/10.1007/s10055-015-0267-3#ref-CR66" id="ref-link-section-d18127e937">1984</a>; Mark <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Mark LS (1987) Eyeheight-scaled information about affordances: a study of sitting and stair climbing. J Exp Psychol Hum Percept Perform 13(3):361–370" href="/article/10.1007/s10055-015-0267-3#ref-CR37" id="ref-link-section-d18127e941">1987</a>; Warren and Whang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Warren W, Whang S (1987) Visual guidance of walking through apertures: body-scaled information for affordances. J Exp Psychol Hum Percept Perform 13(3):371–383" href="/article/10.1007/s10055-015-0267-3#ref-CR67" id="ref-link-section-d18127e944">1987</a>; Oudejans et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Oudejans R, Michaels C, Bakker F, Dolné M (1996) The relevance of action in perceiving affordances: perception of catchableness of fly balls. J Exp Psychol Hum Percept Perform 22(4):879" href="/article/10.1007/s10055-015-0267-3#ref-CR40" id="ref-link-section-d18127e947">1996</a>). Finally, the objectives resulting from the relational dimension were based on results that showed that presence is higher in social contexts (Heeter <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Heeter C (1992) Being there: the subjective experience of presence. Presence Teleoperators Virtual Environ 1(2):262–271" href="/article/10.1007/s10055-015-0267-3#ref-CR21" id="ref-link-section-d18127e950">1992</a>; Ravaja et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Ravaja N, Saari T, Turpeinen M, Laarni J, Salminen M, Kivikangas M (2006) Spatial presence and emotions during video game playing: Does it matter with whom you play? Presence Teleoperators Virtual Environ 15(4):381–392" href="/article/10.1007/s10055-015-0267-3#ref-CR44" id="ref-link-section-d18127e953">2006</a>).</p><h3 class="c-article__sub-heading" id="Sec7">Design features identification</h3><p>The affordances identified by the ABD as well as the objectives resulting from ED were converted into a list of features for the VR technology involved in the simulation of the real locomotion in VEs. They are illustrated in Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0267-3#Tab2">2</a>, <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0267-3#Tab3">3</a>, and <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0267-3#Tab4">4</a>. The features were classified in three categories: “sensing features” (SF), i.e., those capable of detecting in real time various aspects of the user’s locomotion; “navigation features” (NF), i.e., those related to the exploration of the VE during locomotion; “display features” (DF), i.e., those involved in the interactive display of the multimodal feedback resulting from the user’s actions. The sensing features were further subdivided in “body tracking” (BT), i.e., the features related to the tracking of the relevant parts of the body, “foot–floor contact sensing” (FF), i.e., the features related to the sensing of various aspects of the interaction of the foot with the floor, and “multiple users tracking” (MUT), i.e., the features related to the tracking of multiple users navigating in the VE. The navigation features were further subdivided into “general navigation features” (G), i.e., those related to general aspects of the navigation in VEs, “locomotion” (L), i.e., those related to various aspects of locomotion, “exploration” (E), i.e., those related to the exploration of the VE. The display features were further subdivided into “general display features” (G), i.e., those related to general aspects of the feedback display, “perceptually convincing multimodal rendering” (MR), i.e., those related to various aspects of the multimodal stimulation, “multiple users rendering” (MUR), i.e., the features related to the rendering of multiple users navigating in the VE.</p><p>In addition to this, many of the identified features were heavily based on results emerging from the guidelines for the design of locomotion interfaces proposed in Steinicke et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Steinicke F, Visell Y, Campos J, Lécuyer A (2013) Human walking in virtual environments: perception, technology, and applications. Springer, New York" href="/article/10.1007/s10055-015-0267-3#ref-CR57" id="ref-link-section-d18127e976">2013</a>), the guidelines for body tracking and virtual body rendering proposed in Spanlang et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Spanlang B, Normand J, Borland D, Kilteni K, Giannopoulos E, Pomes A, Gonzalez-Franco M, Pérez Marcos D, Arroyo Palacios J, Muncunill X, Slater M (2014) How to build an embodiment lab: achieving body representation illusions in virtual reality. Front Robot AI 1:9" href="/article/10.1007/s10055-015-0267-3#ref-CR54" id="ref-link-section-d18127e979">2014</a>) in order to produce body ownership illusions, as well as the conditions for presence proposed in Slater et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Slater M, Lotto B, Arnold MM, Sanchez-Vives MV (2009) How we experience immersive virtual environments: the concept of presence and its measurement. Anuario de Psicologia 40(2):193–210" href="/article/10.1007/s10055-015-0267-3#ref-CR52" id="ref-link-section-d18127e982">2009</a>).</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 The identified sensing features</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-015-0267-3/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 The identified navigation features</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-015-0267-3/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 The identified display features</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-015-0267-3/tables/4"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        </div></div></section><section aria-labelledby="Sec8"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Practical application of the list of features</h2><div class="c-article-section__content" id="Sec8-content"><p>Although the proposed design process was heavily based on existing affordance, experiential design, and presence theory, it still requires validation to ensure that the features illustrated in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-015-0267-3#Sec7">4.3</a> are effective in pursuing the goal of achieving an intense sense of presence. To investigate the validity of such features, a proper study would consist of evaluating the sense of presence achieved by participants interacting with a system embedding all of them [for example, for this purpose the questionnaire proposed in Chertoff et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Chertoff DB, Goldiez B, LaViola JJ (2010) Virtual experience test: a virtual environment evaluation questionnaire. In: Proceedings the IEEE virtual reality conference, pp 103–110" href="/article/10.1007/s10055-015-0267-3#ref-CR6" id="ref-link-section-d18127e2085">2010</a>) could be used]. However, to date such system is not available since the technology required to implement all those features has not been developed yet.</p><p>Nevertheless, the identified features can be utilized as an instrument to evaluate the maturity of a system such that the greater the number of the developed features, the greater the predicted sense of presence. More importantly, by analyzing a system according to such list of features, it is possible to identify which aspects of the developed technology need further work. Therefore, hereinafter an application of the identified features is described with the aim of showing how they can be practically used. Three systems among the most advanced ones currently implemented were considered as case studies, along with their possible extensions achievable by integrating thoroughly additional technological solutions available today in other systems. They are briefly summarized below.</p><p>
                        <i>Shoe-based architecture (SBA)</i>. This system consists of a HMD, a pair of wired shoes enhanced with pressure sensors and vibrotactile actuators, a multichannel surround sound system with algorithms for sound sources tridimensional spatialization, and an optical motion capture system, which tracks markers placed on user’s head and feet to control the visual feedback and to inform the user about the boundaries of the tracked space (Nordahl et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Nordahl R, Serafin S, Turchet L, Nilsson N (2012) A multimodal architecture for simulating natural interactive walking in virtual environments. PsychNology J 9(3):245–268" href="/article/10.1007/s10055-015-0267-3#ref-CR39" id="ref-link-section-d18127e2097">2012</a>; Turchet et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Turchet L, Nilsson N, Serafin S (2012) Inside the boundaries of the physical world: audio-haptic feedback as support for the navigation in virtual environments. Haptics: Perception, Devices, Mobility, and Communication, vol 7282. Lecture Notes in Computer Science, Springer, Berlin, pp 577–588" href="/article/10.1007/s10055-015-0267-3#ref-CR61" id="ref-link-section-d18127e2100">2012</a>). The shoes’ pressure sensors and actuators are placed in correspondence of heel and toe. They are used to drive a physically based audio-tactile synthesis engine that simulates the act of walking on different surface materials (Turchet et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Turchet L, Nordahl R, Berrezag A, Dimitrov S, Hayward V, Serafin S (2010) Audio-haptic physically based simulation of walking on different grounds. In: Proceedings of IEEE international workshop on multimedia signal processing, IEEE Press, pp 269–273" href="/article/10.1007/s10055-015-0267-3#ref-CR60" id="ref-link-section-d18127e2103">2010</a>). However, no foot–floor dynamics are rendered and the HMD’s box produces an audible noise. Moreover, the navigation is limited by the wires of both HMD and shoes. Footstep sounds and soundscapes are displayed along tridimensional trajectories. The feet of the avatar of the user is visually displayed.</p><p>
                        <i>CyberWalk platform (CWP)</i>. This system consists of an omnidirectional treadmill which allows users to walk in a way very close to that of real world (Frissen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Frissen I, Campos J, Sreenivasa M, Ernst M (2013) Enabling unconstrained omnidirectional walking through virtual environments: an overview of the cyberwalk project. In: Human walking in virtual environments. Springer, New York, pp 113–144" href="/article/10.1007/s10055-015-0267-3#ref-CR11" id="ref-link-section-d18127e2112">2013</a>; Souman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Souman J, Robuffo Giordano P, Schwaiger M, Frissen I, Thümmel T, Ulbrich H, De Luca A, Bülthoff H, Ernst M (2011) Cyberwalk: enabling unconstrained omnidirectional walking through virtual environments. ACM Trans Appl Percept 8(4):25" href="/article/10.1007/s10055-015-0267-3#ref-CR53" id="ref-link-section-d18127e2115">2011</a>). Users are allowed to start and stop walking, vary their walking speed and direction, and walk endlessly in any direction. Running is possible for experienced users. However, slopes and local unevenness of the ground are not rendered. An optical tracking system is capable of full body tracking. The tracked position and orientation of the user’s head is used both for treadmill control and for visualization (provided through a HMD). Auditory feedback is also provided, and some demos have used the visualization of the user’s own avatar. Users are required to wear a safety harness connected to the ceiling, to prevent them from falling.</p><p>
                        <i>TreadPort Active Wind Tunnel (TPAWT)</i>. This system consists of the integration of the TreadPort locomotion interface (Hollerbach et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Hollerbach J, Xu Y, Christensen R, Jacobsen S (2000) Design specifications for the second generation sarcos treadport locomotion interface. In: Haptics symposium, proceedings of the ASME dynamic systems and control division, vol 69, pp 1293–1298" href="/article/10.1007/s10055-015-0267-3#ref-CR25" id="ref-link-section-d18127e2125">2000</a>) with a wind tunnel for atmospheric display (Kulkarni et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Kulkarni S, Fisher C, Pardyjak E, Minor M, Hollerbach J (2009) Wind display device for locomotion interface in a virtual environment. In: Proceedings of IEEE World haptics conference. IEEE, pp 184–189" href="/article/10.1007/s10055-015-0267-3#ref-CR27" id="ref-link-section-d18127e2128">2009</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Kulkarni S, Minor M, Deaver M, Pardyjak E, Hollerbach J (2012) Design, sensing, and control of a scaled wind tunnel for atmospheric display. IEEE Trans Mechatron 17(4):635–645" href="/article/10.1007/s10055-015-0267-3#ref-CR28" id="ref-link-section-d18127e2131">2012</a>). The TreadPort is composed by a CAVE-like visual interface, as well as a harness and a treadmill that provide accurate locomotion forces as a user walks through a virtual environment. The atmospheric display is capable of controlling wind speed and angle acting on a user in the environment. It can provide olfactory and radiant heat display, by injecting scent particles and warm air into the wind tunnel.</p><p>
                        <i>Extended SBA (XSBA)</i>. SBA can be integrated with a portable eyes tracking device and with visual (Bruder et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Bruder G, Steinicke F, Bolte B, Wieland P, Frenz H, Lappe M (2012) Exploiting perceptual limitations and illusions to support walking through virtual environments in confined physical spaces. Displays 34(2):132–141" href="/article/10.1007/s10055-015-0267-3#ref-CR3" id="ref-link-section-d18127e2140">2012</a>) or audio-visual (Peck et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Peck T, Fuchs H, Whitton M (2012) The design and evaluation of a large-scale real-walking locomotion interface. IEEE Trans Visual Comput Graphics 18(7):1053–1067" href="/article/10.1007/s10055-015-0267-3#ref-CR42" id="ref-link-section-d18127e2143">2012</a>) redirection techniques that can complement the system for redirection based on ecological audio-tactile feedback presented in Turchet et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Turchet L, Nilsson N, Serafin S (2012) Inside the boundaries of the physical world: audio-haptic feedback as support for the navigation in virtual environments. Haptics: Perception, Devices, Mobility, and Communication, vol 7282. Lecture Notes in Computer Science, Springer, Berlin, pp 577–588" href="/article/10.1007/s10055-015-0267-3#ref-CR61" id="ref-link-section-d18127e2146">2012</a>). The visual feedback could adopt the visual interaction techniques proposed by Marchal et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Marchal M, Lécuyer A, Cirio G, Bonnet L, Emily M (2010) Walking up and down in immersive virtual worlds: novel interactive techniques based on visual feedback. In: IEEE symposium on 3D user interfaces, pp 19–26" href="/article/10.1007/s10055-015-0267-3#ref-CR36" id="ref-link-section-d18127e2149">2010</a>) to generate illusions of walking up or down on uneven surfaces. The tracking system can be extended to achieve a full body detection. Recently, the shoes have been improved both at hardware and at software level by Zanotto et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Zanotto D, Turchet L, Boggs E, Agrawal S (2014) Solesound: towards a novel portable system for audio-tactile underfoot feedback. In: Proceedings of the 5th IEEE international conference on biomedical robotics and biomechatronics, IEEE, pp 193–198" href="/article/10.1007/s10055-015-0267-3#ref-CR71" id="ref-link-section-d18127e2153">2014</a>): They are equipped with better embedded actuators; a greater number of actuators is involved; inertial sensors have been added; the auditory feedback comes directly from the feet thanks to small loudspeakers placed on the side of each shoe; the system is fully portable (no wires link the shoes to a computer running the synthesis engine); different types of foot–floor interaction (e.g., walking step, jumping step, scuffs) as well as the foot–floor dynamics are rendered thanks to the interactive sonification (Hermann et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Hermann T, Hunt A, Neuhoff J (eds) (2011) The sonification handbook. Logos Publishing House, Berlin" href="/article/10.1007/s10055-015-0267-3#ref-CR23" id="ref-link-section-d18127e2156">2011</a>) of the data coming from the inertial sensors (Turchet <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Turchet L (2014) Custom made wireless systems for footstep sounds synthesis. Appl Acoust 83:22–31" href="/article/10.1007/s10055-015-0267-3#ref-CR58" id="ref-link-section-d18127e2159">2014</a>). In addition, it is possible to integrate the set of audio-tactile tiles developed by Visell et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Visell Y, Law A, Cooperstock JR (2009) Touch is everywhere: floor surfaces as ambient haptic interfaces. IEEE Trans Haptics 2:148–159" href="/article/10.1007/s10055-015-0267-3#ref-CR65" id="ref-link-section-d18127e2162">2009</a>) in order to create stronger tactile sensations about self-motion. Furthermore, SBA can be extended by adding systems for the display of scent (Yanagida et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Yanagida Y, Kawato S, Noma H, Tomono A, Tesutani N (2004) Projection based olfactory display with nose tracking. In: IEEE virtual reality conference, IEEE, pp 43–50" href="/article/10.1007/s10055-015-0267-3#ref-CR68" id="ref-link-section-d18127e2165">2004</a>), wind, and warmth (Hülsmann et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="&#xA;Hülsmann F, Mattar N, Fröhlich J, Wachsmuth I (2014) Simulating wind and warmth in virtual reality: conception, realization and evaluation for a cave environment. J Virtual Real Broadcast 11(10):1–20" href="/article/10.1007/s10055-015-0267-3#ref-CR26" id="ref-link-section-d18127e2168">2014</a>).</p><p>
                        <i>Extended CWP (XCWP)</i>. CWP can be integrated with a portable eyes tracking device, headphones, or a surround sound system with algorithms for sound sources tridimensional spatialization and with the audio-tactile shoes proposed by Zanotto et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Zanotto D, Turchet L, Boggs E, Agrawal S (2014) Solesound: towards a novel portable system for audio-tactile underfoot feedback. In: Proceedings of the 5th IEEE international conference on biomedical robotics and biomechatronics, IEEE, pp 193–198" href="/article/10.1007/s10055-015-0267-3#ref-CR71" id="ref-link-section-d18127e2177">2014</a>). Local unevenness of virtual terrains could be simulated thanks to solutions similar to the series of linear actuators underneath the belt involved in GSS. The visual feedback could adopt the visual interaction techniques proposed by Marchal et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Marchal M, Lécuyer A, Cirio G, Bonnet L, Emily M (2010) Walking up and down in immersive virtual worlds: novel interactive techniques based on visual feedback. In: IEEE symposium on 3D user interfaces, pp 19–26" href="/article/10.1007/s10055-015-0267-3#ref-CR36" id="ref-link-section-d18127e2180">2010</a>) to generate illusions of walking up or down on uneven surfaces. In addition, CWP can be extended by adding systems for the display of scent (Yanagida et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Yanagida Y, Kawato S, Noma H, Tomono A, Tesutani N (2004) Projection based olfactory display with nose tracking. In: IEEE virtual reality conference, IEEE, pp 43–50" href="/article/10.1007/s10055-015-0267-3#ref-CR68" id="ref-link-section-d18127e2183">2004</a>), wind, and warmth (Hülsmann et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="&#xA;Hülsmann F, Mattar N, Fröhlich J, Wachsmuth I (2014) Simulating wind and warmth in virtual reality: conception, realization and evaluation for a cave environment. J Virtual Real Broadcast 11(10):1–20" href="/article/10.1007/s10055-015-0267-3#ref-CR26" id="ref-link-section-d18127e2186">2014</a>).</p><p>
                        <i>Extended TPAWT (XTPAWT)</i>. TPAWT can be integrated with headphones or a surround sound system with algorithms for sound sources tridimensional spatialization and with the audio-tactile shoes proposed by Zanotto et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Zanotto D, Turchet L, Boggs E, Agrawal S (2014) Solesound: towards a novel portable system for audio-tactile underfoot feedback. In: Proceedings of the 5th IEEE international conference on biomedical robotics and biomechatronics, IEEE, pp 193–198" href="/article/10.1007/s10055-015-0267-3#ref-CR71" id="ref-link-section-d18127e2195">2014</a>). In addition, it can be extended by adding the warmth display presented by Hülsmann et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="&#xA;Hülsmann F, Mattar N, Fröhlich J, Wachsmuth I (2014) Simulating wind and warmth in virtual reality: conception, realization and evaluation for a cave environment. J Virtual Real Broadcast 11(10):1–20" href="/article/10.1007/s10055-015-0267-3#ref-CR26" id="ref-link-section-d18127e2198">2014</a>).</p><p>These four systems were evaluated by assigning to each feature one of the following four scores reflecting the progress of that feature: fully accomplished (F), partially accomplished (P), partially accomplished but improved compared to a previous version (<span class="mathjax-tex">\(\hbox {P}_+\)</span>), and absent (A). Such evaluation was mostly based on the information available in the literature, as well as other resources available in the Internet and the author’s personal experience in developing the SBA system. In absence of enough information for a feature of a system, the A score was assigned. Three tables were created for the three identified categories of features: Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0267-3#Tab5">5</a> illustrates the scores for the sensing features, Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0267-3#Tab6">6</a> for the navigation features, and Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0267-3#Tab7">7</a> for the display features. By comparing the evaluations of the SBA, CWP, and TPAWT systems with their extended version, it is possible to notice how for the latter some features were evaluated F in place of P and A, P in place of A, and <span class="mathjax-tex">\(\hbox {P}_+\)</span> in place of P. As a consequence, XSBA, XCWP, and XTPAWT systems would lead to higher states of presence compared to SBA, CWP, and TPAWT, respectively. Moreover, from the three tables, it is possible to notice which features in each category are missing and which are not fully accomplished. These represent directions for future improvements in the system in order to achieve the goal of producing an intense sense of presence. For example, in addition to the proposed extensions, future developments of the three systems should focus on improving the technology toward solutions that allow wireless connectivity. Nevertheless, these considerations are not the main goal of the present work.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 Table of scores for sensing features</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-015-0267-3/tables/5"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-6"><figure><figcaption class="c-article-table__figcaption"><b id="Tab6" data-test="table-caption">Table 6 Table of scores for navigation features</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-015-0267-3/tables/6"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-7"><figure><figcaption class="c-article-table__figcaption"><b id="Tab7" data-test="table-caption">Table 7 Table of scores for display features</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-015-0267-3/tables/7"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     </div></div></section><section aria-labelledby="Sec9"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">Discussion and conclusions</h2><div class="c-article-section__content" id="Sec9-content"><p>The framework described in this paper was motivated by a particular problem: how to design systems for real locomotion in a generic VE, capable of producing strong place and plausibility illusions. The first step taken toward the solution of this problem was to determine which features a system should have. To identify such features, an approach based on the combination of two design strategies was followed. The first was an approach based on the theory of affordances and was utilized to design a generic VE in which all the affordances of the corresponding real environment could be evoked. The second was ED applied to VEs and was utilized to create an experience of locomotion corresponding to that achievable in a real environment. These design strategies were chosen because of their potential to enhance the sense of presence. Both theoretical and empirical evidence was cited in support of the proposed framework. An analysis of three case study systems was performed by means of the identified features, providing some initial support for the framework. It was shown that the list of features can be used in a practical way by VE designers as series of guidelines to evaluate the maturity of their systems and to pinpoint directions for future developments.</p><p>The present research highlights the importance of considering two aspects when designing systems for real locomotion in VEs, with the goal of producing an intense sense of presence. The first is the use of a holistic approach that encompasses on the one hand both environment and body affordances and on the other hand all dimensions of the experience, not just the sensory one, which is what usually is the case. It is argued that when creating VEs in order to accurately simulate real environments, it is necessary not only to simulate all the perceptually important real-world sensorial stimuli, but also to allow the largest set of valid actions possible, as well as to provide a sensorial content that takes into account cognitive, affective, active, and relational aspects of the experience.</p><p>The second aspect is the rendering of the virtual body in a way consistent with the user’s body in order to produce a strong feeling of body ownership (Spanlang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Spanlang B, Normand J, Borland D, Kilteni K, Giannopoulos E, Pomes A, Gonzalez-Franco M, Pérez Marcos D, Arroyo Palacios J, Muncunill X, Slater M (2014) How to build an embodiment lab: achieving body representation illusions in virtual reality. Front Robot AI 1:9" href="/article/10.1007/s10055-015-0267-3#ref-CR54" id="ref-link-section-d18127e5579">2014</a>). Gross et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Gross D, Stanney K, Cohn L (2005) Evoking affordances in virtual environments via sensory-stimuli substitution. Presence Teleoperators Virtual Environ 14(4):482–491" href="/article/10.1007/s10055-015-0267-3#ref-CR18" id="ref-link-section-d18127e5582">2005</a>) posed the attention on the perception of body stature in the VE. Here, it is argued that it is not only the body stature that needs to be perceptually rendered, but also all of the user’s other anthropomorphic features (e.g., gender, weight, foot size, leg length, etc.) with particular regard to those that can be seen, heard, or felt by the user during locomotion. For example, previous research has demonstrated that it is possible to recognize the walker’s gender (Li et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Li XF, Logan RJ, Pastore RE (1991) Perception of acoustic source characteristics: walking sounds. J Acoust Soc Am 90(6):3036–3049" href="/article/10.1007/s10055-015-0267-3#ref-CR32" id="ref-link-section-d18127e5585">1991</a>), identity (Mäkelä et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Mäkelä K, Hakulinen J, Turunen M (2003) The use of walking sounds in supporting awareness. In: Proceedings of ICAD, pp 144–147" href="/article/10.1007/s10055-015-0267-3#ref-CR35" id="ref-link-section-d18127e5588">2003</a>), emotions (Giordano and Bresin <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Giordano B, Bresin R (2006) Walking and playing: What’s the origin of emotional expressiveness in music? In: Proceedings of the 9th international conference on music perception &amp; cognition, p 436" href="/article/10.1007/s10055-015-0267-3#ref-CR15" id="ref-link-section-d18127e5591">2006</a>), and body posture (Pastore et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Pastore R, Flint J, Gaston J, Solomon M (2008) Auditory event perception: the source-perception loop for posture in human gait. Atten Percept Psychophys 70(1):13–29" href="/article/10.1007/s10055-015-0267-3#ref-CR41" id="ref-link-section-d18127e5595">2008</a>) based on auditory information alone contained in footstep sounds, suggesting therefore that an appropriate auditory rendering of the user’s anthropomorphic features can play an important role in the body awareness during the simulated locomotion. In addition, the present study suggests the importance of simulating the sensation of wearing specific shoes and clothes. Future research could assess the role played by different types of clothes on the sense of presence, especially when several properties of the climate of the environment (e.g., temperature, humidity) are also rendered. The impression of wearing clothes and footwear coherent with the VE (e.g., a ski suit in a snowy environment) should then lead to an increase in presence.</p><p>It is worthwhile to notice that the proposed list of features aim at defining what needs to be done, rather than providing objective formalized requirements that indicate exactly how to implement an interface. More practical indications and guidelines to implement some of the listed features with the technology currently available are presented in other works (Hollerbach <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Hollerbach J (2002) Locomotion interfaces. In: Handbook of virtual environments: design, implementation, and applications, pp 239–254" href="/article/10.1007/s10055-015-0267-3#ref-CR24" id="ref-link-section-d18127e5601">2002</a>; Steinicke et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Steinicke F, Visell Y, Campos J, Lécuyer A (2013) Human walking in virtual environments: perception, technology, and applications. Springer, New York" href="/article/10.1007/s10055-015-0267-3#ref-CR57" id="ref-link-section-d18127e5604">2013</a>; Fröhlich and Wachsmuth <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Fröhlich J, Wachsmuth I (2013) The visual, the auditory and the haptic—a user study on combining modalities in virtual worlds. In: Shumaker R (ed) Virtual, augmented and mixed reality. Designing and developing virtual and augmented environments, Lecture Notes in Computer Science, vol 8021. Springer, New York, pp 159–168" href="/article/10.1007/s10055-015-0267-3#ref-CR12" id="ref-link-section-d18127e5607">2013</a>; Spanlang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Spanlang B, Normand J, Borland D, Kilteni K, Giannopoulos E, Pomes A, Gonzalez-Franco M, Pérez Marcos D, Arroyo Palacios J, Muncunill X, Slater M (2014) How to build an embodiment lab: achieving body representation illusions in virtual reality. Front Robot AI 1:9" href="/article/10.1007/s10055-015-0267-3#ref-CR54" id="ref-link-section-d18127e5610">2014</a>). In addition to this, currently it is not possible to fully define the requirements expressed by certain features since these constitute open issues and, therefore, further research is needed. For instance, there are several mentions of tracking technology of “sufficient” accuracy or latency that is “not perceivable,” but no values are given. These notions of sufficiency and perception are not defined in the framework because research has not found yet all such values. Moreover, acceptable values relating to these issues might change over time (for example, some early papers on visual feedback display cite 100 ms end-to-end latency as being excellent but even at 20 ms people may be able to perceive delay in motion cues). Nevertheless, the framework serves as a starting point toward the definition of requirements for the creation of optimal interfaces. It can be complemented in future work when all the requirements will be defined in a formal, objective way.</p><p>Moreover, the proposed list of features aim at guiding VE designers toward improvements in their systems, and this is achieved also by means of comparisons with the systems previous versions. However, it is important to note that such a list has not been conceived to explicitly compare different systems developed by different groups. To achieve such a comparison, an assignment of a weight to each feature would be necessary. Nevertheless, at the moment this seems not feasible due to the fact that it would be a process too much open to interpretations. Future works are needed to investigate thoroughly this issue. Therefore, currently the frameworks are able only to predict that a version of the same system improved with more features fully or partially accomplished would lead to a higher sense of presence compared to that achievable with previous versions.</p><p>Finally, it is necessary to note that the framework has been based on considering the most general scenario, i.e., any form of locomotion and a general VE. For specific contexts, not all the features are needed, while others are critically important. For instance, for rehabilitation applications, the features concerning safety are fundamental while those concerning multiple users can be overlooked. Along the same line, the tracking and visual rendering of the parts of the body that can be seen by the user are only necessary for HMD-based systems, not for CAVE-based systems.</p><p>In conclusion, it is hoped that this framework can be useful to enable designers and developers of systems for real locomotion in VEs to optimize their simulations both technically and perceptually in order to facilitate the production of strong place and plausibility illusions. Moreover, it is hoped that results of future research in the field of locomotion perception in VEs could allow a more formal and objective definition of all the proposed requirements.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Barfield W, Zeltzer D, Sheridan T, Slater M (1995) Presence and performance within virtual environments. In: V" /><p class="c-article-references__text" id="ref-CR1">Barfield W, Zeltzer D, Sheridan T, Slater M (1995) Presence and performance within virtual environments. In: Virtual environments and advanced interface design pp 473–513</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Biocca F, Inque Y, Polinsky H, Lee A, Tang A (2002) Visual cues and virtual touch: role of visual stimuli and " /><p class="c-article-references__text" id="ref-CR2">Biocca F, Inque Y, Polinsky H, Lee A, Tang A (2002) Visual cues and virtual touch: role of visual stimuli and intersensory integration in cross-modal haptic illusions and the sense of presence. In: Proceedings of presence, pp 410–428</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Bruder, F. Steinicke, B. Bolte, P. Wieland, H. Frenz, M. Lappe, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Bruder G, Steinicke F, Bolte B, Wieland P, Frenz H, Lappe M (2012) Exploiting perceptual limitations and illus" /><p class="c-article-references__text" id="ref-CR3">Bruder G, Steinicke F, Bolte B, Wieland P, Frenz H, Lappe M (2012) Exploiting perceptual limitations and illusions to support walking through virtual environments in confined physical spaces. Displays 34(2):132–141</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.displa.2012.10.007" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Exploiting%20perceptual%20limitations%20and%20illusions%20to%20support%20walking%20through%20virtual%20environments%20in%20confined%20physical%20spaces&amp;journal=Displays&amp;volume=34&amp;issue=2&amp;pages=132-141&amp;publication_year=2012&amp;author=Bruder%2CG&amp;author=Steinicke%2CF&amp;author=Bolte%2CB&amp;author=Wieland%2CP&amp;author=Frenz%2CH&amp;author=Lappe%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="G. Calvert, C. Spence, B. Stein, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Calvert G, Spence C, Stein B (2004) The handbook of multisensory processes. MIT press, Cambridge" /><p class="c-article-references__text" id="ref-CR4">Calvert G, Spence C, Stein B (2004) The handbook of multisensory processes. MIT press, Cambridge</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20handbook%20of%20multisensory%20processes&amp;publication_year=2004&amp;author=Calvert%2CG&amp;author=Spence%2CC&amp;author=Stein%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Chertoff, S. Schatz, R. McDaniel, C. Bowers, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Chertoff D, Schatz S, McDaniel R, Bowers C (2008) Improving presence theory through experiential design. Prese" /><p class="c-article-references__text" id="ref-CR5">Chertoff D, Schatz S, McDaniel R, Bowers C (2008) Improving presence theory through experiential design. Presence Teleoperators Virtual Environ 17(4):405–413</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2Fpres.17.4.405" aria-label="View reference 5">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Improving%20presence%20theory%20through%20experiential%20design&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=17&amp;issue=4&amp;pages=405-413&amp;publication_year=2008&amp;author=Chertoff%2CD&amp;author=Schatz%2CS&amp;author=McDaniel%2CR&amp;author=Bowers%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chertoff DB, Goldiez B, LaViola JJ (2010) Virtual experience test: a virtual environment evaluation questionna" /><p class="c-article-references__text" id="ref-CR6">Chertoff DB, Goldiez B, LaViola JJ (2010) Virtual experience test: a virtual environment evaluation questionnaire. In: Proceedings the IEEE virtual reality conference, pp 103–110</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dinh H, Walker N, Hodges L, Song C, Kobayashi A (1999) Evaluating the importance of multi-sensory input on mem" /><p class="c-article-references__text" id="ref-CR7">Dinh H, Walker N, Hodges L, Song C, Kobayashi A (1999) Evaluating the importance of multi-sensory input on memory and the sense of presence in virtual environments. In: IEEE virtual reality conference, pp 222–228</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fajen B (2013) Affordance perception and the visual control of locomotion. In: Human walking in virtual enviro" /><p class="c-article-references__text" id="ref-CR8">Fajen B (2013) Affordance perception and the visual control of locomotion. In: Human walking in virtual environments. Springer, New York, pp 79–98</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Fitzpatrick, C. Carello, R. Schmidt, D. Corey, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Fitzpatrick P, Carello C, Schmidt R, Corey D (1994) Haptic and visual perception of an affordance for upright " /><p class="c-article-references__text" id="ref-CR9">Fitzpatrick P, Carello C, Schmidt R, Corey D (1994) Haptic and visual perception of an affordance for upright posture. Ecol Psychol 6(4):265–287</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1207%2Fs15326969eco0604_2" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Haptic%20and%20visual%20perception%20of%20an%20affordance%20for%20upright%20posture&amp;journal=Ecol%20Psychol&amp;volume=6&amp;issue=4&amp;pages=265-287&amp;publication_year=1994&amp;author=Fitzpatrick%2CP&amp;author=Carello%2CC&amp;author=Schmidt%2CR&amp;author=Corey%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Flach, J. Holden, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Flach J, Holden J (1998) The reality of experience: Gibson’s way. Presence Teleoperators Virtual Environ 7(1):" /><p class="c-article-references__text" id="ref-CR10">Flach J, Holden J (1998) The reality of experience: Gibson’s way. Presence Teleoperators Virtual Environ 7(1):90–95</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474698565550" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20reality%20of%20experience%3A%20Gibson%E2%80%99s%20way&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=7&amp;issue=1&amp;pages=90-95&amp;publication_year=1998&amp;author=Flach%2CJ&amp;author=Holden%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Frissen I, Campos J, Sreenivasa M, Ernst M (2013) Enabling unconstrained omnidirectional walking through virtu" /><p class="c-article-references__text" id="ref-CR11">Frissen I, Campos J, Sreenivasa M, Ernst M (2013) Enabling unconstrained omnidirectional walking through virtual environments: an overview of the cyberwalk project. In: Human walking in virtual environments. Springer, New York, pp 113–144</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fröhlich J, Wachsmuth I (2013) The visual, the auditory and the haptic—a user study on combining modalities in" /><p class="c-article-references__text" id="ref-CR12">Fröhlich J, Wachsmuth I (2013) The visual, the auditory and the haptic—a user study on combining modalities in virtual worlds. In: Shumaker R (ed) Virtual, augmented and mixed reality. Designing and developing virtual and augmented environments, Lecture Notes in Computer Science, vol 8021. Springer, New York, pp 159–168</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gaver W (1991) Technology affordances. In: Proceedings of the SIGCHI conference on Human factors in computing " /><p class="c-article-references__text" id="ref-CR13">Gaver W (1991) Technology affordances. In: Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, New York, pp 79–84</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gibson J (1979) The ecological approach to visual perception. Houghton Miffin, New York" /><p class="c-article-references__text" id="ref-CR14">Gibson J (1979) The ecological approach to visual perception. Houghton Miffin, New York</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Giordano B, Bresin R (2006) Walking and playing: What’s the origin of emotional expressiveness in music? In: P" /><p class="c-article-references__text" id="ref-CR15">Giordano B, Bresin R (2006) Walking and playing: What’s the origin of emotional expressiveness in music? In: Proceedings of the 9th international conference on music perception &amp; cognition, p 436</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="B. Giordano, Y. Visell, HY. Yao, V. Hayward, J. Cooperstock, S. McAdams, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Giordano B, Visell Y, Yao HY, Hayward V, Cooperstock J, McAdams S (2012) Identification of walked-upon materia" /><p class="c-article-references__text" id="ref-CR16">Giordano B, Visell Y, Yao HY, Hayward V, Cooperstock J, McAdams S (2012) Identification of walked-upon materials in auditory, kinesthetic, haptic and audio-haptic conditions. J Acoust Soc Am 131:4002–4012</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1121%2F1.3699205" aria-label="View reference 16">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Identification%20of%20walked-upon%20materials%20in%20auditory%2C%20kinesthetic%2C%20haptic%20and%20audio-haptic%20conditions&amp;journal=J%20Acoust%20Soc%20Am&amp;volume=131&amp;pages=4002-4012&amp;publication_year=2012&amp;author=Giordano%2CB&amp;author=Visell%2CY&amp;author=Yao%2CHY&amp;author=Hayward%2CV&amp;author=Cooperstock%2CJ&amp;author=McAdams%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Grechkin, J. Plumert, J. Kearney, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Grechkin T, Plumert J, Kearney J (2014) Dynamic affordances in embodied interactive systems: the role of displ" /><p class="c-article-references__text" id="ref-CR17">Grechkin T, Plumert J, Kearney J (2014) Dynamic affordances in embodied interactive systems: the role of display and mode of locomotion. IEEE Trans Visual Comput Graph 20(4):596–605</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTVCG.2014.18" aria-label="View reference 17">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Dynamic%20affordances%20in%20embodied%20interactive%20systems%3A%20the%20role%20of%20display%20and%20mode%20of%20locomotion&amp;journal=IEEE%20Trans%20Visual%20Comput%20Graph&amp;volume=20&amp;issue=4&amp;pages=596-605&amp;publication_year=2014&amp;author=Grechkin%2CT&amp;author=Plumert%2CJ&amp;author=Kearney%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Gross, K. Stanney, L. Cohn, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Gross D, Stanney K, Cohn L (2005) Evoking affordances in virtual environments via sensory-stimuli substitution" /><p class="c-article-references__text" id="ref-CR18">Gross D, Stanney K, Cohn L (2005) Evoking affordances in virtual environments via sensory-stimuli substitution. Presence Teleoperators Virtual Environ 14(4):482–491</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474605774785244" aria-label="View reference 18">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Evoking%20affordances%20in%20virtual%20environments%20via%20sensory-stimuli%20substitution&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=14&amp;issue=4&amp;pages=482-491&amp;publication_year=2005&amp;author=Gross%2CD&amp;author=Stanney%2CK&amp;author=Cohn%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Hartson, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Hartson R (2003) Cognitive, physical, sensory, and functional affordances in interaction design. Behav Inf Tec" /><p class="c-article-references__text" id="ref-CR19">Hartson R (2003) Cognitive, physical, sensory, and functional affordances in interaction design. Behav Inf Technol 22(5):315–338</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F01449290310001592587" aria-label="View reference 19">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Cognitive%2C%20physical%2C%20sensory%2C%20and%20functional%20affordances%20in%20interaction%20design&amp;journal=Behav%20Inf%20Technol&amp;volume=22&amp;issue=5&amp;pages=315-338&amp;publication_year=2003&amp;author=Hartson%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Harvey, M. Sanchez-Vives, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Harvey M, Sanchez-Vives M (2005) The binding problem in presence research. Presence Teleoperators Virtual Envi" /><p class="c-article-references__text" id="ref-CR20">Harvey M, Sanchez-Vives M (2005) The binding problem in presence research. Presence Teleoperators Virtual Environ 14(5):616–621</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474605774918714" aria-label="View reference 20">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20binding%20problem%20in%20presence%20research&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=14&amp;issue=5&amp;pages=616-621&amp;publication_year=2005&amp;author=Harvey%2CM&amp;author=Sanchez-Vives%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Heeter, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Heeter C (1992) Being there: the subjective experience of presence. Presence Teleoperators Virtual Environ 1(2" /><p class="c-article-references__text" id="ref-CR21">Heeter C (1992) Being there: the subjective experience of presence. Presence Teleoperators Virtual Environ 1(2):262–271</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Being%20there%3A%20the%20subjective%20experience%20of%20presence&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=1&amp;issue=2&amp;pages=262-271&amp;publication_year=1992&amp;author=Heeter%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Heeter C (1995) Communication research on consumer vr. Communication in the age of virtual reality, pp 191–218" /><p class="c-article-references__text" id="ref-CR22">Heeter C (1995) Communication research on consumer vr. Communication in the age of virtual reality, pp 191–218</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Hermann T, Hunt A, Neuhoff J (eds) (2011) The sonification handbook. Logos Publishing House, Berlin" /><p class="c-article-references__text" id="ref-CR23">Hermann T, Hunt A, Neuhoff J (eds) (2011) The sonification handbook. Logos Publishing House, Berlin</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20sonification%20handbook&amp;publication_year=2011">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hollerbach J (2002) Locomotion interfaces. In: Handbook of virtual environments: design, implementation, and a" /><p class="c-article-references__text" id="ref-CR24">Hollerbach J (2002) Locomotion interfaces. In: Handbook of virtual environments: design, implementation, and applications, pp 239–254</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hollerbach J, Xu Y, Christensen R, Jacobsen S (2000) Design specifications for the second generation sarcos tr" /><p class="c-article-references__text" id="ref-CR25">Hollerbach J, Xu Y, Christensen R, Jacobsen S (2000) Design specifications for the second generation sarcos treadport locomotion interface. In: Haptics symposium, proceedings of the ASME dynamic systems and control division, vol 69, pp 1293–1298</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="F. Hülsmann, N. Mattar, J. Fröhlich, I. Wachsmuth, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="&#xA;Hülsmann F, Mattar N, Fröhlich J, Wachsmuth I (2014) Simulating wind and warmth in virtual reality: conceptio" /><p class="c-article-references__text" id="ref-CR26">
Hülsmann F, Mattar N, Fröhlich J, Wachsmuth I (2014) Simulating wind and warmth in virtual reality: conception, realization and evaluation for a cave environment. J Virtual Real Broadcast 11(10):1–20</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Simulating%20wind%20and%20warmth%20in%20virtual%20reality%3A%20conception%2C%20realization%20and%20evaluation%20for%20a%20cave%20environment&amp;journal=J%20Virtual%20Real%20Broadcast&amp;volume=11&amp;issue=10&amp;pages=1-20&amp;publication_year=2014&amp;author=H%C3%BClsmann%2CF&amp;author=Mattar%2CN&amp;author=Fr%C3%B6hlich%2CJ&amp;author=Wachsmuth%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kulkarni S, Fisher C, Pardyjak E, Minor M, Hollerbach J (2009) Wind display device for locomotion interface in" /><p class="c-article-references__text" id="ref-CR27">Kulkarni S, Fisher C, Pardyjak E, Minor M, Hollerbach J (2009) Wind display device for locomotion interface in a virtual environment. In: Proceedings of IEEE World haptics conference. IEEE, pp 184–189</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Kulkarni, M. Minor, M. Deaver, E. Pardyjak, J. Hollerbach, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Kulkarni S, Minor M, Deaver M, Pardyjak E, Hollerbach J (2012) Design, sensing, and control of a scaled wind t" /><p class="c-article-references__text" id="ref-CR28">Kulkarni S, Minor M, Deaver M, Pardyjak E, Hollerbach J (2012) Design, sensing, and control of a scaled wind tunnel for atmospheric display. IEEE Trans Mechatron 17(4):635–645</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTMECH.2011.2113353" aria-label="View reference 28">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Design%2C%20sensing%2C%20and%20control%20of%20a%20scaled%20wind%20tunnel%20for%20atmospheric%20display&amp;journal=IEEE%20Trans%20Mechatron&amp;volume=17&amp;issue=4&amp;pages=635-645&amp;publication_year=2012&amp;author=Kulkarni%2CS&amp;author=Minor%2CM&amp;author=Deaver%2CM&amp;author=Pardyjak%2CE&amp;author=Hollerbach%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Larsson P, Väljamäe A, Västfjäll D, Tajadura-Jiménez A, Kleiner M (2010) Auditory-induced presence in mixed re" /><p class="c-article-references__text" id="ref-CR29">Larsson P, Väljamäe A, Västfjäll D, Tajadura-Jiménez A, Kleiner M (2010) Auditory-induced presence in mixed reality environments and related technology. In: The engineering of mixed reality systems. Springer, New York, pp 143–163</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Lee, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Lee K (2004) Why presence occurs: evolutionary psychology, media equation, and presence. Presence Teleoperator" /><p class="c-article-references__text" id="ref-CR30">Lee K (2004) Why presence occurs: evolutionary psychology, media equation, and presence. Presence Teleoperators Virtual Environ 13(4):494–505</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F1054746041944830" aria-label="View reference 30">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Why%20presence%20occurs%3A%20evolutionary%20psychology%2C%20media%20equation%2C%20and%20presence&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=13&amp;issue=4&amp;pages=494-505&amp;publication_year=2004&amp;author=Lee%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Lepecq, L. Bringoux, J. Pergandi, T. Coyle, D. Mestre, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Lepecq J, Bringoux L, Pergandi J, Coyle T, Mestre D (2009) Afforded actions as a behavioral assessment of phys" /><p class="c-article-references__text" id="ref-CR31">Lepecq J, Bringoux L, Pergandi J, Coyle T, Mestre D (2009) Afforded actions as a behavioral assessment of physical presence in virtual environments. Virtual Reality 13(3):141–151</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10055-009-0118-1" aria-label="View reference 31">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Afforded%20actions%20as%20a%20behavioral%20assessment%20of%20physical%20presence%20in%20virtual%20environments&amp;journal=Virtual%20Reality&amp;volume=13&amp;issue=3&amp;pages=141-151&amp;publication_year=2009&amp;author=Lepecq%2CJ&amp;author=Bringoux%2CL&amp;author=Pergandi%2CJ&amp;author=Coyle%2CT&amp;author=Mestre%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="XF. Li, RJ. Logan, RE. Pastore, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="Li XF, Logan RJ, Pastore RE (1991) Perception of acoustic source characteristics: walking sounds. J Acoust Soc" /><p class="c-article-references__text" id="ref-CR32">Li XF, Logan RJ, Pastore RE (1991) Perception of acoustic source characteristics: walking sounds. J Acoust Soc Am 90(6):3036–3049</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1121%2F1.401778" aria-label="View reference 32">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Perception%20of%20acoustic%20source%20characteristics%3A%20walking%20sounds&amp;journal=J%20Acoust%20Soc%20Am&amp;volume=90&amp;issue=6&amp;pages=3036-3049&amp;publication_year=1991&amp;author=Li%2CXF&amp;author=Logan%2CRJ&amp;author=Pastore%2CRE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Maier, G. Fadel, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Maier J, Fadel G (2009a) Affordance based design: a relational theory for design. Res Eng Design 20(1):13–27" /><p class="c-article-references__text" id="ref-CR33">Maier J, Fadel G (2009a) Affordance based design: a relational theory for design. Res Eng Design 20(1):13–27</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs00163-008-0060-3" aria-label="View reference 33">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Affordance%20based%20design%3A%20a%20relational%20theory%20for%20design&amp;journal=Res%20Eng%20Design&amp;volume=20&amp;issue=1&amp;pages=13-27&amp;publication_year=2009&amp;author=Maier%2CJ&amp;author=Fadel%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Maier, G. Fadel, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Maier J, Fadel G (2009b) Affordance-based design methods for innovative design, redesign and reverse engineeri" /><p class="c-article-references__text" id="ref-CR34">Maier J, Fadel G (2009b) Affordance-based design methods for innovative design, redesign and reverse engineering. Res Eng Design 20(4):225–239</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs00163-009-0064-7" aria-label="View reference 34">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Affordance-based%20design%20methods%20for%20innovative%20design%2C%20redesign%20and%20reverse%20engineering&amp;journal=Res%20Eng%20Design&amp;volume=20&amp;issue=4&amp;pages=225-239&amp;publication_year=2009&amp;author=Maier%2CJ&amp;author=Fadel%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mäkelä K, Hakulinen J, Turunen M (2003) The use of walking sounds in supporting awareness. In: Proceedings of " /><p class="c-article-references__text" id="ref-CR35">Mäkelä K, Hakulinen J, Turunen M (2003) The use of walking sounds in supporting awareness. In: Proceedings of ICAD, pp 144–147</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Marchal M, Lécuyer A, Cirio G, Bonnet L, Emily M (2010) Walking up and down in immersive virtual worlds: novel" /><p class="c-article-references__text" id="ref-CR36">Marchal M, Lécuyer A, Cirio G, Bonnet L, Emily M (2010) Walking up and down in immersive virtual worlds: novel interactive techniques based on visual feedback. In: IEEE symposium on 3D user interfaces, pp 19–26</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="LS. Mark, " /><meta itemprop="datePublished" content="1987" /><meta itemprop="headline" content="Mark LS (1987) Eyeheight-scaled information about affordances: a study of sitting and stair climbing. J Exp Ps" /><p class="c-article-references__text" id="ref-CR37">Mark LS (1987) Eyeheight-scaled information about affordances: a study of sitting and stair climbing. J Exp Psychol Hum Percept Perform 13(3):361–370</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=932892" aria-label="View reference 37 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2F0096-1523.13.3.361" aria-label="View reference 37">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Eyeheight-scaled%20information%20about%20affordances%3A%20a%20study%20of%20sitting%20and%20stair%20climbing&amp;journal=J%20Exp%20Psychol%20Hum%20Percept%20Perform&amp;volume=13&amp;issue=3&amp;pages=361-370&amp;publication_year=1987&amp;author=Mark%2CLS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. McGrenere, W. Ho, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="McGrenere J, Ho W (2000) Affordances: clarifying and evolving a concept. Graph Interface 2000:179–186" /><p class="c-article-references__text" id="ref-CR38">McGrenere J, Ho W (2000) Affordances: clarifying and evolving a concept. Graph Interface 2000:179–186</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 38 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Affordances%3A%20clarifying%20and%20evolving%20a%20concept&amp;journal=Graph%20Interface&amp;volume=2000&amp;pages=179-186&amp;publication_year=2000&amp;author=McGrenere%2CJ&amp;author=Ho%2CW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Nordahl, S. Serafin, L. Turchet, N. Nilsson, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Nordahl R, Serafin S, Turchet L, Nilsson N (2012) A multimodal architecture for simulating natural interactive" /><p class="c-article-references__text" id="ref-CR39">Nordahl R, Serafin S, Turchet L, Nilsson N (2012) A multimodal architecture for simulating natural interactive walking in virtual environments. PsychNology J 9(3):245–268</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20multimodal%20architecture%20for%20simulating%20natural%20interactive%20walking%20in%20virtual%20environments&amp;journal=PsychNology%20J&amp;volume=9&amp;issue=3&amp;pages=245-268&amp;publication_year=2012&amp;author=Nordahl%2CR&amp;author=Serafin%2CS&amp;author=Turchet%2CL&amp;author=Nilsson%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Oudejans, C. Michaels, F. Bakker, M. Dolné, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Oudejans R, Michaels C, Bakker F, Dolné M (1996) The relevance of action in perceiving affordances: perception" /><p class="c-article-references__text" id="ref-CR40">Oudejans R, Michaels C, Bakker F, Dolné M (1996) The relevance of action in perceiving affordances: perception of catchableness of fly balls. J Exp Psychol Hum Percept Perform 22(4):879</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2F0096-1523.22.4.879" aria-label="View reference 40">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 40 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20relevance%20of%20action%20in%20perceiving%20affordances%3A%20perception%20of%20catchableness%20of%20fly%20balls&amp;journal=J%20Exp%20Psychol%20Hum%20Percept%20Perform&amp;volume=22&amp;issue=4&amp;publication_year=1996&amp;author=Oudejans%2CR&amp;author=Michaels%2CC&amp;author=Bakker%2CF&amp;author=Doln%C3%A9%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Pastore, J. Flint, J. Gaston, M. Solomon, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Pastore R, Flint J, Gaston J, Solomon M (2008) Auditory event perception: the source-perception loop for postu" /><p class="c-article-references__text" id="ref-CR41">Pastore R, Flint J, Gaston J, Solomon M (2008) Auditory event perception: the source-perception loop for posture in human gait. Atten Percept Psychophys 70(1):13–29</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3758%2FPP.70.1.13" aria-label="View reference 41">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 41 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Auditory%20event%20perception%3A%20the%20source-perception%20loop%20for%20posture%20in%20human%20gait&amp;journal=Atten%20Percept%20Psychophys&amp;volume=70&amp;issue=1&amp;pages=13-29&amp;publication_year=2008&amp;author=Pastore%2CR&amp;author=Flint%2CJ&amp;author=Gaston%2CJ&amp;author=Solomon%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Peck, H. Fuchs, M. Whitton, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Peck T, Fuchs H, Whitton M (2012) The design and evaluation of a large-scale real-walking locomotion interface" /><p class="c-article-references__text" id="ref-CR42">Peck T, Fuchs H, Whitton M (2012) The design and evaluation of a large-scale real-walking locomotion interface. IEEE Trans Visual Comput Graphics 18(7):1053–1067</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTVCG.2011.289" aria-label="View reference 42">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 42 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20design%20and%20evaluation%20of%20a%20large-scale%20real-walking%20locomotion%20interface&amp;journal=IEEE%20Trans%20Visual%20Comput%20Graphics&amp;volume=18&amp;issue=7&amp;pages=1053-1067&amp;publication_year=2012&amp;author=Peck%2CT&amp;author=Fuchs%2CH&amp;author=Whitton%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="J. Pine, J. Gilmore, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Pine J, Gilmore J (2011) The experience economy. Harvard Business Press, Boston" /><p class="c-article-references__text" id="ref-CR43">Pine J, Gilmore J (2011) The experience economy. Harvard Business Press, Boston</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 43 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20experience%20economy&amp;publication_year=2011&amp;author=Pine%2CJ&amp;author=Gilmore%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="N. Ravaja, T. Saari, M. Turpeinen, J. Laarni, M. Salminen, M. Kivikangas, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Ravaja N, Saari T, Turpeinen M, Laarni J, Salminen M, Kivikangas M (2006) Spatial presence and emotions during" /><p class="c-article-references__text" id="ref-CR44">Ravaja N, Saari T, Turpeinen M, Laarni J, Salminen M, Kivikangas M (2006) Spatial presence and emotions during video game playing: Does it matter with whom you play? Presence Teleoperators Virtual Environ 15(4):381–392</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2Fpres.15.4.381" aria-label="View reference 44">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 44 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatial%20presence%20and%20emotions%20during%20video%20game%20playing%3A%20Does%20it%20matter%20with%20whom%20you%20play%3F&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=15&amp;issue=4&amp;pages=381-392&amp;publication_year=2006&amp;author=Ravaja%2CN&amp;author=Saari%2CT&amp;author=Turpeinen%2CM&amp;author=Laarni%2CJ&amp;author=Salminen%2CM&amp;author=Kivikangas%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Regia-Corte, M. Marchal, G. Cirio, A. Lécuyer, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Regia-Corte T, Marchal M, Cirio G, Lécuyer A (2013) Perceiving affordances in virtual reality: influence of pe" /><p class="c-article-references__text" id="ref-CR45">Regia-Corte T, Marchal M, Cirio G, Lécuyer A (2013) Perceiving affordances in virtual reality: influence of person and environmental properties in perception of standing on virtual grounds. Virtual Real 17(1):1–12</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10055-012-0216-3" aria-label="View reference 45">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 45 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Perceiving%20affordances%20in%20virtual%20reality%3A%20influence%20of%20person%20and%20environmental%20properties%20in%20perception%20of%20standing%20on%20virtual%20grounds&amp;journal=Virtual%20Real&amp;volume=17&amp;issue=1&amp;pages=1-12&amp;publication_year=2013&amp;author=Regia-Corte%2CT&amp;author=Marchal%2CM&amp;author=Cirio%2CG&amp;author=L%C3%A9cuyer%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Riva, F. Mantovani, C. Capideville, A. Preziosa, F. Morganti, D. Villani, A. Gaggioli, C. Botella, M. Alcañiz, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Riva G, Mantovani F, Capideville C, Preziosa A, Morganti F, Villani D, Gaggioli A, Botella C, Alcañiz M (2007)" /><p class="c-article-references__text" id="ref-CR46">Riva G, Mantovani F, Capideville C, Preziosa A, Morganti F, Villani D, Gaggioli A, Botella C, Alcañiz M (2007) Affective interactions using virtual reality: the link between presence and emotions. CyberPsychol Behav 10(1):45–56</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1089%2Fcpb.2006.9993" aria-label="View reference 46">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 46 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Affective%20interactions%20using%20virtual%20reality%3A%20the%20link%20between%20presence%20and%20emotions&amp;journal=CyberPsychol%20Behav&amp;volume=10&amp;issue=1&amp;pages=45-56&amp;publication_year=2007&amp;author=Riva%2CG&amp;author=Mantovani%2CF&amp;author=Capideville%2CC&amp;author=Preziosa%2CA&amp;author=Morganti%2CF&amp;author=Villani%2CD&amp;author=Gaggioli%2CA&amp;author=Botella%2CC&amp;author=Alca%C3%B1iz%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Ruddle, S. Lessels, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Ruddle R, Lessels S (2009) The benefits of using a walking interface to navigate virtual environments. ACM Tra" /><p class="c-article-references__text" id="ref-CR47">Ruddle R, Lessels S (2009) The benefits of using a walking interface to navigate virtual environments. ACM Trans Comput Human Interact 16(1):5</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F1502800.1502805" aria-label="View reference 47">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 47 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20benefits%20of%20using%20a%20walking%20interface%20to%20navigate%20virtual%20environments&amp;journal=ACM%20Trans%20Comput%20Human%20Interact&amp;volume=16&amp;issue=1&amp;publication_year=2009&amp;author=Ruddle%2CR&amp;author=Lessels%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Schubert, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Schubert T (2009) A new conception of spatial presence: once again, with feeling. Commun Theory 19(2):161–187" /><p class="c-article-references__text" id="ref-CR48">Schubert T (2009) A new conception of spatial presence: once again, with feeling. Commun Theory 19(2):161–187</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1701507" aria-label="View reference 48 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fj.1468-2885.2009.01340.x" aria-label="View reference 48">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 48 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20new%20conception%20of%20spatial%20presence%3A%20once%20again%2C%20with%20feeling&amp;journal=Commun%20Theory&amp;volume=19&amp;issue=2&amp;pages=161-187&amp;publication_year=2009&amp;author=Schubert%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Slater, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Slater M (2002) Presence and the sixth sense. Presence Teleoperators Virtual Environ 11(4):435–439" /><p class="c-article-references__text" id="ref-CR49">Slater M (2002) Presence and the sixth sense. Presence Teleoperators Virtual Environ 11(4):435–439</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474602760204327" aria-label="View reference 49">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 49 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Presence%20and%20the%20sixth%20sense&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=11&amp;issue=4&amp;pages=435-439&amp;publication_year=2002&amp;author=Slater%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Slater, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Slater M (2009) Place illusion and plausibility can lead to realistic behaviour in immersive virtual environme" /><p class="c-article-references__text" id="ref-CR50">Slater M (2009) Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments. Philos Trans R Soc B Biol Sci 364(1535):3549–3557</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1098%2Frstb.2009.0138" aria-label="View reference 50">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 50 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Place%20illusion%20and%20plausibility%20can%20lead%20to%20realistic%20behaviour%20in%20immersive%20virtual%20environments&amp;journal=Philos%20Trans%20R%20Soc%20B%20Biol%20Sci&amp;volume=364&amp;issue=1535&amp;pages=3549-3557&amp;publication_year=2009&amp;author=Slater%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Slater, M. Usoh, A. Steed, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Slater M, Usoh M, Steed A (1995) Taking steps: the influence of a walking technique on presence in virtual rea" /><p class="c-article-references__text" id="ref-CR51">Slater M, Usoh M, Steed A (1995) Taking steps: the influence of a walking technique on presence in virtual reality. ACM Trans Comput Human Interact 2(3):201–219</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F210079.210084" aria-label="View reference 51">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 51 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Taking%20steps%3A%20the%20influence%20of%20a%20walking%20technique%20on%20presence%20in%20virtual%20reality&amp;journal=ACM%20Trans%20Comput%20Human%20Interact&amp;volume=2&amp;issue=3&amp;pages=201-219&amp;publication_year=1995&amp;author=Slater%2CM&amp;author=Usoh%2CM&amp;author=Steed%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Slater, B. Lotto, MM. Arnold, MV. Sanchez-Vives, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Slater M, Lotto B, Arnold MM, Sanchez-Vives MV (2009) How we experience immersive virtual environments: the co" /><p class="c-article-references__text" id="ref-CR52">Slater M, Lotto B, Arnold MM, Sanchez-Vives MV (2009) How we experience immersive virtual environments: the concept of presence and its measurement. Anuario de Psicologia 40(2):193–210</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 52 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=How%20we%20experience%20immersive%20virtual%20environments%3A%20the%20concept%20of%20presence%20and%20its%20measurement&amp;journal=Anuario%20de%20Psicologia&amp;volume=40&amp;issue=2&amp;pages=193-210&amp;publication_year=2009&amp;author=Slater%2CM&amp;author=Lotto%2CB&amp;author=Arnold%2CMM&amp;author=Sanchez-Vives%2CMV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Souman, P. Robuffo Giordano, M. Schwaiger, I. Frissen, T. Thümmel, H. Ulbrich, A. Luca, H. Bülthoff, M. Ernst, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Souman J, Robuffo Giordano P, Schwaiger M, Frissen I, Thümmel T, Ulbrich H, De Luca A, Bülthoff H, Ernst M (20" /><p class="c-article-references__text" id="ref-CR53">Souman J, Robuffo Giordano P, Schwaiger M, Frissen I, Thümmel T, Ulbrich H, De Luca A, Bülthoff H, Ernst M (2011) Cyberwalk: enabling unconstrained omnidirectional walking through virtual environments. ACM Trans Appl Percept 8(4):25</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 53 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Cyberwalk%3A%20enabling%20unconstrained%20omnidirectional%20walking%20through%20virtual%20environments&amp;journal=ACM%20Trans%20Appl%20Percept&amp;volume=8&amp;issue=4&amp;publication_year=2011&amp;author=Souman%2CJ&amp;author=Robuffo%20Giordano%2CP&amp;author=Schwaiger%2CM&amp;author=Frissen%2CI&amp;author=Th%C3%BCmmel%2CT&amp;author=Ulbrich%2CH&amp;author=Luca%2CA&amp;author=B%C3%BClthoff%2CH&amp;author=Ernst%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="B. Spanlang, J. Normand, D. Borland, K. Kilteni, E. Giannopoulos, A. Pomes, M. Gonzalez-Franco, D. Pérez Marcos, J. Arroyo Palacios, X. Muncunill, M. Slater, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Spanlang B, Normand J, Borland D, Kilteni K, Giannopoulos E, Pomes A, Gonzalez-Franco M, Pérez Marcos D, Arroy" /><p class="c-article-references__text" id="ref-CR54">Spanlang B, Normand J, Borland D, Kilteni K, Giannopoulos E, Pomes A, Gonzalez-Franco M, Pérez Marcos D, Arroyo Palacios J, Muncunill X, Slater M (2014) How to build an embodiment lab: achieving body representation illusions in virtual reality. Front Robot AI 1:9</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3389%2Ffrobt.2014.00009" aria-label="View reference 54">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 54 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=How%20to%20build%20an%20embodiment%20lab%3A%20achieving%20body%20representation%20illusions%20in%20virtual%20reality&amp;journal=Front%20Robot%20AI&amp;volume=1&amp;publication_year=2014&amp;author=Spanlang%2CB&amp;author=Normand%2CJ&amp;author=Borland%2CD&amp;author=Kilteni%2CK&amp;author=Giannopoulos%2CE&amp;author=Pomes%2CA&amp;author=Gonzalez-Franco%2CM&amp;author=P%C3%A9rez%20Marcos%2CD&amp;author=Arroyo%20Palacios%2CJ&amp;author=Muncunill%2CX&amp;author=Slater%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Spence, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Spence C (2007) Audiovisual multisensory integration. Acoust Sci Technol 28(2):61–70" /><p class="c-article-references__text" id="ref-CR55">Spence C (2007) Audiovisual multisensory integration. Acoust Sci Technol 28(2):61–70</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1250%2Fast.28.61" aria-label="View reference 55">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 55 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Audiovisual%20multisensory%20integration&amp;journal=Acoust%20Sci%20Technol&amp;volume=28&amp;issue=2&amp;pages=61-70&amp;publication_year=2007&amp;author=Spence%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Spence, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Spence C (2011) Crossmodal correspondences: a tutorial review. Atten Percept Psychophys 73(4):971–995" /><p class="c-article-references__text" id="ref-CR56">Spence C (2011) Crossmodal correspondences: a tutorial review. Atten Percept Psychophys 73(4):971–995</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2831062" aria-label="View reference 56 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3758%2Fs13414-010-0073-7" aria-label="View reference 56">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 56 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Crossmodal%20correspondences%3A%20a%20tutorial%20review&amp;journal=Atten%20Percept%20Psychophys&amp;volume=73&amp;issue=4&amp;pages=971-995&amp;publication_year=2011&amp;author=Spence%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="F. Steinicke, Y. Visell, J. Campos, A. Lécuyer, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Steinicke F, Visell Y, Campos J, Lécuyer A (2013) Human walking in virtual environments: perception, technolog" /><p class="c-article-references__text" id="ref-CR57">Steinicke F, Visell Y, Campos J, Lécuyer A (2013) Human walking in virtual environments: perception, technology, and applications. Springer, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 57 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20walking%20in%20virtual%20environments%3A%20perception%2C%20technology%2C%20and%20applications&amp;publication_year=2013&amp;author=Steinicke%2CF&amp;author=Visell%2CY&amp;author=Campos%2CJ&amp;author=L%C3%A9cuyer%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Turchet, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Turchet L (2014) Custom made wireless systems for footstep sounds synthesis. Appl Acoust 83:22–31" /><p class="c-article-references__text" id="ref-CR58">Turchet L (2014) Custom made wireless systems for footstep sounds synthesis. Appl Acoust 83:22–31</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.apacoust.2014.03.005" aria-label="View reference 58">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 58 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Custom%20made%20wireless%20systems%20for%20footstep%20sounds%20synthesis&amp;journal=Appl%20Acoust&amp;volume=83&amp;pages=22-31&amp;publication_year=2014&amp;author=Turchet%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Turchet, S. Serafin, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Turchet L, Serafin S (2014) Semantic congruence in audio-haptic simulation of footsteps. Appl Acoust 75(1):59–" /><p class="c-article-references__text" id="ref-CR59">Turchet L, Serafin S (2014) Semantic congruence in audio-haptic simulation of footsteps. Appl Acoust 75(1):59–66</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.apacoust.2013.06.016" aria-label="View reference 59">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 59 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Semantic%20congruence%20in%20audio-haptic%20simulation%20of%20footsteps&amp;journal=Appl%20Acoust&amp;volume=75&amp;issue=1&amp;pages=59-66&amp;publication_year=2014&amp;author=Turchet%2CL&amp;author=Serafin%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Turchet L, Nordahl R, Berrezag A, Dimitrov S, Hayward V, Serafin S (2010) Audio-haptic physically based simula" /><p class="c-article-references__text" id="ref-CR60">Turchet L, Nordahl R, Berrezag A, Dimitrov S, Hayward V, Serafin S (2010) Audio-haptic physically based simulation of walking on different grounds. In: Proceedings of IEEE international workshop on multimedia signal processing, IEEE Press, pp 269–273</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Turchet L, Nilsson N, Serafin S (2012) Inside the boundaries of the physical world: audio-haptic feedback as s" /><p class="c-article-references__text" id="ref-CR61">Turchet L, Nilsson N, Serafin S (2012) Inside the boundaries of the physical world: audio-haptic feedback as support for the navigation in virtual environments. Haptics: Perception, Devices, Mobility, and Communication, vol 7282. Lecture Notes in Computer Science, Springer, Berlin, pp 577–588</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Usoh M, Arthur K, Whitton M, Bastos R, Steed A, Slater M, Brooks Jr F (1999) Walking \(&gt;\)walking-in-place\(&gt;\" /><p class="c-article-references__text" id="ref-CR62">Usoh M, Arthur K, Whitton M, Bastos R, Steed A, Slater M, Brooks Jr F (1999) Walking <span class="mathjax-tex">\(&gt;\)</span>walking-in-place<span class="mathjax-tex">\(&gt;\)</span> flying, in virtual environments. In: Proceedings of the 26th annual conference on computer graphics and interactive techniques, pp 359–364</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="datePublished" content="1988" /><meta itemprop="headline" content="Van Toller S, Dodd G (eds) (1988) Perfumery: the psychology and biology of fragrance. Chapman &amp; Hall, London" /><p class="c-article-references__text" id="ref-CR63">Van Toller S, Dodd G (eds) (1988) Perfumery: the psychology and biology of fragrance. Chapman &amp; Hall, London</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 63 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Perfumery%3A%20the%20psychology%20and%20biology%20of%20fragrance&amp;publication_year=1988">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Van Toller S, Dodd G (eds) (1992) Fragrance: the psychology and biology of perfume. Chapman &amp; Hall, London" /><p class="c-article-references__text" id="ref-CR64">Van Toller S, Dodd G (eds) (1992) Fragrance: the psychology and biology of perfume. Chapman &amp; Hall, London</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 64 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Fragrance%3A%20the%20psychology%20and%20biology%20of%20perfume&amp;publication_year=1992">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. Visell, A. Law, JR. Cooperstock, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Visell Y, Law A, Cooperstock JR (2009) Touch is everywhere: floor surfaces as ambient haptic interfaces. IEEE " /><p class="c-article-references__text" id="ref-CR65">Visell Y, Law A, Cooperstock JR (2009) Touch is everywhere: floor surfaces as ambient haptic interfaces. IEEE Trans Haptics 2:148–159</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTOH.2009.31" aria-label="View reference 65">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 65 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Touch%20is%20everywhere%3A%20floor%20surfaces%20as%20ambient%20haptic%20interfaces&amp;journal=IEEE%20Trans%20Haptics&amp;volume=2&amp;pages=148-159&amp;publication_year=2009&amp;author=Visell%2CY&amp;author=Law%2CA&amp;author=Cooperstock%2CJR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="W. Warren, " /><meta itemprop="datePublished" content="1984" /><meta itemprop="headline" content="Warren W (1984) Perceiving affordances: visual guidance of stair climbing. J Exp Psychol Hum Percept Perform 1" /><p class="c-article-references__text" id="ref-CR66">Warren W (1984) Perceiving affordances: visual guidance of stair climbing. J Exp Psychol Hum Percept Perform 10(5):683</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2F0096-1523.10.5.683" aria-label="View reference 66">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 66 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Perceiving%20affordances%3A%20visual%20guidance%20of%20stair%20climbing&amp;journal=J%20Exp%20Psychol%20Hum%20Percept%20Perform&amp;volume=10&amp;issue=5&amp;publication_year=1984&amp;author=Warren%2CW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="W. Warren, S. Whang, " /><meta itemprop="datePublished" content="1987" /><meta itemprop="headline" content="Warren W, Whang S (1987) Visual guidance of walking through apertures: body-scaled information for affordances" /><p class="c-article-references__text" id="ref-CR67">Warren W, Whang S (1987) Visual guidance of walking through apertures: body-scaled information for affordances. J Exp Psychol Hum Percept Perform 13(3):371–383</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2F0096-1523.13.3.371" aria-label="View reference 67">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 67 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20guidance%20of%20walking%20through%20apertures%3A%20body-scaled%20information%20for%20affordances&amp;journal=J%20Exp%20Psychol%20Hum%20Percept%20Perform&amp;volume=13&amp;issue=3&amp;pages=371-383&amp;publication_year=1987&amp;author=Warren%2CW&amp;author=Whang%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Yanagida Y, Kawato S, Noma H, Tomono A, Tesutani N (2004) Projection based olfactory display with nose trackin" /><p class="c-article-references__text" id="ref-CR68">Yanagida Y, Kawato S, Noma H, Tomono A, Tesutani N (2004) Projection based olfactory display with nose tracking. In: IEEE virtual reality conference, IEEE, pp 43–50</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Zahorik, R. Jenison, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Zahorik P, Jenison R (1998) Presence as being-in-the-world. Presence Teleoperators Virtual Environ 7(1):78–89" /><p class="c-article-references__text" id="ref-CR69">Zahorik P, Jenison R (1998) Presence as being-in-the-world. Presence Teleoperators Virtual Environ 7(1):78–89</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474698565541" aria-label="View reference 69">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 69 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Presence%20as%20being-in-the-world&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=7&amp;issue=1&amp;pages=78-89&amp;publication_year=1998&amp;author=Zahorik%2CP&amp;author=Jenison%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Zanbaka, B. Lok, S. Babu, A. Ulinski, L. Hodges, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Zanbaka C, Lok B, Babu S, Ulinski A, Hodges L (2005) Comparison of path visualizations and cognitive measures " /><p class="c-article-references__text" id="ref-CR70">Zanbaka C, Lok B, Babu S, Ulinski A, Hodges L (2005) Comparison of path visualizations and cognitive measures relative to travel technique in a virtual environment. IEEE Trans Visual Comput Graph 11(6):694–705</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTVCG.2005.92" aria-label="View reference 70">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 70 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Comparison%20of%20path%20visualizations%20and%20cognitive%20measures%20relative%20to%20travel%20technique%20in%20a%20virtual%20environment&amp;journal=IEEE%20Trans%20Visual%20Comput%20Graph&amp;volume=11&amp;issue=6&amp;pages=694-705&amp;publication_year=2005&amp;author=Zanbaka%2CC&amp;author=Lok%2CB&amp;author=Babu%2CS&amp;author=Ulinski%2CA&amp;author=Hodges%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zanotto D, Turchet L, Boggs E, Agrawal S (2014) Solesound: towards a novel portable system for audio-tactile u" /><p class="c-article-references__text" id="ref-CR71">Zanotto D, Turchet L, Boggs E, Agrawal S (2014) Solesound: towards a novel portable system for audio-tactile underfoot feedback. In: Proceedings of the 5th IEEE international conference on biomedical robotics and biomechatronics, IEEE, pp 193–198</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-015-0267-3-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Department of Architecture, Design and Media Technology, Aalborg University Copenhagen, A.C. Meyers Vænge 15, 2450, Copenhagen, Denmark</p><p class="c-article-author-affiliation__authors-list">Luca Turchet</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Luca-Turchet"><span class="c-article-authors-search__title u-h3 js-search-name">Luca Turchet</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Luca+Turchet&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Luca+Turchet" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Luca+Turchet%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-015-0267-3/email/correspondent/c1/new">Luca Turchet</a>.</p></div></div></section><section aria-labelledby="ethics"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
              
                <h3 class="c-article__sub-heading">Funding:</h3>
                <p>The research leading to these results has received funding from the Danish Council for Independent Research, Grant No. 12-131985.</p>
              
              
                <h3 class="c-article__sub-heading">Conflict of Interest:</h3>
                <p>The author declares that he has no conflict of interest.</p>
              
              
                <h3 class="c-article__sub-heading">Research involving Human Participants and/or Animals:</h3>
                <p>This work did not involve any research on human participants or animals.</p>
              
            </div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Designing%20presence%20for%20real%20locomotion%20in%20immersive%20virtual%20environments%3A%20an%20affordance-based%20experiential%20approach&amp;author=Luca%20Turchet&amp;contentID=10.1007%2Fs10055-015-0267-3&amp;publication=1359-4338&amp;publicationDate=2015-07-10&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-015-0267-3" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-015-0267-3" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Turchet, L. Designing presence for real locomotion in immersive virtual environments: an affordance-based experiential approach.
                    <i>Virtual Reality</i> <b>19, </b>277–290 (2015). https://doi.org/10.1007/s10055-015-0267-3</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-015-0267-3.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2014-10-25">25 October 2014</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-06-30">30 June 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-07-10">10 July 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-11">November 2015</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-015-0267-3" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-015-0267-3</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Affordance</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Experiential design</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Locomotion interfaces</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Virtual environments</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Presence</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-015-0267-3.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=267;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

