<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Development of a virtual butterfly ecological system based on augmente"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="A campus butterfly garden is a
 useful teaching resource for studying insect ecology because students can learn about a butterfly&#8217;s life cycle and become familiar with its habitual behavior..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/19/3.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Development of a virtual butterfly ecological system based on augmented reality and mobile learning technologies"/>

    <meta name="dc.source" content="Virtual Reality 2015 19:3"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2015-05-21"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2015 Springer-Verlag London"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="A campus butterfly garden is a
 useful teaching resource for studying insect ecology because students can learn about a butterfly&#8217;s life cycle and become familiar with its habitual behavior by breeding and observation activities. However, it requires professional construction and maintenance for sustainable development, so very few schools can afford to own a butterfly garden. In this study, the augmented reality and mobile learning technologies have been used to develop a virtual butterfly ecological system by combining with campus host plants and virtual breeding activities. Students can use smart phones or tablet PCs to breed virtual butterflies on host plants and observe their life cycles at different growing stages. Using the available space in campus, a virtual butterfly garden can also be created as a greenhouse where students are able to observe different species of butterflies using the tracking telescope and catch a butterfly to obtain its information by touch-screen control. The virtual butterfly ecological system can increase the learning motivation and interest of students through virtual breeding and observation activities, so it is a suitable assistant tool for science education. A teaching experiment has been conducted to investigate students&#8217; learning effectiveness and attitudes after using the system, and the results show that using the virtual butterfly ecological system can improve their learning effectively."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2015-05-21"/>

    <meta name="prism.volume" content="19"/>

    <meta name="prism.number" content="3"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="253"/>

    <meta name="prism.endingPage" content="266"/>

    <meta name="prism.copyright" content="2015 Springer-Verlag London"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-015-0265-5"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-015-0265-5"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-015-0265-5.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-015-0265-5"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Development of a virtual butterfly ecological system based on augmented reality and mobile learning technologies"/>

    <meta name="citation_volume" content="19"/>

    <meta name="citation_issue" content="3"/>

    <meta name="citation_publication_date" content="2015/11"/>

    <meta name="citation_online_date" content="2015/05/21"/>

    <meta name="citation_firstpage" content="253"/>

    <meta name="citation_lastpage" content="266"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-015-0265-5"/>

    <meta name="DOI" content="10.1007/s10055-015-0265-5"/>

    <meta name="citation_doi" content="10.1007/s10055-015-0265-5"/>

    <meta name="description" content="A campus butterfly garden is a
 useful teaching resource for studying insect ecology because students can learn about a butterfly&#8217;s life cycle and be"/>

    <meta name="dc.creator" content="Wernhuar Tarng"/>

    <meta name="dc.creator" content="Kuo-Liang Ou"/>

    <meta name="dc.creator" content="Chuan-Sheng Yu"/>

    <meta name="dc.creator" content="Fong-Lu Liou"/>

    <meta name="dc.creator" content="Hsin-Hun Liou"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=Teleop Virtual Environ; citation_title=A survey of augmented reality; citation_author=RT Azuma; citation_volume=6; citation_issue=4; citation_publication_date=1997; citation_pages=355-385; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Gr Appl; citation_title=The magicbook-moving seamlessly between reality and virtuality; citation_author=M Billinghurst, H Kato, I Poupyrev; citation_volume=21; citation_issue=3; citation_publication_date=2001; citation_pages=2-4; citation_id=CR2"/>

    <meta name="citation_reference" content="citation_journal_title=Educ Res; citation_title=Situated cognition and the culture of learning; citation_author=JS Brown, A Collins, P Duguid; citation_volume=18; citation_issue=1; citation_publication_date=1989; citation_pages=32-42; citation_doi=10.3102/0013189X018001032; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_journal_title=J Sci Educ Technol; citation_title=Learning with web tools, simulations, and other technologies in science classrooms; citation_author=T Campbell, SK Wang, H-Y Hsu, AM Duffy, PG Wolf; citation_volume=19; citation_issue=5; citation_publication_date=2010; citation_pages=505-511; citation_doi=10.1007/s10956-010-9217-8; citation_id=CR4"/>

    <meta name="citation_reference" content="citation_title=Butterflies of Taiwan; citation_publication_date=1988; citation_id=CR5; citation_author=WS Chen; citation_publisher=Taiwan Provincial Museum"/>

    <meta name="citation_reference" content="citation_journal_title=J Comput Assist Learn; citation_title=A mobile learning system for scaffolding bird watching learning; citation_author=YS Chen, TC Kao, JP Sheu; citation_volume=19; citation_issue=3; citation_publication_date=2003; citation_pages=347-359; citation_doi=10.1046/j.0266-4909.2003.00036.x; citation_id=CR6"/>

    <meta name="citation_reference" content="Chen YS, Kao TC, Sheu JP (2004) A mobile butterfly-watching learning system for supporting independent learning. In: Proceedings of IEEE workshop on wireless and mobile technologies in education, Taiwan, pp 11&#8211;18"/>

    <meta name="citation_reference" content="citation_journal_title=J Prof Issues Eng Educ Pract; citation_title=Use of tangible and augmented reality models in engineering graphics courses; citation_author=Y-C Chen, H-L Chi, W-H Hung, S-C Kang; citation_volume=137; citation_issue=4; citation_publication_date=2011; citation_pages=267-276; citation_doi=10.1061/(ASCE)EI.1943-5541.0000078; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_journal_title=Br J Educ Technol; citation_title=What are the learning affordances of 3-D virtual environments?; citation_author=B Dalgarno, MJW Lee; citation_volume=41; citation_issue=1; citation_publication_date=2010; citation_pages=10-32; citation_doi=10.1111/j.1467-8535.2009.01038.x; citation_id=CR9"/>

    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Immersive interfaces for engagement and learning; citation_author=C Dede; citation_volume=323; citation_issue=5910; citation_publication_date=2009; citation_pages=66-69; citation_doi=10.1126/science.1167311; citation_id=CR10"/>

    <meta name="citation_reference" content="citation_journal_title=J Sci Educ Technol; citation_title=Affordances and limitations of immersive participatory augmented reality simulations for teaching and learning; citation_author=M Dunleavy, C Dede, R Mitchell; citation_volume=18; citation_issue=1; citation_publication_date=2009; citation_pages=7-22; citation_doi=10.1007/s10956-008-9119-1; citation_id=CR11"/>

    <meta name="citation_reference" content="Harris (2006) Go in mobile. 
                    http://www.learning.circuits.org/2001/jul2001/harris.html
                    
                  . Retrieved 5 May 2006"/>

    <meta name="citation_reference" content="citation_journal_title=J Geogr; citation_title=A mobile learning module for high school fieldwork; citation_author=TY Hsu, CM Chen; citation_volume=109; citation_issue=4; citation_publication_date=2010; citation_pages=141-149; citation_doi=10.1080/00221341.2010.480941; citation_id=CR13"/>

    <meta name="citation_reference" content="Huang TY (2010) A research on combining QR-code and wireless networks to develop an interactive digital learning system for ecological education in an elementary school campus. In: Technical Report, National Science Council (NSC 97-2511-S-153-004)"/>

    <meta name="citation_reference" content="citation_journal_title=Educ Dig; citation_title=Key emerging technologies for elementary and secondary education; citation_author=LF Johnson, A Levine, RS Smith, K Haywood; citation_volume=76; citation_issue=1; citation_publication_date=2010; citation_pages=36-40; citation_id=CR15"/>

    <meta name="citation_reference" content="citation_journal_title=New Dir Youth Dev; citation_title=Augmenting your own reality: student authoring of science-based augmented reality games; citation_author=E Klopfer, J Sheldon; citation_volume=128; citation_publication_date=2010; citation_pages=85-94; citation_doi=10.1002/yd.378; citation_id=CR16"/>

    <meta name="citation_reference" content="citation_title=The observation and breeding of butterflies; citation_publication_date=1986; citation_id=CR17; citation_author=CY Lee; citation_author=SY Wang; citation_publisher=Taiwan Provincial Museum"/>

    <meta name="citation_reference" content="citation_journal_title=Arch Psychol; citation_title=A technique for the measurement of attitudes; citation_author=R Likert; citation_volume=22; citation_issue=40; citation_publication_date=1932; citation_pages=1-55; citation_id=CR18"/>

    <meta name="citation_reference" content="Lin Y-S (2008) Development and effectiveness analysis of a ubiquitous collaborative learning system&#8212;a case study on the butterfly and ecology course of an elementary school. In: Master Thesis, National University of Tainan, Department of Information and Learning Technology, Tainan"/>

    <meta name="citation_reference" content="citation_journal_title=J Comput Assist Learn; citation_title=Wireless and mobile technologies to enhance teaching and learning; citation_author=TC Liu, HY Wang, JK Liang, TW Chan, HW Ko, JC Yang; citation_volume=19; citation_issue=3; citation_publication_date=2003; citation_pages=371-382; citation_doi=10.1046/j.0266-4909.2003.00038.x; citation_id=CR20"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Educ; citation_title=New technology trends in education: seven years of forecasts and convergence; citation_author=S Martin, G Diaz, E Sancristobal, R Gil, M Castro, J Peire; citation_volume=57; citation_issue=3; citation_publication_date=2011; citation_pages=1893-1906; citation_doi=10.1016/j.compedu.2011.04.003; citation_id=CR21"/>

    <meta name="citation_reference" content="citation_title=General guidelines of grades 1&#8211;9 science and life technology curriculum; citation_publication_date=2006; citation_id=CR22; citation_publisher=Ministry of Education"/>

    <meta name="citation_reference" content="citation_journal_title=J Res Sci Teach; citation_title=Student motivation and Internet technology: are students empowered to learn science?; citation_author=M Mistler-Jackson, B Songer; citation_volume=37; citation_publication_date=2000; citation_pages=459-479; citation_doi=10.1002/(SICI)1098-2736(200005)37:5&lt;459::AID-TEA5&gt;3.0.CO;2-C; citation_id=CR23"/>

    <meta name="citation_reference" content="Schilit WN (1995) A system architecture for context-aware mobile computing. In: Unpublished doctoral thesis, Columbia University"/>

    <meta name="citation_reference" content="citation_title=Location-based services; citation_publication_date=2004; citation_id=CR25; citation_author=J Schiller; citation_author=A Voisard; citation_publisher=Morgan Kaufmann"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Mob Learn Organ; citation_title=The development and instructional application of u-library on butterfly and wetland ecology for context-aware ubiquitous learning; citation_author=JL Shih, GJ Hwang, YC Chu; citation_volume=4; citation_issue=3; citation_publication_date=2010; citation_pages=253-268; citation_doi=10.1504/IJMLO.2010.033554; citation_id=CR26"/>

    <meta name="citation_reference" content="ShiVa3D (2013) 
                    http://www.shivaengine.com
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Comput Educ; citation_title=Current status, opportunities and challenges of augmented reality in education; citation_author=H-K Wu, SW-Y Lee, H-Y Chang, J-C Liang; citation_volume=62; citation_publication_date=2013; citation_pages=41-49; citation_doi=10.1016/j.compedu.2012.10.024; citation_id=CR28"/>

    <meta name="citation_author" content="Wernhuar Tarng"/>

    <meta name="citation_author_email" content="wtarng@nhcue.edu.tw"/>

    <meta name="citation_author_institution" content="Graduate Institute of e-Learning Technology, National Hsinchu University of Education, Hsinchu, Taiwan, ROC"/>

    <meta name="citation_author" content="Kuo-Liang Ou"/>

    <meta name="citation_author_email" content="klou@nhcue.edu.tw"/>

    <meta name="citation_author_institution" content="Graduate Institute of e-Learning Technology, National Hsinchu University of Education, Hsinchu, Taiwan, ROC"/>

    <meta name="citation_author" content="Chuan-Sheng Yu"/>

    <meta name="citation_author_email" content="sheng1012@gmail.com"/>

    <meta name="citation_author_institution" content="Graduate Institute of Computer Science, National Hsinchu University of Education, Hsinchu, Taiwan, ROC"/>

    <meta name="citation_author" content="Fong-Lu Liou"/>

    <meta name="citation_author_email" content="dliou@hotmail.com"/>

    <meta name="citation_author_institution" content="Graduate Institute of e-Learning Technology, National Hsinchu University of Education, Hsinchu, Taiwan, ROC"/>

    <meta name="citation_author" content="Hsin-Hun Liou"/>

    <meta name="citation_author_email" content="viviliu0501@gmail.com"/>

    <meta name="citation_author_institution" content="Department of Computer Science and Information Engineering, National Central University, Jhongli, Taiwan, ROC"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-015-0265-5&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2015/11/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-015-0265-5"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Development of a virtual butterfly ecological system based on augmented reality and mobile learning technologies"/>
        <meta property="og:description" content="A campus butterfly garden is a useful teaching resource for studying insect ecology because students can learn about a butterfly’s life cycle and become familiar with its habitual behavior by breeding and observation activities. However, it requires professional construction and maintenance for sustainable development, so very few schools can afford to own a butterfly garden. In this study, the augmented reality and mobile learning technologies have been used to develop a virtual butterfly ecological system by combining with campus host plants and virtual breeding activities. Students can use smart phones or tablet PCs to breed virtual butterflies on host plants and observe their life cycles at different growing stages. Using the available space in campus, a virtual butterfly garden can also be created as a greenhouse where students are able to observe different species of butterflies using the tracking telescope and catch a butterfly to obtain its information by touch-screen control. The virtual butterfly ecological system can increase the learning motivation and interest of students through virtual breeding and observation activities, so it is a suitable assistant tool for science education. A teaching experiment has been conducted to investigate students’ learning effectiveness and attitudes after using the system, and the results show that using the virtual butterfly ecological system can improve their learning effectively."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Development of a virtual butterfly ecological system based on augmented reality and mobile learning technologies | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-015-0265-5","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Augmented reality, Mobile learning, Context awareness, Butterfly ecology","kwrd":["Augmented_reality","Mobile_learning","Context_awareness","Butterfly_ecology"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-015-0265-5","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-015-0265-5","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=265;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-015-0265-5">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Development of a virtual butterfly ecological system based on augmented reality and mobile learning technologies
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-015-0265-5.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-015-0265-5.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2015-05-21" itemprop="datePublished">21 May 2015</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Development of a virtual butterfly ecological system based on augmented reality and mobile learning technologies</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Wernhuar-Tarng" data-author-popup="auth-Wernhuar-Tarng" data-corresp-id="c1">Wernhuar Tarng<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="National Hsinchu University of Education" /><meta itemprop="address" content="grid.412061.0, 0000000097096352, Graduate Institute of e-Learning Technology, National Hsinchu University of Education, Hsinchu, Taiwan, ROC" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Kuo_Liang-Ou" data-author-popup="auth-Kuo_Liang-Ou">Kuo-Liang Ou</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="National Hsinchu University of Education" /><meta itemprop="address" content="grid.412061.0, 0000000097096352, Graduate Institute of e-Learning Technology, National Hsinchu University of Education, Hsinchu, Taiwan, ROC" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Chuan_Sheng-Yu" data-author-popup="auth-Chuan_Sheng-Yu">Chuan-Sheng Yu</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="National Hsinchu University of Education" /><meta itemprop="address" content="grid.412061.0, 0000000097096352, Graduate Institute of Computer Science, National Hsinchu University of Education, Hsinchu, Taiwan, ROC" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Fong_Lu-Liou" data-author-popup="auth-Fong_Lu-Liou">Fong-Lu Liou</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="National Hsinchu University of Education" /><meta itemprop="address" content="grid.412061.0, 0000000097096352, Graduate Institute of e-Learning Technology, National Hsinchu University of Education, Hsinchu, Taiwan, ROC" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Hsin_Hun-Liou" data-author-popup="auth-Hsin_Hun-Liou">Hsin-Hun Liou</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="National Central University" /><meta itemprop="address" content="grid.37589.30, 0000000405323167, Department of Computer Science and Information Engineering, National Central University, Jhongli, Taiwan, ROC" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 19</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">253</span>–<span itemprop="pageEnd">266</span>(<span data-test="article-publication-year">2015</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">1306 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">29 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-015-0265-5/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>A campus butterfly garden is a
 useful teaching resource for studying insect ecology because students can learn about a butterfly’s life cycle and become familiar with its habitual behavior by breeding and observation activities. However, it requires professional construction and maintenance for sustainable development, so very few schools can afford to own a butterfly garden. In this study, the augmented reality and mobile learning technologies have been used to develop a virtual butterfly ecological system by combining with campus host plants and virtual breeding activities. Students can use smart phones or tablet PCs to breed virtual butterflies on host plants and observe their life cycles at different growing stages. Using the available space in campus, a virtual butterfly garden can also be created as a greenhouse where students are able to observe different species of butterflies using the tracking telescope and catch a butterfly to obtain its information by touch-screen control. The virtual butterfly ecological system can increase the learning motivation and interest of students through virtual breeding and observation activities, so it is a suitable assistant tool for science education. A teaching experiment has been conducted to investigate students’ learning effectiveness and attitudes after using the system, and the results show that using the virtual butterfly ecological system can improve their learning effectively.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Observing an insect’s life cycle is an important teaching activity in life science education. By observing eggs hatching into larvae, becoming pupas and imagoes, laying eggs and finally dying, students can understand the continuation of life and develop the sentiments of respecting life (Lee and Wang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1986" title="Lee CY, Wang SY (1986) The observation and breeding of butterflies. Taiwan Provincial Museum, Taipei" href="/article/10.1007/s10055-015-0265-5#ref-CR17" id="ref-link-section-d78314e425">1986</a>). Butterflies are beautiful insects with light and graceful bodies, and their dazzling colors and elegant dances instill vigor and vitality into the nature. A large number of butterflies, in the wild or in captivity, can always attract lots of visitors, so they are helpful to tourism. Regarding the natural ecology, it is an indispensable part of the food chain. The butterfly helps pollinate plants by spreading pollen when collecting nectar; the larva eats plants; the adult butterfly is the food of other predatory animals. Therefore, it is not only a beautiful insect but also a valuable resource in ecological environments.</p><p>Taiwan is located in the junction of subtropical and tropical areas. Due to its special climate, topography, ecological environment and abundant nectar plants, Taiwan has more than 400 species of butterflies, the largest variety in the world, and was once known as the Kingdom of Butterflies. In recent decades, the overexploitation of mountains has devastated the butterfly habitats and resulted in the decrease of butterfly species and populations. The overuse of pesticide further jeopardized their survivals (Chen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Chen WS (1988) Butterflies of Taiwan. Taiwan Provincial Museum, Taipei" href="/article/10.1007/s10055-015-0265-5#ref-CR5" id="ref-link-section-d78314e431">1988</a>). Butterflies need to live in proper natural environments. Most schools in Taiwan are located in metropolitan areas without suitable butterfly habitats, so only a few butterfly species may exist in campus. For the purposes of education and recreation, insect museums and butterfly gardens can often be found in subtropical and tropical countries to exhibit butterflies, specimens and multimedia information for the purposes of science education and the related research.</p><p>Butterflies and insects are often found in the teaching materials of science education in elementary and high schools. As a result, converting the green areas in campus into butterfly habitats by planting more host plants and nectar pants can attract butterflies to provide a useful teaching resource for science teachers. Also, students can obtain knowledge about butterfly ecology through breeding and observation activities. If the green areas are further designed as butterfly gardens, they are more suitable for applications in science education. Considering the required cost and manpower for development, an open butterfly garden is more economical and cost-effective, but a greenhouse is less affected by weather such that teachers may have more control of observation time to achieve the expected learning results. However, a butterfly garden requires professional planning, construction and maintenance for sustainable development, so very few schools can afford to own a butterfly garden.</p><p>As the advance of information and communication technology (ICT), the mobile devices such as personal digital assistants (PDA), smart phones and tablet PCs have been widely applied in school teaching. Consequently, human learning is not confined to classroom, and it can be done anytime and anywhere using any device (Harris <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Harris (2006) Go in mobile. &#xA;                    http://www.learning.circuits.org/2001/jul2001/harris.html&#xA;                    &#xA;                  . Retrieved 5 May 2006" href="/article/10.1007/s10055-015-0265-5#ref-CR12" id="ref-link-section-d78314e440">2006</a>). In 1970, Schiller and Voisard (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Schiller J, Voisard A (2004) Location-based services. Morgan Kaufmann, San Francisco" href="/article/10.1007/s10055-015-0265-5#ref-CR25" id="ref-link-section-d78314e443">2004</a>) proposed the concept of context awareness by using the global positioning system (GPS) to obtain a user’s location for providing services. Its main idea is to satisfy the user’s sensational requirement by updating the information according to environmental changes such as the current time and position (Schilit <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Schilit WN (1995) A system architecture for context-aware mobile computing. In: Unpublished doctoral thesis, Columbia University" href="/article/10.1007/s10055-015-0265-5#ref-CR24" id="ref-link-section-d78314e446">1995</a>).</p><p>There has been a lot of research on applying mobile devices to provide context awareness and ubiquitous learning services. For example, Lin (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Lin Y-S (2008) Development and effectiveness analysis of a ubiquitous collaborative learning system—a case study on the butterfly and ecology course of an elementary school. In: Master Thesis, National University of Tainan, Department of Information and Learning Technology, Tainan" href="/article/10.1007/s10055-015-0265-5#ref-CR19" id="ref-link-section-d78314e453">2008</a>) used RFID, wireless networks and a pattern recognition system to develop a butterfly ecology learning system. The system can obtain the related information in the user’s environment to provide adaptive learning contents. However, the teachers have to attach RFID tags to the leaves of nectar plants to trigger the learning activities, and the students may not be able to observe some butterflies due to the seasonal problem. Huang (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Huang TY (2010) A research on combining QR-code and wireless networks to develop an interactive digital learning system for ecological education in an elementary school campus. In: Technical Report, National Science Council (NSC 97-2511-S-153-004)" href="/article/10.1007/s10055-015-0265-5#ref-CR14" id="ref-link-section-d78314e456">2010</a>) developed an interactive mobile learning system by using QR codes and wireless networks for studying the campus ecology in an elementary school. The user can obtain knowledge about a plant by scanning its QR codes with a pocket PC. In addition to the information on the interpretative board, the user can learn about campus plants by online searching through wireless networks. The learning process is more interactive and thus can enhance the user’s comprehension. Sometimes, it is not very convenient for students to find out and scan the QR codes to obtain knowledge about a plant. Besides, the teachers have to spend a lot of effort deploying the QR code system in the campus for students to use.</p><p>Chen et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Chen YS, Kao TC, Sheu JP (2003) A mobile learning system for scaffolding bird watching learning. J Comput Assist Learn 19(3):347–359" href="/article/10.1007/s10055-015-0265-5#ref-CR6" id="ref-link-section-d78314e462">2003</a>) developed a bird watching and learning system for science teachers to conduct outdoor teaching using a PDA. The teacher must install the server on a notebook to create a database for learning the bird ecology. During outdoor teaching, the teacher sends a bird’s image via wireless networks to students’ PDAs, and they can search for the bird’s information immediately. A similar technology was used to develop a mobile butterfly observation system (Chen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Chen YS, Kao TC, Sheu JP (2004) A mobile butterfly-watching learning system for supporting independent learning. In: Proceedings of IEEE workshop on wireless and mobile technologies in education, Taiwan, pp 11–18" href="/article/10.1007/s10055-015-0265-5#ref-CR7" id="ref-link-section-d78314e465">2004</a>) where the images of observed butterflies can be used to search for their information, which is sent back to the students to provide instant feedback. However, the outdoor observation may take a long time in finding butterflies, and their images sometimes may not be clear enough for comparison to obtain the required information.</p><p>Learning with mobile devices such as smart phones, PDAs and tablet PCs is not limited by time or space. Besides, the teacher can monitor a student’s learning status to provide suitable assistance as needed (Liu et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Liu TC, Wang HY, Liang JK, Chan TW, Ko HW, Yang JC (2003) Wireless and mobile technologies to enhance teaching and learning. J Comput Assist Learn 19(3):371–382" href="/article/10.1007/s10055-015-0265-5#ref-CR20" id="ref-link-section-d78314e471">2003</a>). With the integration of ICT and learning environments, outdoor teaching becomes more flexible and interactive. For example, Shih et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Shih JL, Hwang GJ, Chu YC (2010) The development and instructional application of u-library on butterfly and wetland ecology for context-aware ubiquitous learning. Int J Mob Learn Organ 4(3):253–268" href="/article/10.1007/s10055-015-0265-5#ref-CR26" id="ref-link-section-d78314e474">2010</a>) developed a digital library for mobile and ubiquitous learning situations and it was used to help teach elementary students in learning butterflies and wetland ecology. The experimental results showed that the system received positive responses from students in respect to website design, system uniqueness and potential to instruction. Hsu and Chen (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Hsu TY, Chen CM (2010) A mobile learning module for high school fieldwork. J Geogr 109(4):141–149" href="/article/10.1007/s10055-015-0265-5#ref-CR13" id="ref-link-section-d78314e477">2010</a>) designed a mobile-assisted module for guiding students through field study without a teacher’s presence. A teaching experiment was conducted, and the results showed that the module received positive feedbacks from teachers and most students. It was also discovered that the mobile learning technology had great potential to facilitate independent learning by students in the field study.</p><p>In recent years, mobile devices are equipped with powerful sensors to support applications with the augmented reality (AR) technology. AR is focused on the integration of virtual objects and situations with real environments to increase the interaction with users. Azuma (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Azuma RT (1997) A survey of augmented reality. Teleop Virtual Environ 6(4):355–385" href="/article/10.1007/s10055-015-0265-5#ref-CR1" id="ref-link-section-d78314e483">1997</a>) defined AR as an evolution of virtual reality (VR) with the following features: (1) interacting with real and virtual environments, (2) providing real-time feedbacks and (3) presenting in 3D space. Compared to the operation of VR, AR integrates a real environment with virtual 3D objects to increase their perception and enhance the sense of reality as well. With the powerful sensor functions on mobile devices and the popularity of iPhones and Android smart phones, AR software has become highly developed to provide its users with realistic feeling such that learning activities can be conducted in a sensational and interactive way.</p><p>Klopfer and Sheldon (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Klopfer E, Sheldon J (2010) Augmenting your own reality: student authoring of science-based augmented reality games. New Dir Youth Dev 128:85–94" href="/article/10.1007/s10055-015-0265-5#ref-CR16" id="ref-link-section-d78314e489">2010</a>) defined AR as a technology that combines real-world and virtual world experiences. In general, the implementation of AR can be categorized as: (1) traditional AR, which requires a marker for positioning, e.g., the Magic Book (Billinghurst et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Billinghurst M, Kato H, Poupyrev I (2001) The magicbook-moving seamlessly between reality and virtuality. Comput Gr Appl 21(3):2–4" href="/article/10.1007/s10055-015-0265-5#ref-CR2" id="ref-link-section-d78314e492">2001</a>), (2) AR without a marker, in which positioning is done by GPS or image detection, such as annotating existing spaces with an overlay of location-based information (Johnson et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Johnson LF, Levine A, Smith RS, Haywood K (2010) Key emerging technologies for elementary and secondary education. Educ Dig 76(1):36–40" href="/article/10.1007/s10055-015-0265-5#ref-CR15" id="ref-link-section-d78314e495">2010</a>), and (3) AR combining a marker and image detection for positioning. Therefore, AR can increase interaction with the real world and provide useful information enabling learners to experience scientific phenomena which could not otherwise be experienced in the real world (Wu et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Wu H-K, Lee SW-Y, Chang H-Y, Liang J-C (2013) Current status, opportunities and challenges of augmented reality in education. Comput Educ 62:41–49" href="/article/10.1007/s10055-015-0265-5#ref-CR28" id="ref-link-section-d78314e498">2013</a>).</p><p>Educators and researchers are enthusiastic about new possibilities for teaching and learning provided by AR (Dalgarno and Lee <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Dalgarno B, Lee MJW (2010) What are the learning affordances of 3-D virtual environments? Br J Educ Technol 41(1):10–32" href="/article/10.1007/s10055-015-0265-5#ref-CR9" id="ref-link-section-d78314e504">2010</a>; Martin et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Martin S, Diaz G, Sancristobal E, Gil R, Castro M, Peire J (2011) New technology trends in education: seven years of forecasts and convergence. Comput Educ 57(3):1893–1906" href="/article/10.1007/s10055-015-0265-5#ref-CR21" id="ref-link-section-d78314e507">2011</a>). A mobile AR system integrates mobile devices, wireless networks and GPS technology, and can enable ubiquitous, collaborative and situated learning enhanced by computer simulations, games, models and virtual objects in real environments (Dunleavy et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Dunleavy M, Dede C, Mitchell R (2009) Affordances and limitations of immersive participatory augmented reality simulations for teaching and learning. J Sci Educ Technol 18(1):7–22" href="/article/10.1007/s10055-015-0265-5#ref-CR11" id="ref-link-section-d78314e510">2009</a>; Chen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Chen Y-C, Chi H-L, Hung W-H, Kang S-C (2011) Use of tangible and augmented reality models in engineering graphics courses. J Prof Issues Eng Educ Pract 137(4):267–276" href="/article/10.1007/s10055-015-0265-5#ref-CR8" id="ref-link-section-d78314e513">2011</a>). Artificial information about the environments and virtual objects in the form of texts, images and video can be overlaid and help learners engage in authentic environments with mobile devices (Dede <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Dede C (2009) Immersive interfaces for engagement and learning. Science 323(5910):66–69" href="/article/10.1007/s10055-015-0265-5#ref-CR10" id="ref-link-section-d78314e516">2009</a>). Furthermore, when learning is supported by technology, students can be more easily motivated to engage in inquiry-based instruction (Campbell et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Campbell T, Wang SK, Hsu H-Y, Duffy AM, Wolf PG (2010) Learning with web tools, simulations, and other technologies in science classrooms. J Sci Educ Technol 19(5):505–511" href="/article/10.1007/s10055-015-0265-5#ref-CR4" id="ref-link-section-d78314e520">2010</a>; Mistler-Jackson and Songer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Mistler-Jackson M, Songer B (2000) Student motivation and Internet technology: are students empowered to learn science? J Res Sci Teach 37:459–479" href="/article/10.1007/s10055-015-0265-5#ref-CR23" id="ref-link-section-d78314e523">2000</a>).</p><p>In this study, a virtual butterfly ecological system has been developed using AR and mobile learning technologies to combine with the host plants and nectar plants in a school campus. Students can use smart phones or tablet PCs to breed virtual butterflies on host plants to observe their life cycles at different growing stages. They can search for the information about the butterflies through wireless networks. The virtual butterfly garden can also be designed as a greenhouse at an open area in campus with different species of butterflies flying above beautiful flowers. Students can observe butterflies using a tracking telescope and capture a butterfly on the touch screen to obtain the related information. When the natural enemies of a butterfly appear, students can help expel them and become familiar with the food-chain relationship between the butterfly and its natural enemies at different growing stages.</p><p>During real butterfly breeding activities, students often face the problems that their butterflies die, pupate or break the pupas at night, missing the observation time for recording the important stages of life cycles. Also, the lecture time of a few weeks is too short for observing the complete life cycle. Using the proposed virtual butterfly ecological system, students can conduct long-term breeding and observation activities without the limitation of time or space; it can also remind them of the time for pupating or breaking pupas with a message to make observation and recording data more easily. The system is a suitable assistant tool for elementary and high school science education. Science teachers can set up the system according to campus environments for students to conduct observation and breeding activities. The city government can also use it to create virtual butterfly ecological environments at the park or nature reservation areas for the general public if they are interested in learning the butterfly ecology.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">System design</h2><div class="c-article-section__content" id="Sec2-content"><p>This study used the AR technology and sensor functions on mobile devices, including the touch screen, GPS, electronic compass, three-axis accelerometer and 3G network, to develop a virtual butterfly ecological system. It combines with the host plants and nectar plants in campus for elementary and high school students to participate in learning butterfly ecology activities more easily. They can use smart phones or tablet PCs to breed virtual butterflies on host plants to observe their life cycles at different growing stages (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0265-5#Fig1">1</a>). In the virtual butterfly garden, they can also use the tracking telescope to observe a butterfly and catch it with touch-screen control to obtain the butterfly’s information. The virtual butterfly ecological system solves the problems of constructing and maintaining a real butterfly garden as well as insufficient butterfly species and amounts. It supports a context awareness environment to increase the learning interest and motivation of students by virtual breeding and observation activities. The system serves both educational and entertaining functions, and is therefore a suitable assistant tool for elementary and high school science education.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig1_HTML.jpg" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Using a smart phone to observe virtual butterflies on host plants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>In this study, a virtual butterfly ecological system has been designed according to the learning unit “Life of a butterfly” in the grades 1–9 Science and Life Technology Curriculum in Taiwan (Ministry of Education <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Ministry of Education (2006) General guidelines of grades 1–9 science and life technology curriculum. Ministry of Education, Taipei" href="/article/10.1007/s10055-015-0265-5#ref-CR22" id="ref-link-section-d78314e565">2006</a>) for fourth graders in elementary schools. An analysis was first conducted to understand its background knowledge and learning contents. Then, the system was designed based on the course outlines and the learning objectives. Since the theory of situated learning emphasizes the reality of learning activities (Brown et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1989" title="Brown JS, Collins A, Duguid P (1989) Situated cognition and the culture of learning. Educ Res 18(1):32–42" href="/article/10.1007/s10055-015-0265-5#ref-CR3" id="ref-link-section-d78314e568">1989</a>), the instructional design was focused on the connection with daily-life experiences to provide students with learning activities related to real situations, for example, breeding and observing butterflies.</p><p>The system was developed according to the learning contents of natural science textbooks related to the butterfly ecology, which mainly included the following topics:</p><ul class="u-list-style-bullet">
                  <li>
                    <p>What is an insect?</p>
                  </li>
                  <li>
                    <p>How to name an insect?</p>
                  </li>
                  <li>
                    <p>The classification of butterflies</p>
                  </li>
                  <li>
                    <p>The life cycle of a butterfly</p>
                  </li>
                  <li>
                    <p>The distribution of butterflies in Taiwan</p>
                  </li>
                  <li>
                    <p>Breeding butterflies</p>
                  </li>
                  <li>
                    <p>How to distinguish the sex of butterflies?</p>
                  </li>
                  <li>
                    <p>A butterfly’s natural enemies and the defense</p>
                  </li>
                  <li>
                    <p>Conservation of butterflies</p>
                  </li>
                </ul>
                     <p>After analyzing the learning contents, the virtual butterfly ecological system was developed based on the concepts of situated learning and context awareness to enhance students’ learning interest and motivation. In the following, the design of butterfly models, AR ecological environments and the virtual butterfly garden as well as the user interface and application programs using the sensor functions on mobile devices are described.</p><h3 class="c-article__sub-heading" id="Sec3">Butterfly models and motion design</h3><p>In this study, the major part of system design is the virtual scene of the butterfly garden, the dynamic visual effects of butterflies and the life cycle simulation. When designing the butterfly models, the scanned images of butterflies were obtained by removing their background to produce the outlines and texture materials. Then, the outlines were drawn from different elevations through observation, and the 3D model of a butterfly was determined by drawing the curves along its outlines. Finally, the texture image was pasted to its surface (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0265-5#Fig2">2</a>), and then, the model is exported to Shiva3D (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="ShiVa3D (2013) &#xA;                    http://www.shivaengine.com&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-015-0265-5#ref-CR27" id="ref-link-section-d78314e646">2013</a>) for the design of its flying motion. The completed model can fly and change its direction in the 3D virtual scene under the control of an API program in Shiva3D based on a probabilistic model.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Pasting texture to the surface of a butterfly model</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>To simulate the flying motion of a butterfly in the virtual 3D space, a probabilistic model to simulate its flying motion and rotation was created according to the habitual behavior of butterflies. A state-transition model was used to imitate the behavior of a butterfly, and the time intervals for a state transition were randomly generated. When the probabilities of a state-transition matrix are determined, a probabilistic model is used to simulate the motion of a butterfly. By using the probabilistic model, even the same kind of butterflies (with the same 3D model) will follow different paths in their flying motions. For different kinds of butterflies, the parameters for a state transition can be adjusted to imitate different motions such as flying, mating and foraging (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0265-5#Fig3">3</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig3_HTML.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig3_HTML.jpg" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>State-transition model to simulate the flying motion</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>In this study, three kinds of virtual butterfly models, i.e., Lime Butterfly, Common Rose Swallowtail and Paper Kite, were developed for breeding and observation activities. To simulate their life cycles, the images of their eggs, larvae, pupas and imagoes as well as the periods of the growing stages were obtained (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0265-5#Fig4">4</a>) for the design of 3D models and control programs to make the breeding activity more realistic.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Simulation of a butterfly’s life cycle</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec4">Virtual butterfly garden</h3><p>The user can enter the virtual butterfly garden by following the guidance of GPS. The virtual butterfly garden is designed as a greenhouse where different species of butterflies are flying around the host plants and nectar plants. There are two buttons on the screen, i.e., the tracking telescope and the online quiz. The user can use the tracking telescope to observe butterflies and try to catch a butterfly to obtain its information (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0265-5#Fig5">5</a>). When using the tracking telescope, the system will list the available butterflies for selection. An arrow will appear to show the direction of the selected butterfly, which is marked by a red cross for easy identification. The user can hold the mobile device toward the direction of the tracked butterfly. When approaching the target within a certain distance, the user can catch the butterfly by touching it on the screen to show the related information. Besides, the user can take an online quiz to earn some virtual money. The operating procedure of the virtual butterfly garden is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0265-5#Fig6">6</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig5_HTML.jpg?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig5_HTML.jpg" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Using the tracking telescope to observe a butterfly</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Operating procedure of the virtual butterfly garden</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec5">Host plant areas</h3><p>The main functions of the host plant area include: breeding butterflies, animations to show the changes of a butterfly at different growing stages and the online quiz. The operating procedure of the host plant area is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0265-5#Fig7">7</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig7_HTML.gif?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig7_HTML.gif" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Operating procedure of the host plant area</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <ul class="u-list-style-bullet">
                    <li>
                      <p>Breeding butterflies: A list of butterfly species is shown for selection. A warning message will appear if the user does not have enough money to buy eggs for breeding. Even if the user has enough money, the system will still evaluate if the selected butterfly is suitable for growing on the host plant; if not, the system will inform the user about such a condition; otherwise, the butterfly egg will appear on the host plant, and the breeding list will be updated.</p>
                    </li>
                    <li>
                      <p>Animation for different growing stages: When the user enters a host plant area, the system will obtain the data of the bred butterflies and play the animation of the selected butterfly to show the change based on its growing stage.</p>
                    </li>
                    <li>
                      <p>Online quiz: The system will randomly ask questions, designed by the teacher, about the learning unit “Life of a butterfly”; if the user answers correctly, some virtual money will be awarded and the database will be updated. The virtual money can then be used to purchase butterfly eggs. If the answer is wrong, the user can choose to answer the next question or return to the function of breeding butterflies.</p>
                    </li>
                  </ul>
                        <p>In a host plant area, the users can find virtual butterflies that they have bred; the butterflies may be at different growing stages such as the egg, larva, pupa and imago. If no butterflies have been bred, a butterfly suitable for growing in this area will appear as the default object. When entering a host plant area, three buttons will appear on the screen, namely “Breeding butterfly”, “Watching butterfly animation” and “Online quiz”. Clicking the first button will show the list of available butterfly species for selection. After selecting a butterfly species, the system will decide whether it is suitable for breeding in this area and whether the user has enough money to buy it. After selecting a suitable species, a new butterfly egg will appear on the host plant and the database is updated by adding it to the user’s breeding list. The user can visit this area again later to observe its growth at different stages (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0265-5#Fig8">8</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig8_HTML.jpg?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig8_HTML.jpg" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Observing a lime butterfly hatching from egg to caterpillar</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>When the user is in a host plant area, natural enemies may appear occasionally to attack the butterflies according to the food-chain relationship (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0265-5#Fig9">9</a>). For example, a stinkbug only attacks larvae and pupas. Once the user discovers a natural enemy, the screen will show the life values of the butterfly and its natural enemy. Also, there is an arrow pointing at the enemy to show its position. By pressing the enemy on the screen and moving around continuously, the user can drive it away to save the butterfly. If the enemy is expelled or the butterfly is dead, the system will show the food-chain relationship between the butterfly and its natural enemy (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0265-5#Fig10">10</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig9_HTML.jpg?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig9_HTML.jpg" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Natural enemy appears to attack the butterfly</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig10_HTML.gif?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig10_HTML.gif" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Natural enemies of butterflies at different growing stages</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec6">System functions</h3><p>The system was developed using the software Shiva3D and 3ds Max executed on the operating system of Microsoft Windows. In addition, the tools of JDK, Android 1.5 SDK, Eclipse and Android Development Tool Plug-in software were also required. After the completion of system design, ShiVa3D’s Authoring Tool was used to convert it to the installation file (.apk) for publication on Google Play for users to download. The system modules include: GPS, three-axis accelerometer, electronic compass, camera control, tracking telescope, butterfly garden, breeding activity, online quiz, database and the related API programs, which will be introduced later in this section.</p><p>The virtual butterfly ecological system can be executed on Android mobile devices. For educational applications, science teachers can download it from Google Play and install on smart phones or tablet PCs. During operation, the system is connected to MySQL database by PHP programs (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0265-5#Fig11">11</a>). The login permissions are divided into users and system managers. The former can use the system for learning knowledge about butterfly ecology. The latter can set the GPS coordinates of host plant areas and the virtual butterfly garden, and they can also enter the system to modify the data about virtual butterflies, host plants, learning contents and test items in the database. When setting up the learning environment, the system managers have to go to each host plant area to record the GPS coordinates and input the basic information of the host plant. Also, they have to create the user account for each student.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig11_HTML.gif?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig11_HTML.gif" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Data flow between the server and mobile devices</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The system integrates the virtual butterflies and virtual butterfly garden with the real campus environment by using the sensor functions and overlay display technique on the mobile device to interact with the users in an AR environment, for example, using a mobile device to locate the user’s position and orientation in the virtual butterfly garden (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0265-5#Fig12">12</a>). When the system is started, the GPS, electronic compass and three-axis accelerometer are initialized first. By entering the user name and password, the user can login to the system if both are correct. After that, the user’s personal information is updated first, and the bred butterflies will appear in the host plant areas and the virtual butterfly garden according to their growing stages and the GPS coordinates on the mobile device.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig12_HTML.gif?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig12_HTML.gif" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Using a mobile device to locate the user’s position and orientation in the virtual butterfly garden</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The users can observe virtual butterflies in campus using smart phones or tablet PCs, and breed virtual butterflies on host plants to conduct observation activities. They can also observe butterflies using the tracking telescope in the virtual butterfly garden to become familiar with different butterfly species. The operating procedure of the virtual butterfly ecological system is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0265-5#Fig13">13</a>, and the major functions of the system can be found in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0265-5#Fig14">14</a>. By clicking the green arrow on the right, the users can open the main menu to use the functions of “Personal information”, “My butterflies”, “Where to go” and “Logout” as described in the following:</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-13"><figure><figcaption><b id="Fig13" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 13</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/13" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig13_HTML.gif?as=webp"></source><img aria-describedby="figure-13-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig13_HTML.gif" alt="figure13" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-13-desc"><p>Operation of the virtual butterfly ecological system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/13" data-track-dest="link:Figure13 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-14"><figure><figcaption><b id="Fig14" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 14</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/14" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig14_HTML.jpg?as=webp"></source><img aria-describedby="figure-14-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig14_HTML.jpg" alt="figure14" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-14-desc"><p>Major functions shown on the main menu</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/14" data-track-dest="link:Figure14 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <ul class="u-list-style-bullet">
                    <li>
                      <p>Personal information: The screen will show the user name, owned virtual money, current location, compass direction and butterfly cards (for all adult butterflies in the host plant areas).</p>
                    </li>
                    <li>
                      <p>My butterfly: The butterflies bred by the user in all areas will be shown as a list.</p>
                    </li>
                    <li>
                      <p>Where to go: The user can choose the location of a host plant area or the virtual butterfly garden, and its orientation will be indicated by an arrow for direction.</p>
                    </li>
                    <li>
                      <p>Logout: Logout from the system.</p>
                    </li>
                  </ul>
                        <p>In this study, the functions of GPS, electronic compass and three-axis accelerometer on mobile devices were used to obtain the user’s position and orientation from the Sensor Event API in Shiva3D. The last two sensors provide the data of (1) orientation, including Azimuth, Pitch and Roll, and (2) acceleration, including the accelerations in X, Y and Z directions minus the gravity (9.81 m/s<sup>2</sup>). The data can also be used to measure the user’s motion. During its operation, the system uses the GPS coordinates to determine whether the user is approaching a designated area and decide whether the system should display a virtual scene and butterflies to trigger the breeding or observation activities by downloading data from the server via the wireless network (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0265-5#Fig15">15</a>). The orientation data are used to control the camera to simulate the user’s perception in a virtual scene, e.g., the virtual butterfly garden.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-15"><figure><figcaption><b id="Fig15" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 15</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/15" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig15_HTML.gif?as=webp"></source><img aria-describedby="figure-15-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0265-5/MediaObjects/10055_2015_265_Fig15_HTML.gif" alt="figure15" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-15-desc"><p>Using GPS and wireless networks to locate the user’s position</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0265-5/figures/15" data-track-dest="link:Figure15 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Based on the GPS coordinates, the related situations will be triggered such as breeding and observing butterflies. Sometimes, a butterfly may be attacked by its natural enemies during observation. The scenes are divided into the virtual butterfly garden and host plant areas. The virtual butterfly garden is a greenhouse where the user can observe butterflies using the tracking telescope and catch them on the touch screen to obtain their information. When the user is in a host plant area, he or she can breed and observe virtual butterflies on host plants and take an online quiz to earn some virtual money by answering the questions correctly; the virtual money can be used to buy butterfly eggs for breeding. This function is also available in the virtual butterfly garden. Because the GPS on the mobile device may not be very accurate such that the system will show butterflies within the distance of 10 m from the designated plant area. To solve this problem, we created the virtual leaves for the same types of plants such that the eggs, larvae and pupas are attached to a virtual leaf instead of floating in midair.</p></div></div></section><section aria-labelledby="Sec7"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7">Quasi-experiment</h2><div class="c-article-section__content" id="Sec7-content"><p>To analyze the learning effectiveness of students after using the virtual butterfly ecological system, a quasi-experiment was conducted at an elementary school in North Taiwan. Two classes of fourth-grade students (each containing 30 students) were used as experimental samples, one as the experimental group and the other as the control group. This study used the “nonequivalent groups pretest and posttest” experimental design to investigate whether different teaching tools would lead to different learning effectiveness. In this experiment, the independent term is the teaching tool; the dependent term is students’ ability after learning; the covariant term is student’s ability before learning; the control variants are the teacher, teaching time and learning contents. A questionnaire survey was conducted to analyze the attitudes of the experimental group after using the system, and the questions were divided into three categories: learning contents, interface design and applications. Its results can also be used as a reference for improving the system.</p><p>Both groups of students took the pretest 1 week before the teaching experiment. Then, the teacher spent an hour to demonstrate to the experimental group about how to use the virtual butterfly ecological system on tablet PCs. On the other hand, he taught the control group how to breed moths at home for observing their changes in life cycle. Then, both groups studied the learning unit of “Life of a butterfly” for 6 weeks. During this period of time, the experimental group used tablet PCs to breed and observe virtual butterflies in campus, while the control group bred and observed moths by feeding them with mulberry leaves at home. Six weeks later, both groups took the posttest to compare if a significant difference existed in their learning effectiveness.</p><p>The test questions included the breeding process, butterfly ecology, life cycle, and natural enemies. To ensure their reliability and validity, the test questions were designed based on the learning contents, course outlines and learning objectives listed in textbooks. Thirty students from another class of the same grade were asked to take the test to ensure that they understood these questions. Also, two science teachers had reviewed and modified the questions to enhance their validity. Finally, 25 questions were chosen for usage in the pretest and posttest.</p><p>To investigate whether using the virtual butterfly ecological system as an assistant tool could improve students’ learning significantly, this study conducted a one-way ANCOVA, with the pretest as the covariant, the posttest as the dependent variant, and the teaching tool as the independent term. According to the theories of covariant analysis, it is required to examine the regression coefficient within each group to see whether they meet the assumption of statistic equivalence. The descriptive statistics on the regression coefficient test showed that the two linear regressions have the same slope (the significance <i>p</i> = 0.38 &gt; 0.05), indicating the relationship between the covariant term and the dependent term was not affected by the independent term. Hence, it satisfied the hypothesis of equivalent regression coefficients between the control group and experimental group and was therefore qualified for the covariant analysis.</p><p>To find out the learning effectiveness on the unit of “Life of a butterfly”, this study used a paired sample <i>t</i> test to evaluate each group’s pretest and posttest scores to see whether there was a significant difference. The achievement test contains 25 questions, 4 points for each correct answer. According to the results in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0265-5#Tab1">1</a>, the control group and experimental group both improved significantly in the posttest. Therefore, an ANCOVA was conducted to investigate whether a significant difference existed between these two groups.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Descriptive statistics on pretest and posttest</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-015-0265-5/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The one-way ANCOVA used the pretest score as covariate, the teaching tool as independent term, and the posttest score as dependent variable to perform a statistical analysis. The results showed that the pretest scores had a significant impact on the posttest scores. After removing the influence of the covariate, the teaching tool had a significant impact on the posttest score (<i>p</i> = 0.04 &lt; 0.05), indicating the learning effectiveness of the experimental group was significantly higher than that of the control group. Therefore, using the virtual butterfly ecological system could improve students’ learning in butterfly ecology effectively. A further analysis discovered that the experimental group performed better in the questions about the <i>classification of butterflies</i> and their <i>natural enemies</i>.</p><p>The above results could be explained based on the difference and similarity of the intervention between the two groups. Although the control group bred moths by feeding them with mulberry leaves at home to observe the changes of a moth’s life cycle, the two groups had learned the same teaching materials about the butterfly ecology as well as the classification of butterflies and their natural enemies in class for 6 weeks. According to the test results, the reason that the experimental group did better on the classification of butterflies and their natural enemies can be explained by the fact that the students could observe the butterflies and their natural enemies on the virtual butterfly ecological system to enhance their understanding, while the control group did not have the environment to do that.</p><p>When the teaching experiment was completed, a questionnaire survey was conducted to analyze the attitudes of the experimental group after using the system. The questionnaire was designed by discussing with two science teachers and the Cronbach’s <i>α</i> &gt; 0.9, showing its internal consistency is very high. In the questionnaire survey, a number of 20 multiple-choice questions were used to measure students’ attitudes about the system, and they were divided into three sections: ten questions for the learning contents, five questions for the interface design and five questions for the applications. Besides, the first section was further divided into the virtual butterfly garden and host plant areas to study the major functions in different scenes and their interaction with users. The second section mainly explored the smoothness in system operation and how friendly the user interface was designed. The third section investigated the system practicality and effectiveness as well as students’ willingness to use the system in the future. The questionnaire adopted Likert’s (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1932" title="Likert R (1932) A technique for the measurement of attitudes. Arch Psychol 22(40):1–55" href="/article/10.1007/s10055-015-0265-5#ref-CR18" id="ref-link-section-d78314e1268">1932</a>) five-point scale (strongly agree: 5, agree: 4, no comment: 3, disagree: 2 and strongly disagree: 1), and the statistical results are described in the following where <i>M</i> stands for the average score.</p><ol class="u-list-style-none">
                  <li>
                    <span class="u-custom-list-number">1.</span>
                    
                      <p>Learning contents</p>
                      <p>In the host plant areas, most students thought that expelling natural enemies of butterflies made them feel more involved in the learning situation (<i>M</i> = 4.6); they gained more knowledge about the butterfly ecology by reading the information about the food chain after the enemy attack (<i>M</i> = 4.8). Students would review the animations actively to observe the changes of butterflies at different growing stages (<i>M</i> = 4.5). They felt the virtual butterflies were very realistic and the virtual breeding activities were very close to the real one (<i>M</i> = 4.6), and they felt the flying motions of butterflies were realistic (<i>M</i> = 4.5). They would like to capture butterflies to gain more information about different species. In the virtual butterfly garden, most students used the tracking telescope actively to observe butterflies and they felt as if situated in a real butterfly garden (<i>M</i> = 4.8).</p>
                    
                  </li>
                </ol>
                     <p>Students were willing to take the online quiz (<i>M</i> = 4.6), and they considered the description of learning contents was easy to understand; they agreed with acquiring knowledge about butterfly ecology using AR technology (<i>M</i> = 4.5). Most students thought the interaction increased their knowledge about butterflies (<i>M</i> = 4.6). They felt the 3D butterfly models helped them understand butterflies and the system was designed with proper hints and rewards (<i>M</i> = 4.5). In general, the students thought the AR technology created more interaction and it motivated them to learn butterfly knowledge. Most students had the willingness to take the online quiz to earn more virtual money to buy butterfly eggs for breeding, and they would like to learn more knowledge about the butterfly ecology.</p><ol class="u-list-style-none">
                  <li>
                    <span class="u-custom-list-number">2.</span>
                    
                      <p>Interface design</p>
                      <p>Most students (<i>M</i> = 4.8) found the interface easy to operate and they thought the system was interesting. They found the fonts were of proper sizes and the interface design was consistent (<i>M</i> = 4.6). They thought the menu pages would not interfere with the system operation and the butterfly models were very similar to real butterflies. They agreed that the system operation was smooth and easy to logout without worrying that the data might not be saved (<i>M</i> = 4.3).</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">3.</span>
                    
                      <p>Applications</p>
                      <p>Most students agreed that the system could increase their confidence and interest in breeding butterfly (<i>M</i> = 4.6) and it helped them understand the relationship between butterflies, host plants and nectar plants. They would like to use it as an assistant tool in learning butterfly ecology and were satisfied with its usage (<i>M</i> = 4.8). Most students felt they could know more about the life cycle and growing stages of butterflies after using the system (<i>M</i> = 4.5). They thought the system could improve their knowledge about butterflies and would like to use it again in the future (<i>M</i> = 4.6). After the questionnaire survey, the researchers received more feedback from the experimental group’s class blog.</p>
                    
                  </li>
                </ol>
                     <p>Further interviews with students revealed the following findings. The virtual butterfly ecological system enabled students to situate as if in a real butterfly garden where they could use the tracking telescope to observe a butterfly and catch it with the touch screen to obtain the relative knowledge. At the outdoor plant areas, they were willing to take an online quiz to learn about the butterfly ecology while earning virtual money to buy butterfly eggs for breeding. They could also observe the changes of life cycle as well as a butterfly’s nature enemies to understand their relationships in the food chain. Therefore, most students gave very high scores when answering the questionnaire. The opinions of students, combined with questionnaire results, are summarized in the following:</p><ul class="u-list-style-bullet">
                  <li>
                    <p>The breeding and observation activities on the system are very interesting and convenient.</p>
                  </li>
                  <li>
                    <p>The system encourages students to acquire knowledge about the butterfly ecology more actively.</p>
                  </li>
                  <li>
                    <p>The virtual scenes and butterflies are very realistic, and the students would like to use it again in the future.</p>
                  </li>
                </ul>
                     </div></div></section><section aria-labelledby="Sec8"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Conclusions</h2><div class="c-article-section__content" id="Sec8-content"><p>Learning by playing has always been an ideal approach for many educators. This study used AR and mobile learning technologies to develop a virtual butterfly ecological system by combining with the host plants and nectar plants in campus. Students can use smart phones or tablet PCs to breed virtual butterflies on host plants to observe their life cycles at different growing stages. In the virtual butterfly garden, they can also observe a butterfly using the tracking telescope and capture it on the touch screen to obtain the related information. A quasi-experiment was conducted to investigate students’ learning effectiveness and attitudes after using the system, and the results showed that using the virtual butterfly ecological system could improve their learning effectively. Most students felt that the breeding and observation activities on the system were very interesting and convenient. They thought the system encouraged them to acquire knowledge about the butterfly ecology more easily and actively. Furthermore, students considered the virtual scenes and butterflies very realistic, and they would like to use it again in the future.</p><p>Compared with real butterfly gardens, the virtual butterfly ecological system is easy to develop and maintain, and it can solve the problems of insufficient butterfly species and quantity. The system provides an interesting and realistic learning environment using the AR technology, and it can achieve educational and entertaining purposes with the sensor functions of mobile devices and wireless networks. The application of the virtual butterfly ecological system is not limited by time or space, and students can learn about butterfly ecology in their familiar environments. In addition, it is highly interactive with 3D visual effects, and the user interface is easy for operation. Therefore, it is an effective and suitable assistant tool for science education in elementary and high schools.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RT. Azuma, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Azuma RT (1997) A survey of augmented reality. Teleop Virtual Environ 6(4):355–385" /><p class="c-article-references__text" id="ref-CR1">Azuma RT (1997) A survey of augmented reality. Teleop Virtual Environ 6(4):355–385</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20survey%20of%20augmented%20reality&amp;journal=Teleop%20Virtual%20Environ&amp;volume=6&amp;issue=4&amp;pages=355-385&amp;publication_year=1997&amp;author=Azuma%2CRT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Billinghurst, H. Kato, I. Poupyrev, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Billinghurst M, Kato H, Poupyrev I (2001) The magicbook-moving seamlessly between reality and virtuality. Comp" /><p class="c-article-references__text" id="ref-CR2">Billinghurst M, Kato H, Poupyrev I (2001) The magicbook-moving seamlessly between reality and virtuality. Comput Gr Appl 21(3):2–4</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20magicbook-moving%20seamlessly%20between%20reality%20and%20virtuality&amp;journal=Comput%20Gr%20Appl&amp;volume=21&amp;issue=3&amp;pages=2-4&amp;publication_year=2001&amp;author=Billinghurst%2CM&amp;author=Kato%2CH&amp;author=Poupyrev%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JS. Brown, A. Collins, P. Duguid, " /><meta itemprop="datePublished" content="1989" /><meta itemprop="headline" content="Brown JS, Collins A, Duguid P (1989) Situated cognition and the culture of learning. Educ Res 18(1):32–42" /><p class="c-article-references__text" id="ref-CR3">Brown JS, Collins A, Duguid P (1989) Situated cognition and the culture of learning. Educ Res 18(1):32–42</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3102%2F0013189X018001032" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Situated%20cognition%20and%20the%20culture%20of%20learning&amp;journal=Educ%20Res&amp;volume=18&amp;issue=1&amp;pages=32-42&amp;publication_year=1989&amp;author=Brown%2CJS&amp;author=Collins%2CA&amp;author=Duguid%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Campbell, SK. Wang, H-Y. Hsu, AM. Duffy, PG. Wolf, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Campbell T, Wang SK, Hsu H-Y, Duffy AM, Wolf PG (2010) Learning with web tools, simulations, and other technol" /><p class="c-article-references__text" id="ref-CR4">Campbell T, Wang SK, Hsu H-Y, Duffy AM, Wolf PG (2010) Learning with web tools, simulations, and other technologies in science classrooms. J Sci Educ Technol 19(5):505–511</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10956-010-9217-8" aria-label="View reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20with%20web%20tools%2C%20simulations%2C%20and%20other%20technologies%20in%20science%20classrooms&amp;journal=J%20Sci%20Educ%20Technol&amp;volume=19&amp;issue=5&amp;pages=505-511&amp;publication_year=2010&amp;author=Campbell%2CT&amp;author=Wang%2CSK&amp;author=Hsu%2CH-Y&amp;author=Duffy%2CAM&amp;author=Wolf%2CPG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="WS. Chen, " /><meta itemprop="datePublished" content="1988" /><meta itemprop="headline" content="Chen WS (1988) Butterflies of Taiwan. Taiwan Provincial Museum, Taipei" /><p class="c-article-references__text" id="ref-CR5">Chen WS (1988) Butterflies of Taiwan. Taiwan Provincial Museum, Taipei</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Butterflies%20of%20Taiwan&amp;publication_year=1988&amp;author=Chen%2CWS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="YS. Chen, TC. Kao, JP. Sheu, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Chen YS, Kao TC, Sheu JP (2003) A mobile learning system for scaffolding bird watching learning. J Comput Assi" /><p class="c-article-references__text" id="ref-CR6">Chen YS, Kao TC, Sheu JP (2003) A mobile learning system for scaffolding bird watching learning. J Comput Assist Learn 19(3):347–359</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1046%2Fj.0266-4909.2003.00036.x" aria-label="View reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20mobile%20learning%20system%20for%20scaffolding%20bird%20watching%20learning&amp;journal=J%20Comput%20Assist%20Learn&amp;volume=19&amp;issue=3&amp;pages=347-359&amp;publication_year=2003&amp;author=Chen%2CYS&amp;author=Kao%2CTC&amp;author=Sheu%2CJP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chen YS, Kao TC, Sheu JP (2004) A mobile butterfly-watching learning system for supporting independent learnin" /><p class="c-article-references__text" id="ref-CR7">Chen YS, Kao TC, Sheu JP (2004) A mobile butterfly-watching learning system for supporting independent learning. In: Proceedings of IEEE workshop on wireless and mobile technologies in education, Taiwan, pp 11–18</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y-C. Chen, H-L. Chi, W-H. Hung, S-C. Kang, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Chen Y-C, Chi H-L, Hung W-H, Kang S-C (2011) Use of tangible and augmented reality models in engineering graph" /><p class="c-article-references__text" id="ref-CR8">Chen Y-C, Chi H-L, Hung W-H, Kang S-C (2011) Use of tangible and augmented reality models in engineering graphics courses. J Prof Issues Eng Educ Pract 137(4):267–276</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1061%2F%28ASCE%29EI.1943-5541.0000078" aria-label="View reference 8">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Use%20of%20tangible%20and%20augmented%20reality%20models%20in%20engineering%20graphics%20courses&amp;journal=J%20Prof%20Issues%20Eng%20Educ%20Pract&amp;volume=137&amp;issue=4&amp;pages=267-276&amp;publication_year=2011&amp;author=Chen%2CY-C&amp;author=Chi%2CH-L&amp;author=Hung%2CW-H&amp;author=Kang%2CS-C">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="B. Dalgarno, MJW. Lee, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Dalgarno B, Lee MJW (2010) What are the learning affordances of 3-D virtual environments? Br J Educ Technol 41" /><p class="c-article-references__text" id="ref-CR9">Dalgarno B, Lee MJW (2010) What are the learning affordances of 3-D virtual environments? Br J Educ Technol 41(1):10–32</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fj.1467-8535.2009.01038.x" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=What%20are%20the%20learning%20affordances%20of%203-D%20virtual%20environments%3F&amp;journal=Br%20J%20Educ%20Technol&amp;volume=41&amp;issue=1&amp;pages=10-32&amp;publication_year=2010&amp;author=Dalgarno%2CB&amp;author=Lee%2CMJW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Dede, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Dede C (2009) Immersive interfaces for engagement and learning. Science 323(5910):66–69" /><p class="c-article-references__text" id="ref-CR10">Dede C (2009) Immersive interfaces for engagement and learning. Science 323(5910):66–69</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1126%2Fscience.1167311" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Immersive%20interfaces%20for%20engagement%20and%20learning&amp;journal=Science&amp;volume=323&amp;issue=5910&amp;pages=66-69&amp;publication_year=2009&amp;author=Dede%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Dunleavy, C. Dede, R. Mitchell, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Dunleavy M, Dede C, Mitchell R (2009) Affordances and limitations of immersive participatory augmented reality" /><p class="c-article-references__text" id="ref-CR11">Dunleavy M, Dede C, Mitchell R (2009) Affordances and limitations of immersive participatory augmented reality simulations for teaching and learning. J Sci Educ Technol 18(1):7–22</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10956-008-9119-1" aria-label="View reference 11">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Affordances%20and%20limitations%20of%20immersive%20participatory%20augmented%20reality%20simulations%20for%20teaching%20and%20learning&amp;journal=J%20Sci%20Educ%20Technol&amp;volume=18&amp;issue=1&amp;pages=7-22&amp;publication_year=2009&amp;author=Dunleavy%2CM&amp;author=Dede%2CC&amp;author=Mitchell%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Harris (2006) Go in mobile. http://www.learning.circuits.org/2001/jul2001/harris.html. Retrieved 5 May 2006" /><p class="c-article-references__text" id="ref-CR12">Harris (2006) Go in mobile. <a href="http://www.learning.circuits.org/2001/jul2001/harris.html">http://www.learning.circuits.org/2001/jul2001/harris.html</a>. Retrieved 5 May 2006</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="TY. Hsu, CM. Chen, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Hsu TY, Chen CM (2010) A mobile learning module for high school fieldwork. J Geogr 109(4):141–149" /><p class="c-article-references__text" id="ref-CR13">Hsu TY, Chen CM (2010) A mobile learning module for high school fieldwork. J Geogr 109(4):141–149</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2669663" aria-label="View reference 13 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F00221341.2010.480941" aria-label="View reference 13">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20mobile%20learning%20module%20for%20high%20school%20fieldwork&amp;journal=J%20Geogr&amp;volume=109&amp;issue=4&amp;pages=141-149&amp;publication_year=2010&amp;author=Hsu%2CTY&amp;author=Chen%2CCM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Huang TY (2010) A research on combining QR-code and wireless networks to develop an interactive digital learni" /><p class="c-article-references__text" id="ref-CR14">Huang TY (2010) A research on combining QR-code and wireless networks to develop an interactive digital learning system for ecological education in an elementary school campus. In: Technical Report, National Science Council (NSC 97-2511-S-153-004)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="LF. Johnson, A. Levine, RS. Smith, K. Haywood, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Johnson LF, Levine A, Smith RS, Haywood K (2010) Key emerging technologies for elementary and secondary educat" /><p class="c-article-references__text" id="ref-CR15">Johnson LF, Levine A, Smith RS, Haywood K (2010) Key emerging technologies for elementary and secondary education. Educ Dig 76(1):36–40</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Key%20emerging%20technologies%20for%20elementary%20and%20secondary%20education&amp;journal=Educ%20Dig&amp;volume=76&amp;issue=1&amp;pages=36-40&amp;publication_year=2010&amp;author=Johnson%2CLF&amp;author=Levine%2CA&amp;author=Smith%2CRS&amp;author=Haywood%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="E. Klopfer, J. Sheldon, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Klopfer E, Sheldon J (2010) Augmenting your own reality: student authoring of science-based augmented reality " /><p class="c-article-references__text" id="ref-CR16">Klopfer E, Sheldon J (2010) Augmenting your own reality: student authoring of science-based augmented reality games. New Dir Youth Dev 128:85–94</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2Fyd.378" aria-label="View reference 16">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Augmenting%20your%20own%20reality%3A%20student%20authoring%20of%20science-based%20augmented%20reality%20games&amp;journal=New%20Dir%20Youth%20Dev&amp;volume=128&amp;pages=85-94&amp;publication_year=2010&amp;author=Klopfer%2CE&amp;author=Sheldon%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="CY. Lee, SY. Wang, " /><meta itemprop="datePublished" content="1986" /><meta itemprop="headline" content="Lee CY, Wang SY (1986) The observation and breeding of butterflies. Taiwan Provincial Museum, Taipei" /><p class="c-article-references__text" id="ref-CR17">Lee CY, Wang SY (1986) The observation and breeding of butterflies. Taiwan Provincial Museum, Taipei</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20observation%20and%20breeding%20of%20butterflies&amp;publication_year=1986&amp;author=Lee%2CCY&amp;author=Wang%2CSY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Likert, " /><meta itemprop="datePublished" content="1932" /><meta itemprop="headline" content="Likert R (1932) A technique for the measurement of attitudes. Arch Psychol 22(40):1–55" /><p class="c-article-references__text" id="ref-CR18">Likert R (1932) A technique for the measurement of attitudes. Arch Psychol 22(40):1–55</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20technique%20for%20the%20measurement%20of%20attitudes&amp;journal=Arch%20Psychol&amp;volume=22&amp;issue=40&amp;pages=1-55&amp;publication_year=1932&amp;author=Likert%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lin Y-S (2008) Development and effectiveness analysis of a ubiquitous collaborative learning system—a case stu" /><p class="c-article-references__text" id="ref-CR19">Lin Y-S (2008) Development and effectiveness analysis of a ubiquitous collaborative learning system—a case study on the butterfly and ecology course of an elementary school. In: Master Thesis, National University of Tainan, Department of Information and Learning Technology, Tainan</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="TC. Liu, HY. Wang, JK. Liang, TW. Chan, HW. Ko, JC. Yang, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Liu TC, Wang HY, Liang JK, Chan TW, Ko HW, Yang JC (2003) Wireless and mobile technologies to enhance teaching" /><p class="c-article-references__text" id="ref-CR20">Liu TC, Wang HY, Liang JK, Chan TW, Ko HW, Yang JC (2003) Wireless and mobile technologies to enhance teaching and learning. J Comput Assist Learn 19(3):371–382</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1058.34085" aria-label="View reference 20 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1046%2Fj.0266-4909.2003.00038.x" aria-label="View reference 20">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Wireless%20and%20mobile%20technologies%20to%20enhance%20teaching%20and%20learning&amp;journal=J%20Comput%20Assist%20Learn&amp;volume=19&amp;issue=3&amp;pages=371-382&amp;publication_year=2003&amp;author=Liu%2CTC&amp;author=Wang%2CHY&amp;author=Liang%2CJK&amp;author=Chan%2CTW&amp;author=Ko%2CHW&amp;author=Yang%2CJC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Martin, G. Diaz, E. Sancristobal, R. Gil, M. Castro, J. Peire, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Martin S, Diaz G, Sancristobal E, Gil R, Castro M, Peire J (2011) New technology trends in education: seven ye" /><p class="c-article-references__text" id="ref-CR21">Martin S, Diaz G, Sancristobal E, Gil R, Castro M, Peire J (2011) New technology trends in education: seven years of forecasts and convergence. Comput Educ 57(3):1893–1906</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.compedu.2011.04.003" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=New%20technology%20trends%20in%20education%3A%20seven%20years%20of%20forecasts%20and%20convergence&amp;journal=Comput%20Educ&amp;volume=57&amp;issue=3&amp;pages=1893-1906&amp;publication_year=2011&amp;author=Martin%2CS&amp;author=Diaz%2CG&amp;author=Sancristobal%2CE&amp;author=Gil%2CR&amp;author=Castro%2CM&amp;author=Peire%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Ministry of Education (2006) General guidelines of grades 1–9 science and life technology curriculum. Ministry" /><p class="c-article-references__text" id="ref-CR22">Ministry of Education (2006) General guidelines of grades 1–9 science and life technology curriculum. Ministry of Education, Taipei</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=General%20guidelines%20of%20grades%201%E2%80%939%20science%20and%20life%20technology%20curriculum&amp;publication_year=2006">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Mistler-Jackson, B. Songer, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Mistler-Jackson M, Songer B (2000) Student motivation and Internet technology: are students empowered to learn" /><p class="c-article-references__text" id="ref-CR23">Mistler-Jackson M, Songer B (2000) Student motivation and Internet technology: are students empowered to learn science? J Res Sci Teach 37:459–479</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2F%28SICI%291098-2736%28200005%2937%3A5%3C459%3A%3AAID-TEA5%3E3.0.CO%3B2-C" aria-label="View reference 23">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Student%20motivation%20and%20Internet%20technology%3A%20are%20students%20empowered%20to%20learn%20science%3F&amp;journal=J%20Res%20Sci%20Teach&amp;volume=37&amp;pages=459-479&amp;publication_year=2000&amp;author=Mistler-Jackson%2CM&amp;author=Songer%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Schilit WN (1995) A system architecture for context-aware mobile computing. In: Unpublished doctoral thesis, C" /><p class="c-article-references__text" id="ref-CR24">Schilit WN (1995) A system architecture for context-aware mobile computing. In: Unpublished doctoral thesis, Columbia University</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="J. Schiller, A. Voisard, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Schiller J, Voisard A (2004) Location-based services. Morgan Kaufmann, San Francisco" /><p class="c-article-references__text" id="ref-CR25">Schiller J, Voisard A (2004) Location-based services. Morgan Kaufmann, San Francisco</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Location-based%20services&amp;publication_year=2004&amp;author=Schiller%2CJ&amp;author=Voisard%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JL. Shih, GJ. Hwang, YC. Chu, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Shih JL, Hwang GJ, Chu YC (2010) The development and instructional application of u-library on butterfly and w" /><p class="c-article-references__text" id="ref-CR26">Shih JL, Hwang GJ, Chu YC (2010) The development and instructional application of u-library on butterfly and wetland ecology for context-aware ubiquitous learning. Int J Mob Learn Organ 4(3):253–268</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1504%2FIJMLO.2010.033554" aria-label="View reference 26">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20development%20and%20instructional%20application%20of%20u-library%20on%20butterfly%20and%20wetland%20ecology%20for%20context-aware%20ubiquitous%20learning&amp;journal=Int%20J%20Mob%20Learn%20Organ&amp;volume=4&amp;issue=3&amp;pages=253-268&amp;publication_year=2010&amp;author=Shih%2CJL&amp;author=Hwang%2CGJ&amp;author=Chu%2CYC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="ShiVa3D (2013) http://www.shivaengine.com&#xA;                        " /><p class="c-article-references__text" id="ref-CR27">ShiVa3D (2013) <a href="http://www.shivaengine.com">http://www.shivaengine.com</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H-K. Wu, SW-Y. Lee, H-Y. Chang, J-C. Liang, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Wu H-K, Lee SW-Y, Chang H-Y, Liang J-C (2013) Current status, opportunities and challenges of augmented realit" /><p class="c-article-references__text" id="ref-CR28">Wu H-K, Lee SW-Y, Chang H-Y, Liang J-C (2013) Current status, opportunities and challenges of augmented reality in education. Comput Educ 62:41–49</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.compedu.2012.10.024" aria-label="View reference 28">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Current%20status%2C%20opportunities%20and%20challenges%20of%20augmented%20reality%20in%20education&amp;journal=Comput%20Educ&amp;volume=62&amp;pages=41-49&amp;publication_year=2013&amp;author=Wu%2CH-K&amp;author=Lee%2CSW-Y&amp;author=Chang%2CH-Y&amp;author=Liang%2CJ-C">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-015-0265-5-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgments</h2><div class="c-article-section__content" id="Ack1-content"><p>The authors would like to thank for the financial support of the National Science Council (NSC), Taiwan, ROC, under the contract number NSC 100-2511-S-134-003.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Graduate Institute of e-Learning Technology, National Hsinchu University of Education, Hsinchu, Taiwan, ROC</p><p class="c-article-author-affiliation__authors-list">Wernhuar Tarng, Kuo-Liang Ou &amp; Fong-Lu Liou</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Graduate Institute of Computer Science, National Hsinchu University of Education, Hsinchu, Taiwan, ROC</p><p class="c-article-author-affiliation__authors-list">Chuan-Sheng Yu</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Department of Computer Science and Information Engineering, National Central University, Jhongli, Taiwan, ROC</p><p class="c-article-author-affiliation__authors-list">Hsin-Hun Liou</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Wernhuar-Tarng"><span class="c-article-authors-search__title u-h3 js-search-name">Wernhuar Tarng</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Wernhuar+Tarng&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Wernhuar+Tarng" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Wernhuar+Tarng%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Kuo_Liang-Ou"><span class="c-article-authors-search__title u-h3 js-search-name">Kuo-Liang Ou</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Kuo-Liang+Ou&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Kuo-Liang+Ou" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Kuo-Liang+Ou%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Chuan_Sheng-Yu"><span class="c-article-authors-search__title u-h3 js-search-name">Chuan-Sheng Yu</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Chuan-Sheng+Yu&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Chuan-Sheng+Yu" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Chuan-Sheng+Yu%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Fong_Lu-Liou"><span class="c-article-authors-search__title u-h3 js-search-name">Fong-Lu Liou</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Fong-Lu+Liou&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Fong-Lu+Liou" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Fong-Lu+Liou%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Hsin_Hun-Liou"><span class="c-article-authors-search__title u-h3 js-search-name">Hsin-Hun Liou</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Hsin-Hun+Liou&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Hsin-Hun+Liou" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Hsin-Hun+Liou%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-015-0265-5/email/correspondent/c1/new">Wernhuar Tarng</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Development%20of%20a%20virtual%20butterfly%20ecological%20system%20based%20on%20augmented%20reality%20and%20mobile%20learning%20technologies&amp;author=Wernhuar%20Tarng%20et%20al&amp;contentID=10.1007%2Fs10055-015-0265-5&amp;publication=1359-4338&amp;publicationDate=2015-05-21&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-015-0265-5" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-015-0265-5" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Tarng, W., Ou, K., Yu, C. <i>et al.</i> Development of a virtual butterfly ecological system based on augmented reality and mobile learning technologies.
                    <i>Virtual Reality</i> <b>19, </b>253–266 (2015). https://doi.org/10.1007/s10055-015-0265-5</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-015-0265-5.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2014-04-22">22 April 2014</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-05-06">06 May 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-05-21">21 May 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-11">November 2015</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-015-0265-5" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-015-0265-5</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Augmented reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Mobile learning</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Context awareness</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Butterfly ecology</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-015-0265-5.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=265;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

