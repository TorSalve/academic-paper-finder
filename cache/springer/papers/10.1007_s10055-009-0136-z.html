<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Multisensory VR interaction for protein-docking in the CoRSAIRe projec"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Proteins take on their function in the cell by interacting with other proteins or biomolecular complexes. To study this process, computational methods, collectively named protein docking, are used..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/13/4.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Multisensory VR interaction for protein-docking in the CoRSAIRe project"/>

    <meta name="dc.source" content="Virtual Reality 2009 13:4"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2009-10-01"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2009 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Proteins take on their function in the cell by interacting with other proteins or biomolecular complexes. To study this process, computational methods, collectively named protein docking, are used to predict the position and orientation of a protein ligand when it is bound to a protein receptor or enzyme, taking into account chemical or physical criteria. This process is intensively studied to discover new biological functions for proteins and to better understand how these macromolecules take on these functions at the molecular scale. Pharmaceutical research also employs docking techniques for a variety of purposes, most notably in the virtual screening of large databases of available chemicals to select likely molecular candidates for drug design. The basic hypothesis of our work is that Virtual Reality (VR) and multimodal interaction can increase efficiency in reaching and analysing docking solutions, in addition to fully a computational docking approach. To this end, we conducted an ergonomic analysis of the protein&#8211;protein current docking task as it is carried out today. Using these results, we designed an immersive and multimodal application where VR devices, such as the three-dimensional mouse and haptic devices, are used to interactively manipulate two proteins to explore possible docking solutions. During this exploration, visual, audio, and haptic feedbacks are combined to render and evaluate chemical or physical properties of the current docking configuration."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2009-10-01"/>

    <meta name="prism.volume" content="13"/>

    <meta name="prism.number" content="4"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="273"/>

    <meta name="prism.endingPage" content="293"/>

    <meta name="prism.copyright" content="2009 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-009-0136-z"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-009-0136-z"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-009-0136-z.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-009-0136-z"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Multisensory VR interaction for protein-docking in the CoRSAIRe project"/>

    <meta name="citation_volume" content="13"/>

    <meta name="citation_issue" content="4"/>

    <meta name="citation_publication_date" content="2009/12"/>

    <meta name="citation_online_date" content="2009/10/01"/>

    <meta name="citation_firstpage" content="273"/>

    <meta name="citation_lastpage" content="293"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-009-0136-z"/>

    <meta name="DOI" content="10.1007/s10055-009-0136-z"/>

    <meta name="citation_doi" content="10.1007/s10055-009-0136-z"/>

    <meta name="description" content="Proteins take on their function in the cell by interacting with other proteins or biomolecular complexes. To study this process, computational methods, col"/>

    <meta name="dc.creator" content="N. F&#233;rey"/>

    <meta name="dc.creator" content="J. Nelson"/>

    <meta name="dc.creator" content="C. Martin"/>

    <meta name="dc.creator" content="L. Picinali"/>

    <meta name="dc.creator" content="G. Bouyer"/>

    <meta name="dc.creator" content="A. Tek"/>

    <meta name="dc.creator" content="P. Bourdot"/>

    <meta name="dc.creator" content="J. M. Burkhardt"/>

    <meta name="dc.creator" content="B. F. G. Katz"/>

    <meta name="dc.creator" content="M. Ammi"/>

    <meta name="dc.creator" content="C. Etchebest"/>

    <meta name="dc.creator" content="L. Autin"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Anastassova M, M&#233;gard C, Burkhardt JM (2007) Prototype evaluation and user-needs analysis in the early design of emerging technologies. In: Procedings of the 12th international conference on human-computer interaction (HCI&#8217;07)"/>

    <meta name="citation_reference" content="citation_journal_title=J Mol Graphi Model; citation_title=VRDD: applying virtual reality visualization to protein docking and design; citation_author=A Anderson, Z Weng; citation_volume=17; citation_issue=3; citation_publication_date=1999; citation_pages=180-186; citation_doi=10.1016/S1093-3263(99)00029-7; citation_id=CR2"/>

    <meta name="citation_reference" content="Andr&#233; E (2000) The generation of multimedia presentations. In: Handbook of natural language processing, pp 305&#8211;327"/>

    <meta name="citation_reference" content="citation_journal_title=Proteins; citation_title=FireDock: fast interaction refinement in molecular docking; citation_author=N Andrusier, R Nussinov, HJ Wolfson; citation_volume=69; citation_issue=1; citation_publication_date=2007; citation_pages=139-59; citation_doi=10.1002/prot.21495; citation_id=CR4"/>

    <meta name="citation_reference" content="Annett J (2003) Hierarchical task analysis. In: Handbook of cognitive task design, pp. 17&#8211;35"/>

    <meta name="citation_reference" content="Arboun A (2007) Evaluation des m&#233;taphores de sonification. Master thesis, Ecole Nationale Sup&#233;rieure Louis Lumi&#232;re, Paris, France"/>

    <meta name="citation_reference" content="citation_journal_title=Proc Natl Acad Sci; citation_title=Electrostatics of nanosystems: application to microtubules and the ribosome; citation_author=NA Baker, D Sept, S Joseph, MJ Holst, JA McCammon; citation_volume=98; citation_publication_date=2001; citation_pages=10037-10041; citation_id=CR7"/>

    <meta name="citation_reference" content="Barass S, Zehner B (2000) Responsive sonification of well-logs. In: Proceedings of the international conference on auditory display (ICAD&#8217;00)"/>

    <meta name="citation_reference" content="citation_journal_title=Nucleic Acids Res; citation_title=The Protein Data Bank; citation_author=HM Berman, J Westbrook, Z Feng, G Gilliland, T Bhat, H Weissig, I Shindyalov, P Bourne; citation_volume=1; citation_issue=28; citation_publication_date=2000; citation_pages=235-242; citation_doi=10.1093/nar/28.1.235; citation_id=CR9"/>

    <meta name="citation_reference" content="citation_journal_title=J Chem Theory Comput; citation_title=PELE: protein energy landscape exploration. A novel Monte Carlo based technique; citation_author=KW Borrelli, A Vitalis, R Raul Alcantara, V Guallar; citation_volume=6; citation_issue=1; citation_publication_date=2005; citation_pages=1304-1311; citation_doi=10.1021/ct0501811; citation_id=CR10"/>

    <meta name="citation_reference" content="Bourdot P, Touraine D (2002) Polyvalent display framework to control virtual navigations by 6DoF tracking. In: Proceedings of the IEEE virtual reality international conference (IEEE-VR&#8217;02)"/>

    <meta name="citation_reference" content="Bouyer G (2007) Rendu multimodal en R&#233;alit&#233; Virtuelle: Supervision des interactions au service de la t&#226;che. Ph.d. thesis, Universit&#233; Paris XI, France"/>

    <meta name="citation_reference" content="Bouyer G, Bourdot P (2008) Supervision of 3D multimodal rendering for protein-protein virtual docking. In: Proceedings of the 13th Eurographics symposium on virtual environments (EGVE&#8217;08), pp 49&#8211;56"/>

    <meta name="citation_reference" content="Brooks FP Jr, Ouh-Young M , Batter JJ, Jerome Kilpatrick P (1990) Project GROPE: Haptic displays for scientific visualization. In: Proceedings of the 17th conference on computer graphics and interactive techniques, pp 177&#8211;185"/>

    <meta name="citation_reference" content="citation_journal_title=Bioinformatics; citation_title=ClusPro: an automated docking and discrimination method for the prediction of protein complexes; citation_author=SR Comeau, WD Gatchell, S Vajda, CJ Camacho; citation_volume=20; citation_issue=1; citation_publication_date=2004; citation_pages=45-50; citation_doi=10.1093/bioinformatics/btg371; citation_id=CR14"/>

    <meta name="citation_reference" content="citation_journal_title=J Appl Crystallogr; citation_title=Analytical molecular surface calculation; citation_author=ML Connolly; citation_volume=16; citation_publication_date=1983; citation_pages=548-558; citation_doi=10.1107/S0021889883010985; citation_id=CR15"/>

    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Solvent-accessible surfaces of proteins and nucleic acids; citation_author=ML Connolly; citation_volume=221; citation_publication_date=1983; citation_pages=709-713; citation_doi=10.1126/science.6879170; citation_id=CR16"/>

    <meta name="citation_reference" content="citation_journal_title=Rev Sci Instrum; citation_title=Molecular models of amino acids, peptides, and proteins; citation_author=RB Corey, L Pauling; citation_volume=24; citation_issue=8; citation_publication_date=1953; citation_pages=621-627; citation_doi=10.1063/1.1770803; citation_id=CR17"/>

    <meta name="citation_reference" content="citation_journal_title=ACM SIGGRAPH Comput Graph; citation_title=The CAVE: audio visual experience automatic virtual environment; citation_author=C Cruz-Neira, DJ Sandin, TA DeFanti, RV Kenyon, JC Hart; citation_volume=35; citation_issue=6; citation_publication_date=1992; citation_pages=64-72; citation_id=CR18"/>

    <meta name="citation_reference" content="Dominjon L, L&#233;cuyer A, Burkhardt JM, Andrade-Barroso G, Richir S (2005) The &#8220;Bubble&#8221; technique: interacting with large virtual environments using haptic devices with limited workspace. In: Proceedings of the world haptics conference (joint Eurohaptics conference and haptics symposium)"/>

    <meta name="citation_reference" content="Dominjon L, L&#233;cuyer A, Burkhardt JM, Richir S (2006) Haptic hybrid rotations: overcoming hardware rotational limitations of force-feedback devices. In: Proceedings of the IEEE international conference on virtual reality (IEEE-VR&#8217;05)"/>

    <meta name="citation_reference" content="Ferey N, Delande O, Grasseau G, Baaden M (2008) A VR framework for interacting with molecular simulations. In: Proceedings of the international conference on virtual reality sofware and technologies (ACM-VRST&#8217;08)"/>

    <meta name="citation_reference" content="Fernandez-Recio J, Totrov M, Abagyan R (2003) ICM-DISCO docking by global energy optimization with fully flexible Side-Chains, vol 1, issue 52. Bradford Books/MIT Press, Cambridge, MA, pp 113&#8211;117"/>

    <meta name="citation_reference" content="citation_journal_title=Interact Comput; citation_title=An overview of auditory display to assist comprehension of molecular information; citation_author=MA Garcia-Ruiz, JR Guttierez-Pulido; citation_volume=18; citation_issue=4; citation_publication_date=2006; citation_pages=853-868; citation_doi=10.1016/j.intcom.2005.12.001; citation_id=CR24"/>

    <meta name="citation_reference" content="Ghiglione R, Landr&#233; A, Bromberg M, Molette P (1998) L&#8217;analyse automatique des contenus"/>

    <meta name="citation_reference" content="Gottschalk S, Lin MC, Manocha D (1996) OBBTree: a hierarchical structure for rapid interference detection. In: Proceedings of the 23rd conference on computer graphics and interactive techniques, vol 30, pp 171&#8211;180"/>

    <meta name="citation_reference" content="Grosdidier A (2007) Conception d&#8217;un logiciel de docking et applications dans la recherche de nouvelles mol&#233;cules actives. PhD thesis, Universit&#233; Joseph Fourier Grenoble 1, France"/>

    <meta name="citation_reference" content="citation_journal_title=Proteins Struct Funct Genet; citation_title=A multiple-start Monte Carlo docking method; citation_author=TN Hart, RJ Read; citation_volume=13; citation_issue=3; citation_publication_date=2004; citation_pages=206-222; citation_id=CR28"/>

    <meta name="citation_reference" content="Hermann T, Ritter H (1999) Listen to your Data: model-based sonification for data analysis, pp 189&#8211;194"/>

    <meta name="citation_reference" content="citation_journal_title=J Chem Theory Comput; citation_title=GROMACS 4: algorithms for highly efficient, load-balanced, and scalable molecular simulation; citation_author=B Hess, D Kutzner, C Vanderspoel, E Lindahl; citation_volume=4; citation_issue=3; citation_publication_date=2008; citation_pages=435-447; citation_doi=10.1021/ct700301q; citation_id=CR30"/>

    <meta name="citation_reference" content="citation_journal_title=J Comput Chem; citation_title=The molecular modeling toolkit: a new approach to molecular simulation; citation_author=K Hinsen; citation_volume=21; citation_publication_date=2000; citation_pages=79-85; citation_doi=10.1002/(SICI)1096-987X(20000130)21:2&lt;79::AID-JCC1&gt;3.0.CO;2-B; citation_id=CR31"/>

    <meta name="citation_reference" content="Johnson DE, Willemsen P (2003) Six Degree-of-Freedom Haptic rendering of complex polygonal models. In: Proceedings of the 11th symposium on haptic interfaces for virtual environment and teleoperator systems (HAPTICS&#8217;03)"/>

    <meta name="citation_reference" content="Katz FGB, Rio E, Picinali L, Warusfel O (2008) The effect of spatialization in a data sonification exploration tasks. In: Proceedings of the international conference on auditory display (ICAD&#8217;08)"/>

    <meta name="citation_reference" content="citation_journal_title=J Thorac Cardiovasc Surg; citation_title=Effect of sensory substitution on suture-manipulation forces for robotic surgical systems; citation_author=M Kitagawa, D Dokko, A Okamura, D Yuh; citation_volume=129; citation_issue=1; citation_publication_date=2005; citation_pages=151-158; citation_doi=10.1016/j.jtcvs.2004.05.029; citation_id=CR34"/>

    <meta name="citation_reference" content="citation_journal_title=Proc IEEE Conf Comput Sci Eng; citation_title=Stalk: an interactive system for virtual molecular docking; citation_author=D Levine, M Facello, P Hallstrom, G Reeder, B Walenz, F Stevens; citation_volume=4; citation_issue=2; citation_publication_date=1997; citation_pages=55-65; citation_doi=10.1109/99.609834; citation_id=CR35"/>

    <meta name="citation_reference" content="Lu T-C, Ding JH, Crivelli SN (2005) DockingShop: a tool for interactive protein docking. In: Procedings of the computational systems bioinformatics conference, pp 271&#8211;272"/>

    <meta name="citation_reference" content="Lundin KE, Sillen M, Cooper MD, Ynnerman A (2005) Haptic visualization of computational fluid dynamics data using reactive forces. In: Procedings of the society of photo-optical instrumentation engineer conference (SPIE&#8217;05), visualization and data analysis, vol 5669, pp 31&#8211;41"/>

    <meta name="citation_reference" content="Maciejewski R, Choi S, Ebert DS, Tan HZ (2005) Multi-Modal perceptualization of volumetric data and its application to molecular docking. In: Proceedings of the first joint eurohaptics conference and symposium on haptic interfaces for virtual environment and teleoperator systems."/>

    <meta name="citation_reference" content="citation_journal_title=Semiotica; citation_title=An abductive theory of scientific reasoning; citation_author=L Magnani; citation_volume=153; citation_issue=1&#8211;4; citation_publication_date=2005; citation_pages=261-286; citation_doi=10.1515/semi.2005.2005.153-1-4.261; citation_id=CR39"/>

    <meta name="citation_reference" content="Moore BCJ (2003) An introduction to the psychology of hearing"/>

    <meta name="citation_reference" content="citation_journal_title=Thromb Haemost; citation_title=Recombinant clotting factors; citation_author=SW Pipe; citation_volume=99; citation_issue=5; citation_publication_date=2008; citation_pages=840-850; citation_id=CR41"/>

    <meta name="citation_reference" content="citation_journal_title=J Mol Graph Model; citation_title=Intersurf: dynamic interface between proteins; citation_author=N Ray, X Cavin, JC Paul, B Maigret; citation_volume=23; citation_issue=4; citation_publication_date=2005; citation_pages=347-354; citation_doi=10.1016/j.jmgm.2004.11.004; citation_id=CR42"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Virtual Real; citation_title=Human-scale haptic virtual environment for product design: effect of sensory substitution; citation_author=P Richard, D Chamaret, F-X Inglese, P Lucidarme, J-L Ferrier; citation_volume=5; citation_issue=2; citation_publication_date=2006; citation_pages=37-44; citation_id=CR43"/>

    <meta name="citation_reference" content="citation_journal_title=Proteins; citation_title=Evaluation of protein docking predictions using Hex 3.1 in CAPRI rounds 1 and 2; citation_author=DW Ritchie; citation_volume=52; citation_issue=1; citation_publication_date=2003; citation_pages=98-106; citation_doi=10.1002/prot.10379; citation_id=CR44"/>

    <meta name="citation_reference" content="citation_journal_title=Bioinformatics; citation_title=Adaptive torsion-angle quasi-statics: a general simulation method with applications to protein structure analysis and design; citation_author=R Rossi, M Isorce, S Morin, J Flocard, K Arumugam, S Crouzy, M Vivaudou, S Redon; citation_volume=23; citation_issue=13; citation_publication_date=2007; citation_pages=408-417; citation_doi=10.1093/bioinformatics/btm191; citation_id=CR45"/>

    <meta name="citation_reference" content="Rosson MB, Carroll JM (2002) Scenario-based design. In: Jacko JA, Sears A (eds) The human-computer interaction handbook fundamentals, evolving technologies and emerging applications, pp 1032&#8211;1050"/>

    <meta name="citation_reference" content="citation_journal_title=Biopolymers; citation_title=Reduced surface: an efficient way to compute molecular surfaces; citation_author=M Sanner, A Olson, J-C Spehner; citation_volume=38; citation_publication_date=1996; citation_pages=305-320; citation_doi=10.1002/(SICI)1097-0282(199603)38:3&lt;305::AID-BIP4&gt;3.0.CO;2-Y; citation_id=CR47"/>

    <meta name="citation_reference" content="Seeger A, Chen J (1997) Controlling force feedback over a network. In: Proceedings of the second PHANToM user&#8217;s group workshop"/>

    <meta name="citation_reference" content="Touraine D, Bourdot P, Bellik Y, Bolot L (2002) A framework to manage multimodal fusion of events for advanced interactions within virtual environments. In: Proceedings of the 8th EUROGRAPHICS workshop on virtual environment, (EGVE&#8217;2002)"/>

    <meta name="citation_reference" content="citation_journal_title=Commun ACM; citation_title=Perceptual user interfaces (introduction); citation_author=M Turk, G Robertson; citation_volume=43; citation_issue=3; citation_publication_date=2000; citation_pages=32-34; citation_doi=10.1145/330534.330535; citation_id=CR50"/>

    <meta name="citation_reference" content="citation_journal_title=Curr Pharm Biotechnol; citation_title=In silico-in vitro screening of protein-protein interactions: towards the next generation of therapeutics; citation_author=BO Villoutreix, K Bastard, O Sperandio, R Fahraeus, JL Poyet, F Calvo, B Deprez, MA Miteva; citation_volume=9; citation_issue=2; citation_publication_date=2008; citation_pages=103-22; citation_doi=10.2174/138920108783955218; citation_id=CR51"/>

    <meta name="citation_reference" content="Walker BN, Lane DM (1994) Auditory display: sonification, audification, and auditory interfaces. Westview Press, Boulder, CO, USA"/>

    <meta name="citation_reference" content="Walker BN, Lane DM (2008) Sonification mappings database on the web. In: Proceedings of the international conference on auditory display (ICAD&#8217;01)"/>

    <meta name="citation_reference" content="citation_journal_title=J Med Chem; citation_title=Comparative evaluation of 11 scoring functions for molecular docking; citation_author=R Wang, Y Lu, S Wang; citation_volume=46; citation_publication_date=2003; citation_pages=2287-2303; citation_doi=10.1021/jm0203783; citation_id=CR54"/>

    <meta name="citation_reference" content="citation_journal_title=J Cell Biol; citation_title=Interactive fitting augmented by force-feedback and virtual reality; citation_author=W Wriggers, S Birmanns; citation_volume=144; citation_publication_date=2003; citation_pages=123-131; citation_id=CR55"/>

    <meta name="citation_reference" content="citation_journal_title=Proteins; citation_title=ATTRACT: protein-protein docking in CAPRI using a reduced protein model; citation_author=M Zacharias; citation_volume=60; citation_issue=2; citation_publication_date=2005; citation_pages=252-6; citation_doi=10.1002/prot.20566; citation_id=CR56"/>

    <meta name="citation_author" content="N. F&#233;rey"/>

    <meta name="citation_author_email" content="nicolas.ferey@ibpc.fr"/>

    <meta name="citation_author_institution" content="Laboratoire d&#8217;Informatique et de M&#233;canique pour les Sciences de l&#8217;Ing&#233;nieur, Universit&#233; Paris XI, Orsay Cedex, France"/>

    <meta name="citation_author" content="J. Nelson"/>

    <meta name="citation_author_email" content="julien.nelson@paris.ensam.fr"/>

    <meta name="citation_author_institution" content="Arts et Metiers ParisTech, LCPI, Paris, France"/>

    <meta name="citation_author" content="C. Martin"/>

    <meta name="citation_author_institution" content="Laboratoire d&#8217;Informatique et de M&#233;canique pour les Sciences de l&#8217;Ing&#233;nieur, Universit&#233; Paris XI, Orsay Cedex, France"/>

    <meta name="citation_author" content="L. Picinali"/>

    <meta name="citation_author_email" content="lorenzo@limsi.fr"/>

    <meta name="citation_author_institution" content="Institut de Recherche et Coordination Acoustique/Musique, Paris, France"/>

    <meta name="citation_author" content="G. Bouyer"/>

    <meta name="citation_author_email" content="guillaume.bouyer@ensiie.fr"/>

    <meta name="citation_author_institution" content="Laboratoire d&#8217;Informatique et de M&#233;canique pour les Sciences de l&#8217;Ing&#233;nieur, Universit&#233; Paris XI, Orsay Cedex, France"/>

    <meta name="citation_author" content="A. Tek"/>

    <meta name="citation_author_email" content="tek@limsi.fr"/>

    <meta name="citation_author_institution" content="Laboratoire d&#8217;Informatique et de M&#233;canique pour les Sciences de l&#8217;Ing&#233;nieur, Universit&#233; Paris XI, Orsay Cedex, France"/>

    <meta name="citation_author" content="P. Bourdot"/>

    <meta name="citation_author_email" content="pb@limsi.fr"/>

    <meta name="citation_author_institution" content="Laboratoire d&#8217;Informatique et de M&#233;canique pour les Sciences de l&#8217;Ing&#233;nieur, Universit&#233; Paris XI, Orsay Cedex, France"/>

    <meta name="citation_author" content="J. M. Burkhardt"/>

    <meta name="citation_author_email" content="jean-marie.burkhardt@univ-paris5.fr"/>

    <meta name="citation_author_institution" content="Laboratoire Ergonomie-Comportement-Interactions, Universit&#233; Paris V, Paris, France"/>

    <meta name="citation_author" content="B. F. G. Katz"/>

    <meta name="citation_author_email" content="katz@limsi.fr"/>

    <meta name="citation_author_institution" content="Laboratoire d&#8217;Informatique et de M&#233;canique pour les Sciences de l&#8217;Ing&#233;nieur, Universit&#233; Paris XI, Orsay Cedex, France"/>

    <meta name="citation_author" content="M. Ammi"/>

    <meta name="citation_author_email" content="ammi@limsi.fr"/>

    <meta name="citation_author_institution" content="Laboratoire d&#8217;Informatique et de M&#233;canique pour les Sciences de l&#8217;Ing&#233;nieur, Universit&#233; Paris XI, Orsay Cedex, France"/>

    <meta name="citation_author" content="C. Etchebest"/>

    <meta name="citation_author_email" content="catherine.etchebest@univ-paris-diderot.fr"/>

    <meta name="citation_author_institution" content="Institut National de la Sant&#233; et de la Recherche M&#233;dicale, Equipe DSIMB, Universit&#233; Paris VII, INTS, Paris Cedex 15, France"/>

    <meta name="citation_author" content="L. Autin"/>

    <meta name="citation_author_email" content="ludovic.autin@gmail.com"/>

    <meta name="citation_author_institution" content="Institut National de la Sant&#233; et de la Recherche M&#233;dicale, Equipe DSIMB, Universit&#233; Paris VII, INTS, Paris Cedex 15, France"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-009-0136-z&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2009/12/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-009-0136-z"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Multisensory VR interaction for protein-docking in the CoRSAIRe project"/>
        <meta property="og:description" content="Proteins take on their function in the cell by interacting with other proteins or biomolecular complexes. To study this process, computational methods, collectively named protein docking, are used to predict the position and orientation of a protein ligand when it is bound to a protein receptor or enzyme, taking into account chemical or physical criteria. This process is intensively studied to discover new biological functions for proteins and to better understand how these macromolecules take on these functions at the molecular scale. Pharmaceutical research also employs docking techniques for a variety of purposes, most notably in the virtual screening of large databases of available chemicals to select likely molecular candidates for drug design. The basic hypothesis of our work is that Virtual Reality (VR) and multimodal interaction can increase efficiency in reaching and analysing docking solutions, in addition to fully a computational docking approach. To this end, we conducted an ergonomic analysis of the protein–protein current docking task as it is carried out today. Using these results, we designed an immersive and multimodal application where VR devices, such as the three-dimensional mouse and haptic devices, are used to interactively manipulate two proteins to explore possible docking solutions. During this exploration, visual, audio, and haptic feedbacks are combined to render and evaluate chemical or physical properties of the current docking configuration."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Multisensory VR interaction for protein-docking in the CoRSAIRe project | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-009-0136-z","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Protein docking, User-centered design, Virtual reality, Multimodal rendering","kwrd":["Protein_docking","User-centered_design","Virtual_reality","Multimodal_rendering"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-009-0136-z","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-009-0136-z","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=136;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-009-0136-z">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Multisensory VR interaction for protein-docking in the <i>CoRSAIRe</i> project
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-009-0136-z.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-009-0136-z.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2009-10-01" itemprop="datePublished">01 October 2009</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Multisensory VR interaction for protein-docking in the <i>CoRSAIRe</i> project</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-N_-F_rey" data-author-popup="auth-N_-F_rey" data-corresp-id="c1">N. Férey<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Université Paris XI" /><meta itemprop="address" content="grid.5842.b, 0000000121712558, Laboratoire d’Informatique et de Mécanique pour les Sciences de l’Ingénieur, Université Paris XI, BP133, 91403, Orsay Cedex, France" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-J_-Nelson" data-author-popup="auth-J_-Nelson">J. Nelson</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Arts et Metiers ParisTech, LCPI" /><meta itemprop="address" content="grid.434207.6, 0000000121946047, Arts et Metiers ParisTech, LCPI, 151 Blv. de l’Hôpital, 75013, Paris, France" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-C_-Martin" data-author-popup="auth-C_-Martin">C. Martin</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Université Paris XI" /><meta itemprop="address" content="grid.5842.b, 0000000121712558, Laboratoire d’Informatique et de Mécanique pour les Sciences de l’Ingénieur, Université Paris XI, BP133, 91403, Orsay Cedex, France" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-L_-Picinali" data-author-popup="auth-L_-Picinali">L. Picinali</a></span><sup class="u-js-hide"><a href="#Aff5">5</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Institut de Recherche et Coordination Acoustique/Musique" /><meta itemprop="address" content="grid.425206.7, 0000000406413041, Institut de Recherche et Coordination Acoustique/Musique, 1, place Igor Stravinsky, 75004, Paris, France" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-G_-Bouyer" data-author-popup="auth-G_-Bouyer">G. Bouyer</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Université Paris XI" /><meta itemprop="address" content="grid.5842.b, 0000000121712558, Laboratoire d’Informatique et de Mécanique pour les Sciences de l’Ingénieur, Université Paris XI, BP133, 91403, Orsay Cedex, France" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-A_-Tek" data-author-popup="auth-A_-Tek">A. Tek</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Université Paris XI" /><meta itemprop="address" content="grid.5842.b, 0000000121712558, Laboratoire d’Informatique et de Mécanique pour les Sciences de l’Ingénieur, Université Paris XI, BP133, 91403, Orsay Cedex, France" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-P_-Bourdot" data-author-popup="auth-P_-Bourdot">P. Bourdot</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Université Paris XI" /><meta itemprop="address" content="grid.5842.b, 0000000121712558, Laboratoire d’Informatique et de Mécanique pour les Sciences de l’Ingénieur, Université Paris XI, BP133, 91403, Orsay Cedex, France" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-J__M_-Burkhardt" data-author-popup="auth-J__M_-Burkhardt">J. M. Burkhardt</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Université Paris V" /><meta itemprop="address" content="grid.10992.33, 0000000121880914, Laboratoire Ergonomie-Comportement-Interactions, Université Paris V, 45, rue des Saints-Pères, 75006, Paris, France" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-B__F__G_-Katz" data-author-popup="auth-B__F__G_-Katz">B. F. G. Katz</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Université Paris XI" /><meta itemprop="address" content="grid.5842.b, 0000000121712558, Laboratoire d’Informatique et de Mécanique pour les Sciences de l’Ingénieur, Université Paris XI, BP133, 91403, Orsay Cedex, France" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-M_-Ammi" data-author-popup="auth-M_-Ammi">M. Ammi</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Université Paris XI" /><meta itemprop="address" content="grid.5842.b, 0000000121712558, Laboratoire d’Informatique et de Mécanique pour les Sciences de l’Ingénieur, Université Paris XI, BP133, 91403, Orsay Cedex, France" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-C_-Etchebest" data-author-popup="auth-C_-Etchebest">C. Etchebest</a></span><sup class="u-js-hide"><a href="#Aff4">4</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Université Paris VII, INTS" /><meta itemprop="address" content="Institut National de la Santé et de la Recherche Médicale, Equipe DSIMB, Université Paris VII, INTS, 6, rue Alexandre Cabanel, 75739, Paris Cedex 15, France" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-L_-Autin" data-author-popup="auth-L_-Autin">L. Autin</a></span><sup class="u-js-hide"><a href="#Aff4">4</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Université Paris VII, INTS" /><meta itemprop="address" content="Institut National de la Santé et de la Recherche Médicale, Equipe DSIMB, Université Paris VII, INTS, 6, rue Alexandre Cabanel, 75739, Paris Cedex 15, France" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 13</b>, Article number: <span data-test="article-number">273</span> (<span data-test="article-publication-year">2009</span>)
            <a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">392 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">30 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">0 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-009-0136-z/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Proteins take on their function in the cell by interacting with other proteins or biomolecular complexes. To study this process, computational methods, collectively named protein docking, are used to predict the position and orientation of a protein ligand when it is bound to a protein receptor or enzyme, taking into account chemical or physical criteria. This process is intensively studied to discover new biological functions for proteins and to better understand how these macromolecules take on these functions at the molecular scale. Pharmaceutical research also employs docking techniques for a variety of purposes, most notably in the virtual screening of large databases of available chemicals to select likely molecular candidates for drug design. The basic hypothesis of our work is that Virtual Reality (VR) and multimodal interaction can increase efficiency in reaching and analysing docking solutions, in addition to fully a computational docking approach. To this end, we conducted an ergonomic analysis of the protein–protein current docking task as it is carried out today. Using these results, we designed an immersive and multimodal application where VR devices, such as the three-dimensional mouse and haptic devices, are used to interactively manipulate two proteins to explore possible docking solutions. During this exploration, visual, audio, and haptic feedbacks are combined to render and evaluate chemical or physical properties of the current docking configuration.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Protein–protein docking refers to a problem in structural biology, which consists in predicting how proteins bind together to make up functional complexes within the cell, based on the three-dimensional structure of single partner proteins and on their physicochemical properties (see Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec2">2</a>). Knowledge of the structure of protein–protein complexes allows scientists to better understand the key mechanisms at work in protein–protein interaction. This is a major scientific bottleneck, in terms of both theoretical (understanding protein functions) and applied research (specific inhibition of protein functions for drug design).</p><p>Current methods for protein–protein docking include (1) automatic stages (explained in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec4">3.1</a>), which take into account protein topology, as well as energy (i.e., physicochemical) properties and (2) stages of molecular visualization, allowing evaluation of the results. The automatic stage is costly in terms of processing time, and yields a large numbers of docking configurations which cannot be set apart using only objective and automatic parameters. Therefore, a manual stage of analysis is also necessary, requiring visualization of algorithm results by an expert. However, this visual analysis requires large amounts of information to be processed simultaneously by the docking expert: manipulation of three-dimensional objects, physicochemical data, biological data, etc.</p><p>Given the current limitations of docking tools, it seems relevant to develop complementary or alternative approaches to docking. In project <i>Combination of Sensorimotor Renderings for the Immersive Analysis of Results</i> (CoRSAIRe) our hypothesis is that using Virtual Reality (VR) technologies and related interactions, which rely on multiple sensory and motor channels, may help experts in this docking task. First, stereoscopy, especially when it is adaptative, may improve perception of three-dimensional protein models. Furthermore, direct manipulation of several proteins at the same time, as afforded by peripherals commonly used today for such tasks (e.g., three-dimensional mice, force–feedback interfaces, etc.) may be more intuitive and efficient than traditional, desktop WIMP
<sup><a href="#Fn1"><span class="u-visually-hidden">Footnote </span>1</a></sup>-type interfaces. Additionally, multimodal management of sensorimotor feedbacks (based on an approach aiming to dynamically specify adaptation of visual, haptic and audio renderings to the characteristics of the information in use) is one possible answer to the problems related to the simultaneous presentation of large amounts of data. Finally, a strongly interactive approach of VR docking allows the docking expert to be placed on the forefront of the work, rather than giving an automatic algorithm complete control over the generation of possible sets of solutions. We believe our approach, which combines benefits of multimodal interaction with the capitalization of docking experts’ occupational skills (in biology, crystallography, bioinformatics) in modeling will allow improvements in the speed of predictions for the structure of protein–protein complexes, as well as in overall search efficiency and in the quality of results obtained when analyzing possible solutions.</p><p>Applications for interactive docking, whether multimodal or immersive, have already been developed in the past and are presented in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec5">3.2</a>. However, this work seems set back by a lack of clear knowledge regarding user needs and working practices. In order to gather this knowledge, we conducted ergonomic analyses of the protein docking task the way it is carried out by experts in the field today, in order to determine advantages and drawbacks of existing tools and help design an innovative and relevant tool for multimodal VR interaction. The data, recommendations and task scenarios based on these analyses (see Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec7">4</a>) allowed us to propose a comprehensive hybrid approach to docking, combining interactive and automatic stages. This approach has been implemented in a first prototype. We present its architecture, related constraints, and the technical solutions chosen to circumvent them (in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec15">5.1</a>). We are currently in the process of evaluating this prototype in collaboration with docking experts (see Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec25">6</a>).</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">The context: protein–protein docking</h2><div class="c-article-section__content" id="Sec2-content"><p>Proteins can be viewed as both the building blocks and workforce of cells. They are synthesized based on portions of Deoxyribonucleic Acid (DNA) called coding sequences or genes. Genes are transcribed in the form of Messenger RiboNucleic Acid (mRNA), which is then translated by ribosomes in the form of a protein, following a specific coding scheme (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig1">1</a>A). Each triplet of mRNA bases corresponds to one Amino Acid (AA) or residue. There are 20 basic types of AAs. The various physicochemical properties of AAs give rise to interactions at the atomic level, inducing protein folding which contributes in turn to protein stability (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig1">1</a>B). These properties also play a crucial role in protein–protein interactions. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>
                                    <b>A</b> Overall view of protein synthesis: transcription of DNA to messenger RNA and translation of mRNA to sequences of amino acids chosen from 20 possible varieties, here shown according to their physicochemical properties (using a Venn diagram). <b>B</b> Based on the chemical nature of component amino acids, resulting interactions cause the protein to fold up in space. This three-dimensional shape can be described according to four levels: <b>a</b> primary, <b>b</b> secondary, <b>c</b> tertiary, and last <b>d</b> quaternary</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Proteins, therefore, can be seen as long chains composed of successive AAs folded in space, which are the product of the expression of an organism’s genetic makeup. But in order to execute their functions within cells, proteins must undergo folding and take a specific three-dimensional form. This form may be characterized following four levels of structure (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig1">1</a>B). The order in which residues are linearly arranged, i.e., their sequence, constitutes the protein’s primary structure (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig1">1</a>B, a). Some of the structure’s segments organize themselves into sequences of specific substructures called secondary structures (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig1">1</a>B, b). These structures, stabilized by hydrogen bonds, can be divided into two groups: regular secondary structures, called alpha helices and beta sheets, which are linked together by irregular structures called loops. The arrangement of these secondary structures thus constitutes the three-dimensional, or tertiary structure of the protein (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig1">1</a>B, c), which determines protein function within the cell.</p><p>Once folded, proteins carry out various functions within the cell, such as transporting molecules (e.g., hemoglobin, chaperone proteins), inter- and intracellular signaling and communications (e.g., hormones, neurotransmitters, ions), immune defense functions (immunoglobulins, adhesion molecules), or cellular metabolism (chlorophyll, apoptosis proteins, transcription factors, ATP synthesis). These cellular functions are closely linked to the protein’s tertiary structure, but also to its interactions with other proteins. These interactions produce new entities called protein or supramolecular complexes (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig2">2</a>). Such assemblies make up the protein’s quaternary structure (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig1">1</a>B-d).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>
                                    <b>a</b> Quaternary structure of an antibody (immunoglobulin). This assembly allows antibodies to recognize antigens in foreign bodies in order to form a supramolecular complex. <b>b</b> This particular complex is formed by interactions between an enzyme, barnase (<i>below</i>) and its substrate, barstar (<i>above</i>). Molecular structures are represented along with a transparent molecular surface in order to illustrate surface complementarity</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>In short, better understanding of protein–protein interactions is a major stake for biomedical research. Indeed, designing new drugs increasingly involves targeting specific protein–protein interactions (Villoutreix et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Villoutreix BO, Bastard K, Sperandio O, Fahraeus R, Poyet JL, Calvo F, Deprez B, Miteva MA (2008) In silico-in vitro screening of protein-protein interactions: towards the next generation of therapeutics. Curr Pharm Biotechnol 9(2):103–22" href="/article/10.1007/s10055-009-0136-z#ref-CR51" id="ref-link-section-d9562e695">2008</a>), or alternately, involve synthesizing recombinant proteins meant to emulate interaction with the original native protein (Pipe <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Pipe SW (2008) Recombinant clotting factors. Thromb Haemost 99(5):840–850" href="/article/10.1007/s10055-009-0136-z#ref-CR41" id="ref-link-section-d9562e698">2008</a>). It becomes more and more necessary, therefore, to identify the three-dimensional structure of protein complexes. Two experimental methods currently exist to observe the three-dimensional structure of a protein. These are X-ray crystallography and Nuclear Magnetic Resonance (NMR). All known protein structures are currently housed on the website of the Protein Data Bank (PDB) (Berman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Berman HM, Westbrook J, Feng Z, Gilliland G, Bhat T, Weissig H, Shindyalov I, Bourne P (2000) The protein data bank. Nucleic Acids Res 1(28):235–242" href="/article/10.1007/s10055-009-0136-z#ref-CR9" id="ref-link-section-d9562e701">2000</a>). This database contains about 50,000 protein structures for many kinds of organisms. However, this number remains small in comparison to estimates of the number of existing proteins in the natural world (e.g., about 20,000 proteins for Man). This is because experimental determination of protein structure is often difficult, and in some cases impossible. Indeed, solving this kind of problem involves mass production and purification of the protein, and in the case of crystallography, production of diffractive crystals. In determining the structure of a protein complex, difficulties in production and purification are all the more critical, because partner proteins must be produced at the same time for complexes to form. Additionally, the time necessary for crystallization may be incompatible with the lifespan of some complexes. For all these reasons, many scientists have attempted to predict the structure of such complexes using computing tools through methods and algorithms for molecular docking.</p></div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Related work</h2><div class="c-article-section__content" id="Sec3-content"><p>In this section we present a state of the art in computer-based approaches and existing VR solutions for protein docking, then we introduce the main focus of the <i>CoRSAIRe</i> project in multimodal VR interaction in this application field.</p><h3 class="c-article__sub-heading" id="Sec4">Automatic approaches for docking</h3><p>Current techniques for the experimental study of the three-dimensional structure of protein complexes (crystallography, NMR, electronic cryomicroscopy, etc.) have several limitations (in terms of size and type of proteins) and are costly in terms of time and money. For that reason, computer-based (in silico) docking methods have been developed in the past, to deduce the functional three-dimensional structure of a complex based on single molecules, which turns out to be considerably easier and cheaper than experimental, in vitro methods (Grosdidier <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Grosdidier A (2007) Conception d’un logiciel de docking et applications dans la recherche de nouvelles molécules actives. PhD thesis, Université Joseph Fourier Grenoble 1, France" href="/article/10.1007/s10055-009-0136-z#ref-CR27" id="ref-link-section-d9562e722">2007</a>). Current approaches are strictly computational and results are evaluated using visualization tools. These approaches can be divided into 4–5 successive stages (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig3">3</a>): (1) choice of the representation mode for proteins (atomic view, pseudo-atoms, grid, etc.); (2) conformational exploration (taking into account position, orientation, and shape of the ligand); (3) minimization of the function used to evaluate binding energy (i.e., <i>score</i>) for conformations derived from the exploration; (4) grouping by similarity and classification through evaluation or fine-tuning of the <i>scores</i>, added with a manual stage of visualization when score alone does not allow native conformation (i.e., the one present in nature) to be discriminated from other generated conformations; (5) an optional stage for fine-tuning selected complexes, through energy minimization or molecular dynamics. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>The five stages of the docking task</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>A large number of docking algorithms depend on a comprehensive approach of conformational exploration, the main problem being combinatory explosion of the number of possible solutions. These approaches can be sorted into three categories: those based on systematic sampling, on molecular dynamics techniques, and on classification interaction modes between proteins. An ideal function would yield, for a given mode of interaction, the binding energy of two proteins involved in a complex (see Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec18">5.2.2</a>). Such functions aim to reproduce experimental values of free binding energy, and though minimization, to reach the overall minimum energy in the set of all possible protein–protein complexes.</p><p>Consequently, in real life cases, automatic docking algorithms, such as <i>ClusPro</i> (Comeau et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Comeau SR, Gatchell WD, Vajda S, Camacho CJ (2004) ClusPro: an automated docking and discrimination method for the prediction of protein complexes. Bioinformatics 20(1):45–50" href="/article/10.1007/s10055-009-0136-z#ref-CR14" id="ref-link-section-d9562e764">2004</a>) or <i>Hex</i> (Ritchie <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Ritchie DW (2003) Evaluation of protein docking predictions using Hex 3.1 in CAPRI rounds 1 and 2. Proteins 52(1):98–106" href="/article/10.1007/s10055-009-0136-z#ref-CR44" id="ref-link-section-d9562e770">2003</a>), must manage two difficulties in order to reach a relevant result. The first is to process a space of potential solutions which increases in size along with the number of degrees of freedom in describing protein position and conformation, thus running the risk of not being processed in an acceptable amount of time. The second problem is that search algorithms produce local minima, and cannot easily find the global minimum that is associated to the native form of the complex (Wang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Wang R, Lu Y, Wang S (2003) Comparative evaluation of 11 scoring functions for molecular docking. J Med Chem 46:2287–2303" href="/article/10.1007/s10055-009-0136-z#ref-CR54" id="ref-link-section-d9562e773">2003</a>).</p><p>To finalize a docking simulation, experts rely upon a manual stage of visualization to analyse the generated complexes. This task consists in a detailed analysis of residues and atoms involved in the interface of each complex, through the identification of hydrogen bonds, salt bridges, and especially the presence of hotspots, i.e., amino acids at the interface, known from experimental studies to be part of the interface. However, it can be difficult to manipulate two three-dimensional structures at the same time to observe the interface with traditional interaction tools, since one protein usually hides the other. We therefore believe docking assisted by VR and multimodal interaction presents a relevant alternative to improve the work of experts in the field. Such techniques might allow a more intuitive interaction with three-dimensional protein structures.</p><p>Finally, two approaches are used to “thin the herd” of selected complexes. One consists in minimizing the rigid bodies and lateral chains of amino acids present at the interface. This approach is implemented in several applications such as <i>ICM-DISCO</i> (Fernandez-Recio et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Fernandez-Recio J, Totrov M, Abagyan R (2003) ICM-DISCO docking by global energy optimization with fully flexible Side-Chains, vol 1, issue 52. Bradford Books/MIT Press, Cambridge, MA, pp 113–117" href="/article/10.1007/s10055-009-0136-z#ref-CR22" id="ref-link-section-d9562e786">2003</a>), <i>MMTK</i> (Hinsen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Hinsen K (2000) The molecular modeling toolkit: a new approach to molecular simulation. J Comput Chem 21:79–85" href="/article/10.1007/s10055-009-0136-z#ref-CR31" id="ref-link-section-d9562e792">2000</a>), <i>FireDock</i> (Andrusier et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Andrusier N, Nussinov R, Wolfson HJ (2007) FireDock: fast interaction refinement in molecular docking. Proteins 69(1):139–59" href="/article/10.1007/s10055-009-0136-z#ref-CR4" id="ref-link-section-d9562e799">2007</a>), <i>PELE</i> (Borrelli et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Borrelli KW, Vitalis A, Raul Alcantara R, Guallar V (2005) PELE: protein energy landscape exploration. A novel Monte Carlo based technique. J Chem Theory Comput 6(1):1304–1311" href="/article/10.1007/s10055-009-0136-z#ref-CR10" id="ref-link-section-d9562e805">2005</a>), <i>ATTRACT</i> (Zacharias, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Zacharias M (2005) ATTRACT: protein-protein docking in CAPRI using a reduced protein model. Proteins 60(2):252–6" href="/article/10.1007/s10055-009-0136-z#ref-CR56" id="ref-link-section-d9562e811">2005</a>), etc. The other approach involves studying the dynamic behavior of the selected complex. The software program <i>Gromacs</i> (Hess et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Hess B, Kutzner D, Vanderspoel C, Lindahl E (2008) GROMACS 4: algorithms for highly efficient, load-balanced, and scalable molecular simulation. J Chem Theory Comput 4(3):435–447" href="/article/10.1007/s10055-009-0136-z#ref-CR30" id="ref-link-section-d9562e818">2008</a>), for example, allows evaluation of atomic positions in time based on their physicochemical properties. This approach allows first to evaluate complex stability, as well as possible conformational changes induced by the interaction, e.g., loop deformation. We should add, however, that this approach remains very costly in terms of processing time, compared to minimizers which allow users to process a given configuration very quickly.</p><h3 class="c-article__sub-heading" id="Sec5">Interactive and immersive approaches for docking</h3><p>Given the drawbacks of classical docking algorithms and the new possibilities afforded by VR, several teams have taken an interest in recent years into problems related to interactive and immersive docking. Early work in the field primarily involved identification of technical needs and limitations to achieve this. The <i>STALK</i> system (Levine et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Levine D, Facello M, Hallstrom P, Reeder G, Walenz B, Stevens F (1997) Stalk: an interactive system for virtual molecular docking. Proc IEEE Conf Comput Sci Eng 4(2):55–65" href="/article/10.1007/s10055-009-0136-z#ref-CR35" id="ref-link-section-d9562e832">1997</a>) uses parallel and distributed processing to process visual renderings of three-dimensional protein models and execute the algorithms for generating possible solutions. Using this system, the docking expert may visualize two proteins, assist the docking algorithm, suspend it to move a molecule using a three-dimensional mouse, and resume the algorithm using this new position. System evaluations were concerned with comparing binding energies of solutions obtained. Another system, <i>VRDD</i> (Anderson and Weng <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Anderson A, Weng Z (1999) VRDD: applying virtual reality visualization to protein docking and design. J Mol Graphi Model 17(3):180–186" href="/article/10.1007/s10055-009-0136-z#ref-CR2" id="ref-link-section-d9562e838">1999</a>), implemented a search algorithm using a Monte Carlo method, which allowed gradual reduction of the search space through the exploration of similar solutions. Evaluations were carried out over three test cases, comparing the Root Mean Square Deviation (RMSD) between a solution proposed by the algorithm, and a known crystallographic structure of the same complex. Results were deemed conclusive for two of the test cases, but not for the third, which involved large (i.e., a larger number of possible solutions) and flexible proteins. However, this work allowed identification of issues related to real-time computation of energy values, as well as search and construction for the flexible structures of proteins. Recent work, carried out by Ray et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference (2005" title="Ray N, Cavin X, Paul JC, Maigret B (2005) Intersurf: dynamic interface between proteins. J Mol Graph Model 23(4):347–354" href="/article/10.1007/s10055-009-0136-z#ref-CR42" id="ref-link-section-d9562e841">(2005</a>) and Ferey et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Ferey N, Delande O, Grasseau G, Baaden M (2008) A VR framework for interacting with molecular simulations. In: Proceedings of the international conference on virtual reality sofware and technologies (ACM-VRST’08)" href="/article/10.1007/s10055-009-0136-z#ref-CR21" id="ref-link-section-d9562e845">2008</a>), focused on solving these problems through optimized visual rendering, using a plugin for existing interactive molecular visualization software, such as <i>Visual Molecular Dynamics (VMD)</i> and host molecular simulation software, such as <i>NAMD</i> or <i>GROMACS</i>. The <i>DockingShop</i> software program (Lu et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Lu T-C, Ding JH, Crivelli SN (2005) DockingShop: a tool for interactive protein docking. In: Procedings of the computational systems bioinformatics conference, pp 271–272" href="/article/10.1007/s10055-009-0136-z#ref-CR36" id="ref-link-section-d9562e860">2005</a>) currently seems to be the most advanced system for interactive docking. <i>DockingShop</i> implements representations of proteins using principles of robotics, combined to real-time display of essential data for the study of protein–protein interactions (hydrogen bonds, energy, surface complementarity, interpenetration and hydrophobic effects. More recently, a more sophisticated robotics-based approach was proposed to represent peptide chains and molecules (Rossi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Rossi R, Isorce M, Morin S, Flocard J, Arumugam K, Crouzy S, Vivaudou M, Redon S (2007) Adaptive torsion-angle quasi-statics: a general simulation method with applications to protein structure analysis and design. Bioinformatics 23(13):408–417" href="/article/10.1007/s10055-009-0136-z#ref-CR45" id="ref-link-section-d9562e867">2007</a>).</p><h3 class="c-article__sub-heading" id="Sec6">Main focuses of the <i>CoRSAIRe</i> project for docking</h3><p>However, these approaches remain very complex regarding the quantity of data that must be conveyed to the user, as well as regarding the limitations of classical WIMP interfaces. Currently, the use of VR devices, such as tracking or haptic devices used in VR, allows more direct and natural interactions with objects in a three-dimensional space. They seem relevant for docking tasks, since these consist in evaluating configurations defined by the relative positions and orientations of one protein in relation to another. Second, given the large quantity of information required by users to evaluate the “quality” of a configuration, it also seems relevant to supplement visual feedback with audio and haptic sensorimotor channels. Haptic rendering is known to improve the quality of operator interactivity in an immersive environment, as well as his perception of the objects handled (Seeger and Chen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Seeger A, Chen J (1997) Controlling force feedback over a network. In: Proceedings of the second PHANToM user’s group workshop" href="/article/10.1007/s10055-009-0136-z#ref-CR48" id="ref-link-section-d9562e882">1997</a>) or data analyzed (Lundin et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Lundin KE, Sillen M, Cooper MD, Ynnerman A (2005) Haptic visualization of computational fluid dynamics data using reactive forces. In: Procedings of the society of photo-optical instrumentation engineer conference (SPIE’05), visualization and data analysis, vol 5669, pp 31–41" href="/article/10.1007/s10055-009-0136-z#ref-CR37" id="ref-link-section-d9562e885">2005</a>). Likewise, audio renderings may improve communication of complex information (Barass and Zehner <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Barass S, Zehner B (2000) Responsive sonification of well-logs. In: Proceedings of the international conference on auditory display (ICAD’00)" href="/article/10.1007/s10055-009-0136-z#ref-CR8" id="ref-link-section-d9562e888">2000</a>). Furthermore, substitutions and redundancy between these channels of communication may have beneficial results on user performance, as long as the choice of modalities is relevant to the task at hand. Richard et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Richard P, Chamaret D, Inglese F-X, Lucidarme P, Ferrier J-L (2006) Human-scale haptic virtual environment for product design: effect of sensory substitution. Int J Virtual Real 5(2):37–44" href="/article/10.1007/s10055-009-0136-z#ref-CR43" id="ref-link-section-d9562e891">2006</a>) and Kitagawa et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Kitagawa M, Dokko D, Okamura A, Yuh D (2005) Effect of sensory substitution on suture-manipulation forces for robotic surgical systems. J Thorac Cardiovasc Surg 129(1):151–158" href="/article/10.1007/s10055-009-0136-z#ref-CR34" id="ref-link-section-d9562e894">2005</a>) showed, for example, that specific audio and visual renderings can effectively convey information that is presented used haptic modalities.</p><p>The main focus of the <i>CoRSAIRe</i> project is to design a new methodology in that field based on advanced interaction and rendering possibilities, that VR technologies may offer. With respect to other works on docking, we are specifically studying multi-sensorimotor rendering during an interactive docking task. Several previous works have explored the possibilities afforded by multimodal feedback for the docking task. However these projects mainly rely on haptic or audio channels, but rarely on the combining the two with visual rendering. Haptics-centric projects mostly deal with the generation of force feedback to guide biochemists toward optimal solutions. That is the case of <i>GROPE</i> (Brooks et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1990" title="Brooks FP Jr, Ouh-Young M , Batter JJ, Jerome Kilpatrick P (1990) Project GROPE: Haptic displays for scientific visualization. In: Proceedings of the 17th conference on computer graphics and interactive techniques, pp 177–185" href="/article/10.1007/s10055-009-0136-z#ref-CR23" id="ref-link-section-d9562e906">1990</a>), <i>IVPS</i> (Maciejewski et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Maciejewski R, Choi S, Ebert DS, Tan HZ (2005) Multi-Modal perceptualization of volumetric data and its application to molecular docking. In: Proceedings of the first joint eurohaptics conference and symposium on haptic interfaces for virtual environment and teleoperator systems." href="/article/10.1007/s10055-009-0136-z#ref-CR38" id="ref-link-section-d9562e912">2005</a>) and <i>SenSitus</i> (Wriggers and Birmanns <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Wriggers W, Birmanns S (2003) Interactive fitting augmented by force-feedback and virtual reality. J Cell Biol 144:123–131" href="/article/10.1007/s10055-009-0136-z#ref-CR55" id="ref-link-section-d9562e919">2003</a>), a plug-in for <i>VMD</i> that allows users to explore proteins with a haptic arm. These projects aim to provide simultaneous renderings of multiple kinds of volumetric data, and to test various paradigms for human–computer interaction. These software platforms allow users to move proteins while receiving haptic feedback regarding collisions between molecules. Evaluations are based on the identification of docking errors as well as the execution time of docking task. Stereoscopic rendering allows reduction of error rate, as well as of the execution time for the various paradigms, whereas haptic feedback lengthens manipulation times due to sequential, local strategies of protein exploration. Other types of haptic feedback, such as vibrotactile feedback (vibration-based), are seldom used. However, in the case of audio feedback, existing projects aim to provide users some clues regarding molecular properties (e.g., protein binding sites, surface complementarity, etc.) using <i>earcons</i> (auditory icons) or data sonification (Garcia-Ruiz and Guttierez-Pulido <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Garcia-Ruiz MA, Guttierez-Pulido JR (2006) An overview of auditory display to assist comprehension of molecular information. Interact Comput 18(4):853–868" href="/article/10.1007/s10055-009-0136-z#ref-CR24" id="ref-link-section-d9562e928">2006</a>). Various works are concerned with the sonification of sequential data such as composition of DNA strands (Hart and Read <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Hart TN, Read RJ (2004) A multiple-start Monte Carlo docking method. Proteins Struct Funct Genet 13(3):206–222" href="/article/10.1007/s10055-009-0136-z#ref-CR28" id="ref-link-section-d9562e931">2004</a>) or of surface complementarity between proteins, based on computing the standard deviation of minimal distances between pairs of atoms.</p><p>Beyond these purely technical aspects, lack of analysis of user needs in the initial stages of such design projects causes gaps between their expectations (natural interaction with generated representations of proteins, allowing quick and easy docking of protein complexes) and the end results of the design process (technically impressive systems that are useless as work tools). Conversely, our approach relies on early involvement of users in the design process of a docking system, aiming to (1) hasten and ease the development of functional prototypes through improved decision making; (2) improve acceptance of such systems by users of these innovative interfaces; (3) suggest new, unexplored avenues for research and innovation in docking (Anastassova et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Andrusier N, Nussinov R, Wolfson HJ (2007) FireDock: fast interaction refinement in molecular docking. Proteins 69(1):139–59" href="/article/10.1007/s10055-009-0136-z#ref-CR4" id="ref-link-section-d9562e937">2007</a>). Furthermore, current tools for docking put the user in a position of observing and controlling computer-generated solutions, rather than playing an active part in the process. In other words, the scientist is not truly part of the system and cannot tap into his expertise during the search for solutions. The second original aspect of our approach thus aims to involve the scientist in the docking “loop”.</p><p>For these reasons, before designing the <i>CoRSAIRe</i> approach for docking (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec13">4.3</a>) and implementing its concepts into our immersive and multimodal application (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec14">5</a>), we performed a set of ergonomic studies. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec8">4.1</a> below describes the methodology followed, and the model obtained for the docking task as it is carried out today, in order to identify advantages and drawbacks of existing computer-based and VR solutions in that field (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec9">4.2</a>). These results allowed us to propose a set of basic principles to specify multimodal VR user interface for docking of proteins, which would likely allow users to reach the objectives outlined.</p></div></div></section><section aria-labelledby="Sec7"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7">An initial step for design: clarifying field practices and users needs</h2><div class="c-article-section__content" id="Sec7-content"><h3 class="c-article__sub-heading" id="Sec8">Method</h3><p>Our study first focused on analyzing the use of existing docking tools, designed for desktop interfaces, as well as the impact, as foreseen by users, of the introduction of VR technology and multimodal interfaces in this task. Four researchers in bioinformatics, aged 28–50 years (M = 36 years, SD = 9.95) took part in this investigation. First, we carried out, recorded and made <i>verbatim</i> transcriptions of four interviews in the workplace. These interviews were anonymous and confidential. They were structured according to a guide which covered various questions ranging from the types of docking problems subjects were confronted to in their line of work, which software was used to solve these, as well as how subjects might envision working in a multimodal virtual environment (MVE). A cognitive discursive analysis (Ghiglione et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Ghiglione R, Landré A, Bromberg M, Molette P (1998) L’analyse automatique des contenus" href="/article/10.1007/s10055-009-0136-z#ref-CR25" id="ref-link-section-d9562e974">1998</a>) of the interview corpora was carried out using the program <i>Tropes</i> developed by <i>Acetic Software</i>. Second, three work sessions were videotaped and analyzed, allowing us to view the use of three standard software programs used in docking: <i>ICM-Disco</i> (Fernandez-Recio et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Fernandez-Recio J, Totrov M, Abagyan R (2003) ICM-DISCO docking by global energy optimization with fully flexible Side-Chains, vol 1, issue 52. Bradford Books/MIT Press, Cambridge, MA, pp 113–117" href="/article/10.1007/s10055-009-0136-z#ref-CR22" id="ref-link-section-d9562e987">2003</a>), <i>ClusPro</i> (Comeau et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Comeau SR, Gatchell WD, Vajda S, Camacho CJ (2004) ClusPro: an automated docking and discrimination method for the prediction of protein complexes. Bioinformatics 20(1):45–50" href="/article/10.1007/s10055-009-0136-z#ref-CR14" id="ref-link-section-d9562e993">2004</a>), and <i>Hex</i> (Ritchie, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Ritchie DW (2003) Evaluation of protein docking predictions using Hex 3.1 in CAPRI rounds 1 and 2. Proteins 52(1):98–106" href="/article/10.1007/s10055-009-0136-z#ref-CR44" id="ref-link-section-d9562e999">2003</a>). Video data of these sessions served as a basis for task analysis. Verbal protocols were collected throughout these sessions, and analyzed using explicit verbalizations of a task as a unit for analysis. Coding the actions and verbalizations collected in this way, allowed us to elaborate two distinct resources for designers. The first, a task model in the form of a hierarchical decomposition using Hierarchical Task Analysis (HTA) methodology (Annett, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Annett J (2003) Hierarchical task analysis. In: Handbook of cognitive task design, pp. 17–35" href="/article/10.1007/s10055-009-0136-z#ref-CR5" id="ref-link-section-d9562e1002">2003</a>); the second, an illustrated overview of the course of a session in the form of a story-board describing the tasks carried out in a standard docking problem: docking of the barnase-barstar complex (Rosson and Carroll <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Rosson MB, Carroll JM (2002) Scenario-based design. In: Jacko JA, Sears A (eds) The human-computer interaction handbook fundamentals, evolving technologies and emerging applications, pp 1032–1050" href="/article/10.1007/s10055-009-0136-z#ref-CR46" id="ref-link-section-d9562e1006">2002</a>).</p><h3 class="c-article__sub-heading" id="Sec9">Results</h3><p>Results of the analysis allowed us to construct three elements relevant to the design of a MVE for molecular docking: (1) a model of the tasks carried out; (2) a model of user needs, and (3) a set of principles to guide design choices in the allotment of information to various display modalities and in designing the associated display and interaction techniques.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec10">A goal-oriented hierarchical model of the current task and its anticipated changes with multimodal VR assistance</h4><p>The HTA task tree (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig4">4</a>) describes the current way of carrying out the docking task as a hierarchy of goals and subgoals. This model was extracted by combining results form the interviews and observations. In short, the first stage involves generating a large number of potential models of the protein–protein complex. As an input to this task, files are used that describe the three-dimensional structure of proteins in their unbound form, as housed on the <i>PDB</i> server. The second stage is the execution of an automatic algorithm to explore the conformational space associated to binding energies (scores) in order to eliminate physically impossible solutions. Clustering then allows grouping of remaining solutions according to similarity. Complex clusters thus produced are then classified according to their score. Finally, the scientist selects a small number of these solutions as candidates for comparative experimental validation. Based on this initial model, we have formalized an hypothetical model of how the task could evolve with multimodal VR in order to provide experts with an improved support to their activities and informational needs related to docking (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig5">5</a>). A more detailed account of the arguments and basis to this anticipation is given afterwards.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>A partial view of the HTA task tree for molecular docking, and corresponding task plan (<i>inset</i>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                              <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>A proposal for molecular docking as it might be carried out in a multimodal context, and corresponding task plan (<i>inset</i>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec11">Needs in terms of information display</h4><p>Cognitive Discursive Analysis highlighted, through balancing and geometrical proximity between central referents in scientists discourse, four basic informational needs in docking. Three of these relate to the properties of the molecules studied. Their interaction is viewed as a central aspect of searching and adjusting for the optimal configuration:
</p><ul class="u-list-style-dash">
                      <li>
                        <p>Topological complementarity of molecules (see Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec17">5.2.1</a>);</p>
                      </li>
                      <li>
                        <p>Energy characteristics (see Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec18">5.2.2</a>);</p>
                      </li>
                      <li>
                        <p>The fourth need relates to existing knowledge of the molecular interface studied, when such knowledge is available. It consists in a list of amino acids, termed “hotspots”, which the biologist knows to be involved in protein–protein interaction, and therefore to be present at the interface.</p>
                      </li>
                    </ul>
                           <p>One should note that the statistical weight of the score function in the subjects discourse was zero. This suggests that the score function is not viewed as a central tool for docking, but rather as one of several means to confirm hypotheses. This is congruent with the theory underlying scoring functions. Indeed, scores are assessed based on equations physical and chemical phenomena in order to best reflect binding energy. However, in most cases, scoring functions do not allow to discriminate one single complex among all generated complexes. Interviews have shown that docking entails joint study of these molecular properties, based on existing knowledge of the molecular interface. Observations of work sessions also showed that scientists spend on average 42% of session time consulting external data sources such as the PubMed database or work notes, in order to identify potential hotspots and construct this knowledge prior to docking.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec12">Restricting the design space for multimodal information distribution by considering usability principles and user task characteristics</h4><p>The term “modal allocation” (André <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="André E (2000) The generation of multimedia presentations. In: Handbook of natural language processing, pp 305–327" href="/article/10.1007/s10055-009-0136-z#ref-CR3" id="ref-link-section-d9562e1123">2000</a>) refers to the specific use of one or more sensory modalities to display an information. It is preferable for users to use optimal modal allocation considering both technical (e.g. VR-related), task (e.g. characteristics of information relevant to scientists), and operator-related constraints (e.g. characteristics of perception, of expertise, etc.).</p><p>Proposing principles for modal allocation implies weighing specific information–modality associations. One problem is that there exist no a priori ergonomic specifications regarding modal allocation for information crucial to such types of tasks. Indeed, although research on the design of human–machine interfaces started several decades ago, few works offer robust principles for choosing a specific modality to display specific types of information. Furthermore, little work focuses on the design of Human–Computer Interaction (HCI) for data exploration tasks. It is, however, possible to formulate hypotheses based on the one hand on the ways in which operators process information, and on the other hand (and even more strongly) on the needs highlighted by task analysis. In the case of molecular docking, such analysis has shown the need to display one to four sources of information simultaneously according to what stage the task is at, and to what prior knowledge is available: molecular topology, hydrophobicity of residues, electrostatic fields, and residues potentially involved in the interface.</p><p>Task analysis also allowed identification of the following constraints, related to the docking task:
</p><ul class="u-list-style-dash">
                      <li>
                        <p>Since all four types of information may be used by the docking expert at any one time, the risk of overload needs to be anticipated. Therefore, information needs to be spread out over various information channels in a balanced fashion to avoid such an overload, particularly visual overload. Although sonification and haptization are liable to effectively lighten the visual channel and improve task performance, randomizing modal allocation may lead to inferior performance or to an interface in which all information would be displayed on a single mode. It is therefore necessary to define criteria to decide allocation schemes which would prove to be acceptable to users;</p>
                      </li>
                      <li>
                        <p>One important distinction according to this point of view is between data whose status is perennial and invariant as opposed to that which is dynamic and ephemeral, both these types being instrumental to the docking task. Some information, e.g., regarding molecular structure, should be available at all times, never changing in the course of one work session. If one were to choose audio or haptic displays for perennial information, one consequence of the properties of cognitive systems for information processing may be perceptual filtering of this information, i.e., its disappearance from the focus of attention. One other consequence may be user discomfort, possibly resulting in de-activation of corresponding display functions when the user views the information as already known and overly invasive. For perennial information, we thus suggest to use the visual modality.</p>
                      </li>
                      <li>
                        <p>One other criterion for modal allocation is the semantics of information, specifically its proximity to properties of display modalities. As mentioned earlier, taking into account information such as electrostatic forces or hydrophobic interactions is essential to constructing protein–protein complexes. Electrostatic forces might be displayed using a haptic constraint, since this modality can convey attraction or repulsion in a way reminiscent of everyday experience. Visual and audio modalities should not, however, be excluded on principle. But using them would imply constructing an interpretation scale where attraction and repulsion phenomena would be made apparent, as would the scale’s “neutral point”, e.g., using one tone for attraction and another for repulsion).</p>
                      </li>
                    </ul>
                           <p>These various constraints allow us to formulate the following principles for the design of a multimodal application for molecular docking, summed up in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-009-0136-z#Tab1">1</a>:
</p><ul class="u-list-style-dash">
                      <li>
                        <p>Use at least the visual modality to display molecular surfaces and contours, as well as allow manipulation of protein models;</p>
                      </li>
                      <li>
                        <p>Simultaneously, present all information involved in the computation of energy scores, using a combination of modalities;</p>
                      </li>
                      <li>
                        <p>As long as it is possible, remain close to the realm of everyday experience, based on information semantics (e.g., use haptic rendering for collisions and electrostatic forces);</p>
                      </li>
                      <li>
                        <p>Audio signals may be used to sonify time-dependent variables such as the score, presence of hotspots in the interface, presence of hydrogen bonds at the interface, etc.</p>
                      </li>
                      <li>
                        <p>Use a combination of modalities to display as much information as feasible without reaching cognitive overload in the user.</p>
                      </li>
                    </ul>
                              <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Restricting the modal allocation space</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-009-0136-z/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>It should be noted, however, that these principles are in part hypotheses which will be validated experimentally in the course of an ongoing research project. These validations will be briefly evoked in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec25">6</a>.</p><h3 class="c-article__sub-heading" id="Sec13">Reconciling fully automatic and interactive approaches</h3><p>According to results presented in the previous section, we designed a new approach for protein docking which aims to use expert knowledge by combining multimodal interaction and rendering with automatic approaches. By allowing the user to interact earlier in the process rather than in the laye stages of work or through a single, early operation of parameter-setting, we aim to reduce processing times and the risks of false positive results (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig6">6</a>). A first stage of the docking task in an immersive environment, named “reduction of the conformational search space”, allows the user, an expert in docking, to interactively build a protein complex (tasks 0.1 and 0.2 of HTA tree in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig5">5</a>) which are potential docking configurations, using visual, audio and haptic feedback (tasks 0.3). This first stage also allows quick reduction of the search space by relying on the expert’s three-dimensional pattern matching skills and specific knowledge in protein–protein docking. At this point, a qualitative analysis can be done by interpreting multimodal feedback (tasks 0.3.2) in order to save these docking configurations (tasks 0.4). A second stage named “automatic filtering of selected configurations” relates to the classic automated docking procedure, but will be restricted to search spaces defined by the docking expert. This stage consists in assessing a finer <i>score</i> for those conformations selected in the first stage, as well as submitting those to an automatic stage of refining by energy minimization (tasks 0.2.1). Finally, the third stage is called “exploration of the sorted and filtered docking configurations”. In this final stage, intermolecular movements are disabled (tasks 0.2.2), because the goal is to explore and compare (tasks 0.5) the solutions generated in the first stage and sort them based on the results of the second stage in order to extract a very small number of protein complexes selected for experimental validation.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>A hybrid and multimodal approach for docking</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        </div></div></section><section aria-labelledby="Sec14"><div class="c-article-section" id="Sec14-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec14">Our multimodal and immersive application dedicated to protein docking</h2><div class="c-article-section__content" id="Sec14-content"><h3 class="c-article__sub-heading" id="Sec15">Hardware and software architecture</h3><p>The hardware architecture of our multimodal docking VR environment is based on a CAVE-type device (Cruz-Neira et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Cruz-Neira C, Sandin DJ, DeFanti TA, Kenyon RV, Hart JC (1992) The CAVE: audio visual experience automatic virtual environment. ACM SIGGRAPH Comput Graph 35(6):64–72" href="/article/10.1007/s10055-009-0136-z#ref-CR18" id="ref-link-section-d9562e1480">1992</a>) equipped with a system for overhead projection with an active stereoscopic device for visual immersion. Three-dimensional audio feedbacks are generated using <i>MaX/MSP</i> and their transmission is carried out using either headphones, or a set of eight loudspeakers spread out over the immersive system. Haptic feedback, finally, is carried out using the <i>Virtuose</i> haptic interface, commercialized by <i>Haption</i>. Capture of the user’s movements and head movements for active stereoscopy, hand movements to manipulate a three-dimensional mouse is carried out by <i>ARTrack</i>, a system of infrared cameras and sensors.</p><p>The software architecture of our multimodal docking VR environment (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig7">7</a>) is based on a component programming. Each component can be distributed on the network, and is encapsulated into a <i>Open Sound Control</i> (OSC) layer, for managing communication through network between “command” components, “scoring” components, and “rendering” components. Data and events involving these components are synchronized on the network through encapsulation of selected data (the position and orientation of each protein for example) using our own <i>OSC</i> protocol. A “command” component manages distribution of events coming from all VR devices using the software platform <i>VEserver</i> (Touraine et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Touraine D, Bourdot P, Bellik Y, Bolot L (2002) A framework to manage multimodal fusion of events for advanced interactions within virtual environments. In: Proceedings of the 8th EUROGRAPHICS workshop on virtual environment, (EGVE’2002)" href="/article/10.1007/s10055-009-0136-z#ref-CR49" id="ref-link-section-d9562e1510">2002</a>), except for haptic device, for which we used the <i>Virtuose</i> API for managing 6DoF output and force feedback rendering. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig7_HTML.gif?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig7_HTML.gif" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Software architecture of the CoRSAIRe platform dedicated to multimodal immersive docking</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The “scoring” component refers to physical engine we developed dedicated to protein docking, which provides biophysical properties of the system in interactive time, such as energies, forces on atoms or proteins described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec16">5.2</a>, and computes visual audio and haptic feedback, sent to the “rendering” components.</p><p>The “visual rendering” component refers to the <i>Pymol</i> software, which was customized to receive <i>OSC</i> messages, interpret information computed by the “scoring” and “command” components, and to display this information, in addition to classical molecular representations. The visual feedbacks we implemented are described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec21">5.4</a>. The “audio rendering” component is based on <i>MaX/MSP</i> software, which already provides <i>OSC</i> support, as well as sonification of data sent from the “scoring” and “command” components. The implemented audio feedback are described in detail in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec23">5.6</a>. In the “haptic rendering” component, we adapted the <i>Virtuose</i> API for receiving <i>OSC</i> messages and providing haptic feedback of data sent from “scoring” and “command” components. The implemented haptic feedback are described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec23">5.6</a>.</p><p>Each component has its own representation of proteins and of their characteristics, which is well-adapted to the corresponding device constraints and rendering needs. For example, the “visual rendering” component needs information regarding all the atom positions, their chemical type, and a mesh of protein surface of the two proteins, to provide respectively atom and surface representations, while the “haptic rendering” component only needs a mesh of the protein surface of both partner proteins to compute and render rigid body collision.</p><p>Finally the “supervisor” component enables or disables feedback and associated computing (feedback control and computing control messages in see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig7">7</a>) according to a rule-based and context-sensitive system (scene and computing context messages). A description of the multimodal supervisor is presented in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec24">5.7</a>.</p><h3 class="c-article__sub-heading" id="Sec16">The “scoring” component : a physical engine dedicated to protein docking</h3><p>The main constraint we have to overcome in an interactive and multimodal docking environment is to compute and provide biophysical and geometrical parameters real time, while the protein complex constructs itself. Morever, some computation of these parameters such as protein surface interpenetration, electrostatic and van der Waals forces on atoms, must be very efficient to be haptically rendered. As the automatic docking software programs presented in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec4">3.1</a> do not respond to these constraints, we developed a physical engine optimized for the interactive and multimodal protein docking context, which we present in this section. Protein docking methods are essentially based on two sets of criteria: geometric/topological criteria, and biophysical criteria.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec17">Geometry and surface</h4><p>One of the earliest criteria identified in protein–protein interaction is surface topology of the proteins involved. In most known structures of three-dimensional complexes, partners exhibit good surface complementarity (e.g. Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig2">2</a>B). Studies have also shown that the surface of the protein–protein interface generally covers between 1000 and 2500 square Angstroms. This criteria allowed the development of first-generation docking software, based solely on shape recognition (Connolly <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1983a" title="Connolly ML (1983a) Analytical molecular surface calculation. J Appl Crystallogr 16:548–558" href="/article/10.1007/s10055-009-0136-z#ref-CR15" id="ref-link-section-d9562e1606">1983a</a>) (i.e., complementarity of molecular surfaces). This approach is well adapted to rigid protein docking. We used these geometric/topological criteria in our multimodal immersive environment in two ways:
</p><ul class="u-list-style-none">
                      <li>
                        <p>
                                       <i>Surface collision</i>. For each protein, a surface mesh is computed using <i>MSMS</i> before interactive docking occurs (Sanner et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Sanner M, Olson A, Spehner J-C (1996) Reduced surface: an efficient way to compute molecular surfaces. Biopolymers 38:305–320" href="/article/10.1007/s10055-009-0136-z#ref-CR47" id="ref-link-section-d9562e1621">1996</a>). Resolution of this mesh can be set using parameters. Collision detection during interaction then uses the <i>RAPID</i> library (Gottschalk et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Gottschalk S, Lin MC, Manocha D (1996) OBBTree: a hierarchical structure for rapid interference detection. In: Proceedings of the 23rd conference on computer graphics and interactive techniques, vol 30, pp 171–180" href="/article/10.1007/s10055-009-0136-z#ref-CR26" id="ref-link-section-d9562e1627">1996</a>), which allows real-time computation of a list of triangles colliding in the two protein surface meshes during docking. This set of triangles can be used to generate feedback based on triangle normals and on the intersection volume of the two protein surfaces.</p>
                      </li>
                      <li>
                        <p>
                                       <i>Atomic surface complementarity</i>. Atomic surface complementarity is estimated essentially as a calculation of the variance of the inter-atomic distances on the two proteins surfaces. We use this overall atomic surface complementarity score in audio or visual feedback.</p>
                      </li>
                    </ul>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec18">Physicochemical properties and energies</h4><p>However, geometric criteria turned out to be insufficient to predict the structure of a complex. Thus, we had to rely on methods including energy criteria. Protein–protein complexes seem to follow the rule of thumb that the active configuration is that whose level of free energy is lowest (Wang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Wang R, Lu Y, Wang S (2003) Comparative evaluation of 11 scoring functions for molecular docking. J Med Chem 46:2287–2303" href="/article/10.1007/s10055-009-0136-z#ref-CR54" id="ref-link-section-d9562e1650">2003</a>). In order to evaluate free energy between two proteins, we rely on methods of molecular mechanics. To achieve this, atoms are viewed as spheres, and interactions between atoms can be computed using the van der Waals and electrostatic potentials. The free energy for protein–protein interaction can then be approximated by the sum these potentials, which is known as the <i>score</i>. In the context of real-time immersive docking, the choice of equations and methods to evaluate a complex’s energy and score is a crucial issue (Wang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Wang R, Lu Y, Wang S (2003) Comparative evaluation of 11 scoring functions for molecular docking. J Med Chem 46:2287–2303" href="/article/10.1007/s10055-009-0136-z#ref-CR54" id="ref-link-section-d9562e1656">2003</a>).</p><p>
                              <i>Van der Waals interactions</i>. Van der Waals interactions are an empirical approximation of atomic interactions. The van der Waals force, obtained by constructing a gradient of the potential field, is defined by the Lennard-Jones’ potential equation (Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10055-009-0136-z#Equ1">1</a>). In this equation, <i>r</i> is the distance between two atoms, σ the interatomic distance for which the potential becomes zero, and ε the depth of the potential well (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig8">8</a>). ε and σ are determined empirically and depend on what pair of atoms is considered. The van der Waals potential includes an attractive component when atoms are bound, and a repulsive component when atoms are too close to each other. It allows preventing two proteins from penetrating into each other during interactive docking, through calculation of interatomic forces at the protein–protein interface.
</p><div id="Equ1" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ U_{\rm vw}(r) = 4 \epsilon \left[\left({\frac{\sigma}{r}}\right)^{12} - \left({\frac{\sigma}{r}}\right)^{6}\right] $$</span></div><div class="c-article-equation__number">
                    (1)
                </div></div>
                              <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig8_HTML.gif?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig8_HTML.gif" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Lennard-Jones’s potential for van der Waals interactions</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>These forces apply only to very short distances and only concern surface atoms. As computing distances between all pairs of atoms have a quadratic complexity, we apply specific filtering rules to keep only surface atoms and opposite atoms from the each protein (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig9">9</a>). The resultant translational and rotational components of van der Waals’s forces on each atom are calculated and applied to barycenter protein. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig9_HTML.gif?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig9_HTML.gif" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Dynamic and static atom filtering for optimized computing of van der Waals interactions</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>
                              <i>Electrostatic interactions</i> Unlike van der Waals interactions, electrostatic interactions operate when “long” distances (about 10 Å) separate groups of electrically charged atoms. Indeed some amino acids or atoms may present with a positive or negative electric charge, which gives rise to electrostatic phenomena allowing formation of a protein–protein complex. Two approaches have been implemented to compute electrostatic phenomena.</p><p>We consider the interaction between two point charges in vacuum (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig10">10</a>), and we use Coulomb’s law (Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10055-009-0136-z#Equ2">2</a>) with <i>r</i> is the distance between the barycenters of charges <i>q</i>
                              <sub>1</sub> and <i>q</i>
                              <sub>2</sub> of the atoms considered, and ε<sub>0</sub> is the constant of the permittivity of a vacuum. This potential can be translated to force (<i>F</i>
                              <sub>el</sub>) usable for haptic interaction for example (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig10">10</a>). This first approach involves calculating the forces to apply to each electrically charged particle considering only pairs of charged particles. This computation has quadratic complexity, because all distances between atoms must be computed. But it remains relevant in the case of medium-sized proteins, since the number of charged particles in a protein is limited in several models.
</p><div id="Equ2" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ U_{\rm el}(r) = {\frac{1}{4 \pi \epsilon_{0}}} {\frac{q_1 q_2}{r}} $$</span></div><div class="c-article-equation__number">
                    (2)
                </div></div>
                              <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig10_HTML.gif?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig10_HTML.gif" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Resulting forces in the interaction between two point charges, with identical and opposite signs, according to Coulomb’s law. Note: (<span class="mathjax-tex">\({\frac{1}{4 \pi \epsilon_{0}}}\)</span>) is also known as <i>K</i>
                                          <sub>c</sub> or Coulomb’s constant</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>In the second approach (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig11">11</a>, designed for optimization considerations, the overall field of the electrostatic potential of the target protein (receptor) is computed beforehand using <i>APBS</i>
                              <sup><a href="#Fn2"><span class="u-visually-hidden">Footnote </span>2</a></sup> which allows generation of a three-dimensional grid of electrostatic potential, which can be used as a three-dimensional texture. The gradient of the electrostatic potential allows computation of force field vectors for each point of the grid. Atoms from the ligand protein are then “immersed” in this three-dimensional force field surrounding the receptor. This method allows us to compute electrostatic forces for each atom in linear time, depending on the number of charged atoms in the ligand. In both case, we are able to obtain overall electrostatic energy and electrostatic force on each atom. These data are then used for visual, haptic or audio feedbacks.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig11_HTML.gif?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig11_HTML.gif" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Ligand immersion in the electrostatic potential grid of the receptor</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec19">Other criteria</h4><p>In order to reach a finer description of protein–protein interactions, other criteria, based on energy, can be taken into account. To geometric/topological criteria, and biophysical criteria, one can add other criteria which are of utmost importance to protein–protein interaction, such as hydrogen bonds or hydrophobic effects. We only implemented hydrogen bonds in our application.</p><p>
                              <i>Hydrogen bonds</i>. Hydrogen bonds (e.g. Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig1">1</a> in the bottom left corner) are one of the strongest types of interaction in terms of binding energy. On average, there are 5–6 hydrogen bonds per protein–protein interface. In our application, when several atoms (nitrogen and oxygen) on the surface of each protein are close enough, under a distance of 3 Å, and when their chemical environment is adequate, hydrogen bonds are created between these atoms. We used the same methods as we had done for van der Waals interations to filter surface atoms in order to decrease computing complexity of distances between atoms.</p><p>
                              <i>Hotspot at the interface</i>. The number of “hotspots” at the complex interface refers to the list of amino acids present within the current interface region, previously identified using experimental methods as being important actors for protein–protein interaction. Finding hotspots at the protein–protein interface is an important part in judging the quality of a docking complex.</p><h3 class="c-article__sub-heading" id="Sec20">Using haptic device and three-dimensional mouse for bimanual manipulation of proteins</h3><p>In order to manipulate both proteins and attempt to carry out virtual docking, the user may rely on various devices and interaction paradigms (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig12">12</a>). A first paradigm associates the position and orientation of the smaller protein (also called the “ligand”), with the haptic device (6 degrees of freedom, 6DoF), while in the second larger protein (also called “receptor”) orientation of the receptor protein is controlled by a trackball present on the three-dimensional mouse (3 degrees of freedom, 3DoF). To implement this paradigm, the device events are provided by the “command” component and are interpreted by scoring and rendering components (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig7">7</a>). This interaction modality highlights an existing use, since in docking solutions, the receptor protein is static and exploration is concerned with position and orientation of the ligand around the receptor. Another paradigm, more in line with natural interaction, consists in manipulating the position and orientation of the ligand and the receptor respectively with the force-feedback device and with the three-dimensional mouse, respectively. This modality is symmetrical, in terms of manipulation, but not in terms of renderings, since haptic renderings are only available for one of the two proteins.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig12_HTML.jpg?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig12_HTML.jpg" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>A user immersed in the docking application (<i>left</i>). On the right, a sample screen capture following selection of three conformations by the user</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Moreover, we used a specific method to help users manipulate tiny objects with the haptic device. The basic approach was a direct mapping of device motion on a molecule, but the interaction aims to act at the atomic level. Therfore, it would be useful to perform fine tuning operations, especially during rotation movements. Furthermore the physical constraints of the device emerge rapidly during the manipulation. (i.e., in terms of workspace and freedom of movement). Within the <i>CoRSAIRe</i> project, several haptic paradigms are under investigation to better fit to the accuracy required by biologist in such manipulation. For instance, the <i>Bubble</i> (Dominjon et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Dominjon L, Lécuyer A, Burkhardt JM, Andrade-Barroso G, Richir S (2005) The “Bubble” technique: interacting with large virtual environments using haptic devices with limited workspace. In: Proceedings of the world haptics conference (joint Eurohaptics conference and haptics symposium)" href="/article/10.1007/s10055-009-0136-z#ref-CR19" id="ref-link-section-d9562e1927">2005</a>) and <i>Haptic Hybrid Rotation</i> methods (Dominjon et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Dominjon L, Lécuyer A, Burkhardt JM, Richir S (2006) Haptic hybrid rotations: overcoming hardware rotational limitations of force-feedback devices. In: Proceedings of the IEEE international conference on virtual reality (IEEE-VR’05)" href="/article/10.1007/s10055-009-0136-z#ref-CR20" id="ref-link-section-d9562e1933">2006</a>) are centered on the perception of hardware limitations. When the device was closed to its workspace boundaries, authors proposed an elastic force feedback to come back at its neutral position and orientation, and a rate-control of the clutched object. Conversely, when the device is far from these limits, a position control is directly mapped on the clutched object. However, with tiny objects such as molecules and atoms, the rate-control must be computed with a damping effect. We are currently investigating if a model of 6DoF control damped by a SLERP
<sup><a href="#Fn3"><span class="u-visually-hidden">Footnote </span>3</a></sup> function proposed in (Bourdot and Touraine <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Bourdot P, Touraine D (2002) Polyvalent display framework to control virtual navigations by 6DoF tracking. In: Proceedings of the IEEE virtual reality international conference (IEEE-VR’02)" href="/article/10.1007/s10055-009-0136-z#ref-CR11" id="ref-link-section-d9562e1943">2002</a>) may be applied for such accurate haptic manipulations.</p><h3 class="c-article__sub-heading" id="Sec21">Visual rendering</h3><p>In order to be congruent with docking experts’ everyday experience, while not re-developing the existing scope of visual representations of proteins, we chose to reuse one of several existing tools for molecular visualization. Our choice was set on the open source software program <i>Pymol</i> which allows us the use of various visual modalities to view an element essential to the docking task:
</p><ul class="u-list-style-none">
                    <li>
                      <p>
                                    <i>Surface representations</i>. The surface representation may be obtained from various methods depending on the required degree of surface granularity, e.g., solvent-accessible surfaced (Sanner et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Sanner M, Olson A, Spehner J-C (1996) Reduced surface: an efficient way to compute molecular surfaces. Biopolymers 38:305–320" href="/article/10.1007/s10055-009-0136-z#ref-CR47" id="ref-link-section-d9562e1966">1996</a>), or molecular surfaces (Connolly <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1983b" title="Connolly ML (1983b) Solvent-accessible surfaces of proteins and nucleic acids. Science 221:709–713" href="/article/10.1007/s10055-009-0136-z#ref-CR16" id="ref-link-section-d9562e1969">1983b</a>).</p>
                    </li>
                    <li>
                      <p>
                                    <i>Atomic representations</i>. For atomic representations, various CPK-type schemes (Corey and Pauling <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1953" title="Corey RB, Pauling L (1953) Molecular models of amino acids, peptides, and proteins. Rev Sci Instrum 24(8):621–627" href="/article/10.1007/s10055-009-0136-z#ref-CR17" id="ref-link-section-d9562e1981">1953</a>) can be used, e.g., to represent atoms as spheres whose radius equals their van der Waals’s radius; sticks to represent covalent bonds as tubes or lines; ball-and-stick to represent atomic nuclei as spheres and covalent bonds as tubes or lines; and wireframe, to represent atomic bonds as lines.</p>
                    </li>
                    <li>
                      <p>
                                    <i>Secondary structure representations</i>. The secondary structure representations (α helices and β sheets, are described in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig1">1</a>B, b: ribbon type (a uniform tube follows the carbon chain) or cartoon-type (helices and strands are represented as <i>arrows</i>).</p>
                    </li>
                  </ul>
                        <p>Other criteria were also used in choosing this program, including:
</p><ul class="u-list-style-dash">
                    <li>
                      <p>The fact that expert docking experts had already were mastered its use in their everyday working practice;</p>
                    </li>
                    <li>
                      <p>The potential to easily integrate specific data obtained a priori in the literature (e.g. hotspots) or part of the user’s implicit expertise;</p>
                    </li>
                    <li>
                      <p>The Pymol API (in python) allows us a quick integration of new visual or interactive functionalities (under OpenGL);</p>
                    </li>
                    <li>
                      <p>The large number of already available scripts and libraries which were relevant to our application.</p>
                    </li>
                  </ul>
                        <p>From these three main aspects of visual representation (surface, atomic, and secondary), any combination of modalities can be used to visualize a protein. Furthermore, various types of information can be projected onto these representations, e.g., types of atoms and amino acids on the protein surface; electric charges of atoms; hydrophobic properties, degree of flexibility, of sequence conservation or <i>hot spots</i>. We especially used <i>Pymol</i> API, to add our own visual feedback schemes, used to render information computed by the docking engine of docking program:
</p><ul class="u-list-style-none">
                    <li>
                      <p>
                                    <i>Van der Waals and electrostatic energies</i>. During the docking task, the overall energy level is computed interactively. For example, electroctatic energy or van der Waals energy are currently rendered by haptic au audio madalities, but also by text (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig12">12</a>), when needed, or when audio or haptic channels are unavailable.</p>
                    </li>
                    <li>
                      <p>
                                    <i>Hydrogen bonds</i>. Furthermore, in rigid docking, when several atoms (nitrogen and oxygen) located at on the surface of each protein are close together (i.e., under a distance of 3 Å) and when their chemical environment is adequate, a hydrogen bond is created between these atoms. Potential hydrogen bonds are rendered as lines between atoms.</p>
                    </li>
                  </ul>
                        <h3 class="c-article__sub-heading" id="Sec22">Haptic rendering</h3><p>Currently, there are very few molecular docking systems which include large-scale haptic feedback (force/tactile feedback). This is mainly due to the complexity of computing operations behind the physical engines used for molecular dynamics, which makes it difficult to comply with constraints in terms of refresh rates for real time haptic feedback (from 200 to 1 kHz). This led us to consider only hard docking paradigms, with rigid proteins following a lock-and-key or <i>LEGO</i> metaphor. Another difficulty is to render various kinds of information: collisions and physicochemical interactions such as van der Waals forces and electrostatic forces. In order to obtain a consistent haptic feedback, only one type of rendering is provided to the user at a time. However, one should note that at the perceptual level, van der Waals’s force renderings are similar to surface col1ision renderings since it prevents interpenetration.</p><p>Several haptic renderings were implemented computed with optimized scoring methods described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec16">5.2</a>. In all paradigms, we recall that one protein is controlled by the haptic device and the other one by the three-dimensional mouse, which allows user to manipulate their position and orientation of the two proteins at the same time. The haptic-device controlled protein is therefore considered as a big probe with multiple contact points depending on the orientation given by the user.</p><p>
                           <i>Van der Waals and electrostatic interactions</i>. This rendering is used to provide a biophysically relevant haptic feedback. Haptic rendering of physicochemical interactions consists in feeding the haptic device with the resultant forces computed as described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec16">5.2</a>. Forces can be computed and rendered independently or summed up to obtain a total resultant force. Exploration of the receptor by the ligand thus aims at finding stable areas. When the two proteins are in an unstable conformation it renders an unsteady feedback is rendered, thus leading the user to back the ligand towards the surface of the receptor to find a better position and orientation. However the complexity of the force fields induces very irregular directional forces affecting the precision of the manipulation. It appears especially with van der Waals interactions because of the non-linearity in the <i>Lennard-Jones</i> potential used to model these forces.</p><p>
                           <i>Surface collision</i>. Two approaches were explored to render collisions between the both molecules. The first consists in computing a repulsive force. The direction of this force is the opposite of the direction provided and the module is proportional to the number of colliding triangles determined by the <i>RAPID</i> computation as explained in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec16">5.2</a>. This force can also be weighed by a distance or a volume of interpenetration. Therefore the feedback is more relevant, but the complexity of the computation induces lower refresh rates which could lead to lags in feedback. Rather than repulse the two molecules from each other, the second approach, also based on distance computation, aims to prevent collisions locally by modeling contacts points as springs. The method is introduced in Johnson and Willemsen (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Johnson DE, Willemsen P (2003) Six Degree-of-Freedom Haptic rendering of complex polygonal models. In: Proceedings of the 11th symposium on haptic interfaces for virtual environment and teleoperator systems (HAPTICS’03)" href="/article/10.1007/s10055-009-0136-z#ref-CR32" id="ref-link-section-d9562e2107">2003</a>) and provides a fast computation of local minimum distances based on the geometry of the model as well as resulting force and torque. Interestingly the spring model described can be easily adapted to model atomic clashes, such as van der Waals interactions in our case. Instead of using the complex Lennard-Jones potential to render the resulting force, interactions are modeled through this more simple spring model with realistic cutoffs (2.5 Å). As the atomic distances computation is already optimized to take into account only surface and opposite atoms, the refresh rates are sufficient and allows a very precise rendering of the contacts, allowing users to feel holes and bumps at the surface. Hence computation speed and consistent feedback constraints are observed ensuring a biological relevance. Current research aims to determine how the size of the proteins affects computation time. It will also be interesting to compare this atomic clashes-based approach with the geometric one which could provide faster computation.</p><h3 class="c-article__sub-heading" id="Sec23">Audio rendering</h3><p>Sonification is the use of non-speech audio to convey information. Due to the high temporal resolution and wide bandwidth, the use of auditory stimuli seems highly suitable for time-varying parameters (very high temporal definition when compared to other modalities such as video and haptics), concurrent streams (overlapping of multiple audio renderings for various parameters is possible and easily understandable if these are properly designed), and spatial information (lower definition if compared to visual stimuli, but perceptible over the 360° sphere, therefore allowing true three-dimensional rendering). Considering the MBI application, the audio channel seems to be well suited for the rendering of time-varying parameters, whether overall or distributed locally, which would be difficult to visualize (i.e., due to overlapping visual objects, the complex geometrical interface is not visible unless one pries apart the two proteins or alters the ligand display modality).</p><p>A large variety of sonification techniques exist and are used in various applications (Walker and Lane <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Walker BN, Lane DM (1994) Auditory display: sonification, audification, and auditory interfaces. Westview Press, Boulder, CO, USA" href="/article/10.1007/s10055-009-0136-z#ref-CR52" id="ref-link-section-d9562e2121">1994</a>). One sonification technique is referred to as “parameter mapping” (Hermann and Ritter <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Hermann T, Ritter H (1999) Listen to your Data: model-based sonification for data analysis, pp 189–194" href="/article/10.1007/s10055-009-0136-z#ref-CR29" id="ref-link-section-d9562e2124">1999</a>), and it is this technique which has been implemented for the current project. Parameter mapping sonification is based on creating a link between the data to be rendered and the parameters of a synthesizer (or of any other device which generates or plays back sound). In this particular sonification typology, three elements need to be carefully considered (Walker and Lane <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Walker BN, Lane DM (2008) Sonification mappings database on the web. In: Proceedings of the international conference on auditory display (ICAD’01)" href="/article/10.1007/s10055-009-0136-z#ref-CR53" id="ref-link-section-d9562e2127">2008</a>):
</p><ul class="u-list-style-dash">
                    <li>
                      <p>The nature of the mapping: which data dimension (i.e., temperature, pressure, velocity…) is mapped onto, or represented by, each acoustic parameter (i.e. frequency, loudness, tempo…). As an example, for a sonification task the temperature might be linked with the frequency of a sound, therefore as the temperature increases, the frequency of the corresponding sonification increases.</p>
                    </li>
                    <li>
                      <p>Mapping polarity: in the event of an increase in the sonified data, the sonification parameter can decrease or increase. In the case of temperature-frequency mapping, it is common to use an increasing-TO-increasing (up-up) polarity. An alternate example could be the size of an object being mapped to frequency: the polarity would likely be increasing-TO-decreasing such that large objects are linked to low sounds and vice versa.</p>
                    </li>
                    <li>
                      <p>Mapping scale: in response to a specific increase of the data to be sonified, how much should the sonification parameter increase or decrease. One must take into account the possible range of the data, and the percentage of the usable audible range which is to be exploited. Human hearing is more sensitive to small frequency changes at low frequencies, rather than higher, following an exponential scale. In the case of temperature–frequency mapping the temperature could be linked to the frequency exponentially.</p>
                    </li>
                  </ul>
                        <p>One study was recently performed within this research project regarding the use of sound spatialization, examining the effect of sound spatialization on a specific sonification and sound exploration task (Katz et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Katz FGB, Rio E, Picinali L, Warusfel O (2008) The effect of spatialization in a data sonification exploration tasks. In: Proceedings of the international conference on auditory display (ICAD’08)" href="/article/10.1007/s10055-009-0136-z#ref-CR33" id="ref-link-section-d9562e2154">2008</a>). Subjects were asked to virtually navigate, using a pointing and tracking device, a two dimensional function mapped onto the surface of a sphere surrounding the user. The data function was sonified with a modified click/beep sound and the task was simply to find the maximum of the function, the point with the highest frequency beep. The experiment was repeated with and without the use of sound spatialization techniques.</p><p>In our application, sound spatialization is used in two different ways: first, for local parameters the sonification is spatialized in the specific position where the parameter is calculated, in accordance with visual or haptic rendering, to provide additional information in the protein coordinate system (i.e., if the task is to sonify the collision between two different atoms on the two proteins, sonification is spatialised at the position of the collision). Then, multiple concurrent sonifications can be spatially distributed in order to give a better intelligibility of the sonifications themselves [i.e., stream segregation, selective attention in auditory perception, cocktail party effect (Moore <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Moore BCJ (2003) An introduction to the psychology of hearing" href="/article/10.1007/s10055-009-0136-z#ref-CR40" id="ref-link-section-d9562e2160">2003</a>)]. In 2007, LIMSI and IRCAM set up a test for the validation of different sonification methods for object manipulation. Within this test, the subject was asked to change the orientation of a simplified three-dimensional chemical compound in order to be the same as that of a given reference. To do this, the subject used an orientation tracking device. Three approaches for data parameter sonification were tested to improve the speed and accuracy of this manipulation: manipulation speed, angular distance from the reference configuration, and guidance towards the reference position (Arboun <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Arboun A (2007) Evaluation des métaphores de sonification. Master thesis, Ecole Nationale Supérieure Louis Lumière, Paris, France" href="/article/10.1007/s10055-009-0136-z#ref-CR6" id="ref-link-section-d9562e2163">2007</a>).</p><p>Regarding the protein–protein docking task, the following parameters have been selected for the sonification:
</p><ul class="u-list-style-none">
                    <li>
                      <p>
                                    <i>Surface complementarity</i>. Atomic surface complementarity is estimated essentially as a calculation of the variance of the inter-atomic distances on the two proteins surfaces.</p>
                    </li>
                    <li>
                      <p>
                                    <i>Surface collisions</i>. This parameter represents the number of collisions computed between the two surfaces (see Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec16">5.2</a>).</p>
                    </li>
                    <li>
                      <p>
                                    <i>Electrostatic energy of the complex</i>. This parameter is computed from electrostatic interaction energies between charged particles (see Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec16">5.2</a>).</p>
                    </li>
                    <li>
                      <p>
                                    <i>Van der Waals energy of the complex</i>. This parameter is computed from van der Waals interaction energies between particles (see Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec16">5.2</a>).</p>
                    </li>
                    <li>
                      <p>
                                    <i>Hotspot at the interface</i>. The number of “hotspots” at the complex interface refers to the list of amino acids present within the current interface region, previously identified using experimental methods as being important actors for protein–protein interaction. Finding hotspots at the protein–protein interface is an important part in judging the quality of solutions.</p>
                    </li>
                  </ul>
                        <p>In the current study, different metaphors have been used for the sonification of the various parameters furnished by the main platform, individually and/or at the same time. Currently, the majority of supplied parameters are global, rather than local. The modules that follow have been specifically designed and developed for this application:
</p><ul class="u-list-style-none">
                    <li>
                      <p>
                                    <i>Surface complementarity</i>. This parameter is used to control the variance of a randomly applied pitch to different grains of a granular synthesis process. Granular synthesis has been applied using a spoken word as audio sample (for this particular application, the french word “complementaire” has been recorded and used), repeated cyclically within the granular engine. In this instance, the word is unintelligible if the geometrical complementarity parameter is low, becoming more intelligible as the parameter increases. The rendered audio stream is doubled and associated to each of the two proteins, in preparation for further processing.</p>
                    </li>
                    <li>
                      <p>
                                    <i>Hotspot at the interface</i>. In a second stage, the two audio streams are processed with a low-pass filter with the cutoff frequency controlled by the percentage of proteins hotspots which are situated on the interface region. If none of the hotspots are present on the interface the low-pass filter frequency is set at 200 Hz, making the sound nearly inaudible. The cutoff frequency of the filter increases with the number hotspots present at the interface, making the sound clearer and brighter until, in the optimal position, the frequency filtering is completely deactivated. The two audio streams are rendered stereophonically, associating the left and right channels respectively to the first and second protein.</p>
                    </li>
                    <li>
                      <p>
                                    <i>Surface collisions</i>. The employed method for atomic collision sonification uses a modulation of the phase of a sinusoidal wave whose parameters (carrier and modulator) are controlled by the global number of collisions. Starting with a continuous 400 Hz sinusoidal wave modulated by a 1 Hz signal, the frequency of the modulation increases as the global collision score gets higher, and with it the number of modulating waves, going from 1 to 4, when the two proteins are completely superposed. A second method developed is based on the individual association of every collision with a broadband noise processed with subtractive synthesis (the result is similar to wind noise). The noise is specifically filtered for every collision, adding a controlled randomization of the filtering parameters, so that every “noise generator” sounds different from the others, and spatialized according to its proper position in space. Both of these sonification methods are based on the principle that the signal produced becomes more and more annoying as the number of collisions increases, encouraging the user to change the position and distance of the proteins in order to reduce the number of collisions, and as such stopping the annoying sound. Regarding the second sonification method, sound spatialization helps the listener to localize the part of the protein surface where the collision is taking place, and to guide him/her towards an orientation of the protein for which no collisions are present.</p>
                    </li>
                    <li>
                      <p>
                                    <i>Electrostatic energy of the complex</i>. Electrostatic energy sonification is performed through the alternation of two sounds, generated using additive synthesis, whose pitch and timbre vary as a function of the global value of this specific force (scalar value). The electrostatic force value is highly variable, and there is not a direct linear relationship between this parameter and a quality judgement of it being good or bad for the docking condition. The link between the parameter and the quality of its specific value has therefore been traced in a two dimensional Cartesian diagram, with the value of the parameter on the <i>x</i>-axis, and the quality (being good or bad) on the <i>y</i>-axis. At a given electrostatic force value, the correspondent value on the <i>y</i>-axis has been sonified with the method previously described. For good values, the frequencies of the two sounds are coincident, and their spectra are perfectly harmonic, while as the value worsens, the two frequencies become more distant, and the spectra more inharmonic.</p>
                    </li>
                    <li>
                      <p>
                                    <i>Van der Waals energy of the complex</i>. The sonification of the van der Waals energy is based on the principle of the beatings between two sound frequentially close. As with the electrostatic force, for the van der Waals force value there is not a linear relationship between the parameter and a quality judgement (being good or bad). A mapping similar to the one described for the previous sonification method (electrostatic force) has been employed, with the Y axis value being sonified. Two intermittent sinusoidal pulses are played back simultaneously: if the quality value for the van der Waals force is good, then the two waves have the same frequency, while as it becomes worse, one of the two pulses reduces in frequency by up to 20 Hz from the other. This processing results in the creation of beatings between the two frequencies. If there are no beatings, then the score can be considered to be good. In contrast, if the beatings becomes more frequent (more rapid beat frequency indicates greater frequency separation between the two pulses) the score is becoming worse.</p>
                    </li>
                  </ul>
                        <h3 class="c-article__sub-heading" id="Sec24">Multimodal supervisor</h3><p>As we have seen, part of the choices regarding multimodal allocation is carried out statically, before execution of the docking application, based on ergonomic recommendations issued from the task analysis. However, generation of renderings must be controlled throughout the application. These must depend on characteristics of the data used, but also on the context of interaction. This context is defined by the user, the real-world environment, virtual environment, and available devices.</p><p>To manage multimodal renderings, we modeled and developed a supervision process (Bouyer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Bouyer G (2007) Rendu multimodal en Réalité Virtuelle: Supervision des interactions au service de la tâche. Ph.d. thesis, Université Paris XI, France" href="/article/10.1007/s10055-009-0136-z#ref-CR12" id="ref-link-section-d9562e2298">2007</a>) (Bouyer and Bourdot <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Bouyer G, Bourdot P (2008) Supervision of 3D multimodal rendering for protein-protein virtual docking. In: Proceedings of the 13th Eurographics symposium on virtual environments (EGVE’08), pp 49–56" href="/article/10.1007/s10055-009-0136-z#ref-CR13" id="ref-link-section-d9562e2301">2008</a>). This process was developed in a generic way, keeping in mind the need for it to adapt to various applications, before using it for a molecular docking application.</p><p>This supervision relies on four main elements (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0136-z#Fig13">13</a>):
</p><ul class="u-list-style-none">
                    <li>
                      <p>
                                    <i>The real world</i>. The docking expert commands the system using the three-dimensional mouse and the haptic device and perceives multimodal renderings via screens, loudspeakers and the same haptic device. He/she is also tracked using various sensors (located on his/her head, in his/her hand, etc.)</p>
                    </li>
                    <li>
                      <p>
                                    <i>The application</i>. We model the docking application as three related elements. The Virtual Environment (VE) contains a virtual representation of the user as well as of the whole dataset involved in the interaction: proteins, scores, numerical variables, etc. The application also rests on hardware and software architectures. Input and output devices are managed by drivers and renderings are generated by specific engines (for graphics, audio and haptic rendering). Finally, the interaction manager interprets user commands, asks the supervisor to control rendering processes and orders the artchitecture to display the rendering as agreed upon.</p>
                    </li>
                    <li>
                      <p>
                                    <i>The supervisor</i>. The supervisor is in charge of controlling multimodal rendering. To do this, it relies on a knowledge base containing rules for multimodal allocation (see ergonomic recommendations) as well as a rule base for decision making to determine its behavior and a contextual base describing elements liable to impact renderings.</p>
                    </li>
                    <li>
                      <p>
                                    <i>The observer/interpreter</i>. It allows communication between the docking application and the supervisor, by acting as a translator for all the information they exchange. Its second role is to supervise in real time the running of the application in real time to isolate elements of the context and dynamically share them put them with the supervisor. Contextual elements might come from the real world (e.g., tracking data) and concern for example the user’s position and his movements, or else from the VE and concern the spatial organization of the scene (relative positions of both proteins, etc.). Knowledge of the application’s rendering abilities is particularly useful: what are the media and modalities available in the software? - what are the respective load of all sensory channels? - etc.</p>
                    </li>
                  </ul>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-13"><figure><figcaption><b id="Fig13" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 13</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/13" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig13_HTML.gif?as=webp"></source><img aria-describedby="figure-13-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0136-z/MediaObjects/10055_2009_136_Fig13_HTML.gif" alt="figure13" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-13-desc"><p>General architecture for multimodal supervision</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0136-z/figures/13" data-track-dest="link:Figure13 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>More specifically, the supervision process consists in successive exchanges of messages between the following four actors:
</p><ul class="u-list-style-dash">
                    <li>
                      <p>In simplest cases, the user tells the system that he/she wishes to interact with data from the VE (mostly with proteins). The application may also set off an interaction, e.g., render a score for electrostatic complementarity when a parameter exceeds a threshold, or navigate following detection of an interesting hotspot.</p>
                    </li>
                    <li>
                      <p>The interaction manager interprets this command and makes a request to the supervisor so it can determine the most relevant modalities for display. If designers have preset a specific rendering scheme (e.g., following ergonomic recommendations) or if users have explicitly defined one in their commands, this scheme is appended to the request.</p>
                    </li>
                    <li>
                      <p>The request is translated and propagated by the interpreter, to the supervisor. If no rendering is proposed, the supervisor must specify it completely. If the request is accompanied by proposals, the supervisor will have to validate, reject, or further specify them. The supervisor’s decision is a logical process based on static knowledge, dynamic knowledge, and rules applying to this knowledge. First, static knowledge contains the semantic elements of multimodal rendering. They involve choices for information allocation to the various display modalities. Next, dynamic knowledge refers to the contextual elements provided by the observer. Finally, a number of logic rules determine supervisor behavior based on predicates formed by this knowledge.</p>
                    </li>
                    <li>
                      <p>The result of the request is processed by the interaction manager. Renderings are then generated by the appropriate engines and transmitted to the user through relevant media. All contextual information is updated, both in terms of application data and of the supervisor’s contextual database.</p>
                    </li>
                  </ul>
                        </div></div></section><section aria-labelledby="Sec25"><div class="c-article-section" id="Sec25-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec25">Evaluations</h2><div class="c-article-section__content" id="Sec25-content"><p>From the human factors point of view, evaluation of the <i>CoRSAIRe</i> prototype for molecular docking is being carried out through an iterative approach of design and evaluation, following the projects a user centered design methodology, which characterizes the project as a whole. The two main goals of ongoing evaluations are as follows:
</p><ul class="u-list-style-dash">
                  <li>
                    <p>To evaluate the virtual environment in terms of usability and usefulness, for the target population of scientists, as well as the docking task, and the context in which these users carry it out. However, we should point out that the goal here is not so much to evaluate an operational system as to evaluate the relevance of a concept for the design of work tools.</p>
                  </li>
                  <li>
                    <p>To design and evaluate an interface, notably in terms of interaction techniques and multimodal representation of information.</p>
                  </li>
                </ul>
                     <p>These two goals require very different methods and situations in terms of distance and degree of complexity between, on the one hand, the devices and users subjected to evaluation, and on the other hand, situations of use involving “real” users in a “real-world occupational context on the other hand”. Evaluating a prototype based on its use involves using realistic scenarios (i.e., those involving real data and real molecules deemed representative of real docking problems) and also calling upon representative users. Conversely, when deciding upon choices of modal allocation and evaluating their intelligibility, it is not always compulsory to rely on task experts.</p><p>So far, the evaluations we carried out have been formative, i.e., aims to evaluate throughout product development, the technical and ergonomic quality of prototypes at a given moment, in order to provide designers with feedback and realign design choices as they were made. At the end of the project, the approach used is then said to be summative, i.e., aims to assess its quality and properties with reference to external norms and performance criteria. These studies are underway.</p></div></div></section><section aria-labelledby="Sec26"><div class="c-article-section" id="Sec26-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec26">Conclusion</h2><div class="c-article-section__content" id="Sec26-content"><p>In this document, we presented our immersive multimodal environment and application to assist scientists in their study of protein–protein docking phenomena. The essential contribution of this work consists in designing a new methodology for protein–protein docking (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec13">4.3</a>) taking into account some advanced interaction and rendering features offering by a Virtual Reality environment. With respect to other work on docking described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec4">3.1</a>, we essentially addressed the problems relating to multisensory rendering during the interactive docking task, we designed new haptic feedback (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec22">5.5</a>) and audio rendering schemes (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec23">5.6</a>), specifically dedicated to protein docking, We also designed and developed our own physical engine, dedicated to protein docking, optimized to take into account the constraints of the interactive context, and well-adapted to audio feedback and haptic interactions. Furthermore, we applied a new method described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec24">5.7</a> to supervise the visual, audio and haptic renderings in our immersive multimodal environment dedicated to protein docking. Moreover, to design this new methodology for protein–protein docking and implementing its concepts within our dedicated environment, we followed an iterative user centered design approach. A significant part of our work was to carry out an ergonomic study presented in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0136-z#Sec7">4</a>, of existing practices of domain experts in the context of their everyday work. Specifically, this preliminary study mainly aimed to formalize user needs and tasks in order to propose a limited set of design principles and a tool which was adapted to existing working practices, while leaving some tool for them to evolve. This study mainly aimed to take into account user needs, to propose a set of design principles, and to integrate user practices within our immersive and multimodal environment.</p><p>Our aim was to design an explicitly innovative working environment, yielding new possibilities for use and work practices. Our initial study showed in particular that user participation in the docking task was very limited, since it only involved configuring docking scripts and choosing one result amongst the computer-generated solutions to the studied problem. Indeed classic approaches to docking provide large numbers of complex configuration based on three-dimensional data describing partner proteins. These algorithms take a long time to produce results, since they test all possible geometric configurations to dock the two proteins. These configurations are then filtered according to energy and physicochemical criteria. Finally, the scientist selects, in this set of results, a smaller set of possible solutions that can be tested against each other experimentally. Relying on user expertise before applying automatic docking algorithms in a multimodal and immersive context allows the user to use natural abilities for the detection of surface complementarity, as well as prior implicit or literature based knowledge regarding for example the nature of the protein–protein interface, what hotspots are present, etc. We think this process allows significant reduction of the number of configurations to be tested by algorithms used afterwards, and we are currently in intensive evaluation stage to validate this hypothesis, and to evaluate the efficiency of each designed modality for rendering the biophysical parameters during the interactive docking task.</p><p>Our approach could be reused in the design of other docking interfaces, integrating factors such as protein flexibility, based on the premise that many docking problems involve flexible partners. Later work will focus on identifying a typology of docking tasks upon which to base a scope of intent. Furthermore, this work should also focus on defining future situations of use of such tools. Indeed, our interactions with future users identified several possible avenues for the use of docking tools, e.g., teaching, scientific discovery, collaborative work, etc. All of these situations involve various kinds of constraints and tasks.</p><p>The novelty of our approach is that it strives to ensure continuous user participation in the process through direct manipulation of the protein models. In proposing a novel approach in which users are involved both upstream and downstream from automatic docking procedures in a multimodal virtual environment, we hope to maximize the use of his/her expertise. This echoes directly to (Magnani <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Magnani L (2005) An abductive theory of scientific reasoning. Semiotica 153(1–4):261–286" href="/article/10.1007/s10055-009-0136-z#ref-CR39" id="ref-link-section-d9562e2467">2005</a>) discussion of assisting scientific reasoning through the use of “epistemic mediators”, i.e., external objects which “give rise to new signs, new chances for interpretations, and new interpretations”. In particular, the use of interactive mediators in a multimodal framework would allow widening the perceptual bandwidth (Turk and Robertson <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Turk M, Robertson G (2000) Perceptual user interfaces (introduction). Commun ACM 43(3):32–34" href="/article/10.1007/s10055-009-0136-z#ref-CR50" id="ref-link-section-d9562e2470">2000</a>), multiplying the sources of available information, i.e., topological, electrochemical, a priori knowledge of the protein–protein interface), thereby reducing the risk of false positives which plagues current docking tools.</p></div></div></section>
                        
                    

                    <section aria-labelledby="notes"><div class="c-article-section" id="notes-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="notes">Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1"><span class="c-article-footnote--listed__index">1.</span><div class="c-article-footnote--listed__content"><p>Acronym of Window, Icon, Menu, and Pointing device.</p></div></li><li class="c-article-footnote--listed__item" id="Fn2"><span class="c-article-footnote--listed__index">2.</span><div class="c-article-footnote--listed__content"><p>
                                    <i>Adaptative Poisson-Boltzmann Solver</i> (Baker et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Baker NA, Sept D, Joseph S, Holst MJ, McCammon JA (2001) Electrostatics of nanosystems: application to microtubules and the ribosome. Proc Natl Acad Sci 98: 10037–10041" href="/article/10.1007/s10055-009-0136-z#ref-CR7" id="ref-link-section-d9562e1835">2001</a>).</p></div></li><li class="c-article-footnote--listed__item" id="Fn3"><span class="c-article-footnote--listed__index">3.</span><div class="c-article-footnote--listed__content"><p>SLERP is shorthand for spherical linear interpolation used with quaternion representation of 3D rotation.</p></div></li></ol></div></div></section><section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Anastassova M, Mégard C, Burkhardt JM (2007) Prototype evaluation and user-needs analysis in the early design " /><p class="c-article-references__text" id="ref-CR1">Anastassova M, Mégard C, Burkhardt JM (2007) Prototype evaluation and user-needs analysis in the early design of emerging technologies. In: Procedings of the 12th international conference on human-computer interaction (HCI’07)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Anderson, Z. Weng, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Anderson A, Weng Z (1999) VRDD: applying virtual reality visualization to protein docking and design. J Mol Gr" /><p class="c-article-references__text" id="ref-CR2">Anderson A, Weng Z (1999) VRDD: applying virtual reality visualization to protein docking and design. J Mol Graphi Model 17(3):180–186</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS1093-3263%2899%2900029-7" aria-label="View reference 2">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=VRDD%3A%20applying%20virtual%20reality%20visualization%20to%20protein%20docking%20and%20design&amp;journal=J%20Mol%20Graphi%20Model&amp;volume=17&amp;issue=3&amp;pages=180-186&amp;publication_year=1999&amp;author=Anderson%2CA&amp;author=Weng%2CZ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="André E (2000) The generation of multimedia presentations. In: Handbook of natural language processing, pp 305" /><p class="c-article-references__text" id="ref-CR3">André E (2000) The generation of multimedia presentations. In: Handbook of natural language processing, pp 305–327</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="N. Andrusier, R. Nussinov, HJ. Wolfson, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Andrusier N, Nussinov R, Wolfson HJ (2007) FireDock: fast interaction refinement in molecular docking. Protein" /><p class="c-article-references__text" id="ref-CR4">Andrusier N, Nussinov R, Wolfson HJ (2007) FireDock: fast interaction refinement in molecular docking. Proteins 69(1):139–59</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2Fprot.21495" aria-label="View reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=FireDock%3A%20fast%20interaction%20refinement%20in%20molecular%20docking&amp;journal=Proteins&amp;volume=69&amp;issue=1&amp;pages=139-59&amp;publication_year=2007&amp;author=Andrusier%2CN&amp;author=Nussinov%2CR&amp;author=Wolfson%2CHJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Annett J (2003) Hierarchical task analysis. In: Handbook of cognitive task design, pp. 17–35" /><p class="c-article-references__text" id="ref-CR5">Annett J (2003) Hierarchical task analysis. In: Handbook of cognitive task design, pp. 17–35</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Arboun A (2007) Evaluation des métaphores de sonification. Master thesis, Ecole Nationale Supérieure Louis Lum" /><p class="c-article-references__text" id="ref-CR6">Arboun A (2007) Evaluation des métaphores de sonification. Master thesis, Ecole Nationale Supérieure Louis Lumière, Paris, France</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="NA. Baker, D. Sept, S. Joseph, MJ. Holst, JA. McCammon, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Baker NA, Sept D, Joseph S, Holst MJ, McCammon JA (2001) Electrostatics of nanosystems: application to microtu" /><p class="c-article-references__text" id="ref-CR7">Baker NA, Sept D, Joseph S, Holst MJ, McCammon JA (2001) Electrostatics of nanosystems: application to microtubules and the ribosome. Proc Natl Acad Sci 98: 10037–10041</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Electrostatics%20of%20nanosystems%3A%20application%20to%20microtubules%20and%20the%20ribosome&amp;journal=Proc%20Natl%20Acad%20Sci&amp;volume=98&amp;pages=10037-10041&amp;publication_year=2001&amp;author=Baker%2CNA&amp;author=Sept%2CD&amp;author=Joseph%2CS&amp;author=Holst%2CMJ&amp;author=McCammon%2CJA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Barass S, Zehner B (2000) Responsive sonification of well-logs. In: Proceedings of the international conferenc" /><p class="c-article-references__text" id="ref-CR8">Barass S, Zehner B (2000) Responsive sonification of well-logs. In: Proceedings of the international conference on auditory display (ICAD’00)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HM. Berman, J. Westbrook, Z. Feng, G. Gilliland, T. Bhat, H. Weissig, I. Shindyalov, P. Bourne, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Berman HM, Westbrook J, Feng Z, Gilliland G, Bhat T, Weissig H, Shindyalov I, Bourne P (2000) The protein data" /><p class="c-article-references__text" id="ref-CR9">Berman HM, Westbrook J, Feng Z, Gilliland G, Bhat T, Weissig H, Shindyalov I, Bourne P (2000) The protein data bank. Nucleic Acids Res 1(28):235–242</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1093%2Fnar%2F28.1.235" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Protein%20Data%20Bank&amp;journal=Nucleic%20Acids%20Res&amp;volume=1&amp;issue=28&amp;pages=235-242&amp;publication_year=2000&amp;author=Berman%2CHM&amp;author=Westbrook%2CJ&amp;author=Feng%2CZ&amp;author=Gilliland%2CG&amp;author=Bhat%2CT&amp;author=Weissig%2CH&amp;author=Shindyalov%2CI&amp;author=Bourne%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="KW. Borrelli, A. Vitalis, R. Raul Alcantara, V. Guallar, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Borrelli KW, Vitalis A, Raul Alcantara R, Guallar V (2005) PELE: protein energy landscape exploration. A novel" /><p class="c-article-references__text" id="ref-CR10">Borrelli KW, Vitalis A, Raul Alcantara R, Guallar V (2005) PELE: protein energy landscape exploration. A novel Monte Carlo based technique. J Chem Theory Comput 6(1):1304–1311</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1021%2Fct0501811" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=PELE%3A%20protein%20energy%20landscape%20exploration.%20A%20novel%20Monte%20Carlo%20based%20technique&amp;journal=J%20Chem%20Theory%20Comput&amp;volume=6&amp;issue=1&amp;pages=1304-1311&amp;publication_year=2005&amp;author=Borrelli%2CKW&amp;author=Vitalis%2CA&amp;author=Raul%20Alcantara%2CR&amp;author=Guallar%2CV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bourdot P, Touraine D (2002) Polyvalent display framework to control virtual navigations by 6DoF tracking. In:" /><p class="c-article-references__text" id="ref-CR11">Bourdot P, Touraine D (2002) Polyvalent display framework to control virtual navigations by 6DoF tracking. In: Proceedings of the IEEE virtual reality international conference (IEEE-VR’02)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bouyer G (2007) Rendu multimodal en Réalité Virtuelle: Supervision des interactions au service de la tâche. Ph" /><p class="c-article-references__text" id="ref-CR12">Bouyer G (2007) Rendu multimodal en Réalité Virtuelle: Supervision des interactions au service de la tâche. Ph.d. thesis, Université Paris XI, France</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bouyer G, Bourdot P (2008) Supervision of 3D multimodal rendering for protein-protein virtual docking. In: Pro" /><p class="c-article-references__text" id="ref-CR13">Bouyer G, Bourdot P (2008) Supervision of 3D multimodal rendering for protein-protein virtual docking. In: Proceedings of the 13th Eurographics symposium on virtual environments (EGVE’08), pp 49–56</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Brooks FP Jr, Ouh-Young M , Batter JJ, Jerome Kilpatrick P (1990) Project GROPE: Haptic displays for scientifi" /><p class="c-article-references__text" id="ref-CR23">Brooks FP Jr, Ouh-Young M , Batter JJ, Jerome Kilpatrick P (1990) Project GROPE: Haptic displays for scientific visualization. In: Proceedings of the 17th conference on computer graphics and interactive techniques, pp 177–185</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SR. Comeau, WD. Gatchell, S. Vajda, CJ. Camacho, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Comeau SR, Gatchell WD, Vajda S, Camacho CJ (2004) ClusPro: an automated docking and discrimination method for" /><p class="c-article-references__text" id="ref-CR14">Comeau SR, Gatchell WD, Vajda S, Camacho CJ (2004) ClusPro: an automated docking and discrimination method for the prediction of protein complexes. Bioinformatics 20(1):45–50</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1093%2Fbioinformatics%2Fbtg371" aria-label="View reference 15">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=ClusPro%3A%20an%20automated%20docking%20and%20discrimination%20method%20for%20the%20prediction%20of%20protein%20complexes&amp;journal=Bioinformatics&amp;volume=20&amp;issue=1&amp;pages=45-50&amp;publication_year=2004&amp;author=Comeau%2CSR&amp;author=Gatchell%2CWD&amp;author=Vajda%2CS&amp;author=Camacho%2CCJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="ML. Connolly, " /><meta itemprop="datePublished" content="1983" /><meta itemprop="headline" content="Connolly ML (1983a) Analytical molecular surface calculation. J Appl Crystallogr 16:548–558" /><p class="c-article-references__text" id="ref-CR15">Connolly ML (1983a) Analytical molecular surface calculation. J Appl Crystallogr 16:548–558</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1107%2FS0021889883010985" aria-label="View reference 16">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Analytical%20molecular%20surface%20calculation&amp;journal=J%20Appl%20Crystallogr&amp;volume=16&amp;pages=548-558&amp;publication_year=1983&amp;author=Connolly%2CML">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="ML. Connolly, " /><meta itemprop="datePublished" content="1983" /><meta itemprop="headline" content="Connolly ML (1983b) Solvent-accessible surfaces of proteins and nucleic acids. Science 221:709–713" /><p class="c-article-references__text" id="ref-CR16">Connolly ML (1983b) Solvent-accessible surfaces of proteins and nucleic acids. Science 221:709–713</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1126%2Fscience.6879170" aria-label="View reference 17">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Solvent-accessible%20surfaces%20of%20proteins%20and%20nucleic%20acids&amp;journal=Science&amp;volume=221&amp;pages=709-713&amp;publication_year=1983&amp;author=Connolly%2CML">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RB. Corey, L. Pauling, " /><meta itemprop="datePublished" content="1953" /><meta itemprop="headline" content="Corey RB, Pauling L (1953) Molecular models of amino acids, peptides, and proteins. Rev Sci Instrum 24(8):621–" /><p class="c-article-references__text" id="ref-CR17">Corey RB, Pauling L (1953) Molecular models of amino acids, peptides, and proteins. Rev Sci Instrum 24(8):621–627</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1063%2F1.1770803" aria-label="View reference 18">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Molecular%20models%20of%20amino%20acids%2C%20peptides%2C%20and%20proteins&amp;journal=Rev%20Sci%20Instrum&amp;volume=24&amp;issue=8&amp;pages=621-627&amp;publication_year=1953&amp;author=Corey%2CRB&amp;author=Pauling%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Cruz-Neira, DJ. Sandin, TA. DeFanti, RV. Kenyon, JC. Hart, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Cruz-Neira C, Sandin DJ, DeFanti TA, Kenyon RV, Hart JC (1992) The CAVE: audio visual experience automatic vir" /><p class="c-article-references__text" id="ref-CR18">Cruz-Neira C, Sandin DJ, DeFanti TA, Kenyon RV, Hart JC (1992) The CAVE: audio visual experience automatic virtual environment. ACM SIGGRAPH Comput Graph 35(6):64–72</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20CAVE%3A%20audio%20visual%20experience%20automatic%20virtual%20environment&amp;journal=ACM%20SIGGRAPH%20Comput%20Graph&amp;volume=35&amp;issue=6&amp;pages=64-72&amp;publication_year=1992&amp;author=Cruz-Neira%2CC&amp;author=Sandin%2CDJ&amp;author=DeFanti%2CTA&amp;author=Kenyon%2CRV&amp;author=Hart%2CJC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dominjon L, Lécuyer A, Burkhardt JM, Andrade-Barroso G, Richir S (2005) The “Bubble” technique: interacting wi" /><p class="c-article-references__text" id="ref-CR19">Dominjon L, Lécuyer A, Burkhardt JM, Andrade-Barroso G, Richir S (2005) The “Bubble” technique: interacting with large virtual environments using haptic devices with limited workspace. In: Proceedings of the world haptics conference (joint Eurohaptics conference and haptics symposium)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dominjon L, Lécuyer A, Burkhardt JM, Richir S (2006) Haptic hybrid rotations: overcoming hardware rotational l" /><p class="c-article-references__text" id="ref-CR20">Dominjon L, Lécuyer A, Burkhardt JM, Richir S (2006) Haptic hybrid rotations: overcoming hardware rotational limitations of force-feedback devices. In: Proceedings of the IEEE international conference on virtual reality (IEEE-VR’05)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ferey N, Delande O, Grasseau G, Baaden M (2008) A VR framework for interacting with molecular simulations. In:" /><p class="c-article-references__text" id="ref-CR21">Ferey N, Delande O, Grasseau G, Baaden M (2008) A VR framework for interacting with molecular simulations. In: Proceedings of the international conference on virtual reality sofware and technologies (ACM-VRST’08)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fernandez-Recio J, Totrov M, Abagyan R (2003) ICM-DISCO docking by global energy optimization with fully flexi" /><p class="c-article-references__text" id="ref-CR22">Fernandez-Recio J, Totrov M, Abagyan R (2003) ICM-DISCO docking by global energy optimization with fully flexible Side-Chains, vol 1, issue 52. Bradford Books/MIT Press, Cambridge, MA, pp 113–117</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MA. Garcia-Ruiz, JR. Guttierez-Pulido, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Garcia-Ruiz MA, Guttierez-Pulido JR (2006) An overview of auditory display to assist comprehension of molecula" /><p class="c-article-references__text" id="ref-CR24">Garcia-Ruiz MA, Guttierez-Pulido JR (2006) An overview of auditory display to assist comprehension of molecular information. Interact Comput 18(4):853–868</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.intcom.2005.12.001" aria-label="View reference 24">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20overview%20of%20auditory%20display%20to%20assist%20comprehension%20of%20molecular%20information&amp;journal=Interact%20Comput&amp;volume=18&amp;issue=4&amp;pages=853-868&amp;publication_year=2006&amp;author=Garcia-Ruiz%2CMA&amp;author=Guttierez-Pulido%2CJR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ghiglione R, Landré A, Bromberg M, Molette P (1998) L’analyse automatique des contenus" /><p class="c-article-references__text" id="ref-CR25">Ghiglione R, Landré A, Bromberg M, Molette P (1998) L’analyse automatique des contenus</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gottschalk S, Lin MC, Manocha D (1996) OBBTree: a hierarchical structure for rapid interference detection. In:" /><p class="c-article-references__text" id="ref-CR26">Gottschalk S, Lin MC, Manocha D (1996) OBBTree: a hierarchical structure for rapid interference detection. In: Proceedings of the 23rd conference on computer graphics and interactive techniques, vol 30, pp 171–180</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Grosdidier A (2007) Conception d’un logiciel de docking et applications dans la recherche de nouvelles molécul" /><p class="c-article-references__text" id="ref-CR27">Grosdidier A (2007) Conception d’un logiciel de docking et applications dans la recherche de nouvelles molécules actives. PhD thesis, Université Joseph Fourier Grenoble 1, France</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="TN. Hart, RJ. Read, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Hart TN, Read RJ (2004) A multiple-start Monte Carlo docking method. Proteins Struct Funct Genet 13(3):206–222" /><p class="c-article-references__text" id="ref-CR28">Hart TN, Read RJ (2004) A multiple-start Monte Carlo docking method. Proteins Struct Funct Genet 13(3):206–222</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20multiple-start%20Monte%20Carlo%20docking%20method&amp;journal=Proteins%20Struct%20Funct%20Genet&amp;volume=13&amp;issue=3&amp;pages=206-222&amp;publication_year=2004&amp;author=Hart%2CTN&amp;author=Read%2CRJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hermann T, Ritter H (1999) Listen to your Data: model-based sonification for data analysis, pp 189–194" /><p class="c-article-references__text" id="ref-CR29">Hermann T, Ritter H (1999) Listen to your Data: model-based sonification for data analysis, pp 189–194</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="B. Hess, D. Kutzner, C. Vanderspoel, E. Lindahl, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Hess B, Kutzner D, Vanderspoel C, Lindahl E (2008) GROMACS 4: algorithms for highly efficient, load-balanced, " /><p class="c-article-references__text" id="ref-CR30">Hess B, Kutzner D, Vanderspoel C, Lindahl E (2008) GROMACS 4: algorithms for highly efficient, load-balanced, and scalable molecular simulation. J Chem Theory Comput 4(3):435–447</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1021%2Fct700301q" aria-label="View reference 30">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=GROMACS%204%3A%20algorithms%20for%20highly%20efficient%2C%20load-balanced%2C%20and%20scalable%20molecular%20simulation&amp;journal=J%20Chem%20Theory%20Comput&amp;volume=4&amp;issue=3&amp;pages=435-447&amp;publication_year=2008&amp;author=Hess%2CB&amp;author=Kutzner%2CD&amp;author=Vanderspoel%2CC&amp;author=Lindahl%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Hinsen, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Hinsen K (2000) The molecular modeling toolkit: a new approach to molecular simulation. J Comput Chem 21:79–85" /><p class="c-article-references__text" id="ref-CR31">Hinsen K (2000) The molecular modeling toolkit: a new approach to molecular simulation. J Comput Chem 21:79–85</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2F%28SICI%291096-987X%2820000130%2921%3A2%3C79%3A%3AAID-JCC1%3E3.0.CO%3B2-B" aria-label="View reference 31">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20molecular%20modeling%20toolkit%3A%20a%20new%20approach%20to%20molecular%20simulation&amp;journal=J%20Comput%20Chem&amp;volume=21&amp;pages=79-85&amp;publication_year=2000&amp;author=Hinsen%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Johnson DE, Willemsen P (2003) Six Degree-of-Freedom Haptic rendering of complex polygonal models. In: Proceed" /><p class="c-article-references__text" id="ref-CR32">Johnson DE, Willemsen P (2003) Six Degree-of-Freedom Haptic rendering of complex polygonal models. In: Proceedings of the 11th symposium on haptic interfaces for virtual environment and teleoperator systems (HAPTICS’03)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Katz FGB, Rio E, Picinali L, Warusfel O (2008) The effect of spatialization in a data sonification exploration" /><p class="c-article-references__text" id="ref-CR33">Katz FGB, Rio E, Picinali L, Warusfel O (2008) The effect of spatialization in a data sonification exploration tasks. In: Proceedings of the international conference on auditory display (ICAD’08)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Kitagawa, D. Dokko, A. Okamura, D. Yuh, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Kitagawa M, Dokko D, Okamura A, Yuh D (2005) Effect of sensory substitution on suture-manipulation forces for " /><p class="c-article-references__text" id="ref-CR34">Kitagawa M, Dokko D, Okamura A, Yuh D (2005) Effect of sensory substitution on suture-manipulation forces for robotic surgical systems. J Thorac Cardiovasc Surg 129(1):151–158</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.jtcvs.2004.05.029" aria-label="View reference 34">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Effect%20of%20sensory%20substitution%20on%20suture-manipulation%20forces%20for%20robotic%20surgical%20systems&amp;journal=J%20Thorac%20Cardiovasc%20Surg&amp;volume=129&amp;issue=1&amp;pages=151-158&amp;publication_year=2005&amp;author=Kitagawa%2CM&amp;author=Dokko%2CD&amp;author=Okamura%2CA&amp;author=Yuh%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Levine, M. Facello, P. Hallstrom, G. Reeder, B. Walenz, F. Stevens, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Levine D, Facello M, Hallstrom P, Reeder G, Walenz B, Stevens F (1997) Stalk: an interactive system for virtua" /><p class="c-article-references__text" id="ref-CR35">Levine D, Facello M, Hallstrom P, Reeder G, Walenz B, Stevens F (1997) Stalk: an interactive system for virtual molecular docking. Proc IEEE Conf Comput Sci Eng 4(2):55–65</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F99.609834" aria-label="View reference 35">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Stalk%3A%20an%20interactive%20system%20for%20virtual%20molecular%20docking&amp;journal=Proc%20IEEE%20Conf%20Comput%20Sci%20Eng&amp;volume=4&amp;issue=2&amp;pages=55-65&amp;publication_year=1997&amp;author=Levine%2CD&amp;author=Facello%2CM&amp;author=Hallstrom%2CP&amp;author=Reeder%2CG&amp;author=Walenz%2CB&amp;author=Stevens%2CF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lu T-C, Ding JH, Crivelli SN (2005) DockingShop: a tool for interactive protein docking. In: Procedings of the" /><p class="c-article-references__text" id="ref-CR36">Lu T-C, Ding JH, Crivelli SN (2005) DockingShop: a tool for interactive protein docking. In: Procedings of the computational systems bioinformatics conference, pp 271–272</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lundin KE, Sillen M, Cooper MD, Ynnerman A (2005) Haptic visualization of computational fluid dynamics data us" /><p class="c-article-references__text" id="ref-CR37">Lundin KE, Sillen M, Cooper MD, Ynnerman A (2005) Haptic visualization of computational fluid dynamics data using reactive forces. In: Procedings of the society of photo-optical instrumentation engineer conference (SPIE’05), visualization and data analysis, vol 5669, pp 31–41</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Maciejewski R, Choi S, Ebert DS, Tan HZ (2005) Multi-Modal perceptualization of volumetric data and its applic" /><p class="c-article-references__text" id="ref-CR38">Maciejewski R, Choi S, Ebert DS, Tan HZ (2005) Multi-Modal perceptualization of volumetric data and its application to molecular docking. In: Proceedings of the first joint eurohaptics conference and symposium on haptic interfaces for virtual environment and teleoperator systems.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Magnani, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Magnani L (2005) An abductive theory of scientific reasoning. Semiotica 153(1–4):261–286" /><p class="c-article-references__text" id="ref-CR39">Magnani L (2005) An abductive theory of scientific reasoning. Semiotica 153(1–4):261–286</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1515%2Fsemi.2005.2005.153-1-4.261" aria-label="View reference 39">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2176673" aria-label="View reference 39 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20abductive%20theory%20of%20scientific%20reasoning&amp;journal=Semiotica&amp;volume=153&amp;issue=1%E2%80%934&amp;pages=261-286&amp;publication_year=2005&amp;author=Magnani%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Moore BCJ (2003) An introduction to the psychology of hearing" /><p class="c-article-references__text" id="ref-CR40">Moore BCJ (2003) An introduction to the psychology of hearing</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SW. Pipe, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Pipe SW (2008) Recombinant clotting factors. Thromb Haemost 99(5):840–850" /><p class="c-article-references__text" id="ref-CR41">Pipe SW (2008) Recombinant clotting factors. Thromb Haemost 99(5):840–850</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 41 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Recombinant%20clotting%20factors&amp;journal=Thromb%20Haemost&amp;volume=99&amp;issue=5&amp;pages=840-850&amp;publication_year=2008&amp;author=Pipe%2CSW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="N. Ray, X. Cavin, JC. Paul, B. Maigret, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Ray N, Cavin X, Paul JC, Maigret B (2005) Intersurf: dynamic interface between proteins. J Mol Graph Model 23(" /><p class="c-article-references__text" id="ref-CR42">Ray N, Cavin X, Paul JC, Maigret B (2005) Intersurf: dynamic interface between proteins. J Mol Graph Model 23(4):347–354</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.jmgm.2004.11.004" aria-label="View reference 42">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 42 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Intersurf%3A%20dynamic%20interface%20between%20proteins&amp;journal=J%20Mol%20Graph%20Model&amp;volume=23&amp;issue=4&amp;pages=347-354&amp;publication_year=2005&amp;author=Ray%2CN&amp;author=Cavin%2CX&amp;author=Paul%2CJC&amp;author=Maigret%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Richard, D. Chamaret, F-X. Inglese, P. Lucidarme, J-L. Ferrier, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Richard P, Chamaret D, Inglese F-X, Lucidarme P, Ferrier J-L (2006) Human-scale haptic virtual environment for" /><p class="c-article-references__text" id="ref-CR43">Richard P, Chamaret D, Inglese F-X, Lucidarme P, Ferrier J-L (2006) Human-scale haptic virtual environment for product design: effect of sensory substitution. Int J Virtual Real 5(2):37–44</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 43 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Human-scale%20haptic%20virtual%20environment%20for%20product%20design%3A%20effect%20of%20sensory%20substitution&amp;journal=Int%20J%20Virtual%20Real&amp;volume=5&amp;issue=2&amp;pages=37-44&amp;publication_year=2006&amp;author=Richard%2CP&amp;author=Chamaret%2CD&amp;author=Inglese%2CF-X&amp;author=Lucidarme%2CP&amp;author=Ferrier%2CJ-L">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DW. Ritchie, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Ritchie DW (2003) Evaluation of protein docking predictions using Hex 3.1 in CAPRI rounds 1 and 2. Proteins 52" /><p class="c-article-references__text" id="ref-CR44">Ritchie DW (2003) Evaluation of protein docking predictions using Hex 3.1 in CAPRI rounds 1 and 2. Proteins 52(1):98–106</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2Fprot.10379" aria-label="View reference 44">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 44 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Evaluation%20of%20protein%20docking%20predictions%20using%20Hex%203.1%20in%20CAPRI%20rounds%201%20and%202&amp;journal=Proteins&amp;volume=52&amp;issue=1&amp;pages=98-106&amp;publication_year=2003&amp;author=Ritchie%2CDW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Rossi, M. Isorce, S. Morin, J. Flocard, K. Arumugam, S. Crouzy, M. Vivaudou, S. Redon, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Rossi R, Isorce M, Morin S, Flocard J, Arumugam K, Crouzy S, Vivaudou M, Redon S (2007) Adaptive torsion-angle" /><p class="c-article-references__text" id="ref-CR45">Rossi R, Isorce M, Morin S, Flocard J, Arumugam K, Crouzy S, Vivaudou M, Redon S (2007) Adaptive torsion-angle quasi-statics: a general simulation method with applications to protein structure analysis and design. Bioinformatics 23(13):408–417</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1093%2Fbioinformatics%2Fbtm191" aria-label="View reference 45">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 45 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Adaptive%20torsion-angle%20quasi-statics%3A%20a%20general%20simulation%20method%20with%20applications%20to%20protein%20structure%20analysis%20and%20design&amp;journal=Bioinformatics&amp;volume=23&amp;issue=13&amp;pages=408-417&amp;publication_year=2007&amp;author=Rossi%2CR&amp;author=Isorce%2CM&amp;author=Morin%2CS&amp;author=Flocard%2CJ&amp;author=Arumugam%2CK&amp;author=Crouzy%2CS&amp;author=Vivaudou%2CM&amp;author=Redon%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rosson MB, Carroll JM (2002) Scenario-based design. In: Jacko JA, Sears A (eds) The human-computer interaction" /><p class="c-article-references__text" id="ref-CR46">Rosson MB, Carroll JM (2002) Scenario-based design. In: Jacko JA, Sears A (eds) The human-computer interaction handbook fundamentals, evolving technologies and emerging applications, pp 1032–1050</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Sanner, A. Olson, J-C. Spehner, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Sanner M, Olson A, Spehner J-C (1996) Reduced surface: an efficient way to compute molecular surfaces. Biopoly" /><p class="c-article-references__text" id="ref-CR47">Sanner M, Olson A, Spehner J-C (1996) Reduced surface: an efficient way to compute molecular surfaces. Biopolymers 38:305–320</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2F%28SICI%291097-0282%28199603%2938%3A3%3C305%3A%3AAID-BIP4%3E3.0.CO%3B2-Y" aria-label="View reference 47">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 47 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Reduced%20surface%3A%20an%20efficient%20way%20to%20compute%20molecular%20surfaces&amp;journal=Biopolymers&amp;volume=38&amp;pages=305-320&amp;publication_year=1996&amp;author=Sanner%2CM&amp;author=Olson%2CA&amp;author=Spehner%2CJ-C">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Seeger A, Chen J (1997) Controlling force feedback over a network. In: Proceedings of the second PHANToM user’" /><p class="c-article-references__text" id="ref-CR48">Seeger A, Chen J (1997) Controlling force feedback over a network. In: Proceedings of the second PHANToM user’s group workshop</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Touraine D, Bourdot P, Bellik Y, Bolot L (2002) A framework to manage multimodal fusion of events for advanced" /><p class="c-article-references__text" id="ref-CR49">Touraine D, Bourdot P, Bellik Y, Bolot L (2002) A framework to manage multimodal fusion of events for advanced interactions within virtual environments. In: Proceedings of the 8th EUROGRAPHICS workshop on virtual environment, (EGVE’2002)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Turk, G. Robertson, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Turk M, Robertson G (2000) Perceptual user interfaces (introduction). Commun ACM 43(3):32–34" /><p class="c-article-references__text" id="ref-CR50">Turk M, Robertson G (2000) Perceptual user interfaces (introduction). Commun ACM 43(3):32–34</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F330534.330535" aria-label="View reference 50">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 50 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Perceptual%20user%20interfaces%20%28introduction%29&amp;journal=Commun%20ACM&amp;volume=43&amp;issue=3&amp;pages=32-34&amp;publication_year=2000&amp;author=Turk%2CM&amp;author=Robertson%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="BO. Villoutreix, K. Bastard, O. Sperandio, R. Fahraeus, JL. Poyet, F. Calvo, B. Deprez, MA. Miteva, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Villoutreix BO, Bastard K, Sperandio O, Fahraeus R, Poyet JL, Calvo F, Deprez B, Miteva MA (2008) In silico-in" /><p class="c-article-references__text" id="ref-CR51">Villoutreix BO, Bastard K, Sperandio O, Fahraeus R, Poyet JL, Calvo F, Deprez B, Miteva MA (2008) In silico-in vitro screening of protein-protein interactions: towards the next generation of therapeutics. Curr Pharm Biotechnol 9(2):103–22</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.2174%2F138920108783955218" aria-label="View reference 51">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 51 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=In%20silico-in%20vitro%20screening%20of%20protein-protein%20interactions%3A%20towards%20the%20next%20generation%20of%20therapeutics&amp;journal=Curr%20Pharm%20Biotechnol&amp;volume=9&amp;issue=2&amp;pages=103-22&amp;publication_year=2008&amp;author=Villoutreix%2CBO&amp;author=Bastard%2CK&amp;author=Sperandio%2CO&amp;author=Fahraeus%2CR&amp;author=Poyet%2CJL&amp;author=Calvo%2CF&amp;author=Deprez%2CB&amp;author=Miteva%2CMA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Walker BN, Lane DM (1994) Auditory display: sonification, audification, and auditory interfaces. Westview Pres" /><p class="c-article-references__text" id="ref-CR52">Walker BN, Lane DM (1994) Auditory display: sonification, audification, and auditory interfaces. Westview Press, Boulder, CO, USA</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Walker BN, Lane DM (2008) Sonification mappings database on the web. In: Proceedings of the international conf" /><p class="c-article-references__text" id="ref-CR53">Walker BN, Lane DM (2008) Sonification mappings database on the web. In: Proceedings of the international conference on auditory display (ICAD’01)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Wang, Y. Lu, S. Wang, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Wang R, Lu Y, Wang S (2003) Comparative evaluation of 11 scoring functions for molecular docking. J Med Chem 4" /><p class="c-article-references__text" id="ref-CR54">Wang R, Lu Y, Wang S (2003) Comparative evaluation of 11 scoring functions for molecular docking. J Med Chem 46:2287–2303</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1021%2Fjm0203783" aria-label="View reference 54">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 54 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Comparative%20evaluation%20of%2011%20scoring%20functions%20for%20molecular%20docking&amp;journal=J%20Med%20Chem&amp;volume=46&amp;pages=2287-2303&amp;publication_year=2003&amp;author=Wang%2CR&amp;author=Lu%2CY&amp;author=Wang%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="W. Wriggers, S. Birmanns, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Wriggers W, Birmanns S (2003) Interactive fitting augmented by force-feedback and virtual reality. J Cell Biol" /><p class="c-article-references__text" id="ref-CR55">Wriggers W, Birmanns S (2003) Interactive fitting augmented by force-feedback and virtual reality. J Cell Biol 144:123–131</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 55 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Interactive%20fitting%20augmented%20by%20force-feedback%20and%20virtual%20reality&amp;journal=J%20Cell%20Biol&amp;volume=144&amp;pages=123-131&amp;publication_year=2003&amp;author=Wriggers%2CW&amp;author=Birmanns%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Zacharias, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Zacharias M (2005) ATTRACT: protein-protein docking in CAPRI using a reduced protein model. Proteins 60(2):252" /><p class="c-article-references__text" id="ref-CR56">Zacharias M (2005) ATTRACT: protein-protein docking in CAPRI using a reduced protein model. Proteins 60(2):252–6</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2Fprot.20566" aria-label="View reference 56">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2158943" aria-label="View reference 56 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 56 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=ATTRACT%3A%20protein-protein%20docking%20in%20CAPRI%20using%20a%20reduced%20protein%20model&amp;journal=Proteins&amp;volume=60&amp;issue=2&amp;pages=252-6&amp;publication_year=2005&amp;author=Zacharias%2CM">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-009-0136-z-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgments</h2><div class="c-article-section__content" id="Ack1-content"><p>This work is currently supported by the <i>ANR</i> (the French National Agency for Research) through the <i>CoRSAIRe</i> project of <i>ARA MDMSA</i> program, and by the <i>RTRA</i> (french Thematic Network of Advanced Research) <i>DIGITEO labs</i>, through the <i>SIMCoD</i> project.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Laboratoire d’Informatique et de Mécanique pour les Sciences de l’Ingénieur, Université Paris XI, BP133, 91403, Orsay Cedex, France</p><p class="c-article-author-affiliation__authors-list">N. Férey, C. Martin, G. Bouyer, A. Tek, P. Bourdot, B. F. G. Katz &amp; M. Ammi</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Arts et Metiers ParisTech, LCPI, 151 Blv. de l’Hôpital, 75013, Paris, France</p><p class="c-article-author-affiliation__authors-list">J. Nelson</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Laboratoire Ergonomie-Comportement-Interactions, Université Paris V, 45, rue des Saints-Pères, 75006, Paris, France</p><p class="c-article-author-affiliation__authors-list">J. M. Burkhardt</p></li><li id="Aff4"><p class="c-article-author-affiliation__address">Institut National de la Santé et de la Recherche Médicale, Equipe DSIMB, Université Paris VII, INTS, 6, rue Alexandre Cabanel, 75739, Paris Cedex 15, France</p><p class="c-article-author-affiliation__authors-list">C. Etchebest &amp; L. Autin</p></li><li id="Aff5"><p class="c-article-author-affiliation__address">Institut de Recherche et Coordination Acoustique/Musique, 1, place Igor Stravinsky, 75004, Paris, France</p><p class="c-article-author-affiliation__authors-list">L. Picinali</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-N_-F_rey"><span class="c-article-authors-search__title u-h3 js-search-name">N. Férey</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;N.+F%C3%A9rey&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=N.+F%C3%A9rey" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22N.+F%C3%A9rey%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-J_-Nelson"><span class="c-article-authors-search__title u-h3 js-search-name">J. Nelson</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;J.+Nelson&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=J.+Nelson" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22J.+Nelson%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-C_-Martin"><span class="c-article-authors-search__title u-h3 js-search-name">C. Martin</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;C.+Martin&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=C.+Martin" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22C.+Martin%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-L_-Picinali"><span class="c-article-authors-search__title u-h3 js-search-name">L. Picinali</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;L.+Picinali&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=L.+Picinali" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22L.+Picinali%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-G_-Bouyer"><span class="c-article-authors-search__title u-h3 js-search-name">G. Bouyer</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;G.+Bouyer&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=G.+Bouyer" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22G.+Bouyer%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-A_-Tek"><span class="c-article-authors-search__title u-h3 js-search-name">A. Tek</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;A.+Tek&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=A.+Tek" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22A.+Tek%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-P_-Bourdot"><span class="c-article-authors-search__title u-h3 js-search-name">P. Bourdot</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;P.+Bourdot&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=P.+Bourdot" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22P.+Bourdot%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-J__M_-Burkhardt"><span class="c-article-authors-search__title u-h3 js-search-name">J. M. Burkhardt</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;J. M.+Burkhardt&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=J. M.+Burkhardt" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22J. M.+Burkhardt%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-B__F__G_-Katz"><span class="c-article-authors-search__title u-h3 js-search-name">B. F. G. Katz</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;B. F. G.+Katz&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=B. F. G.+Katz" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22B. F. G.+Katz%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-M_-Ammi"><span class="c-article-authors-search__title u-h3 js-search-name">M. Ammi</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;M.+Ammi&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=M.+Ammi" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22M.+Ammi%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-C_-Etchebest"><span class="c-article-authors-search__title u-h3 js-search-name">C. Etchebest</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;C.+Etchebest&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=C.+Etchebest" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22C.+Etchebest%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-L_-Autin"><span class="c-article-authors-search__title u-h3 js-search-name">L. Autin</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;L.+Autin&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=L.+Autin" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22L.+Autin%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-009-0136-z/email/correspondent/c1/new">N. Férey</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Multisensory%20VR%20interaction%20for%20protein-docking%20in%20the%20CoRSAIRe%20project&amp;author=N.%20F%C3%A9rey%20et%20al&amp;contentID=10.1007%2Fs10055-009-0136-z&amp;publication=1359-4338&amp;publicationDate=2009-10-01&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Férey, N., Nelson, J., Martin, C. <i>et al.</i> Multisensory VR interaction for protein-docking in the <i>CoRSAIRe</i> project.
                    <i>Virtual Reality</i> <b>13, </b>273 (2009). https://doi.org/10.1007/s10055-009-0136-z</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-009-0136-z.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2009-03-10">10 March 2009</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2009-09-09">09 September 2009</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2009-10-01">01 October 2009</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-009-0136-z" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-009-0136-z</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Protein docking</span></li><li class="c-article-subject-list__subject"><span itemprop="about">User-centered design</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Virtual reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Multimodal rendering</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-009-0136-z.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=136;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

