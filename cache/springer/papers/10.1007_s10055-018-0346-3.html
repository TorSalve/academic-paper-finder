<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Virtual memory palaces: immersion aids recall"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Virtual reality displays, such as head-mounted displays (HMD), afford us a superior spatial awareness by leveraging our vestibular and proprioceptive senses, as compared to traditional desktop..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/23/1.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Virtual memory palaces: immersion aids recall"/>

    <meta name="dc.source" content="Virtual Reality 2018 23:1"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2018-05-16"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2018 The Author(s)"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Virtual reality displays, such as head-mounted displays (HMD), afford us a superior spatial awareness by leveraging our vestibular and proprioceptive senses, as compared to traditional desktop displays. Since classical times, people have used memory palaces as a spatial mnemonic to help remember information by organizing it spatially and associating it with salient features in that environment. In this paper, we explore whether using virtual memory palaces in a head-mounted display with head-tracking (HMD condition) would allow a user to better recall information than when using a traditional desktop display with a mouse-based interaction (desktop condition). We found that virtual memory palaces in HMD condition provide a superior memory recall ability compared to the desktop condition. We believe this is a first step in using virtual environments for creating more memorable experiences that enhance productivity through better recall of large amounts of information organized using the idea of virtual memory palaces."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2018-05-16"/>

    <meta name="prism.volume" content="23"/>

    <meta name="prism.number" content="1"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="1"/>

    <meta name="prism.endingPage" content="15"/>

    <meta name="prism.copyright" content="2018 The Author(s)"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-018-0346-3"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-018-0346-3"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-018-0346-3.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-018-0346-3"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Virtual memory palaces: immersion aids recall"/>

    <meta name="citation_volume" content="23"/>

    <meta name="citation_issue" content="1"/>

    <meta name="citation_publication_date" content="2019/03"/>

    <meta name="citation_online_date" content="2018/05/16"/>

    <meta name="citation_firstpage" content="1"/>

    <meta name="citation_lastpage" content="15"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_fulltext_world_readable" content=""/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-018-0346-3"/>

    <meta name="DOI" content="10.1007/s10055-018-0346-3"/>

    <meta name="citation_doi" content="10.1007/s10055-018-0346-3"/>

    <meta name="description" content="Virtual reality displays, such as head-mounted displays (HMD), afford us a superior spatial awareness by leveraging our vestibular and proprioceptive sense"/>

    <meta name="dc.creator" content="Eric Krokos"/>

    <meta name="dc.creator" content="Catherine Plaisant"/>

    <meta name="dc.creator" content="Amitabh Varshney"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="3DMarko (2011) Medieval town 01 Dubrovnik. 
                    https://www.turbosquid.com/FullPreview/Index.cfm/ID/632415
                    
                  . Retrieved 10 May 2018"/>

    <meta name="citation_reference" content="3DMarko (2014) Palace interior 02. 
                    https://www.turbosquid.com/FullPreview/Index.cfm/ID/809577
                    
                  . Retrieved 10 May 2018"/>

    <meta name="citation_reference" content="citation_journal_title=Psychol Learn Motiv; citation_title=Human memory: a proposed system and its control processes; citation_author=RC Atkinson, RM Shiffrin; citation_volume=2; citation_publication_date=1968; citation_pages=89-195; citation_doi=10.1016/S0079-7421(08)60422-3; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_journal_title=Psychol Learn Motiv; citation_title=Working memory; citation_author=AD Baddeley, G Hitch; citation_volume=8; citation_publication_date=1974; citation_pages=47-89; citation_doi=10.1016/S0079-7421(08)60452-1; citation_id=CR4"/>

    <meta name="citation_reference" content="citation_journal_title=Rev Neurosci; citation_title=The boundary vector cell model of place cell firing and spatial memory; citation_author=C Barry, C Lever, R Hayman, T Hartley, S Burton, J O&#8217;Keefe, K Jeffery, N Burgess; citation_volume=17; citation_issue=1&#8211;2; citation_publication_date=2006; citation_pages=71-98; citation_id=CR5"/>

    <meta name="citation_reference" content="citation_journal_title=Annu Rev Psychol; citation_title=Grounded cognition; citation_author=LW Barsalou; citation_volume=59; citation_publication_date=2008; citation_pages=617-645; citation_doi=10.1146/annurev.psych.59.103006.093639; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_journal_title=J Neurosci; citation_title=Medial parietal cortex encodes perceived heading direction in humans; citation_author=O Baumann, JB Mattingley; citation_volume=30; citation_issue=39; citation_publication_date=2010; citation_pages=12,897-12,901; citation_doi=10.1523/JNEUROSCI.3077-10.2010; citation_id=CR7"/>

    <meta name="citation_reference" content="citation_journal_title=Computer; citation_title=Virtual reality: how much immersion is enough?; citation_author=DA Bowman, RP McMahan; citation_volume=40; citation_issue=7; citation_publication_date=2007; citation_pages=36-43; citation_doi=10.1109/MC.2007.257; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_journal_title=Memory; citation_title=The specificity of memory enhancement during interaction with a virtual environment; citation_author=BM Brooks; citation_volume=7; citation_issue=1; citation_publication_date=1999; citation_pages=65-78; citation_doi=10.1080/741943713; citation_id=CR9"/>

    <meta name="citation_reference" content="Brooks FP Jr, Airey J, Alspaugh J, Bell A, Brown R, Hill C, Nimscheck U, Rheingans P, Rohlf J, Smith D, Turner D, Varshney A, Wang Y, Weber H, Yuan X (1992) Six generations of building walkthrough: final technical report to the National Science Foundation TR92-026, Department of Computer Science. University of North Carolina at Chapel Hill"/>

    <meta name="citation_reference" content="citation_journal_title=Nat Rev Neurosci; citation_title=Recognition memory: what are the roles of the perirhinal cortex and hippocampus?; citation_author=MW Brown, JP Aggleton; citation_volume=2; citation_issue=1; citation_publication_date=2001; citation_pages=51-61; citation_doi=10.1038/35049064; citation_id=CR11"/>

    <meta name="citation_reference" content="citation_journal_title=Ann N Y Acad Sci; citation_title=Spatial cognition and the brain; citation_author=N Burgess; citation_volume=1124; citation_issue=1; citation_publication_date=2008; citation_pages=77-97; citation_doi=10.1196/annals.1440.002; citation_id=CR12"/>

    <meta name="citation_reference" content="citation_journal_title=Nat Neurosci; citation_title=Memory, navigation and theta rhythm in the hippocampal-entorhinal system; citation_author=G Buzs&#225;ki, EI Moser; citation_volume=16; citation_issue=2; citation_publication_date=2013; citation_pages=130-138; citation_doi=10.1038/nn.3304; citation_id=CR13"/>

    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Cellular networks underlying human spatial navigation; citation_author=AD Ekstrom, MJ Kahana, JB Caplan, TA Fields, EA Isham, EL Newman, I Fried; citation_volume=425; citation_issue=6954; citation_publication_date=2003; citation_pages=184-188; citation_doi=10.1038/nature01964; citation_id=CR14"/>

    <meta name="citation_reference" content="citation_journal_title=J Comput Inf Syst; citation_title=The virtual memory palace; citation_author=E Fassbender, W Heiden; citation_volume=2; citation_issue=1; citation_publication_date=2006; citation_pages=457-464; citation_id=CR15"/>

    <meta name="citation_reference" content="citation_title=Multiple intelligences: new horizons; citation_publication_date=2006; citation_isbn=978-0465047680; citation_id=CR16; citation_author=H Gardner; citation_publisher=Basic books"/>

    <meta name="citation_reference" content="citation_journal_title=Br J Psychol; citation_title=Context-dependent memory in two natural environments: on land and underwater; citation_author=DR Godden, AD Baddeley; citation_volume=66; citation_issue=3; citation_publication_date=1975; citation_pages=325-331; citation_doi=10.1111/j.2044-8295.1975.tb01468.x; citation_id=CR17"/>

    <meta name="citation_reference" content="citation_journal_title=Lang Learn Technol; citation_title=Emerging technologies from memory palaces to spacing algorithms: approaches to second-language vocabulary learning; citation_author=R Godwin-Jones; citation_volume=14; citation_issue=2; citation_publication_date=2010; citation_pages=4; citation_id=CR18"/>

    <meta name="citation_reference" content="Harman J (2001) Creating a memory palace using a computer. In: CHI &#8217;01 extended abstracts on human factors in computing systems, pp 407&#8211;408"/>

    <meta name="citation_reference" content="Harman J, Brown R, Johnson D (2017) Improved memory elicitation in virtual reality: new experimental results and insights. In: IFIP conference on human&#8211;computer interaction, Springer, pp 128&#8211;146"/>

    <meta name="citation_reference" content="citation_journal_title=Mem Cogn; citation_title=Memory aids people use: two interview studies; citation_author=JE Harris; citation_volume=8; citation_issue=1; citation_publication_date=1980; citation_pages=31-38; citation_doi=10.3758/BF03197549; citation_id=CR21"/>

    <meta name="citation_reference" content="citation_journal_title=Philos Trans R Soc B; citation_title=Space in the brain: how the hippocampal formation supports spatial cognition; citation_author=T Hartley, C Lever, N Burgess, J O&#8217;Keefe; citation_volume=369; citation_issue=1635; citation_publication_date=2014; citation_pages=20120,510; citation_doi=10.1098/rstb.2012.0510; citation_id=CR22"/>

    <meta name="citation_reference" content="citation_journal_title=Proc Natl Acad Sci USA; citation_title=Coding for spatial goals in the prelimbic/infralimbic area of the rat frontal cortex; citation_author=V Hok, E Save, P Lenck-Santini, B Poucet; citation_volume=102; citation_issue=12; citation_publication_date=2005; citation_pages=4602-4607; citation_doi=10.1073/pnas.0407332102; citation_id=CR23"/>

    <meta name="citation_reference" content="citation_title=The origin of consciousness in the breakdown of the bicameral mind; citation_publication_date=1976; citation_id=CR24; citation_author=J Julian; citation_publisher=The Adelphi"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Appl Percept (TAP); citation_title=Mesh saliency and human eye fixations; citation_author=Y Kim, A Varshney, DW Jacobs, F Guimbreti&#232;re; citation_volume=7; citation_issue=2; citation_publication_date=2010; citation_pages=12; citation_id=CR26"/>

    <meta name="citation_reference" content="citation_journal_title=J Neurosci; citation_title=Neural correlates of object-in-place learning in hippocampus and prefrontal cortex; citation_author=J Kim, S Delcasso, I Lee; citation_volume=31; citation_issue=47; citation_publication_date=2011; citation_pages=16,991-17,006; citation_doi=10.1523/JNEUROSCI.2859-11.2011; citation_id=CR25"/>

    <meta name="citation_reference" content="citation_title=Space to reason: a spatial theory of human thought; citation_publication_date=2013; citation_id=CR27; citation_author=M Knauff; citation_publisher=MIT Press"/>

    <meta name="citation_reference" content="citation_journal_title=Acta Psychol; citation_title=Building a memory palace in minutes: equivalent memory performance using virtual versus conventional environments with the method of loci; citation_author=EL Legge, CR Madan, ET Ng, JB Caplan; citation_volume=141; citation_issue=3; citation_publication_date=2012; citation_pages=380-390; citation_doi=10.1016/j.actpsy.2012.09.002; citation_id=CR28"/>

    <meta name="citation_reference" content="citation_journal_title=Curr Opin Neurobiol; citation_title=Place cells, spatial maps and the population code for memory; citation_author=S Leutgeb, JK Leutgeb, MB Moser, EI Moser; citation_volume=15; citation_issue=6; citation_publication_date=2005; citation_pages=738-746; citation_doi=10.1016/j.conb.2005.10.002; citation_id=CR29"/>

    <meta name="citation_reference" content="citation_journal_title=J Neurosci; citation_title=Boundary vector cells in the subiculum of the hippocampal formation; citation_author=C Lever, S Burton, A Jeewajee, J O&#8217;Keefe, N Burgess; citation_volume=29; citation_issue=31; citation_publication_date=2009; citation_pages=9771-9777; citation_doi=10.1523/JNEUROSCI.1319-09.2009; citation_id=CR30"/>

    <meta name="citation_reference" content="citation_journal_title=Behav Res Methods Instrum Comput; citation_title=Immersive virtual environment technology as a basic research tool in psychology; citation_author=JM Loomis, JJ Blascovich, AC Beall; citation_volume=31; citation_issue=4; citation_publication_date=1999; citation_pages=557-564; citation_doi=10.3758/BF03200735; citation_id=CR31"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Netw; citation_title=Computational cognitive models of spatial memory in navigation space: a review; citation_author=T Madl, K Chen, D Montaldi, R Trappl; citation_volume=65; citation_publication_date=2015; citation_pages=18-43; citation_doi=10.1016/j.neunet.2015.01.002; citation_id=CR32"/>

    <meta name="citation_reference" content="citation_journal_title=CyberPsychol Behav; citation_title=The effects of levels of immersion on memory and presence in virtual environments: a reality centered approach; citation_author=K Mania, A Chalmers; citation_volume=4; citation_issue=2; citation_publication_date=2001; citation_pages=247-264; citation_doi=10.1089/109493101300117938; citation_id=CR33"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoper Virtual Environ; citation_title=Fidelity metrics for virtual environment simulations based on spatial memory awareness states; citation_author=K Mania, T Troscianko, R Hawkes, A Chalmers; citation_volume=12; citation_issue=3; citation_publication_date=2003; citation_pages=296-310; citation_doi=10.1162/105474603765879549; citation_id=CR34"/>

    <meta name="citation_reference" content="citation_journal_title=Emotion; citation_title=Emotional intelligence as a standard intelligence; citation_author=JD Mayer, P Salovey, DR Caruso, G Sitarenios; citation_volume=1; citation_issue=3; citation_publication_date=2001; citation_pages=232-242; citation_doi=10.1037/1528-3542.1.3.232; citation_id=CR35"/>

    <meta name="citation_reference" content="citation_journal_title=Teach Psychol; citation_title=Location, location, location! Demonstrating the mnemonic benefit of the method of loci; citation_author=JA McCabe; citation_volume=42; citation_issue=2; citation_publication_date=2015; citation_pages=169-173; citation_doi=10.1177/0098628315573143; citation_id=CR36"/>

    <meta name="citation_reference" content="citation_journal_title=Psychol Rev; citation_title=The magical number seven, plus or minus two: some limits on our capacity for processing information; citation_author=GA Miller; citation_volume=63; citation_issue=2; citation_publication_date=1956; citation_pages=81; citation_doi=10.1037/h0043158; citation_id=CR37"/>

    <meta name="citation_reference" content="citation_journal_title=Annu Rev Neurosci; citation_title=Place cells, grid cells, and the brain&#8217;s spatial representation system; citation_author=EI Moser, E Kropff, MB Moser; citation_volume=31; citation_publication_date=2008; citation_pages=69-89; citation_doi=10.1146/annurev.neuro.31.061307.090723; citation_id=CR38"/>

    <meta name="citation_reference" content="citation_journal_title=Behav Brain Sci; citation_title=A sensorimotor account of vision and visual consciousness; citation_author=JK O&#8217;Regan, A No&#235;; citation_volume=24; citation_issue=5; citation_publication_date=2001; citation_pages=939-973; citation_doi=10.1017/S0140525X01000115; citation_id=CR39"/>

    <meta name="citation_reference" content="citation_journal_title=Front Hum Neurosci; citation_title=Virtual reality for enhanced ecological validity and experimental control in the clinical, affective and social neurosciences; citation_author=TD Parsons; citation_volume=9; citation_publication_date=2015; citation_pages=660; citation_doi=10.3389/fnhum.2015.00660; citation_id=CR40"/>

    <meta name="citation_reference" content="Pausch R, Proffitt D, Williams G (1997) Quantifying immersion in virtual reality. In: Proceedings of the 24th annual conference on computer graphics and interactive techniques, SIGGRAPH &#8217;97, pp 13&#8211;18"/>

    <meta name="citation_reference" content="Perrault ST, Lecolinet E, Bourse YP, Zhao S, Guiard Y (2015) Physical loci: leveraging spatial, object and semantic memory for command selection. In: Proceedings of the 33rd annual ACM conference on human factors in computing systems, CHI &#8217;15, pp 299&#8211;308"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoper Virtual Environ; citation_title=The effects of higher levels of immersion on procedure memorization performance and implications for educational virtual environments; citation_author=ED Ragan, A Sowndararajan, R Kopper, DA Bowman; citation_volume=19; citation_issue=6; citation_publication_date=2010; citation_pages=527-543; citation_doi=10.1162/pres_a_00016; citation_id=CR43"/>

    <meta name="citation_reference" content="citation_journal_title=Front Psychol; citation_title=Virtual reality as an embodied tool to enhance episodic memory in elderly; citation_author=C Repetto, S Serino, M Macedonia, G Riva; citation_volume=7; citation_publication_date=2016; citation_pages=1839:1-1839:4; citation_doi=10.3389/fpsyg.2016.01839; citation_id=CR44"/>

    <meta name="citation_reference" content="citation_journal_title=Mem Cognit; citation_title=Spatial knowledge acquisition from maps and from navigation in real and virtual environments; citation_author=AE Richardson, DR Montello, M Hegarty; citation_volume=27; citation_issue=4; citation_publication_date=1999; citation_pages=741-750; citation_doi=10.3758/BF03211566; citation_id=CR45"/>

    <meta name="citation_reference" content="citation_journal_title=Bull Psychon Soc; citation_title=Implicit and explicit memory models; citation_author=HL Roediger; citation_volume=13; citation_issue=6; citation_publication_date=1979; citation_pages=339-342; citation_doi=10.3758/BF03336889; citation_id=CR46"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoper Virtual Environ; citation_title=Navigating large-scale virtual environments: what differences occur between helmet-mounted and desktop displays?; citation_author=RA Ruddle, SJ Payne, DM Jones; citation_volume=8; citation_issue=2; citation_publication_date=1999; citation_pages=157-168; citation_doi=10.1162/105474699566143; citation_id=CR47"/>

    <meta name="citation_reference" content="citation_journal_title=Nat Rev Neurosci; citation_title=From presence to consciousness through virtual reality; citation_author=MV Sanchez-Vives, M Slater; citation_volume=6; citation_issue=4; citation_publication_date=2005; citation_pages=332-339; citation_doi=10.1038/nrn1651; citation_id=CR48"/>

    <meta name="citation_reference" content="citation_title=Embodied cognition; citation_publication_date=2010; citation_isbn=978-0415773423; citation_id=CR49; citation_author=L Shapiro; citation_publisher=Routledge"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Comput Surv; citation_title=A survey of presence and related concepts; citation_author=R Skarbez, FP Brooks, MC Whitton; citation_volume=50; citation_issue=6; citation_publication_date=2017; citation_pages=96:1-96:39; citation_doi=10.1145/3134301; citation_id=CR50"/>

    <meta name="citation_reference" content="citation_journal_title=Philos Trans R Soc Lond B Biol Sci; citation_title=Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments; citation_author=M Slater; citation_volume=364; citation_issue=1535; citation_publication_date=2009; citation_pages=3549-3557; citation_doi=10.1098/rstb.2009.0138; citation_id=CR51"/>

    <meta name="citation_reference" content="Sowndararajan A, Wang R, Bowman DA (2008) Quantifying the benefits of immersion for procedural training. In: Proceedings of the 2008 workshop on immersive projection technologies/emerging display technologies, IPT/EDT &#8217;08, pp 2:1&#8211;2:4"/>

    <meta name="citation_reference" content="citation_journal_title=Mem Cognit; citation_title=Spatial updating of virtual displays; citation_author=M Wraga, SH Creem-Regehr, DR Proffitt; citation_volume=32; citation_issue=3; citation_publication_date=2004; citation_pages=399-415; citation_doi=10.3758/BF03195834; citation_id=CR53"/>

    <meta name="citation_reference" content="citation_title=The art of memory; citation_publication_date=1992; citation_id=CR54; citation_author=FA Yates; citation_publisher=Random House"/>

    <meta name="citation_author" content="Eric Krokos"/>

    <meta name="citation_author_email" content="ekrokos@umiacs.umd.edu"/>

    <meta name="citation_author_institution" content="University of Maryland, College Park, College Park, USA"/>

    <meta name="citation_author" content="Catherine Plaisant"/>

    <meta name="citation_author_email" content="plaisant@cs.umd.edu"/>

    <meta name="citation_author_institution" content="University of Maryland, College Park, College Park, USA"/>

    <meta name="citation_author" content="Amitabh Varshney"/>

    <meta name="citation_author_email" content="varshney@umiacs.umd.edu"/>

    <meta name="citation_author_institution" content="University of Maryland, College Park, College Park, USA"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-018-0346-3&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2019/03/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-018-0346-3"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Virtual memory palaces: immersion aids recall"/>
        <meta property="og:description" content="Virtual reality displays, such as head-mounted displays (HMD), afford us a superior spatial awareness by leveraging our vestibular and proprioceptive senses, as compared to traditional desktop displays. Since classical times, people have used memory palaces as a spatial mnemonic to help remember information by organizing it spatially and associating it with salient features in that environment. In this paper, we explore whether using virtual memory palaces in a head-mounted display with head-tracking (HMD condition) would allow a user to better recall information than when using a traditional desktop display with a mouse-based interaction (desktop condition). We found that virtual memory palaces in HMD condition provide a superior memory recall ability compared to the desktop condition. We believe this is a first step in using virtual environments for creating more memorable experiences that enhance productivity through better recall of large amounts of information organized using the idea of virtual memory palaces."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Virtual memory palaces: immersion aids recall | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-018-0346-3","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Immersion, Experimental methods, HMD, 3D navigation, Visualization, Psychology, Training, Education, User study, Perception, Presence","kwrd":["Immersion","Experimental_methods","HMD","3D_navigation","Visualization","Psychology","Training","Education","User_study","Perception","Presence"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"Y","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"vgzm.415900-10.1007-s10055-018-0346-3","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-018-0346-3","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=346;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-018-0346-3">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Virtual memory palaces: immersion aids recall
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-018-0346-3.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-018-0346-3.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
        <li class="c-article-identifiers__item">
            <span class="c-article-identifiers__open" data-test="open-access">Open Access</span>
        </li>
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2018-05-16" itemprop="datePublished">16 May 2018</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Virtual memory palaces: immersion aids recall</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Eric-Krokos" data-author-popup="auth-Eric-Krokos" data-corresp-id="c1">Eric Krokos<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><span class="u-js-hide"> 
            <a class="js-orcid" itemprop="url" href="http://orcid.org/0000-0003-1350-5297"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-1350-5297</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Maryland, College Park" /><meta itemprop="address" content="0000 0001 0941 7177, grid.164295.d, University of Maryland, College Park, AV. Williams 4406, College Park, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Catherine-Plaisant" data-author-popup="auth-Catherine-Plaisant">Catherine Plaisant</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Maryland, College Park" /><meta itemprop="address" content="0000 0001 0941 7177, grid.164295.d, University of Maryland, College Park, Hornbake Bldg. 2117C, College Park, USA" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Amitabh-Varshney" data-author-popup="auth-Amitabh-Varshney">Amitabh Varshney</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Maryland, College Park" /><meta itemprop="address" content="0000 0001 0941 7177, grid.164295.d, University of Maryland, College Park, AV. Williams 2119, College Park, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 23</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">1</span>–<span itemprop="pageEnd">15</span>(<span data-test="article-publication-year">2019</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">15k <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">35 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">671 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-018-0346-3/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Virtual reality displays, such as head-mounted displays (HMD), afford us a superior spatial awareness by leveraging our vestibular and proprioceptive senses, as compared to traditional desktop displays. Since classical times, people have used memory palaces as a spatial mnemonic to help remember information by organizing it spatially and associating it with salient features in that environment. In this paper, we explore whether using virtual memory palaces in a head-mounted display with head-tracking (HMD condition) would allow a user to better recall information than when using a traditional desktop display with a mouse-based interaction (desktop condition). We found that virtual memory palaces in HMD condition provide a superior memory recall ability compared to the desktop condition. We believe this is a first step in using virtual environments for creating more memorable experiences that enhance productivity through better recall of large amounts of information organized using the idea of virtual memory palaces.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Throughout history, humans have relied on technology to help us remember information. From cave paintings, clay tablets, and papyrus to modern paper, audio, and video, we have used technology to encode and recall information. This paper addresses the question of whether virtual environments could be the next step in our quest for better tools to help us memorize and recall information. Virtual reality displays, in contrast to traditional displays, can combine visually immersive spatial representations of data with our vestibular and proprioceptive senses. The technique of memory palaces provides a natural spatial mnemonic to assist in recall. Since classical times, people have used memory palaces (method of loci), by taking advantage of the brain’s ability to spatially organize thoughts and concepts (Julian <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1976" title="Julian J (1976) The origin of consciousness in the breakdown of the bicameral mind. The Adelphi, Milan" href="/article/10.1007/s10055-018-0346-3#ref-CR24" id="ref-link-section-d42203e419">1976</a>; Roediger <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1979" title="Roediger HL (1979) Implicit and explicit memory models. Bull Psychon Soc 13(6):339–342" href="/article/10.1007/s10055-018-0346-3#ref-CR46" id="ref-link-section-d42203e422">1979</a>; Knauff <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Knauff M (2013) Space to reason: a spatial theory of human thought. MIT Press, Cambridge" href="/article/10.1007/s10055-018-0346-3#ref-CR27" id="ref-link-section-d42203e425">2013</a>). In a memory palace, one mentally navigates an imagined structure to recall information (Yates <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Yates FA (1992) The art of memory, vol 64. Random House, New York" href="/article/10.1007/s10055-018-0346-3#ref-CR54" id="ref-link-section-d42203e428">1992</a>; Harman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Harman J (2001) Creating a memory palace using a computer. In: CHI ’01 extended abstracts on human factors in computing systems, pp 407–408" href="/article/10.1007/s10055-018-0346-3#ref-CR19" id="ref-link-section-d42203e431">2001</a>). Even the Roman orator Cicero is believed to have used the memory palace technique by visualizing his speeches and poems as spatial locations within the auditorium he was in (Yates <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Yates FA (1992) The art of memory, vol 64. Random House, New York" href="/article/10.1007/s10055-018-0346-3#ref-CR54" id="ref-link-section-d42203e435">1992</a>; Godwin-Jones <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Godwin-Jones R (2010) Emerging technologies from memory palaces to spacing algorithms: approaches to second-language vocabulary learning. Lang Learn Technol 14(2):4" href="/article/10.1007/s10055-018-0346-3#ref-CR18" id="ref-link-section-d42203e438">2010</a>). Spatial intelligence has been associated with a heightened sense of situational awareness and of relationships in one’s own surroundings (Mayer et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Mayer JD, Salovey P, Caruso DR, Sitarenios G (2001) Emotional intelligence as a standard intelligence. Emotion 1(3):232–242" href="/article/10.1007/s10055-018-0346-3#ref-CR35" id="ref-link-section-d42203e441">2001</a>; Gardner <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Gardner H (2006) Multiple intelligences: new horizons. Basic books, New York. ISBN 978-0465047680" href="/article/10.1007/s10055-018-0346-3#ref-CR16" id="ref-link-section-d42203e444">2006</a>).</p><p>Research in cognitive psychology has shown that recall is superior in the same environment in which the learning took place (Godden and Baddeley <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1975" title="Godden DR, Baddeley AD (1975) Context-dependent memory in two natural environments: on land and underwater. Br J Psychol 66(3):325–331" href="/article/10.1007/s10055-018-0346-3#ref-CR17" id="ref-link-section-d42203e450">1975</a>). Such findings of context-dependent memory have interesting implications for virtual environments that have not yet been fully explored. Imagine, for instance, a victim of a street aggression being asked to recall the appearance details of their assailant. Virtual environments that mirror the scene of the crime could provide superior assistance in recall by placing the victim back into such an environment.</p><p>In this paper, we present the results of a user study that examined if virtual memory palaces could assist in superior recall of faces and their spatial locations aided by the <i>context-dependent</i> immersion afforded by a head-tracked head-mounted display (HMD condition) as compared to using a traditional desktop display with a mouse-based interaction (desktop condition). To explore this question, we designed an experiment where participants were asked to recall specific information in the two environments: the HMD condition and the desktop condition. We created the virtual memory palaces prior to the start of the study. Our hypotheses are as follows:</p><ul class="u-list-style-dash">
                  <li>
                    <p>Hypothesis 1: The participant memory recall accuracy will be higher in the HMD condition as compared to the desktop condition due to the increased immersion.</p>
                  </li>
                  <li>
                    <p>Hypothesis 2: Participants will have higher confidence in their answers in the HMD condition as compared to the desktop condition.</p>
                  </li>
                </ul><p>The experiment was a within-subject, <span class="mathjax-tex">\(2 \times 2 \times 2\)</span> Latin-square design, ensuring all the different combinations of variables and factors were accounted for. The experimental results of our study support both hypotheses.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Related work</h2><div class="c-article-section__content" id="Sec2-content"><p>Memory palaces have been used since the classical times to aid recall by using spatial mappings and environmental attributes. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig1">1</a> shows a depiction of a memory palace attributed to Giulio Camillo in 1511. The idea was to map words or phrases onto a mental model of an environment (in this case an amphitheater) and then recall those phrases by mentally visualizing that part of the environment.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig1_HTML.png?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig1_HTML.png" alt="figure1" loading="lazy" width="685" height="491" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Giulio Camillo’s depiction of a memory palace (1511 AD). Memory palaces like this have been used since the classical times as a spatial mnemonic</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>An important component of the memory palace technique is the subjective experience of being virtually present in the palace, even when one is physically elsewhere. This notion of <i>presence</i> has long been considered central to virtual environments, for evaluation of their effectiveness as well as their quality Skarbez et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Skarbez R, Brooks FP Jr, Whitton MC (2017) A survey of presence and related concepts. ACM Comput Surv 50(6):96:1–96:39. &#xA;                    https://doi.org/10.1145/3134301&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0346-3#ref-CR50" id="ref-link-section-d42203e538">2017</a>). More precisely, Slater (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Slater M (2009) Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments. Philos Trans R Soc Lond B Biol Sci 364(1535):3549–3557" href="/article/10.1007/s10055-018-0346-3#ref-CR51" id="ref-link-section-d42203e541">2009</a>) developed the idea of place illusion (PI), referring to the aspects of presence “constrained by the sensorimotor contingencies afforded by the virtual reality system.” Sensorimotor contingencies are those actions which are used in the process of perceiving the virtual world, such as moving the head and eyes to change gaze direction or seeing around occluding objects to gain an understanding of the space (O’Regan and Noë <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="O’Regan JK, Noë A (2001) A sensorimotor account of vision and visual consciousness. Behav Brain Sci 24(5):939–973" href="/article/10.1007/s10055-018-0346-3#ref-CR39" id="ref-link-section-d42203e544">2001</a>). Slater (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Slater M (2009) Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments. Philos Trans R Soc Lond B Biol Sci 364(1535):3549–3557" href="/article/10.1007/s10055-018-0346-3#ref-CR51" id="ref-link-section-d42203e547">2009</a>) therefore concluded that establishing presence or “being there” for lower-order immersive systems such as desktops is not feasible. In contrast, the sensorimotor contingencies of walking and looking around facilitated by head-mounted displays contribute to their higher-order immersion and establishing presence.</p><p>Recent research in cognitive psychology (Repetto et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Repetto C, Serino S, Macedonia M, Riva G (2016) Virtual reality as an embodied tool to enhance episodic memory in elderly. Front Psychol 7:1839:1–1839:4" href="/article/10.1007/s10055-018-0346-3#ref-CR44" id="ref-link-section-d42203e553">2016</a>) suggests that the mind is inherently embodied. The way we create and recall mental constructs is influenced by the way we perceive and move (Barsalou <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Barsalou LW (2008) Grounded cognition. Annu Rev Psychol 59:617–645" href="/article/10.1007/s10055-018-0346-3#ref-CR6" id="ref-link-section-d42203e556">2008</a>; Shapiro <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Shapiro L (2010) Embodied cognition. Routledge, New York. ISBN 978-0415773423" href="/article/10.1007/s10055-018-0346-3#ref-CR49" id="ref-link-section-d42203e559">2010</a>). The memory system that encodes, stores, recognizes, embodies, and recalls spatial information about the environment is called spatial memory (Madl et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Madl T, Chen K, Montaldi D, Trappl R (2015) Computational cognitive models of spatial memory in navigation space: a review. Neural Netw 65:18–43" href="/article/10.1007/s10055-018-0346-3#ref-CR32" id="ref-link-section-d42203e562">2015</a>). Several studies have found that embodied navigation and memory are closely connected  (Leutgeb et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Leutgeb S, Leutgeb JK, Moser MB, Moser EI (2005) Place cells, spatial maps and the population code for memory. Curr Opin Neurobiol 15(6):738–746" href="/article/10.1007/s10055-018-0346-3#ref-CR29" id="ref-link-section-d42203e565">2005</a>; Buzsáki and Moser <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Buzsáki G, Moser EI (2013) Memory, navigation and theta rhythm in the hippocampal-entorhinal system. Nat Neurosci 16(2):130–138" href="/article/10.1007/s10055-018-0346-3#ref-CR13" id="ref-link-section-d42203e569">2013</a>). Madl et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Madl T, Chen K, Montaldi D, Trappl R (2015) Computational cognitive models of spatial memory in navigation space: a review. Neural Netw 65:18–43" href="/article/10.1007/s10055-018-0346-3#ref-CR32" id="ref-link-section-d42203e572">2015</a>) state that there are several different types of brain mechanisms involved in processing spatial representations in the brain. <i>Grid cells</i> in the entorhinal cortex, used for path integration, are activated by changes in movement direction and speed (Moser et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Moser EI, Kropff E, Moser MB (2008) Place cells, grid cells, and the brain’s spatial representation system. Annu Rev Neurosci 31:69–89" href="/article/10.1007/s10055-018-0346-3#ref-CR38" id="ref-link-section-d42203e578">2008</a>; Burgess <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Burgess N (2008) Spatial cognition and the brain. Ann N Y Acad Sci 1124(1):77–97. &#xA;                    https://doi.org/10.1196/annals.1440.002&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0346-3#ref-CR12" id="ref-link-section-d42203e581">2008</a>). <i>Head-direction cells</i> activate in the medial parietal cortex when the head points in a given direction, providing information on viewing direction (Baumann and Mattingley <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Baumann O, Mattingley JB (2010) Medial parietal cortex encodes perceived heading direction in humans. J Neurosci 30(39):12,897–12,901" href="/article/10.1007/s10055-018-0346-3#ref-CR7" id="ref-link-section-d42203e588">2010</a>). <i>Border cells</i> and <i>boundary vector cells</i> in the subiculum and entorhinal cortex activate in close proximity to environment boundaries, depending on head direction (Burgess <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Burgess N (2008) Spatial cognition and the brain. Ann N Y Acad Sci 1124(1):77–97. &#xA;                    https://doi.org/10.1196/annals.1440.002&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0346-3#ref-CR12" id="ref-link-section-d42203e597">2008</a>; Lever et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lever C, Burton S, Jeewajee A, O’Keefe J, Burgess N (2009) Boundary vector cells in the subiculum of the hippocampal formation. J Neurosci 29(31):9771–9777" href="/article/10.1007/s10055-018-0346-3#ref-CR30" id="ref-link-section-d42203e600">2009</a>). Lastly, <i>place cells</i> in the hippocampus activate in specific spatial locations, independent of orientation, providing an internal representation of the environment (Ekstrom et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Ekstrom AD, Kahana MJ, Caplan JB, Fields TA, Isham EA, Newman EL, Fried I (2003) Cellular networks underlying human spatial navigation. Nature 425(6954):184–188" href="/article/10.1007/s10055-018-0346-3#ref-CR14" id="ref-link-section-d42203e607">2003</a>; Hartley et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Hartley T, Lever C, Burgess N, O’Keefe J (2014) Space in the brain: how the hippocampal formation supports spatial cognition. Philos Trans R Soc B 369(1635):20120,510" href="/article/10.1007/s10055-018-0346-3#ref-CR22" id="ref-link-section-d42203e610">2014</a>). It is believed that place cell fields arise from groups of grid and boundary cells which activate for different spatial scales and environmental geometry to provide a sense of location (Barry et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Barry C, Lever C, Hayman R, Hartley T, Burton S, O’Keefe J, Jeffery K, Burgess N (2006) The boundary vector cell model of place cell firing and spatial memory. Rev Neurosci 17(1–2):71–98" href="/article/10.1007/s10055-018-0346-3#ref-CR5" id="ref-link-section-d42203e613">2006</a>; Kim et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Kim J, Delcasso S, Lee I (2011) Neural correlates of object-in-place learning in hippocampus and prefrontal cortex. J Neurosci 31(47):16,991–17,006" href="/article/10.1007/s10055-018-0346-3#ref-CR25" id="ref-link-section-d42203e616">2011</a>). In addition, these hippocampal cells also provide information about place–object associations, associating place cell representations of specific locations with the representations of specific objects in recognition memory (Brown and Aggleton <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Brown MW, Aggleton JP (2001) Recognition memory: what are the roles of the perirhinal cortex and hippocampus? Nat Rev Neurosci 2(1):51–61" href="/article/10.1007/s10055-018-0346-3#ref-CR11" id="ref-link-section-d42203e619">2001</a>; Hok et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Hok V, Save E, Lenck-Santini P, Poucet B (2005) Coding for spatial goals in the prelimbic/infralimbic area of the rat frontal cortex. Proc Natl Acad Sci USA 102(12):4602–4607" href="/article/10.1007/s10055-018-0346-3#ref-CR23" id="ref-link-section-d42203e622">2005</a>). This leads us to the possibility that a spatial virtual memory palace, experienced in an immersive virtual environment, could enhance learning and recall by leveraging the integration of vestibular and proprioceptive inputs (overall sense of body position, movement, and acceleration) (Hartley et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Hartley T, Lever C, Burgess N, O’Keefe J (2014) Space in the brain: how the hippocampal formation supports spatial cognition. Philos Trans R Soc B 369(1635):20120,510" href="/article/10.1007/s10055-018-0346-3#ref-CR22" id="ref-link-section-d42203e626">2014</a>).</p><h3 class="c-article__sub-heading" id="Sec3">Memory palaces on a desktop monitor</h3><p>
Legge et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Legge EL, Madan CR, Ng ET, Caplan JB (2012) Building a memory palace in minutes: equivalent memory performance using virtual versus conventional environments with the method of loci. Acta Psychol 141(3):380–390" href="/article/10.1007/s10055-018-0346-3#ref-CR28" id="ref-link-section-d42203e636">2012</a>) compared the use of the traditional method of loci using a mental environment against a 3D graphics desktop environment. In this study, the subjects were divided into three groups. The first group was instructed to use a mental location or scene, the second group was a 3D graphics scene, and the third (control) group was not informed on the use of any mnemonic device. The subjects in the three groups were given 10–11 uncorrelated words and asked to memorize the words with their mnemonic device, if any. The users then recalled the words serially. This study found that the users who used a graphics desktop environment as the basis for their method of loci performed better than those using a mental scene of their choice, and those who were not instructed on a memory strategy did not perform as well as those who were instructed to use the memory strategy. Fassbender and Heiden (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Fassbender E, Heiden W (2006) The virtual memory palace. J Comput Inf Syst 2(1):457–464" href="/article/10.1007/s10055-018-0346-3#ref-CR15" id="ref-link-section-d42203e639">2006</a>) compared the ability of users to recall a list of 10 words when using a desktop compared to memorizing the word list. The authors created a navigable 3D castle with 4 sections and 10 objects, where each object has a visual and audible component, with the idea that a user will associate a word with that object. First, each user was given 10 words to memorize and then were asked to recall as many as they could after a 2-min distraction task. Next, each user was explained and shown the 3D castle on a desktop. After being given time to learn the associations between the words, images, and audio, the users were evaluated on their ability to recall the words in the 3D castle on the desktop. The study found that there was no significant difference between the users’ ability to immediately recall the words after a 2-min break, but after one week there was a 25% difference in recall in favor of the 3D graphics desktop memory palace environment condition. The above studies show that compared to a purely mental mnemonic, a graphics desktop setup is better in assisting retention and recall.</p><p>Both of these studies have been carried out on desktops and not in immersive HMDs. In our study, we compare the performance of users on a desktop compared with an immersive HMD.</p><h3 class="c-article__sub-heading" id="Sec4">Memory palaces on multiple displays</h3><p>The efficacy of varying immersion levels by changing the field of view has also been studied in the context of procedural training (Bowman and McMahan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Bowman DA, McMahan RP (2007) Virtual reality: how much immersion is enough? Computer 40(7):36–43" href="/article/10.1007/s10055-018-0346-3#ref-CR8" id="ref-link-section-d42203e654">2007</a>). Sowndararajan et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Sowndararajan A, Wang R, Bowman DA (2008) Quantifying the benefits of immersion for procedural training. In: Proceedings of the 2008 workshop on immersive projection technologies/emerging display technologies, IPT/EDT ’08, pp 2:1–2:4" href="/article/10.1007/s10055-018-0346-3#ref-CR52" id="ref-link-section-d42203e657">2008</a>) compared subject performance for a simple and complex procedural task (involving a different number of steps and interactions), but with two different fields of view—one with a laptop and the other with a large rear-projected L-shaped display. The study had participants trained on two procedures, and the performance with the two levels of immersion was compared. The study found that higher levels of immersion (in this case, field of view) were more effective in learning complex procedures that reference spatial locations. In addition, there was no statistical difference in performance for the simple task for the different levels of immersion. Ragan et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Ragan ED, Sowndararajan A, Kopper R, Bowman DA (2010) The effects of higher levels of immersion on procedure memorization performance and implications for educational virtual environments. Presence Teleoper Virtual Environ 19(6):527–543" href="/article/10.1007/s10055-018-0346-3#ref-CR43" id="ref-link-section-d42203e660">2010</a>) carried out a user study in which participants were asked to memorize and recall the sequence of placement of virtual objects on a grid shown on three rear-projected screens (one front and two side screens). The participants were divided into multiple groups that performed the task with different fields of view and fields of regard. The field of view is the size of the visual field seen in one instant, while the field of regard is the total size of the visual field that <i>can</i> be seen by a user (Bowman and McMahan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Bowman DA, McMahan RP (2007) Virtual reality: how much immersion is enough? Computer 40(7):36–43" href="/article/10.1007/s10055-018-0346-3#ref-CR8" id="ref-link-section-d42203e666">2007</a>). Both are measured in degrees of visual angle. Ragan et al. found that higher field of view and field of regard produced a statistically significant performance improvement.</p><p>The above studies examined the effectiveness of memory recall of objects, their locations, and the sequence of placement actions, in a limited field of view and field of regard in monoscopic display environments with multiple monitors. The field of regard in these studies did not surround the viewer completely. In our study, we wanted to examine the effectiveness of stereoscopic, spherical field of regard afforded by modern HMDs compared to a desktop for memory recall of objects and their spatial locations.</p><h3 class="c-article__sub-heading" id="Sec5">Search and recall in head-mounted displays</h3><p>
Pausch et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Pausch R, Proffitt D, Williams G (1997) Quantifying immersion in virtual reality. In: Proceedings of the 24th annual conference on computer graphics and interactive techniques, SIGGRAPH ’97, pp 13–18" href="/article/10.1007/s10055-018-0346-3#ref-CR41" id="ref-link-section-d42203e680">1997</a>) studied whether immersion in a virtual environment using a HMD aids in searching and detection of information. For their study, they created a virtual room with letters distributed on walls, ceiling, and floor. A user was placed in the center of this room and was asked whether a set of letters was present or not. The test was conducted using a HMD and a traditional display with a mouse and keyboard. They found that when the search target was present, the HMD and the traditional display had no statistically significant difference in performance. However, when the target was absent, the users were able to confirm its absence faster in the HMD than on the traditional display. In addition, the users that used the HMD first and then moved to a traditional desktop had better performance than those who used the desktop first and then the HMD. This suggests a positive transfer effect from the HMD to a desktop. Our user study is highly influenced by the study of Pausch et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Pausch R, Proffitt D, Williams G (1997) Quantifying immersion in virtual reality. In: Proceedings of the 24th annual conference on computer graphics and interactive techniques, SIGGRAPH ’97, pp 13–18" href="/article/10.1007/s10055-018-0346-3#ref-CR41" id="ref-link-section-d42203e683">1997</a>), but in our study, users perform recall rather than search.</p><p>
Ruddle et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Ruddle RA, Payne SJ, Jones DM (1999) Navigating large-scale virtual environments: what differences occur between helmet-mounted and desktop displays? Presence Teleoper Virtual Environ 8(2):157–168" href="/article/10.1007/s10055-018-0346-3#ref-CR47" id="ref-link-section-d42203e689">1999</a>) compared user navigation time and relative straight-line distance accuracy (amount of wasteful navigational movement) between a HMD and a traditional desktop. Users were then asked to learn the layout of two virtual buildings: one using a HMD, and the other using a desktop. After familiarizing themselves with the buildings, each user was placed in the lobby of that building and were told to go to each of five named rooms and then return to the lobby. They found that the users wearing the HMD had faster navigation times and less waste-full movement and were more accurately able to estimate distances, compared to those using a desktop.</p><p>
Mania et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Mania K, Troscianko T, Hawkes R, Chalmers A (2003) Fidelity metrics for virtual environment simulations based on spatial memory awareness states. Presence Teleoper Virtual Environ 12(3):296–310" href="/article/10.1007/s10055-018-0346-3#ref-CR34" id="ref-link-section-d42203e695">2003</a>) examined accuracy and confidence levels associated with recall and cognitive awareness in a room filled with objects such as pyramids, spheres, and cubes. Participants were exposed to one of the following scenarios: (a) a virtual room using a HMD, (b) a rendered room on a desktop, or (c) a real room experienced through glasses designed to restrict the field of view to <span class="mathjax-tex">\(30^{\circ }\)</span> to match that of the HMD and desktop. All the four walls of the room were distinct. After 3 min of exposure, the participants were given a paper containing a representation of the room which included numbered positions of objects in the various locations. The participants were asked to recall which objects were present and where they were located in the room, and to give a confidence and awareness state with each answer. The study evaluated the participants immediately after the exposure and then again after one week. The study found that immediately after the exposure the participants had the most accurate recall in the real-world scene and were slightly less accurate and confident in the HMD and least accurate and confident on the desktop. After one week, the overall scores and confidence levels dropped consistently across the board, with the viewing condition having no effect on the relative reduction in performance. In this inspirational study, the participants only experienced one display. In our study, the participants were exposed to both the desktop and the HMD. This makes it possible to compare recall for the same user across the two display modalities. Further, to use the context provided by immersion, the participants in our study were asked to recall the information while viewing the same virtual scenes on the same display, rather than recording their answers on a representation of the scene on paper.</p><p>
Harman et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Harman J, Brown R, Johnson D (2017) Improved memory elicitation in virtual reality: new experimental results and insights. In: IFIP conference on human–computer interaction, Springer, pp 128–146" href="/article/10.1007/s10055-018-0346-3#ref-CR20" id="ref-link-section-d42203e725">2017</a>) explored immersive virtual environments for memory recall by having participants take on the role of a boarding an airplane in a virtual airport. After the experience, the participants were asked about the tasks they performed. The participants who experienced the virtual airport in a HMD had more accurate recall than those who used the desktop. In this study, each participant used either a HMD or a desktop. Also, the evaluation of the memory recall was done outside of the visual experience, through a questionnaire. In our study, not only do participants experience the virtual environment in both, HMD and desktop, but are also asked to recall in the same environment in which they experienced the information.</p><h3 class="c-article__sub-heading" id="Sec6">Embodied interaction and recall</h3><p>Virtual walk-throughs have been one of the earliest applications of virtual worlds (Brooks Jr et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Brooks FP Jr, Airey J, Alspaugh J, Bell A, Brown R, Hill C, Nimscheck U, Rheingans P, Rohlf J, Smith D, Turner D, Varshney A, Wang Y, Weber H, Yuan X (1992) Six generations of building walkthrough: final technical report to the National Science Foundation TR92-026, Department of Computer Science. University of North Carolina at Chapel Hill" href="/article/10.1007/s10055-018-0346-3#ref-CR10" id="ref-link-section-d42203e736">1992</a>). Brooks (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Brooks BM (1999) The specificity of memory enhancement during interaction with a virtual environment. Memory 7(1):65–78" href="/article/10.1007/s10055-018-0346-3#ref-CR9" id="ref-link-section-d42203e739">1999</a>) studied whether active participants had superior recall of the layout of a 3D virtual house on a desktop compared to passive participants. Active participants controlled camera navigation via a joystick, while passive participants observed the navigation. They found that active participants had a superior environment layout recall compared to those who were passive. However, they also found that there was no statistically significant difference between the recall or recognition of objects (such as furniture or entrances and exits of a room) or their positions within the environment between the active and passive participants. This suggests that memory was only enhanced for those aspects of the environment that were interacted with directly—particularly the environment which was navigated.</p><p>
Richardson et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Richardson AE, Montello DR, Hegarty M (1999) Spatial knowledge acquisition from maps and from navigation in real and virtual environments. Mem Cognit 27(4):741–750" href="/article/10.1007/s10055-018-0346-3#ref-CR45" id="ref-link-section-d42203e745">1999</a>) had users learn the layout of a complex building through either 2D maps, physically walking through the real building, or through a 3D virtual representation of that building built using the Doom II engine and shown on a desktop. The study found that when the building was a single floor, the real-world and virtual-environment-trained users had comparable results. However, when the building had two floors, relative view orientation during learning and testing mattered. If the participants were in the same orientation that they had used during learning, they were able to navigate the environment just as well as those who were physically in the environment. However, participants were susceptible to disorientation if their starting-out views were different between their training and testing. The authors concluded that training in the virtual and real-world environments likely used similar cognitive mechanisms.</p><p>
Wraga et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Wraga M, Creem-Regehr SH, Proffitt DR (2004) Spatial updating of virtual displays. Mem Cognit 32(3):399–415" href="/article/10.1007/s10055-018-0346-3#ref-CR53" id="ref-link-section-d42203e751">2004</a>) compared the effectiveness of vestibular and proprioceptive rotations in assisting recall by having participants recall on which of the four walls was a object located relative to their orientation before and after rotation. Participants were placed in a virtual room with four distinctly colored alcoves on four walls and given time to learn and recognize the alcoves. Participants would then rotate, either using the HMD accelerometer or a joystick, to find a certain object on one of the alcoves as described by the tester. Once the user was looking at that object on one of the alcoves, their view would be frozen and the tester would ask the participant to state where a particular (different) alcove was relative to their orientation. They found that users in a HMD were better able to keep track of the objects by rotating their heads as compared to using a joystick. In another experiment, the authors also found that users in a HMD who controlled their bearing in a virtual world by actively rotating in a swivel chair were better able to keep track of an object than those that were being rotated by a tester. In our study, we expect vestibular and proprioceptive inputs to improve performance in the HMD. We study how well people can recall information regardless of their orientation. In addition, our objects are distributed in more than four unique locations.</p><p>
Perrault et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Perrault ST, Lecolinet E, Bourse YP, Zhao S, Guiard Y (2015) Physical loci: leveraging spatial, object and semantic memory for command selection. In: Proceedings of the 33rd annual ACM conference on human factors in computing systems, CHI ’15, pp 299–308" href="/article/10.1007/s10055-018-0346-3#ref-CR42" id="ref-link-section-d42203e757">2015</a>) leveraged the method of loci technique by allowing participants to link gestural commands, which would control some system, to physical objects within a real room. They compared their interaction technique to a mid-air swipe menu which relies on directional swiping gestures. Their idea was to leverage spatial, object, and semantic memory to help users learn and recall a large number of gestures and commands. In a home environment, participants were shown a command (or stimulus) on a television and then performed a motion that a Microsoft Kinect would track and record as representing that command. For the mid-air swipe, the participant would perform a 2-segment marking menu gesture. For the physical loci, the participant would simply point at an object in the environment that they wanted associated with the command, such as a chair or poster. Once the gestures and physical loci were trained, the participants went into the recall phase. In this phase, a command would be presented on the screen and the user had to quickly and accurately perform the corresponding gesture. The system would then show whether the participant performed the correct gesture or pointed at the correct loci object that they originally assigned for that command. The authors found that users, when using their physical loci technique, had superior command recall and were more robust compared to the more traditional mid-air swipe menu.</p></div></div></section><section aria-labelledby="Sec7"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7">Method</h2><div class="c-article-section__content" id="Sec7-content"><p>A memory palace is a spatial mnemonic technique where information is associated with different aspects of the imagined environment, such as people, objects, or rooms, to assist in their recall (Yates <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Yates FA (1992) The art of memory, vol 64. Random House, New York" href="/article/10.1007/s10055-018-0346-3#ref-CR54" id="ref-link-section-d42203e769">1992</a>; Harman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Harman J (2001) Creating a memory palace using a computer. In: CHI ’01 extended abstracts on human factors in computing systems, pp 407–408" href="/article/10.1007/s10055-018-0346-3#ref-CR19" id="ref-link-section-d42203e772">2001</a>). The goal of our user study was to examine whether a virtual memory palace, experienced immersively in a head-tracked stereoscopic HMD, can assist in recall better than a mouse-based interaction on a traditional, non-immersive, monoscopic desktop display. Previous work has examined the role of spatial organization, immersion, and interaction in assisting recall.</p><p>This study is different from the previous work in several ways. First, we are focusing on spatial memory using a 3D model of a virtual memory palace, rather than relying on other forms of memory (such as temporal/episodic). Second, both the training and testing (recall) phases take place within the same virtual memory palace. Third, participants used both the desktop and HMD displays, which allows us to compare each participant’s recall across displays. Lastly, the content used in previous studies was either abstract, verbal, textual, visually simplistic, low in diversity, or time based, whereas our study uses faces, with unique and diverse characteristics.</p><h3 class="c-article__sub-heading" id="Sec8">Participants</h3><p>Our user study for this research was carried out under IRB ID 751321-1 approved on August 7, 2015, by the University of Maryland College Park IRB board. In this study, we recruited 40 participants, 30 male and 10 female, from our campus and surrounding community. Each participant had normal or corrected-to-normal vision (self reported). The study session for each participant lasted around 45 min.</p><h3 class="c-article__sub-heading" id="Sec9">Materials</h3><p>For this study, we used a traditional desktop with a 30 inch (76.2) cm—diagonal monitor and an Oculus DK2 HMD. The rendering for the desktop was configured to match that of the Oculus with a resolution of <span class="mathjax-tex">\(1920 \times 1080\)</span> pixels (across the two eyes) with a rendering field of view (FOV) of <span class="mathjax-tex">\(100^{\circ }\)</span>. In order to give the desktop display the same field of view as the HMD, the participants were positioned with their heads 10 inches (25.4 cm) away from the monitor. The software used to render the 3D environments on both the desktop and HMD was identical and was designed in-house using C++ and OpenGL-accelerated rendering. The rendering was designed to replicate a realistic looking environment as closely as possible, incorporating realistic lighting, shadows, and textures. The models (the medieval town and palace) were purchased through the 3D modeling distribution Web site TurboSquid (3DMarko <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="3DMarko (2011) Medieval town 01 Dubrovnik. &#xA;                    https://www.turbosquid.com/FullPreview/Index.cfm/ID/632415&#xA;                    &#xA;                  . Retrieved 10 May 2018" href="/article/10.1007/s10055-018-0346-3#ref-CR1" id="ref-link-section-d42203e843">2011</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="3DMarko (2014) Palace interior 02. &#xA;                    https://www.turbosquid.com/FullPreview/Index.cfm/ID/809577&#xA;                    &#xA;                  . Retrieved 10 May 2018" href="/article/10.1007/s10055-018-0346-3#ref-CR2" id="ref-link-section-d42203e846">2014</a>).</p><h3 class="c-article__sub-heading" id="Sec10">Design</h3><p>The participants were shown two scenes, on two display conditions (head-tracked HMD and a mouse-based interaction desktop), and two sets of faces (within-subject design), all treated as independent variables, with the measured accuracy of recall as the dependent variable. The two scenes (virtual memory palaces) consist of pre-constructed palace and medieval town environments filled with faces. We decided to use faces given the previous work (Harris <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1980" title="Harris JE (1980) Memory aids people use: two interview studies. Mem Cogn 8(1):31–38" href="/article/10.1007/s10055-018-0346-3#ref-CR21" id="ref-link-section-d42203e858">1980</a>; McCabe <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="McCabe JA (2015) Location, location, location! Demonstrating the mnemonic benefit of the method of loci. Teach Psychol 42(2):169–173" href="/article/10.1007/s10055-018-0346-3#ref-CR36" id="ref-link-section-d42203e861">2015</a>) showing the effectiveness of memory palaces aiding users in recalling face-name pairs. We used faces as the objects to be memorized and carefully partitioned them into two sets of roughly equal familiarity. We quantified the familiarity of the faces using Google trends data over the four months preceding the study. The faces are shown in “Appendix” (at the very end of the paper) in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig11">11</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig12">12</a>, and the Google trends statistics are presented in Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0346-3#Tab1">1</a> and <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0346-3#Tab2">2</a>. There was no statistically significant difference between the two sets of Google trends data: <span class="mathjax-tex">\(p = 0.45 &gt; 0.05\)</span>.</p><p>The faces in the palace and medieval town were hand positioned for each environment, before the start of the study, and remained consistent throughout the study. We distributed the faces at varying distances from the users’ location (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig2">2</a>) so that they surrounded and faced the user. Since we used perspective projection, the sizes of the faces varied. However, the distribution of the angular resolution of the faces across the two sets/environments was not statistically different, with <span class="mathjax-tex">\(p = 0.44 &gt; 0.05\)</span> (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0346-3#Tab3">3</a> in “Appendix”).</p><p>Users were allowed to freely rotate their view but not translate. This effectively simulated a stereoscopic spherical panoramic image with the participant at its center. Our motivation behind this study design decision was that if even this limited level of immersion could show an improvement in recall, it could lead to a better-informed exploration of how greater levels of immersion relate to varying levels of recall.</p><h3 class="c-article__sub-heading" id="Sec11">Procedure</h3><p>First, each participant familiarized themselves with all the 42 faces and their names used in the study. The participants received a randomly permuted collection of printouts, each containing a face-name pair used in the study. Participants were given as much time as needed until they stated when they were comfortable with the faces. In general, participants did not spend more than 5 min on this familiarization.</p><p>Next, each participant was told about the training and testing procedure, including how many faces were going to be in each scene (21), how much time they had to view the faces (5 min), how the breaks would work, that the faces would be replaced with numbers in the recall phase, and that they were to give a name and confidence for their recalled faces for each numbered position. In almost every case, we recorded the answer as the name explicitly recalled by the participant. However, in rare, exceptional circumstances, when the participants gave an extremely detailed and unambiguous description of the face (“fat, wore a wig, was King of France, and is not Napoleon” for King Louis), we marked it correct. Next, each participant was placed either in front of a desktop monitor with a mouse or inside a head-tracked stereoscopic HMD. They were given as much time as they desired to get comfortable, looking around the scene without numbers or faces. The users rotated the scene on a desktop monitor with a mouse, and in the HMD setup they rotated their head and body, but no further navigation was possible.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig2_HTML.jpg" alt="figure2" loading="lazy" width="685" height="1247" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Locations of faces and numbers in the virtual memory palaces used in our user study <b>a</b> an ornate palace and <b>b</b> a medieval town. Note that this is not the view the participants had during the experiment, and these pictures are used to convey the distribution of the face locations. The participants would have been placed in the middle of these scenes surrounded by the faces as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig3">3</a></p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Once each participant was comfortable with the setup and the controls, a set of 21 faces were added to the 3D scene and distributed around the entire space as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig2">2</a>. We used two such scenes—a palace and a medieval town, shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig3">3</a>. The faces were divided into two consistent sets used for the whole study; if a face appeared in one set (or scene) for a given participant, it would not be shown again in the second set or scene.</p><p>To cover all possible treatments of the <span class="mathjax-tex">\(2 \times 2 \times 2\)</span> Latin-square design, each participant was tested in both scenes, both display conditions (HMD and desktop), and both sets of faces, with their relative ordering counterbalanced across participants. The 21 faces within the scene were presented to the participants all at once, and the participants were able to view and memorize the faces in any order of their choosing. The faces were deterministically placed in the same order for all participants. However, since the participants were free to look in any direction, the order of presentation of faces was self-determined. Each participant was given 5 min to memorize the faces and their locations within the scene. After the 5-min period, the display went blank and each participant was given a 2-min break in which they were asked a series of questions. Questions we asked included how each participant learned about the study, what their profession/major was, and what were their general hobbies or interests. In the second half of the study, during the break for the alternative display, we asked how often a participant used a computer, what their previous experience was with VR, and their general impressions of VR. We consistently asked these questions of each participant, but did not record the responses.</p><p>The reasons for these study design decisions are rooted in foundational research in psychology on memory. From the seminal work by Miller (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1956" title="Miller GA (1956) The magical number seven, plus or minus two: some limits on our capacity for processing information. Psychol Rev 63(2):81" href="/article/10.1007/s10055-018-0346-3#ref-CR37" id="ref-link-section-d42203e1032">1956</a>), we learn that the working memory (Baddeley and Hitch <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1974" title="Baddeley AD, Hitch G (1974) Working memory. Psychol Learn Motiv 8:47–89" href="/article/10.1007/s10055-018-0346-3#ref-CR4" id="ref-link-section-d42203e1035">1974</a>) can only retain <span class="mathjax-tex">\(7 \pm 2\)</span> items. According to Atkinson and Shiffrin (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1968" title="Atkinson RC, Shiffrin RM (1968) Human memory: a proposed system and its control processes. Psychol Learn Motiv 2:89–195" href="/article/10.1007/s10055-018-0346-3#ref-CR3" id="ref-link-section-d42203e1064">1968</a>), the information in the short-term memory decays and is lost within a period of 15–30 s. We feel confident that having participants recall 21 faces after a 2-min break will engage their long-term memory.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig3_HTML.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig3_HTML.jpg" alt="figure3" loading="lazy" width="685" height="1243" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>The two virtual memory palace scenes used in our user study <b>a</b> an ornate palace and <b>b</b> a medieval town, as seen from the view of the participants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig4_HTML.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig4_HTML.jpg" alt="figure4" loading="lazy" width="685" height="614" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Virtual memory palace: recall phase</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>After the 2-min break, the scene would reappear on the display with numbers having replaced the faces, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig4">4</a>. Each participant was then asked to recall, in any order, which face had been at each numbered location. During this recall phase, each participant could look around and explore the scene just as they did in the training phase, using the mouse on the desktop or rotating their head-tracked HMD. Each participant had up to 5 min to recall the names of all the faces in the scene. Once the participant was confident in all their answers, or the 5-min period had passed, the testing phase ended. After a break, each participant was placed in the other display that they had not previously tested with. The process was then repeated with a different scene and a different set of 21 faces to avoid information overlap from the previous test.</p><p>For each numbered location in the scene, the participants verbally recalled the name of the face at that location, as well as a confidence rating for their answer, ranging from 1 to 10, with 10 being certain. If a participant had no answer for a location, it was given a score of 0. The results were hand-recorded by the study administrator, keeping track of the number, name, user confidence, and any changes in a previously given answer.</p><p>To mitigate any learning behavior from the first trial to the second, we employed a within-subject trial structure, using a 2 (HMD-condition to desktop-condition vs desktop-condition to HMD-condition) × 2 (Scene 1 vs Scene 2 ) × 2 (Face Set 1 vs Face Set 2) Latin-square design. By alternating between the displays shown first (2), the scenes (2), and the faces (2), we expect to mitigate any confounding effects. At the end, each participant was tested on the two display conditions, desktop and HMD, on two different scenes, and with two different sets of 21 faces. We note that participants could have used personal mnemonics to help remember the locations and ordering of faces. However, since we evaluated recall for each participant over a desktop and a HMD, their performance should be counterbalanced between the two display conditions.</p></div></div></section><section aria-labelledby="Sec12"><div class="c-article-section" id="Sec12-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec12">Results</h2><div class="c-article-section__content" id="Sec12-content"><p>Our hypothesis is that a virtual memory palace experienced in an immersive head-tracked HMD (the HMD condition) will lead to a more accurate recall than on a mouse-controlled desktop display (the desktop condition). In addition, we hypothesized that participants should be more confident in their answers in the headset and make fewer mistakes or errors in recall. Our null hypothesis is that there is no statistical difference between the accuracy and confidence of results between the HMD and desktop conditions and that there is no statistical difference in the ordering of the display conditions.</p><p>We confirmed using a four-way mixed ANOVA that there were no statistically significant effects on recall due to the scenes (palace and town) <span class="mathjax-tex">\(F(1,79)=0.27, p &gt; 0.05\)</span>, the two sets of 21 faces <span class="mathjax-tex">\(F(1,79)=0.27, p&gt; 0.05\)</span>, or the ordering of display conditions (HMD followed by desktop vs desktop followed by HMD) <span class="mathjax-tex">\(F(1,79) = 1.93, p &gt; 0.05\)</span>. We found that there was a statistically significant effect for the display condition (HMD vs desktop) with <span class="mathjax-tex">\(F(1,79)=4.6\)</span> and <span class="mathjax-tex">\(p&lt;0.05\)</span>. This means participants were able to recall better in the HMD condition as compared to the desktop condition, permitting us to reject the null hypothesis.</p><h3 class="c-article__sub-heading" id="Sec13">Task performance</h3><p>The overall average recall performance of participants in the HMD condition was 8.8% higher compared to the desktop condition with the mean recall accuracy percentage for HMD condition at 84.05% and the desktop condition at 75.24%. Using a paired t test with Bonferroni–Holm correction, we calculated <span class="mathjax-tex">\(p = 0.0017 &lt; 0.05\)</span> which shows that our result was statistically significant. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig5">5</a>, we present the overall performance of the users in the HMD condition as compared to the desktop condition.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig5_HTML.png?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig5_HTML.png" alt="figure5" loading="lazy" width="685" height="398" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>The overall average recall performance of participants in the HMD condition was 8.8% higher compared to the desktop condition. The median recall accuracy percentage for HMD was 90.48% and for desktop display was 78.57%. The figure shows the first and third quartiles for each display modality</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec14">Errors and skips</h3><p>The recall accuracy measures the number of correct answers. In addition, we kept track of when participants in our user studies made an error in recall (i.e., gave an incorrect answer) or skipped answering (i.e., did not provide an answer). We show the percentile distribution of the average number of erroneous answers per participant for each display modality in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig6">6</a>. Participants in the HMD condition made on average fewer errors than those in the desktop condition. The total number of errors in the HMD condition for 40 people was 33 out of 840, and in the desktop condition it was 56 out of 840. In addition, the difference in the incorrect answers was statistically significant, shown using a paired t test with Bonferroni–Holm correction resulting in <span class="mathjax-tex">\(p=0.0195 &lt; 0.05\)</span>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig6_HTML.png?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig6_HTML.png" alt="figure6" loading="lazy" width="685" height="371" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>The distribution of incorrect answers for each display modality showing the median, first, and third quartiles</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig7">7</a>, we showed that the number of faces for which participants skipped an answer in the desktop condition was significantly higher than in the HMD condition. This was shown to be statistically significant using a paired t test with Bonferroni–Holm correction with <span class="mathjax-tex">\(p=0.0062 &lt; 0.05\)</span>, which reinforces that participants in the HMD had better recall than those on the desktop.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig7_HTML.png?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig7_HTML.png" alt="figure7" loading="lazy" width="685" height="370" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>The distribution of faces skipped during recall for each display modality showing the median, first, and third quartiles</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec15">Confidence</h3><p>Previous work by (Mania and Chalmers <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Mania K, Chalmers A (2001) The effects of levels of immersion on memory and presence in virtual environments: a reality centered approach. CyberPsychol Behav 4(2):247–264" href="/article/10.1007/s10055-018-0346-3#ref-CR33" id="ref-link-section-d42203e1518">2001</a>; Mania et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Mania K, Troscianko T, Hawkes R, Chalmers A (2003) Fidelity metrics for virtual environment simulations based on spatial memory awareness states. Presence Teleoper Virtual Environ 12(3):296–310" href="/article/10.1007/s10055-018-0346-3#ref-CR34" id="ref-link-section-d42203e1521">2003</a>) examined user confidence with recall accuracy. This allows us to study not only the objective recall accuracy but also the subjective certainty of the user answers. We asked each participant to indicate their confidence on a scale of 1–10, with 10 being certain, as a measure of how certain they were in the correctness of their response, for each answer. The confidence scores aggregated across all the 40 participants and all the 42 faces that each studied are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig8">8</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig8_HTML.png?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig8_HTML.png" alt="figure8" loading="lazy" width="685" height="385" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>The overall confidence scores of participants in the HMD condition and the desktop condition. Each participant gave a confidence score between 1 and 10 for each face they recalled. Those in the HMD condition are slightly more confident about their answers than those in the desktop condition</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>From Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig8">8</a>, we can see that users were slightly more confident in the HMD condition than on the desktop condition. The average confidence values for the HMD and desktop conditions were 9.4 and 9.1 respectively, ignoring skips. For the highest confidence, a confidence score equal to 10, there was a statistical difference between the number of correct answers given in the HMD and the desktop conditions, with <span class="mathjax-tex">\(p = 0.009 &lt; 0.05\)</span> using a Chi-square test, and with <span class="mathjax-tex">\(p=0.022 &lt; 0.05\)</span> including Yates community correction. However, confidence is not always an indication of correctness. We wanted to see whether the HMD condition was giving a false sense of confidence. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig9">9</a> shows the number of errors given in each display based on the confidence of participant answers.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig9_HTML.png?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig9_HTML.png" alt="figure9" loading="lazy" width="685" height="378" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>The number of errors made for each display condition for various confidence levels</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>The results in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig9">9</a> show that when the users were less error-prone in the HMD condition, their confidence was better-grounded in the recall accuracy than when in the desktop condition. In general, participants were more often correct in the HMD condition than for the desktop condition for a given confidence level.</p><h3 class="c-article__sub-heading" id="Sec16">Ordering effect</h3><p>In our study, we alternated the order in which participants were exposed to the displays. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig10">10</a> shows the accuracy when using the desktop first followed by the HMD versus using the HMD first and then the desktop.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig10_HTML.png?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig10_HTML.png" alt="figure10" loading="lazy" width="685" height="389" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>The performance of participants going from a desktop to a HMD and from a HMD to a desktop, showing the median, first and third quartiles</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>For both the desktop and HMD conditions, users started with roughly the same performance (accuracy) on both the desktop and HMD (desktop-1 and HMD-1 in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0346-3#Fig10">10</a>), but when going to the other display, the performance changed. When users went from a desktop to a HMD, their performance generally improved. However, when the users went from a HMD to a desktop, their performance surprisingly decreased. When comparing each participant’s first trials, the desktop-1 and HMD-1, their distribution of recall scores was not significantly different with <span class="mathjax-tex">\(p = 0.62 &gt; 0.05\)</span>, but they were for the second trials, the HMD-2 and desktop-2, with <span class="mathjax-tex">\(p = 0.025 &lt; 0.05\)</span>.</p></div></div></section><section aria-labelledby="Sec17"><div class="c-article-section" id="Sec17-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec17">Discussion</h2><div class="c-article-section__content" id="Sec17-content"><p>We next report some interesting observations based on a questionnaire the participants filled out after the study. All our participants were expert desktop users, but almost none had experienced a HMD before. We believe that if there were to be any implicit advantage, it would lie with the desktop, given the overall familiarity with it. Although we gave the participants enough time to get comfortable in the HMD before we began the study, we observed that many were not fully accustomed to the HMD, even though they performed better in it. We asked each participant which display they preferred for the given task of recall. We explicitly stated that their decision should not be based on the novelty or “coolness” of the display or the experience. All but two of the 40 participants stated they preferred the HMD for this task. They further stated that they felt more immersed in the scene and so were more focused on the task. In addition, a majority of the users (70%) reported that HMD afforded them a superior sense of the spatial awareness which they claimed was important to their success. Approximately a third mentioned that they actively used the virtual memory palace setup by associating the information relative to their own body. This ability to associate information with the spatial context around the body only adds to the benefit of increased immersion afforded by the HMD.</p><p>We note the interesting results we obtained with the display ordering. When starting with the desktop and then using the HMD, we observed a significant improvement as compared to starting with the HMD and then using the desktop. A possible explanation for this could be that those who used the HMD first are able to benefit from the HMD’s superior immersion, which they lose when they transfer to the desktop. However, when the users start on the desktop they invest a greater effort to memorize the information and therefore when they transfer to the HMD, they not only keep their dedication but also gain from the improved immersion.</p><h3 class="c-article__sub-heading" id="Sec18">Study limitations</h3><p>In general, it is a difficult design decision to balance the goals of experimental control and ecological validity. In our study, we placed the faces for a particular face set in the same locations for all participants. However, since the participants were free to look in any direction, the order of presentation of faces was self-determined. We could have restricted the participants to look at the faces in a predetermined order. However, we allowed the participants to look around freely, so that the results would achieve greater ecological validity. Randomization of faces could have led to unintended consequences; having the Dalai Lama’s face next to Abraham Lincoln’s in one instantiation could alter its memorability, as could the opportune positioning of the Dalai Lama on a roof-top background. To avoid such inter-object semantic saliency confounds, we decided to preserve the same ordering of faces for all participants that viewed the scene with a given set of faces. We recognize that not randomizing the stimuli in a within-subject design could introduce a bias. To make sure that this did not result in any significant effects, we carried out a four-way mixed ANOVA (reported at the beginning of Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0346-3#Sec12">4</a>) and we did not find any statistically significant effects on recall due to the scenes, face sets, or the ordering of the display conditions. Previous research, such as Loomis et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Loomis JM, Blascovich JJ, Beall AC (1999) Immersive virtual environment technology as a basic research tool in psychology. Behav Res Methods Instrum Comput 31(4):557–564" href="/article/10.1007/s10055-018-0346-3#ref-CR31" id="ref-link-section-d42203e1752">1999</a>), points out the trade-offs between experimental control and ecological validity for virtual environments. Parsons (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Parsons TD (2015) Virtual reality for enhanced ecological validity and experimental control in the clinical, affective and social neurosciences. Front Hum Neurosci 9:660" href="/article/10.1007/s10055-018-0346-3#ref-CR40" id="ref-link-section-d42203e1755">2015</a>) persuasively argues for designing virtual environment studies that strike a balance between naturalistic observation and the need for exacting control over variables.</p><p>The modality of interactive exploration of the virtual environment in the two conditions was different (head tracking versus mouse tracking). Thus, differences in the recall performance may be explained by this diverse interaction modality. Our study did not attempt to distinguish the role of proprioceptive and vestibular information from visual stimuli, but examined them in the respective contexts of immersive HMD and desktop display conditions. It will be interesting to examine the relative advantage of the diverse interaction modalities with the same display modality, in future user studies.</p><h3 class="c-article__sub-heading" id="Sec19">Conclusions</h3><p>We found that the use of virtual memory palaces in HMD condition improves recall accuracy when compared to using a traditional desktop condition. We had 40 participants memorize and recall faces on two display–interaction modalities for two virtual memory palaces, with two different sets of faces. The HMD condition was found to have 8.8% improvement in recall accuracy compared to the desktop condition, and this was found to be statistically significant. This suggests an exciting opportunity for the role of immersive virtual environments in assisting in recall. Given the results of our user study, we believe that virtual memory palaces offer us a fascinating insight into how we may be able to organize and structure large information spaces and navigate them in ways that assist in superior recall.</p><p>One of the strengths of virtual reality is the experience of <i>presence</i> through immersion that it provides (Sanchez-Vives and Slater <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Sanchez-Vives MV, Slater M (2005) From presence to consciousness through virtual reality. Nat Rev Neurosci 6(4):332–339" href="/article/10.1007/s10055-018-0346-3#ref-CR48" id="ref-link-section-d42203e1775">2005</a>; Skarbez et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Skarbez R, Brooks FP Jr, Whitton MC (2017) A survey of presence and related concepts. ACM Comput Surv 50(6):96:1–96:39. &#xA;                    https://doi.org/10.1145/3134301&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0346-3#ref-CR50" id="ref-link-section-d42203e1778">2017</a>). If memory recall could be enhanced through immersively experiencing the environment in which the information was learned, it would suggest that virtual environments could serve as a valuable tool for various facets of retrospective cognizance, including retention and recall.</p><h3 class="c-article__sub-heading" id="Sec20">Future work</h3><p>Our study provides a tantalizing glimpse into what may lie ahead in virtual-environment-based tools to enhance human memory. The next steps will be to identify and characterize what elements of virtual memory palaces are most effective in eliciting a superior information recall. At present, we have only studied the effect of in-place stereoscopic immersion, in which the participants were allowed to freely rotate their viewpoint but not translate. It will be valuable to study how the addition of translation impacts information recall in a virtual memory palace.</p><p>Other directions of future studies could include elements in the architecture of the virtual memory palaces such as their design, the visual saliency of the structure of model (Kim et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Kim Y, Varshney A, Jacobs DW, Guimbretière F (2010) Mesh saliency and human eye fixations. ACM Trans Appl Percept (TAP) 7(2):12" href="/article/10.1007/s10055-018-0346-3#ref-CR26" id="ref-link-section-d42203e1793">2010</a>), their type, and various kinds of layouts and distribution of content that could help with recall. Another interesting future work would be to allow people to build their own virtual memory palaces, manipulate and organize the content on their own, and then ask them to recall that information. If their active participation in the organization of the data in virtual memory palaces makes a meaningful difference, then that could be further useful in designing interaction-based virtual environments that could one day assist in far superior information management and recall tools than those currently available to us. Yet another interesting future direction of research could be to compare elements of virtual memory palaces that are highly personal versus those that could be used by larger groups. Much as textbooks and videos are used today for knowledge dissemination, it could be possible for virtual memory palaces to be used one day for effective transfer of mnemonic devices among humans in virtual environments.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="3DMarko (2011) Medieval town 01 Dubrovnik. https://www.turbosquid.com/FullPreview/Index.cfm/ID/632415. Retriev" /><p class="c-article-references__text" id="ref-CR1">3DMarko (2011) Medieval town 01 Dubrovnik. <a href="https://www.turbosquid.com/FullPreview/Index.cfm/ID/632415">https://www.turbosquid.com/FullPreview/Index.cfm/ID/632415</a>. Retrieved 10 May 2018</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="3DMarko (2014) Palace interior 02. https://www.turbosquid.com/FullPreview/Index.cfm/ID/809577. Retrieved 10 Ma" /><p class="c-article-references__text" id="ref-CR2">3DMarko (2014) Palace interior 02. <a href="https://www.turbosquid.com/FullPreview/Index.cfm/ID/809577">https://www.turbosquid.com/FullPreview/Index.cfm/ID/809577</a>. Retrieved 10 May 2018</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RC. Atkinson, RM. Shiffrin, " /><meta itemprop="datePublished" content="1968" /><meta itemprop="headline" content="Atkinson RC, Shiffrin RM (1968) Human memory: a proposed system and its control processes. Psychol Learn Motiv" /><p class="c-article-references__text" id="ref-CR3">Atkinson RC, Shiffrin RM (1968) Human memory: a proposed system and its control processes. Psychol Learn Motiv 2:89–195</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0079-7421%2808%2960422-3" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20memory%3A%20a%20proposed%20system%20and%20its%20control%20processes&amp;journal=Psychol%20Learn%20Motiv&amp;volume=2&amp;pages=89-195&amp;publication_year=1968&amp;author=Atkinson%2CRC&amp;author=Shiffrin%2CRM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AD. Baddeley, G. Hitch, " /><meta itemprop="datePublished" content="1974" /><meta itemprop="headline" content="Baddeley AD, Hitch G (1974) Working memory. Psychol Learn Motiv 8:47–89" /><p class="c-article-references__text" id="ref-CR4">Baddeley AD, Hitch G (1974) Working memory. Psychol Learn Motiv 8:47–89</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0079-7421%2808%2960452-1" aria-label="View reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Working%20memory&amp;journal=Psychol%20Learn%20Motiv&amp;volume=8&amp;pages=47-89&amp;publication_year=1974&amp;author=Baddeley%2CAD&amp;author=Hitch%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Barry, C. Lever, R. Hayman, T. Hartley, S. Burton, J. O’Keefe, K. Jeffery, N. Burgess, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Barry C, Lever C, Hayman R, Hartley T, Burton S, O’Keefe J, Jeffery K, Burgess N (2006) The boundary vector ce" /><p class="c-article-references__text" id="ref-CR5">Barry C, Lever C, Hayman R, Hartley T, Burton S, O’Keefe J, Jeffery K, Burgess N (2006) The boundary vector cell model of place cell firing and spatial memory. Rev Neurosci 17(1–2):71–98</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20boundary%20vector%20cell%20model%20of%20place%20cell%20firing%20and%20spatial%20memory&amp;journal=Rev%20Neurosci&amp;volume=17&amp;issue=1%E2%80%932&amp;pages=71-98&amp;publication_year=2006&amp;author=Barry%2CC&amp;author=Lever%2CC&amp;author=Hayman%2CR&amp;author=Hartley%2CT&amp;author=Burton%2CS&amp;author=O%E2%80%99Keefe%2CJ&amp;author=Jeffery%2CK&amp;author=Burgess%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="LW. Barsalou, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Barsalou LW (2008) Grounded cognition. Annu Rev Psychol 59:617–645" /><p class="c-article-references__text" id="ref-CR6">Barsalou LW (2008) Grounded cognition. Annu Rev Psychol 59:617–645</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1146%2Fannurev.psych.59.103006.093639" aria-label="View reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Grounded%20cognition&amp;journal=Annu%20Rev%20Psychol&amp;volume=59&amp;pages=617-645&amp;publication_year=2008&amp;author=Barsalou%2CLW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="O. Baumann, JB. Mattingley, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Baumann O, Mattingley JB (2010) Medial parietal cortex encodes perceived heading direction in humans. J Neuros" /><p class="c-article-references__text" id="ref-CR7">Baumann O, Mattingley JB (2010) Medial parietal cortex encodes perceived heading direction in humans. J Neurosci 30(39):12,897–12,901</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1523%2FJNEUROSCI.3077-10.2010" aria-label="View reference 7">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Medial%20parietal%20cortex%20encodes%20perceived%20heading%20direction%20in%20humans&amp;journal=J%20Neurosci&amp;volume=30&amp;issue=39&amp;pages=12%2C897-12%2C901&amp;publication_year=2010&amp;author=Baumann%2CO&amp;author=Mattingley%2CJB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DA. Bowman, RP. McMahan, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Bowman DA, McMahan RP (2007) Virtual reality: how much immersion is enough? Computer 40(7):36–43" /><p class="c-article-references__text" id="ref-CR8">Bowman DA, McMahan RP (2007) Virtual reality: how much immersion is enough? Computer 40(7):36–43</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FMC.2007.257" aria-label="View reference 8">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%3A%20how%20much%20immersion%20is%20enough%3F&amp;journal=Computer&amp;volume=40&amp;issue=7&amp;pages=36-43&amp;publication_year=2007&amp;author=Bowman%2CDA&amp;author=McMahan%2CRP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="BM. Brooks, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Brooks BM (1999) The specificity of memory enhancement during interaction with a virtual environment. Memory 7" /><p class="c-article-references__text" id="ref-CR9">Brooks BM (1999) The specificity of memory enhancement during interaction with a virtual environment. Memory 7(1):65–78</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F741943713" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20specificity%20of%20memory%20enhancement%20during%20interaction%20with%20a%20virtual%20environment&amp;journal=Memory&amp;volume=7&amp;issue=1&amp;pages=65-78&amp;publication_year=1999&amp;author=Brooks%2CBM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Brooks FP Jr, Airey J, Alspaugh J, Bell A, Brown R, Hill C, Nimscheck U, Rheingans P, Rohlf J, Smith D, Turner" /><p class="c-article-references__text" id="ref-CR10">Brooks FP Jr, Airey J, Alspaugh J, Bell A, Brown R, Hill C, Nimscheck U, Rheingans P, Rohlf J, Smith D, Turner D, Varshney A, Wang Y, Weber H, Yuan X (1992) Six generations of building walkthrough: final technical report to the National Science Foundation TR92-026, Department of Computer Science. University of North Carolina at Chapel Hill</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MW. Brown, JP. Aggleton, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Brown MW, Aggleton JP (2001) Recognition memory: what are the roles of the perirhinal cortex and hippocampus? " /><p class="c-article-references__text" id="ref-CR11">Brown MW, Aggleton JP (2001) Recognition memory: what are the roles of the perirhinal cortex and hippocampus? Nat Rev Neurosci 2(1):51–61</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1038%2F35049064" aria-label="View reference 11">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Recognition%20memory%3A%20what%20are%20the%20roles%20of%20the%20perirhinal%20cortex%20and%20hippocampus%3F&amp;journal=Nat%20Rev%20Neurosci&amp;volume=2&amp;issue=1&amp;pages=51-61&amp;publication_year=2001&amp;author=Brown%2CMW&amp;author=Aggleton%2CJP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="N. Burgess, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Burgess N (2008) Spatial cognition and the brain. Ann N Y Acad Sci 1124(1):77–97. https://doi.org/10.1196/anna" /><p class="c-article-references__text" id="ref-CR12">Burgess N (2008) Spatial cognition and the brain. Ann N Y Acad Sci 1124(1):77–97. <a href="https://doi.org/10.1196/annals.1440.002">https://doi.org/10.1196/annals.1440.002</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1196%2Fannals.1440.002" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatial%20cognition%20and%20the%20brain&amp;journal=Ann%20N%20Y%20Acad%20Sci&amp;doi=10.1196%2Fannals.1440.002&amp;volume=1124&amp;issue=1&amp;pages=77-97&amp;publication_year=2008&amp;author=Burgess%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Buzsáki, EI. Moser, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Buzsáki G, Moser EI (2013) Memory, navigation and theta rhythm in the hippocampal-entorhinal system. Nat Neuro" /><p class="c-article-references__text" id="ref-CR13">Buzsáki G, Moser EI (2013) Memory, navigation and theta rhythm in the hippocampal-entorhinal system. Nat Neurosci 16(2):130–138</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1038%2Fnn.3304" aria-label="View reference 13">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Memory%2C%20navigation%20and%20theta%20rhythm%20in%20the%20hippocampal-entorhinal%20system&amp;journal=Nat%20Neurosci&amp;volume=16&amp;issue=2&amp;pages=130-138&amp;publication_year=2013&amp;author=Buzs%C3%A1ki%2CG&amp;author=Moser%2CEI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AD. Ekstrom, MJ. Kahana, JB. Caplan, TA. Fields, EA. Isham, EL. Newman, I. Fried, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Ekstrom AD, Kahana MJ, Caplan JB, Fields TA, Isham EA, Newman EL, Fried I (2003) Cellular networks underlying " /><p class="c-article-references__text" id="ref-CR14">Ekstrom AD, Kahana MJ, Caplan JB, Fields TA, Isham EA, Newman EL, Fried I (2003) Cellular networks underlying human spatial navigation. Nature 425(6954):184–188</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1038%2Fnature01964" aria-label="View reference 14">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Cellular%20networks%20underlying%20human%20spatial%20navigation&amp;journal=Nature&amp;volume=425&amp;issue=6954&amp;pages=184-188&amp;publication_year=2003&amp;author=Ekstrom%2CAD&amp;author=Kahana%2CMJ&amp;author=Caplan%2CJB&amp;author=Fields%2CTA&amp;author=Isham%2CEA&amp;author=Newman%2CEL&amp;author=Fried%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="E. Fassbender, W. Heiden, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Fassbender E, Heiden W (2006) The virtual memory palace. J Comput Inf Syst 2(1):457–464" /><p class="c-article-references__text" id="ref-CR15">Fassbender E, Heiden W (2006) The virtual memory palace. J Comput Inf Syst 2(1):457–464</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20virtual%20memory%20palace&amp;journal=J%20Comput%20Inf%20Syst&amp;volume=2&amp;issue=1&amp;pages=457-464&amp;publication_year=2006&amp;author=Fassbender%2CE&amp;author=Heiden%2CW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="H. Gardner, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Gardner H (2006) Multiple intelligences: new horizons. Basic books, New York. ISBN 978-0465047680" /><p class="c-article-references__text" id="ref-CR16">Gardner H (2006) Multiple intelligences: new horizons. Basic books, New York. ISBN 978-0465047680</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Multiple%20intelligences%3A%20new%20horizons&amp;publication_year=2006&amp;author=Gardner%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DR. Godden, AD. Baddeley, " /><meta itemprop="datePublished" content="1975" /><meta itemprop="headline" content="Godden DR, Baddeley AD (1975) Context-dependent memory in two natural environments: on land and underwater. Br" /><p class="c-article-references__text" id="ref-CR17">Godden DR, Baddeley AD (1975) Context-dependent memory in two natural environments: on land and underwater. Br J Psychol 66(3):325–331</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fj.2044-8295.1975.tb01468.x" aria-label="View reference 17">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Context-dependent%20memory%20in%20two%20natural%20environments%3A%20on%20land%20and%20underwater&amp;journal=Br%20J%20Psychol&amp;volume=66&amp;issue=3&amp;pages=325-331&amp;publication_year=1975&amp;author=Godden%2CDR&amp;author=Baddeley%2CAD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Godwin-Jones, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Godwin-Jones R (2010) Emerging technologies from memory palaces to spacing algorithms: approaches to second-la" /><p class="c-article-references__text" id="ref-CR18">Godwin-Jones R (2010) Emerging technologies from memory palaces to spacing algorithms: approaches to second-language vocabulary learning. Lang Learn Technol 14(2):4</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Emerging%20technologies%20from%20memory%20palaces%20to%20spacing%20algorithms%3A%20approaches%20to%20second-language%20vocabulary%20learning&amp;journal=Lang%20Learn%20Technol&amp;volume=14&amp;issue=2&amp;publication_year=2010&amp;author=Godwin-Jones%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Harman J (2001) Creating a memory palace using a computer. In: CHI ’01 extended abstracts on human factors in " /><p class="c-article-references__text" id="ref-CR19">Harman J (2001) Creating a memory palace using a computer. In: CHI ’01 extended abstracts on human factors in computing systems, pp 407–408</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Harman J, Brown R, Johnson D (2017) Improved memory elicitation in virtual reality: new experimental results a" /><p class="c-article-references__text" id="ref-CR20">Harman J, Brown R, Johnson D (2017) Improved memory elicitation in virtual reality: new experimental results and insights. In: IFIP conference on human–computer interaction, Springer, pp 128–146</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JE. Harris, " /><meta itemprop="datePublished" content="1980" /><meta itemprop="headline" content="Harris JE (1980) Memory aids people use: two interview studies. Mem Cogn 8(1):31–38" /><p class="c-article-references__text" id="ref-CR21">Harris JE (1980) Memory aids people use: two interview studies. Mem Cogn 8(1):31–38</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3758%2FBF03197549" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Memory%20aids%20people%20use%3A%20two%20interview%20studies&amp;journal=Mem%20Cogn&amp;volume=8&amp;issue=1&amp;pages=31-38&amp;publication_year=1980&amp;author=Harris%2CJE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Hartley, C. Lever, N. Burgess, J. O’Keefe, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Hartley T, Lever C, Burgess N, O’Keefe J (2014) Space in the brain: how the hippocampal formation supports spa" /><p class="c-article-references__text" id="ref-CR22">Hartley T, Lever C, Burgess N, O’Keefe J (2014) Space in the brain: how the hippocampal formation supports spatial cognition. Philos Trans R Soc B 369(1635):20120,510</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1098%2Frstb.2012.0510" aria-label="View reference 22">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Space%20in%20the%20brain%3A%20how%20the%20hippocampal%20formation%20supports%20spatial%20cognition&amp;journal=Philos%20Trans%20R%20Soc%20B&amp;volume=369&amp;issue=1635&amp;publication_year=2014&amp;author=Hartley%2CT&amp;author=Lever%2CC&amp;author=Burgess%2CN&amp;author=O%E2%80%99Keefe%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="V. Hok, E. Save, P. Lenck-Santini, B. Poucet, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Hok V, Save E, Lenck-Santini P, Poucet B (2005) Coding for spatial goals in the prelimbic/infralimbic area of " /><p class="c-article-references__text" id="ref-CR23">Hok V, Save E, Lenck-Santini P, Poucet B (2005) Coding for spatial goals in the prelimbic/infralimbic area of the rat frontal cortex. Proc Natl Acad Sci USA 102(12):4602–4607</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1073%2Fpnas.0407332102" aria-label="View reference 23">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Coding%20for%20spatial%20goals%20in%20the%20prelimbic%2Finfralimbic%20area%20of%20the%20rat%20frontal%20cortex&amp;journal=Proc%20Natl%20Acad%20Sci%20USA&amp;volume=102&amp;issue=12&amp;pages=4602-4607&amp;publication_year=2005&amp;author=Hok%2CV&amp;author=Save%2CE&amp;author=Lenck-Santini%2CP&amp;author=Poucet%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="J. Julian, " /><meta itemprop="datePublished" content="1976" /><meta itemprop="headline" content="Julian J (1976) The origin of consciousness in the breakdown of the bicameral mind. The Adelphi, Milan" /><p class="c-article-references__text" id="ref-CR24">Julian J (1976) The origin of consciousness in the breakdown of the bicameral mind. The Adelphi, Milan</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20origin%20of%20consciousness%20in%20the%20breakdown%20of%20the%20bicameral%20mind&amp;publication_year=1976&amp;author=Julian%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. Kim, A. Varshney, DW. Jacobs, F. Guimbretière, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Kim Y, Varshney A, Jacobs DW, Guimbretière F (2010) Mesh saliency and human eye fixations. ACM Trans Appl Perc" /><p class="c-article-references__text" id="ref-CR26">Kim Y, Varshney A, Jacobs DW, Guimbretière F (2010) Mesh saliency and human eye fixations. ACM Trans Appl Percept (TAP) 7(2):12</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Mesh%20saliency%20and%20human%20eye%20fixations&amp;journal=ACM%20Trans%20Appl%20Percept%20%28TAP%29&amp;volume=7&amp;issue=2&amp;publication_year=2010&amp;author=Kim%2CY&amp;author=Varshney%2CA&amp;author=Jacobs%2CDW&amp;author=Guimbreti%C3%A8re%2CF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Kim, S. Delcasso, I. Lee, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Kim J, Delcasso S, Lee I (2011) Neural correlates of object-in-place learning in hippocampus and prefrontal co" /><p class="c-article-references__text" id="ref-CR25">Kim J, Delcasso S, Lee I (2011) Neural correlates of object-in-place learning in hippocampus and prefrontal cortex. J Neurosci 31(47):16,991–17,006</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1523%2FJNEUROSCI.2859-11.2011" aria-label="View reference 26">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20correlates%20of%20object-in-place%20learning%20in%20hippocampus%20and%20prefrontal%20cortex&amp;journal=J%20Neurosci&amp;volume=31&amp;issue=47&amp;pages=16%2C991-17%2C006&amp;publication_year=2011&amp;author=Kim%2CJ&amp;author=Delcasso%2CS&amp;author=Lee%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="M. Knauff, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Knauff M (2013) Space to reason: a spatial theory of human thought. MIT Press, Cambridge" /><p class="c-article-references__text" id="ref-CR27">Knauff M (2013) Space to reason: a spatial theory of human thought. MIT Press, Cambridge</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Space%20to%20reason%3A%20a%20spatial%20theory%20of%20human%20thought&amp;publication_year=2013&amp;author=Knauff%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EL. Legge, CR. Madan, ET. Ng, JB. Caplan, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Legge EL, Madan CR, Ng ET, Caplan JB (2012) Building a memory palace in minutes: equivalent memory performance" /><p class="c-article-references__text" id="ref-CR28">Legge EL, Madan CR, Ng ET, Caplan JB (2012) Building a memory palace in minutes: equivalent memory performance using virtual versus conventional environments with the method of loci. Acta Psychol 141(3):380–390</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.actpsy.2012.09.002" aria-label="View reference 28">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Building%20a%20memory%20palace%20in%20minutes%3A%20equivalent%20memory%20performance%20using%20virtual%20versus%20conventional%20environments%20with%20the%20method%20of%20loci&amp;journal=Acta%20Psychol&amp;volume=141&amp;issue=3&amp;pages=380-390&amp;publication_year=2012&amp;author=Legge%2CEL&amp;author=Madan%2CCR&amp;author=Ng%2CET&amp;author=Caplan%2CJB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Leutgeb, JK. Leutgeb, MB. Moser, EI. Moser, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Leutgeb S, Leutgeb JK, Moser MB, Moser EI (2005) Place cells, spatial maps and the population code for memory." /><p class="c-article-references__text" id="ref-CR29">Leutgeb S, Leutgeb JK, Moser MB, Moser EI (2005) Place cells, spatial maps and the population code for memory. Curr Opin Neurobiol 15(6):738–746</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.conb.2005.10.002" aria-label="View reference 29">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Place%20cells%2C%20spatial%20maps%20and%20the%20population%20code%20for%20memory&amp;journal=Curr%20Opin%20Neurobiol&amp;volume=15&amp;issue=6&amp;pages=738-746&amp;publication_year=2005&amp;author=Leutgeb%2CS&amp;author=Leutgeb%2CJK&amp;author=Moser%2CMB&amp;author=Moser%2CEI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Lever, S. Burton, A. Jeewajee, J. O’Keefe, N. Burgess, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Lever C, Burton S, Jeewajee A, O’Keefe J, Burgess N (2009) Boundary vector cells in the subiculum of the hippo" /><p class="c-article-references__text" id="ref-CR30">Lever C, Burton S, Jeewajee A, O’Keefe J, Burgess N (2009) Boundary vector cells in the subiculum of the hippocampal formation. J Neurosci 29(31):9771–9777</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1523%2FJNEUROSCI.1319-09.2009" aria-label="View reference 30">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Boundary%20vector%20cells%20in%20the%20subiculum%20of%20the%20hippocampal%20formation&amp;journal=J%20Neurosci&amp;volume=29&amp;issue=31&amp;pages=9771-9777&amp;publication_year=2009&amp;author=Lever%2CC&amp;author=Burton%2CS&amp;author=Jeewajee%2CA&amp;author=O%E2%80%99Keefe%2CJ&amp;author=Burgess%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JM. Loomis, JJ. Blascovich, AC. Beall, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Loomis JM, Blascovich JJ, Beall AC (1999) Immersive virtual environment technology as a basic research tool in" /><p class="c-article-references__text" id="ref-CR31">Loomis JM, Blascovich JJ, Beall AC (1999) Immersive virtual environment technology as a basic research tool in psychology. Behav Res Methods Instrum Comput 31(4):557–564</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3758%2FBF03200735" aria-label="View reference 31">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Immersive%20virtual%20environment%20technology%20as%20a%20basic%20research%20tool%20in%20psychology&amp;journal=Behav%20Res%20Methods%20Instrum%20Comput&amp;volume=31&amp;issue=4&amp;pages=557-564&amp;publication_year=1999&amp;author=Loomis%2CJM&amp;author=Blascovich%2CJJ&amp;author=Beall%2CAC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Madl, K. Chen, D. Montaldi, R. Trappl, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Madl T, Chen K, Montaldi D, Trappl R (2015) Computational cognitive models of spatial memory in navigation spa" /><p class="c-article-references__text" id="ref-CR32">Madl T, Chen K, Montaldi D, Trappl R (2015) Computational cognitive models of spatial memory in navigation space: a review. Neural Netw 65:18–43</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.neunet.2015.01.002" aria-label="View reference 32">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Computational%20cognitive%20models%20of%20spatial%20memory%20in%20navigation%20space%3A%20a%20review&amp;journal=Neural%20Netw&amp;volume=65&amp;pages=18-43&amp;publication_year=2015&amp;author=Madl%2CT&amp;author=Chen%2CK&amp;author=Montaldi%2CD&amp;author=Trappl%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Mania, A. Chalmers, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Mania K, Chalmers A (2001) The effects of levels of immersion on memory and presence in virtual environments: " /><p class="c-article-references__text" id="ref-CR33">Mania K, Chalmers A (2001) The effects of levels of immersion on memory and presence in virtual environments: a reality centered approach. CyberPsychol Behav 4(2):247–264</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1089%2F109493101300117938" aria-label="View reference 33">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effects%20of%20levels%20of%20immersion%20on%20memory%20and%20presence%20in%20virtual%20environments%3A%20a%20reality%20centered%20approach&amp;journal=CyberPsychol%20Behav&amp;volume=4&amp;issue=2&amp;pages=247-264&amp;publication_year=2001&amp;author=Mania%2CK&amp;author=Chalmers%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Mania, T. Troscianko, R. Hawkes, A. Chalmers, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Mania K, Troscianko T, Hawkes R, Chalmers A (2003) Fidelity metrics for virtual environment simulations based " /><p class="c-article-references__text" id="ref-CR34">Mania K, Troscianko T, Hawkes R, Chalmers A (2003) Fidelity metrics for virtual environment simulations based on spatial memory awareness states. Presence Teleoper Virtual Environ 12(3):296–310</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474603765879549" aria-label="View reference 34">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Fidelity%20metrics%20for%20virtual%20environment%20simulations%20based%20on%20spatial%20memory%20awareness%20states&amp;journal=Presence%20Teleoper%20Virtual%20Environ&amp;volume=12&amp;issue=3&amp;pages=296-310&amp;publication_year=2003&amp;author=Mania%2CK&amp;author=Troscianko%2CT&amp;author=Hawkes%2CR&amp;author=Chalmers%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JD. Mayer, P. Salovey, DR. Caruso, G. Sitarenios, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Mayer JD, Salovey P, Caruso DR, Sitarenios G (2001) Emotional intelligence as a standard intelligence. Emotion" /><p class="c-article-references__text" id="ref-CR35">Mayer JD, Salovey P, Caruso DR, Sitarenios G (2001) Emotional intelligence as a standard intelligence. Emotion 1(3):232–242</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2F1528-3542.1.3.232" aria-label="View reference 35">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Emotional%20intelligence%20as%20a%20standard%20intelligence&amp;journal=Emotion&amp;volume=1&amp;issue=3&amp;pages=232-242&amp;publication_year=2001&amp;author=Mayer%2CJD&amp;author=Salovey%2CP&amp;author=Caruso%2CDR&amp;author=Sitarenios%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JA. McCabe, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="McCabe JA (2015) Location, location, location! Demonstrating the mnemonic benefit of the method of loci. Teach" /><p class="c-article-references__text" id="ref-CR36">McCabe JA (2015) Location, location, location! Demonstrating the mnemonic benefit of the method of loci. Teach Psychol 42(2):169–173</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1177%2F0098628315573143" aria-label="View reference 36">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 36 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Location%2C%20location%2C%20location%21%20Demonstrating%20the%20mnemonic%20benefit%20of%20the%20method%20of%20loci&amp;journal=Teach%20Psychol&amp;volume=42&amp;issue=2&amp;pages=169-173&amp;publication_year=2015&amp;author=McCabe%2CJA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="GA. Miller, " /><meta itemprop="datePublished" content="1956" /><meta itemprop="headline" content="Miller GA (1956) The magical number seven, plus or minus two: some limits on our capacity for processing infor" /><p class="c-article-references__text" id="ref-CR37">Miller GA (1956) The magical number seven, plus or minus two: some limits on our capacity for processing information. Psychol Rev 63(2):81</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2Fh0043158" aria-label="View reference 37">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20magical%20number%20seven%2C%20plus%20or%20minus%20two%3A%20some%20limits%20on%20our%20capacity%20for%20processing%20information&amp;journal=Psychol%20Rev&amp;volume=63&amp;issue=2&amp;publication_year=1956&amp;author=Miller%2CGA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EI. Moser, E. Kropff, MB. Moser, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Moser EI, Kropff E, Moser MB (2008) Place cells, grid cells, and the brain’s spatial representation system. An" /><p class="c-article-references__text" id="ref-CR38">Moser EI, Kropff E, Moser MB (2008) Place cells, grid cells, and the brain’s spatial representation system. Annu Rev Neurosci 31:69–89</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1146%2Fannurev.neuro.31.061307.090723" aria-label="View reference 38">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 38 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Place%20cells%2C%20grid%20cells%2C%20and%20the%20brain%E2%80%99s%20spatial%20representation%20system&amp;journal=Annu%20Rev%20Neurosci&amp;volume=31&amp;pages=69-89&amp;publication_year=2008&amp;author=Moser%2CEI&amp;author=Kropff%2CE&amp;author=Moser%2CMB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JK. O’Regan, A. Noë, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="O’Regan JK, Noë A (2001) A sensorimotor account of vision and visual consciousness. Behav Brain Sci 24(5):939–" /><p class="c-article-references__text" id="ref-CR39">O’Regan JK, Noë A (2001) A sensorimotor account of vision and visual consciousness. Behav Brain Sci 24(5):939–973</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1017%2FS0140525X01000115" aria-label="View reference 39">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20sensorimotor%20account%20of%20vision%20and%20visual%20consciousness&amp;journal=Behav%20Brain%20Sci&amp;volume=24&amp;issue=5&amp;pages=939-973&amp;publication_year=2001&amp;author=O%E2%80%99Regan%2CJK&amp;author=No%C3%AB%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="TD. Parsons, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Parsons TD (2015) Virtual reality for enhanced ecological validity and experimental control in the clinical, a" /><p class="c-article-references__text" id="ref-CR40">Parsons TD (2015) Virtual reality for enhanced ecological validity and experimental control in the clinical, affective and social neurosciences. Front Hum Neurosci 9:660</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3389%2Ffnhum.2015.00660" aria-label="View reference 40">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 40 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20for%20enhanced%20ecological%20validity%20and%20experimental%20control%20in%20the%20clinical%2C%20affective%20and%20social%20neurosciences&amp;journal=Front%20Hum%20Neurosci&amp;volume=9&amp;publication_year=2015&amp;author=Parsons%2CTD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pausch R, Proffitt D, Williams G (1997) Quantifying immersion in virtual reality. In: Proceedings of the 24th " /><p class="c-article-references__text" id="ref-CR41">Pausch R, Proffitt D, Williams G (1997) Quantifying immersion in virtual reality. In: Proceedings of the 24th annual conference on computer graphics and interactive techniques, SIGGRAPH ’97, pp 13–18</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Perrault ST, Lecolinet E, Bourse YP, Zhao S, Guiard Y (2015) Physical loci: leveraging spatial, object and sem" /><p class="c-article-references__text" id="ref-CR42">Perrault ST, Lecolinet E, Bourse YP, Zhao S, Guiard Y (2015) Physical loci: leveraging spatial, object and semantic memory for command selection. In: Proceedings of the 33rd annual ACM conference on human factors in computing systems, CHI ’15, pp 299–308</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="ED. Ragan, A. Sowndararajan, R. Kopper, DA. Bowman, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Ragan ED, Sowndararajan A, Kopper R, Bowman DA (2010) The effects of higher levels of immersion on procedure m" /><p class="c-article-references__text" id="ref-CR43">Ragan ED, Sowndararajan A, Kopper R, Bowman DA (2010) The effects of higher levels of immersion on procedure memorization performance and implications for educational virtual environments. Presence Teleoper Virtual Environ 19(6):527–543</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2Fpres_a_00016" aria-label="View reference 43">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 43 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effects%20of%20higher%20levels%20of%20immersion%20on%20procedure%20memorization%20performance%20and%20implications%20for%20educational%20virtual%20environments&amp;journal=Presence%20Teleoper%20Virtual%20Environ&amp;volume=19&amp;issue=6&amp;pages=527-543&amp;publication_year=2010&amp;author=Ragan%2CED&amp;author=Sowndararajan%2CA&amp;author=Kopper%2CR&amp;author=Bowman%2CDA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Repetto, S. Serino, M. Macedonia, G. Riva, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Repetto C, Serino S, Macedonia M, Riva G (2016) Virtual reality as an embodied tool to enhance episodic memory" /><p class="c-article-references__text" id="ref-CR44">Repetto C, Serino S, Macedonia M, Riva G (2016) Virtual reality as an embodied tool to enhance episodic memory in elderly. Front Psychol 7:1839:1–1839:4</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3389%2Ffpsyg.2016.01839" aria-label="View reference 44">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 44 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20as%20an%20embodied%20tool%20to%20enhance%20episodic%20memory%20in%20elderly&amp;journal=Front%20Psychol&amp;volume=7&amp;pages=1839%3A1-1839%3A4&amp;publication_year=2016&amp;author=Repetto%2CC&amp;author=Serino%2CS&amp;author=Macedonia%2CM&amp;author=Riva%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AE. Richardson, DR. Montello, M. Hegarty, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Richardson AE, Montello DR, Hegarty M (1999) Spatial knowledge acquisition from maps and from navigation in re" /><p class="c-article-references__text" id="ref-CR45">Richardson AE, Montello DR, Hegarty M (1999) Spatial knowledge acquisition from maps and from navigation in real and virtual environments. Mem Cognit 27(4):741–750</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3758%2FBF03211566" aria-label="View reference 45">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 45 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatial%20knowledge%20acquisition%20from%20maps%20and%20from%20navigation%20in%20real%20and%20virtual%20environments&amp;journal=Mem%20Cognit&amp;volume=27&amp;issue=4&amp;pages=741-750&amp;publication_year=1999&amp;author=Richardson%2CAE&amp;author=Montello%2CDR&amp;author=Hegarty%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HL. Roediger, " /><meta itemprop="datePublished" content="1979" /><meta itemprop="headline" content="Roediger HL (1979) Implicit and explicit memory models. Bull Psychon Soc 13(6):339–342" /><p class="c-article-references__text" id="ref-CR46">Roediger HL (1979) Implicit and explicit memory models. Bull Psychon Soc 13(6):339–342</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3758%2FBF03336889" aria-label="View reference 46">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 46 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Implicit%20and%20explicit%20memory%20models&amp;journal=Bull%20Psychon%20Soc&amp;volume=13&amp;issue=6&amp;pages=339-342&amp;publication_year=1979&amp;author=Roediger%2CHL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Ruddle, SJ. Payne, DM. Jones, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Ruddle RA, Payne SJ, Jones DM (1999) Navigating large-scale virtual environments: what differences occur betwe" /><p class="c-article-references__text" id="ref-CR47">Ruddle RA, Payne SJ, Jones DM (1999) Navigating large-scale virtual environments: what differences occur between helmet-mounted and desktop displays? Presence Teleoper Virtual Environ 8(2):157–168</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474699566143" aria-label="View reference 47">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 47 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Navigating%20large-scale%20virtual%20environments%3A%20what%20differences%20occur%20between%20helmet-mounted%20and%20desktop%20displays%3F&amp;journal=Presence%20Teleoper%20Virtual%20Environ&amp;volume=8&amp;issue=2&amp;pages=157-168&amp;publication_year=1999&amp;author=Ruddle%2CRA&amp;author=Payne%2CSJ&amp;author=Jones%2CDM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MV. Sanchez-Vives, M. Slater, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Sanchez-Vives MV, Slater M (2005) From presence to consciousness through virtual reality. Nat Rev Neurosci 6(4" /><p class="c-article-references__text" id="ref-CR48">Sanchez-Vives MV, Slater M (2005) From presence to consciousness through virtual reality. Nat Rev Neurosci 6(4):332–339</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1038%2Fnrn1651" aria-label="View reference 48">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 48 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=From%20presence%20to%20consciousness%20through%20virtual%20reality&amp;journal=Nat%20Rev%20Neurosci&amp;volume=6&amp;issue=4&amp;pages=332-339&amp;publication_year=2005&amp;author=Sanchez-Vives%2CMV&amp;author=Slater%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="L. Shapiro, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Shapiro L (2010) Embodied cognition. Routledge, New York. ISBN 978-0415773423" /><p class="c-article-references__text" id="ref-CR49">Shapiro L (2010) Embodied cognition. Routledge, New York. ISBN 978-0415773423</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 49 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Embodied%20cognition&amp;publication_year=2010&amp;author=Shapiro%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Skarbez, FP. Brooks, MC. Whitton, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Skarbez R, Brooks FP Jr, Whitton MC (2017) A survey of presence and related concepts. ACM Comput Surv 50(6):96" /><p class="c-article-references__text" id="ref-CR50">Skarbez R, Brooks FP Jr, Whitton MC (2017) A survey of presence and related concepts. ACM Comput Surv 50(6):96:1–96:39. <a href="https://doi.org/10.1145/3134301">https://doi.org/10.1145/3134301</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F3134301" aria-label="View reference 50">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 50 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20survey%20of%20presence%20and%20related%20concepts&amp;journal=ACM%20Comput%20Surv&amp;doi=10.1145%2F3134301&amp;volume=50&amp;issue=6&amp;pages=96%3A1-96%3A39&amp;publication_year=2017&amp;author=Skarbez%2CR&amp;author=Brooks%2CFP&amp;author=Whitton%2CMC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Slater, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Slater M (2009) Place illusion and plausibility can lead to realistic behaviour in immersive virtual environme" /><p class="c-article-references__text" id="ref-CR51">Slater M (2009) Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments. Philos Trans R Soc Lond B Biol Sci 364(1535):3549–3557</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1098%2Frstb.2009.0138" aria-label="View reference 51">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 51 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Place%20illusion%20and%20plausibility%20can%20lead%20to%20realistic%20behaviour%20in%20immersive%20virtual%20environments&amp;journal=Philos%20Trans%20R%20Soc%20Lond%20B%20Biol%20Sci&amp;volume=364&amp;issue=1535&amp;pages=3549-3557&amp;publication_year=2009&amp;author=Slater%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sowndararajan A, Wang R, Bowman DA (2008) Quantifying the benefits of immersion for procedural training. In: P" /><p class="c-article-references__text" id="ref-CR52">Sowndararajan A, Wang R, Bowman DA (2008) Quantifying the benefits of immersion for procedural training. In: Proceedings of the 2008 workshop on immersive projection technologies/emerging display technologies, IPT/EDT ’08, pp 2:1–2:4</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Wraga, SH. Creem-Regehr, DR. Proffitt, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Wraga M, Creem-Regehr SH, Proffitt DR (2004) Spatial updating of virtual displays. Mem Cognit 32(3):399–415" /><p class="c-article-references__text" id="ref-CR53">Wraga M, Creem-Regehr SH, Proffitt DR (2004) Spatial updating of virtual displays. Mem Cognit 32(3):399–415</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3758%2FBF03195834" aria-label="View reference 53">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 53 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatial%20updating%20of%20virtual%20displays&amp;journal=Mem%20Cognit&amp;volume=32&amp;issue=3&amp;pages=399-415&amp;publication_year=2004&amp;author=Wraga%2CM&amp;author=Creem-Regehr%2CSH&amp;author=Proffitt%2CDR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="FA. Yates, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Yates FA (1992) The art of memory, vol 64. Random House, New York" /><p class="c-article-references__text" id="ref-CR54">Yates FA (1992) The art of memory, vol 64. Random House, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 54 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20art%20of%20memory&amp;publication_year=1992&amp;author=Yates%2CFA">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-018-0346-3-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>We would like to extend our sincere appreciation to the anonymous reviewers who helped us refine this paper that significantly improved its presentation. We appreciate the support of the NSF Grants 14-29404, 15-64212, the State of Maryland’s MPower initiative, and the NVIDIA CUDA Center of Excellence. Any opinions, findings, conclusions, or recommendations expressed in this article are those of the authors and do not necessarily reflect the views of the research sponsors. Lastly, we would like to thank the 40 study participants.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">University of Maryland, College Park, AV. Williams 4406, College Park, USA</p><p class="c-article-author-affiliation__authors-list">Eric Krokos</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">University of Maryland, College Park, Hornbake Bldg. 2117C, College Park, USA</p><p class="c-article-author-affiliation__authors-list">Catherine Plaisant</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">University of Maryland, College Park, AV. Williams 2119, College Park, USA</p><p class="c-article-author-affiliation__authors-list">Amitabh Varshney</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Eric-Krokos"><span class="c-article-authors-search__title u-h3 js-search-name">Eric Krokos</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Eric+Krokos&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Eric+Krokos" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Eric+Krokos%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Catherine-Plaisant"><span class="c-article-authors-search__title u-h3 js-search-name">Catherine Plaisant</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Catherine+Plaisant&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Catherine+Plaisant" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Catherine+Plaisant%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Amitabh-Varshney"><span class="c-article-authors-search__title u-h3 js-search-name">Amitabh Varshney</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Amitabh+Varshney&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Amitabh+Varshney" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Amitabh+Varshney%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-018-0346-3/email/correspondent/c1/new">Eric Krokos</a>.</p></div></div></section><section aria-labelledby="additional-information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><p>The original version of this article was revised due to a retrospective Open Access order.</p></div></div></section><section aria-labelledby="appendices"><div class="c-article-section" id="appendices-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="appendices">Appendix</h2><div class="c-article-section__content" id="appendices-content"><h3 class="c-article__sub-heading u-visually-hidden" id="App1">Appendix</h3><p>See Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0346-3#Tab1">1</a>, <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0346-3#Tab2">2</a> and <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0346-3#Tab3">3</a>.</p>
                  <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Trend scores for each face for Face Set 1 from Google Trends, with the average trend score of 30.5 and standard deviation of 21.86.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0346-3/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Trend scores for each face for Face Set 2 from Google Trends, with the average trend score of 29.83 and standard deviation of 18.32.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0346-3/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Angular resolution of faces in the town and palace scenes, with the average and standard deviation of the angular resolutions of the set of faces for each scene</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0346-3/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig11_HTML.png?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig11_HTML.png" alt="figure11" loading="lazy" width="685" height="930" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Face Set 1, containing 21 faces</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig12_HTML.png?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0346-3/MediaObjects/10055_2018_346_Fig12_HTML.png" alt="figure12" loading="lazy" width="685" height="932" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Face Set 2, containing 21 faces</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0346-3/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                </div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content">
                <p><b>Open Access</b> 
This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<a href="http://creativecommons.org/licenses/by/4.0/" rel="license" itemprop="license">http://creativecommons.org/licenses/by/4.0/</a>), which permits use, duplication, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made.</p>
              <p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Virtual%20memory%20palaces%3A%20immersion%20aids%20recall&amp;author=Eric%20Krokos%20et%20al&amp;contentID=10.1007%2Fs10055-018-0346-3&amp;publication=1359-4338&amp;publicationDate=2018-05-16&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-018-0346-3" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-018-0346-3" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Krokos, E., Plaisant, C. &amp; Varshney, A. Virtual memory palaces: immersion aids recall.
                    <i>Virtual Reality</i> <b>23, </b>1–15 (2019). https://doi.org/10.1007/s10055-018-0346-3</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-018-0346-3.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-10-21">21 October 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-05-03">03 May 2018</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-05-16">16 May 2018</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2019-03-05">05 March 2019</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-018-0346-3" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-018-0346-3</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Immersion</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Experimental methods</span></li><li class="c-article-subject-list__subject"><span itemprop="about">HMD</span></li><li class="c-article-subject-list__subject"><span itemprop="about">3D navigation</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Visualization</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Psychology</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Training</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Education</span></li><li class="c-article-subject-list__subject"><span itemprop="about">User study</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Perception</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Presence</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-018-0346-3.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=346;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

