<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Automatic synthesis of explosion sound synchronized with animation"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Sound is an essential element for enhancing the realness of virtual world. Currently, there are some remarkable works on the synthesis of fluid sound, such as fire and water. However, little..."/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Automatic synthesis of explosion sound synchronized with animation"/>

    <meta name="dc.source" content="Virtual Reality 2019"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2019-11-18"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2019 Springer-Verlag London Ltd., part of Springer Nature"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Sound is an essential element for enhancing the realness of virtual world. Currently, there are some remarkable works on the synthesis of fluid sound, such as fire and water. However, little attention has been paid to synthesizing explosion sound. This paper proposes an automatic method for synthesizing explosion sounds that are synchronized with the visual phenomena of explosion animations, including fireball generation and flame combustion. Such two types of visual animation correspond to two types of sound, which we name as explosive sound and combustion noise, respectively. For the synthesis of explosive sound, firstly, the occurrence time and duration of explosion sound are determined according to the dynamic process of fuel consumption, and then, the corresponding explosive sound is extracted from the recording examples according to the high-frequency content. For the combustion noise, we propose a synthesis method of combustion noise on the basis of the timbre similarity between sound examples and low-frequency combustion noise generated by a physical method. Finally, the two types of sound are blended respecting the occurrence and duration of the explosions and combustions parts detected in the visual stream. Our experiments and the user study show the results of our method and demonstrate the effectiveness of our method."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2019-11-18"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="1"/>

    <meta name="prism.endingPage" content="13"/>

    <meta name="prism.copyright" content="2019 Springer-Verlag London Ltd., part of Springer Nature"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-019-00408-7"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-019-00408-7"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-019-00408-7.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-019-00408-7"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Automatic synthesis of explosion sound synchronized with animation"/>

    <meta name="citation_online_date" content="2019/11/18"/>

    <meta name="citation_firstpage" content="1"/>

    <meta name="citation_lastpage" content="13"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-019-00408-7"/>

    <meta name="DOI" content="10.1007/s10055-019-00408-7"/>

    <meta name="citation_doi" content="10.1007/s10055-019-00408-7"/>

    <meta name="description" content="Sound is an essential element for enhancing the realness of virtual world. Currently, there are some remarkable works on the synthesis of fluid sound, such"/>

    <meta name="dc.creator" content="Shiguang Liu"/>

    <meta name="dc.creator" content="Si Gao"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Agostino DS (1999) Synthesis of environmental sound textures by iterated nonlinear functions. In: Digital audio effects. pp 109&#8211;117"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Graph; citation_title=Motion-driven concatenative synthesis of cloth sounds; citation_author=SS An, DL James, S Marschner; citation_volume=31; citation_issue=4; citation_publication_date=2012; citation_pages=1-10; citation_doi=10.1145/2185520.2185598; citation_id=CR2"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Graph; citation_title=Animating fire with sound; citation_author=JN Chadwick, DL James; citation_volume=30; citation_issue=4; citation_publication_date=2011; citation_pages=84-92; citation_doi=10.1145/2010324.1964979; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_title=Modern methods in analytical acoustics; citation_publication_date=1992; citation_id=CR4; citation_author=D Crighton; citation_author=A Dowling; citation_author=J Ffowcs-Williams; citation_author=M Heckl; citation_author=F Leppington; citation_author=JF Bartram; citation_publisher=Springer"/>

    <meta name="citation_reference" content="Dobashi Y, Kaneda K, Yamashita H, Okita T, Nishita T (2000) A simple, efficient method for realistic animation of clouds. In: ACM SIGGRAPH. pp 19&#8211;28"/>

    <meta name="citation_reference" content="Dobashi Y, Yamamoto T, Nishita T (2003) Real-time rendering of aerodynamic sound using sound textures based on computational fluid dynamics. In: ACM SIGGRAPH. pp 732&#8211;740"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph Forum; citation_title=Synthesizing sound from turbulent field using sound textures for interactive fluid simulation; citation_author=Y Dobashi, T Yamamoto, T Nishita; citation_volume=23; citation_issue=3; citation_publication_date=2004; citation_pages=539-545; citation_doi=10.1111/j.1467-8659.2004.00785.x; citation_id=CR7"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Appl Percept; citation_title=Physically-based models for liquid sounds; citation_author=KVD Doel; citation_volume=2; citation_issue=4; citation_publication_date=2005; citation_pages=534-546; citation_doi=10.1145/1101530.1101554; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Comput Graph Appl; citation_title=Synthesizing sound textures through wavelet tree learning; citation_author=S Dubnov, Z Barjoseph, EY Ran, D Lischinski, M Werman; citation_volume=22; citation_issue=4; citation_publication_date=2002; citation_pages=38-48; citation_doi=10.1109/MCG.2002.1016697; citation_id=CR9"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Graph; citation_title=Animating suspended particle explosions; citation_author=BE Feldman, JF O&#8217;brien, O Arikan; citation_volume=22; citation_issue=3; citation_publication_date=2003; citation_pages=708-715; citation_doi=10.1145/882262.882336; citation_id=CR10"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Animat Virtual Worlds; citation_title=Detail-preserving sph fluid control with deformation constraints; citation_author=G Feng, S Liu; citation_volume=29; citation_issue=1; citation_publication_date=2018; citation_pages=e1781; citation_doi=10.1002/cav.1781; citation_id=CR11"/>

    <meta name="citation_reference" content="citation_journal_title=Proc Combust Inst; citation_title=Radiation of noise in turbulent non-premixed flames; citation_author=M Ihme, H Pitsch, D Bodony; citation_volume=32; citation_issue=1; citation_publication_date=2009; citation_pages=1545-1553; citation_doi=10.1016/j.proci.2008.06.137; citation_id=CR12"/>

    <meta name="citation_reference" content="Kersten S, Purwins H (2013) Fire texture sound re-synthesis using sparse decomposition and noise modelling. In: Digital audio effects. pp 1&#8211;5"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=Fast and stable simulation of virtual water scenes with interactions; citation_author=S Liu, Y Xiong; citation_volume=17; citation_issue=1; citation_publication_date=2013; citation_pages=77-88; citation_doi=10.1007/s10055-013-0222-0; citation_id=CR14"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=Sounding fire for immersive virtual reality; citation_author=S Liu, Z Yu; citation_volume=19; citation_issue=3&#8211;4; citation_publication_date=2015; citation_pages=291-302; citation_doi=10.1007/s10055-015-0271-7; citation_id=CR15"/>

    <meta name="citation_reference" content="citation_journal_title=Fluid Mech; citation_title=An analytic model of sound production by raindrops; citation_author=MS Longuethiggins; citation_volume=214; citation_publication_date=1990; citation_pages=395-410; citation_doi=10.1017/S0022112090000179; citation_id=CR16"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Audio Speech Lang Process; citation_title=An efficient time&#8211;frequency method for synthesizing noisy sounds with short transients and narrow spectral components; citation_author=D Marelli, M Aramaki, R Kronland-Martinet, C Verron; citation_volume=20; citation_issue=4; citation_publication_date=2012; citation_pages=1400-1408; citation_doi=10.1109/TASL.2011.2176334; citation_id=CR17"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Graph; citation_title=Sounding liquids: automatic sound synthesis from fluid simulation; citation_author=W Moss, H Yeh, JM Hong, MC Lin, D Manocha; citation_volume=29; citation_issue=3; citation_publication_date=2010; citation_pages=1-13; citation_doi=10.1145/1805964.1805965; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Graph; citation_title=Physically based modeling and animation of fire; citation_author=DQ Nguyen, R Fedkiw, HW Jensen; citation_volume=21; citation_issue=3; citation_publication_date=2002; citation_pages=721-728; citation_doi=10.1145/566654.566643; citation_id=CR19"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Graph; citation_title=Graphical modeling and animation of ductile fracture; citation_author=JF O&#8217;Brien, AW Bargteil, JK Hodgins; citation_volume=21; citation_issue=3; citation_publication_date=2002; citation_pages=291-294; citation_id=CR20"/>

    <meta name="citation_reference" content="citation_title=Theory of vortex sound; citation_publication_date=2003; citation_id=CR21; citation_author=A Powell; citation_publisher=Cambridge University Press"/>

    <meta name="citation_reference" content="citation_title=Bubble dynamics in oceanic ambient noise; citation_publication_date=1988; citation_id=CR22; citation_author=A Prosperetti; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_title=Microsound; citation_publication_date=2004; citation_id=CR23; citation_author=C Roads; citation_publisher=The MIT Press"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Animat Virtual Worlds; citation_title=Feedback control of fire simulation based on computational fluid dynamics; citation_author=S Sato, K Mizutani, Y Dobashi, T Nishita, T Yamamoto; citation_volume=28; citation_issue=3&#8211;4; citation_publication_date=2017; citation_pages=e1766; citation_doi=10.1002/cav.1766; citation_id=CR24"/>

    <meta name="citation_reference" content="Schreck C, Rohmer D, James DL, Hahmann S, Cani MP (2016) Real-time sound synthesis for paper material based on geometric analysis. In: ACM SIGGRAPH. pp 211&#8211;220"/>

    <meta name="citation_reference" content="Schwarz D (2011) State of the art in sound texture synthesis. In: Digital audio effects (DAFx-12). pp 151&#8211;171"/>

    <meta name="citation_reference" content="citation_title=Interactive Sound Texture Synthesis Through Semi-Automatic User Annotations; citation_inbook_title=Lecture Notes in Computer Science; citation_publication_date=2014; citation_pages=372-392; citation_id=CR27; citation_author=Diemo Schwarz; citation_author=Baptiste Caramiaux; citation_publisher=Springer International Publishing"/>

    <meta name="citation_reference" content="Schwarz D, O&#8217;Leary S (2015) Smooth granular sound texture synthesis by control of timbral similarity. In: Sound and music computing. pp 471 &#8211; 476"/>

    <meta name="citation_reference" content="Schwarz D, Schnell N (2008) Descriptor-based sound texture sampling. In: Sound and music computing. pp 510&#8211;515"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=Using immersive game-based virtual reality to teach fire-safety skills to children; citation_author=S Smith, E Ericson; citation_volume=13; citation_issue=2; citation_publication_date=2009; citation_pages=87-99; citation_doi=10.1007/s10055-009-0113-6; citation_id=CR30"/>

    <meta name="citation_reference" content="Stam J (1999) Stable fluids. In: Proceedings of the 26th annual conference on computer graphics and interactive techniques. pp 121&#8211;128"/>

    <meta name="citation_reference" content="citation_journal_title=Commun ACM; citation_title=Interacting with smoke and fire in real time; citation_author=J Stam; citation_volume=43; citation_issue=7; citation_publication_date=2000; citation_pages=76-83; citation_doi=10.1145/341852.341866; citation_id=CR32"/>

    <meta name="citation_reference" content="Stam J, Stam J, Jensen HW (2001) Visual simulation of smoke. In: ACM SIGGRAPH. pp 15&#8211;22"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Animat Virtual Worlds; citation_title=Example-based synthesis for sound of ocean waves caused by bubble dynamics; citation_author=K Wang, S Liu; citation_volume=29; citation_issue=4; citation_publication_date=2018; citation_pages=e1835; citation_doi=10.1002/cav.1835; citation_id=CR34"/>

    <meta name="citation_reference" content="Wang K, Cheng H, Liu S (2017) Efficient sound synthesis for natural scenes. In: IEEE virtual reality. pp 303&#8211;304"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Vis Comput Graph; citation_title=Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles; citation_author=Q Yin, S Liu; citation_volume=24; citation_issue=2; citation_publication_date=2018; citation_pages=1179-1189; citation_doi=10.1109/TVCG.2016.2642958; citation_id=CR36"/>

    <meta name="citation_reference" content="Yngve GD, O&#8217;Brien JF, Hodgins JK (2000) Animating explosions. In: ACM SIGGRAPH. pp 29&#8211;36"/>

    <meta name="citation_author" content="Shiguang Liu"/>

    <meta name="citation_author_email" content="shgliu@126.com"/>

    <meta name="citation_author_institution" content="Division of Intelligence and Computing, School of Computer Science and Technology, Tianjin, People&#8217;s Republic of China"/>

    <meta name="citation_author" content="Si Gao"/>

    <meta name="citation_author_institution" content="Division of Intelligence and Computing, School of Computer Science and Technology, Tianjin, People&#8217;s Republic of China"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-019-00408-7&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-019-00408-7"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Automatic synthesis of explosion sound synchronized with animation"/>
        <meta property="og:description" content="Sound is an essential element for enhancing the realness of virtual world. Currently, there are some remarkable works on the synthesis of fluid sound, such as fire and water. However, little attention has been paid to synthesizing explosion sound. This paper proposes an automatic method for synthesizing explosion sounds that are synchronized with the visual phenomena of explosion animations, including fireball generation and flame combustion. Such two types of visual animation correspond to two types of sound, which we name as explosive sound and combustion noise, respectively. For the synthesis of explosive sound, firstly, the occurrence time and duration of explosion sound are determined according to the dynamic process of fuel consumption, and then, the corresponding explosive sound is extracted from the recording examples according to the high-frequency content. For the combustion noise, we propose a synthesis method of combustion noise on the basis of the timbre similarity between sound examples and low-frequency combustion noise generated by a physical method. Finally, the two types of sound are blended respecting the occurrence and duration of the explosions and combustions parts detected in the visual stream. Our experiments and the user study show the results of our method and demonstrate the effectiveness of our method."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Automatic synthesis of explosion sound synchronized with animation | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-019-00408-7","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Audiovisual synchronization, Explosive sound, Combustion noise, Sound synthesis, Immersive virtual reality","kwrd":["Audiovisual_synchronization","Explosive_sound","Combustion_noise","Sound_synthesis","Immersive_virtual_reality"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-019-00408-7","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-019-00408-7","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=408;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-019-00408-7">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Automatic synthesis of explosion sound synchronized with animation
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-019-00408-7.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-019-00408-7.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2019-11-18" itemprop="datePublished">18 November 2019</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Automatic synthesis of explosion sound synchronized with animation</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Shiguang-Liu" data-author-popup="auth-Shiguang-Liu" data-corresp-id="c1">Shiguang Liu<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="School of Computer Science and Technology" /><meta itemprop="address" content="Division of Intelligence and Computing, School of Computer Science and Technology, Tianjin, People’s Republic of China" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Si-Gao" data-author-popup="auth-Si-Gao">Si Gao</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="School of Computer Science and Technology" /><meta itemprop="address" content="Division of Intelligence and Computing, School of Computer Science and Technology, Tianjin, People’s Republic of China" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            (<span data-test="article-publication-year">2019</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">57 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-019-00408-7/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Sound is an essential element for enhancing the realness of virtual world. Currently, there are some remarkable works on the synthesis of fluid sound, such as fire and water. However, little attention has been paid to synthesizing explosion sound. This paper proposes an automatic method for synthesizing explosion sounds that are synchronized with the visual phenomena of explosion animations, including fireball generation and flame combustion. Such two types of visual animation correspond to two types of sound, which we name as explosive sound and combustion noise, respectively. For the synthesis of explosive sound, firstly, the occurrence time and duration of explosion sound are determined according to the dynamic process of fuel consumption, and then, the corresponding explosive sound is extracted from the recording examples according to the high-frequency content. For the combustion noise, we propose a synthesis method of combustion noise on the basis of the timbre similarity between sound examples and low-frequency combustion noise generated by a physical method. Finally, the two types of sound are blended respecting the occurrence and duration of the explosions and combustions parts detected in the visual stream. Our experiments and the user study show the results of our method and demonstrate the effectiveness of our method.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Fluid animations, such as explosion (Yngve et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Yngve GD, O’Brien JF, Hodgins JK (2000) Animating explosions. In: ACM SIGGRAPH. pp 29–36" href="/article/10.1007/s10055-019-00408-7#ref-CR37" id="ref-link-section-d47354e290">2000</a>), fire (Smith and Ericson <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Smith S, Ericson E (2009) Using immersive game-based virtual reality to teach fire-safety skills to children. Virtual Real 13(2):87–99" href="/article/10.1007/s10055-019-00408-7#ref-CR30" id="ref-link-section-d47354e293">2009</a>) and water (Liu and Xiong <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Liu S, Xiong Y (2013) Fast and stable simulation of virtual water scenes with interactions. Virtual Real 17(1):77–88" href="/article/10.1007/s10055-019-00408-7#ref-CR14" id="ref-link-section-d47354e296">2013</a>), are becoming more and more common in films, games and interactive virtual environment. Adding sound to these scenes is of importance to enhance the immersion quality of virtual reality scenes. At present, there are some successful works for synthesizing synchronous fluid sounds, such as fire (Chadwick and James <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Chadwick JN, James DL (2011) Animating fire with sound. ACM Trans Graph 30(4):84–92" href="/article/10.1007/s10055-019-00408-7#ref-CR3" id="ref-link-section-d47354e299">2011</a>; Yin and Liu <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e302">2018</a>), or water (Moss et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Moss W, Yeh H, Hong JM, Lin MC, Manocha D (2010) Sounding liquids: automatic sound synthesis from fluid simulation. ACM Trans Graph 29(3):1–13" href="/article/10.1007/s10055-019-00408-7#ref-CR18" id="ref-link-section-d47354e306">2010</a>; Wang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Wang K, Cheng H, Liu S (2017) Efficient sound synthesis for natural scenes. In: IEEE virtual reality. pp 303–304" href="/article/10.1007/s10055-019-00408-7#ref-CR35" id="ref-link-section-d47354e309">2017</a>). However, little attention has been paid to automatic sound synthesis for explosion. The main reason is that there are multiple types of sound (e.g., explosive sound, combustion noise) in the process of explosion, and their physical mechanisms are complicated.</p><p>Previous studies have simplified the explosion as a combustion phenomenon and synthesized several examples of explosion sound (Dobashi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Dobashi Y, Yamamoto T, Nishita T (2004) Synthesizing sound from turbulent field using sound textures for interactive fluid simulation. Comput Graph Forum 23(3):539–545" href="/article/10.1007/s10055-019-00408-7#ref-CR7" id="ref-link-section-d47354e315">2004</a>; Yin and Liu <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e318">2018</a>). However, there are not only burning but also fireball and other main visual phenomena in the explosion. Moreover, the explosive sound corresponding to the fireball phenomenon is essential. Dobashi et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Dobashi Y, Yamamoto T, Nishita T (2004) Synthesizing sound from turbulent field using sound textures for interactive fluid simulation. Comput Graph Forum 23(3):539–545" href="/article/10.1007/s10055-019-00408-7#ref-CR7" id="ref-link-section-d47354e321">2004</a>) proposed a method to generate flame noise based on flame animation, which focuses on the complex motion of vortices and simulates vortex noise by calculating vortices with computational fluid dynamics. This method first synthesizes the sound texture of vortex noise in off-line phase and then synthesizes the sound of explosion and flame in real time. Their method produced the explosive sound by rapidly reducing the velocity of their explosion products around the center of explosion. Since their sound synthesis model is designed to simulate vortex sound, which is only a small part of the explosion sound, their synthesis result is not very accurate. Yin and Liu’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e324">2018</a>) also got the explosive sound by adding popping sound to the generated fire sound. Their method adds popping sound to the whole explosion process, which may lead to incorrect noise in the resulting explosion sound. Therefore, we need to develop a special method to synthesize the explosive sound synchronized with fireballs.</p><p>As for the synthesis of flame sound, previous methods typically synthesize low-frequency fire sound by physically based method and then supplement the high-frequency details with non-physical methods (Chadwick and James <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Chadwick JN, James DL (2011) Animating fire with sound. ACM Trans Graph 30(4):84–92" href="/article/10.1007/s10055-019-00408-7#ref-CR3" id="ref-link-section-d47354e330">2011</a>; Yin and Liu <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e333">2018</a>), which may lead to the lack of mid-frequency information in the resulting fire sound. Conversely, in real flame sound, the mid-frequency “whooshing” behavior is common (Marelli et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Marelli D, Aramaki M, Kronland-Martinet R, Verron C (2012) An efficient time–frequency method for synthesizing noisy sounds with short transients and narrow spectral components. IEEE Trans Audio Speech Lang Process 20(4):1400–1408" href="/article/10.1007/s10055-019-00408-7#ref-CR17" id="ref-link-section-d47354e336">2012</a>).</p><p>To this end, we propose a new method for automatic synthesis of explosion sound, which accounts for two primary sources of acoustic emissions from explosion, namely explosive sound and combustion noise. These two types of sound correspond to the fireball and burning animation in the explosion, respectively. They are synthesized in two stages based on the real sound examples and the state variables derived from the physically based explosion animation. To begin with, on the basis of real explosion sound example, we synthesize the resulting explosive sound synchronizing with the fireball by utilizing the dynamic process of fuel consumption in the process of producing the explosion animation. In addition, different from previous synthesis methods of combustion noise, we propose an effective approach which can synthesize the combustion noise that conforms to the texture features of the real flame sound. Exploiting the timbre similarity between sound examples and low-frequency combustion noise generated by a physical method, the combustion noise synchronizing with combustion animation can be automatically synthesized. Instead of producing the combustion noise matching the animation only according to the velocity of the gas product, our method can guarantee the authenticity of the resulting sound while ensuring synchronism. Finally, according to the occurrence and duration of the explosive sound determined by the fuel consumption in explosion animation, we blended the two types of sound to get a reasonable explosion sound.</p><p>The main contributions of our work can be summarized as follows:</p><ol class="u-list-style-none"><li><span class="u-custom-list-number">1.</span><p>A novel, automatic sound synthesis method for explosion animations is proposed, which can produce plausible sound results synchronized with the visual explosion animations.</p></li><li><span class="u-custom-list-number">2.</span><p>We consider the explosive sound and combustion noise in the explosion phenomenon and combine the physical information of animations with the real sound examples to ensure the integrity and authenticity of the explosion sound.</p></li><li><span class="u-custom-list-number">3.</span><p>We propose a new method for synthesizing combustion noise based on timbre similarity between sound examples and low-frequency combustion noise generated by a physical method. The appropriate combustion noise can be synthesized by this way.</p></li></ol></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Related work</h2><div class="c-article-section__content" id="Sec2-content"><p>The purpose of this paper is to automatically synthesize the explosion sound corresponding to the mainly visual phenomena of the explosion. Therefore, we mainly discuss the previous methods related to the sound synthesis and fluid animation.</p><h3 class="c-article__sub-heading" id="Sec3">Sound synthesis</h3><p>The physical basis for producing fluid sound has been intensively studied (Prosperetti <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Prosperetti A (1988) Bubble dynamics in oceanic ambient noise. Springer, Dordrecht" href="/article/10.1007/s10055-019-00408-7#ref-CR22" id="ref-link-section-d47354e377">1988</a>; Longuethiggins <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1990" title="Longuethiggins MS (1990) An analytic model of sound production by raindrops. Fluid Mech 214:395–410" href="/article/10.1007/s10055-019-00408-7#ref-CR16" id="ref-link-section-d47354e380">1990</a>; Crighton et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Crighton D, Dowling A, Ffowcs-Williams J, Heckl M, Leppington F, Bartram JF (1992) Modern methods in analytical acoustics. Springer, Berlin" href="/article/10.1007/s10055-019-00408-7#ref-CR4" id="ref-link-section-d47354e383">1992</a>). Based on this, researchers in the field of computer graphics have made great success in fluid sound synthesis (Doel <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Doel KVD (2005) Physically-based models for liquid sounds. ACM Trans Appl Percept 2(4):534–546" href="/article/10.1007/s10055-019-00408-7#ref-CR8" id="ref-link-section-d47354e386">2005</a>; Dobashi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Dobashi Y, Yamamoto T, Nishita T (2003) Real-time rendering of aerodynamic sound using sound textures based on computational fluid dynamics. In: ACM SIGGRAPH. pp 732–740" href="/article/10.1007/s10055-019-00408-7#ref-CR6" id="ref-link-section-d47354e389">2003</a>; Chadwick and James <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Chadwick JN, James DL (2011) Animating fire with sound. ACM Trans Graph 30(4):84–92" href="/article/10.1007/s10055-019-00408-7#ref-CR3" id="ref-link-section-d47354e393">2011</a>). Among them, the synthesis of fire sound has attracted more and more attention. Dobashi et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Dobashi Y, Yamamoto T, Nishita T (2004) Synthesizing sound from turbulent field using sound textures for interactive fluid simulation. Comput Graph Forum 23(3):539–545" href="/article/10.1007/s10055-019-00408-7#ref-CR7" id="ref-link-section-d47354e396">2004</a>) synthesized the turbulent sound according to the vortex motion of fluid (Powell <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Powell A (2003) Theory of vortex sound. Cambridge University Press, Cambridge" href="/article/10.1007/s10055-019-00408-7#ref-CR21" id="ref-link-section-d47354e399">2003</a>). In their experiments, the sound of flames and explosions has been synthesized. However, whether it is a flame or an explosion, their sound is multi-source because it builds from contributions from a continuous and large region of space, where there are combustion phenomena or shock wave propagation. Moreover, it is impossible to simulate all sound sources by using physically based method due to the large amount of computational overhead. Therefore, in the follow-up studies, researchers began to use a hybrid approach for fire sound synthesis.</p><p>
Chadwick and James (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Chadwick JN, James DL (2011) Animating fire with sound. ACM Trans Graph 30(4):84–92" href="/article/10.1007/s10055-019-00408-7#ref-CR3" id="ref-link-section-d47354e405">2011</a>) pioneered the use of physically based methods to synthesize the low-frequency flame noise, while spectral bandwidth extension or sound texture synthesis was used to supplement high-frequency noise. This method can synthesize sound effects that are greatly synchronized with the flame animation. However, their method of calculating low-frequency sound pressure is not totally efficient. Later, Liu and Yu (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Liu S, Yu Z (2015) Sounding fire for immersive virtual reality. Virtual Real 19(3–4):291–302" href="/article/10.1007/s10055-019-00408-7#ref-CR15" id="ref-link-section-d47354e408">2015</a>) put forward an efficient method to calculate the low-frequency noise and added the middle- and high-frequency wavelet details in the low-frequency content to produce the fire sound. The latest flame sound synthesis method by Yin and Liu (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e411">2018</a>) can synthesize different sounds according to solid materials, which took into account both the direct combustion noise and the vortex sound. Yin and Liu (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e414">2018</a>) also used explosion as a form of fire to get explosion sound by adding sound textures to the resulting fire sound. However, the resulting explosion sound contains some undesired noises. Moreover, when using Yin and Liu’s method to synthesize the fire sound, there is a strict requirement for the sound examples to be used, i.e., the sound examples must contain obvious popping sound produced by the combustion of different materials.</p><p>Non-physical methods are also widely used in the field of sound synthesis; for example, signal processing (Marelli et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Marelli D, Aramaki M, Kronland-Martinet R, Verron C (2012) An efficient time–frequency method for synthesizing noisy sounds with short transients and narrow spectral components. IEEE Trans Audio Speech Lang Process 20(4):1400–1408" href="/article/10.1007/s10055-019-00408-7#ref-CR17" id="ref-link-section-d47354e420">2012</a>), sound texture modeling and synthesis (Schwarz <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Schwarz D (2011) State of the art in sound texture synthesis. In: Digital audio effects (DAFx-12). pp 151–171" href="/article/10.1007/s10055-019-00408-7#ref-CR26" id="ref-link-section-d47354e423">2011</a>; Kersten and Purwins <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Kersten S, Purwins H (2013) Fire texture sound re-synthesis using sparse decomposition and noise modelling. In: Digital audio effects. pp 1–5" href="/article/10.1007/s10055-019-00408-7#ref-CR13" id="ref-link-section-d47354e426">2013</a>), wavelet tree learning (Dubnov et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Dubnov S, Barjoseph Z, Ran EY, Lischinski D, Werman M (2002) Synthesizing sound textures through wavelet tree learning. IEEE Comput Graph Appl 22(4):38–48" href="/article/10.1007/s10055-019-00408-7#ref-CR9" id="ref-link-section-d47354e429">2002</a>) and granular synthesis (Roads <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Roads C (2004) Microsound. The MIT Press, Cambridge" href="/article/10.1007/s10055-019-00408-7#ref-CR23" id="ref-link-section-d47354e432">2004</a>) are all available for sound synthesis. Among them, sound texture modeling by granular synthesis is a classical method of synthesizing environmental sound. Existing granular synthesis methods for sound texture are often concerned with the variety and extension of a given recording, while keeping its overall properties and avoiding artifacts. Agostino (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Agostino DS (1999) Synthesis of environmental sound textures by iterated nonlinear functions. In: Digital audio effects. pp 109–117" href="/article/10.1007/s10055-019-00408-7#ref-CR1" id="ref-link-section-d47354e436">1999</a>) used a nonlinear iterative function to synthesize the sound texture of ambient sounds (including rain, burning sounds, etc.). Schwarz and Schnell (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Schwarz D, Schnell N (2008) Descriptor-based sound texture sampling. In: Sound and music computing. pp 510–515" href="/article/10.1007/s10055-019-00408-7#ref-CR29" id="ref-link-section-d47354e439">2008</a>) proposed a descriptor-based sound texture sampling method, so that the resulting sound texture is controllable. In the research of Schwarz and O’Leary (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Schwarz D, O’Leary S (2015) Smooth granular sound texture synthesis by control of timbral similarity. In: Sound and music computing. pp 471 – 476" href="/article/10.1007/s10055-019-00408-7#ref-CR28" id="ref-link-section-d47354e442">2015</a>), a method of synthesizing sound textures of any length by controlling the timbre similarity of grains is proposed. In this method, it is proved by listening test that the generated sound using descriptor-based distance is more natural than that mel-frequency cepstrum coefficients (MFCC)-based distance. Our synthesis method of combustion noise is inspired by the research, but the animation synchronization is considered. However, the aforementioned methods only focus on the synthesis of real sound, without considering the effect of synchronizing with visual animation. By means of user annotations, although, Schwarz and Caramiaux (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Schwarz D, Caramiaux B (2014) Interactive sound texture synthesis through semi-automatic user annotations. In: Lecture notes in computer science. pp 372–392" href="/article/10.1007/s10055-019-00408-7#ref-CR27" id="ref-link-section-d47354e445">2014</a>) proposed a semiautomatic interactive sound texture synthesis method, which can synthesize audio synchronously with film. However, in this method, recording still needs to be annotated artificially, so this method cannot automatically synthesize sound synchronized with the animation.</p><p>In the computer graphics community, researchers used non-physically based methods to automatically synthesize sounds synchronized with animations using some parameters derived from physically based animation (An et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="An SS, James DL, Marschner S (2012) Motion-driven concatenative synthesis of cloth sounds. ACM Trans Graph 31(4):1–10" href="/article/10.1007/s10055-019-00408-7#ref-CR2" id="ref-link-section-d47354e451">2012</a>; Schreck et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Schreck C, Rohmer D, James DL, Hahmann S, Cani MP (2016) Real-time sound synthesis for paper material based on geometric analysis. In: ACM SIGGRAPH. pp 211–220" href="/article/10.1007/s10055-019-00408-7#ref-CR25" id="ref-link-section-d47354e454">2016</a>; Wang and Liu <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Wang K, Liu S (2018) Example-based synthesis for sound of ocean waves caused by bubble dynamics. Comput Animat Virtual Worlds 29(4):e1835" href="/article/10.1007/s10055-019-00408-7#ref-CR34" id="ref-link-section-d47354e457">2018</a>). An et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="An SS, James DL, Marschner S (2012) Motion-driven concatenative synthesis of cloth sounds. ACM Trans Graph 31(4):1–10" href="/article/10.1007/s10055-019-00408-7#ref-CR2" id="ref-link-section-d47354e460">2012</a>) proposed a concatenative sound synthesis method for cloth animation, in which a low-quality sound signal is synthesized firstly, and then, according to the mel-frequency cepstrum coefficients (MFCC) of the signal, short sounds matching the material animation are selected from real recording. The selected short sounds are concatenated together to produce the final cloth sound. Our combustion noise is synthesized based on the signal’s timbre descriptor which makes it possible to synthesize more natural sounds.</p><h3 class="c-article__sub-heading" id="Sec4">Fluid simulation</h3><p>Fluid simulation and control have a long history in computer animation (Dobashi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Dobashi Y, Kaneda K, Yamashita H, Okita T, Nishita T (2000) A simple, efficient method for realistic animation of clouds. In: ACM SIGGRAPH. pp 19–28" href="/article/10.1007/s10055-019-00408-7#ref-CR5" id="ref-link-section-d47354e471">2000</a>; Nguyen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Nguyen DQ, Fedkiw R, Jensen HW (2002) Physically based modeling and animation of fire. ACM Trans Graph 21(3):721–728" href="/article/10.1007/s10055-019-00408-7#ref-CR19" id="ref-link-section-d47354e474">2002</a>; Sato et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Sato S, Mizutani K, Dobashi Y, Nishita T, Yamamoto T (2017) Feedback control of fire simulation based on computational fluid dynamics. Comput Animat Virtual Worlds 28(3–4):e1766" href="/article/10.1007/s10055-019-00408-7#ref-CR24" id="ref-link-section-d47354e477">2017</a>; Feng and Liu <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Feng G, Liu S (2018) Detail-preserving sph fluid control with deformation constraints. Comput Animat Virtual Worlds 29(1):e1781" href="/article/10.1007/s10055-019-00408-7#ref-CR11" id="ref-link-section-d47354e480">2018</a>). Stam (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Stam J (1999) Stable fluids. In: Proceedings of the 26th annual conference on computer graphics and interactive techniques. pp 121–128" href="/article/10.1007/s10055-019-00408-7#ref-CR31" id="ref-link-section-d47354e483">1999</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Stam J (2000) Interacting with smoke and fire in real time. Commun ACM 43(7):76–83" href="/article/10.1007/s10055-019-00408-7#ref-CR32" id="ref-link-section-d47354e487">2000</a>) firstly proposed an unconditional stable model and realized fast fluid simulation. To model the explosion animation, Yngve et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Yngve GD, O’Brien JF, Hodgins JK (2000) Animating explosions. In: ACM SIGGRAPH. pp 29–36" href="/article/10.1007/s10055-019-00408-7#ref-CR37" id="ref-link-section-d47354e490">2000</a>) modeled the propagation of an explosion through the surrounding air using a computational fluid dynamics-based method to solve the equations for compressible, viscous flow. Their system included two-way coupling between solid objects and surrounding fluid and used the spectacular brittle fracture technology in O’Brien et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="O’Brien JF, Bargteil AW, Hodgins JK (2002) Graphical modeling and animation of ductile fracture. ACM Trans Graph 21(3):291–294" href="/article/10.1007/s10055-019-00408-7#ref-CR20" id="ref-link-section-d47354e493">2002</a>). However, using the compressible fluid method to compute the explosive behavior is expensive. When the explosion is shown in animation, in fact, only the main visual phenomena such as fireball and combustion are displayed. Feldman et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Feldman BE, O’brien JF, Arikan O (2003) Animating suspended particle explosions. ACM Trans Graph 22(3):708–715" href="/article/10.1007/s10055-019-00408-7#ref-CR10" id="ref-link-section-d47354e496">2003</a>) proposed a method for simulating the suspended particle explosion animations. They modeled the mixture of air and gaseous combustion products of explosions using a slightly modified version of the fluid model applied in Stam et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Stam J, Stam J, Jensen HW (2001) Visual simulation of smoke. In: ACM SIGGRAPH. pp 15–22" href="/article/10.1007/s10055-019-00408-7#ref-CR33" id="ref-link-section-d47354e499">2001</a>). They explicitly ignored the behavior of the wave and simulated the effect of the initial detonation outward flow by rapidly increasing the velocity divergence to the peak. Note that the explosion animations we simulated are gas explosion, and those effects of fireball and combustion can be well simulated.</p></div></div></section><section aria-labelledby="Sec5"><div class="c-article-section" id="Sec5-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec5">Overview</h2><div class="c-article-section__content" id="Sec5-content"><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig1">1</a> illustrates the whole framework of our method.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig1_HTML.png?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig1_HTML.png" alt="figure1" loading="lazy" width="685" height="338" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>The framework of our new method for explosion sound synthesis</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p> Firstly, a physically based visual explosion model is used to simulate the explosion animation, which, together with the explosion and combustion sound examples, are used as the input to the whole framework. Then, we divide into two stages the synthesis of explosive sound and combustion noise corresponding to the fireball and flame combustion, respectively. For the synthesis of explosive sound, we first determine the occurrence and duration of explosive sound according to the dynamic process of fuel consumption, and then, we extract the corresponding explosive sound from the recording example based on the high-frequency content. For the combustion noise in explosion animation, so as in An et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="An SS, James DL, Marschner S (2012) Motion-driven concatenative synthesis of cloth sounds. ACM Trans Graph 31(4):1–10" href="/article/10.1007/s10055-019-00408-7#ref-CR2" id="ref-link-section-d47354e522">2012</a>), we propose a synthesis method of combustion noise according to the timbre similarity between sound examples and low-frequency combustion noise generated by a physical method. In this method, by comparing the timbre similarity, we can select the combustion noise which is the closest to the low-frequency combustion noise from a corpus of flame noise. Finally, the two types of sound are blended in the corresponding time which is determined by the variation of fuel source volume. Thus, the explosion sound which is synchronous with the explosion animation is synthesized.</p></div></div></section><section aria-labelledby="Sec6"><div class="c-article-section" id="Sec6-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec6">Physically based explosion simulation and low-frequency explosion sound synthesis</h2><div class="c-article-section__content" id="Sec6-content"><h3 class="c-article__sub-heading" id="Sec7">Explosion animation</h3><p>Physically based visual explosion simulation provides important physics information for our automatic sound synthesis method in terms of synchronism. We simulated the gas explosion animations, where gaseous products and fuel of explosions are treated as a slightly modified version of incompressible, inviscid fluid that fills a rectilinear three-dimensional grid. The motion of the fluid obeys the momentum conservation which is enforced by the following Euler equations:</p><div id="Equ1" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \frac{{\partial \mathbf{{v}}}}{{\partial t}} = - \nabla p/\rho - \mathbf{{v}} \cdot \nabla \mathbf{{v}} + \mathbf{{f}}/\rho \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (1)
                </div></div><p>where <span class="mathjax-tex">\(\mathbf{{v}}\)</span> is the fluid velocity, <span class="mathjax-tex">\(\nabla p\)</span> represents the pressure gradient causing velocity to move from areas of high pressure to areas of low pressure, <span class="mathjax-tex">\(\rho\)</span> is the density and <span class="mathjax-tex">\(\mathbf{{f}}\)</span> refers to the external force acting on the velocity field, such as vorticity confinement force, gravity and buoyancy.</p><p>For an incompressible fluid, the velocity divergence is zero according to the mass conservation. However, as the temperature of the fluid rises during the explosion, it causes thermal expansion; we require each fluid cell:</p><div id="Equ2" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \nabla \cdot \mathbf{{v}} = \phi \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (2)
                </div></div><p>where <span class="mathjax-tex">\(\phi\)</span> is proportional to temperature changes (Feldman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Feldman BE, O’brien JF, Arikan O (2003) Animating suspended particle explosions. ACM Trans Graph 22(3):708–715" href="/article/10.1007/s10055-019-00408-7#ref-CR10" id="ref-link-section-d47354e656">2003</a>).</p><p>Equation (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10055-019-00408-7#Equ2">2</a>) can be enforced by solving a slightly modified version of the Poisson’s equation (Feldman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Feldman BE, O’brien JF, Arikan O (2003) Animating suspended particle explosions. ACM Trans Graph 22(3):708–715" href="/article/10.1007/s10055-019-00408-7#ref-CR10" id="ref-link-section-d47354e665">2003</a>):</p><div id="Equ3" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} {\nabla ^2}p = \frac{\rho }{{\Delta t}}(\nabla \mathbf{{v}} - \phi ) \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (3)
                </div></div><p>At the time of the initial detonation, the divergence value of <span class="mathjax-tex">\(\phi\)</span> rises rapidly until it reaches the peak value determined by the detonation intensity. Then, it decays back to zero, slightly negative, and finally stabilizes again at zero. That is, the result is a discrete approximation of a continuous incompressible flow field, which moves outward at the place where the expansion occurs (or, inward if <span class="mathjax-tex">\(\phi &lt; 0\)</span>).</p><p>We model the explosion animations using Houdini’s Pyro FX explosion component. According to the Houdini’s Pyro FX solver, fuel is stored as a volume field in pace with velocity, temperature, etc. Fuel has an associated ignition temperature <span class="mathjax-tex">\({T_0}\)</span> and burn rate <i>b</i>. Within a given time step <span class="mathjax-tex">\(\Delta t\)</span>, if voxel (<i>i</i>, <i>j</i>, <i>k</i>) has fuel concentration <span class="mathjax-tex">\({f_{ijk}} &gt; 0\)</span> and temperature <span class="mathjax-tex">\({T_{ijk}} &gt; {T_0}\)</span>, then a quantity of fuel <span class="mathjax-tex">\(\Delta {f_{ijk}} = \Delta tb\)</span> is consumed and removed from voxel (<i>i</i>, <i>j</i>, <i>k</i>). According to fuel consumption, temperature, divergence source and density are modified. It is important to note that the source volume of fuel varies over time. The explosion occurred at the time when fuel consumption is far greater than the amount of fuel consumed during combustion.</p><h3 class="c-article__sub-heading" id="Sec8">Low-frequency explosion sound generation</h3><p>Our synthesized explosion sounds mainly consist of the explosive sound and combustion noise corresponding to the fireball and combustion appearance. Explosion sounds are multi-source, so it is quite difficult to simulate all the sound sources of explosion completely using physically based methods. On the other hand, the sounds synthesized by non-physical method cannot achieve the effect of automatic synchronization with animations (Dubnov et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Dubnov S, Barjoseph Z, Ran EY, Lischinski D, Werman M (2002) Synthesizing sound textures through wavelet tree learning. IEEE Comput Graph Appl 22(4):38–48" href="/article/10.1007/s10055-019-00408-7#ref-CR9" id="ref-link-section-d47354e838">2002</a>; Marelli et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Marelli D, Aramaki M, Kronland-Martinet R, Verron C (2012) An efficient time–frequency method for synthesizing noisy sounds with short transients and narrow spectral components. IEEE Trans Audio Speech Lang Process 20(4):1400–1408" href="/article/10.1007/s10055-019-00408-7#ref-CR17" id="ref-link-section-d47354e841">2012</a>). Therefore, the synthesis of sounds based on physical methods is an essential part to automatically match the visual animation.</p><p>Since our physically based explosion model does not simulate shock waves, the explosion animations we simulate are actually deflagration animation with initial explosive detonation. The direct combustion noise caused by the unstable density fluctuation resulting from heat release is the dominant source of combustion phenomenon, and it is also the main sound source of the simulated explosion sound (Ihme et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Ihme M, Pitsch H, Bodony D (2009) Radiation of noise in turbulent non-premixed flames. Proc Combust Inst 32(1):1545–1553" href="/article/10.1007/s10055-019-00408-7#ref-CR12" id="ref-link-section-d47354e847">2009</a>). Crighton et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Crighton D, Dowling A, Ffowcs-Williams J, Heckl M, Leppington F, Bartram JF (1992) Modern methods in analytical acoustics. Springer, Berlin" href="/article/10.1007/s10055-019-00408-7#ref-CR4" id="ref-link-section-d47354e850">1992</a>) pointed out that it can be represented by the following linear wave equation:</p><div id="Equ4" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} {\nabla ^2}p - \frac{{{\partial ^2}p}}{{c_0^2\partial {t^2}}} = \frac{\partial }{{\partial t}}\left( \frac{{{\rho _0}q(\varUpsilon - 1)}}{{\rho {c^2}}}\right) \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (4)
                </div></div><p>where <i>p</i>, <i>c</i>, <span class="mathjax-tex">\(\varUpsilon\)</span>, <i>q</i> and <span class="mathjax-tex">\(\rho\)</span> represent the pressure of the air around the explosion, speed of sound, specific heat ratio, heat release and density, respectively; <span class="mathjax-tex">\({c_0}\)</span> and <span class="mathjax-tex">\({\rho _0}\)</span> represent the ambient speed of sound and density.</p><p>The sound pressure of the explosion animation we simulated can be obtained by using free-space Green’s function (Crighton et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Crighton D, Dowling A, Ffowcs-Williams J, Heckl M, Leppington F, Bartram JF (1992) Modern methods in analytical acoustics. Springer, Berlin" href="/article/10.1007/s10055-019-00408-7#ref-CR4" id="ref-link-section-d47354e967">1992</a>) to solve Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10055-019-00408-7#Equ4">4</a>):</p><div id="Equ5" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} p(\mathbf{{x}},t) = \frac{{\varUpsilon - 1}}{{4\pi c_0^2}}\frac{\partial }{{\partial t}}\int _{{R^3}} {\frac{{[q]}}{{||\mathbf{{x}} - \mathbf{{y}}||}}{{\rm d}^3}{} \mathbf{{y}}} \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (5)
                </div></div><p>where <span class="mathjax-tex">\(\mathbf{{x}}\)</span> and <span class="mathjax-tex">\(\mathbf{{y}}\)</span> are the positions of the listener and sound source, respectively. [<i>q</i>] is evaluated at <span class="mathjax-tex">\(t - ||\mathbf{{x}} - \mathbf{{y}}||/{c_0}\)</span>.</p><p>In order to model the noise output of explosion, we assume that the heat release caused by the velocity fluctuation on the front surface of the explosion animation is proportional to the velocity flux near the <span class="mathjax-tex">\(\mathbf{{x}}\)</span> point. We ignore the constant terms in Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10055-019-00408-7#Equ5">5</a>), the distance decay and the time delay, which control only the fixed-scaled terms of the sound. At the same time, by using Gauss divergence theorem, the surface integral of a explosion front surface can be transformed into the volume integral of divergence. The combustion noise can be generated by using the following formula:</p><div id="Equ6" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} p(t) = \frac{{\mathrm{d}}}{{{\mathrm{d}}t}}\int _V {\nabla \cdot \mathbf{{v}}} (\mathbf{{x}},t){\mathrm{d}}v(\mathbf{{x}}) \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (6)
                </div></div><p>where the velocity field <span class="mathjax-tex">\(\mathbf{{v}}\)</span> is time-dependent, <span class="mathjax-tex">\(\mathbf{{v}}(\mathbf{{x}},t)\)</span> refers to the velocity at the position <span class="mathjax-tex">\(\mathbf{{x}}\)</span> and at time <i>t</i>.</p><p>According to the marching-cube-like method, the explosion sound can be calculated (Liu and Yu <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Liu S, Yu Z (2015) Sounding fire for immersive virtual reality. Virtual Real 19(3–4):291–302" href="/article/10.1007/s10055-019-00408-7#ref-CR15" id="ref-link-section-d47354e1225">2015</a>). We discretize the simulation space into <span class="mathjax-tex">\(M \times N \times L\)</span> cubes uniformly and calculate the value <span class="mathjax-tex">\({\varphi _{{x_i}}}\)</span> in the burning field at the vertex of each cube. Each cube voxel is traversed to get its volume <span class="mathjax-tex">\(\delta v\)</span> after we get <span class="mathjax-tex">\({\varphi _{{x_i}}}\)</span>. If <span class="mathjax-tex">\(\delta v &gt; 0\)</span>, the velocity divergence is <span class="mathjax-tex">\(\nabla \mathbf{{v}}\)</span>. Otherwise, the data are 0. We add the products of <span class="mathjax-tex">\(\nabla \mathbf{{v}}\)</span> and <span class="mathjax-tex">\(\delta v\)</span> to get the velocity divergence integral:</p><div id="Equ7" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \int _V {\nabla \cdot } \mathbf{{v}}{{\mathrm{d}}_v} = \sum {\nabla \cdot \mathbf{{v}}\delta v} \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (7)
                </div></div><p>Due to the limitation of computer resource budget allocation, it is not realistic to synthesize a complete explosion sound by using physical method, nor can it be realized in existing methods (Chadwick and James <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Chadwick JN, James DL (2011) Animating fire with sound. ACM Trans Graph 30(4):84–92" href="/article/10.1007/s10055-019-00408-7#ref-CR3" id="ref-link-section-d47354e1369">2011</a>; Yin and Liu <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e1372">2018</a>). Therefore, in order to meet the requirements of the bandwidth, in all of our experiments, only the low-frequency explosion sound with a time-stepping rate of 360 Hz is simulated.</p></div></div></section><section aria-labelledby="Sec9"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">Explosive sound synthesis</h2><div class="c-article-section__content" id="Sec9-content"><p>The explosive sound is generated by a large amount of energy released, which is a brief and intense transient sound that is accompanied by the phenomenon of fireball. In order to obtain the explosive sound that matches the explosion animation, based on the real sound examples, we propose a synthesis method of explosive sound using the dynamic changes of fuel consumption. First of all, according to the fuel source volume variation, we can determine the occurrence and duration of explosive sound and the section that is considered to be the explosive sound. Then, according to the duration of the explosive sound, we propose an explosive sound extraction method based on the high-frequency contents, which can accurately extract the explosive sound of the corresponding length from an explosion recording. Thus, the explosive sound matching the fireball animation is obtained.</p><p>In our simulated explosion animations, the fuel is stored as a volume field, which is the source of energy during the whole explosion process. At the time of initial explosion, the expansion rate of fireball is far greater than that of combustion (Nguyen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Nguyen DQ, Fedkiw R, Jensen HW (2002) Physically based modeling and animation of fire. ACM Trans Graph 21(3):721–728" href="/article/10.1007/s10055-019-00408-7#ref-CR19" id="ref-link-section-d47354e1387">2002</a>). In other words, the fuel consumption is much larger in the initial stage of the explosion than that in the combustion process. Therefore, we can determine the occurrence and duration of explosive sound based on the dynamic change of fuel source volume, and thus can determine the length of the explosive sound example that needs to be extracted.</p><p>In all the experiments of this paper, the explosion animations have a frame rate of 30FPS. We can only get the fuel parameters of each frame in an animation. However, the sampling frequency of the sound we generate is 44.1 kHz. We have to reconstruct the fuel curve of the explosion animation by upsampling. We use cubic spline interpolation with <span class="mathjax-tex">\({C^3}\)</span> continuity at end points. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig2">2</a> shows the reconstruction results of the fuel source volume of nuclear explosion, smoke explosion, continuous explosion and light explosion animations (from left to right).</p><p>After reconstructing the fuel source volume variation curve, in order to determine the occurrence and duration of explosive sound, according to the change curve of fuel consumption, we assume that when the maximum value within interval is greater than 1.5, it means that fireballs appear in the interval <span class="mathjax-tex">\(\theta\)</span>, and the left minimum is the initial explosive time. We treat the boundary points as extreme points as well. Taking into account the decay delay of the explosive sound, based on empirical judgment, the final duration of the explosive sound is set to be <span class="mathjax-tex">\(5\theta\)</span>, which is also the occurrence and duration of explosive sound in the generated low-frequency explosion sound.</p><p>We conducted an experimental analysis of explosion sound examples, and the results show that the high-frequency sound content is the highest in explosive sound. Therefore, in order to accurately extract the explosive sound, we provide a method of extracting explosive sound based on high-frequency content in a relative time. According to the duration of the explosive sound, we extract the explosive sound from a explosion sound example by the following operation. Firstly, we select an explosion recording and divide it into frames with a frame length of <span class="mathjax-tex">\(\theta\)</span> and a time shift of <span class="mathjax-tex">\(\tau\)</span> that is taken as 200 ms in our experiments. Then, starting from the frame containing the most high-frequency content, 5 frames were selected continuously as the explosive sound matching the fireball animation in explosion.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig2_HTML.png?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig2_HTML.png" alt="figure2" loading="lazy" width="685" height="117" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Reconstruction results of fuel source volume for different scenarios</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig3">3</a> shows the spectrograms of the three real explosion sounds used in our experiments and the segmentation results according to high-frequency content of the three examples for nuclear explosion, smoke explosion and light explosion animations (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-019-00408-7#Tab1">1</a>). The first and second explosive sound in the continuous explosion animation occurs for the same duration as the smoke explosion animation and light explosion animation, respectively. Therefore, we do not show the results of the segmentation of the sound examples by the continuous explosion animation. These sound examples used came from an audio library (<a href="https://1soundfx.com">https://1soundfx.com</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig3_HTML.png?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig3_HTML.png" alt="figure3" loading="lazy" width="685" height="635" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Spectrograms of sound examples and segmentation results. <b>a</b> The spectrograms of different explosion sound examples used in experiments. <b>b</b> The segmentation results of the three examples for nuclear explosion, <b>c</b> the segmentation results of the three examples for smoke explosion, <b>d</b> the segmentation results of the three examples for light explosion</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div></div></div></section><section aria-labelledby="Sec10"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Combustion noise synthesis</h2><div class="c-article-section__content" id="Sec10-content"><p>Combustion is one of the main visual phenomena in explosion animations, so the synthesis of combustion noise in explosion is very critical. As aforementioned, it is not realistic to simulate complete combustion noise by physical method. In the simulated explosion animation, gaseous fuel and explosive products are the main sources of combustion, and the phenomenon of deflagration often occurs. In this paper, a texture synthesis method of combustion noise based on timbre similarity of low-frequency combustion noise is proposed. </p><div class="c-article-section__figure c-article-section__figure--no-border" data-test="figure" data-container-section="figure" id="figure-a"><figure><div class="c-article-section__figure-content" id="Figa"><div class="c-article-section__figure-item"><div class="c-article-section__figure-content"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Figa_HTML.png?as=webp"></source><img aria-describedby="figure-a-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Figa_HTML.png" alt="figurea" loading="lazy" width="685" height="317" /></picture></div></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-a-desc"></div></div></figure></div><h3 class="c-article__sub-heading" id="Sec11">Timbre similarity sound synthesis</h3><p>For the synthesis of combustion noise in explosion animation, after the low-frequency explosion sound is obtained and the explosive sound is removed, we do not supplement the missing high-frequency detail for the low-frequency noise, but select the corresponding combustion noise from the combustion sound corpus according to the timbre characteristics of the generated low-frequency noise. Because the main information in a signal concentrated on the low-frequency component, we can find a plausible combustion noise from a flame sound corpus according to the timbre characteristics of the generated low-frequency combustion noise. By using the following algorithm, the combustion noise synchronized with the animation can be obtained:</p><ol class="u-list-style-none"><li><span class="u-custom-list-number">(1)</span><p>Construct two corpus which include the flame sound corpus <i>s</i> and the low-frequency flame sound corpus <i>l</i>. The low-frequency flame sound corpus is obtained by low-pass filtering of the recordings in the flame sound corpus.</p></li><li><span class="u-custom-list-number">(2)</span><p>Segment the recordings in both corpus into grains of 800 ms without overlap. Moreover, we also perform the same segmentation operation for the low-frequency combustion noise in explosion animation obtained in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-019-00408-7#Sec8">4.2</a>.</p></li><li><span class="u-custom-list-number">(3)</span><p>Analyze the timbre characteristics of each grain <i>i</i> for the generated low-frequency combustion noise <span class="mathjax-tex">\({g_i}\)</span> and the recording low-frequency noise <span class="mathjax-tex">\({l_j}\)</span> in a feature vector <span class="mathjax-tex">\({u_i}\)</span>, respectively. Firstly, the pitch <span class="mathjax-tex">\({P_i}\)</span>, loudness <span class="mathjax-tex">\({L_i}\)</span>, spectral flatness <span class="mathjax-tex">\({F_i}\)</span>, spectral centroid <span class="mathjax-tex">\({C_i}\)</span> and energy <span class="mathjax-tex">\({E_i}\)</span> characteristics of each grain are normalized. Then, we calculate the average value of these characteristics of each grain to get their timbre characteristics.</p></li><li><span class="u-custom-list-number">(4)</span><p>Start with the first generated low-frequency combustion noise grain, and the nearest grain is searched for it from the recording low-frequency sound grains. The distance function is an Euclidean distance of grain’s mean of characteristics.</p></li><li><span class="u-custom-list-number">(5)</span><p>Select the complete recording grain from the flame sound corpus corresponding to the grain obtained in the Step 4.</p></li><li><span class="u-custom-list-number">(6)</span><p>Repeat Step 4 and Step 5 until the corresponding recording grains are obtained for all generated low-frequency combustion noise grains. Thus, the complete fire sound <i>s</i> synchronized with animation can be generated. Algorithm 1 describes above process of combustion noise synthesis based on the timbre of low-frequency noise.</p></li></ol><h3 class="c-article__sub-heading" id="Sec12">Synchronized explosion sound synthesis</h3><p>During the explosion, the source volume of fuel varies over time. The sudden increase and decrease in the source volume of fuel lead to the production of the fireball, which is accompanied by the explosive sound. According to the phenomenon, we propose a method to synchronize the sound and animation of explosion based on the fuel supply. After getting the appropriate explosive sound and combustion noise, we blend them in the following way: the moment that a sudden increase in the source volume of fuel is used as the initial explosive detonation point for the explosive sound. Since the loudness of the explosive sound is far greater than that of the fire, the fire sound during the fireball is negligible. Therefore, we start from the initial point by adding the explosive sound to the combustion noise. Finally, we normalize the sound waves to get the resulting explosion sound.</p><p>It should be noted that due to the speed of sound, and the distance of the microphone from the explosion, the explosive sound we hear tends to be delayed for some time. As a result, we postpone the initial explosive detonation time by 200 milliseconds in our real experiments.</p></div></div></section><section aria-labelledby="Sec13"><div class="c-article-section" id="Sec13-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec13">Experiments and results</h2><div class="c-article-section__content" id="Sec13-content"><h3 class="c-article__sub-heading" id="Sec14">Sound synthesis in different scenes</h3><p>We demonstrate several results obtained using our new method, including nuclear explosion, smoke explosion, continuous explosion and the light explosion used for comparison test. The relevant parameters used in different scenarios are shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-019-00408-7#Tab1">1</a>. Our explosion animations are created by Side Effects Software’s Houdini Pyro FX solver, which uses a physical method to simulate the explosion animations (<a href="https://www.sidefx.com">https://www.sidefx.com</a>). All the experiments were performed under the same environment: Intel Core i5-4460 3.20 GHz CPU, NVIDIA GeForce GT745 GPU, 8 GB RAM.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 The parameters for different scenarios</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-019-00408-7/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Firstly, we apply the proposed method to the simulation of nuclear explosion, and the experiment is presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig4">4</a>. The synthetic combustion noise is obtained from a set of real flame sound examples based on the timbre characteristics of the low-frequency combustion noise generated by a physically based method. According to the segmentation result of example 1 that was segmented by the nuclear explosion in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig3">3</a>, we can extract the real explosive sound from the example. Finally, we blended the two types of sound according to the variation of fuel source volume to obtain the final explosion sound effects. Because the synthesized explosion sound is extracted from the real examples according to the physical parameters of explosion model, the synthesized explosion sound can guarantee the soundness as well as the synchronism with animation.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig4_HTML.png?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig4_HTML.png" alt="figure4" loading="lazy" width="685" height="295" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>The results of the synthesized nuclear explosion sound. The top row: the visual nuclear explosion model and the spectrogram of real explosion sound; the bottom row (from left to right): the spectrograms of the generated low-frequency explosion sound, the synthesized combustion noise and the resulting sound of nuclear explosion</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Then, we synthesized the sound of a smoke explosion to further verify the validity of our method. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig5">5</a> shows the simulated visual model of smoke explosion and its sound waveforms generated at various stages. The explosion sound is synthesized according to the physical characteristics of the explosion animation and the real sound examples. The waveforms in the figure from left to right are the waveforms of the composite low-frequency explosion sound, combustion noise and explosion sound results, respectively. We generate rich combustion noise results through timbre features of low-frequency explosion sound and then add explosive sound to respect the occurrence moment of explosion, which keeps time consistency with animation. The sound waveform in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig5">5</a> further verifies the validity of our method in time domain. In other words, our method is able to produce more realistic explosion sounds according to the specific situation of the explosion animation.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig5_HTML.png?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig5_HTML.png" alt="figure5" loading="lazy" width="685" height="322" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>The results of the synthesized smoke explosion sound. The top row: the visual smoke explosion model including fireball, burning and the diffused smoke; the bottom row (from left to right): the sound waveforms of the synthesized low-frequency explosion sound, the combustion noise and the resulting explosion sound, respectively</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Moreover, the sound of continuous explosion is also synthesized in our experiments. As shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig6">6</a>, the top row demonstrates visual model of the simulated continuous explosion and sound waveform of synthesized continuous explosion. The bottom row, from left to right, shows the spectrograms of the generated low-frequency continuous explosion sound, the combustion noise in continuous explosion sound and the synthesized continuous explosion sound, respectively. In this experiment, as a result of two explosions, we used our explosive sound synthesis method twice to synthesize the sound of continuous explosions. As can be seen from Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig6">6</a>, because the duration of the two explosive sounds is different, the final sound results are also different. This again proves the effectiveness of our method.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig6_HTML.png?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig6_HTML.png" alt="figure6" loading="lazy" width="685" height="360" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>The results of the synthesized continuous explosion sound. The top row: the visual model of continuous explosion and the sound waveform of synthesized continuous explosion; the bottom row (from left to right): the spectrograms of the generated low-frequency continuous explosion sound, the synthesized combustion noise in continuous explosion and the resulting sound of continuous explosion</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec15">Comparison with the state-of-the-art methods</h3><p>To further verify that our new method of combustion noise synthesis is more suitable for the synthesis of combustion noise in explosion sound, we compared it with state-of-the-art synthesis methods including Chadwick and James’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Chadwick JN, James DL (2011) Animating fire with sound. ACM Trans Graph 30(4):84–92" href="/article/10.1007/s10055-019-00408-7#ref-CR3" id="ref-link-section-d47354e1856">2011</a>) as well as Yin and Liu’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e1859">2018</a>). Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig7">7</a> illustrates the spectrograms and sound waveforms of the real combustion noise and the synthesized combustion noise by different methods. The general idea of Chadwick and James’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Chadwick JN, James DL (2011) Animating fire with sound. ACM Trans Graph 30(4):84–92" href="/article/10.1007/s10055-019-00408-7#ref-CR3" id="ref-link-section-d47354e1865">2011</a>) is to synthesize the combustion noise by adding high-frequency details to the low-frequency noise. However, the sound they synthesized lacked the mid-frequency “whooshing” behavior present in real flames (as shown in the blue wire frame), yet the combustion noise we synthesized is more reasonable because it comes from real sound examples. Moreover, Yin and Liu’s method compensates for the missing high-frequency information in low-frequency combustion noise by extracting popping sound from a recording (Yin and Liu <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e1868">2018</a>). However, there is no obvious popping sound in the used flame sound example, so the high-frequency information of combustion noise generated by Yin and Liu’s method is not obvious. In fact, the combustion noise generated by gaseous fuel combustion has no obvious popping sound. Our method can still synthesize reasonable combustion noise; therefore, our method is more suitable for combustion noise synthesis in explosion animation.</p><p>We also compared our method with the state-of-the-art methods of explosion sound synthesis, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig8">8</a>, from left to right, showing the light explosion’s sound spectrogram generated by Dobashi et al.’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Dobashi Y, Yamamoto T, Nishita T (2004) Synthesizing sound from turbulent field using sound textures for interactive fluid simulation. Comput Graph Forum 23(3):539–545" href="/article/10.1007/s10055-019-00408-7#ref-CR7" id="ref-link-section-d47354e1877">2004</a>), Yin and Liu’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e1880">2018</a>) as well as our method, respectively. Since Dobashi et al.’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Dobashi Y, Yamamoto T, Nishita T (2004) Synthesizing sound from turbulent field using sound textures for interactive fluid simulation. Comput Graph Forum 23(3):539–545" href="/article/10.1007/s10055-019-00408-7#ref-CR7" id="ref-link-section-d47354e1883">2004</a>) only takes into account vortex sound, the explosion sound synthesized by their method is a little monotonous. Yin and Liu’s method is used to synthesize the explosion sound, which sounds like a clipping because it contains incorrect noise. Our method not only synthesizes clear explosive sound and combustion noise, but also sounds more real.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig7_HTML.png?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig7_HTML.png" alt="figure7" loading="lazy" width="685" height="118" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>The results of combustion noise produced by different methods. <b>a</b> The spectrograms and sound waveforms of the real combustion noise, <b>b</b> the resulting combustion noise by Chadwick and James’s spectral bandwidth extension method, <b>c</b> the resulting combustion noise by Chadwick and James’s sound texture synthesis method, <b>d</b> the resulting combustion noise by Yin and Liu’s method, <b>e</b> the resulting combustion noise by our method</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig8_HTML.png?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig8_HTML.png" alt="figure8" loading="lazy" width="685" height="157" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>The spectrograms of a light explosion animation’s sound synthesized using different methods</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec16">User study</h3><p>In order to further certify the validity of our method, we designed a perception assessment survey. A total of 51 subjects (28 men and 23 women, between the ages of 22 and 35) participated in the test. The explosion sounds synthesized by different methods mentioned above are compared in the experiment. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig9">9</a> is the light explosion animation’s visual model used in the comparison experiment. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig10">10</a> shows the results of user study [blue is Dobashi et al.’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Dobashi Y, Yamamoto T, Nishita T (2004) Synthesizing sound from turbulent field using sound textures for interactive fluid simulation. Comput Graph Forum 23(3):539–545" href="/article/10.1007/s10055-019-00408-7#ref-CR7" id="ref-link-section-d47354e1930">2004</a>), pink is Yin and Liu’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e1933">2018</a>), and orange is our method]. The experimental details are shown below.</p><p>The first experiment is a comparison of richness, to verify the richness of sound content. In the experiment, volunteers are told that the audio clips are the result of an explosion, but do not know which method produces the result. Each audio clip has three levels, from one to three. One means the lowest level, and three means the highest level. According to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig10">10</a>a, we can see that in terms of sound richness, both Yin and Liu’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e1942">2018</a>) and our method achieve higher scores than Dobashi et al.’s method, which illustrates that both methods show more sound details. However, our method has a slightly higher score than Yin and Liu’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e1945">2018</a>), because our method specifically introduced the explosion-specific explosive sound. Since the explosion sound synthesized by Dobashi et al.’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Dobashi Y, Yamamoto T, Nishita T (2004) Synthesizing sound from turbulent field using sound textures for interactive fluid simulation. Comput Graph Forum 23(3):539–545" href="/article/10.1007/s10055-019-00408-7#ref-CR7" id="ref-link-section-d47354e1948">2004</a>) contains only vortex sound and the sound of fire consists of many components other than the vortex sound, the score in terms of sound richness is relatively low. As shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig8">8</a>, the explosion sound synthesized by Dobashi et al. is sometimes too low to be heard by the users (shown in the red wireframe).</p><p>The second experiment is a synchrony comparison, to verify the synchronization of sound and animated content. In the experiment, volunteers are shown clips of sound and animation scenes produced by different methods while volunteers do not know the method’s name. We ask volunteers to rate the synchronicity of animation and sound. There are also three levels, ranging from one to three. According to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig10">10</a>b, the three methods all get high scores. Because they all make use of the physical properties of the sound produced by explosion. Nevertheless, owing to introducing the occurrence and duration of explosive sound, our method has the highest score.</p><p>The third experiment is a comparison of realness. The experiment is to test whether the result of the generated explosion sound is close to the real-life explosion sound. In the experiment, the volunteers rate the results of different methods according to their own life experience and memory of the explosions, also with three grades. The volunteers do not know which method generated the results. As can been seen from Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00408-7#Fig10">10</a>c, our method scores far better than others. For the realness judgment of synthesized sound, although the Yin and Liu’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e1966">2018</a>) produced more sound details than Dobashi et al.’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Dobashi Y, Yamamoto T, Nishita T (2004) Synthesizing sound from turbulent field using sound textures for interactive fluid simulation. Comput Graph Forum 23(3):539–545" href="/article/10.1007/s10055-019-00408-7#ref-CR7" id="ref-link-section-d47354e1969">2004</a>), Yin and Liu (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e1972">2018</a>) used the extracted interactive sound for the entire explosion process, which lead to some incorrect noise points. Therefore, Yin and Liu’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e1975">2018</a>) has lower scores than the other two methods. Moreover, because the explosion sound we synthesized come from real sound examples, we get the highest score.</p><p>These results further demonstrate that our method is more suitable for the synthesis of explosion sound. Dobashi et al.’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Dobashi Y, Yamamoto T, Nishita T (2004) Synthesizing sound from turbulent field using sound textures for interactive fluid simulation. Comput Graph Forum 23(3):539–545" href="/article/10.1007/s10055-019-00408-7#ref-CR7" id="ref-link-section-d47354e1982">2004</a>) considers only vortex sound, while in explosion, not only vortex sounds but also sounds on account of the rapid expansion of heated air are common components. So Dobashi et al.’s method does not sound rich. Yin and Liu’s method (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189" href="/article/10.1007/s10055-019-00408-7#ref-CR36" id="ref-link-section-d47354e1985">2018</a>) adds the popping sounds for the entire explosion process, but when there are no obvious popping sounds in a phenomenon, Yin and Liu’s method would lead to incorrect noise points. In contrast, our method performs better in generating sound of explosion scenes.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig9_HTML.jpg?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig9_HTML.jpg" alt="figure9" loading="lazy" width="685" height="132" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>The result of the visual model of light explosion</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig10_HTML.png?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00408-7/MediaObjects/10055_2019_408_Fig10_HTML.png" alt="figure10" loading="lazy" width="685" height="262" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Results of the user study. <b>a</b> Richness comparison, <b>b</b> synchronism comparison and <b>c</b> realness comparison</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00408-7/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div></div></div></section><section aria-labelledby="Sec17"><div class="c-article-section" id="Sec17-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec17">Conclusion and future work</h2><div class="c-article-section__content" id="Sec17-content"><p>This paper has proposed a new framework for the synthesis of explosion sound. Using the physical parameters of explosion animation and real sound examples, we have proposed a novel non-physically based method to automatically synthesize the explosive sound and combustion noise in explosion animation in two stages. We first synthesized the resulting explosive sound matching the fireball based on the real explosive sound examples and the variation of fuel source volume during the explosion. Then, we proposed a new combustion noise synthesis approach which can synthesize the combustion noise that is more consistent with the texture features of real combustion sound. According to the timbre characteristics of generated low-frequency combustion noise in explosion, we selected the right grains from a flame sound corpus and synthesized the plausible combustion noise. Finally, according to the occurrence and duration of the explosive sound, we blended the explosive sound and combustion noise. We showed several experiments generated by our method and compared them with the state-of-the-art methods. The experimental results showed that the proposed method can synthesize the explosion sound synchronously with the explosion animation.</p><p>Our method still has some room for improvement. This paper mainly focuses on the synthesis of real explosion sound without much consideration of sound propagation. The sound propagation in explosion scenes can be incorporated to enhance the sound quality. A few things remain to be achieved in the future. We plan to apply our method to the different explosion scenarios, such as cars, buildings and other explosion scenes. However, in these scenarios, not only the explosion sounds but also the interactive sounds among the various substances are important. These elements should be simulated to create more realistic sound effects.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Agostino DS (1999) Synthesis of environmental sound textures by iterated nonlinear functions. In: Digital audi" /><p class="c-article-references__text" id="ref-CR1">Agostino DS (1999) Synthesis of environmental sound textures by iterated nonlinear functions. In: Digital audio effects. pp 109–117</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SS. An, DL. James, S. Marschner, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="An SS, James DL, Marschner S (2012) Motion-driven concatenative synthesis of cloth sounds. ACM Trans Graph 31(" /><p class="c-article-references__text" id="ref-CR2">An SS, James DL, Marschner S (2012) Motion-driven concatenative synthesis of cloth sounds. ACM Trans Graph 31(4):1–10</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F2185520.2185598" aria-label="View reference 2">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Motion-driven%20concatenative%20synthesis%20of%20cloth%20sounds&amp;journal=ACM%20Trans%20Graph&amp;volume=31&amp;issue=4&amp;pages=1-10&amp;publication_year=2012&amp;author=An%2CSS&amp;author=James%2CDL&amp;author=Marschner%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JN. Chadwick, DL. James, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Chadwick JN, James DL (2011) Animating fire with sound. ACM Trans Graph 30(4):84–92" /><p class="c-article-references__text" id="ref-CR3">Chadwick JN, James DL (2011) Animating fire with sound. ACM Trans Graph 30(4):84–92</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F2010324.1964979" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Animating%20fire%20with%20sound&amp;journal=ACM%20Trans%20Graph&amp;volume=30&amp;issue=4&amp;pages=84-92&amp;publication_year=2011&amp;author=Chadwick%2CJN&amp;author=James%2CDL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="D. Crighton, A. Dowling, J. Ffowcs-Williams, M. Heckl, F. Leppington, JF. Bartram, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Crighton D, Dowling A, Ffowcs-Williams J, Heckl M, Leppington F, Bartram JF (1992) Modern methods in analytica" /><p class="c-article-references__text" id="ref-CR4">Crighton D, Dowling A, Ffowcs-Williams J, Heckl M, Leppington F, Bartram JF (1992) Modern methods in analytical acoustics. Springer, Berlin</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Modern%20methods%20in%20analytical%20acoustics&amp;publication_year=1992&amp;author=Crighton%2CD&amp;author=Dowling%2CA&amp;author=Ffowcs-Williams%2CJ&amp;author=Heckl%2CM&amp;author=Leppington%2CF&amp;author=Bartram%2CJF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dobashi Y, Kaneda K, Yamashita H, Okita T, Nishita T (2000) A simple, efficient method for realistic animation" /><p class="c-article-references__text" id="ref-CR5">Dobashi Y, Kaneda K, Yamashita H, Okita T, Nishita T (2000) A simple, efficient method for realistic animation of clouds. In: ACM SIGGRAPH. pp 19–28</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dobashi Y, Yamamoto T, Nishita T (2003) Real-time rendering of aerodynamic sound using sound textures based on" /><p class="c-article-references__text" id="ref-CR6">Dobashi Y, Yamamoto T, Nishita T (2003) Real-time rendering of aerodynamic sound using sound textures based on computational fluid dynamics. In: ACM SIGGRAPH. pp 732–740</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. Dobashi, T. Yamamoto, T. Nishita, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Dobashi Y, Yamamoto T, Nishita T (2004) Synthesizing sound from turbulent field using sound textures for inter" /><p class="c-article-references__text" id="ref-CR7">Dobashi Y, Yamamoto T, Nishita T (2004) Synthesizing sound from turbulent field using sound textures for interactive fluid simulation. Comput Graph Forum 23(3):539–545</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fj.1467-8659.2004.00785.x" aria-label="View reference 7">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Synthesizing%20sound%20from%20turbulent%20field%20using%20sound%20textures%20for%20interactive%20fluid%20simulation&amp;journal=Comput%20Graph%20Forum&amp;volume=23&amp;issue=3&amp;pages=539-545&amp;publication_year=2004&amp;author=Dobashi%2CY&amp;author=Yamamoto%2CT&amp;author=Nishita%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="KVD. Doel, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Doel KVD (2005) Physically-based models for liquid sounds. ACM Trans Appl Percept 2(4):534–546" /><p class="c-article-references__text" id="ref-CR8">Doel KVD (2005) Physically-based models for liquid sounds. ACM Trans Appl Percept 2(4):534–546</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F1101530.1101554" aria-label="View reference 8">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Physically-based%20models%20for%20liquid%20sounds&amp;journal=ACM%20Trans%20Appl%20Percept&amp;volume=2&amp;issue=4&amp;pages=534-546&amp;publication_year=2005&amp;author=Doel%2CKVD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Dubnov, Z. Barjoseph, EY. Ran, D. Lischinski, M. Werman, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Dubnov S, Barjoseph Z, Ran EY, Lischinski D, Werman M (2002) Synthesizing sound textures through wavelet tree " /><p class="c-article-references__text" id="ref-CR9">Dubnov S, Barjoseph Z, Ran EY, Lischinski D, Werman M (2002) Synthesizing sound textures through wavelet tree learning. IEEE Comput Graph Appl 22(4):38–48</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FMCG.2002.1016697" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Synthesizing%20sound%20textures%20through%20wavelet%20tree%20learning&amp;journal=IEEE%20Comput%20Graph%20Appl&amp;volume=22&amp;issue=4&amp;pages=38-48&amp;publication_year=2002&amp;author=Dubnov%2CS&amp;author=Barjoseph%2CZ&amp;author=Ran%2CEY&amp;author=Lischinski%2CD&amp;author=Werman%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="BE. Feldman, JF. O’brien, O. Arikan, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Feldman BE, O’brien JF, Arikan O (2003) Animating suspended particle explosions. ACM Trans Graph 22(3):708–715" /><p class="c-article-references__text" id="ref-CR10">Feldman BE, O’brien JF, Arikan O (2003) Animating suspended particle explosions. ACM Trans Graph 22(3):708–715</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1205.68464" aria-label="View reference 10 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F882262.882336" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Animating%20suspended%20particle%20explosions&amp;journal=ACM%20Trans%20Graph&amp;volume=22&amp;issue=3&amp;pages=708-715&amp;publication_year=2003&amp;author=Feldman%2CBE&amp;author=O%E2%80%99brien%2CJF&amp;author=Arikan%2CO">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Feng, S. Liu, " /><meta itemprop="datePublished" content="2018" /><meta itemprop="headline" content="Feng G, Liu S (2018) Detail-preserving sph fluid control with deformation constraints. Comput Animat Virtual W" /><p class="c-article-references__text" id="ref-CR11">Feng G, Liu S (2018) Detail-preserving sph fluid control with deformation constraints. Comput Animat Virtual Worlds 29(1):e1781</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3753726" aria-label="View reference 11 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2Fcav.1781" aria-label="View reference 11">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Detail-preserving%20sph%20fluid%20control%20with%20deformation%20constraints&amp;journal=Comput%20Animat%20Virtual%20Worlds&amp;volume=29&amp;issue=1&amp;publication_year=2018&amp;author=Feng%2CG&amp;author=Liu%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Ihme, H. Pitsch, D. Bodony, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Ihme M, Pitsch H, Bodony D (2009) Radiation of noise in turbulent non-premixed flames. Proc Combust Inst 32(1)" /><p class="c-article-references__text" id="ref-CR12">Ihme M, Pitsch H, Bodony D (2009) Radiation of noise in turbulent non-premixed flames. Proc Combust Inst 32(1):1545–1553</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.proci.2008.06.137" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Radiation%20of%20noise%20in%20turbulent%20non-premixed%20flames&amp;journal=Proc%20Combust%20Inst&amp;volume=32&amp;issue=1&amp;pages=1545-1553&amp;publication_year=2009&amp;author=Ihme%2CM&amp;author=Pitsch%2CH&amp;author=Bodony%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kersten S, Purwins H (2013) Fire texture sound re-synthesis using sparse decomposition and noise modelling. In" /><p class="c-article-references__text" id="ref-CR13">Kersten S, Purwins H (2013) Fire texture sound re-synthesis using sparse decomposition and noise modelling. In: Digital audio effects. pp 1–5</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Liu, Y. Xiong, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Liu S, Xiong Y (2013) Fast and stable simulation of virtual water scenes with interactions. Virtual Real 17(1)" /><p class="c-article-references__text" id="ref-CR14">Liu S, Xiong Y (2013) Fast and stable simulation of virtual water scenes with interactions. Virtual Real 17(1):77–88</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10055-013-0222-0" aria-label="View reference 14">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Fast%20and%20stable%20simulation%20of%20virtual%20water%20scenes%20with%20interactions&amp;journal=Virtual%20Real&amp;volume=17&amp;issue=1&amp;pages=77-88&amp;publication_year=2013&amp;author=Liu%2CS&amp;author=Xiong%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Liu, Z. Yu, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Liu S, Yu Z (2015) Sounding fire for immersive virtual reality. Virtual Real 19(3–4):291–302" /><p class="c-article-references__text" id="ref-CR15">Liu S, Yu Z (2015) Sounding fire for immersive virtual reality. Virtual Real 19(3–4):291–302</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10055-015-0271-7" aria-label="View reference 15">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Sounding%20fire%20for%20immersive%20virtual%20reality&amp;journal=Virtual%20Real&amp;volume=19&amp;issue=3%E2%80%934&amp;pages=291-302&amp;publication_year=2015&amp;author=Liu%2CS&amp;author=Yu%2CZ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MS. Longuethiggins, " /><meta itemprop="datePublished" content="1990" /><meta itemprop="headline" content="Longuethiggins MS (1990) An analytic model of sound production by raindrops. Fluid Mech 214:395–410" /><p class="c-article-references__text" id="ref-CR16">Longuethiggins MS (1990) An analytic model of sound production by raindrops. Fluid Mech 214:395–410</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1054107" aria-label="View reference 16 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1017%2FS0022112090000179" aria-label="View reference 16">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20analytic%20model%20of%20sound%20production%20by%20raindrops&amp;journal=Fluid%20Mech&amp;volume=214&amp;pages=395-410&amp;publication_year=1990&amp;author=Longuethiggins%2CMS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Marelli, M. Aramaki, R. Kronland-Martinet, C. Verron, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Marelli D, Aramaki M, Kronland-Martinet R, Verron C (2012) An efficient time–frequency method for synthesizing" /><p class="c-article-references__text" id="ref-CR17">Marelli D, Aramaki M, Kronland-Martinet R, Verron C (2012) An efficient time–frequency method for synthesizing noisy sounds with short transients and narrow spectral components. IEEE Trans Audio Speech Lang Process 20(4):1400–1408</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTASL.2011.2176334" aria-label="View reference 17">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20efficient%20time%E2%80%93frequency%20method%20for%20synthesizing%20noisy%20sounds%20with%20short%20transients%20and%20narrow%20spectral%20components&amp;journal=IEEE%20Trans%20Audio%20Speech%20Lang%20Process&amp;volume=20&amp;issue=4&amp;pages=1400-1408&amp;publication_year=2012&amp;author=Marelli%2CD&amp;author=Aramaki%2CM&amp;author=Kronland-Martinet%2CR&amp;author=Verron%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="W. Moss, H. Yeh, JM. Hong, MC. Lin, D. Manocha, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Moss W, Yeh H, Hong JM, Lin MC, Manocha D (2010) Sounding liquids: automatic sound synthesis from fluid simula" /><p class="c-article-references__text" id="ref-CR18">Moss W, Yeh H, Hong JM, Lin MC, Manocha D (2010) Sounding liquids: automatic sound synthesis from fluid simulation. ACM Trans Graph 29(3):1–13</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F1805964.1805965" aria-label="View reference 18">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Sounding%20liquids%3A%20automatic%20sound%20synthesis%20from%20fluid%20simulation&amp;journal=ACM%20Trans%20Graph&amp;volume=29&amp;issue=3&amp;pages=1-13&amp;publication_year=2010&amp;author=Moss%2CW&amp;author=Yeh%2CH&amp;author=Hong%2CJM&amp;author=Lin%2CMC&amp;author=Manocha%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DQ. Nguyen, R. Fedkiw, HW. Jensen, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Nguyen DQ, Fedkiw R, Jensen HW (2002) Physically based modeling and animation of fire. ACM Trans Graph 21(3):7" /><p class="c-article-references__text" id="ref-CR19">Nguyen DQ, Fedkiw R, Jensen HW (2002) Physically based modeling and animation of fire. ACM Trans Graph 21(3):721–728</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F566654.566643" aria-label="View reference 19">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Physically%20based%20modeling%20and%20animation%20of%20fire&amp;journal=ACM%20Trans%20Graph&amp;volume=21&amp;issue=3&amp;pages=721-728&amp;publication_year=2002&amp;author=Nguyen%2CDQ&amp;author=Fedkiw%2CR&amp;author=Jensen%2CHW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JF. O’Brien, AW. Bargteil, JK. Hodgins, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="O’Brien JF, Bargteil AW, Hodgins JK (2002) Graphical modeling and animation of ductile fracture. ACM Trans Gra" /><p class="c-article-references__text" id="ref-CR20">O’Brien JF, Bargteil AW, Hodgins JK (2002) Graphical modeling and animation of ductile fracture. ACM Trans Graph 21(3):291–294</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Graphical%20modeling%20and%20animation%20of%20ductile%20fracture&amp;journal=ACM%20Trans%20Graph&amp;volume=21&amp;issue=3&amp;pages=291-294&amp;publication_year=2002&amp;author=O%E2%80%99Brien%2CJF&amp;author=Bargteil%2CAW&amp;author=Hodgins%2CJK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="A. Powell, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Powell A (2003) Theory of vortex sound. Cambridge University Press, Cambridge" /><p class="c-article-references__text" id="ref-CR21">Powell A (2003) Theory of vortex sound. Cambridge University Press, Cambridge</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Theory%20of%20vortex%20sound&amp;publication_year=2003&amp;author=Powell%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="A. Prosperetti, " /><meta itemprop="datePublished" content="1988" /><meta itemprop="headline" content="Prosperetti A (1988) Bubble dynamics in oceanic ambient noise. Springer, Dordrecht" /><p class="c-article-references__text" id="ref-CR22">Prosperetti A (1988) Bubble dynamics in oceanic ambient noise. Springer, Dordrecht</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Bubble%20dynamics%20in%20oceanic%20ambient%20noise&amp;publication_year=1988&amp;author=Prosperetti%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="C. Roads, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Roads C (2004) Microsound. The MIT Press, Cambridge" /><p class="c-article-references__text" id="ref-CR23">Roads C (2004) Microsound. The MIT Press, Cambridge</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Microsound&amp;publication_year=2004&amp;author=Roads%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Sato, K. Mizutani, Y. Dobashi, T. Nishita, T. Yamamoto, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Sato S, Mizutani K, Dobashi Y, Nishita T, Yamamoto T (2017) Feedback control of fire simulation based on compu" /><p class="c-article-references__text" id="ref-CR24">Sato S, Mizutani K, Dobashi Y, Nishita T, Yamamoto T (2017) Feedback control of fire simulation based on computational fluid dynamics. Comput Animat Virtual Worlds 28(3–4):e1766</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2Fcav.1766" aria-label="View reference 24">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Feedback%20control%20of%20fire%20simulation%20based%20on%20computational%20fluid%20dynamics&amp;journal=Comput%20Animat%20Virtual%20Worlds&amp;volume=28&amp;issue=3%E2%80%934&amp;publication_year=2017&amp;author=Sato%2CS&amp;author=Mizutani%2CK&amp;author=Dobashi%2CY&amp;author=Nishita%2CT&amp;author=Yamamoto%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Schreck C, Rohmer D, James DL, Hahmann S, Cani MP (2016) Real-time sound synthesis for paper material based on" /><p class="c-article-references__text" id="ref-CR25">Schreck C, Rohmer D, James DL, Hahmann S, Cani MP (2016) Real-time sound synthesis for paper material based on geometric analysis. In: ACM SIGGRAPH. pp 211–220</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Schwarz D (2011) State of the art in sound texture synthesis. In: Digital audio effects (DAFx-12). pp 151–171" /><p class="c-article-references__text" id="ref-CR26">Schwarz D (2011) State of the art in sound texture synthesis. In: Digital audio effects (DAFx-12). pp 151–171</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="Diemo. Schwarz, Baptiste. Caramiaux, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Schwarz D, Caramiaux B (2014) Interactive sound texture synthesis through semi-automatic user annotations. In:" /><p class="c-article-references__text" id="ref-CR27">Schwarz D, Caramiaux B (2014) Interactive sound texture synthesis through semi-automatic user annotations. In: Lecture notes in computer science. pp 372–392</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Lecture%20Notes%20in%20Computer%20Science&amp;pages=372-392&amp;publication_year=2014&amp;author=Schwarz%2CDiemo&amp;author=Caramiaux%2CBaptiste">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Schwarz D, O’Leary S (2015) Smooth granular sound texture synthesis by control of timbral similarity. In: Soun" /><p class="c-article-references__text" id="ref-CR28">Schwarz D, O’Leary S (2015) Smooth granular sound texture synthesis by control of timbral similarity. In: Sound and music computing. pp 471 – 476</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Schwarz D, Schnell N (2008) Descriptor-based sound texture sampling. In: Sound and music computing. pp 510–515" /><p class="c-article-references__text" id="ref-CR29">Schwarz D, Schnell N (2008) Descriptor-based sound texture sampling. In: Sound and music computing. pp 510–515</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Smith, E. Ericson, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Smith S, Ericson E (2009) Using immersive game-based virtual reality to teach fire-safety skills to children. " /><p class="c-article-references__text" id="ref-CR30">Smith S, Ericson E (2009) Using immersive game-based virtual reality to teach fire-safety skills to children. Virtual Real 13(2):87–99</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10055-009-0113-6" aria-label="View reference 30">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Using%20immersive%20game-based%20virtual%20reality%20to%20teach%20fire-safety%20skills%20to%20children&amp;journal=Virtual%20Real&amp;volume=13&amp;issue=2&amp;pages=87-99&amp;publication_year=2009&amp;author=Smith%2CS&amp;author=Ericson%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Stam J (1999) Stable fluids. In: Proceedings of the 26th annual conference on computer graphics and interactiv" /><p class="c-article-references__text" id="ref-CR31">Stam J (1999) Stable fluids. In: Proceedings of the 26th annual conference on computer graphics and interactive techniques. pp 121–128</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Stam, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Stam J (2000) Interacting with smoke and fire in real time. Commun ACM 43(7):76–83" /><p class="c-article-references__text" id="ref-CR32">Stam J (2000) Interacting with smoke and fire in real time. Commun ACM 43(7):76–83</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F341852.341866" aria-label="View reference 32">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Interacting%20with%20smoke%20and%20fire%20in%20real%20time&amp;journal=Commun%20ACM&amp;volume=43&amp;issue=7&amp;pages=76-83&amp;publication_year=2000&amp;author=Stam%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Stam J, Stam J, Jensen HW (2001) Visual simulation of smoke. In: ACM SIGGRAPH. pp 15–22" /><p class="c-article-references__text" id="ref-CR33">Stam J, Stam J, Jensen HW (2001) Visual simulation of smoke. In: ACM SIGGRAPH. pp 15–22</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Wang, S. Liu, " /><meta itemprop="datePublished" content="2018" /><meta itemprop="headline" content="Wang K, Liu S (2018) Example-based synthesis for sound of ocean waves caused by bubble dynamics. Comput Animat" /><p class="c-article-references__text" id="ref-CR34">Wang K, Liu S (2018) Example-based synthesis for sound of ocean waves caused by bubble dynamics. Comput Animat Virtual Worlds 29(4):e1835</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2Fcav.1835" aria-label="View reference 34">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Example-based%20synthesis%20for%20sound%20of%20ocean%20waves%20caused%20by%20bubble%20dynamics&amp;journal=Comput%20Animat%20Virtual%20Worlds&amp;volume=29&amp;issue=4&amp;publication_year=2018&amp;author=Wang%2CK&amp;author=Liu%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Wang K, Cheng H, Liu S (2017) Efficient sound synthesis for natural scenes. In: IEEE virtual reality. pp 303–3" /><p class="c-article-references__text" id="ref-CR35">Wang K, Cheng H, Liu S (2017) Efficient sound synthesis for natural scenes. In: IEEE virtual reality. pp 303–304</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Q. Yin, S. Liu, " /><meta itemprop="datePublished" content="2018" /><meta itemprop="headline" content="Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combus" /><p class="c-article-references__text" id="ref-CR36">Yin Q, Liu S (2018) Sounding solid combustibles: non-premixed flame sound synthesis for different solid combustibles. IEEE Trans Vis Comput Graph 24(2):1179–1189</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTVCG.2016.2642958" aria-label="View reference 36">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 36 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Sounding%20solid%20combustibles%3A%20non-premixed%20flame%20sound%20synthesis%20for%20different%20solid%20combustibles&amp;journal=IEEE%20Trans%20Vis%20Comput%20Graph&amp;volume=24&amp;issue=2&amp;pages=1179-1189&amp;publication_year=2018&amp;author=Yin%2CQ&amp;author=Liu%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Yngve GD, O’Brien JF, Hodgins JK (2000) Animating explosions. In: ACM SIGGRAPH. pp 29–36" /><p class="c-article-references__text" id="ref-CR37">Yngve GD, O’Brien JF, Hodgins JK (2000) Animating explosions. In: ACM SIGGRAPH. pp 29–36</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-019-00408-7-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>Funding was provided by Natural Science Foundation of China (Grant Nos. 61672375 and 61170118).</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Division of Intelligence and Computing, School of Computer Science and Technology, Tianjin, People’s Republic of China</p><p class="c-article-author-affiliation__authors-list">Shiguang Liu &amp; Si Gao</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Shiguang-Liu"><span class="c-article-authors-search__title u-h3 js-search-name">Shiguang Liu</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Shiguang+Liu&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Shiguang+Liu" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Shiguang+Liu%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Si-Gao"><span class="c-article-authors-search__title u-h3 js-search-name">Si Gao</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Si+Gao&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Si+Gao" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Si+Gao%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-019-00408-7/email/correspondent/c1/new">Shiguang Liu</a>.</p></div></div></section><section aria-labelledby="additional-information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><h3 class="c-article__sub-heading">Publisher's Note</h3><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section aria-labelledby="Sec18"><div class="c-article-section" id="Sec18-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec18">Electronic supplementary material</h2><div class="c-article-section__content" id="Sec18-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><p>Below is the link to the electronic supplementary material.

</p><div id="MOESM1"><div class="video" id="mijsvdiv1348086"><script src="https://www.edge-cdn.net/videojs_1348086?jsdiv=mijsvdiv1348086&amp;playerskin=37016" defer="defer"></script></div><div class="serif suppress-bottom-margin add-top-margin standard-space-below" data-test="bottom-caption"><p>Supplementary material 1 (wmv 9315 KB)</p></div></div></div></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Automatic%20synthesis%20of%20explosion%20sound%20synchronized%20with%20animation&amp;author=Shiguang%20Liu%20et%20al&amp;contentID=10.1007%2Fs10055-019-00408-7&amp;publication=1359-4338&amp;publicationDate=2019-11-18&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-019-00408-7" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-019-00408-7" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Liu, S., Gao, S. Automatic synthesis of explosion sound synchronized with animation.
                    <i>Virtual Reality</i>  (2019). https://doi.org/10.1007/s10055-019-00408-7</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-019-00408-7.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-12-10">10 December 2018</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2019-11-07">07 November 2019</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2019-11-18">18 November 2019</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-019-00408-7" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-019-00408-7</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Audiovisual synchronization</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Explosive sound</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Combustion noise</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Sound synthesis</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Immersive virtual reality</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-019-00408-7.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=408;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

