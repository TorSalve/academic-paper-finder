<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Afforded actions as a behavioral assessment of physical presence in vi"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="A particular affordance was used as a potential candidate for behavioral assessment of physical presence in virtual environments. The subjects&#8217; task was to walk through a virtual aperture of..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/13/3.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Afforded actions as a behavioral assessment of physical presence in virtual environments"/>

    <meta name="dc.source" content="Virtual Reality 2009 13:3"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2009-05-28"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2009 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="A particular affordance was used as a potential candidate for behavioral assessment of physical presence in virtual environments. The subjects&#8217; task was to walk through a virtual aperture of variable widths. In the case of presence, the subjects&#8217; body orientation, while walking, was hypothesized to be adapted to the width of the aperture and to their own shoulder width. Results show that most subjects adapted their behavior to both their body architecture and the virtual width constraints. These subjects exhibited a behavioral transition from frontal walking to body rotation while walking through broad to narrow apertures. The same behavioral transition has already been documented in real environments (Warren and Whang in J Exp Psychol Human Percept Perform 13(3):371&#8211;383, 1987). This behavioral adjustment is thus assumed to be an objective indication of presence. Beyond these results, the present study suggests that every afforded action could be a potential tool for sensorimotor assessment of physical presence."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2009-05-28"/>

    <meta name="prism.volume" content="13"/>

    <meta name="prism.number" content="3"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="141"/>

    <meta name="prism.endingPage" content="151"/>

    <meta name="prism.copyright" content="2009 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-009-0118-1"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-009-0118-1"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-009-0118-1.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-009-0118-1"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Afforded actions as a behavioral assessment of physical presence in virtual environments"/>

    <meta name="citation_volume" content="13"/>

    <meta name="citation_issue" content="3"/>

    <meta name="citation_publication_date" content="2009/09"/>

    <meta name="citation_online_date" content="2009/05/28"/>

    <meta name="citation_firstpage" content="141"/>

    <meta name="citation_lastpage" content="151"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-009-0118-1"/>

    <meta name="DOI" content="10.1007/s10055-009-0118-1"/>

    <meta name="citation_doi" content="10.1007/s10055-009-0118-1"/>

    <meta name="description" content="A particular affordance was used as a potential candidate for behavioral assessment of physical presence in virtual environments. The subjects&#8217; task "/>

    <meta name="dc.creator" content="Jean-Claude Lepecq"/>

    <meta name="dc.creator" content="Lionel Bringoux"/>

    <meta name="dc.creator" content="Jean-Marie Pergandi"/>

    <meta name="dc.creator" content="Thelma Coyle"/>

    <meta name="dc.creator" content="Daniel Mestre"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=Trends Neurosci; citation_title=The body in the brain: Neural bases of corporeal awareness; citation_author=G Berlucchi, S Aglioti; citation_volume=20; citation_publication_date=1997; citation_pages=560-564; citation_doi=10.1016/S0166-2236(97)01136-3; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_title=A situated cognition perspective on presence; citation_inbook_title=XXVII Annual conference of the cognitive science society; citation_publication_date=2005; citation_pages=384-389; citation_id=CR2; citation_author=A Carassa; citation_author=F Morganti; citation_author=M Tirassa; citation_publisher=Sheridan Printing"/>

    <meta name="citation_reference" content="Cruz-Neira C, Sandin DJ, DeFanti TA (1993) Surround-screen projection-based virtual reality: the design and implementation of the cave. Proceedings of the 20th annual conference on computer graphics and interactive techniques, New York, pp 135&#8211;142"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=The reality of experience: Gibson&#8217;s way; citation_author=JM Flach, JG Holden; citation_volume=7; citation_issue=1; citation_publication_date=1998; citation_pages=90-95; citation_doi=10.1162/105474698565550; citation_id=CR4"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Using behavioural realism to estimate presence: a study of the utility of postural responses to motion stimuli; citation_author=J Freeman, SE Avons, R Meddis, DE Pearson, WA Ijsselsteijn; citation_volume=9; citation_issue=2; citation_publication_date=2000; citation_pages=149-164; citation_doi=10.1162/105474600566691; citation_id=CR5"/>

    <meta name="citation_reference" content="citation_title=The ecological approach to visual perception; citation_publication_date=1979; citation_id=CR6; citation_author=JJ Gibson; citation_publisher=Houghton Mifflin"/>

    <meta name="citation_reference" content="citation_journal_title=Ecol Psychol; citation_title=Perception of sound-obstructing surfaces using body-scaled judgments; citation_author=MS Gordon, LD Rosenblum; citation_volume=16; citation_issue=2; citation_publication_date=2004; citation_pages=87-113; citation_doi=10.1207/s15326969eco1602_1; citation_id=CR7"/>

    <meta name="citation_reference" content="citation_journal_title=Cyber Psychol Behav; citation_title=Field dependency and the sense of object presence in haptic virtual environments; citation_author=D Hecht, M Reiner; citation_volume=10; citation_publication_date=2007; citation_pages=243-251; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_journal_title=Exp Brain Res; citation_title=Locomotion through apertures when wider space for locomotion is necessary to artificially altered bodily states; citation_author=T Higuchi, ME Cinelli, MA Greig, AE Patla; citation_volume=175; citation_publication_date=2006; citation_pages=50-59; citation_doi=10.1007/s00221-006-0525-4; citation_id=CR9"/>

    <meta name="citation_reference" content="citation_title=Beyond the body schema: visual, prosthetic, and technological contributions to bodily perception and awareness; citation_inbook_title=Human body perception from the inside out; citation_publication_date=2006; citation_pages=15-64; citation_id=CR10; citation_author=NP Holmes; citation_author=C Spence; citation_publisher=Oxford University Press"/>

    <meta name="citation_reference" content="citation_journal_title=Proc Soc Photo Opt Instrum Eng; citation_title=Presence: concept, determinants and measurement; citation_author=WA Ijsselsteijn, H Ridder, J Freeman, SE Avons; citation_volume=3959; citation_publication_date=2000; citation_pages=520-529; citation_id=CR11"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Effects of stereoscopic presentation, image motion, and screen size on subjective and objective corroborative measures of presence; citation_author=WA Ijsselsteijn, H Ridder, J Freeman, SE Avons, D Bouwhuis; citation_volume=10; citation_issue=3; citation_publication_date=2001; citation_pages=298-311; citation_doi=10.1162/105474601300343621; citation_id=CR12"/>

    <meta name="citation_reference" content="citation_title=Measuring presence: subjective, behavioral, and physiological methods; citation_inbook_title=Being there: concepts, effects and measurement of user presence in synthetic environments; citation_publication_date=2003; citation_pages=109-119; citation_id=CR13; citation_author=B Insko; citation_publisher=IOS Press"/>

    <meta name="citation_reference" content="International Society for Presence Research (2008) The concept of presence: explication statement. Retrieved May 15, 2008 from 
                    http://www.temple.edu/ispr/frame_explicat.htm
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=J Exp Psychol Human Percept Perform; citation_title=Perceiving affordances for fitting through apertures; citation_author=S Ishak, KE Adolph, GC Lin; citation_volume=34; citation_issue=6; citation_publication_date=2008; citation_pages=1501-1514; citation_doi=10.1037/a0011393; citation_id=CR15"/>

    <meta name="citation_reference" content="Lombard M, Ditton TB (1997) At the heart of it all: the concept of presence. J Comp Mediat Commun 3(2). Retrieved May 15, 2008 from 
                    http://jcmc.indiana.edu/vol3/issue2/lombard.html
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Psychnology J; citation_title=Identifying the (tele) presence literature; citation_author=M Lombard, MT Jones; citation_volume=5; citation_issue=2; citation_publication_date=2007; citation_pages=197-206; citation_id=CR17"/>

    <meta name="citation_reference" content="citation_journal_title=Psychnology J; citation_title=Telepresence bibliography (n&#160;=&#160;1, 834) as of May 2007. Addition to: Lombard M, Jones MT Identifying the (tele) presence literature; citation_author=M Lombard, MT Jones; citation_volume=5; citation_issue=2; citation_publication_date=2007; citation_pages=197-206; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=Trav Hum; citation_title=Perception de la verticale avec un cadre visuel solidaire de la t&#234;te: implications pour l&#8217;utilisation des visiocasques; citation_author=F Mars, L Bringoux, C Cian, PA Barraud, C Raphel, JL Vercher; citation_volume=68; citation_publication_date=2005; citation_pages=125-152; citation_doi=10.3917/th.682.0125; citation_id=CR19"/>

    <meta name="citation_reference" content="citation_title=The logic of scientific discovery; citation_publication_date=1959; citation_id=CR20; citation_author=KR Popper; citation_publisher=Basic Books"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Presence equation: an investigation into cognitive factors underlying presence; citation_author=C Sas, G O&#8217;Hare; citation_volume=12; citation_issue=5; citation_publication_date=2003; citation_pages=523-537; citation_doi=10.1162/105474603322761315; citation_id=CR21"/>

    <meta name="citation_reference" content="citation_journal_title=Commun Theory; citation_title=A new conception of spatial presence: once again, with feeling; citation_author=T Schubert; citation_volume=19; citation_publication_date=2009; citation_pages=161-187; citation_doi=10.1111/j.1468-2885.2009.01340.x; citation_id=CR22"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Presence and the sixth sense; citation_author=M Slater; citation_volume=11; citation_issue=4; citation_publication_date=2002; citation_pages=435-439; citation_doi=10.1162/105474602760204327; citation_id=CR23"/>

    <meta name="citation_reference" content="Stappers PJ, Flach JM, Voorhorst FA (1999) Critical ratio as behavioral indices of presence. Presented at the second international workshop on presence, University of Essex, UK, April 6&#8211;7 1999. Retrieved November 11, 2008 
                    http://www.temple.edu/ispr/prev_conferences/proceedings/98-99-2000/1999/Stappers,%20Flach%20and%20Voorhorst.pdf
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_title=Special study: Injuries and deaths associated with children&#8217;s playground equipment; citation_publication_date=2001; citation_id=CR25; citation_author=DK Tinsworth; citation_author=JE McDonald; citation_publisher=Consumer Product Safety Commission"/>

    <meta name="citation_reference" content="van Baren J, Ijsselsteijn WA (2004) Compendium of presence measures. Retrieved November 11, 2008. 
                    http://www.informatik.umu.se/~jwworth/PresenceMeasurement.pdf
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=J Exp Psychol Human Percept Perform; citation_title=Visual guidance of walking through apertures: Body-scaled information for affordances; citation_author=WH Warren, S Whang; citation_volume=13; citation_issue=3; citation_publication_date=1987; citation_pages=371-383; citation_doi=10.1037/0096-1523.13.3.371; citation_id=CR27"/>

    <meta name="citation_reference" content="citation_title=An investigation into physiological responses in virtual environments: an objective measurement of presence; citation_inbook_title=Towards cyber psychology: mind, cognitions and society in the Internet age; citation_publication_date=2001; citation_pages=175-183; citation_id=CR28; citation_author=BK Wiederhold; citation_author=DP Jang; citation_author=M Kaneda; citation_author=I Cabral; citation_author=Y Lurie; citation_author=T May; citation_author=IY Kim; citation_author=MD Wiederhold; citation_author=SI Kim; citation_publisher=IOS Press"/>

    <meta name="citation_reference" content="citation_journal_title=Media Psychol; citation_title=A process model of the formation of spatial presence experiences; citation_author=W Wirth, T Hartmann, S B&#246;cking, P Vorderer, C Klimmt, H Schramm, T Saari, J Laarni, N Ravaja, F Ribeiro Gouveia, F Biocca, A Sacau, L J&#228;ncke, T Baumgartner, P J&#228;ncke; citation_volume=9; citation_issue=3; citation_publication_date=2007; citation_pages=493-525; citation_id=CR29"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Measuring presence in virtual environments: a presence questionnaire; citation_author=BG Witmer, MJ Singer; citation_volume=7; citation_issue=3; citation_publication_date=1998; citation_pages=225-240; citation_doi=10.1162/105474698565686; citation_id=CR30"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Presence as being-in-the-world; citation_author=P Zahorik, RL Jenison; citation_volume=7; citation_issue=1; citation_publication_date=1998; citation_pages=78-89; citation_doi=10.1162/105474698565541; citation_id=CR31"/>

    <meta name="citation_author" content="Jean-Claude Lepecq"/>

    <meta name="citation_author_email" content="jean-claude.lepecq@univmed.fr"/>

    <meta name="citation_author_institution" content="UMR 6233 Institut des Sciences du Mouvement, CNRS, Universit&#233; de la M&#233;diterran&#233;e, Marseille Cedex 9, France"/>

    <meta name="citation_author" content="Lionel Bringoux"/>

    <meta name="citation_author_institution" content="UMR 6233 Institut des Sciences du Mouvement, CNRS, Universit&#233; de la M&#233;diterran&#233;e, Marseille Cedex 9, France"/>

    <meta name="citation_author" content="Jean-Marie Pergandi"/>

    <meta name="citation_author_institution" content="UMR 6233 Institut des Sciences du Mouvement, CNRS, Universit&#233; de la M&#233;diterran&#233;e, Marseille Cedex 9, France"/>

    <meta name="citation_author" content="Thelma Coyle"/>

    <meta name="citation_author_institution" content="UMR 6233 Institut des Sciences du Mouvement, CNRS, Universit&#233; de la M&#233;diterran&#233;e, Marseille Cedex 9, France"/>

    <meta name="citation_author" content="Daniel Mestre"/>

    <meta name="citation_author_institution" content="UMR 6233 Institut des Sciences du Mouvement, CNRS, Universit&#233; de la M&#233;diterran&#233;e, Marseille Cedex 9, France"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-009-0118-1&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2009/09/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-009-0118-1"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Afforded actions as a behavioral assessment of physical presence in virtual environments"/>
        <meta property="og:description" content="A particular affordance was used as a potential candidate for behavioral assessment of physical presence in virtual environments. The subjects’ task was to walk through a virtual aperture of variable widths. In the case of presence, the subjects’ body orientation, while walking, was hypothesized to be adapted to the width of the aperture and to their own shoulder width. Results show that most subjects adapted their behavior to both their body architecture and the virtual width constraints. These subjects exhibited a behavioral transition from frontal walking to body rotation while walking through broad to narrow apertures. The same behavioral transition has already been documented in real environments (Warren and Whang in J Exp Psychol Human Percept Perform 13(3):371–383, 1987). This behavioral adjustment is thus assumed to be an objective indication of presence. Beyond these results, the present study suggests that every afforded action could be a potential tool for sensorimotor assessment of physical presence."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Afforded actions as a behavioral assessment of physical presence in virtual environments | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-009-0118-1","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Presence, Behavior, Affordance, Virtual reality","kwrd":["Presence","Behavior","Affordance","Virtual_reality"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-009-0118-1","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-009-0118-1","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=118;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-009-0118-1">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Afforded actions as a behavioral assessment of physical presence in virtual environments
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-009-0118-1.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-009-0118-1.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2009-05-28" itemprop="datePublished">28 May 2009</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Afforded actions as a behavioral assessment of physical presence in virtual environments</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Jean_Claude-Lepecq" data-author-popup="auth-Jean_Claude-Lepecq" data-corresp-id="c1">Jean-Claude Lepecq<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="CNRS, Université de la Méditerranée" /><meta itemprop="address" content="UMR 6233 Institut des Sciences du Mouvement, CNRS, Université de la Méditerranée, 163 avenue de Luminy CP 910, 13288, Marseille Cedex 9, France" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Lionel-Bringoux" data-author-popup="auth-Lionel-Bringoux">Lionel Bringoux</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="CNRS, Université de la Méditerranée" /><meta itemprop="address" content="UMR 6233 Institut des Sciences du Mouvement, CNRS, Université de la Méditerranée, 163 avenue de Luminy CP 910, 13288, Marseille Cedex 9, France" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Jean_Marie-Pergandi" data-author-popup="auth-Jean_Marie-Pergandi">Jean-Marie Pergandi</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="CNRS, Université de la Méditerranée" /><meta itemprop="address" content="UMR 6233 Institut des Sciences du Mouvement, CNRS, Université de la Méditerranée, 163 avenue de Luminy CP 910, 13288, Marseille Cedex 9, France" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Thelma-Coyle" data-author-popup="auth-Thelma-Coyle">Thelma Coyle</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="CNRS, Université de la Méditerranée" /><meta itemprop="address" content="UMR 6233 Institut des Sciences du Mouvement, CNRS, Université de la Méditerranée, 163 avenue de Luminy CP 910, 13288, Marseille Cedex 9, France" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Daniel-Mestre" data-author-popup="auth-Daniel-Mestre">Daniel Mestre</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="CNRS, Université de la Méditerranée" /><meta itemprop="address" content="UMR 6233 Institut des Sciences du Mouvement, CNRS, Université de la Méditerranée, 163 avenue de Luminy CP 910, 13288, Marseille Cedex 9, France" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 13</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">141</span>–<span itemprop="pageEnd">151</span>(<span data-test="article-publication-year">2009</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">279 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">25 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">0 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-009-0118-1/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>A particular affordance was used as a potential candidate for behavioral assessment of physical presence in virtual environments. The subjects’ task was to walk through a virtual aperture of variable widths. In the case of presence, the subjects’ body orientation, while walking, was hypothesized to be adapted to the width of the aperture and to their own shoulder width. Results show that most subjects adapted their behavior to both their body architecture and the virtual width constraints. These subjects exhibited a behavioral transition from frontal walking to body rotation while walking through broad to narrow apertures. The same behavioral transition has already been documented in real environments (Warren and Whang in J Exp Psychol Human Percept Perform 13(3):371–383, 1987). This behavioral adjustment is thus assumed to be an objective indication of presence. Beyond these results, the present study suggests that every afforded action could be a potential tool for sensorimotor assessment of physical presence.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>The notion of presence in a virtual environment (VE) is central to virtual reality research (Lombard and Jones <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007a" title="Lombard M, Jones MT (2007a) Identifying the (tele) presence literature. Psychnology J 5(2):197–206" href="/article/10.1007/s10055-009-0118-1#ref-CR17" id="ref-link-section-d68082e329">2007a</a>, b). Because this notion is highly interdisciplinary, its use has long been marked by a rich and burgeoning polysemy. In an attempt to share a common terminology, the presence community research has proposed the following definition (International Society for Presence Research <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="International Society for Presence Research (2008) The concept of presence: explication statement. Retrieved May 15, 2008 from &#xA;                    http://www.temple.edu/ispr/frame_explicat.htm&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-009-0118-1#ref-CR14" id="ref-link-section-d68082e332">2008</a>): “Presence is a psychological state or subjective perception in which even though part or all of an individual’s current experience is generated by and/or filtered through human-made technology, part or all of the individual’s perception fails to accurately acknowledge the role of the technology in the experience.” This definition has two main interests. First, it stresses the fundamental illusory aspect of presence. It is close to the conception according to which presence would be basically “a perceptual illusion of non-mediation’’ (Lombard and Ditton <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Lombard M, Ditton TB (1997) At the heart of it all: the concept of presence. J Comp Mediat Commun 3(2). Retrieved May 15, 2008 from &#xA;                    http://jcmc.indiana.edu/vol3/issue2/lombard.html&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-009-0118-1#ref-CR16" id="ref-link-section-d68082e335">1997</a>). Additionally, this definition contains a criterion of falsifiability (Popper <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1959" title="Popper KR (1959) The logic of scientific discovery. Basic Books, New York" href="/article/10.1007/s10055-009-0118-1#ref-CR20" id="ref-link-section-d68082e338">1959</a>). According to this criterion, depending on whether or not “part or all of the individual fails to accurately acknowledge the role of the technology in the experience”, it can be concluded that such experience involves presence (or not).</p><p>Beyond this minimally agreed-upon definition, what psychological and neurological processes underlie presence remains an open question. One possible way to progress on this question would be not to consider presence as a whole but rather to differentiate between different types of presence. As a multi-dimensional concept, it has generally been proposed that three main categories of dimensions could be taken into account: the dimensions “that involve perceptions of physical environments, those that involve perceptions of social interaction, and those that involve both of these” (International Society for Presence Research <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="International Society for Presence Research (2008) The concept of presence: explication statement. Retrieved May 15, 2008 from &#xA;                    http://www.temple.edu/ispr/frame_explicat.htm&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-009-0118-1#ref-CR14" id="ref-link-section-d68082e344">2008</a>). For example, Ijsselsteijn et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Ijsselsteijn WA, de Ridder H, Freeman J, Avons SE (2000) Presence: concept, determinants and measurement. Proc Soc Photo Opt Instrum Eng 3959:520–529" href="/article/10.1007/s10055-009-0118-1#ref-CR11" id="ref-link-section-d68082e347">2000</a>) distinguished between social presence (the feeling of being together and communicating with others) and physical presence (the feeling of being physically located in a place). The present work is focused on physical presence.</p><p>Considering that presence was a key aspect of virtual reality, ultimately linked to its effectiveness, researchers went on to measure it. There are multiple ways of assessing presence (van Baren and Ijsselsteijn <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="van Baren J, Ijsselsteijn WA (2004) Compendium of presence measures. Retrieved November 11, 2008. &#xA;                    http://www.informatik.umu.se/~jwworth/PresenceMeasurement.pdf&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-009-0118-1#ref-CR26" id="ref-link-section-d68082e353">2004</a>). However, three main evaluation approaches (with rich interactions) can be distinguished (Insko <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Insko B (2003) Measuring presence: subjective, behavioral, and physiological methods. In: Riva G, Davide F, Ijsselsteijn W (eds) Being there: concepts, effects and measurement of user presence in synthetic environments. IOS Press, Amsterdam, pp 109–119" href="/article/10.1007/s10055-009-0118-1#ref-CR13" id="ref-link-section-d68082e356">2003</a>). Historically, questionnaires have been first developed and are still being used and improved (e.g., Witmer and Singer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Witmer BG, Singer MJ (1998) Measuring presence in virtual environments: a presence questionnaire. Presence Teleoperators Virtual Environ 7(3):225–240" href="/article/10.1007/s10055-009-0118-1#ref-CR30" id="ref-link-section-d68082e359">1998</a>). Next to this, physiological indicators involving the autonomous nervous system activity, such as skin conductance or cardiac rhythm are used, considered as more objective than answers to questionnaires (e.g., Wiederhold et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Wiederhold BK, Jang DP, Kaneda M, Cabral I, Lurie Y, May T, Kim IY, Wiederhold MD, Kim SI (2001) An investigation into physiological responses in virtual environments: an objective measurement of presence. In: Riva G, Galimberti C (eds) Towards cyber psychology: mind, cognitions and society in the Internet age. IOS Press, Amsterdam, pp 175–183" href="/article/10.1007/s10055-009-0118-1#ref-CR28" id="ref-link-section-d68082e362">2001</a>). Finally, overt behavioral observations which are thought not to be under conscious control, such as a startle reflex or postural sway, are also used to assess presence (e.g., Freeman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Freeman J, Avons SE, Meddis R, Pearson DE, Ijsselsteijn WA (2000) Using behavioural realism to estimate presence: a study of the utility of postural responses to motion stimuli. Presence Teleoperators Virtual Environ 9(2):149–164" href="/article/10.1007/s10055-009-0118-1#ref-CR5" id="ref-link-section-d68082e365">2000</a>). Moreover, physiological and behavioral evaluations can be conducted during virtual reality exposure, whereas questionnaires are post-exposure measurements of presence. For both physiological indicators and overt behaviors, the basic assumption is that the more a subject feels present in a VE, the more similar his/her responses will be to those s/he would exhibit in a similar real environment (Slater <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Slater M (2002) Presence and the sixth sense. Presence Teleoperators Virtual Environ 11(4):435–439" href="/article/10.1007/s10055-009-0118-1#ref-CR23" id="ref-link-section-d68082e369">2002</a>). This work is focused on a particular type of overt behavior as a tool to objectify physical presence.</p><p>In the present experiment, in order to assess presence in VE, we investigated spatio-temporal aspects of adaptive behavior, governed by volition and selection. In everyday life, there are numerous adaptive behaviors, which imply both an intention to act and a selection among variations of the same act. For example, walking from one place to another can be performed using different paths. The selection of a particular behavior may be constrained by the relationships between the environment and the body architecture. For example, the choice of a peculiar locomotor trajectory may result from the variety of possible paths in a cluttered environment and the size or the suppleness of the body. As such, evaluating presence in a VE may be approached using the concept of affordances (Gibson <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1979" title="Gibson JJ (1979) The ecological approach to visual perception. Houghton Mifflin, Boston" href="/article/10.1007/s10055-009-0118-1#ref-CR6" id="ref-link-section-d68082e375">1979</a>). The affordances are the perceivable possibilities for action which are both provided by the environment and allowed by the actor capabilities. The idea that affordances could be used to assess physical presence has already been repeatedly suggested from various theoretical standpoints. Gibson’s ecological framework has thus been presented as a promising functional approach for defining the reality of experience in relation to the problem of designing VE (Flach and Holden <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Flach JM, Holden JG (1998) The reality of experience: Gibson’s way. Presence Teleoperators Virtual Environ 7(1):90–95" href="/article/10.1007/s10055-009-0118-1#ref-CR4" id="ref-link-section-d68082e378">1998</a>). In a similar Gibsonian vein, it has been proposed that presence is equivalent to successfully supported action in the environment, whether the environment is virtual or real, local or remote in relation to the actor (Zahorik and Jenison <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Zahorik P, Jenison RL (1998) Presence as being-in-the-world. Presence Teleoperators Virtual Environ 7(1):78–89" href="/article/10.1007/s10055-009-0118-1#ref-CR31" id="ref-link-section-d68082e381">1998</a>). In a situated cognition perspective on presence, it has been argued that physical presence depends on integration of aspects relevant to movement and perception, as well as on how these aspects interact with the possibilities for action afforded in the interaction with the VE (Carassa et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Carassa A, Morganti F, Tirassa M (2005) A situated cognition perspective on presence. In: Bara L, Barsalou LW, Bucciarelli M (eds) XXVII Annual conference of the cognitive science society. Sheridan Printing, Alpha (New Jersey), pp 384–389" href="/article/10.1007/s10055-009-0118-1#ref-CR2" id="ref-link-section-d68082e384">2005</a>). In a mental model approach of physical presence, it has been recently proposed that such presence is a bistable experience, during which perceived self-location and perceived action possibilities (i.e., affordances) are connected to a mediated spatial environment, and mental capacities are bound by the mediated environment instead of reality (Wirth et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Wirth W, Hartmann T, Böcking S, Vorderer P, Klimmt C, Schramm H, Saari T, Laarni J, Ravaja N, Ribeiro Gouveia F, Biocca F, Sacau A, Jäncke L, Baumgartner T, Jäncke P (2007) A process model of the formation of spatial presence experiences. Media Psychol 9(3):493–525" href="/article/10.1007/s10055-009-0118-1#ref-CR29" id="ref-link-section-d68082e387">2007</a>). Even more recently, Schubert (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Schubert T (2009) A new conception of spatial presence: once again, with feeling. Commun Theory 19:161–187" href="/article/10.1007/s10055-009-0118-1#ref-CR22" id="ref-link-section-d68082e391">2009</a>) considers that affordances determine physical presence and calls for the need to study affordances in an embodied conceptualization of physical presence.</p><p>The main hypothesis of our study is that the degree of presence in a VE can be evaluated by its actual affordances for action, which can be experimentally tested. For example, a subject may have to lengthen the stride while stepping over a street gutter or to rotate the body while walking through a narrow aperture (Warren and Whang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Warren WH, Whang S (1987) Visual guidance of walking through apertures: Body-scaled information for affordances. J Exp Psychol Human Percept Perform 13(3):371–383" href="/article/10.1007/s10055-009-0118-1#ref-CR27" id="ref-link-section-d68082e398">1987</a>). These adaptive behaviors pertain to body-scaled motor adjustments. For a street gutter of constant width, the tendency to lengthen the step is more pronounced if the legs are short. Similarly, for an aperture of constant width, the tendency to rotate the body is more marked for larger shoulder widths. These body-scaled behaviors, such as the shoulder rotation pattern involved in walking through an aperture, present various theoretical and methodological interests. From a theoretical point of view, it is important to determine where such behavior takes place along a continuum of controllability ranging from uncontrollable “hard-wired” behaviors to self-controlled volitive behaviors. In the first case indeed, this uncontrollable “hard-wired” behavior would always occur, whether the subject feels present or not. In the second case, the behavior would reflect a deliberate spatially guided postural locomotor behavior devoted to obstacle avoidance. This behavior would thus depend on the subject’s belief according to which there is some obstacle to avoid. Since the subject’s belief reflects, at some level, a failure to accurately acknowledge the role of the technology in the experience, this belief is compatible with the assumption of physical presence. Where does “shoulder rotation” take place along the continuum of controllability? First, it seems excluded that this behavior belongs to the uncontrollable “hard-wired” category. Indeed, navigating through apertures is learned through trial and error-learning during ontogenesis. For example, it is known that children may dangerously push their head between the spindles of a crib or piece of playground equipment (Tinsworth and McDonald <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Tinsworth DK, McDonald JE (2001) Special study: Injuries and deaths associated with children’s playground equipment. Consumer Product Safety Commission, Washington, DC" href="/article/10.1007/s10055-009-0118-1#ref-CR25" id="ref-link-section-d68082e401">2001</a>; Ishak et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Ishak S, Adolph KE, Lin GC (2008) Perceiving affordances for fitting through apertures. J Exp Psychol Human Percept Perform 34(6):1501–1514" href="/article/10.1007/s10055-009-0118-1#ref-CR15" id="ref-link-section-d68082e404">2008</a>). Even adults might slightly misjudge their ability to pass through doorways while walking (Gordon and Rosenblum <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Gordon MS, Rosenblum LD (2004) Perception of sound-obstructing surfaces using body-scaled judgments. Ecol Psychol 16(2):87–113" href="/article/10.1007/s10055-009-0118-1#ref-CR7" id="ref-link-section-d68082e407">2004</a>; Warren and Whang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Warren WH, Whang S (1987) Visual guidance of walking through apertures: Body-scaled information for affordances. J Exp Psychol Human Percept Perform 13(3):371–383" href="/article/10.1007/s10055-009-0118-1#ref-CR27" id="ref-link-section-d68082e410">1987</a>). Second, navigating through an aperture involves posturo-locomotor behavior. At some level, locomotion is clearly an automatic activity. Possibly, the postural component of this activity (shoulder rotation while locomoting) may also become automatic in the repetitive exposure to obstacle avoidance. The point here is, even if this postural locomotor behavior is an automatic one, it can be voluntarily modified. For example, locomotion as an automatic behavior can be voluntarily modified in terms of speed or direction. In short, shoulder rotation while walking is probably an automatic activity which can be voluntarily modified. As a controllable activity, the “shoulder rotation pattern involved in walking through an aperture” provides a test sensitive to physical presence. Additionally, from a methodological point of view, such body-scaled behaviors present a triple interest. First, they can be potentially elicited within VEs. Second, they happen at the very time during which presence occurs. In other words, they are not postponed, but they are contemporaneous with the psychological state involving presence. Finally, their variations due to the interplay of body architecture and virtual constraints are objectively measurable. As such, they can provide a behavioral evaluation of presence.</p><p>Surprisingly, there is very little research in which afforded actions were used to assess presence in VE. Objectifying presence via body scaled motor adjustment while walking through an aperture has already been attempted (Stappers et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Stappers PJ, Flach JM, Voorhorst FA (1999) Critical ratio as behavioral indices of presence. Presented at the second international workshop on presence, University of Essex, UK, April 6–7 1999. Retrieved November 11, 2008 &#xA;                    http://www.temple.edu/ispr/prev_conferences/proceedings/98-99-2000/1999/Stappers,%20Flach%20and%20Voorhorst.pdf&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-009-0118-1#ref-CR24" id="ref-link-section-d68082e416">1999</a>). However, this study failed to demonstrate that virtual and real apertures were experienced in the same way. While walking through a real aperture, subjects classically exhibit a behavioral transition from frontal walking (when the aperture is large enough) to body rotation (when the aperture is too narrow) (Warren and Whang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Warren WH, Whang S (1987) Visual guidance of walking through apertures: Body-scaled information for affordances. J Exp Psychol Human Percept Perform 13(3):371–383" href="/article/10.1007/s10055-009-0118-1#ref-CR27" id="ref-link-section-d68082e419">1987</a>; Higuchi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Higuchi T, Cinelli ME, Greig MA, Patla AE (2006) Locomotion through apertures when wider space for locomotion is necessary to artificially altered bodily states. Exp Brain Res 175:50–59" href="/article/10.1007/s10055-009-0118-1#ref-CR9" id="ref-link-section-d68082e422">2006</a>). In addition, subjects with large shoulders exhibit greater angles of shoulder rotation than small subjects. However, when the same shoulder rotations are plotted against a relevant body-scaled ratio (aperture width/shoulder width), the difference between subjects of different sizes vanishes. This suggests that, in real conditions, “large” and “small” subjects behave similarly relative to their own body size (Warren and Whang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Warren WH, Whang S (1987) Visual guidance of walking through apertures: Body-scaled information for affordances. J Exp Psychol Human Percept Perform 13(3):371–383" href="/article/10.1007/s10055-009-0118-1#ref-CR27" id="ref-link-section-d68082e425">1987</a>; Higuchi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Higuchi T, Cinelli ME, Greig MA, Patla AE (2006) Locomotion through apertures when wider space for locomotion is necessary to artificially altered bodily states. Exp Brain Res 175:50–59" href="/article/10.1007/s10055-009-0118-1#ref-CR9" id="ref-link-section-d68082e428">2006</a>). On the other hand, in VE, there was no evidence that the subjects could relate the size of the aperture to their own shoulder width. Instead, in the study of Stappers et al (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Stappers PJ, Flach JM, Voorhorst FA (1999) Critical ratio as behavioral indices of presence. Presented at the second international workshop on presence, University of Essex, UK, April 6–7 1999. Retrieved November 11, 2008 &#xA;                    http://www.temple.edu/ispr/prev_conferences/proceedings/98-99-2000/1999/Stappers,%20Flach%20and%20Voorhorst.pdf&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-009-0118-1#ref-CR24" id="ref-link-section-d68082e432">1999</a>), body rotation was observed for every aperture size, even when no body rotation was required to pass through the aperture. This initial failure may explain why affordances have been so poorly investigated in physical presence research (Lombard and Jones <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007a" title="Lombard M, Jones MT (2007a) Identifying the (tele) presence literature. Psychnology J 5(2):197–206" href="/article/10.1007/s10055-009-0118-1#ref-CR17" id="ref-link-section-d68082e435">2007a</a>, b).</p><p>Stappers’ et al. (1999) negative results might also have been due to the use of helmet-mounted displays, suffering from a reduced field of vision and the residual presence of a head-fixed visual reference frame (Mars et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Mars F, Bringoux L, Cian C, Barraud PA, Raphel C, Vercher JL (2005) Perception de la verticale avec un cadre visuel solidaire de la tête: implications pour l’utilisation des visiocasques. Trav Hum 68:125–152" href="/article/10.1007/s10055-009-0118-1#ref-CR19" id="ref-link-section-d68082e441">2005</a>). Thus, we undertook a similar study with a four-sided cave-like system, enabling us to stimulate the subject’s entire visual field (Cruz-Neira et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Cruz-Neira C, Sandin DJ, DeFanti TA (1993) Surround-screen projection-based virtual reality: the design and implementation of the cave. Proceedings of the 20th annual conference on computer graphics and interactive techniques, New York, pp 135–142" href="/article/10.1007/s10055-009-0118-1#ref-CR3" id="ref-link-section-d68082e444">1993</a>). We designed an experimental study, in which subjects had to walk through a virtual aperture whose width was manipulated. Continuous monitoring of their movements while walking forward through the virtual aperture was achieved, in order to evaluate the adequacy of their body adjustments to the size of the aperture and to their own shoulder size. The core hypothesis of our study was that, if subjects experienced presence then they should exhibit in VEs the basic behavioral properties already observed in corresponding real environments (Slater <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Slater M (2002) Presence and the sixth sense. Presence Teleoperators Virtual Environ 11(4):435–439" href="/article/10.1007/s10055-009-0118-1#ref-CR23" id="ref-link-section-d68082e447">2002</a>). Three expectations were investigated in this respect (Warren and Whang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Warren WH, Whang S (1987) Visual guidance of walking through apertures: Body-scaled information for affordances. J Exp Psychol Human Percept Perform 13(3):371–383" href="/article/10.1007/s10055-009-0118-1#ref-CR27" id="ref-link-section-d68082e450">1987</a>; Higuchi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Higuchi T, Cinelli ME, Greig MA, Patla AE (2006) Locomotion through apertures when wider space for locomotion is necessary to artificially altered bodily states. Exp Brain Res 175:50–59" href="/article/10.1007/s10055-009-0118-1#ref-CR9" id="ref-link-section-d68082e453">2006</a>). The first one was that subjects should exhibit a behavioral transition from frontal walking (large aperture) to body rotation (narrow aperture) while walking through the virtual door. In order to check this expectation, we examined whether their eventual shoulder rotation was adapted to the width of the virtual aperture. Secondly, the subjects were also expected not to collide with the sides of the virtual door. In order to investigate this point, we examined the spatial accuracy with which walking through the virtual aperture was performed. Thirdly, it was expected that not only the subjects with large shoulders should show greater angles of shoulder rotation than small subjects, but also that both types of subjects should behave similarly with respect to their own body size. In order to check this expectation, we compared the critical aperture widths and the critical body-scaled (aperture width/shoulder width) ratios from which “large” and “small” subjects exhibit a behavioral transition from frontal walking to body rotation while walking through the virtual aperture.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Method</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Subjects</h3><p>Nineteen male subjects voluntarily participated in the experiment, ranging in age from 18 to 30 years (mean = 21.6; SD = 3.1). The rationale for including males only was morphological. In males, the body rotation while walking through an aperture is known to depend upon the shoulder width, i.e., the widest frontal body dimension (Warren and Whang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Warren WH, Whang S (1987) Visual guidance of walking through apertures: Body-scaled information for affordances. J Exp Psychol Human Percept Perform 13(3):371–383" href="/article/10.1007/s10055-009-0118-1#ref-CR27" id="ref-link-section-d68082e468">1987</a>). In females, the same behavior is potentially more complex since it could depend not only on the shoulder width but also on the bust size. The 19 male subjects had normal or corrected to normal vision. They were free from any known locomotor disorder. They were naïve as to the purpose of the experiment. They were not a priori selected regarding their stature. Their standing height ranged from 159 to 194 cm (mean = 178.4; SD = 8.9). Their shoulder width ranged from 40 to 55 cm (mean = 45.6; SD = 3.1). Their inter-pupillary distance ranged from 57 to 69.5 mm (mean = 63.6; SD = 3.2). Their stereoscopic acuity, as assessed using the Randot<sup>®</sup> Graded Circles test (Stereo Optical Company Inc, Chicago, IL, USA) ranged from 20 to 140 s of arc (median = 20; upper and lower quartiles were 50 and 20; interquartile range = 30).</p><h3 class="c-article__sub-heading" id="Sec4">Apparatus</h3><p>The experiment was conducted inside a cave-like virtual reality system (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0118-1#Fig1">1</a>). The hardware consisted of four projection surfaces: the front, left and right vertical walls and the horizontal floor. The three walls (3 m wide and 4 m high) were back-projected acrylic screens. The floor (a square with a side of 3 m) was directly projected from above. The height of the display (4 m) was defined in order to avoid the need for a ceiling projection surface, while optimizing visual immersion. Only the top and the rear faces of our cave were not projection surfaces.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig1_HTML.jpg" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Schematic representation of the VR system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Each projection surface received images with 1,400 × 1,050 pixels resolution. The screens were seamlessly joined to provide a visually continuous projection surface. Stereoscopic projection of VEs was achieved by two DLP<sup>®</sup> (Digital Light Processing) projectors attached to each projection surface. Each projector addressed one eye. Stereoscopic separation between left and right eye images was ensured by colorimetric separation (Infitec<sup>®</sup> technological solution). Infitec filters were installed in the projectors, while the subject was wearing glasses with the same filters. This guaranteed perfect separation of images between the two eyes. Finally, a head tracking system (ArtTrack<sup>®</sup>), using infrared recognition of passive markers placed on the subject’s glasses, was used to record the subject’s head position and orientation and to update in real time (60 Hz frame rate) the stereoscopic images relative to the subject’s point of view (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0118-1#Fig3">3</a>). Additionally, passive markers were symmetrically placed on the subject’s shoulders. The whole projection system was controlled by a cluster of five PCs (one master + four slaves). Each slave PC was attached to a couple of projectors devoted to a projection surface. Surrounding spatialized sound stimulation was achieved by means of a 7.1 sound system. We used Virtools<sup>®</sup> solution to build and control virtual scenarios, for experimental control and data recording.</p><h3 class="c-article__sub-heading" id="Sec5">The virtual environment</h3><p>The VE was designed using 3D modeling software (3DSmax<sup>®</sup>). It was then imported into Virtools for building and running the experimental scenario. The VE was composed of two adjoining rooms connected via a sliding door (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0118-1#Fig2">2</a>). The first room was empty and was marked with a starting point (light-gray disk displayed on the floor). The second room was furnished (in order to provide static and dynamic depth cues) and was marked with an arrival point (dark-gray disk). The sliding door consisted of two mobile surfaces (height = 204 cm, thickness = 25 cm) that could be closed or opened by lateral translation. The opening and the closing of the door were accompanied with different rattle sounds. The sliding door formed an aperture whose width was variable and ranged from 40 to 80 cm, by 5 cm steps. The nine possible aperture widths were 40, 45, 50, 55, 60, 65, 70, 75 and 80 cm. The starting point, the center of the door and the arrival point were aligned. The distance from the starting point to the door and from the door to the arrival point was 110 and 90 cm, respectively. The center of the door was located at the center of the cave (along front–back and left–right axes).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>The virtual rooms and the sliding door</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec6">Procedure</h3><p>Each subject was briefed in an independent room adjoining the room containing the cave. Several anthropometric and perceptual measures were performed in that room. The standing height was canonically measured using a stadiometer. Shoulder width, the widest frontal body dimension, was measured with an anthropometer from the tip of the left humerus (humeral greater tubercle) to the tip of the right humerus with the shoulders relaxed, in a standing subject. The inter-pupillary distance was measured with a corneal reflection pupillometer. This measure was taken into account in order to generate stereoscopic images and hence individually optimize spatial perception from binocular vision.</p><p>Inside the immersive environment, the subject was equipped with INFITEC stereo glasses and with reflective markers on the glasses and on both shoulders (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0118-1#Fig3">3</a>). The shoulder markers were symmetrically placed over the trapezius muscles (between the neck and the shoulder) and not on the heads of the right and left humeri. This particular placement was designed to avoid subjective widening of the shoulders (Berlucchi and Aglioti <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Berlucchi G, Aglioti S (1997) The body in the brain: Neural bases of corporeal awareness. Trends Neurosci 20:560–564" href="/article/10.1007/s10055-009-0118-1#ref-CR1" id="ref-link-section-d68082e560">1997</a>; Holmes and Spence <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Holmes NP, Spence C (2006) Beyond the body schema: visual, prosthetic, and technological contributions to bodily perception and awareness. In: Knoblich G, Thornton IM, Grosjean M, Shiffrar M (eds) Human body perception from the inside out. Oxford University Press, New York, pp 15–64" href="/article/10.1007/s10055-009-0118-1#ref-CR10" id="ref-link-section-d68082e563">2006</a>). These equipments allowed 3D tracking of the subject’s cyclopean point of gaze (for real-time updating of the visual scene) and recording of shoulders’ positions (for offline analysis of the subject’s posture) by the ART<sup>®</sup> system. These trackings and recordings were performed with respect to three axes. These were left–right or X axis, front–back or Z axis and up–down or Y axis (for a subject facing the front wall).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig3_HTML.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig3_HTML.jpg" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Representation of the subject’s equipment, with markers attached to stereo glasses and a set of markers on each shoulder</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Once equipped, the subject was conducted from the welcome room into the cave. In order to optimize immersion into the VE, the eyes-closed subjects were guided by the experimenter into the VE and required to open their eyes only when facing the front wall from the starting point, while the VE was displayed. In this way, they could see the VE only throughout the experimental session.</p><p>The initial scene (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0118-1#Fig2">2</a>) showed the sliding doors wide open (aperture = 250 cm). Then the doors were closed, leaving an aperture whose width was one of the nine predetermined values. This closing was accompanied by a spatialized rattling sound at the doors location. Facing the front wall, the subject stood on the starting point. He was prevented from walking forward since he was restrained by the shoulders by the experimenter located behind him. The subject was then required to walk straight from the starting point to the arrival point and to stop at this point (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0118-1#Fig4">4</a>). This neutral directive aimed to avoid any behavior induction by instructional semantic effects. To allow him to do so, the experimenter liberated the subject from any physical constraints. The unconstrained walking speed should be normal and comfortable. Once at the arrival point, the subject was required to stand still, facing the front wall and not to make a U-turn. The subject was informed that the sliding door behind him would open wide. This opening was accompanied by a spatialized rattling sound located behind the subject. When the sliding door was opened, the subject walked backwards from the arrival point to the starting point. The experimenter held the subject by the shoulders in order to guide him during this backward walk. This backward walk with the doors wide opened was designed to avoid possible cognitive conflict that may have arisen if the subject had walked through or hit the virtual walls that delimited the door. Once at the starting point, the subject was required to precisely face the front wall. The doors were then closed, leaving an aperture whose width was one of nine predetermined values. A new trial could then begin.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig4_HTML.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig4_HTML.jpg" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Schematic representation of a subject walking through the virtual aperture</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>During an experimental session, subjects run a series of trials, with the following logic. The aperture could be one of nine widths: 40, 45, 50, 55, 60, 65, 70, 75, 80 cm. A block of trials involved nine trials (one trial per width). Each subject performed three blocks (i.e., 3 × 9 = 27 trials). For each block, the order of presentation of the nine widths was randomized.</p><h3 class="c-article__sub-heading" id="Sec7">Dependant variables</h3><p>From the recorded successive positions of the shoulder markers, while the subjects walked through the virtual aperture, three dependant variables were computed for each trial: the maximal absolute shoulder rotation, the minimal distance between each shoulder and each lateral side of the door, and the presence of a collision between each shoulder and any lateral side of the door.</p></div></div></section><section aria-labelledby="Sec8"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Results</h2><div class="c-article-section__content" id="Sec8-content"><h3 class="c-article__sub-heading" id="Sec9">Shoulder rotation during walking through the aperture</h3><p>We here assess the hypothesis that, if subjects experienced presence, they should exhibit a behavioral transition from frontal walking to body rotation as the width of the virtual aperture diminishes. It is thus minimally expected that the body rotation should increase as aperture width decreases. Out of the 19 subjects who completed the experiment, 17 subjects adapted their body orientation to the aperture width. Their mean absolute maximum angle of shoulder rotation is plotted as a function of aperture width (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0118-1#Fig5">5</a>). An ANOVA (blocks × apertures) was conducted on individual means of shoulder rotation. This ANOVA revealed a main effect of aperture width (F<sub>8,128</sub> = 89.62, p &lt; 0.001) and a main effect of blocks (F<sub>2,32</sub> = 4.03, p &lt; 0.03) without interactions. The main result here is that the magnitude of body rotation significantly increases as aperture width decreases. Additionally, the magnitude of body rotation increases with the repetition of experimental blocks.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Individual mean absolute max angle of shoulder rotation as a function of aperture width for the seventeen subjects who adapted their body orientation to the aperture width</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec10">Spatial accuracy of walking through the aperture</h3><p>Under the presence hypothesis, walking through the aperture should also be spatially accurate enough to allow avoiding collisions against the sides of the door. Two analyses check this expectation.</p><p>A first analysis examines the number of collisions against the (left or right) lateral sides of the door upon the number of walkings through the door (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-009-0118-1#Tab1">1</a>). For the 17 subjects who adapted their body rotation to the aperture width, they were 51 (i.e., 17 × 3) passages per each aperture width. Almost all these passages were collision-free whatever the aperture width. Only some very rare collisions occurred for the narrow apertures (40, 45 and 50 cm). Over the 459 (i.e., 51 × 9) passages performed by the 17 subjects, all aperture width conditions pooled, there were six collisions. In these collisions, the shoulder exceeded the door limit by a distance ranging from 4 to 26 mm (median = 7 mm).</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Number of collisions against the left and the right side of the door upon the number of passages for each aperture width</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-009-0118-1/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>A second analysis examines the minimal security distance between the shoulders and the lateral sides of the door during walking through the aperture performed by the 17 subjects who adapted their body orientation to the aperture width. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0118-1#Fig6">6</a> plots the location of each side of the door and of each shoulder along the left–right or X axis as a function of the aperture width. The locations of the shoulders were the most extreme left position for the left shoulder and the most extreme right position for the right shoulder recorded during the walking through the aperture. Each shoulder position was recorded from the moment it entered the door until the moment it left the door. ANOVAs (blocks × apertures) were conducted on the means of minimal security distance for each body side. These ANOVAs revealed that the minimal security distance did not vary with aperture width for most apertures (65, 60, 55, 50, 45 and 40 cm) neither for the left (F<sub>5,80</sub> = 0.53, ns) nor for the right side (F<sub>5,80</sub> = 0.44, ns). This absence of effect is illustrated (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0118-1#Fig6">6</a>) by the parallelism between the locations of the (left or right) side of the door and the locations of the (left or right) shoulder for these apertures (65, 60, 55, 50, 45 and 40 cm). However, the minimal security distance decreased with aperture width for larger apertures (80, 75 and 70 cm) both for the left (F<sub>2,32</sub> = 29.78, p &lt; 0.001) and for the right side (F<sub>2,32</sub> = 15.57, p &lt; 0.001). This effect is illustrated (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0118-1#Fig6">6</a>) by the non-parallelism between the locations of the (left or right) side of the door and the locations of the (left or right) shoulder for larger apertures (80, 75 and 70 cm). Finally, the symmetrical position of the two shoulders above and below 0 (the center of the door) indicates that the subjects centered their passages toward the middle of the door whatever the aperture width.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Minimal security distance between the shoulders and the lateral sides of the door during the walking through the aperture as a function of aperture width. The minimal security distance is the interval between the location of the (left or right) door side and the location (mean ± 1 standard deviation) of the (left or right) shoulder</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec11">Critical aperture widths and “aperture/shoulder” ratios</h3><p>The two previous analyses demonstrated that, for 17 subjects, the shoulder rotation was related to the width of the virtual aperture and the spatial accuracy of the walking through the aperture was almost optimal. These analyses reflected that these subjects accurately obey the virtual width constraints. This new analysis additionally examined whether shoulder rotation was conjointly determined by both the aperture width and the shoulder width. Under the presence hypothesis, it was expected that, while the subjects with large shoulders should show greater angles of shoulder rotation than small subjects, both types of subjects should however behave similarly with respect to their own body size.</p><p>To assess this expectation, the population of 17 subjects was then divided into three groups (small, medium and large) based on their shoulder width. The shoulder width ranged from 40 to 45 cm for the small group (n = 6 subjects), and from 46 to 55 cm for the large group (n = 6 subjects). The shoulder width was above 45 cm and below 46 cm for the medium group (n = 5 subjects). Hereafter, we focused on the comparison between “small” and “large” subjects.</p><p>As expected, the “large” subjects have greater (F<sub>1,10</sub> = 6.03, p = 0.034) angles of shoulder rotation than the “small” subjects (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0118-1#Fig7">7</a>a) for intermediate apertures (55, 60, 65, 70, 75 cm). On the contrary, there was no effect of shoulder width when the subjects walked through narrow (40, 45, 50 cm) apertures (F<sub>1,10</sub> = 0.55, p = 0.47) or when they walked through the broadest (80 cm) aperture (F<sub>1,10</sub> = 0.59, p = 0.45). These results were probably due to the interplay between aperture widths and shoulder widths. When there was no constraint upon shoulder rotation (broadest aperture), “large” and “small” subjects displayed similar absence of shoulder rotation (i.e., frontal walking). Similarly, when the constraints were maximal (narrowest apertures), “large” and “small” subjects exhibited non-different shoulder rotations. Finally, “large” and “small” subjects showed different shoulder rotations when the constraints were variable (intermediate apertures).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig7_HTML.gif?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig7_HTML.gif" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Average max angle of shoulder rotation (± 1 standard deviation), for “large” and “small” subjects, as a function of aperture width (a) and as a function of the body-scaled ratio of aperture width divided by shoulder width (b)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Interestingly, the difference between groups tended to diminish when the same shoulder rotation data were replotted against the “aperture width/shoulder width” (body-scaled) ratio, hereafter referred to as A/S ratio (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0118-1#Fig7">7</a>b). Thus, rescaling of the virtual aperture as a function of a relevant body characteristic eliminates group differences, suggesting that “small” and “large” subjects behave similarly relative to their own body size.</p><p>In order to test this hypothesis, we computed the critical aperture width and critical A/S ratio from which subjects exhibit a behavioral transition from frontal walking to body rotation while walking through the aperture. This was done under the following assumptions. Each subject was considered to use “frontal walking” while walking through the largest aperture (80 cm). The eventual body rotation exhibited at each narrower aperture (75, 70, 65, 60, 55, 50, 45, 40 cm) was statistically assessed by comparison with frontal walking through the largest aperture. For each subject, following descendant width values, the first aperture giving rise to a significant difference with frontal walking (as assessed using paired <i>t</i> tests) defined the critical aperture width or the critical A/S ratio.</p><p>Mean critical aperture widths and critical A/S ratios are given in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-009-0118-1#Tab2">2</a>. The difference between the critical widths for the “small” group (52.5 cm) and “large” group (62.5 cm) was statistically significant, as assessed by Student’s <i>t</i> test (t<sub>10</sub> = −2.65, p &lt; 0.02). However, when these values were expressed intrinsically, the A/S ratios are quite similar: 1.22 for the “small” group and 1.29 for the “large” group, and not statistically different (t<sub>10</sub> = −0.83, ns). The critical A/S ratios observed here in VE are quite similar to that measured in real environment (Warren and Whang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Warren WH, Whang S (1987) Visual guidance of walking through apertures: Body-scaled information for affordances. J Exp Psychol Human Percept Perform 13(3):371–383" href="/article/10.1007/s10055-009-0118-1#ref-CR27" id="ref-link-section-d68082e1000">1987</a>). These results lend strong support to the view according to which, in real environment (Warren and Whang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Warren WH, Whang S (1987) Visual guidance of walking through apertures: Body-scaled information for affordances. J Exp Psychol Human Percept Perform 13(3):371–383" href="/article/10.1007/s10055-009-0118-1#ref-CR27" id="ref-link-section-d68082e1004">1987</a>) as well as in VE, “small” and “large” subjects behave similarly relative to their own body size.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Mean and standard deviations of critical aperture widths and critical A/S ratios in small and large subjects</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-009-0118-1/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec12">Non-adaptive behavior in two subjects</h3><p>Out of the 19 subjects who completed the experiment, 2 subjects did not adapt their body orientation to the aperture width. They did not rotate the shoulders at all while walking through the virtual aperture. During each trial, they systematically exhibited frontal walking whatever the aperture width (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0118-1#Fig8">8</a>). Because of this systematic frontal walking, they unavoidably collided against the sides of the virtual door. For geometrical reasons, these collisions occurred at the narrowest apertures. Given that these two subjects were 46.5 and 42 cm large (shoulder width) on the one hand, and that they performed straight frontal walking from the starting point to the arrival point on the other hand, they had occasional unilateral (left or right side) collisions for 45 and 50 cm aperture widths or even systematic bilateral (left and right sides) collisions for 40 cm aperture width. Interestingly, it should be noted that the peculiar behavior of these two subjects is not due to insufficient stereoscopic vision. The stereoscopic acuity of each of these two subjects corresponded to the median stereoscopic acuity (20 s of arc) of the whole population studied.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig8_HTML.gif?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0118-1/MediaObjects/10055_2009_118_Fig8_HTML.gif" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Individual mean absolute max angle of shoulder rotation as a function of aperture width for the two subjects who exhibited frontal walking whatever the aperture width</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0118-1/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        </div></div></section><section aria-labelledby="Sec13"><div class="c-article-section" id="Sec13-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec13">Discussion</h2><div class="c-article-section__content" id="Sec13-content"><p>The results of this study indicate that the locomotor postural patterns of subjects having to walk through a virtual aperture strongly resemble those of subjects who have to walk through a real aperture (Warren and Whang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Warren WH, Whang S (1987) Visual guidance of walking through apertures: Body-scaled information for affordances. J Exp Psychol Human Percept Perform 13(3):371–383" href="/article/10.1007/s10055-009-0118-1#ref-CR27" id="ref-link-section-d68082e1175">1987</a>; Higuchi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Higuchi T, Cinelli ME, Greig MA, Patla AE (2006) Locomotion through apertures when wider space for locomotion is necessary to artificially altered bodily states. Exp Brain Res 175:50–59" href="/article/10.1007/s10055-009-0118-1#ref-CR9" id="ref-link-section-d68082e1178">2006</a>). For most subjects indeed, a behavioral transition from frontal walking to body rotation was observed as the width of the virtual aperture diminishes. Most subjects also walked through the virtual aperture of different widths with great accuracy. Additionally, subjects with wider shoulders were observed to rotate their body more than subjects with small shoulder widths. Finally, the differences between “small” and “large” subjects tended to vanish when body rotation was considered with respect to a body-scaled ratio (aperture width/shoulder width). Indeed, while the behavioral transition from frontal walking to body rotation occurred at different critical aperture widths (expressed in centimeters) in “small” versus “large” subjects, the same behavioral transition occurred at the same critical body-scaled ratio (aperture width/shoulder width) in both types of subjects. All these conclusions are common to our study performed in VE and to Warren and Whang’s study (1987) completed in real conditions. We thus suggest that all these facts together constitute a strong behavioral indicator of physical presence. Indeed, all these facts fulfill the basic assumption that the more a subject feels present in a VE, the more similar his responses will be to those he would exhibit in a similar real environment (Slater <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Slater M (2002) Presence and the sixth sense. Presence Teleoperators Virtual Environ 11(4):435–439" href="/article/10.1007/s10055-009-0118-1#ref-CR23" id="ref-link-section-d68082e1181">2002</a>).</p><p>Furthermore, the present results show that, out of 19 naïve subjects, 17 always systematically responded to the experimental setup (rotating their body to pass through the aperture without hitting the sides), while being only asked to step forward. This result demonstrates the immersive characteristics of the VR setup, including real-time interaction between the subject’s movement and sensorial updating of the VE, 3D cues (stereoscopic vision, motion parallax), surrounding visual and auditory stimulation. Here, it should be noted that they are multiple methodological differences between our study and that of Stappers et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Stappers PJ, Flach JM, Voorhorst FA (1999) Critical ratio as behavioral indices of presence. Presented at the second international workshop on presence, University of Essex, UK, April 6–7 1999. Retrieved November 11, 2008 &#xA;                    http://www.temple.edu/ispr/prev_conferences/proceedings/98-99-2000/1999/Stappers,%20Flach%20and%20Voorhorst.pdf&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-009-0118-1#ref-CR24" id="ref-link-section-d68082e1187">1999</a>) which first attempted to evidence that walking through an aperture of variable widths share basic properties between virtual and real conditions, and as such might potentially constitute a behavioral index of physical presence. It is then difficult to explain with precision why the present study solves the problem that has led to unsuccessful demonstration in this previous research. Future research will investigate more precisely the role of these different factors. From the literature, it can be suggested that self-generated motion cues associated with large field stimulation (Ijsselsteijn et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Ijsselsteijn WA, de Ridder H, Freeman J, Avons SE, Bouwhuis D (2001) Effects of stereoscopic presentation, image motion, and screen size on subjective and objective corroborative measures of presence. Presence Teleoperators Virtual Environ 10(3):298–311" href="/article/10.1007/s10055-009-0118-1#ref-CR12" id="ref-link-section-d68082e1190">2001</a>), as well as converging multi-sensorial stimulation (here sound and vision) contribute to the sensation of presence (Slater <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Slater M (2002) Presence and the sixth sense. Presence Teleoperators Virtual Environ 11(4):435–439" href="/article/10.1007/s10055-009-0118-1#ref-CR23" id="ref-link-section-d68082e1193">2002</a>).</p><p>The fact that 17 of our subjects behave in coherence with the VE can be then considered as evidence that our experimental setup was efficient in making the subjects believe that they were actually facing a real door, necessitating shoulder rotation to pass through. In short, most subjects behave as if they believed in the tangibility of the visual world. In this regard, it can be hypothesized that the belief in the tangibility of the door would be based on the experience of the actual tangibility of the ground. In our experiment, the visible parts of the virtual world are heterogeneous in terms of potential tangibility. Some parts, like the horizontal ground surface, are both visible and tangible. Other parts, like the vertical sides of the door, are visible but not tangible. It may be that the property of tangibility would be extended to all visual parts. This extension would be cognitively possible for two reasons. First, the subjects experienced by walking the tangibility of the visual floor. Second, the subjects never experienced the non-tangibility of the door. The systematic confirmation of the tangibility of the floor associated to the systematic lack of disconfirmation of the non-tangibility of the door may feed the belief in a general tangibility of the visual virtual world.</p><p>The achievement of walking through apertures in real environment presupposes the involvement of at least two distinct perceptions: visual perception (for aperture width) and the self-perception of body stature (for shoulder width) (Warren and Whang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Warren WH, Whang S (1987) Visual guidance of walking through apertures: Body-scaled information for affordances. J Exp Psychol Human Percept Perform 13(3):371–383" href="/article/10.1007/s10055-009-0118-1#ref-CR27" id="ref-link-section-d68082e1201">1987</a>; Higuchi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Higuchi T, Cinelli ME, Greig MA, Patla AE (2006) Locomotion through apertures when wider space for locomotion is necessary to artificially altered bodily states. Exp Brain Res 175:50–59" href="/article/10.1007/s10055-009-0118-1#ref-CR9" id="ref-link-section-d68082e1204">2006</a>). The fact that most subjects managed to adequately walk through apertures in our VE, suggests that both perceptions were preserved during this action. In other words, our study suggests that our VE not only provided an exact metric regarding the environment, but also that this VE did not alter the perception of metric regarding the body. It is thus possible that this type of VE, which represent canonical views of the reality (in terms of usual size, orientation and motion), let unchanged the kinesthetic and proprioceptive processes by which the self-perception of the body is routinely achieved in normal earth environment.</p><p>However, it remains that two subjects never responded to our experimental setup. They systematically adopted frontal walking while they walked through the aperture whatever its size. They systematically collided against both sides of the door of the narrowest width. What happened with these two subjects? Here a couple of (non-exclusive) hypotheses can be evoked, which will certainly require further studies. We tried our best to optimize immersion, including having subjects blindfolded until they were “inside” the VE and never letting them look backwards. Doing that, we tried to minimize “real world” stimulation. However, it might be that some uncontrolled variables (e.g., the unavoidable junction between screen surfaces) and/or subject behavior (looking up momentarily to the ceiling) has destroyed the sensation of presence inside the VE. This hypothesis points toward limitations of the immersive setup (one subject told us that he did not see the reason why he would react to immaterial, transparent surfaces). In addition, we might also consider the hypothesis that subjects’ cognitive and personality characteristics, such as field-dependency (Sas and O`Hare 2003; Hecht and Reiner <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Hecht D, Reiner M (2007) Field dependency and the sense of object presence in haptic virtual environments. Cyber Psychol Behav 10:243–251" href="/article/10.1007/s10055-009-0118-1#ref-CR8" id="ref-link-section-d68082e1211">2007</a>) come into play, when it comes to the subjective and integrative balance between different sensorial streams. Finally, it should be noted that the absence of the expected response in subjects suggests that the behavioral index (“shoulder rotation”) was not a compulsory uncontrollable behavior.</p><p>Now, the present study needs to be completed by additional investigations, in order to further support the validity of the studied behavior (“shoulder adjustment”) as a measurement of physical presence. Generally speaking, these complementary investigations should regard various metrological properties of presence measurement by the way of this behavioral index. In particular, these investigations should assess the sensitivity of the measure. So far, the experiment demonstrates that most (17 of 19) subjects adapted their body orientation to the aperture width. This suggests that most subjects feel strong presence with this scenario. However, this sole result only informs us about the strong power to induce presence of this simple scenario generated by a sophisticated VE. In order to assess the sensitivity of this behavioral index in measuring felt presence, it is also necessary to demonstrate that different scenario ranked according to their power to induce physical presence, cause various responses from this behavioral index. In particular, this behavior is expected to occur less frequently, in fewer participants or with less accuracy in a condition with a low inducing level of presence than in a condition with a high one. It is our intention to perform this kind of research in order to potentially strengthen the validity of the particular afforded behavior used here as a measurement tool for physical presence.</p><p>To sum up, presence was assessed in the present study by a particular motor adjustment which links the size of a body feature (shoulder width) to the size of some characteristics in the environment (width of the door). This kind of adjustment pertains to body-scaled motor adjustment. In other words, these motor adjustments constitute some “realized affordances”. According to Gibson (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1979" title="Gibson JJ (1979) The ecological approach to visual perception. Houghton Mifflin, Boston" href="/article/10.1007/s10055-009-0118-1#ref-CR6" id="ref-link-section-d68082e1219">1979</a>), an affordance is an action possibility which is provided to an organism depending both on the organism properties and environment properties. In short, the present study suggests that eliciting “acted affordances” in virtual reality research could contribute to the behavioral assessment of presence in VEs. Since any “acted affordance” implies measurable variations (e.g., magnitude of body rotation) of a given action (e.g., walking through an aperture) and that these variations depend on both some body characteristics (e.g., the shoulder width) and some VE feature (e.g., the width of the aperture), we propose that any “acted affordance” can provide a sensorimotor evaluation of presence. For example, it is possible to investigate the behavior which involves bending one’s head forward while walking through either a virtual or real door whose height is variable. Unlike the behavioral index studied here (“shoulder adjustment”) with males only, this new afforded action (“to lower one’s head”) could be equally assessed in both genders and thus would allow better generalization over the population.</p><p>As a conclusion, the present study behaviorally objectivates physical presence in VR by the way of an afforded action. In both the real and the virtual world, human navigation through apertures is expectedly co-determined by the individual body architecture characteristics and the spatial metrics of the aperture. As a behavioral assessment of physical presence in VR, the present research calls for additional investigations devoted to evaluate the psychometric validity of this kind of measurement.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Berlucchi, S. Aglioti, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Berlucchi G, Aglioti S (1997) The body in the brain: Neural bases of corporeal awareness. Trends Neurosci 20:5" /><p class="c-article-references__text" id="ref-CR1">Berlucchi G, Aglioti S (1997) The body in the brain: Neural bases of corporeal awareness. Trends Neurosci 20:560–564</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0166-2236%2897%2901136-3" aria-label="View reference 1">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20body%20in%20the%20brain%3A%20Neural%20bases%20of%20corporeal%20awareness&amp;journal=Trends%20Neurosci&amp;volume=20&amp;pages=560-564&amp;publication_year=1997&amp;author=Berlucchi%2CG&amp;author=Aglioti%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="A. Carassa, F. Morganti, M. Tirassa, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Carassa A, Morganti F, Tirassa M (2005) A situated cognition perspective on presence. In: Bara L, Barsalou LW," /><p class="c-article-references__text" id="ref-CR2">Carassa A, Morganti F, Tirassa M (2005) A situated cognition perspective on presence. In: Bara L, Barsalou LW, Bucciarelli M (eds) XXVII Annual conference of the cognitive science society. Sheridan Printing, Alpha (New Jersey), pp 384–389</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=XXVII%20Annual%20conference%20of%20the%20cognitive%20science%20society&amp;pages=384-389&amp;publication_year=2005&amp;author=Carassa%2CA&amp;author=Morganti%2CF&amp;author=Tirassa%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cruz-Neira C, Sandin DJ, DeFanti TA (1993) Surround-screen projection-based virtual reality: the design and im" /><p class="c-article-references__text" id="ref-CR3">Cruz-Neira C, Sandin DJ, DeFanti TA (1993) Surround-screen projection-based virtual reality: the design and implementation of the cave. Proceedings of the 20th annual conference on computer graphics and interactive techniques, New York, pp 135–142</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JM. Flach, JG. Holden, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Flach JM, Holden JG (1998) The reality of experience: Gibson’s way. Presence Teleoperators Virtual Environ 7(1" /><p class="c-article-references__text" id="ref-CR4">Flach JM, Holden JG (1998) The reality of experience: Gibson’s way. Presence Teleoperators Virtual Environ 7(1):90–95</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474698565550" aria-label="View reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20reality%20of%20experience%3A%20Gibson%E2%80%99s%20way&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=7&amp;issue=1&amp;pages=90-95&amp;publication_year=1998&amp;author=Flach%2CJM&amp;author=Holden%2CJG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Freeman, SE. Avons, R. Meddis, DE. Pearson, WA. Ijsselsteijn, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Freeman J, Avons SE, Meddis R, Pearson DE, Ijsselsteijn WA (2000) Using behavioural realism to estimate presen" /><p class="c-article-references__text" id="ref-CR5">Freeman J, Avons SE, Meddis R, Pearson DE, Ijsselsteijn WA (2000) Using behavioural realism to estimate presence: a study of the utility of postural responses to motion stimuli. Presence Teleoperators Virtual Environ 9(2):149–164</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474600566691" aria-label="View reference 5">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Using%20behavioural%20realism%20to%20estimate%20presence%3A%20a%20study%20of%20the%20utility%20of%20postural%20responses%20to%20motion%20stimuli&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=9&amp;issue=2&amp;pages=149-164&amp;publication_year=2000&amp;author=Freeman%2CJ&amp;author=Avons%2CSE&amp;author=Meddis%2CR&amp;author=Pearson%2CDE&amp;author=Ijsselsteijn%2CWA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="JJ. Gibson, " /><meta itemprop="datePublished" content="1979" /><meta itemprop="headline" content="Gibson JJ (1979) The ecological approach to visual perception. Houghton Mifflin, Boston" /><p class="c-article-references__text" id="ref-CR6">Gibson JJ (1979) The ecological approach to visual perception. Houghton Mifflin, Boston</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20ecological%20approach%20to%20visual%20perception&amp;publication_year=1979&amp;author=Gibson%2CJJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MS. Gordon, LD. Rosenblum, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Gordon MS, Rosenblum LD (2004) Perception of sound-obstructing surfaces using body-scaled judgments. Ecol Psyc" /><p class="c-article-references__text" id="ref-CR7">Gordon MS, Rosenblum LD (2004) Perception of sound-obstructing surfaces using body-scaled judgments. Ecol Psychol 16(2):87–113</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1207%2Fs15326969eco1602_1" aria-label="View reference 7">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Perception%20of%20sound-obstructing%20surfaces%20using%20body-scaled%20judgments&amp;journal=Ecol%20Psychol&amp;volume=16&amp;issue=2&amp;pages=87-113&amp;publication_year=2004&amp;author=Gordon%2CMS&amp;author=Rosenblum%2CLD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Hecht, M. Reiner, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Hecht D, Reiner M (2007) Field dependency and the sense of object presence in haptic virtual environments. Cyb" /><p class="c-article-references__text" id="ref-CR8">Hecht D, Reiner M (2007) Field dependency and the sense of object presence in haptic virtual environments. Cyber Psychol Behav 10:243–251</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Field%20dependency%20and%20the%20sense%20of%20object%20presence%20in%20haptic%20virtual%20environments&amp;journal=Cyber%20Psychol%20Behav&amp;volume=10&amp;pages=243-251&amp;publication_year=2007&amp;author=Hecht%2CD&amp;author=Reiner%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Higuchi, ME. Cinelli, MA. Greig, AE. Patla, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Higuchi T, Cinelli ME, Greig MA, Patla AE (2006) Locomotion through apertures when wider space for locomotion " /><p class="c-article-references__text" id="ref-CR9">Higuchi T, Cinelli ME, Greig MA, Patla AE (2006) Locomotion through apertures when wider space for locomotion is necessary to artificially altered bodily states. Exp Brain Res 175:50–59</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs00221-006-0525-4" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Locomotion%20through%20apertures%20when%20wider%20space%20for%20locomotion%20is%20necessary%20to%20artificially%20altered%20bodily%20states&amp;journal=Exp%20Brain%20Res&amp;volume=175&amp;pages=50-59&amp;publication_year=2006&amp;author=Higuchi%2CT&amp;author=Cinelli%2CME&amp;author=Greig%2CMA&amp;author=Patla%2CAE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="NP. Holmes, C. Spence, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Holmes NP, Spence C (2006) Beyond the body schema: visual, prosthetic, and technological contributions to bodi" /><p class="c-article-references__text" id="ref-CR10">Holmes NP, Spence C (2006) Beyond the body schema: visual, prosthetic, and technological contributions to bodily perception and awareness. In: Knoblich G, Thornton IM, Grosjean M, Shiffrar M (eds) Human body perception from the inside out. Oxford University Press, New York, pp 15–64</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20body%20perception%20from%20the%20inside%20out&amp;pages=15-64&amp;publication_year=2006&amp;author=Holmes%2CNP&amp;author=Spence%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="WA. Ijsselsteijn, H. Ridder, J. Freeman, SE. Avons, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Ijsselsteijn WA, de Ridder H, Freeman J, Avons SE (2000) Presence: concept, determinants and measurement. Proc" /><p class="c-article-references__text" id="ref-CR11">Ijsselsteijn WA, de Ridder H, Freeman J, Avons SE (2000) Presence: concept, determinants and measurement. Proc Soc Photo Opt Instrum Eng 3959:520–529</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Presence%3A%20concept%2C%20determinants%20and%20measurement&amp;journal=Proc%20Soc%20Photo%20Opt%20Instrum%20Eng&amp;volume=3959&amp;pages=520-529&amp;publication_year=2000&amp;author=Ijsselsteijn%2CWA&amp;author=Ridder%2CH&amp;author=Freeman%2CJ&amp;author=Avons%2CSE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="WA. Ijsselsteijn, H. Ridder, J. Freeman, SE. Avons, D. Bouwhuis, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Ijsselsteijn WA, de Ridder H, Freeman J, Avons SE, Bouwhuis D (2001) Effects of stereoscopic presentation, ima" /><p class="c-article-references__text" id="ref-CR12">Ijsselsteijn WA, de Ridder H, Freeman J, Avons SE, Bouwhuis D (2001) Effects of stereoscopic presentation, image motion, and screen size on subjective and objective corroborative measures of presence. Presence Teleoperators Virtual Environ 10(3):298–311</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474601300343621" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Effects%20of%20stereoscopic%20presentation%2C%20image%20motion%2C%20and%20screen%20size%20on%20subjective%20and%20objective%20corroborative%20measures%20of%20presence&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=10&amp;issue=3&amp;pages=298-311&amp;publication_year=2001&amp;author=Ijsselsteijn%2CWA&amp;author=Ridder%2CH&amp;author=Freeman%2CJ&amp;author=Avons%2CSE&amp;author=Bouwhuis%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="B. Insko, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Insko B (2003) Measuring presence: subjective, behavioral, and physiological methods. In: Riva G, Davide F, Ij" /><p class="c-article-references__text" id="ref-CR13">Insko B (2003) Measuring presence: subjective, behavioral, and physiological methods. In: Riva G, Davide F, Ijsselsteijn W (eds) Being there: concepts, effects and measurement of user presence in synthetic environments. IOS Press, Amsterdam, pp 109–119</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Being%20there%3A%20concepts%2C%20effects%20and%20measurement%20of%20user%20presence%20in%20synthetic%20environments&amp;pages=109-119&amp;publication_year=2003&amp;author=Insko%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="International Society for Presence Research (2008) The concept of presence: explication statement. Retrieved M" /><p class="c-article-references__text" id="ref-CR14">International Society for Presence Research (2008) The concept of presence: explication statement. Retrieved May 15, 2008 from <a href="http://www.temple.edu/ispr/frame_explicat.htm">http://www.temple.edu/ispr/frame_explicat.htm</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Ishak, KE. Adolph, GC. Lin, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Ishak S, Adolph KE, Lin GC (2008) Perceiving affordances for fitting through apertures. J Exp Psychol Human Pe" /><p class="c-article-references__text" id="ref-CR15">Ishak S, Adolph KE, Lin GC (2008) Perceiving affordances for fitting through apertures. J Exp Psychol Human Percept Perform 34(6):1501–1514</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2Fa0011393" aria-label="View reference 15">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Perceiving%20affordances%20for%20fitting%20through%20apertures&amp;journal=J%20Exp%20Psychol%20Human%20Percept%20Perform&amp;volume=34&amp;issue=6&amp;pages=1501-1514&amp;publication_year=2008&amp;author=Ishak%2CS&amp;author=Adolph%2CKE&amp;author=Lin%2CGC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lombard M, Ditton TB (1997) At the heart of it all: the concept of presence. J Comp Mediat Commun 3(2). Retrie" /><p class="c-article-references__text" id="ref-CR16">Lombard M, Ditton TB (1997) At the heart of it all: the concept of presence. J Comp Mediat Commun 3(2). Retrieved May 15, 2008 from <a href="http://jcmc.indiana.edu/vol3/issue2/lombard.html">http://jcmc.indiana.edu/vol3/issue2/lombard.html</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Lombard, MT. Jones, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Lombard M, Jones MT (2007a) Identifying the (tele) presence literature. Psychnology J 5(2):197–206" /><p class="c-article-references__text" id="ref-CR17">Lombard M, Jones MT (2007a) Identifying the (tele) presence literature. Psychnology J 5(2):197–206</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Identifying%20the%20%28tele%29%20presence%20literature&amp;journal=Psychnology%20J&amp;volume=5&amp;issue=2&amp;pages=197-206&amp;publication_year=2007&amp;author=Lombard%2CM&amp;author=Jones%2CMT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Lombard, MT. Jones, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Lombard M, Jones MT (2007b) Telepresence bibliography (n = 1, 834) as of May 2007. Addition to: Lombard M, Jon" /><p class="c-article-references__text" id="ref-CR18">Lombard M, Jones MT (2007b) Telepresence bibliography (n = 1, 834) as of May 2007. Addition to: Lombard M, Jones MT Identifying the (tele) presence literature. Psychnology J 5(2):197–206</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Telepresence%20bibliography%20%28n%C2%A0%3D%C2%A01%2C%20834%29%20as%20of%20May%202007.%20Addition%20to%3A%20Lombard%20M%2C%20Jones%20MT%20Identifying%20the%20%28tele%29%20presence%20literature&amp;journal=Psychnology%20J&amp;volume=5&amp;issue=2&amp;pages=197-206&amp;publication_year=2007&amp;author=Lombard%2CM&amp;author=Jones%2CMT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="F. Mars, L. Bringoux, C. Cian, PA. Barraud, C. Raphel, JL. Vercher, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Mars F, Bringoux L, Cian C, Barraud PA, Raphel C, Vercher JL (2005) Perception de la verticale avec un cadre v" /><p class="c-article-references__text" id="ref-CR19">Mars F, Bringoux L, Cian C, Barraud PA, Raphel C, Vercher JL (2005) Perception de la verticale avec un cadre visuel solidaire de la tête: implications pour l’utilisation des visiocasques. Trav Hum 68:125–152</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3917%2Fth.682.0125" aria-label="View reference 19">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Perception%20de%20la%20verticale%20avec%20un%20cadre%20visuel%20solidaire%20de%20la%20t%C3%AAte%3A%20implications%20pour%20l%E2%80%99utilisation%20des%20visiocasques&amp;journal=Trav%20Hum&amp;volume=68&amp;pages=125-152&amp;publication_year=2005&amp;author=Mars%2CF&amp;author=Bringoux%2CL&amp;author=Cian%2CC&amp;author=Barraud%2CPA&amp;author=Raphel%2CC&amp;author=Vercher%2CJL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="KR. Popper, " /><meta itemprop="datePublished" content="1959" /><meta itemprop="headline" content="Popper KR (1959) The logic of scientific discovery. Basic Books, New York" /><p class="c-article-references__text" id="ref-CR20">Popper KR (1959) The logic of scientific discovery. Basic Books, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20logic%20of%20scientific%20discovery&amp;publication_year=1959&amp;author=Popper%2CKR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Sas, G. O’Hare, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Sas C, O’Hare G (2003) Presence equation: an investigation into cognitive factors underlying presence. Presenc" /><p class="c-article-references__text" id="ref-CR21">Sas C, O’Hare G (2003) Presence equation: an investigation into cognitive factors underlying presence. Presence Teleoperators Virtual Environ 12(5):523–537</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474603322761315" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Presence%20equation%3A%20an%20investigation%20into%20cognitive%20factors%20underlying%20presence&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=12&amp;issue=5&amp;pages=523-537&amp;publication_year=2003&amp;author=Sas%2CC&amp;author=O%E2%80%99Hare%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Schubert, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Schubert T (2009) A new conception of spatial presence: once again, with feeling. Commun Theory 19:161–187" /><p class="c-article-references__text" id="ref-CR22">Schubert T (2009) A new conception of spatial presence: once again, with feeling. Commun Theory 19:161–187</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fj.1468-2885.2009.01340.x" aria-label="View reference 22">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20new%20conception%20of%20spatial%20presence%3A%20once%20again%2C%20with%20feeling&amp;journal=Commun%20Theory&amp;volume=19&amp;pages=161-187&amp;publication_year=2009&amp;author=Schubert%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Slater, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Slater M (2002) Presence and the sixth sense. Presence Teleoperators Virtual Environ 11(4):435–439" /><p class="c-article-references__text" id="ref-CR23">Slater M (2002) Presence and the sixth sense. Presence Teleoperators Virtual Environ 11(4):435–439</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474602760204327" aria-label="View reference 23">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Presence%20and%20the%20sixth%20sense&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=11&amp;issue=4&amp;pages=435-439&amp;publication_year=2002&amp;author=Slater%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Stappers PJ, Flach JM, Voorhorst FA (1999) Critical ratio as behavioral indices of presence. Presented at the " /><p class="c-article-references__text" id="ref-CR24">Stappers PJ, Flach JM, Voorhorst FA (1999) Critical ratio as behavioral indices of presence. Presented at the second international workshop on presence, University of Essex, UK, April 6–7 1999. Retrieved November 11, 2008 <a href="http://www.temple.edu/ispr/prev_conferences/proceedings/98-99-2000/1999/Stappers,%20Flach%20and%20Voorhorst.pdf">http://www.temple.edu/ispr/prev_conferences/proceedings/98-99-2000/1999/Stappers,%20Flach%20and%20Voorhorst.pdf</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="DK. Tinsworth, JE. McDonald, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Tinsworth DK, McDonald JE (2001) Special study: Injuries and deaths associated with children’s playground equi" /><p class="c-article-references__text" id="ref-CR25">Tinsworth DK, McDonald JE (2001) Special study: Injuries and deaths associated with children’s playground equipment. Consumer Product Safety Commission, Washington, DC</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Special%20study%3A%20Injuries%20and%20deaths%20associated%20with%20children%E2%80%99s%20playground%20equipment&amp;publication_year=2001&amp;author=Tinsworth%2CDK&amp;author=McDonald%2CJE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="van Baren J, Ijsselsteijn WA (2004) Compendium of presence measures. Retrieved November 11, 2008. http://www.i" /><p class="c-article-references__text" id="ref-CR26">van Baren J, Ijsselsteijn WA (2004) Compendium of presence measures. Retrieved November 11, 2008. <a href="http://www.informatik.umu.se/~jwworth/PresenceMeasurement.pdf">http://www.informatik.umu.se/~jwworth/PresenceMeasurement.pdf</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="WH. Warren, S. Whang, " /><meta itemprop="datePublished" content="1987" /><meta itemprop="headline" content="Warren WH, Whang S (1987) Visual guidance of walking through apertures: Body-scaled information for affordance" /><p class="c-article-references__text" id="ref-CR27">Warren WH, Whang S (1987) Visual guidance of walking through apertures: Body-scaled information for affordances. J Exp Psychol Human Percept Perform 13(3):371–383</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2F0096-1523.13.3.371" aria-label="View reference 27">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20guidance%20of%20walking%20through%20apertures%3A%20Body-scaled%20information%20for%20affordances&amp;journal=J%20Exp%20Psychol%20Human%20Percept%20Perform&amp;volume=13&amp;issue=3&amp;pages=371-383&amp;publication_year=1987&amp;author=Warren%2CWH&amp;author=Whang%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="BK. Wiederhold, DP. Jang, M. Kaneda, I. Cabral, Y. Lurie, T. May, IY. Kim, MD. Wiederhold, SI. Kim, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Wiederhold BK, Jang DP, Kaneda M, Cabral I, Lurie Y, May T, Kim IY, Wiederhold MD, Kim SI (2001) An investigat" /><p class="c-article-references__text" id="ref-CR28">Wiederhold BK, Jang DP, Kaneda M, Cabral I, Lurie Y, May T, Kim IY, Wiederhold MD, Kim SI (2001) An investigation into physiological responses in virtual environments: an objective measurement of presence. In: Riva G, Galimberti C (eds) Towards cyber psychology: mind, cognitions and society in the Internet age. IOS Press, Amsterdam, pp 175–183</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Towards%20cyber%20psychology%3A%20mind%2C%20cognitions%20and%20society%20in%20the%20Internet%20age&amp;pages=175-183&amp;publication_year=2001&amp;author=Wiederhold%2CBK&amp;author=Jang%2CDP&amp;author=Kaneda%2CM&amp;author=Cabral%2CI&amp;author=Lurie%2CY&amp;author=May%2CT&amp;author=Kim%2CIY&amp;author=Wiederhold%2CMD&amp;author=Kim%2CSI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="W. Wirth, T. Hartmann, S. Böcking, P. Vorderer, C. Klimmt, H. Schramm, T. Saari, J. Laarni, N. Ravaja, F. Ribeiro Gouveia, F. Biocca, A. Sacau, L. Jäncke, T. Baumgartner, P. Jäncke, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Wirth W, Hartmann T, Böcking S, Vorderer P, Klimmt C, Schramm H, Saari T, Laarni J, Ravaja N, Ribeiro Gouveia " /><p class="c-article-references__text" id="ref-CR29">Wirth W, Hartmann T, Böcking S, Vorderer P, Klimmt C, Schramm H, Saari T, Laarni J, Ravaja N, Ribeiro Gouveia F, Biocca F, Sacau A, Jäncke L, Baumgartner T, Jäncke P (2007) A process model of the formation of spatial presence experiences. Media Psychol 9(3):493–525</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20process%20model%20of%20the%20formation%20of%20spatial%20presence%20experiences&amp;journal=Media%20Psychol&amp;volume=9&amp;issue=3&amp;pages=493-525&amp;publication_year=2007&amp;author=Wirth%2CW&amp;author=Hartmann%2CT&amp;author=B%C3%B6cking%2CS&amp;author=Vorderer%2CP&amp;author=Klimmt%2CC&amp;author=Schramm%2CH&amp;author=Saari%2CT&amp;author=Laarni%2CJ&amp;author=Ravaja%2CN&amp;author=Ribeiro%20Gouveia%2CF&amp;author=Biocca%2CF&amp;author=Sacau%2CA&amp;author=J%C3%A4ncke%2CL&amp;author=Baumgartner%2CT&amp;author=J%C3%A4ncke%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="BG. Witmer, MJ. Singer, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Witmer BG, Singer MJ (1998) Measuring presence in virtual environments: a presence questionnaire. Presence Tel" /><p class="c-article-references__text" id="ref-CR30">Witmer BG, Singer MJ (1998) Measuring presence in virtual environments: a presence questionnaire. Presence Teleoperators Virtual Environ 7(3):225–240</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474698565686" aria-label="View reference 30">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Measuring%20presence%20in%20virtual%20environments%3A%20a%20presence%20questionnaire&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=7&amp;issue=3&amp;pages=225-240&amp;publication_year=1998&amp;author=Witmer%2CBG&amp;author=Singer%2CMJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Zahorik, RL. Jenison, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Zahorik P, Jenison RL (1998) Presence as being-in-the-world. Presence Teleoperators Virtual Environ 7(1):78–89" /><p class="c-article-references__text" id="ref-CR31">Zahorik P, Jenison RL (1998) Presence as being-in-the-world. Presence Teleoperators Virtual Environ 7(1):78–89</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474698565541" aria-label="View reference 31">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Presence%20as%20being-in-the-world&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=7&amp;issue=1&amp;pages=78-89&amp;publication_year=1998&amp;author=Zahorik%2CP&amp;author=Jenison%2CRL">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-009-0118-1-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">UMR 6233 Institut des Sciences du Mouvement, CNRS, Université de la Méditerranée, 163 avenue de Luminy CP 910, 13288, Marseille Cedex 9, France</p><p class="c-article-author-affiliation__authors-list">Jean-Claude Lepecq, Lionel Bringoux, Jean-Marie Pergandi, Thelma Coyle &amp; Daniel Mestre</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Jean_Claude-Lepecq"><span class="c-article-authors-search__title u-h3 js-search-name">Jean-Claude Lepecq</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Jean-Claude+Lepecq&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jean-Claude+Lepecq" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jean-Claude+Lepecq%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Lionel-Bringoux"><span class="c-article-authors-search__title u-h3 js-search-name">Lionel Bringoux</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Lionel+Bringoux&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Lionel+Bringoux" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Lionel+Bringoux%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Jean_Marie-Pergandi"><span class="c-article-authors-search__title u-h3 js-search-name">Jean-Marie Pergandi</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Jean-Marie+Pergandi&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jean-Marie+Pergandi" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jean-Marie+Pergandi%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Thelma-Coyle"><span class="c-article-authors-search__title u-h3 js-search-name">Thelma Coyle</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Thelma+Coyle&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Thelma+Coyle" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Thelma+Coyle%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Daniel-Mestre"><span class="c-article-authors-search__title u-h3 js-search-name">Daniel Mestre</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Daniel+Mestre&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Daniel+Mestre" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Daniel+Mestre%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-009-0118-1/email/correspondent/c1/new">Jean-Claude Lepecq</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Afforded%20actions%20as%20a%20behavioral%20assessment%20of%20physical%20presence%20in%20virtual%20environments&amp;author=Jean-Claude%20Lepecq%20et%20al&amp;contentID=10.1007%2Fs10055-009-0118-1&amp;publication=1359-4338&amp;publicationDate=2009-05-28&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Lepecq, J., Bringoux, L., Pergandi, J. <i>et al.</i> Afforded actions as a behavioral assessment of physical presence in virtual environments.
                    <i>Virtual Reality</i> <b>13, </b>141–151 (2009). https://doi.org/10.1007/s10055-009-0118-1</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-009-0118-1.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2009-01-30">30 January 2009</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2009-05-07">07 May 2009</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2009-05-28">28 May 2009</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2009-09">September 2009</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-009-0118-1" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-009-0118-1</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Presence</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Behavior</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Affordance</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Virtual reality</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-009-0118-1.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=118;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

