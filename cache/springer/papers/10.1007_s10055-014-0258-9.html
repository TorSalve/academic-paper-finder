<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Virtual reality 360 interactive panorama reproduction obstacles and is"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="The research studies obstacles and issues for spherical panorama image reproduction. Virtual reality 360 interactive panorama presentation involves accurately reproduced spherical panorama images..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/19/2.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Virtual reality 360 interactive panorama reproduction obstacles and issues"/>

    <meta name="dc.source" content="Virtual Reality 2014 19:2"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2014-12-24"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2014 Springer-Verlag London"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="The research studies obstacles and issues for spherical panorama image reproduction. Virtual reality 360 interactive panorama presentation involves accurately reproduced spherical panorama images which can deliver pre-produced image information of the real-world location that allows user-controlled interactivity in virtual reality digital platforms with up to three hundred and sixty degrees of visibility. Spherical panorama image is also useful in various mixed and augmented reality applications. However, the photographic reproduction of spherical panorama image may tolerate various obstacles and issues that can cause visual abnormality. These can include parallax error, nadir angle difficulty, inconsistent white balance, insufficient dynamic range in multiple angle images, ghosting effect when working with high dynamic range imaging, high amount of multiple angle source images to manage correctly and overall lengthy acquisition time. Biased reproduction of spherical panorama would be inadequate to record and report authentic visual information. This case study investigation provides an overview of the occurrence of potential obstacles and issues with the intention of acquiring high-fidelity spherical panorama photographic reproduction."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2014-12-24"/>

    <meta name="prism.volume" content="19"/>

    <meta name="prism.number" content="2"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="71"/>

    <meta name="prism.endingPage" content="81"/>

    <meta name="prism.copyright" content="2014 Springer-Verlag London"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-014-0258-9"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-014-0258-9"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-014-0258-9.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-014-0258-9"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Virtual reality 360 interactive panorama reproduction obstacles and issues"/>

    <meta name="citation_volume" content="19"/>

    <meta name="citation_issue" content="2"/>

    <meta name="citation_publication_date" content="2015/06"/>

    <meta name="citation_online_date" content="2014/12/24"/>

    <meta name="citation_firstpage" content="71"/>

    <meta name="citation_lastpage" content="81"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-014-0258-9"/>

    <meta name="DOI" content="10.1007/s10055-014-0258-9"/>

    <meta name="citation_doi" content="10.1007/s10055-014-0258-9"/>

    <meta name="description" content="The research studies obstacles and issues for spherical panorama image reproduction. Virtual reality 360 interactive panorama presentation involves accurat"/>

    <meta name="dc.creator" content="Zi Siang See"/>

    <meta name="dc.creator" content="Adrian David Cheok"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="
Andrews P (2003) 360 Degree imaging: the photographer&#8217;s panoramic virtual reality manual. RotoVision. 
                    http://www.amazon.com/360-Degree-Imaging-Photographers-Photography/dp/2880467322
                    
                  
                "/>

    <meta name="citation_reference" content="Archos (2014) Archos VR glasses: jump into the mobile virtual reality world. 
                    http://www.archos.com/corporate/press/press_releases/US_Archos_VR_Glasses_PR_20141016.pdf
                    
                  . Accessed 25 Nov 2014"/>

    <meta name="citation_reference" content="Arth C, Klopschitz M, Reitmayr G, Schmalstieg D (2011) Real-time self-localization from panoramic images on mobile devices. 2011 10th IEEE International Symposium on Mixed and Augmented Reality"/>

    <meta name="citation_reference" content="citation_title=Panoramic vision: sensors, theory, and applications; citation_publication_date=2001; citation_id=CR4; citation_author=R Benosman; citation_author=SB Kang; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Comput Vis; citation_title=Automatic Panoramic Image Stitching using Invariant Features; citation_author=M Brown, DG Lowe; citation_volume=74; citation_issue=1; citation_publication_date=2007; citation_pages=59-73; citation_doi=10.1007/s11263-006-0002-3; citation_id=CR5"/>

    <meta name="citation_reference" content="Chen E (1995) Quicktime VR: an image-based approach to virtual environment navigation. In SIGGRAPH&#8217;95"/>

    <meta name="citation_reference" content="
Debevec PE, Malik J (1997) Recovering high dynamic range radiance maps from photographs. In: SIGGRAPH &#39;97: Proceedings of the 24th annual conference on Computer graphics and interactive techniques, pp 369&#8211;378. 
                    http://dl.acm.org/citation.cfm?id=258884
                    
                  
                "/>

    <meta name="citation_reference" content="citation_journal_title=Proc IEEE Virtual Real Conf; citation_title=Envisor: online environment map construction for mixed reality; citation_author=S DiVerdi, J Wither, T Hollerer; citation_volume=2008; citation_publication_date=2008; citation_pages=19-26; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Gr; citation_title=All Around the map: online spherical panorama construction; citation_author=S DiVerdi, J Wither, T H&#246;llerer; citation_volume=33; citation_issue=1; citation_publication_date=2009; citation_pages=73-84; citation_doi=10.1016/j.cag.2008.11.002; citation_id=CR9"/>

    <meta name="citation_reference" content="Felinto D, Zang AR, Velho L (2012) Production framework for full panoramic scenes with photorealistic augmented reality. XXXVIII Latin American Conference of Informatics (CLEI)"/>

    <meta name="citation_reference" content="Gardner R (2012) Digital tones and exposure zones. 2004, 
                    http://www.rags-int-inc.com/PhotoTechStuff/TonesnZones
                    
                  . Accessed 27 July 2012"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Gr; citation_title=Panoramic imaging&#8212;a review; citation_author=D Gledhill, GY Tian, D Taylor, D Clarke; citation_volume=27; citation_issue=3; citation_publication_date=2003; citation_pages=435-445; citation_doi=10.1016/S0097-8493(03)00038-4; citation_id=CR12"/>

    <meta name="citation_reference" content="Guan X-Y, Shark L-K, Hall G, Deng W (2009) Distortion correction for immersive navigation in spherical image environment. 2009 International Conference on CyberWorlds"/>

    <meta name="citation_reference" content="Imatest (2012) Imatest&#8212;using stepchart, 
                    http://www.imatest.com/docs/q13/#dynamic
                    
                  . Accessed 27 July 2012"/>

    <meta name="citation_reference" content="citation_title=Interactive panorama; citation_publication_date=2004; citation_id=CR15; citation_author=C Jacobs; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Pervasive Comput; citation_title=Online creation of panoramic augmented reality annotations on mobile phones; citation_author=T Langlotz, D Wagner, A Mulloni, D Schmalstieg; citation_volume=11; citation_issue=2; citation_publication_date=2012; citation_pages=56-63; citation_doi=10.1109/MPRV.2010.69; citation_id=CR16"/>

    <meta name="citation_reference" content="citation_journal_title=Proc IEEE; citation_title=Next-generation augmented reality browsers: rich, seamless, and adaptive; citation_author=T Langlotz, T Nguyen, D Schmalstieg, R Grasset; citation_volume=102; citation_issue=2; citation_publication_date=2014; citation_pages=155-169; citation_doi=10.1109/JPROC.2013.2294255; citation_id=CR17"/>

    <meta name="citation_reference" content="citation_title=The panorama; citation_publication_date=1997; citation_id=CR18; citation_author=S Oettermann; citation_publisher=MIT Press"/>

    <meta name="citation_reference" content="Ravine M (2012) Mars rover camera project manager explains 2MP camera choice. 
                    http://www.dpreview.com/news/2012/08/08/Curiosity-interview-with-Malin-Space-Science-Systems-Mike-Ravine
                    
                  . Accessed 11 August 2012"/>

    <meta name="citation_reference" content="Rehm L (2009) D3x In Depth Review, 2009, 
                    http://www.dpreview.com/reviews/nikond3x
                    
                  . Accessed 01 Dec 2010"/>

    <meta name="citation_reference" content="Reinhard E, Heidrich W, Debevec P, Pattanaik S, Ward G, Myszkowski K (2010) High dynamic range imaging: Acquisition, Display, and Image-based lighting, 2nd edn. Elsevier, Amsterdam. 
                    http://www.amazon.com/Dynamic-Range-Imaging-Second-Edition/dp/012374914X
                    
                  
                "/>

    <meta name="citation_reference" content="Samsung, Gear VR (2014) 
                    http://www.samsung.com/global/microsite/gearvr
                    
                  . Accessed 25 Nov 2014"/>

    <meta name="citation_reference" content="
Schmidt L, Baumgart U (2007) What&#8217;s the meaning of VR photography/VR panoramas? Art-documentation.com. Accessed 21 Aug 2012"/>

    <meta name="citation_reference" content="citation_title=The art of case research; citation_publication_date=1995; citation_id=CR24; citation_author=R Stake; citation_publisher=Sage"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=Structure and motion in urban environments using upright panoramas; citation_author=J Ventura, T H&#246;llerer; citation_volume=17; citation_issue=2; citation_publication_date=2013; citation_pages=147-156; citation_doi=10.1007/s10055-012-0208-3; citation_id=CR25"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Virtual Real Conf; citation_title=Real-time panoramic mapping and tracking on mobile phones; citation_author=D Wagner, A Mulloni, T Langlotz, D Schmalstieg; citation_volume=2010; citation_publication_date=2010; citation_pages=211-218; citation_id=CR26"/>

    <meta name="citation_reference" content="Warrington C (2007) Markerless Augmented Reality for Panoramic Sequences, MA Thesis submitted to Faculty of Engineering, University of Ottawa"/>

    <meta name="citation_reference" content="citation_title=Case study research: design and methods; citation_publication_date=1994; citation_id=CR28; citation_author=R Yin; citation_publisher=Sage"/>

    <meta name="citation_reference" content="Zang AR, Felinto D, Velho L (2012) Augmented reality using full panoramic captured scene light-depth maps. Siggraph Asia 2012"/>

    <meta name="citation_reference" content="Zeiss (2014) VR One. 
                    http://zeissvrone.tumblr.com
                    
                  . Accessed 25 Nov 2014"/>

    <meta name="citation_author" content="Zi Siang See"/>

    <meta name="citation_author_email" content="zisiang@reina.com.my"/>

    <meta name="citation_author_institution" content="Reina Imaging, Kuala Lumpur, Malaysia"/>

    <meta name="citation_author_institution" content="Universiti Tunku Abdul Rahman, Kuala Lumpur, Malaysia"/>

    <meta name="citation_author" content="Adrian David Cheok"/>

    <meta name="citation_author_email" content="adriancheok@mixedrealitylab.org"/>

    <meta name="citation_author_institution" content="City University London, London, UK"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-014-0258-9&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2015/06/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-014-0258-9"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Virtual reality 360 interactive panorama reproduction obstacles and issues"/>
        <meta property="og:description" content="The research studies obstacles and issues for spherical panorama image reproduction. Virtual reality 360 interactive panorama presentation involves accurately reproduced spherical panorama images which can deliver pre-produced image information of the real-world location that allows user-controlled interactivity in virtual reality digital platforms with up to three hundred and sixty degrees of visibility. Spherical panorama image is also useful in various mixed and augmented reality applications. However, the photographic reproduction of spherical panorama image may tolerate various obstacles and issues that can cause visual abnormality. These can include parallax error, nadir angle difficulty, inconsistent white balance, insufficient dynamic range in multiple angle images, ghosting effect when working with high dynamic range imaging, high amount of multiple angle source images to manage correctly and overall lengthy acquisition time. Biased reproduction of spherical panorama would be inadequate to record and report authentic visual information. This case study investigation provides an overview of the occurrence of potential obstacles and issues with the intention of acquiring high-fidelity spherical panorama photographic reproduction."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Virtual reality 360 interactive panorama reproduction obstacles and issues | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-014-0258-9","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Spherical panorama, High dynamic range imaging, Image reproduction, Virtual reality, Augmented reality","kwrd":["Spherical_panorama","High_dynamic_range_imaging","Image_reproduction","Virtual_reality","Augmented_reality"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-014-0258-9","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-014-0258-9","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=258;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-014-0258-9">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Virtual reality 360 interactive panorama reproduction obstacles and issues
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-014-0258-9.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-014-0258-9.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2014-12-24" itemprop="datePublished">24 December 2014</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Virtual reality 360 interactive panorama reproduction obstacles and issues</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Zi_Siang-See" data-author-popup="auth-Zi_Siang-See" data-corresp-id="c1">Zi Siang See<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Reina Imaging" /><meta itemprop="address" content="Reina Imaging, Kuala Lumpur, Malaysia" /></span><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Universiti Tunku Abdul Rahman" /><meta itemprop="address" content="grid.412261.2, 000000041798283X, Universiti Tunku Abdul Rahman, Kuala Lumpur, Malaysia" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Adrian_David-Cheok" data-author-popup="auth-Adrian_David-Cheok">Adrian David Cheok</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="City University London" /><meta itemprop="address" content="grid.28577.3f, 0000000123539090, City University London, London, UK" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 19</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">71</span>–<span itemprop="pageEnd">81</span>(<span data-test="article-publication-year">2015</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">1251 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">7 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-014-0258-9/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>The research studies obstacles and issues for spherical panorama image reproduction. Virtual reality 360 interactive panorama presentation involves accurately reproduced spherical panorama images which can deliver pre-produced image information of the real-world location that allows user-controlled interactivity in virtual reality digital platforms with up to three hundred and sixty degrees of visibility. Spherical panorama image is also useful in various mixed and augmented reality applications. However, the photographic reproduction of spherical panorama image may tolerate various obstacles and issues that can cause visual abnormality. These can include parallax error, nadir angle difficulty, inconsistent white balance, insufficient dynamic range in multiple angle images, ghosting effect when working with high dynamic range imaging, high amount of multiple angle source images to manage correctly and overall lengthy acquisition time. Biased reproduction of spherical panorama would be inadequate to record and report authentic visual information. This case study investigation provides an overview of the occurrence of potential obstacles and issues with the intention of acquiring high-fidelity spherical panorama photographic reproduction.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>There are virtual reality 360 (VR360) interactive panorama image presentations or augmented reality applications that must rely on accurately reproduced spherical panorama image or source content with least visual abnormality. Spherical panorama with panoramic photographic technique has been discussed and explored by various studies (Jacobs <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Jacobs C (2004) Interactive panorama. Springer, Heidelberg" href="/article/10.1007/s10055-014-0258-9#ref-CR15" id="ref-link-section-d14675e335">2004</a>; Arth et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Arth C, Klopschitz M, Reitmayr G, Schmalstieg D (2011) Real-time self-localization from panoramic images on mobile devices. 2011 10th IEEE International Symposium on Mixed and Augmented Reality" href="/article/10.1007/s10055-014-0258-9#ref-CR3" id="ref-link-section-d14675e338">2011</a>; Andrews <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="&#xA;Andrews P (2003) 360 Degree imaging: the photographer’s panoramic virtual reality manual. RotoVision. &#xA;                    http://www.amazon.com/360-Degree-Imaging-Photographers-Photography/dp/2880467322&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-014-0258-9#ref-CR1" id="ref-link-section-d14675e341">2003</a>; Felinto et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Felinto D, Zang AR, Velho L (2012) Production framework for full panoramic scenes with photorealistic augmented reality. XXXVIII Latin American Conference of Informatics (CLEI)" href="/article/10.1007/s10055-014-0258-9#ref-CR10" id="ref-link-section-d14675e344">2012</a>; Brown and Lowe <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Brown M, Lowe DG (2007) Automatic Panoramic Image Stitching using Invariant Features. Int J Comput Vis 74(1):59–73" href="/article/10.1007/s10055-014-0258-9#ref-CR5" id="ref-link-section-d14675e347">2007</a>; DiVerdi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="DiVerdi S, Wither J, Höllerer T (2009) All Around the map: online spherical panorama construction. Comput Gr 33(1):73–84" href="/article/10.1007/s10055-014-0258-9#ref-CR9" id="ref-link-section-d14675e351">2009</a>; Gledhill et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Gledhill D, Tian GY, Taylor D, Clarke D (2003) Panoramic imaging—a review. Comput Gr 27(3):435–445" href="/article/10.1007/s10055-014-0258-9#ref-CR12" id="ref-link-section-d14675e354">2003</a>), usually involving omnidirectional camera setup or with multiple angle image acquisition for constructing a high-resolution panoramic imagery. Interactive user-controlled spherical panorama has been possible in the example of QuickTime Virtual Reality (Chen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Chen E (1995) Quicktime VR: an image-based approach to virtual environment navigation. In SIGGRAPH’95" href="/article/10.1007/s10055-014-0258-9#ref-CR6" id="ref-link-section-d14675e357">1995</a>) or various interactive panorama applications (Jacobs <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Jacobs C (2004) Interactive panorama. Springer, Heidelberg" href="/article/10.1007/s10055-014-0258-9#ref-CR15" id="ref-link-section-d14675e360">2004</a>). The basic aim of a panorama is to reproduce the real world so skillfully that spectators could believe what they are seeing as genuine (Oettermann <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Oettermann S (1997) The panorama. MIT Press, Cambridge" href="/article/10.1007/s10055-014-0258-9#ref-CR18" id="ref-link-section-d14675e363">1997</a>); in fact, high-fidelity reproduction is the key focus. Panoramic image can serve many functions including the main purpose of reproducing the visual elements of real-world scene (Benosman and Kang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Benosman R, Kang SB (2001) Panoramic vision: sensors, theory, and applications. Springer, Heidelberg" href="/article/10.1007/s10055-014-0258-9#ref-CR4" id="ref-link-section-d14675e366">2001</a>; Guan et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Guan X-Y, Shark L-K, Hall G, Deng W (2009) Distortion correction for immersive navigation in spherical image environment. 2009 International Conference on CyberWorlds" href="/article/10.1007/s10055-014-0258-9#ref-CR13" id="ref-link-section-d14675e370">2009</a>). Such an utilization example can be seen in the technical usage for Mars Rover Curiosity (Ravine <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Ravine M (2012) Mars rover camera project manager explains 2MP camera choice. &#xA;                    http://www.dpreview.com/news/2012/08/08/Curiosity-interview-with-Malin-Space-Science-Systems-Mike-Ravine&#xA;                    &#xA;                  . Accessed 11 August 2012" href="/article/10.1007/s10055-014-0258-9#ref-CR19" id="ref-link-section-d14675e373">2012</a>) for archiving panorama images using multi-shot method. Imaging variables during the image reproduction process of spherical panorama can potentially tolerate various obstacles and issues that lead to undesirable visual abnormality. As a result, it is difficult to reproduce spherical panorama reproduction that is completely free from imaging errors. Augmented reality applications that require to work with spherical panorama source content is speculated to operate correctly only in conditions of having accurately reproduced imagery content (Warrington <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Warrington C (2007) Markerless Augmented Reality for Panoramic Sequences, MA Thesis submitted to Faculty of Engineering, University of Ottawa" href="/article/10.1007/s10055-014-0258-9#ref-CR27" id="ref-link-section-d14675e376">2007</a>; Arth et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Arth C, Klopschitz M, Reitmayr G, Schmalstieg D (2011) Real-time self-localization from panoramic images on mobile devices. 2011 10th IEEE International Symposium on Mixed and Augmented Reality" href="/article/10.1007/s10055-014-0258-9#ref-CR3" id="ref-link-section-d14675e379">2011</a>; Ventura <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Ventura J, Höllerer T (2013) Structure and motion in urban environments using upright panoramas. Virtual Real 17(2):147–156" href="/article/10.1007/s10055-014-0258-9#ref-CR25" id="ref-link-section-d14675e382">2013</a>; Felinto et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Felinto D, Zang AR, Velho L (2012) Production framework for full panoramic scenes with photorealistic augmented reality. XXXVIII Latin American Conference of Informatics (CLEI)" href="/article/10.1007/s10055-014-0258-9#ref-CR10" id="ref-link-section-d14675e385">2012</a>; Langlotz et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Langlotz T, Wagner D, Mulloni A, Schmalstieg D (2012) Online creation of panoramic augmented reality annotations on mobile phones. IEEE Pervasive Comput 11(2):56–63" href="/article/10.1007/s10055-014-0258-9#ref-CR16" id="ref-link-section-d14675e389">2012</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Langlotz T, Nguyen T, Schmalstieg D, Grasset R (2014) Next-generation augmented reality browsers: rich, seamless, and adaptive. Proc IEEE 102(2):155–169" href="/article/10.1007/s10055-014-0258-9#ref-CR17" id="ref-link-section-d14675e392">2014</a>).</p><p>Parallax error can happen in spherical panorama photographic image reproduction (Diverdi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="DiVerdi S, Wither J, Höllerer T (2009) All Around the map: online spherical panorama construction. Comput Gr 33(1):73–84" href="/article/10.1007/s10055-014-0258-9#ref-CR9" id="ref-link-section-d14675e398">2009</a>; Andrews <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="&#xA;Andrews P (2003) 360 Degree imaging: the photographer’s panoramic virtual reality manual. RotoVision. &#xA;                    http://www.amazon.com/360-Degree-Imaging-Photographers-Photography/dp/2880467322&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-014-0258-9#ref-CR1" id="ref-link-section-d14675e401">2003</a>) when working with more than two images to be combined or stitched together, in order to produce the expanded viewing coverage in the image. Parallax error can be introduced when two source photographic images are acquired from an inconsistent viewpoint. This can result in the foreground and background of the main subjects in the multiple images to have slight changes in viewing perspective (Brown and Lowe <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Brown M, Lowe DG (2007) Automatic Panoramic Image Stitching using Invariant Features. Int J Comput Vis 74(1):59–73" href="/article/10.1007/s10055-014-0258-9#ref-CR5" id="ref-link-section-d14675e404">2007</a>). Such a parallax error that has slight differences in the viewing perspective would disallow multiple images to be combined correctly; therefore, usually visual elements in the photographed multiple angle images may be forced to compromise with certain levels of unwanted parallax error.</p><p>Nadir angle in multi-row configuration (Felinto et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Felinto D, Zang AR, Velho L (2012) Production framework for full panoramic scenes with photorealistic augmented reality. XXXVIII Latin American Conference of Informatics (CLEI)" href="/article/10.1007/s10055-014-0258-9#ref-CR10" id="ref-link-section-d14675e410">2012</a>; Jacobs  <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Jacobs C (2004) Interactive panorama. Springer, Heidelberg" href="/article/10.1007/s10055-014-0258-9#ref-CR15" id="ref-link-section-d14675e413">2004</a>) is where the nadir angle is difficult to be acquired correctly during the photographic process. Industrial convention configurations such as the spherical panorama photographic tripod head generically allow photography users to reproduce multiple angle images from the horizontal plane with acceptable precision control (Gledhill et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Gledhill D, Tian GY, Taylor D, Clarke D (2003) Panoramic imaging—a review. Comput Gr 27(3):435–445" href="/article/10.1007/s10055-014-0258-9#ref-CR12" id="ref-link-section-d14675e416">2003</a>; Schmidt and Baumgart <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="&#xA;Schmidt L, Baumgart U (2007) What’s the meaning of VR photography/VR panoramas? Art-documentation.com. Accessed 21 Aug 2012" href="/article/10.1007/s10055-014-0258-9#ref-CR23" id="ref-link-section-d14675e419">2007</a>); however, it usually does not allow acquiring the nadir angle image due to the obstacle of the equipment that has blocked the nadir viewing perspective.</p><p>Dynamic range in photographic image reproduction refers to the capability of reproducing visual luminance from the real-world scene (Debevec and Malik <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="&#xA;Debevec PE, Malik J (1997) Recovering high dynamic range radiance maps from photographs. In: SIGGRAPH '97: Proceedings of the 24th annual conference on Computer graphics and interactive techniques, pp 369–378. &#xA;                    http://dl.acm.org/citation.cfm?id=258884&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-014-0258-9#ref-CR7" id="ref-link-section-d14675e425">1997</a>). Usually shadow and highlight luminosity may exceed the recording capability of the film negative or digital sensor in camera. High dynamic range imaging (HDRI) method of combining multiple exposures can be useful for the reproduction of spherical panorama image (Reinhard et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Reinhard E, Heidrich W, Debevec P, Pattanaik S, Ward G, Myszkowski K (2010) High dynamic range imaging: Acquisition, Display, and Image-based lighting, 2nd edn. Elsevier, Amsterdam. &#xA;                    http://www.amazon.com/Dynamic-Range-Imaging-Second-Edition/dp/012374914X&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-014-0258-9#ref-CR21" id="ref-link-section-d14675e428">2010</a>; Felinto et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Felinto D, Zang AR, Velho L (2012) Production framework for full panoramic scenes with photorealistic augmented reality. XXXVIII Latin American Conference of Informatics (CLEI)" href="/article/10.1007/s10055-014-0258-9#ref-CR10" id="ref-link-section-d14675e431">2012</a>; Brown and Lowe <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Brown M, Lowe DG (2007) Automatic Panoramic Image Stitching using Invariant Features. Int J Comput Vis 74(1):59–73" href="/article/10.1007/s10055-014-0258-9#ref-CR5" id="ref-link-section-d14675e434">2007</a>). However, HDRI is prone to introducing various associated obstacles and issues including ghosting error, inconsistent white balance and differently rendered HDRI appearance in multiple angle images.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Real-world acquisition</h2><div class="c-article-section__content" id="Sec2-content"><p>Multiple angle images to be combined into a panorama image reproduction for having expanded view (Chen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Chen E (1995) Quicktime VR: an image-based approach to virtual environment navigation. In SIGGRAPH’95" href="/article/10.1007/s10055-014-0258-9#ref-CR6" id="ref-link-section-d14675e445">1995</a>; Jacobs <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Jacobs C (2004) Interactive panorama. Springer, Heidelberg" href="/article/10.1007/s10055-014-0258-9#ref-CR15" id="ref-link-section-d14675e448">2004</a>; Gledhill et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Gledhill D, Tian GY, Taylor D, Clarke D (2003) Panoramic imaging—a review. Comput Gr 27(3):435–445" href="/article/10.1007/s10055-014-0258-9#ref-CR12" id="ref-link-section-d14675e451">2003</a>; Diverdi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="DiVerdi S, Wither J, Höllerer T (2009) All Around the map: online spherical panorama construction. Comput Gr 33(1):73–84" href="/article/10.1007/s10055-014-0258-9#ref-CR9" id="ref-link-section-d14675e454">2009</a>; Felinto et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Felinto D, Zang AR, Velho L (2012) Production framework for full panoramic scenes with photorealistic augmented reality. XXXVIII Latin American Conference of Informatics (CLEI)" href="/article/10.1007/s10055-014-0258-9#ref-CR10" id="ref-link-section-d14675e457">2012</a>; Brown and Lowe <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Brown M, Lowe DG (2007) Automatic Panoramic Image Stitching using Invariant Features. Int J Comput Vis 74(1):59–73" href="/article/10.1007/s10055-014-0258-9#ref-CR5" id="ref-link-section-d14675e461">2007</a>; Schmidt and Baumgart <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="&#xA;Schmidt L, Baumgart U (2007) What’s the meaning of VR photography/VR panoramas? Art-documentation.com. Accessed 21 Aug 2012" href="/article/10.1007/s10055-014-0258-9#ref-CR23" id="ref-link-section-d14675e464">2007</a>) are also known as multi-shot or multi-row configuration; usually, high-precision handling is mandatory to maximize the accuracy of visual information reproduced. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig1">1</a> shows a generic process of multi-row configuration to cover zenith, horizontal and nadir angles.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Generic multi-row process for combining multiple angle photographic images</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>
This case study investigates how imaging variables caused by obstacles and issues can happen during the spherical panorama image reproduction process, and then provides an overview assessment that is useful for current and future research studies that have the intention to overcome these difficulties from the photographic reproduction perspective. Case studies allow the observation to look into the complex cause and effect (Stake <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Stake R (1995) The art of case research. Sage, Thousand Oaks" href="/article/10.1007/s10055-014-0258-9#ref-CR24" id="ref-link-section-d14675e491">1995</a>; Yin <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Yin R (1994) Case study research: design and methods, 2nd edn. Sage, Beverly Hills" href="/article/10.1007/s10055-014-0258-9#ref-CR28" id="ref-link-section-d14675e494">1994</a>) of the potential obstacles and issues. There has been extensive research that triggers high interest on HDRI (Reinhard et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Reinhard E, Heidrich W, Debevec P, Pattanaik S, Ward G, Myszkowski K (2010) High dynamic range imaging: Acquisition, Display, and Image-based lighting, 2nd edn. Elsevier, Amsterdam. &#xA;                    http://www.amazon.com/Dynamic-Range-Imaging-Second-Edition/dp/012374914X&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-014-0258-9#ref-CR21" id="ref-link-section-d14675e497">2010</a>; Debevec and Malik <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="&#xA;Debevec PE, Malik J (1997) Recovering high dynamic range radiance maps from photographs. In: SIGGRAPH '97: Proceedings of the 24th annual conference on Computer graphics and interactive techniques, pp 369–378. &#xA;                    http://dl.acm.org/citation.cfm?id=258884&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-014-0258-9#ref-CR7" id="ref-link-section-d14675e500">1997</a>) and panoramic vision (Benosman and Kang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Benosman R, Kang SB (2001) Panoramic vision: sensors, theory, and applications. Springer, Heidelberg" href="/article/10.1007/s10055-014-0258-9#ref-CR4" id="ref-link-section-d14675e503">2001</a>).</p><p>This study has the intention of providing insightful field acquisition scenario for current and future studies that focus on the following interests:</p><ul class="u-list-style-bullet">
                  <li>
                    <p>Spherical panorama study that requires working with HDRI.</p>
                  </li>
                  <li>
                    <p>HDRI study that attempts to have high compatibility that matches with spherical panorama reproduction process.</p>
                  </li>
                  <li>
                    <p>Augmented reality (AR) using high-fidelity spherical panorama.</p>
                  </li>
                </ul>
              <p>The field acquisition is conducted with Nikon-manufactured D3x attached with a 16-mm full-frame fisheye lens. The equipment is being configured on Manfrotto 303SPH for acquiring multiple angle images as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig2">2</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Field test that utilizes multi-row configuration</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig3">3</a> shows an example of spherical panorama reproduction for VR360 interactive panorama for having digital image projection viewing on a multimedia mobile device. This sampling example, however, demonstrates parallax error and stitching error that can result in incapability to suggest accurate representation of the original real-world scene.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig3_HTML.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig3_HTML.jpg" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Inaccurately reproduced spherical panorama used on interactive panorama digital image projection</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <h3 class="c-article__sub-heading" id="Sec3">Spherical panorama image reproduction and observation</h3><p>Real-world acquisition of spherical panorama image reproduction has been conducted to identify the major obstacles and issues. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig4">4</a> is a spherical panorama imaging sampling of location “FOM Entrance” reproduced from eight image sequences. The multiple angle image sequences have been produced with conventional single exposure which is also known as low dynamic range (LDR) image. Observation has shown that the sampling of this spherical panorama contains parallax error due to less precisely calibrated multi-row configuration as demonstrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig5">5</a>a. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig5">5</a>b magnifies nadir angle difficulty where the equipment situated at the bottom direction of the configuration has been captured. This leads to an undesirable visual occlusion in the location-based photographic reproduction.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig4_HTML.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig4_HTML.jpg" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Spherical panorama image reproduction that contains several identical obstacles and issues</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>
                          <b>a</b> Parallax error. <b>b</b> Nadir angle difficulty</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Parallax error, nadir angle difficulty and insufficient dynamic range can be observed in the spherical panorama reproduction in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig4">4</a>. As a consequence of these obstacles and issues, the entire representation of the spherical panorama reproduction is incapable of delivering adequate visual information of the location-based real-world scene.</p><p>Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig6">6</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig7">7</a> from “Interpass Walkway” are the spherical panorama reproductions that have nadir angle difficulty. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig6">6</a>a demonstrates the situation where equipment is visible at the nadir angle of the image, as observed with the cubic projection in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig6">6</a>b. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig7">7</a>a has been reproduced with extra nadir angle image to capture the nadir facade, but parallax error can be observed at the nadir angle during the post-processing outcome that contains geometrical bias in visual, as observed in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig7">7</a>b cubic projection.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig6_HTML.jpg?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig6_HTML.jpg" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>
                          <b>a</b> Spherical panorama where equipment is visible at nadir angle. <b>b</b> Cubic projection observation</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig7_HTML.jpg?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig7_HTML.jpg" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>
                          <b>a</b> Spherical panorama nadir angle with parallax error. <b>b</b> Cubic projection observation</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Nadir angle has been found to be one of the angles that can be difficult for spherical panorama reproduction (Felinto et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Felinto D, Zang AR, Velho L (2012) Production framework for full panoramic scenes with photorealistic augmented reality. XXXVIII Latin American Conference of Informatics (CLEI)" href="/article/10.1007/s10055-014-0258-9#ref-CR10" id="ref-link-section-d14675e716">2012</a>; Jacobs <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Jacobs C (2004) Interactive panorama. Springer, Heidelberg" href="/article/10.1007/s10055-014-0258-9#ref-CR15" id="ref-link-section-d14675e719">2004</a>). During the acquisition process, there are several factors being observed that can cause nadir angle difficulty in spherical panorama reproduction. Equipment such as the tripod or multi-row mounting situated at the bottom of the configuration will easily be captured in the multiple angle acquisition. In order to avoid the visibility of the equipment situated at the nadir of the configuration, additional image can be acquired from the original source of real-world scene. The intended extra nadir angle image has to be acquired with a stable configuration, and it must accurately match the calibration of horizontal angles in order to provide a completeness of three hundred and sixty degrees post-processing stitching correctness. Accurately reproduced spherical panorama without parallax error and sufficient dynamic range that can have adequate representation of the real-world scene is vital for providing authentic visual information for location-based documentation. Accurately reproduced visual information can satisfy the needs in cultural heritage preservation, architectural subject reproduction and scientific recording.</p><h3 class="c-article__sub-heading" id="Sec4">Dynamic range observation</h3><p>This section provides assessment of dynamic range in spherical panorama production process. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig8">8</a> shows a simplified scenario observation of histogram pattern from low-key to high-key source of multiple exposures and the result of HDRI reproduced with middle-key histogram outcome. Usually, the darker images with shadow may demonstrate a low-key histogram and the brighter images with highlight may demonstrate a high-key histogram. Tone mapping reproduction, such as the industrial convention Photomatix Pro used in the sampling example of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig8">8</a>, would attempt to merge all sources of multiple exposure images into a HDRI reproduction with middle-key histogram. Fusing the multiple exposures into a HDRI that can maintain a middle-key histogram has the purpose of preserving the global or local tone reproduction in terms of extended luminance; however, it will be crucial to inspect whether the entire set of multiple angle HDRI images with middle-key histogram would be appropriate for usage in spherical panorama reproduction.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig8_HTML.gif?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig8_HTML.gif" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Observation of histogram pattern from low-key to high-key source of multiple exposures and the result of HDRI reproduced with middle-key histogram outcome</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig9">9</a> is spherical panorama reproduction sampling from “Putrajaya PM Office.” The multiple angle images were reproduced with HDRI. Each HDRI image angle has been reproduced from nine multiple exposures with one EV stop of increment from the shadow to highlight coverage. It is aimed to capture wider dynamic range in terms of extended luminance. HDRI is required when the lighting conditions at the real-world scene contains high contrast luminance, usually unable to be recorded by the single-exposure photographic process, when using typical industry convention camera. For photographic image documentation, the analog film image recording method exhibits limited amount of imagery information due to the limitations of resolution and dynamic range (Reinhard et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Reinhard E, Heidrich W, Debevec P, Pattanaik S, Ward G, Myszkowski K (2010) High dynamic range imaging: Acquisition, Display, and Image-based lighting, 2nd edn. Elsevier, Amsterdam. &#xA;                    http://www.amazon.com/Dynamic-Range-Imaging-Second-Edition/dp/012374914X&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-014-0258-9#ref-CR21" id="ref-link-section-d14675e760">2010</a>); with digital imaging method by combining multiple exposures into HDRI, it can result in an increased, recorded and presented dynamic range in image. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig10">10</a> shows eight angles of HDRI including the nadir and zenith acquired from the location-based real-world scene with histogram analyzed. Each angle of HDRI local reproduction during post-processing has attempted to merge the multiple exposures into a single HDRI based on what is the maximum pixel value that can be preserved for luminance. This process attempts to fuse the multiple exposures into a middle-key tonal reproduction as observed in the histograms for each image angle shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig10">10</a>. This can produce a result of inconsistent luminance reproduction in multiple angles when using HDRI for spherical panorama.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig9_HTML.jpg?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig9_HTML.jpg" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Multiple angle images were reproduced with high dynamic range imaging (HDRI)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig10_HTML.jpg?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig10_HTML.jpg" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Inconsistent luminance reproduction in multiple angles using HDRI</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Dynamic range for image reproduction is crucial for defining the level of visual information that can be preserved in terms of luminance from shadow to highlight. Observing exposure range in photographic image reproduction is vital (Reinhard et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Reinhard E, Heidrich W, Debevec P, Pattanaik S, Ward G, Myszkowski K (2010) High dynamic range imaging: Acquisition, Display, and Image-based lighting, 2nd edn. Elsevier, Amsterdam. &#xA;                    http://www.amazon.com/Dynamic-Range-Imaging-Second-Edition/dp/012374914X&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-014-0258-9#ref-CR21" id="ref-link-section-d14675e809">2010</a>; Imatest <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Imatest (2012) Imatest—using stepchart, &#xA;                    http://www.imatest.com/docs/q13/#dynamic&#xA;                    &#xA;                  . Accessed 27 July 2012" href="/article/10.1007/s10055-014-0258-9#ref-CR14" id="ref-link-section-d14675e812">2012</a>; Gardner <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Gardner R (2012) Digital tones and exposure zones. 2004, &#xA;                    http://www.rags-int-inc.com/PhotoTechStuff/TonesnZones&#xA;                    &#xA;                  . Accessed 27 July 2012" href="/article/10.1007/s10055-014-0258-9#ref-CR11" id="ref-link-section-d14675e815">2012</a>; Rehm <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Rehm L (2009) D3x In Depth Review, 2009, &#xA;                    http://www.dpreview.com/reviews/nikond3x&#xA;                    &#xA;                  . Accessed 01 Dec 2010" href="/article/10.1007/s10055-014-0258-9#ref-CR20" id="ref-link-section-d14675e818">2009</a>) to understand the amount of luminance information which would be preserved. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig11">11</a>a–c is the inspection process of the acquired 18 image sequences sampling of Gretagmacbeth colorchecker chart, having the subject as images, which were acquired in laboratory environment with fixed source of lighting. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-014-0258-9#Tab1">1</a> shows the digital negative RAW processors being used for the test. The 18 image sequences were acquired from darker to brighter exposures for identifying the pixel values of Neutral 5 patch from the Gretagmacbeth colorchecker chart in a laboratory environment as indicated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig11">11</a>a–c, forming an observation of pixel value as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig12">12</a>a–c as supported by Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-014-0258-9#Tab2">2</a> for the tested RAW processors.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig11_HTML.gif?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig11_HTML.gif" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Inspection of the acquired 18 image sequences sampling of Gretagmacbeth colorchecker chart</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Digital negative RAW processors being used for the test</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-014-0258-9/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig12_HTML.gif?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig12_HTML.gif" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Pixel value of the acquired image sequences sampling of Gretagmacbeth colorchecker chart</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Pixel value of image sequences tested by different RAW processors</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-014-0258-9/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig13">13</a> shows pixel value information is being sampled from the Neutral 5 patch of each image from the 18 sequences acquired as demonstrated in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig11">11</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig12">12</a>. The same set of image sequences are being processed and tested with three different RAW processors and indicated in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-014-0258-9#Tab2">2</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-13"><figure><figcaption><b id="Fig13" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 13</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/13" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig13_HTML.jpg?as=webp"></source><img aria-describedby="figure-13-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig13_HTML.jpg" alt="figure13" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-13-desc"><p>Pixel value information is being sampled from the Neutral 5 patch of each image from the 18 sequences acquired</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/13" data-track-dest="link:Figure13 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>The dynamic range observation has demonstrated that similar source images acquired may produce dissimilar pixel value outcomes as seen in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig11">11</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig12">12</a>. Overall exposure range is approximately 8.5EV produced from the camera configuration in this study, indicating that this would be the approximated exposure range that can be preserved and presented in the multiple angle image acquisition required by spherical panorama reproduction, when working with source images of LDR. Therefore, should the situation require dynamic range greater than the capability of the photographic equipment used, HDRI technique is recommended for spherical panorama reproduction. It can be assumed that a specific solution would be needed for having consistent luminance reproduction across multiple angles required by spherical panorama multi-row process.</p></div></div></section><section aria-labelledby="Sec5"><div class="c-article-section" id="Sec5-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec5">Discussion</h2><div class="c-article-section__content" id="Sec5-content"><p>Several augmented research studies have been relying on using panorama image as source tracking content (Warrington <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Warrington C (2007) Markerless Augmented Reality for Panoramic Sequences, MA Thesis submitted to Faculty of Engineering, University of Ottawa" href="/article/10.1007/s10055-014-0258-9#ref-CR27" id="ref-link-section-d14675e1523">2007</a>; Arth et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Arth C, Klopschitz M, Reitmayr G, Schmalstieg D (2011) Real-time self-localization from panoramic images on mobile devices. 2011 10th IEEE International Symposium on Mixed and Augmented Reality" href="/article/10.1007/s10055-014-0258-9#ref-CR3" id="ref-link-section-d14675e1526">2011</a>; Ventura and Höllerer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Ventura J, Höllerer T (2013) Structure and motion in urban environments using upright panoramas. Virtual Real 17(2):147–156" href="/article/10.1007/s10055-014-0258-9#ref-CR25" id="ref-link-section-d14675e1529">2013</a>; DiVerdi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="DiVerdi S, Wither J, Hollerer T (2008) Envisor: online environment map construction for mixed reality. Proc IEEE Virtual Real Conf 2008:19–26" href="/article/10.1007/s10055-014-0258-9#ref-CR8" id="ref-link-section-d14675e1532">2008</a>; Wagner et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Wagner D, Mulloni A, Langlotz T, Schmalstieg D (2010) Real-time panoramic mapping and tracking on mobile phones. IEEE Virtual Real Conf 2010:211–218" href="/article/10.1007/s10055-014-0258-9#ref-CR26" id="ref-link-section-d14675e1535">2010</a>; Langlotz et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Langlotz T, Wagner D, Mulloni A, Schmalstieg D (2012) Online creation of panoramic augmented reality annotations on mobile phones. IEEE Pervasive Comput 11(2):56–63" href="/article/10.1007/s10055-014-0258-9#ref-CR16" id="ref-link-section-d14675e1539">2012</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Langlotz T, Nguyen T, Schmalstieg D, Grasset R (2014) Next-generation augmented reality browsers: rich, seamless, and adaptive. Proc IEEE 102(2):155–169" href="/article/10.1007/s10055-014-0258-9#ref-CR17" id="ref-link-section-d14675e1542">2014</a>; Zang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Zang AR, Felinto D, Velho L (2012) Augmented reality using full panoramic captured scene light-depth maps. Siggraph Asia 2012" href="/article/10.1007/s10055-014-0258-9#ref-CR29" id="ref-link-section-d14675e1545">2012</a>); however, obstacles and issues that have resulted in inaccurately reproduced panorama images can lead to ineffectively augmented and virtual reality applications. For instance, a panorama image reproduced from an actual location-based scene can be used for AR image-based tracking of the original real-world scene in real-time order. Authenticity of visual information from the source of panorama image reproduction is mandatory in providing virtual reality user experience with a sense of realism resembling the original real-world condition. The multi-shot or multi-row configuration used in the spherical panorama image samplings suggests parallax error should be minimized or entirely avoided during the photographic acquisition process without performing compensated correction during the post-processing process. Inconsistency of photographic conditions across the multiple image sequence can be minimized with some of the following suggestions:</p><ol class="u-list-style-none">
                  <li>
                    <span class="u-custom-list-number">1.</span>
                    
                      <p>Manual decisions can be made for selecting the appropriate photographic moment to avoid unwanted moving objects being photographically recorded.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">2.</span>
                    
                      <p>Gretagmacbeth color chart used for fixing a selected white balance can be consistently applied on the entire multiple image sequence, on the condition that natural lighting such as the sunlight of the real-world scene is maintaining a slow changing pace with a calm weather condition.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">3.</span>
                    
                      <p>The time needed to acquire the entire set of multiple image sequences is suggested to be minimal, in order to avoid any unpredictable imaging variables such as any moving objects or fast changing weather conditions if the architectural subject involves any natural lighting.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">4.</span>
                    
                      <p>Ideally all the image sequences required for constructing the spherical panorama image rendering can be acquired with clarity of imagery feature, in order to suggest a robust image stitching process via any spherical imaging processor.</p>
                    
                  </li>
                </ol>
              <p>The dynamic range in high contrast real-world scene such as a location-based subject of architectural context would be difficult to be recorded and presented using the conventional single-exposure method. This study brings an important perspective of observing the phenomenon of inconsistent HDRI luminance reproduction for multiple angles required for constructing spherical panorama. Fusing multiple exposures into a HDRI that can maintain a middle-key histogram preserves global or local tone reproduction in terms of extended luminance; however, the resultant multiple angles with inconsistent luminance is observed as not being suitable for accurate spherical panorama reproduction. There are various approaches for HDRI (Reinhard et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Reinhard E, Heidrich W, Debevec P, Pattanaik S, Ward G, Myszkowski K (2010) High dynamic range imaging: Acquisition, Display, and Image-based lighting, 2nd edn. Elsevier, Amsterdam. &#xA;                    http://www.amazon.com/Dynamic-Range-Imaging-Second-Edition/dp/012374914X&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-014-0258-9#ref-CR21" id="ref-link-section-d14675e1594">2010</a>; Debevec and Malik <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="&#xA;Debevec PE, Malik J (1997) Recovering high dynamic range radiance maps from photographs. In: SIGGRAPH '97: Proceedings of the 24th annual conference on Computer graphics and interactive techniques, pp 369–378. &#xA;                    http://dl.acm.org/citation.cfm?id=258884&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-014-0258-9#ref-CR7" id="ref-link-section-d14675e1597">1997</a>; Felinto et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Felinto D, Zang AR, Velho L (2012) Production framework for full panoramic scenes with photorealistic augmented reality. XXXVIII Latin American Conference of Informatics (CLEI)" href="/article/10.1007/s10055-014-0258-9#ref-CR10" id="ref-link-section-d14675e1600">2012</a>) that can produce different intended outcomes in each single image. It may be vital to take advantage of HDRI approach to preserve and present luminance information. It can be significant that the method and apparatus of HDRI suitable to work with high-fidelity spherical panorama reproduction can be explored with further studies.</p><p>The ideal situation to include selective moving subjects in the spherical panorama imagery can be manually managed, as it requires high attention, spontaneous decision making during the consideration in pre-visualization stage. The spherical panorama imagery reproduced from multiple angle images is observed to be moderately suitable for recording and presenting the photographic moment of a location-based subject, however, on “multiple moment basis” instead of “single photographic moment.” Unpredictable moving objects cannot be appropriately recorded and presented using multiple angle images approach, as it may potentially create a minor extent of biased photographic interpretation such as for the usage of forensic and news reporting purposes. The situation of image manipulation correction during the post-processing stage, however, may affect the authenticity of architectural image reproduction to a certain degree. In such a situation, the study considers that the nadir angle difficulty is a mistake that requires rectification.</p><p>Industrial convention of virtual reality wearable computer has become more accessible to consumers. Several recent developments in wearable virtual reality headsets have incorporated the main feature for use with a smartphone (Zeiss <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Zeiss (2014) VR One. &#xA;                    http://zeissvrone.tumblr.com&#xA;                    &#xA;                  . Accessed 25 Nov 2014" href="/article/10.1007/s10055-014-0258-9#ref-CR30" id="ref-link-section-d14675e1608">2014</a>; Archos <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Archos (2014) Archos VR glasses: jump into the mobile virtual reality world. &#xA;                    http://www.archos.com/corporate/press/press_releases/US_Archos_VR_Glasses_PR_20141016.pdf&#xA;                    &#xA;                  . Accessed 25 Nov 2014" href="/article/10.1007/s10055-014-0258-9#ref-CR2" id="ref-link-section-d14675e1611">2014</a>; Samsung <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Samsung, Gear VR (2014) &#xA;                    http://www.samsung.com/global/microsite/gearvr&#xA;                    &#xA;                  . Accessed 25 Nov 2014" href="/article/10.1007/s10055-014-0258-9#ref-CR22" id="ref-link-section-d14675e1614">2014</a>); experiencing interactive panorama using a wearable head-mounted display (HMD) would become feasible in terms of computing, affordable device and user application availability. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-014-0258-9#Fig14">14</a> shows a conceptual implementation of VR360 interactive panorama experience on a HMD powered by a mobile-based device or interchangeable computing module. Fundamentally, most of the interactive panorama systems may consider it important to work with high-fidelity source of panorama image reproduction in order to record and present real-world elements with reliable information. We hope this case study can provide an in-depth empirical understanding for interactive panorama producers and users toward how obstacles and issues can be interrelated to each other. The ideal reproduction of spherical imagery content should be considered in whole instead of fixing a portion of the overall difficulty. Future studies may explore if virtual reality HMD to be used for interactive panorama can provide user experience beyond the limitations of vision and sound, these potential areas can include experiencing communications via the elements of smell and taste.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-14"><figure><figcaption><b id="Fig14" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 14</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/14" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig14_HTML.gif?as=webp"></source><img aria-describedby="figure-14-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-014-0258-9/MediaObjects/10055_2014_258_Fig14_HTML.gif" alt="figure14" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-14-desc"><p>Virtual reality 360 interactive panorama user experience using a head-mounted display powered by a mobile phone or tablet</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-014-0258-9/figures/14" data-track-dest="link:Figure14 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>The next step in this study may focus on lean reproduction studies of spherical panorama that is facilitated with HDRI. The availability of visual information in terms of higher resolution when working with higher-resolution image recording instrument for multiple angle images may allow greater viewing magnification of the spherical panorama content. Therefore, the goal to obtain high-fidelity reproduction is recommended to have low tolerance to visual abnormality for both technical configuration and human handling. The future development of the intended study can work on potential technical optimization on how spherical panorama reproduction with high authenticity can be operated using method and apparatus which require least amount of photographic production time and human effort.</p></div></div></section><section aria-labelledby="Sec6"><div class="c-article-section" id="Sec6-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec6">Implication and conclusion</h2><div class="c-article-section__content" id="Sec6-content"><p>VR360 interactive panorama image presentations are becoming more widespread in recent years and have invited many changes in digital lifestyle. It especially improves the way we can interact with location-based images and access high-fidelity visual information via various augmented and virtual reality development. This paper has observed how imaging variables caused by various obstacles and issues can happen during the spherical panorama image reproduction process. High-precision method and apparatus calibration have been essential during the digital imaging workflow that involves the processes of pre-visualization, photographic acquisition and post-processing. Imaging errors or visual abnormalities that can be minimized or avoided include parallax error, white balance inconsistency, exposures inconsistency and ghosting effect caused by moving objects. Consistent luminance in multiple angles is critical to suggest accurate visual information being reproduced. For interactive panorama presentation and augmented reality applications, further studies can attempt to explore the method and apparatus that has the capability to operate precision reproduction process of spherical panorama facilitated with HDRI.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="&#xA;Andrews P (2003) 360 Degree imaging: the photographer’s panoramic virtual reality manual. RotoVision. http://" /><p class="c-article-references__text" id="ref-CR1">
Andrews P (2003) 360 Degree imaging: the photographer’s panoramic virtual reality manual. RotoVision. <a href="http://www.amazon.com/360-Degree-Imaging-Photographers-Photography/dp/2880467322">http://www.amazon.com/360-Degree-Imaging-Photographers-Photography/dp/2880467322</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Archos (2014) Archos VR glasses: jump into the mobile virtual reality world. http://www.archos.com/corporate/p" /><p class="c-article-references__text" id="ref-CR2">Archos (2014) Archos VR glasses: jump into the mobile virtual reality world. <a href="http://www.archos.com/corporate/press/press_releases/US_Archos_VR_Glasses_PR_20141016.pdf">http://www.archos.com/corporate/press/press_releases/US_Archos_VR_Glasses_PR_20141016.pdf</a>. Accessed 25 Nov 2014</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Arth C, Klopschitz M, Reitmayr G, Schmalstieg D (2011) Real-time self-localization from panoramic images on mo" /><p class="c-article-references__text" id="ref-CR3">Arth C, Klopschitz M, Reitmayr G, Schmalstieg D (2011) Real-time self-localization from panoramic images on mobile devices. 2011 10th IEEE International Symposium on Mixed and Augmented Reality</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="R. Benosman, SB. Kang, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Benosman R, Kang SB (2001) Panoramic vision: sensors, theory, and applications. Springer, Heidelberg" /><p class="c-article-references__text" id="ref-CR4">Benosman R, Kang SB (2001) Panoramic vision: sensors, theory, and applications. Springer, Heidelberg</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Panoramic%20vision%3A%20sensors%2C%20theory%2C%20and%20applications&amp;publication_year=2001&amp;author=Benosman%2CR&amp;author=Kang%2CSB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Brown, DG. Lowe, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Brown M, Lowe DG (2007) Automatic Panoramic Image Stitching using Invariant Features. Int J Comput Vis 74(1):5" /><p class="c-article-references__text" id="ref-CR5">Brown M, Lowe DG (2007) Automatic Panoramic Image Stitching using Invariant Features. Int J Comput Vis 74(1):59–73</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs11263-006-0002-3" aria-label="View reference 5">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Automatic%20Panoramic%20Image%20Stitching%20using%20Invariant%20Features&amp;journal=Int%20J%20Comput%20Vis&amp;volume=74&amp;issue=1&amp;pages=59-73&amp;publication_year=2007&amp;author=Brown%2CM&amp;author=Lowe%2CDG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chen E (1995) Quicktime VR: an image-based approach to virtual environment navigation. In SIGGRAPH’95" /><p class="c-article-references__text" id="ref-CR6">Chen E (1995) Quicktime VR: an image-based approach to virtual environment navigation. In SIGGRAPH’95</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="&#xA;Debevec PE, Malik J (1997) Recovering high dynamic range radiance maps from photographs. In: SIGGRAPH '97: Pr" /><p class="c-article-references__text" id="ref-CR7">
Debevec PE, Malik J (1997) Recovering high dynamic range radiance maps from photographs. In: SIGGRAPH '97: Proceedings of the 24th annual conference on Computer graphics and interactive techniques, pp 369–378. <a href="http://dl.acm.org/citation.cfm?id=258884">http://dl.acm.org/citation.cfm?id=258884</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. DiVerdi, J. Wither, T. Hollerer, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="DiVerdi S, Wither J, Hollerer T (2008) Envisor: online environment map construction for mixed reality. Proc IE" /><p class="c-article-references__text" id="ref-CR8">DiVerdi S, Wither J, Hollerer T (2008) Envisor: online environment map construction for mixed reality. Proc IEEE Virtual Real Conf 2008:19–26</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Envisor%3A%20online%20environment%20map%20construction%20for%20mixed%20reality&amp;journal=Proc%20IEEE%20Virtual%20Real%20Conf&amp;volume=2008&amp;pages=19-26&amp;publication_year=2008&amp;author=DiVerdi%2CS&amp;author=Wither%2CJ&amp;author=Hollerer%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. DiVerdi, J. Wither, T. Höllerer, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="DiVerdi S, Wither J, Höllerer T (2009) All Around the map: online spherical panorama construction. Comput Gr 3" /><p class="c-article-references__text" id="ref-CR9">DiVerdi S, Wither J, Höllerer T (2009) All Around the map: online spherical panorama construction. Comput Gr 33(1):73–84</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.cag.2008.11.002" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=All%20Around%20the%20map%3A%20online%20spherical%20panorama%20construction&amp;journal=Comput%20Gr&amp;volume=33&amp;issue=1&amp;pages=73-84&amp;publication_year=2009&amp;author=DiVerdi%2CS&amp;author=Wither%2CJ&amp;author=H%C3%B6llerer%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Felinto D, Zang AR, Velho L (2012) Production framework for full panoramic scenes with photorealistic augmente" /><p class="c-article-references__text" id="ref-CR10">Felinto D, Zang AR, Velho L (2012) Production framework for full panoramic scenes with photorealistic augmented reality. XXXVIII Latin American Conference of Informatics (CLEI)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gardner R (2012) Digital tones and exposure zones. 2004, http://www.rags-int-inc.com/PhotoTechStuff/TonesnZone" /><p class="c-article-references__text" id="ref-CR11">Gardner R (2012) Digital tones and exposure zones. 2004, <a href="http://www.rags-int-inc.com/PhotoTechStuff/TonesnZones">http://www.rags-int-inc.com/PhotoTechStuff/TonesnZones</a>. Accessed 27 July 2012</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Gledhill, GY. Tian, D. Taylor, D. Clarke, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Gledhill D, Tian GY, Taylor D, Clarke D (2003) Panoramic imaging—a review. Comput Gr 27(3):435–445" /><p class="c-article-references__text" id="ref-CR12">Gledhill D, Tian GY, Taylor D, Clarke D (2003) Panoramic imaging—a review. Comput Gr 27(3):435–445</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0097-8493%2803%2900038-4" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Panoramic%20imaging%E2%80%94a%20review&amp;journal=Comput%20Gr&amp;volume=27&amp;issue=3&amp;pages=435-445&amp;publication_year=2003&amp;author=Gledhill%2CD&amp;author=Tian%2CGY&amp;author=Taylor%2CD&amp;author=Clarke%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Guan X-Y, Shark L-K, Hall G, Deng W (2009) Distortion correction for immersive navigation in spherical image e" /><p class="c-article-references__text" id="ref-CR13">Guan X-Y, Shark L-K, Hall G, Deng W (2009) Distortion correction for immersive navigation in spherical image environment. 2009 International Conference on CyberWorlds</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Imatest (2012) Imatest—using stepchart, http://www.imatest.com/docs/q13/#dynamic. Accessed 27 July 2012" /><p class="c-article-references__text" id="ref-CR14">Imatest (2012) Imatest—using stepchart, <a href="http://www.imatest.com/docs/q13/#dynamic">http://www.imatest.com/docs/q13/#dynamic</a>. Accessed 27 July 2012</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="C. Jacobs, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Jacobs C (2004) Interactive panorama. Springer, Heidelberg" /><p class="c-article-references__text" id="ref-CR15">Jacobs C (2004) Interactive panorama. Springer, Heidelberg</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Interactive%20panorama&amp;publication_year=2004&amp;author=Jacobs%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Langlotz, D. Wagner, A. Mulloni, D. Schmalstieg, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Langlotz T, Wagner D, Mulloni A, Schmalstieg D (2012) Online creation of panoramic augmented reality annotatio" /><p class="c-article-references__text" id="ref-CR16">Langlotz T, Wagner D, Mulloni A, Schmalstieg D (2012) Online creation of panoramic augmented reality annotations on mobile phones. IEEE Pervasive Comput 11(2):56–63</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FMPRV.2010.69" aria-label="View reference 16">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Online%20creation%20of%20panoramic%20augmented%20reality%20annotations%20on%20mobile%20phones&amp;journal=IEEE%20Pervasive%20Comput&amp;volume=11&amp;issue=2&amp;pages=56-63&amp;publication_year=2012&amp;author=Langlotz%2CT&amp;author=Wagner%2CD&amp;author=Mulloni%2CA&amp;author=Schmalstieg%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Langlotz, T. Nguyen, D. Schmalstieg, R. Grasset, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Langlotz T, Nguyen T, Schmalstieg D, Grasset R (2014) Next-generation augmented reality browsers: rich, seamle" /><p class="c-article-references__text" id="ref-CR17">Langlotz T, Nguyen T, Schmalstieg D, Grasset R (2014) Next-generation augmented reality browsers: rich, seamless, and adaptive. Proc IEEE 102(2):155–169</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FJPROC.2013.2294255" aria-label="View reference 17">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Next-generation%20augmented%20reality%20browsers%3A%20rich%2C%20seamless%2C%20and%20adaptive&amp;journal=Proc%20IEEE&amp;volume=102&amp;issue=2&amp;pages=155-169&amp;publication_year=2014&amp;author=Langlotz%2CT&amp;author=Nguyen%2CT&amp;author=Schmalstieg%2CD&amp;author=Grasset%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="S. Oettermann, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Oettermann S (1997) The panorama. MIT Press, Cambridge" /><p class="c-article-references__text" id="ref-CR18">Oettermann S (1997) The panorama. MIT Press, Cambridge</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20panorama&amp;publication_year=1997&amp;author=Oettermann%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ravine M (2012) Mars rover camera project manager explains 2MP camera choice. http://www.dpreview.com/news/201" /><p class="c-article-references__text" id="ref-CR19">Ravine M (2012) Mars rover camera project manager explains 2MP camera choice. <a href="http://www.dpreview.com/news/2012/08/08/Curiosity-interview-with-Malin-Space-Science-Systems-Mike-Ravine">http://www.dpreview.com/news/2012/08/08/Curiosity-interview-with-Malin-Space-Science-Systems-Mike-Ravine</a>. Accessed 11 August 2012</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rehm L (2009) D3x In Depth Review, 2009, http://www.dpreview.com/reviews/nikond3x. Accessed 01 Dec 2010" /><p class="c-article-references__text" id="ref-CR20">Rehm L (2009) D3x In Depth Review, 2009, <a href="http://www.dpreview.com/reviews/nikond3x">http://www.dpreview.com/reviews/nikond3x</a>. Accessed 01 Dec 2010</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Reinhard E, Heidrich W, Debevec P, Pattanaik S, Ward G, Myszkowski K (2010) High dynamic range imaging: Acquis" /><p class="c-article-references__text" id="ref-CR21">Reinhard E, Heidrich W, Debevec P, Pattanaik S, Ward G, Myszkowski K (2010) High dynamic range imaging: Acquisition, Display, and Image-based lighting, 2nd edn. Elsevier, Amsterdam. <a href="http://www.amazon.com/Dynamic-Range-Imaging-Second-Edition/dp/012374914X">http://www.amazon.com/Dynamic-Range-Imaging-Second-Edition/dp/012374914X</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Samsung, Gear VR (2014) http://www.samsung.com/global/microsite/gearvr. Accessed 25 Nov 2014" /><p class="c-article-references__text" id="ref-CR22">Samsung, Gear VR (2014) <a href="http://www.samsung.com/global/microsite/gearvr">http://www.samsung.com/global/microsite/gearvr</a>. Accessed 25 Nov 2014</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="&#xA;Schmidt L, Baumgart U (2007) What’s the meaning of VR photography/VR panoramas? Art-documentation.com. Access" /><p class="c-article-references__text" id="ref-CR23">
Schmidt L, Baumgart U (2007) What’s the meaning of VR photography/VR panoramas? Art-documentation.com. Accessed 21 Aug 2012</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="R. Stake, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Stake R (1995) The art of case research. Sage, Thousand Oaks" /><p class="c-article-references__text" id="ref-CR24">Stake R (1995) The art of case research. Sage, Thousand Oaks</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20art%20of%20case%20research&amp;publication_year=1995&amp;author=Stake%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Ventura, T. Höllerer, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Ventura J, Höllerer T (2013) Structure and motion in urban environments using upright panoramas. Virtual Real " /><p class="c-article-references__text" id="ref-CR25">Ventura J, Höllerer T (2013) Structure and motion in urban environments using upright panoramas. Virtual Real 17(2):147–156</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10055-012-0208-3" aria-label="View reference 25">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Structure%20and%20motion%20in%20urban%20environments%20using%20upright%20panoramas&amp;journal=Virtual%20Real&amp;volume=17&amp;issue=2&amp;pages=147-156&amp;publication_year=2013&amp;author=Ventura%2CJ&amp;author=H%C3%B6llerer%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Wagner, A. Mulloni, T. Langlotz, D. Schmalstieg, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Wagner D, Mulloni A, Langlotz T, Schmalstieg D (2010) Real-time panoramic mapping and tracking on mobile phone" /><p class="c-article-references__text" id="ref-CR26">Wagner D, Mulloni A, Langlotz T, Schmalstieg D (2010) Real-time panoramic mapping and tracking on mobile phones. IEEE Virtual Real Conf 2010:211–218</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Real-time%20panoramic%20mapping%20and%20tracking%20on%20mobile%20phones&amp;journal=IEEE%20Virtual%20Real%20Conf&amp;volume=2010&amp;pages=211-218&amp;publication_year=2010&amp;author=Wagner%2CD&amp;author=Mulloni%2CA&amp;author=Langlotz%2CT&amp;author=Schmalstieg%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Warrington C (2007) Markerless Augmented Reality for Panoramic Sequences, MA Thesis submitted to Faculty of En" /><p class="c-article-references__text" id="ref-CR27">Warrington C (2007) Markerless Augmented Reality for Panoramic Sequences, MA Thesis submitted to Faculty of Engineering, University of Ottawa</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="R. Yin, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Yin R (1994) Case study research: design and methods, 2nd edn. Sage, Beverly Hills" /><p class="c-article-references__text" id="ref-CR28">Yin R (1994) Case study research: design and methods, 2nd edn. Sage, Beverly Hills</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Case%20study%20research%3A%20design%20and%20methods&amp;publication_year=1994&amp;author=Yin%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zang AR, Felinto D, Velho L (2012) Augmented reality using full panoramic captured scene light-depth maps. Sig" /><p class="c-article-references__text" id="ref-CR29">Zang AR, Felinto D, Velho L (2012) Augmented reality using full panoramic captured scene light-depth maps. Siggraph Asia 2012</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zeiss (2014) VR One. http://zeissvrone.tumblr.com. Accessed 25 Nov 2014" /><p class="c-article-references__text" id="ref-CR30">Zeiss (2014) VR One. <a href="http://zeissvrone.tumblr.com">http://zeissvrone.tumblr.com</a>. Accessed 25 Nov 2014</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-014-0258-9-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Reina Imaging, Kuala Lumpur, Malaysia</p><p class="c-article-author-affiliation__authors-list">Zi Siang See</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Universiti Tunku Abdul Rahman, Kuala Lumpur, Malaysia</p><p class="c-article-author-affiliation__authors-list">Zi Siang See</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">City University London, London, UK</p><p class="c-article-author-affiliation__authors-list">Adrian David Cheok</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Zi_Siang-See"><span class="c-article-authors-search__title u-h3 js-search-name">Zi Siang See</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Zi Siang+See&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Zi Siang+See" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Zi Siang+See%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Adrian_David-Cheok"><span class="c-article-authors-search__title u-h3 js-search-name">Adrian David Cheok</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Adrian David+Cheok&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Adrian David+Cheok" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Adrian David+Cheok%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-014-0258-9/email/correspondent/c1/new">Zi Siang See</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Virtual%20reality%20360%20interactive%20panorama%20reproduction%20obstacles%20and%20issues&amp;author=Zi%20Siang%20See%20et%20al&amp;contentID=10.1007%2Fs10055-014-0258-9&amp;publication=1359-4338&amp;publicationDate=2014-12-24&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-014-0258-9" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-014-0258-9" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">See, Z.S., Cheok, A.D. Virtual reality 360 interactive panorama reproduction obstacles and issues.
                    <i>Virtual Reality</i> <b>19, </b>71–81 (2015). https://doi.org/10.1007/s10055-014-0258-9</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-014-0258-9.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2014-07-01">01 July 2014</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2014-12-11">11 December 2014</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2014-12-24">24 December 2014</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-06">June 2015</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-014-0258-9" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-014-0258-9</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Spherical panorama</span></li><li class="c-article-subject-list__subject"><span itemprop="about">High dynamic range imaging</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Image reproduction</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Virtual reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Augmented reality</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-014-0258-9.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=258;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

