<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Haptic virtual reality and immersive learning for enhanced organic che"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Human&#8211;Computer interaction, including technology-aided instruction, is beginning to focus on virtual reality (VR) technology due to its ability to support immersive learning, teaching through..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/23/4.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Haptic virtual reality and immersive learning for enhanced organic chemistry instruction"/>

    <meta name="dc.source" content="Virtual Reality 2018 23:4"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2018-06-15"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2018 Springer-Verlag London Ltd., part of Springer Nature"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Human&#8211;Computer interaction, including technology-aided instruction, is beginning to focus on virtual reality (VR) technology due to its ability to support immersive learning, teaching through simulation, and gamification of learning. These systems can deliver high-level multisensory learning experiences that are important in the teaching of many subjects, especially those involving abstract concepts or requiring spatial skills, such as organic chemistry. Haptic experiences with VR, however, remain a challenge. In addition, development has focused on general entertainment/gaming; VR systems in chemistry implement simulations of the chemistry laboratory and other advanced systems whereas those that support safe, game-like, immersive and multisensory learning of organic chemistry with haptics at pre-university education levels are scarce. We developed the VR Multisensory Classroom (VRMC) as an immersive learning environment within a VR head-mounted display, where learners employ hand movements to build hydrocarbon molecules and experience haptic feedback through gloves with built-in sensors and hand-tracking with the Leap Motion system. We report here the evaluation of the first prototype by learners from diverse backgrounds who reported on the ability of the VRMC to support high engagement, motivation, interest and organic chemistry learning as well as diverse learning styles. The VRMC is a novel VR classroom that supports immersive learning in molecular organic chemistry with haptics for multisensory learning."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2018-06-15"/>

    <meta name="prism.volume" content="23"/>

    <meta name="prism.number" content="4"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="363"/>

    <meta name="prism.endingPage" content="373"/>

    <meta name="prism.copyright" content="2018 Springer-Verlag London Ltd., part of Springer Nature"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-018-0345-4"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-018-0345-4"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-018-0345-4.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-018-0345-4"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Haptic virtual reality and immersive learning for enhanced organic chemistry instruction"/>

    <meta name="citation_volume" content="23"/>

    <meta name="citation_issue" content="4"/>

    <meta name="citation_publication_date" content="2019/12"/>

    <meta name="citation_online_date" content="2018/06/15"/>

    <meta name="citation_firstpage" content="363"/>

    <meta name="citation_lastpage" content="373"/>

    <meta name="citation_article_type" content="S.I. : VR in Education"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-018-0345-4"/>

    <meta name="DOI" content="10.1007/s10055-018-0345-4"/>

    <meta name="citation_doi" content="10.1007/s10055-018-0345-4"/>

    <meta name="description" content="Human&#8211;Computer interaction, including technology-aided instruction, is beginning to focus on virtual reality (VR) technology due to its ability to su"/>

    <meta name="dc.creator" content="Bosede Iyiade Edwards"/>

    <meta name="dc.creator" content="Kevin S. Bielawski"/>

    <meta name="dc.creator" content="Rui Prada"/>

    <meta name="dc.creator" content="Adrian David Cheok"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Axon VR (2017) Virtual reality you can feel. 
                    https://axonvr.com/#haptx-haptics-evolved
                    
                  . Accessed 26 May 2017"/>

    <meta name="citation_reference" content="citation_journal_title=J Mix Methods Res; citation_title=Book Review: V. L. Plano Clark and J. W. Creswell (Eds.) The Mixed Methods Reader. Thousand Oaks, CA: SAGE, 2008, 617&#160;pp. Supplied by Footprint Books, AU$79 (paperback); citation_author=P Bazeley; citation_volume=4; citation_issue=1; citation_publication_date=2010; citation_pages=79-81; citation_doi=10.1177/1558689809356926; citation_id=CR2"/>

    <meta name="citation_reference" content="citation_journal_title=Interact Learn Environ; citation_title=Gamification and student motivation; citation_author=P Buckley, E Doyle; citation_volume=24; citation_issue=6; citation_publication_date=2016; citation_pages=1162-1175; citation_doi=10.1080/10494820.2014.964263; citation_id=CR3"/>

    <meta name="citation_reference" content="Cambridge Dictionary (2017) Definition of immersive. Cambridge Dictionary. Cambridge University Press. 
                    http://dictionary.cambridge.org/dictionary/english/immersive
                    
                  . Accessed 26 May 2017"/>

    <meta name="citation_reference" content="citation_journal_title=Concur Eng Res Appl; citation_title=Virtual reality applications in manufacturing industries: past research, present findings, and future directions; citation_author=S Choi, K Jung, SD Noh; citation_volume=23; citation_issue=1; citation_publication_date=2015; citation_pages=40-63; citation_doi=10.1177/1063293X14568814; citation_id=CR5"/>

    <meta name="citation_reference" content="citation_journal_title=Education; citation_title=Virtual reality in education; citation_author=C Christou; citation_publication_date=2010; citation_doi=10.4018/978-1-60566-940-3.ch012; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_journal_title=Muqarnas; citation_title=Creswell&#39;s Appreciation of Arabian Architecture; citation_author=G. R. D. King; citation_volume=8; citation_publication_date=1991; citation_pages=94; citation_doi=10.2307/1523157; citation_id=CR7"/>

    <meta name="citation_reference" content="Creswell JW, Plano Clark VL (2007) Choosing a mixed method design. In: Designing and conducting mixed methods research. SAGE Publications, Inc, pp 58&#8211;89. ISBN: 1412927927"/>

    <meta name="citation_reference" content="Culatta R (2013) ADDIE model. Retrieved from 
                    http://www.instructionaldesign.org/models/addie
                    
                  
                        "/>

    <meta name="citation_reference" content="DextaRobotics (2018) DextaRobotics builds hand haptics device for virtual reality medical learning. 
                    https://www.healthysimulation.com/9009/dextarobotics-builds-hand-haptics-device-for-virtual-reality-medical-learning/
                    
                  . Accessed 16 Mar 2018"/>

    <meta name="citation_reference" content="D&#252;nser A, Steinb&#252;gl K, Kaufmann H, Gl&#252;ck J (2006) Virtual and augmented reality as spatial ability training tools. In: Proceedings of the 6th ACM SIGCHI New Zealand chapter&#8217;s international conference on Computer-human interaction design centered HCI - CHINZ&#8217;06, vol 158, pp 125&#8211;132. 
                    https://doi.org/10.1145/1152760.1152776
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=J Chem Educ; citation_title=Fastest fingers: a molecule-building game for teaching organic chemistry; citation_author=ML Eastwood; citation_volume=90; citation_issue=8; citation_publication_date=2013; citation_pages=1038-1041; citation_doi=10.1021/ed3004462; citation_id=CR12"/>

    <meta name="citation_reference" content="citation_title=Doing naturalistic inquiry: a guide to methods; citation_publication_date=1993; citation_id=CR13; citation_author=DA Erlandson; citation_author=EL Harris; citation_author=BL Skipper; citation_author=SD Allen; citation_publisher=SAGE Publications Inc"/>

    <meta name="citation_reference" content="citation_journal_title=Nurse Educ Pract; citation_title=Virtual reality disaster training: translation to practice; citation_author=SL Farra, ET Miller, E Hodgson; citation_volume=15; citation_issue=1; citation_publication_date=2015; citation_pages=53-57; citation_doi=10.1016/j.nepr.2013.08.017; citation_id=CR14"/>

    <meta name="citation_reference" content="Fildes N (2015, December) 2016 set to be year virtual reality takes off. Raconteur. 
                    https://www.raconteur.net/technology/2016-set-to-be-year-virtual-reality-takes-off
                    
                  . Accessed 26 May 2017"/>

    <meta name="citation_reference" content="Google (2017) Virtual reality for everyone. Retrieved November 9, 2017. 
                    https://vr.google.com/
                    
                  . Accessed 26 May 2017"/>

    <meta name="citation_reference" content="GoTouch VR Team (2017) Go touch VR. Retrieved November 9, 2017. 
                    https://www.gotouchvr.com/
                    
                  . Accessed 26 May 2017"/>

    <meta name="citation_reference" content="Hamid NSS, Aziz FA, Azizi A (2014) Virtual reality applications in manufacturing system. In: Proceedings of 2014 science and information conference, SAI 2014. pp 1034&#8211;1037. 
                    https://doi.org/10.1109/SAI.2014.6918317
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Comput Educ; citation_title=Enhancement of spatial thinking with virtual spaces 1.0; citation_author=H Hauptman; citation_volume=54; citation_issue=1; citation_publication_date=2010; citation_pages=123-135; citation_doi=10.1016/j.compedu.2009.07.013; citation_id=CR19"/>

    <meta name="citation_reference" content="Heinich R, Molenda M, Russell J, Smaldino S (2002) The ASSURE model. In Instructional media and technologies for learning, vol 7"/>

    <meta name="citation_reference" content="Hyun EHE, Yoon HYH, Son SSS (2010) Relationships between user experiences and children&#8217;s perceptions of the education robot. In: Human-robot interaction (HRI), 2010 5th ACM/IEEE international conference on, pp 199&#8211;200. 
                    https://doi.org/10.1109/HRI.2010.5453197
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Instr Sci; citation_title=Cognitive load theory, educational research, and instructional design: some food for thought; citation_author=T Jong; citation_volume=38; citation_issue=2; citation_publication_date=2009; citation_pages=105-134; citation_doi=10.1007/s11251-009-9110-0; citation_id=CR22"/>

    <meta name="citation_reference" content="Koedinger KR, Kim J, Jia JZ, McLaughlin EA, Bier NL (2015) Learning is not a spectator sport: doing is better than watching for learning from a MOOC. In: Proceedings of the second (2015) ACM conference on learning @ Scale-L@S&#8217;15. pp 111&#8211;120. 
                    https://doi.org/10.1145/2724660.2724681
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Nurse Education Today; citation_title=The assessment ofstudent nurse learning styles using the Kolb Learning Styles Inventory; citation_author=Stephen J. Cavanagh, Kevin Hogan, Terenlall Ramgopal; citation_volume=15; citation_issue=3; citation_publication_date=1995; citation_pages=177-183; citation_doi=10.1016/S0260-6917(95)80103-0; citation_id=CR24"/>

    <meta name="citation_reference" content="citation_journal_title=Perspect Think Learn Cognit Styl; citation_title=Experiential learning theory: previous research and new directions; citation_author=DA Kolb, RE Boyatzis, C Mainemelis; citation_volume=1; citation_issue=216; citation_publication_date=2000; citation_pages=227-247; citation_doi=10.5465/AMLE.2005.17268566; citation_id=CR25"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Hum Behav; citation_title=How gamification motivates visits and engagement for online academic dissemination: an empirical study; citation_author=MS Kuo, TY Chuang; citation_volume=55; citation_publication_date=2016; citation_pages=16-27; citation_doi=10.1016/j.chb.2015.08.025; citation_id=CR26"/>

    <meta name="citation_reference" content="Leap Motion (2017) Reach into Virtual Reality with your bare hands. 
                    https://www.leapmotion.com/#112
                    
                  . Accessed 26 May 2017"/>

    <meta name="citation_reference" content="Mahatma Chemistry (2017) MEL chemistry VR. 
                    https://melscience.com/vr/
                    
                  . Accessed 26 May 2017"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Inf Educ Technol; citation_title=Applying situated learning in a virtual reality system to enhance learning motivation; citation_author=HH Mei, LS Sheng; citation_volume=1; citation_issue=4; citation_publication_date=2011; citation_pages=298-302; citation_doi=10.7763/IJIET.2011.V1.48; citation_id=CR29"/>

    <meta name="citation_reference" content="citation_journal_title=J Comput Assist Learn; citation_title=Exploring 3-D virtual reality technology for spatial ability and chemistry achievement; citation_author=Z Merchant, ET Goetz, W Keeney-Kennicutt, L Cifuentes, O Kwok, TJ Davis; citation_volume=29; citation_issue=6; citation_publication_date=2013; citation_pages=579-590; citation_doi=10.1111/jcal.12018; citation_id=CR30"/>

    <meta name="citation_reference" content="Merriam Webster Dictionary (2017) Definition of IMMERSIVE. Retrieved from 
                    https://www.merriamwebster.com/dictionary/immersive
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_title=Immersion and presence; citation_inbook_title=Virtual Reality; citation_publication_date=2011; citation_id=CR32; citation_author=Daniel Mestre; citation_author=Jean-Louis Vercher"/>

    <meta name="citation_reference" content="citation_journal_title=Rev Educ Res; citation_title=Haptics in education: exploring an untapped sensory modality; citation_author=J Minogue, MG Jones; citation_volume=76; citation_issue=3; citation_publication_date=2006; citation_pages=317-348; citation_doi=10.3102/00346543076003317; citation_id=CR33"/>

    <meta name="citation_reference" content="Molenda M (2003a) ADDIE model. 
                    http://www.nwlink.com/~donclark/history_isd/addie.html#FSU
                    
                  . Accessed 26 May 2017"/>

    <meta name="citation_reference" content="Molenda (2003b) ADDIE Timeline. The performance juxtaposition site. Retrieved from 
                    http://www.nwlink.com/~donclark/history_isd/addie.html#FSU
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Comput Educ; citation_title=Virtual reality for collaborative e-learning; citation_author=T Monahan, G McArdle, M Bertolotto; citation_volume=50; citation_issue=4; citation_publication_date=2008; citation_pages=1339-1353; citation_doi=10.1016/j.compedu.2006.12.008; citation_id=CR36"/>

    <meta name="citation_reference" content="citation_journal_title=J Mater Process Technol; citation_title=Virtual reality applications in manufacturing process simulation; citation_author=T Mujber, T Szecsi, M Hashmi; citation_volume=155156; citation_publication_date=2004; citation_pages=1834-1838; citation_doi=10.1016/j.jmatprotec.2004.04.401; citation_id=CR37"/>

    <meta name="citation_reference" content="citation_journal_title=Oxf Handb Posit Psychol; citation_title=Flow theory and research; citation_author=J Nakamura, M Csikszentmihalyi; citation_publication_date=2009; citation_doi=10.1093/oxfordhb/9780195187243.013.0018; citation_id=CR38"/>

    <meta name="citation_reference" content="citation_journal_title=J Chem Inf Model; citation_title=Molecular rift: virtual reality for drug designers; citation_author=M Norrby, C Grebner, J Eriksson, J Bostrom; citation_volume=55; citation_issue=11; citation_publication_date=2015; citation_pages=2475-2484; citation_doi=10.1021/acs.jcim.5b00544; citation_id=CR39"/>

    <meta name="citation_reference" content="citation_journal_title=J Sci Educ Technol; citation_title=The frequency of hands-on experimentation and student attitudes toward science: a statistically significant relation (2005-51-ornstein); citation_author=A Ornstein; citation_volume=15; citation_issue=3&#8211;4; citation_publication_date=2006; citation_pages=285-297; citation_doi=10.1007/s10956-006-9015-5; citation_id=CR40"/>

    <meta name="citation_reference" content="React! Team (2017) React! the organic chemistry board game. Retrieved June 22, 2017, 
                    http://reactgame.com/#/
                    
                  . Accessed 26 May 2017"/>

    <meta name="citation_reference" content="citation_journal_title=J Chem Educ; citation_title=Virtual titrator: a student-oriented instrument; citation_author=D Ritter, M Johnson; citation_volume=74; citation_issue=1; citation_publication_date=1997; citation_pages=120; citation_doi=10.1021/ed074p120; citation_id=CR42"/>

    <meta name="citation_reference" content="Sanders T, Cairns P (2010) Time perception, immersion and music in videogames. In: Proceedings of the 24th BCS interaction specialist group conference, pp 160&#8211;167"/>

    <meta name="citation_reference" content="Schell Games (2017) SuperChem VR. Retrieved June 20, 2017, 
                    https://www.schellgames.com/games/superchem-vr
                    
                  . Accessed 26 May 2017"/>

    <meta name="citation_reference" content="Smith C, Agcaoili K, Kannan A (2016) Chemistry Lab VR. Retrieved May 20, 2017, 
                    https://devpost.com/software/chemistry-lab-vr
                    
                  . Accessed 26 May 2017"/>

    <meta name="citation_reference" content="citation_journal_title=J Res Sci Teach; citation_title=An analysis of frequency of hands-on experience and science achievement; citation_author=PM Stohr-Hunt; citation_volume=33; citation_issue=1; citation_publication_date=1996; citation_pages=101-109; citation_doi=10.1002/(SICI)1098-2736(199601)33:1&lt;101::AID-TEA6&gt;3.0.CO;2-Z; citation_id=CR46"/>

    <meta name="citation_reference" content="citation_journal_title=J Chem Educ; citation_title=Teaching chromatography using virtual laboratory exercises; citation_author=DC Stone; citation_volume=84; citation_issue=9; citation_publication_date=2007; citation_pages=1488-1495; citation_doi=10.1021/ed084p1488; citation_id=CR47"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Hum Behav; citation_title=Usability of concrete and virtual models in chemistry instruction; citation_author=AT Stull, T Barrett, M Hegarty; citation_volume=29; citation_issue=6; citation_publication_date=2013; citation_pages=2546-2556; citation_doi=10.1016/j.chb.2013.06.012; citation_id=CR48"/>

    <meta name="citation_reference" content="citation_journal_title=Learn Instr; citation_title=Selfish learning: the impact of self-referential encoding on children&#8217;s literacy attainment; citation_author=DJ Turk, K Gillespie-Smith, OE Krigolson, C Havard, MA Conway, SJ Cunningham; citation_volume=40; citation_publication_date=2015; citation_pages=54-60; citation_doi=10.1016/j.learninstruc.2015.08.001; citation_id=CR49"/>

    <meta name="citation_reference" content="Tuveri E, Macis L, Sorrentino F, Spano LD, Scateni R (2016) Fitmersive games: fitness gamification through immersive VR. In Proceedings of the international working conference on advanced visual interfaces-AVI&#8217;16. pp 212&#8211;215. 
                    https://doi.org/10.1145/2909132.2909287
                    
                  
                        "/>

    <meta name="citation_reference" content="Unimersiv (2016) Chemistry VR. Retrieved June 20, 2017, 
                    https://unimersiv.com/review/chemistry-vr/
                    
                  
                        "/>

    <meta name="citation_reference" content="Whitson C, Consoli J (2009) Flow theory and student engagement. J Cross-Discip Perspect Educ 2(1):40&#8211;49. 
                    http://jcpe.wmwikis.net/file/view/whitsonconsoli.pdf
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=J Chem Educ; citation_title=A study of high school students&#8217; performance of a chemistry experiment within the virtual world of second life; citation_author=K Winkelmann, M Scott, D Wong; citation_volume=91; citation_issue=9; citation_publication_date=2014; citation_pages=1432-1438; citation_doi=10.1021/ed500009e; citation_id=CR53"/>

    <meta name="citation_reference" content="citation_journal_title=J Chem Educ; citation_title=Chairs!: a mobile game for organic chemistry students to learn the ring flip of cyclohexane; citation_author=J Winter, M Wentzel, S Ahluwalia; citation_volume=93; citation_issue=9; citation_publication_date=2016; citation_pages=1657-1659; citation_doi=10.1021/acs.jchemed.5b00872; citation_id=CR54"/>

    <meta name="citation_reference" content="Woolley J, Sheeley J, Sheeley S (2010) Organic molecule game. 
                    http://chem.illinois.edu/omg/index.html
                    
                  . Accessed 26 May 2017"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Surg; citation_title=Virtual reality simulators and training in laparoscopic surgery; citation_author=E Yiannakopoulou, N Nikiteas, D Perrea, C Tsigris; citation_volume=13; citation_publication_date=2015; citation_pages=60-64; citation_doi=10.1016/j.ijsu.2014.11.014; citation_id=CR56"/>

    <meta name="citation_author" content="Bosede Iyiade Edwards"/>

    <meta name="citation_author_email" content="bosede@imagineeringinstitute.org"/>

    <meta name="citation_author_institution" content="Imagineering Institute, Iskandar Puteri, Malaysia"/>

    <meta name="citation_author_institution" content="City, University of London, London, UK"/>

    <meta name="citation_author" content="Kevin S. Bielawski"/>

    <meta name="citation_author_email" content="kevin@imagineeringinstitute.org"/>

    <meta name="citation_author_institution" content="Imagineering Institute, Iskandar Puteri, Malaysia"/>

    <meta name="citation_author_institution" content="City, University of London, London, UK"/>

    <meta name="citation_author" content="Rui Prada"/>

    <meta name="citation_author_email" content="rui.prada@tecnico.ulisboa.pt"/>

    <meta name="citation_author_institution" content="Instituto Superior T&#233;cnico, Universidade de Lisboa, Lisbon, Portugal"/>

    <meta name="citation_author" content="Adrian David Cheok"/>

    <meta name="citation_author_email" content="adrian@imagineeringinstitute.org"/>

    <meta name="citation_author_institution" content="Imagineering Institute, Iskandar Puteri, Malaysia"/>

    <meta name="citation_author_institution" content="City, University of London, London, UK"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-018-0345-4&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2019/12/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-018-0345-4"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Haptic virtual reality and immersive learning for enhanced organic chemistry instruction"/>
        <meta property="og:description" content="Human–Computer interaction, including technology-aided instruction, is beginning to focus on virtual reality (VR) technology due to its ability to support immersive learning, teaching through simulation, and gamification of learning. These systems can deliver high-level multisensory learning experiences that are important in the teaching of many subjects, especially those involving abstract concepts or requiring spatial skills, such as organic chemistry. Haptic experiences with VR, however, remain a challenge. In addition, development has focused on general entertainment/gaming; VR systems in chemistry implement simulations of the chemistry laboratory and other advanced systems whereas those that support safe, game-like, immersive and multisensory learning of organic chemistry with haptics at pre-university education levels are scarce. We developed the VR Multisensory Classroom (VRMC) as an immersive learning environment within a VR head-mounted display, where learners employ hand movements to build hydrocarbon molecules and experience haptic feedback through gloves with built-in sensors and hand-tracking with the Leap Motion system. We report here the evaluation of the first prototype by learners from diverse backgrounds who reported on the ability of the VRMC to support high engagement, motivation, interest and organic chemistry learning as well as diverse learning styles. The VRMC is a novel VR classroom that supports immersive learning in molecular organic chemistry with haptics for multisensory learning."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Haptic virtual reality and immersive learning for enhanced organic chemistry instruction | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-018-0345-4","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Virtual reality, Immersive learning, Haptics, Chemistry education, Organic chemistry, Hydrocarbons, Middle school science, Introductory chemistry, Hands-on learning, Gamification","kwrd":["Virtual_reality","Immersive_learning","Haptics","Chemistry_education","Organic_chemistry","Hydrocarbons","Middle_school_science","Introductory_chemistry","Hands-on_learning","Gamification"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-018-0345-4","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-018-0345-4","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-b0018c9f69.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-c02f1b37f0.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=345;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-018-0345-4">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Haptic virtual reality and immersive learning for enhanced organic chemistry instruction
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-018-0345-4.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-018-0345-4.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">S.I. : VR in Education</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2018-06-15" itemprop="datePublished">15 June 2018</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Haptic virtual reality and immersive learning for enhanced organic chemistry instruction</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Bosede_Iyiade-Edwards" data-author-popup="auth-Bosede_Iyiade-Edwards" data-corresp-id="c1">Bosede Iyiade Edwards<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Imagineering Institute" /><meta itemprop="address" content="Imagineering Institute, Medini Mall, 79200, Iskandar Puteri, Johor, Malaysia" /></span><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="City, University of London" /><meta itemprop="address" content="grid.28577.3f, 0000 0004 1936 8497, City, University of London, Northampton Square, Clerkenwell, London, EC1V 0HB, UK" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Kevin_S_-Bielawski" data-author-popup="auth-Kevin_S_-Bielawski">Kevin S. Bielawski</a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Imagineering Institute" /><meta itemprop="address" content="Imagineering Institute, Medini Mall, 79200, Iskandar Puteri, Johor, Malaysia" /></span><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="City, University of London" /><meta itemprop="address" content="grid.28577.3f, 0000 0004 1936 8497, City, University of London, Northampton Square, Clerkenwell, London, EC1V 0HB, UK" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Rui-Prada" data-author-popup="auth-Rui-Prada">Rui Prada</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Universidade de Lisboa" /><meta itemprop="address" content="grid.9983.b, 0000 0001 2181 4263, Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Adrian_David-Cheok" data-author-popup="auth-Adrian_David-Cheok">Adrian David Cheok</a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Imagineering Institute" /><meta itemprop="address" content="Imagineering Institute, Medini Mall, 79200, Iskandar Puteri, Johor, Malaysia" /></span><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="City, University of London" /><meta itemprop="address" content="grid.28577.3f, 0000 0004 1936 8497, City, University of London, Northampton Square, Clerkenwell, London, EC1V 0HB, UK" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 23</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">363</span>–<span itemprop="pageEnd">373</span>(<span data-test="article-publication-year">2019</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">1277 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">7 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-018-0345-4/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Human–Computer interaction, including technology-aided instruction, is beginning to focus on virtual reality (VR) technology due to its ability to support immersive learning, teaching through simulation, and gamification of learning. These systems can deliver high-level multisensory learning experiences that are important in the teaching of many subjects, especially those involving abstract concepts or requiring spatial skills, such as organic chemistry. Haptic experiences with VR, however, remain a challenge. In addition, development has focused on general entertainment/gaming; VR systems in chemistry implement simulations of the chemistry laboratory and other advanced systems whereas those that support safe, game-like, immersive and multisensory learning of organic chemistry with haptics at pre-university education levels are scarce. We developed the VR Multisensory Classroom (VRMC) as an immersive learning environment within a VR head-mounted display, where learners employ hand movements to build hydrocarbon molecules and experience haptic feedback through gloves with built-in sensors and hand-tracking with the Leap Motion system. We report here the evaluation of the first prototype by learners from diverse backgrounds who reported on the ability of the VRMC to support high engagement, motivation, interest and organic chemistry learning as well as diverse learning styles. The VRMC is a novel VR classroom that supports immersive learning in molecular organic chemistry with haptics for multisensory learning.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Science, technology, engineering, and mathematics (STEM) education has become a key concept in basic education across the world, due to its pivotal nature to the learning of other subjects and its fundamental role in science and technological development of any nation. Increased funding, extensive research and development of learning technologies, including several multimedia systems, and pedagogical interventions in the delivery of STEM instruction continue with the principal aim of increasing performance in STEM subjects.</p><p>Multimedia learning systems have, however, focused largely on the visual and auditory senses to the exclusion of others like haptics and olfactory senses, thereby reducing the additional advantages that focusing on these extra senses can deliver. Technology use in education had evolved over the years, and it is beginning to focus on virtual reality (VR) technology due to its ability to support immersive and collaborative learning (Christou <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Christou C (2010) Virtual reality in education. Education. &#xA;                    https://doi.org/10.4018/978-1-60566-940-3.ch012&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR6" id="ref-link-section-d93017e493">2010</a>; Monahan et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Monahan T, McArdle G, Bertolotto M (2008) Virtual reality for collaborative e-learning. Comput Educ 50(4):1339–1353. &#xA;                    https://doi.org/10.1016/j.compedu.2006.12.008&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR36" id="ref-link-section-d93017e496">2008</a>) and teaching through simulation (Hamid et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Hamid NSS, Aziz FA, Azizi A (2014) Virtual reality applications in manufacturing system. In: Proceedings of 2014 science and information conference, SAI 2014. pp 1034–1037. &#xA;                    https://doi.org/10.1109/SAI.2014.6918317&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR18" id="ref-link-section-d93017e499">2014</a>; Mujber et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Mujber T, Szecsi T, Hashmi M (2004) Virtual reality applications in manufacturing process simulation. J Mater Process Technol 155156:1834–1838. &#xA;                    https://doi.org/10.1016/j.jmatprotec.2004.04.401&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR37" id="ref-link-section-d93017e502">2004</a>), and gaming (Choi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Choi S, Jung K, Noh SD (2015) Virtual reality applications in manufacturing industries: past research, present findings, and future directions. Concur Eng Res Appl 23(1):40–63. &#xA;                    https://doi.org/10.1177/1063293X14568814&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR5" id="ref-link-section-d93017e505">2015</a>). VR is considered the next frontier of computer interaction (Fildes <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Fildes N (2015, December) 2016 set to be year virtual reality takes off. Raconteur. &#xA;                    https://www.raconteur.net/technology/2016-set-to-be-year-virtual-reality-takes-off&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR15" id="ref-link-section-d93017e509">2015</a>); it is employed in various types of training programmes (Farra et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Farra SL, Miller ET, Hodgson E (2015) Virtual reality disaster training: translation to practice. Nurse Educ Pract 15(1):53–57. &#xA;                    https://doi.org/10.1016/j.nepr.2013.08.017&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR14" id="ref-link-section-d93017e512">2015</a>; Yiannakopoulou et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Yiannakopoulou E, Nikiteas N, Perrea D, Tsigris C (2015) Virtual reality simulators and training in laparoscopic surgery. Int J Surg 13:60–64. &#xA;                    https://doi.org/10.1016/j.ijsu.2014.11.014&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR56" id="ref-link-section-d93017e515">2015</a>) and it is specifically useful for supporting effective approaches to learner engagement and motivation (Buckley and Doyle <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Buckley P, Doyle E (2016) Gamification and student motivation. Interact Learn Environ 24(6):1162–1175. &#xA;                    https://doi.org/10.1080/10494820.2014.964263&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR3" id="ref-link-section-d93017e518">2016</a>; Kuo and Chuang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Kuo MS, Chuang TY (2016) How gamification motivates visits and engagement for online academic dissemination: an empirical study. Comput Hum Behav 55:16–27. &#xA;                    https://doi.org/10.1016/j.chb.2015.08.025&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR26" id="ref-link-section-d93017e521">2016</a>). In fields like chemistry, where learners have to engage spatial skills (Dünser et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Dünser A, Steinbügl K, Kaufmann H, Glück J (2006) Virtual and augmented reality as spatial ability training tools. In: Proceedings of the 6th ACM SIGCHI New Zealand chapter’s international conference on Computer-human interaction design centered HCI - CHINZ’06, vol 158, pp 125–132. &#xA;                    https://doi.org/10.1145/1152760.1152776&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR11" id="ref-link-section-d93017e524">2006</a>; Hauptman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Hauptman H (2010) Enhancement of spatial thinking with virtual spaces 1.0. Comput Educ 54(1):123–135. &#xA;                    https://doi.org/10.1016/j.compedu.2009.07.013&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR19" id="ref-link-section-d93017e528">2010</a>), VR can deliver outstanding advantages as educational technology and/or learning environment. In particular, it can support the visualization of abstract concepts like atoms, molecules, bonds, and others within an immersive environment.</p><p>Though several 3D applications exist for teaching chemistry, those that take advantage of haptics to improve multisensory learning are scarce and those that combine haptics with 3D in an immersive environment are much rarer. Such systems can deliver great advantages in chemistry education, especially in the learning of spatial orientations of organic molecules. The immersive environment can foster increased motivation, engagement and interest in chemistry as a subject (Mei and Sheng <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Mei HH, Sheng LS (2011) Applying situated learning in a virtual reality system to enhance learning motivation. Int J Inf Educ Technol 1(4):298–302. &#xA;                    https://doi.org/10.7763/IJIET.2011.V1.48&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR29" id="ref-link-section-d93017e534">2011</a>), thereby increasing the interest of high school learners in STEM subjects. Leveraging VR with haptics for the teaching of chemistry can represent a novel approach to chemistry education; and a facilitating tool for tangible and multisensory instruction in a highly motivating learning environment. When properly designed, it can support more effective multimedia instruction and collaborative learning than non-immersive, or 3D systems offering physical tangibility.</p><p>We are interested in chemistry as a key STEM subject due to its place as a link to entry and performance in several fields, including engineering, medicine, pharmacy, bio-technology, and many others. More specifically, our focus is on organic chemistry instruction, and how novel technologies can be leveraged for addressing concepts which continue to constitute a challenge in the learning of structure and bonding in organic molecules. In this paper, we describe the VR multisensory Classroom (VRMC), a chemistry classroom with haptics in VR for the teaching of basic hydrocarbon bonding and molecule formation, considered as initial step in the understanding of more complex molecules. We also report findings from the initial evaluation of the system.</p><p>Our project focuses on the design and development of an immersive, haptic VR system for teaching basic hydrocarbon bonding and molecular structures in organic chemistry. Within the VRMC environment, learners can ‘touch’ atoms and bonds, view them in 3D space and bring them together to form molecules. They can also view the spatial distribution of molecules so formed, thereby experiencing the real-ness of concepts learnt in 2D classrooms. This can be extended to the learning of other chemistry concepts like structural and conformational isomerism as well as other relevant topics like periodicity, and atomic structures in inorganic chemistry. In this paper, we focus on an implementation and evaluation of the VRMC system. Though, for the design, we focus on basic organic chemistry, this represents only one of several uses that the system can be designed for; our report will, therefore, exclude issues of content, pedagogy, or learning strategies.</p><p>The remainder of this paper is divided into six sections: Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0345-4#Sec2">2</a> discusses related works and state-of-the-art in haptic VR for learning, while Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0345-4#Sec6">3</a> presents a discussion of the underpinning theory and instructional systems design (ISD) for the VRMC system in addition to description of the general features of the system. In Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0345-4#Sec10">4</a>, we report the initial evaluations of the VRMC, describing the procedure and methodology employed. We present findings from the evaluation in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0345-4#Sec14">5</a>, and a brief discussion section in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0345-4#Sec18">6</a>. Conclusions, implications of study and our future plans are outlined in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0345-4#Sec19">7</a>.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">State of the art</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Immersive learning with VR</h3><p>Immersiveness is described as ‘seeming to surround the audience, player…so that they feel completely involved in something’ (Cambridge Dictionary <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Cambridge Dictionary (2017) Definition of immersive. Cambridge Dictionary. Cambridge University Press. &#xA;                    http://dictionary.cambridge.org/dictionary/english/immersive&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR4" id="ref-link-section-d93017e578">2017</a>) or ‘providing, involving, or characterized by deep absorption or immersion in something (such as an activity or a real or artificial environment)’ (Merriam Webster Dictionary <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Merriam Webster Dictionary (2017) Definition of IMMERSIVE. Retrieved from &#xA;                    https://www.merriamwebster.com/dictionary/immersive&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR31" id="ref-link-section-d93017e581">2017</a>). Immersion describes the experience of ‘presence’ or feelings of ‘being there’ usually associated with games (Sanders and Cairns <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Sanders T, Cairns P (2010) Time perception, immersion and music in videogames. In: Proceedings of the 24th BCS interaction specialist group conference, pp 160–167" href="/article/10.1007/s10055-018-0345-4#ref-CR43" id="ref-link-section-d93017e584">2010</a>) and VR (Mestre and Vercher <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Mestre D, Vercher J-L (2011) Immersion and presence. In: Virtual reality: concepts and technologies. pp 81–96. &#xA;                    http://www.ism.univmed.fr/mestre/projects/virtualreality/Pres_2005.pdf&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR32" id="ref-link-section-d93017e587">2011</a>; Tuveri et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Tuveri E, Macis L, Sorrentino F, Spano LD, Scateni R (2016) Fitmersive games: fitness gamification through immersive VR. In Proceedings of the international working conference on advanced visual interfaces-AVI’16. pp 212–215. &#xA;                    https://doi.org/10.1145/2909132.2909287&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR50" id="ref-link-section-d93017e590">2016</a>). It implies a heightened sense of enjoyment (Sanders and Cairns <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Sanders T, Cairns P (2010) Time perception, immersion and music in videogames. In: Proceedings of the 24th BCS interaction specialist group conference, pp 160–167" href="/article/10.1007/s10055-018-0345-4#ref-CR43" id="ref-link-section-d93017e594">2010</a>) that promotes engagement and the ‘flow’ experience (Nakamura and Csikszentmihalyi <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Nakamura J, Csikszentmihalyi M (2009) Flow theory and research. Oxf Handb Posit Psychol. &#xA;                    https://doi.org/10.1093/oxfordhb/9780195187243.013.0018&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR38" id="ref-link-section-d93017e597">2009</a>; Whitson and Consoli <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Whitson C, Consoli J (2009) Flow theory and student engagement. J Cross-Discip Perspect Educ 2(1):40–49. &#xA;                    http://jcpe.wmwikis.net/file/view/whitsonconsoli.pdf&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR52" id="ref-link-section-d93017e600">2009</a>). Within VR environments, the user is completely removed from all other forms of visual engagement and the focus on the virtual environment is almost total. The main theme of immersion is reality or its simulation of it, in manners that get the user completely involved or absorbed. The significance for learning, in terms of learner engagement, cannot be overemphasized. Immersion is, therefore, a major aim of instructional design and facilitation and should also be a key focus in pedagogy or educational technology selection. Though VR systems are increasingly available across various fields, the systems mostly focus on games and entertainment rather than as subject-focused educational technologies. The time is, therefore, ripe for more developmental efforts to focus on haptic VR systems that are dedicated to the teaching of various subjects.</p><h3 class="c-article__sub-heading" id="Sec4">Haptic multimedia and VR systems</h3><p>Touch or haptics is one of the vital ways we discover the world around us; it is a key non-verbal means of communication that can promote meaningful and active learning. However, haptics in learning is currently largely untapped (Minogue and Jones <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Minogue J, Jones MG (2006) Haptics in education: exploring an untapped sensory modality. Rev Educ Res 76(3):317–348. &#xA;                    https://doi.org/10.3102/00346543076003317&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR33" id="ref-link-section-d93017e611">2006</a>). Progress in the development of multimedia systems has given birth to several 3D and VR systems; however, those that combine haptics with multimedia experiences are scarce. Virtual learning systems in chemistry have been reported in some studies. The virtual auto-titrator (Ritter and Johnson <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Ritter D, Johnson M (1997) Virtual titrator: a student-oriented instrument. J Chem Educ 74(1):120. &#xA;                    https://doi.org/10.1021/ed074p120&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR42" id="ref-link-section-d93017e614">1997</a>) allows the user to manipulate auto-generated pH data in spreadsheets and obtain pH curves to determine titration endpoints on a graphical output. Winkelmann et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Winkelmann K, Scott M, Wong D (2014) A study of high school students’ performance of a chemistry experiment within the virtual world of second life. J Chem Educ 91(9):1432–1438. &#xA;                    https://doi.org/10.1021/ed500009e&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR53" id="ref-link-section-d93017e617">2014</a>) reported on students’ activity on an experiment in VR on Second Life, noting positive student perception that supports virtual laboratories as feasible alternatives to real ones. Stone (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Stone DC (2007) Teaching chromatography using virtual laboratory exercises. J Chem Educ 84(9):1488–1495. &#xA;                    https://doi.org/10.1021/ed084p1488&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR47" id="ref-link-section-d93017e620">2007</a>) also demonstrated the ability of virtual chemistry systems to support the reinforcement of the connections between classroom learning of chemistry principles and real-life applications, as well as to support self-paced independent learning using chromatography with virtual laboratory exercises. These systems do not employ haptics in their design, thereby failing to leverage the advantages of higher multisensory capabilities for improved learning. A major gap in general multimedia or VR technology in education thus remains those that combine haptics with immersive experience as the integration of haptics in VR remains a key challenge.</p><p>Currently available VR systems are mostly commercial applications and games, employing mostly hardware input. Axon (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Axon VR (2017) Virtual reality you can feel. &#xA;                    https://axonvr.com/#haptx-haptics-evolved&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR1" id="ref-link-section-d93017e626">2017</a>) is a haptic textile with feedback for texture, shape, vibration, etc.; it uses one hand for handling input hardware and the second hand for haptic experience. Hardlight suit and Haptx exoskeleton (Axon <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Axon VR (2017) Virtual reality you can feel. &#xA;                    https://axonvr.com/#haptx-haptics-evolved&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR1" id="ref-link-section-d93017e629">2017</a>) are haptic feedback suits designed for gaming and entertainment. Dexmo, a hand haptic device for VR medical education by DextaRobotics (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="DextaRobotics (2018) DextaRobotics builds hand haptics device for virtual reality medical learning. &#xA;                    https://www.healthysimulation.com/9009/dextarobotics-builds-hand-haptics-device-for-virtual-reality-medical-learning/&#xA;                    &#xA;                  . Accessed 16 Mar 2018" href="/article/10.1007/s10055-018-0345-4#ref-CR10" id="ref-link-section-d93017e632">2018</a>) is one of the few, existing, haptic VR learning systems. It uses force feedback to enable user feelings of size and shape, and captures 11 DoF of users’ hand motion. Others like GoTouch VR Team (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="GoTouch VR Team (2017) Go touch VR. Retrieved November 9, 2017. &#xA;                    https://www.gotouchvr.com/&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR17" id="ref-link-section-d93017e635">2017</a>) and Google VR (Google <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Google (2017) Virtual reality for everyone. Retrieved November 9, 2017. &#xA;                    https://vr.google.com/&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR16" id="ref-link-section-d93017e638">2017</a>) are developer systems.</p><h3 class="c-article__sub-heading" id="Sec5">VR and other multimedia systems for organic chemistry instruction</h3><p>Development of VR systems for chemistry education has also grown and some of the systems currently available include MEL Chemistry VR (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Mahatma Chemistry (2017) MEL chemistry VR. &#xA;                    https://melscience.com/vr/&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR28" id="ref-link-section-d93017e649">2017</a>), Chemistry Experiment VR (MEL Chemistry <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Mahatma Chemistry (2017) MEL chemistry VR. &#xA;                    https://melscience.com/vr/&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR28" id="ref-link-section-d93017e652">2017</a>), SuperChem VR (Schell Games <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Schell Games (2017) SuperChem VR. Retrieved June 20, 2017, &#xA;                    https://www.schellgames.com/games/superchem-vr&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR44" id="ref-link-section-d93017e655">2017</a>), and Unimersiv Chemistry VR (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Unimersiv (2016) Chemistry VR. Retrieved June 20, 2017, &#xA;                    https://unimersiv.com/review/chemistry-vr/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR51" id="ref-link-section-d93017e658">2016</a>). These systems focus mostly on simulation of experimental chemistry systems. ‘Chairs!’ (Winter et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Winter J, Wentzel M, Ahluwalia S (2016) Chairs!: a mobile game for organic chemistry students to learn the ring flip of cyclohexane. J Chem Educ 93(9):1657–1659. &#xA;                    https://doi.org/10.1021/acs.jchemed.5b00872&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR54" id="ref-link-section-d93017e661">2016</a>) is a mobile application that teaches cyclohexane chemistry; it employs touchscreen as input. VR systems that focus on organic chemistry are scarce and limited in their capabilities; for example, in Stull et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Stull AT, Barrett T, Hegarty M (2013) Usability of concrete and virtual models in chemistry instruction. Comput Hum Behav 29(6):2546–2556" href="/article/10.1007/s10055-018-0345-4#ref-CR48" id="ref-link-section-d93017e665">2013</a>) a mouse interface is employed for manipulating virtual models. Chemistry VR systems applied as educational technologies and/or learning environments include MEL Chemistry (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Mahatma Chemistry (2017) MEL chemistry VR. &#xA;                    https://melscience.com/vr/&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR28" id="ref-link-section-d93017e668">2017</a>) which supports learning with a view of the molecular world but does not provide haptic experience. Chemistry Experiment VR (Merchant et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Merchant Z, Goetz ET, Keeney-Kennicutt W, Cifuentes L, Kwok O, Davis TJ (2013) Exploring 3-D virtual reality technology for spatial ability and chemistry achievement. J Comput Assist Learn 29(6):579–590. &#xA;                    https://doi.org/10.1111/jcal.12018&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR30" id="ref-link-section-d93017e671">2013</a>) is a VR-based chemistry laboratory for teaching high school experimental chemistry. It simulates haptic experience with ‘triggers’ using hardware. Superchem VR (Schell Games <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Schell Games (2017) SuperChem VR. Retrieved June 20, 2017, &#xA;                    https://www.schellgames.com/games/superchem-vr&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR44" id="ref-link-section-d93017e674">2017</a>) is a similar system that uses HTC Vive for simulating haptics. Unimersiv Chemistry VR (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Unimersiv (2016) Chemistry VR. Retrieved June 20, 2017, &#xA;                    https://unimersiv.com/review/chemistry-vr/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR51" id="ref-link-section-d93017e677">2016</a>) focuses on the periodic table and uses a cardboard magnet for simulating haptics. Devpost’s Chemistry Lab VR (Smith et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Smith C, Agcaoili K, Kannan A (2016) Chemistry Lab VR. Retrieved May 20, 2017, &#xA;                    https://devpost.com/software/chemistry-lab-vr&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR45" id="ref-link-section-d93017e680">2016</a>) is a simulation of lab procedure with important safety instruction; it also uses hardware input through HTC Vive for haptics. Molecular Rift (Norrby et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Norrby M, Grebner C, Eriksson J, Bostrom J (2015) Molecular rift: virtual reality for drug designers. J Chem Inf Model 55(11):2475–2484. &#xA;                    https://doi.org/10.1021/acs.jcim.5b00544&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR39" id="ref-link-section-d93017e684">2015</a>) simulates an advanced organic chemistry classroom with haptic VR, and it is designed for molecular visualization in drug design. It is the only one of the systems that employs direct hand manipulation rather than hardware. The need for an immersive VR system that employs direct hand manipulation in the teaching of basic organic chemistry thus becomes strong. A system that focuses on basic chemistry can help to address the challenge of beginner organic chemistry learners, thereby supporting the building of a strong foundation. We designed the VRMC, with a focus on teaching the nature and forms of bonding in hydrocarbon molecules.</p></div></div></section><section aria-labelledby="Sec6"><div class="c-article-section" id="Sec6-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec6">The VRMC</h2><div class="c-article-section__content" id="Sec6-content"><h3 class="c-article__sub-heading" id="Sec7">Theoretical framework and ISD</h3><p>Gamifying organic chemistry has been conceived by chemistry teachers as a tool to solve students’ problems with learning the subject. Examples of chemistry game systems include ‘Organic Molecule Game’ (Woolley et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Woolley J, Sheeley J, Sheeley S (2010) Organic molecule game. &#xA;                    http://chem.illinois.edu/omg/index.html&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR55" id="ref-link-section-d93017e700">2010</a>), ‘Fastest Fingers’ (Eastwood <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Eastwood ML (2013) Fastest fingers: a molecule-building game for teaching organic chemistry. J Chem Educ 90(8):1038–1041. &#xA;                    https://doi.org/10.1021/ed3004462&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR12" id="ref-link-section-d93017e703">2013</a>), ‘React!’ (React! Team <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="React! Team (2017) React! the organic chemistry board game. Retrieved June 22, 2017, &#xA;                    http://reactgame.com/#/&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR41" id="ref-link-section-d93017e706">2017</a>), and ‘Chairs!’ (Winter et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Winter J, Wentzel M, Ahluwalia S (2016) Chairs!: a mobile game for organic chemistry students to learn the ring flip of cyclohexane. J Chem Educ 93(9):1657–1659. &#xA;                    https://doi.org/10.1021/acs.jchemed.5b00872&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR54" id="ref-link-section-d93017e709">2016</a>). All these systems focus on the creation of game-like experiences which support learning through trial-and-error during play. This model is adopted in the design of the VRMC system. In addition, prior to the current extensive use of modern technologies in teaching and learning to simulate real-life application environments, it has been demonstrated that hands-on learning significantly affects attitudes toward science (Ornstein <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Ornstein A (2006) The frequency of hands-on experimentation and student attitudes toward science: a statistically significant relation (2005-51-ornstein). J Sci Educ Technol 15(3–4):285–297. &#xA;                    https://doi.org/10.1007/s10956-006-9015-5&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR40" id="ref-link-section-d93017e712">2006</a>) and science achievement (Stohr-Hunt <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Stohr-Hunt PM (1996) An analysis of frequency of hands-on experience and science achievement. J Res Sci Teach 33(1):101–109. &#xA;                    https://doi.org/10.1002/(SICI)1098-2736(199601)33:1&lt;101::AID-TEA6&gt;3.0.CO;2-Z&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR46" id="ref-link-section-d93017e716">1996</a>). The significance of hands-on or experiential learning has also informed several pedagogical approaches including service, problem-based and scenario-based learning, as well as science laboratory activities. The development of the VRMC is based on the significance and focus of experiential learning theory (ELT) as described by Kolb et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Kolb DA, Boyatzis RE, Mainemelis C (2000) Experiential learning theory: previous research and new directions. Perspect Think Learn Cognit Styl 1(216):227–247. &#xA;                    https://doi.org/10.5465/AMLE.2005.17268566&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR25" id="ref-link-section-d93017e719">2000</a>), which addresses four concepts (Kolb and Kolb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Kolb AY, Kolb DA (2005) The Kolb learning style inventory—version 3.1 2005 technical specifications. LSI Technical Manual, pp 1–72. &#xA;                    https://doi.org/10.1016/S0260-6917(95)80103-0&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR24" id="ref-link-section-d93017e722">2005</a>). These are captured as abstract conceptualization (AC), that is, the generation of evidence from ideas and theories rather than from concrete examples and Concrete experience (CE), referring to being involved in a new experience. Reflective Observation (RO) is linked to personal experience or the experience of others as basis for developing observations while Active Experimentation (AE) involves using theories as a basis for problem-solving or decision-making.</p><p>The design of the VRMC is informed by these concepts, hence we developed an immersive learning environment where learners can build hydrocarbon molecules using hand motions, thereby taking advantage of learning through seeing, ‘touching’ (AC, CE), and bringing the abstract carbon and hydrogen ‘atoms’ together to form bonds (AC, RO), thus creating different types of hydrocarbon molecules (RO, AE). This experience of ‘touching’, ‘taking’, and ‘making’ plays significant roles in learning and describes the four elements (AC, CE, RO and AE) of ELT. Within the VRMC, abstract concepts like atoms, bonds, and molecules take ‘concrete forms’ and can be seen and touched due to the haptic sensory capability of the system. In this way, the generation of evidence becomes based on both theory and ‘concrete examples’ (AC), and the learners have novel experiences (CE) that form the basis of problem-solving or decision making (RO). In essence, the elements of ELT get new meanings. The VRMC system is thus designed to support game-like approach to learning through building of organic molecules.</p><p>Approaches to ISD have been described in the literature (Heinich et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Heinich R, Molenda M, Russell J, Smaldino S (2002) The ASSURE model. In Instructional media and technologies for learning, vol 7" href="/article/10.1007/s10055-018-0345-4#ref-CR20" id="ref-link-section-d93017e731">2002</a>; Jong <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Jong T (2009) Cognitive load theory, educational research, and instructional design: some food for thought. Instr Sci 38(2):105–134. &#xA;                    https://doi.org/10.1007/s11251-009-9110-0&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR22" id="ref-link-section-d93017e734">2009</a>; Molenda <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003a" title="Molenda M (2003a) ADDIE model. &#xA;                    http://www.nwlink.com/~donclark/history_isd/addie.html#FSU&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR34" id="ref-link-section-d93017e737">2003a</a>). Most of the models follow a basic framework that identifies the five elements of analysis, design, development, implementation, and evaluation or ADDIE (Culatta <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Culatta R (2013) ADDIE model. Retrieved from &#xA;                    http://www.instructionaldesign.org/models/addie&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR9" id="ref-link-section-d93017e740">2013</a>; Molenda <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003b" title="Molenda (2003b) ADDIE Timeline. The performance juxtaposition site. Retrieved from &#xA;                    http://www.nwlink.com/~donclark/history_isd/addie.html#FSU&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR35" id="ref-link-section-d93017e743">2003b</a>). Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0345-4#Tab1">1</a> highlights the development of VRMC in line with ADDIE model.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Instructional system design for the VRMC based on ADDIE model</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0345-4/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec8">General features of the VRMC</h3><p>VRMC integrates haptic input and supports multiple advantages for learning through tangible user-interfaces, multisensory instruction, immersive learning, and gamification. The initial system begins with only Carbon and Hydrogen as constituents of the simplest group of organic molecules, popularly known as hydrocarbons (HCs) which can exist as singly, doubly, or triply bonded molecules. We describe here the VRMC interface and VR environment, the atoms, the bonding process, and the interaction and feedback in the system. We also provide a brief description of the basic modifications made in upgrading the initial system to the first tested version.</p><p>The VRMC system consists of an Android phone in a VR headset with a Leap Motion controller and haptic gloves. The system is controlled by a computer running Unity. A secondary display allows the observers to see a rendering of the VR environment. The carbon and hydrogen atoms are shown as semi-transparent black and blue spheres, respectively. Different hydrocarbon molecules with single, double, and triple bonds can be made from the atoms and bonds. The user can also call for more atoms of carbon or hydrogen by ‘pressing’ the respective virtual buttons provided in the system. The VRMC environment with Ethyne (C<sub>3</sub>H<sub>3</sub>), the first member of the triply bonded series, is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig1">1</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig1_HTML.png?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig1_HTML.png" alt="figure1" loading="lazy" width="685" height="355" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>The VRMC with the triply bonded ethyne has some features to control the game and guide the user in the creation of molecules</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>The system implements three virtual buttons, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig1">1</a>. The virtual button to the upper right side of the screen is used to check what molecule was made. It provides the user with feedback on whether a correct molecule was made or not and displays the name of the molecule. The virtual button to the upper left enables the user to add additional hydrogen atoms when needed for the creation of a molecule, while the virtual button to the lower right enables the user to add additional carbon atoms. A list of all atoms made by the user is shown at the bottom left corner of the screen. Feedback is provided as points gained by the player (user/learner) when bonds are successfully and correctly formed. Each correct bond attracts two points which is added to user scores. Current points are displayed at the top left of the work area in the VR environment. The system can be modified to include other types of atoms and to create different levels of task difficulty which can be made to correspond to varying levels of gaming experience.</p><p>Bonds between molecules are formed by grabbing an atom, bringing it into contact with another atom, then releasing it. Multiple bonds are formed by ‘hitting’ the atoms multiple times (twice for double bonds and thrice for triple bonds). The semi-transparent nature of the atoms makes it possible to view the spatial tetrahedral orientation of the C atoms at the actual 109.5°. Electrons available for bonding are shown as coloured spots on the semi-transparent black carbon atoms. The spots are replaced by the bonds formed and become hidden after bonding. Visual and haptic feedback clues are provided to users to facilitate ease in building molecules. When the atom is ready to be moved, atoms change colour and the user experiences a haptic response in form of vibration so the user is given two forms of feedback that they can move the atom. While interacting with other atoms, the atom again changes colour with different haptic responses so the user can sense that a bond is ready to be made. The system comes with a pair of haptic gloves for providing input from and feedback to the user in conjunction with the Leap Motion system (Leap Motion <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Leap Motion (2017) Reach into Virtual Reality with your bare hands. &#xA;                    https://www.leapmotion.com/#112&#xA;                    &#xA;                  . Accessed 26 May 2017" href="/article/10.1007/s10055-018-0345-4#ref-CR27" id="ref-link-section-d93017e897">2017</a>) as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig2">2</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig2_HTML.png?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig2_HTML.png" alt="figure2" loading="lazy" width="685" height="416" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>The VRMC system showing a user with different components of the system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec9">Hardware implementation and user interface design</h3><p>A flex sensor continually measures if the user is grasping for an atom, and vibration motors at each fingertip provide feedback to the user. Signals for the flex sensor and vibration motors are controlled from an Arduino using a serial connection to the computer. The haptic glove consists of coin-type vibration motors at the finger tips, and a flex sensor along the middle finger. The motors and the sensor are connected to Arduino for control. The Arduino device communicates with the game through the serial port of a PC. The flex sensor enables precise monitoring of finger position, regardless of the orientation of the hand. This enhances the user experience, because the detection of grasping with Leap Motion can often create frustrating experiences. The haptic glove system with the flex sensor is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig3">3</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig3_HTML.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig3_HTML.jpg" alt="figure3" loading="lazy" width="685" height="256" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>The haptic gloves provide feedback to the users through coin-type vibration motors and the gloves contain a sensor to monitor the grasping of virtual atoms</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>User-interface design provides opportunities for user-manipulation modelled after existing GUI systems, including laptops, mobile phones, and tablets, which feature either physical or touch-enabled ‘buttons’ to aid input. In designing the game-like virtual environment of VRMC, the system starts with minimal (2) number of atoms necessary for building a molecule, but with the possibility of the user getting more atoms if/when required. To achieve this, we implemented two buttons named ‘Another Hydrogen’ and ‘Another Carbon’. User feedback is central in digital game design as well as in learning; hence, building of correct/incorrect molecule can be checked by users through the ‘Check Molecule’ button which is followed by relevant feedback from the system.</p></div></div></section><section aria-labelledby="Sec10"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Evaluation of the VRMC system</h2><div class="c-article-section__content" id="Sec10-content"><p>User perceptions are central to determining future user experience and usability of various systems (Hyun et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Hyun EHE, Yoon HYH, Son SSS (2010) Relationships between user experiences and children’s perceptions of the education robot. In: Human-robot interaction (HRI), 2010 5th ACM/IEEE international conference on, pp 199–200. &#xA;                    https://doi.org/10.1109/HRI.2010.5453197&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR21" id="ref-link-section-d93017e960">2010</a>). The initial system evaluation was aimed at providing feedback on user perception, usability of the system and its adequacy for instructional purposes. Findings from the study were meant to answer the broad question: what are users’ perceptions on the application of VRMC as an instructional tool for organic chemistry. The assessment is linked to the theoretical basis of VRMC’s development; hence, we focus on assessment of the system’s ability to support haptics (AC, CE), motivation/engagement (RO, AE), its ability to support collaborative learning and to serve as an instructional tool for organic chemistry, (CE, RO), and for the teaching of bonding through hands-on activities (AE, RO). We are also interested in the necessary improvement needs based on user experience.</p><p>The study engages a mixed design, that is, a combination of quantitative and qualitative approaches (Creswell <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Creswell JW (2014) Research design: qualitative, quantitative and mixed approaches, 4th edn. &#xA;                    https://doi.org/10.2307/1523157&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR7" id="ref-link-section-d93017e966">2014</a>), based on its ability to support richer feedback. Thus, a quantitative survey, and qualitative open-ended responses, and observations are employed in the study. Mixed approaches can employ any of sequential (qualitative after quantitative data collection or vice versa), nested (qualitative during quantitative data collection or vice versa), or concurrent (single-phase or quantitative and qualitative data collection in parallel) designs. We used the concurrent design, based on its ability to support complimentary results (Bazeley <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Bazeley P (2010) Book Review: V. L. Plano Clark and J. W. Creswell (Eds.) The Mixed Methods Reader. Thousand Oaks, CA: SAGE, 2008, 617 pp. Supplied by Footprint Books, AU$79 (paperback). J Mix Methods Res 4(1):79–81. &#xA;                    https://doi.org/10.1177/1558689809356926&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR2" id="ref-link-section-d93017e969">2010</a>) as both types of data are given equal weights and are obtained within the same time frame (Creswell and Plano Clark <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Creswell JW, Plano Clark VL (2007) Choosing a mixed method design. In: Designing and conducting mixed methods research. SAGE Publications, Inc, pp 58–89. ISBN: 1412927927" href="/article/10.1007/s10055-018-0345-4#ref-CR8" id="ref-link-section-d93017e972">2007</a>).</p><h3 class="c-article__sub-heading" id="Sec11">Participants and study details</h3><p>Learners and teachers are the key stakeholders in any learning environment and their feedback is central to the usability or effectiveness of any instructional system or technology. Our samples, therefore, consist of individuals across a wide age range but all participants assessed the VRMC from a learners’ viewpoint. We sampled 13 users (7 females, 6 males), aged 12–36 years, including a chemistry teacher. This range of users can provide information on the utility and user experience with the VRMC as an instructional tool for individuals with different levels of familiarity with organic chemistry. Each participant wears the VR gear and experiences the VRMC learning environment (LE). They were guided to explore the GUI and to carry out simple activities of building molecules using the bonds and the carbon and hydrogen atoms available within the LE.</p><h3 class="c-article__sub-heading" id="Sec12">Briefing</h3><p>Participants were provided with an information sheet detailing the study procedure and requesting their informed consent before they participated in the study. The document provides game rules as the basics of hydrocarbon chemistry and how to build molecules, with an example shown for methane (CH<sub>4</sub>). Participants were then expected to build molecules of their choice, ensuring that the conditions of bonding in carbon are fully satisfied in each case. Molecules built can be confirmed as (in)correct by ‘pressing’ a virtual button labelled ‘check molecule’ on the upper right section of the system. If there was more than one molecule in the system, the user will ‘press’ the ‘check molecule’ button and then touch the molecule to be checked. The system responds with statements like ‘You have built methane!’ Following the interaction session, the participants complete the short survey.</p><h3 class="c-article__sub-heading" id="Sec13">Instrumentation and procedure</h3><p>Quantitative evaluation was based on a mini-survey while qualitative evaluations employed open-ended responses and participant observation during trial sessions with the system. We developed the mini-survey to capture the factors that are important regarding our system, as discussed above; hence, it assesses six characteristics, including (i) users’ overall perception of the system, (ii) perception of haptics and experience of multisensory learning, (iii) experience of motivation, interest and engagement, and (iv) adequacy of the system for general and chemistry education. Participants rated each item as one of the five options including ‘very low’, ‘low’, ‘medium’, ‘high’, and ‘very high’. The internal consistency reliability of the mini-survey instrument based on Cronbach’s alpha, <i>α</i>, is 0.92, this is a measure of ‘scale reliability’ or how closely related the set of items in the instrument are as a group. A high Cronbach’s alpha value (0.70–0.99) shows that an instrument is a reliable measure. The ‘Cronbach’s alpha if items deleted’ values for all items of our mini-survey were between 0.91 and 0.92, that is, similar to the Cronbach’s alpha of the whole scale, and implying that item deletion will not improve the internal consistency of the instrument in any significant way. Hence, we used all the items in the instrument.</p><p>Participants’ open-ended responses were designed to capture additional user comments and/or recommendations for system improvement. The protocol captured recommendations on seven characteristics, including general design, colour system, touch system, audio, instructional system, the haptic gloves and the design of the atoms. There was also a free-format feedback section for respondents to provide additional information on issues that might not have been captured in other sections.</p><p>Participants were immersed in the VR environment and were eliciting physical responses that are viewable only by observers; certain characteristics, like responses describing motivation, interest or enjoyment of the system, and physical feedback by users are only accessible through observation. Hence, the live observation was intended to achieve what Erlandson et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Erlandson DA, Harris EL, Skipper BL, Allen SD (1993) Doing naturalistic inquiry: a guide to methods. SAGE Publications Inc, Thousand Oaks" href="/article/10.1007/s10055-018-0345-4#ref-CR13" id="ref-link-section-d93017e1010">1993</a>) described as a “written photograph” of the situation being studied. An open (unstructured) protocol was designed to capture a multisensory description of the study in context. The observer records these descriptions as memo entries.</p></div></div></section><section aria-labelledby="Sec14"><div class="c-article-section" id="Sec14-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec14">Results</h2><div class="c-article-section__content" id="Sec14-content"><h3 class="c-article__sub-heading" id="Sec15">Quantitative results</h3><p>The short survey instrument assessed participants’ perceptions of the VRMC usability as an instructional tool based on its support for multisensory learning, haptics, motivation, and engagement. Its adequacy to serve as a learning tool both generally and specifically for chemistry as a subject was also assessed. The results of participants’ evaluations are presented in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig4">4</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig5">5</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig6">6</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig7">7</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig8">8</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig9">9</a>. Participants rating from “Very high” to Very Low” are plotted against the frequency of ratings which are the total number of times a construct is rated out of 52 possible times (13 persons on each of 4 items per construct). Ratings for each of the sub-constructs of multisensory learning, motivation and engagement, and haptics are plotted against frequencies. Participants’ rating of the usefulness of system as an instructional tool and specifically for chemistry instruction is also plotted in addition to participants’ overall rating of the system. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig4">4</a> shows that the system is highly rated in terms of support for multisensory learning. There were 45 high/very high ratings out of a total of 52 with 7 average ratings and no “low” or “very low” ratings, indicating that on the whole, participants have very positive perception of the system in terms of its ability to support multisensory instruction.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig4_HTML.png?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig4_HTML.png" alt="figure4" loading="lazy" width="685" height="312" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Participants’ rating of system’s support for multisensory learning</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig5_HTML.png?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig5_HTML.png" alt="figure5" loading="lazy" width="685" height="317" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Participants’ rating of system’s support for motivation and engagement</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig6_HTML.png?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig6_HTML.png" alt="figure6" loading="lazy" width="685" height="397" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Participants’ rating of system’s support for haptics</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig7_HTML.png?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig7_HTML.png" alt="figure7" loading="lazy" width="685" height="387" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Participants’ rating of adequacy of system as an instructional tool</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig8_HTML.png?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig8_HTML.png" alt="figure8" loading="lazy" width="685" height="358" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Participants’ rating of adequacy of system for chemistry instruction</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig9_HTML.png?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0345-4/MediaObjects/10055_2018_345_Fig9_HTML.png" alt="figure9" loading="lazy" width="685" height="332" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Participants’ rating of overall perception of system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0345-4/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Rating of system’s support for motivation and engagement is similar to that of multisensory learning as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig5">5</a>.</p><p>There were 49 ratings in the high and very high levels with a single low and 5 average. Ratings in the haptics category were more distributed than for other categories as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig6">6</a>, with 33 overall high ratings, 12 average ratings and 7 in the low ratings category. This presents an interesting view, especially with the ability to support haptics being the focus of system development. Though data are still skewed in the direction of high ratings, participants’ perception of the concept of haptics appears more diverse than for other elements. Individual interpretations or expectations of haptic perceptions might have contributed to this feedback. However, this objective is outside the scope of the present study and further investigation of individual’s perception of the ‘haptic’ construct will be required to obtain more information on this.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig7">7</a> presents participants’ perception of the adequacy of the system as an instructional tool. This is a general rating assessing system’s ability to serve as educational technology or instructional material rather than specific use in a subject. Findings in this category were comparable to previous ones with no low ratings and only 2 average ratings. The remaining 50 are in the high categories.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig8">8</a> presents ratings on suitability of system as a tool for chemistry instruction. The chart is similar to ratings of the system as a general instructional tool presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig7">7</a> (above). This feedback shows consistency in participants’ feedback on the system and highlights the reliability of the feedback.</p><p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0345-4#Fig9">9</a>, we present the overall rating of the system. Values are based on the sum of all feedbacks. Distribution of ratings is similar to ratings on the various sub-constructs presented above. There were mostly high ratings (37 of 52), no ‘very low’ and only 6 ‘low’ ratings. The remaining 9 are in the average category. These findings indicate that participants have very positive perception of the system, both based on various elements assessed as well as on its use as learning technology.</p><p>The statistical outputs with mean values and standard deviation are presented with the coefficient of variation (CV) in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0345-4#Tab2">2</a>. CV is a ratio of SD to Mean; it provides a measure of relative variability in the data. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0345-4#Tab2">2</a> shows that all CVs values are within 0.1 and 0.2, that is, variance is low and values are closely dispersed around the mean of the data.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Descriptive statistics for participants’ evaluation of the VRMC</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0345-4/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>The values show that participants’ responses were favourable for the indicators and the system was rated positively in terms of the purpose of its development.</p><h3 class="c-article__sub-heading" id="Sec16">Open-ended feedback</h3><p>All participants found the general design of the system impressive, interesting, and educative. They agreed that the VRMC has potential to serve as an instructional tool and particularly for teaching bonding and structure in organic chemistry. We will consider this in future system upgrades. Participants reported enjoyment and engagement and are confident that an improved version can support improved learning experience.</p><p>The need for more feedback to user (e.g., for identification of atoms and a built-in tutorial) and improved background graphics were noted. Feedback on the colour system was divergent; findings indicate user-preference as a strong factor and the possibility of user-setting for colour in future versions. Major improvement needs were noted regarding the haptic system and the gloves; the need for greater precision and sensitivity to support easier grasping were also reported. Participants also suggested the need for instruction provided as built-in audio (current version has no built-in instruction) with the possibility of a ‘help’ button. The only audio in the current prototype is the sound from the haptic feedback; participants suggested that the introductory tutorial should be deployed in audio format to support more immersive experience and user engagement. Consideration for non-native English speakers was suggested by some users to improve usability.</p><p>Some of the limitations noted by users included the need for built-in audio for instruction and feedback, improved sensitivity and precision of the haptic system, and these items will be considered in the next version. We further noted that enabling repetition at user’s request is also an important factor to be considered in future versions.</p><p>The wired glove connections make wearing the glove and reaching far out with the hands difficult. Almost all participants suggested a lighter, wireless glove system that supports users’ free movement. Atom design was perceived very positively and noted as acceptable by all participants. There were suggestions that labelling the atoms can assist users who might not have a background in chemistry.</p><h3 class="c-article__sub-heading" id="Sec17">Participant observation</h3><p>User’s experience of immersion was noted in their display of enjoyment and interest during observation. There were exclamations when they succeeded in ‘picking’ an atom. A participant was heard saying ‘hey, come here!’ while trying to pick up an atom; another said ‘come on, don’t go’ addressing a ‘falling’ atom. A participant exclaimed, ‘yeah! I made methane!’ when she formed the methane molecule. Overall, live observation of users shows that the system is practical and has the potential to promote improved engagement and motivation of users.</p></div></div></section><section aria-labelledby="Sec18"><div class="c-article-section" id="Sec18-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec18">Discussion</h2><div class="c-article-section__content" id="Sec18-content"><p>The current system is run from the Unity editor, using an Android phone connected with Unity Remote so that the PC can be used with the Leap Motion controller and the haptic gloves. This arrangement requires several wired connections from the headset and gloves to the computer, which imposes limitations on the user. We are planning for future versions to use wireless communication. Furthermore, the game could be modified to be a stand-alone application to eliminate wired connections and make it more suitable for use in a classroom setting; however, this would require different hand-tracking methods. Hand tracking in the current system is limited in volume and it is responsible for ‘dropped’ atoms; this will be improved in future versions. The current system is designed for the basic chemistry of hydrocarbons but it can easily be modified to include other atoms just by creating additional virtual atomic models so that more complex organic molecules can be made to support advanced chemistry instruction. The chemical reactions involved in forming molecules can be simulated in future developments to give students a greater understanding of chemistry.</p><p>In comparison to existing systems, the VRMC demonstrates capabilities not currently available, that is, haptic VR for classroom instruction in basic organic chemistry. Findings from this evaluation highlight the effectiveness of the system as an educational technology and learning environment, highlighting how the immersive experience possible within VR can be augmented with haptics to promote game-like learning with an actual classroom subject. Users’ perception of the system was high and responses in both quantitative and qualitative evaluations show that the VRMC has the potential to support teaching and learning of basic organic chemistry. System evaluation highlights the need for improved technology, wireless connections, and the use of in-built audio presentation of user instructions to further enhance the immersive experience.</p><p>Observation of user experience with the system showed that written instructions were not effective with almost all participants; instructions had to be verbally repeated during trials. Because molecules built remain in the system, they sometimes obstruct visual navigation of the system; hence, we will consider the possibility of a ‘molecule bank’. The system position drifts as user activity progresses, affecting user balance; in addition, initial calibration procedure was not clearly understood by users. We plan to consider more explicit instruction to assist users in manipulating atoms. Overall, qualitative feedback through observation is in line with participants’ feedback from the quantitative results and in spite of the limitations of the current system, there are a lot of room for upgraded versions, and we are confident of significant improvement in future versions.</p></div></div></section><section aria-labelledby="Sec19"><div class="c-article-section" id="Sec19-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec19">Conclusions, implications and future steps</h2><div class="c-article-section__content" id="Sec19-content"><p>The VRMC is a learning system that employs natural hand motion (haptics) for building molecules that use either or both hands for haptic experience in the learning of structure and bonding in organic chemistry in a VR environment. The system integrates the multiple advantages of immersive, multisensory, and tactile learning. According to Koedinger et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Koedinger KR, Kim J, Jia JZ, McLaughlin EA, Bier NL (2015) Learning is not a spectator sport: doing is better than watching for learning from a MOOC. In: Proceedings of the second (2015) ACM conference on learning @ Scale-L@S’15. pp 111–120. &#xA;                    https://doi.org/10.1145/2724660.2724681&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR23" id="ref-link-section-d93017e1413">2015</a>), learning is not a ‘spectator sport’ and, hence, the current emphasis on the concept of ‘learning by doing’ which represents the basis for project- and scenario-based learning. This study is limited by the small size of respondents (<i>n</i> = 13); however, participants represent a diverse group of individuals, and the use of a mixed approach provides complementary and rich feedback to reduce the limitation of single designs using small samples. Qualitative and quantitative data on user experience support system usability to support multisensory learning, engagement, motivation, haptics and usefulness as learning technology.</p><p>Future versions will deploy different levels of gaming to extend the learning content to more topics. The VRMC demonstrates how VR technology is leveraged to provide an immersive learning experience that integrates several effective learning approaches including multimedia and multisensory instruction, haptics, and gamification of learning. The immersive VR environment supports simulation of abstract concepts like atoms and molecules, thereby promoting high engagement, motivation, and interest, which are known to promote enhanced memory (Turk et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Turk DJ, Gillespie-Smith K, Krigolson OE, Havard C, Conway MA, Cunningham SJ (2015) Selfish learning: the impact of self-referential encoding on children’s literacy attainment. Learn Instr 40:54–60. &#xA;                    https://doi.org/10.1016/j.learninstruc.2015.08.001&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0345-4#ref-CR49" id="ref-link-section-d93017e1422">2015</a>). Within the immersive environment, the user is disengaged from physical distraction and the system can thus be useful for addressing the critical problem of learner engagement. In addition, the ability of users to view and touch atoms, molecules and bonds, supports the real-ness of abstracts as well as multisensory instruction.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Axon VR (2017) Virtual reality you can feel. https://axonvr.com/#haptx-haptics-evolved. Accessed 26 May 2017" /><p class="c-article-references__text" id="ref-CR1">Axon VR (2017) Virtual reality you can feel. <a href="https://axonvr.com/%23haptx-haptics-evolved">https://axonvr.com/#haptx-haptics-evolved</a>. Accessed 26 May 2017</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Bazeley, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Bazeley P (2010) Book Review: V. L. Plano Clark and J. W. Creswell (Eds.) The Mixed Methods Reader. Thousand O" /><p class="c-article-references__text" id="ref-CR2">Bazeley P (2010) Book Review: V. L. Plano Clark and J. W. Creswell (Eds.) The Mixed Methods Reader. Thousand Oaks, CA: SAGE, 2008, 617 pp. Supplied by Footprint Books, AU$79 (paperback). J Mix Methods Res 4(1):79–81. <a href="https://doi.org/10.1177/1558689809356926">https://doi.org/10.1177/1558689809356926</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1177%2F1558689809356926" aria-label="View reference 2">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Book%20Review%3A%20V.%20L.%20Plano%20Clark%20and%20J.%20W.%20Creswell%20%28Eds.%29%20The%20Mixed%20Methods%20Reader.%20Thousand%20Oaks%2C%20CA%3A%20SAGE%2C%202008%2C%20617%C2%A0pp.%20Supplied%20by%20Footprint%20Books%2C%20AU%2479%20%28paperback%29&amp;journal=J%20Mix%20Methods%20Res&amp;doi=10.1177%2F1558689809356926&amp;volume=4&amp;issue=1&amp;pages=79-81&amp;publication_year=2010&amp;author=Bazeley%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Buckley, E. Doyle, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Buckley P, Doyle E (2016) Gamification and student motivation. Interact Learn Environ 24(6):1162–1175. https:/" /><p class="c-article-references__text" id="ref-CR3">Buckley P, Doyle E (2016) Gamification and student motivation. Interact Learn Environ 24(6):1162–1175. <a href="https://doi.org/10.1080/10494820.2014.964263">https://doi.org/10.1080/10494820.2014.964263</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F10494820.2014.964263" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Gamification%20and%20student%20motivation&amp;journal=Interact%20Learn%20Environ&amp;doi=10.1080%2F10494820.2014.964263&amp;volume=24&amp;issue=6&amp;pages=1162-1175&amp;publication_year=2016&amp;author=Buckley%2CP&amp;author=Doyle%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cambridge Dictionary (2017) Definition of immersive. Cambridge Dictionary. Cambridge University Press. http://" /><p class="c-article-references__text" id="ref-CR4">Cambridge Dictionary (2017) Definition of immersive. Cambridge Dictionary. Cambridge University Press. <a href="http://dictionary.cambridge.org/dictionary/english/immersive">http://dictionary.cambridge.org/dictionary/english/immersive</a>. Accessed 26 May 2017</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Choi, K. Jung, SD. Noh, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Choi S, Jung K, Noh SD (2015) Virtual reality applications in manufacturing industries: past research, present" /><p class="c-article-references__text" id="ref-CR5">Choi S, Jung K, Noh SD (2015) Virtual reality applications in manufacturing industries: past research, present findings, and future directions. Concur Eng Res Appl 23(1):40–63. <a href="https://doi.org/10.1177/1063293X14568814">https://doi.org/10.1177/1063293X14568814</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1177%2F1063293X14568814" aria-label="View reference 5">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20applications%20in%20manufacturing%20industries%3A%20past%20research%2C%20present%20findings%2C%20and%20future%20directions&amp;journal=Concur%20Eng%20Res%20Appl&amp;doi=10.1177%2F1063293X14568814&amp;volume=23&amp;issue=1&amp;pages=40-63&amp;publication_year=2015&amp;author=Choi%2CS&amp;author=Jung%2CK&amp;author=Noh%2CSD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Christou, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Christou C (2010) Virtual reality in education. Education. https://doi.org/10.4018/978-1-60566-940-3.ch012&#xA;   " /><p class="c-article-references__text" id="ref-CR6">Christou C (2010) Virtual reality in education. Education. <a href="https://doi.org/10.4018/978-1-60566-940-3.ch012">https://doi.org/10.4018/978-1-60566-940-3.ch012</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.4018%2F978-1-60566-940-3.ch012" aria-label="View reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20in%20education&amp;journal=Education&amp;doi=10.4018%2F978-1-60566-940-3.ch012&amp;publication_year=2010&amp;author=Christou%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. R. D.. King, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="Creswell JW (2014) Research design: qualitative, quantitative and mixed approaches, 4th edn. https://doi.org/1" /><p class="c-article-references__text" id="ref-CR7">Creswell JW (2014) Research design: qualitative, quantitative and mixed approaches, 4th edn. <a href="https://doi.org/10.2307/1523157">https://doi.org/10.2307/1523157</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.2307%2F1523157" aria-label="View reference 7">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Creswell%27s%20Appreciation%20of%20Arabian%20Architecture&amp;journal=Muqarnas&amp;volume=8&amp;publication_year=1991&amp;author=King%2CG.%20R.%20D.">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Creswell JW, Plano Clark VL (2007) Choosing a mixed method design. In: Designing and conducting mixed methods " /><p class="c-article-references__text" id="ref-CR8">Creswell JW, Plano Clark VL (2007) Choosing a mixed method design. In: Designing and conducting mixed methods research. SAGE Publications, Inc, pp 58–89. ISBN: 1412927927</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Culatta R (2013) ADDIE model. Retrieved from http://www.instructionaldesign.org/models/addie&#xA;                 " /><p class="c-article-references__text" id="ref-CR9">Culatta R (2013) ADDIE model. Retrieved from <a href="http://www.instructionaldesign.org/models/addie">http://www.instructionaldesign.org/models/addie</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="DextaRobotics (2018) DextaRobotics builds hand haptics device for virtual reality medical learning. https://ww" /><p class="c-article-references__text" id="ref-CR10">DextaRobotics (2018) DextaRobotics builds hand haptics device for virtual reality medical learning. <a href="https://www.healthysimulation.com/9009/dextarobotics-builds-hand-haptics-device-for-virtual-reality-medical-learning/">https://www.healthysimulation.com/9009/dextarobotics-builds-hand-haptics-device-for-virtual-reality-medical-learning/</a>. Accessed 16 Mar 2018</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dünser A, Steinbügl K, Kaufmann H, Glück J (2006) Virtual and augmented reality as spatial ability training to" /><p class="c-article-references__text" id="ref-CR11">Dünser A, Steinbügl K, Kaufmann H, Glück J (2006) Virtual and augmented reality as spatial ability training tools. In: Proceedings of the 6th ACM SIGCHI New Zealand chapter’s international conference on Computer-human interaction design centered HCI - CHINZ’06, vol 158, pp 125–132. <a href="https://doi.org/10.1145/1152760.1152776">https://doi.org/10.1145/1152760.1152776</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="ML. Eastwood, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Eastwood ML (2013) Fastest fingers: a molecule-building game for teaching organic chemistry. J Chem Educ 90(8)" /><p class="c-article-references__text" id="ref-CR12">Eastwood ML (2013) Fastest fingers: a molecule-building game for teaching organic chemistry. J Chem Educ 90(8):1038–1041. <a href="https://doi.org/10.1021/ed3004462">https://doi.org/10.1021/ed3004462</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1021%2Fed3004462" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Fastest%20fingers%3A%20a%20molecule-building%20game%20for%20teaching%20organic%20chemistry&amp;journal=J%20Chem%20Educ&amp;doi=10.1021%2Fed3004462&amp;volume=90&amp;issue=8&amp;pages=1038-1041&amp;publication_year=2013&amp;author=Eastwood%2CML">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="DA. Erlandson, EL. Harris, BL. Skipper, SD. Allen, " /><meta itemprop="datePublished" content="1993" /><meta itemprop="headline" content="Erlandson DA, Harris EL, Skipper BL, Allen SD (1993) Doing naturalistic inquiry: a guide to methods. SAGE Publ" /><p class="c-article-references__text" id="ref-CR13">Erlandson DA, Harris EL, Skipper BL, Allen SD (1993) Doing naturalistic inquiry: a guide to methods. SAGE Publications Inc, Thousand Oaks</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Doing%20naturalistic%20inquiry%3A%20a%20guide%20to%20methods&amp;publication_year=1993&amp;author=Erlandson%2CDA&amp;author=Harris%2CEL&amp;author=Skipper%2CBL&amp;author=Allen%2CSD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SL. Farra, ET. Miller, E. Hodgson, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Farra SL, Miller ET, Hodgson E (2015) Virtual reality disaster training: translation to practice. Nurse Educ P" /><p class="c-article-references__text" id="ref-CR14">Farra SL, Miller ET, Hodgson E (2015) Virtual reality disaster training: translation to practice. Nurse Educ Pract 15(1):53–57. <a href="https://doi.org/10.1016/j.nepr.2013.08.017">https://doi.org/10.1016/j.nepr.2013.08.017</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.nepr.2013.08.017" aria-label="View reference 14">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20disaster%20training%3A%20translation%20to%20practice&amp;journal=Nurse%20Educ%20Pract&amp;doi=10.1016%2Fj.nepr.2013.08.017&amp;volume=15&amp;issue=1&amp;pages=53-57&amp;publication_year=2015&amp;author=Farra%2CSL&amp;author=Miller%2CET&amp;author=Hodgson%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fildes N (2015, December) 2016 set to be year virtual reality takes off. Raconteur. https://www.raconteur.net/" /><p class="c-article-references__text" id="ref-CR15">Fildes N (2015, December) 2016 set to be year virtual reality takes off. Raconteur. <a href="https://www.raconteur.net/technology/2016-set-to-be-year-virtual-reality-takes-off">https://www.raconteur.net/technology/2016-set-to-be-year-virtual-reality-takes-off</a>. Accessed 26 May 2017</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Google (2017) Virtual reality for everyone. Retrieved November 9, 2017. https://vr.google.com/. Accessed 26 Ma" /><p class="c-article-references__text" id="ref-CR16">Google (2017) Virtual reality for everyone. Retrieved November 9, 2017. <a href="https://vr.google.com/">https://vr.google.com/</a>. Accessed 26 May 2017</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="GoTouch VR Team (2017) Go touch VR. Retrieved November 9, 2017. https://www.gotouchvr.com/. Accessed 26 May 20" /><p class="c-article-references__text" id="ref-CR17">GoTouch VR Team (2017) Go touch VR. Retrieved November 9, 2017. <a href="https://www.gotouchvr.com/">https://www.gotouchvr.com/</a>. Accessed 26 May 2017</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hamid NSS, Aziz FA, Azizi A (2014) Virtual reality applications in manufacturing system. In: Proceedings of 20" /><p class="c-article-references__text" id="ref-CR18">Hamid NSS, Aziz FA, Azizi A (2014) Virtual reality applications in manufacturing system. In: Proceedings of 2014 science and information conference, SAI 2014. pp 1034–1037. <a href="https://doi.org/10.1109/SAI.2014.6918317">https://doi.org/10.1109/SAI.2014.6918317</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Hauptman, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Hauptman H (2010) Enhancement of spatial thinking with virtual spaces 1.0. Comput Educ 54(1):123–135. https://" /><p class="c-article-references__text" id="ref-CR19">Hauptman H (2010) Enhancement of spatial thinking with virtual spaces 1.0. Comput Educ 54(1):123–135. <a href="https://doi.org/10.1016/j.compedu.2009.07.013">https://doi.org/10.1016/j.compedu.2009.07.013</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.compedu.2009.07.013" aria-label="View reference 19">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Enhancement%20of%20spatial%20thinking%20with%20virtual%20spaces%201.0&amp;journal=Comput%20Educ&amp;doi=10.1016%2Fj.compedu.2009.07.013&amp;volume=54&amp;issue=1&amp;pages=123-135&amp;publication_year=2010&amp;author=Hauptman%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Heinich R, Molenda M, Russell J, Smaldino S (2002) The ASSURE model. In Instructional media and technologies f" /><p class="c-article-references__text" id="ref-CR20">Heinich R, Molenda M, Russell J, Smaldino S (2002) The ASSURE model. In Instructional media and technologies for learning, vol 7</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hyun EHE, Yoon HYH, Son SSS (2010) Relationships between user experiences and children’s perceptions of the ed" /><p class="c-article-references__text" id="ref-CR21">Hyun EHE, Yoon HYH, Son SSS (2010) Relationships between user experiences and children’s perceptions of the education robot. In: Human-robot interaction (HRI), 2010 5th ACM/IEEE international conference on, pp 199–200. <a href="https://doi.org/10.1109/HRI.2010.5453197">https://doi.org/10.1109/HRI.2010.5453197</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Jong, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Jong T (2009) Cognitive load theory, educational research, and instructional design: some food for thought. In" /><p class="c-article-references__text" id="ref-CR22">Jong T (2009) Cognitive load theory, educational research, and instructional design: some food for thought. Instr Sci 38(2):105–134. <a href="https://doi.org/10.1007/s11251-009-9110-0">https://doi.org/10.1007/s11251-009-9110-0</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs11251-009-9110-0" aria-label="View reference 22">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Cognitive%20load%20theory%2C%20educational%20research%2C%20and%20instructional%20design%3A%20some%20food%20for%20thought&amp;journal=Instr%20Sci&amp;doi=10.1007%2Fs11251-009-9110-0&amp;volume=38&amp;issue=2&amp;pages=105-134&amp;publication_year=2009&amp;author=Jong%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Koedinger KR, Kim J, Jia JZ, McLaughlin EA, Bier NL (2015) Learning is not a spectator sport: doing is better " /><p class="c-article-references__text" id="ref-CR23">Koedinger KR, Kim J, Jia JZ, McLaughlin EA, Bier NL (2015) Learning is not a spectator sport: doing is better than watching for learning from a MOOC. In: Proceedings of the second (2015) ACM conference on learning @ Scale-L@S’15. pp 111–120. <a href="https://doi.org/10.1145/2724660.2724681">https://doi.org/10.1145/2724660.2724681</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Stephen J.. Cavanagh, Kevin. Hogan, Terenlall. Ramgopal, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Kolb AY, Kolb DA (2005) The Kolb learning style inventory—version 3.1 2005 technical specifications. LSI Techn" /><p class="c-article-references__text" id="ref-CR24">Kolb AY, Kolb DA (2005) The Kolb learning style inventory—version 3.1 2005 technical specifications. LSI Technical Manual, pp 1–72. <a href="https://doi.org/10.1016/S0260-6917(95)80103-0">https://doi.org/10.1016/S0260-6917(95)80103-0</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0260-6917%2895%2980103-0" aria-label="View reference 24">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20assessment%20ofstudent%20nurse%20learning%20styles%20using%20the%20Kolb%20Learning%20Styles%20Inventory&amp;journal=Nurse%20Education%20Today&amp;volume=15&amp;issue=3&amp;pages=177-183&amp;publication_year=1995&amp;author=Cavanagh%2CStephen%20J.&amp;author=Hogan%2CKevin&amp;author=Ramgopal%2CTerenlall">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DA. Kolb, RE. Boyatzis, C. Mainemelis, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Kolb DA, Boyatzis RE, Mainemelis C (2000) Experiential learning theory: previous research and new directions. " /><p class="c-article-references__text" id="ref-CR25">Kolb DA, Boyatzis RE, Mainemelis C (2000) Experiential learning theory: previous research and new directions. Perspect Think Learn Cognit Styl 1(216):227–247. <a href="https://doi.org/10.5465/AMLE.2005.17268566">https://doi.org/10.5465/AMLE.2005.17268566</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.5465%2FAMLE.2005.17268566" aria-label="View reference 25">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Experiential%20learning%20theory%3A%20previous%20research%20and%20new%20directions&amp;journal=Perspect%20Think%20Learn%20Cognit%20Styl&amp;doi=10.5465%2FAMLE.2005.17268566&amp;volume=1&amp;issue=216&amp;pages=227-247&amp;publication_year=2000&amp;author=Kolb%2CDA&amp;author=Boyatzis%2CRE&amp;author=Mainemelis%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MS. Kuo, TY. Chuang, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Kuo MS, Chuang TY (2016) How gamification motivates visits and engagement for online academic dissemination: a" /><p class="c-article-references__text" id="ref-CR26">Kuo MS, Chuang TY (2016) How gamification motivates visits and engagement for online academic dissemination: an empirical study. Comput Hum Behav 55:16–27. <a href="https://doi.org/10.1016/j.chb.2015.08.025">https://doi.org/10.1016/j.chb.2015.08.025</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.chb.2015.08.025" aria-label="View reference 26">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=How%20gamification%20motivates%20visits%20and%20engagement%20for%20online%20academic%20dissemination%3A%20an%20empirical%20study&amp;journal=Comput%20Hum%20Behav&amp;doi=10.1016%2Fj.chb.2015.08.025&amp;volume=55&amp;pages=16-27&amp;publication_year=2016&amp;author=Kuo%2CMS&amp;author=Chuang%2CTY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Leap Motion (2017) Reach into Virtual Reality with your bare hands. https://www.leapmotion.com/#112. Accessed " /><p class="c-article-references__text" id="ref-CR27">Leap Motion (2017) Reach into Virtual Reality with your bare hands. <a href="https://www.leapmotion.com/%23112">https://www.leapmotion.com/#112</a>. Accessed 26 May 2017</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mahatma Chemistry (2017) MEL chemistry VR. https://melscience.com/vr/. Accessed 26 May 2017" /><p class="c-article-references__text" id="ref-CR28">Mahatma Chemistry (2017) MEL chemistry VR. <a href="https://melscience.com/vr/">https://melscience.com/vr/</a>. Accessed 26 May 2017</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HH. Mei, LS. Sheng, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Mei HH, Sheng LS (2011) Applying situated learning in a virtual reality system to enhance learning motivation." /><p class="c-article-references__text" id="ref-CR29">Mei HH, Sheng LS (2011) Applying situated learning in a virtual reality system to enhance learning motivation. Int J Inf Educ Technol 1(4):298–302. <a href="https://doi.org/10.7763/IJIET.2011.V1.48">https://doi.org/10.7763/IJIET.2011.V1.48</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.7763%2FIJIET.2011.V1.48" aria-label="View reference 29">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Applying%20situated%20learning%20in%20a%20virtual%20reality%20system%20to%20enhance%20learning%20motivation&amp;journal=Int%20J%20Inf%20Educ%20Technol&amp;doi=10.7763%2FIJIET.2011.V1.48&amp;volume=1&amp;issue=4&amp;pages=298-302&amp;publication_year=2011&amp;author=Mei%2CHH&amp;author=Sheng%2CLS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Z. Merchant, ET. Goetz, W. Keeney-Kennicutt, L. Cifuentes, O. Kwok, TJ. Davis, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Merchant Z, Goetz ET, Keeney-Kennicutt W, Cifuentes L, Kwok O, Davis TJ (2013) Exploring 3-D virtual reality t" /><p class="c-article-references__text" id="ref-CR30">Merchant Z, Goetz ET, Keeney-Kennicutt W, Cifuentes L, Kwok O, Davis TJ (2013) Exploring 3-D virtual reality technology for spatial ability and chemistry achievement. J Comput Assist Learn 29(6):579–590. <a href="https://doi.org/10.1111/jcal.12018">https://doi.org/10.1111/jcal.12018</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fjcal.12018" aria-label="View reference 30">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Exploring%203-D%20virtual%20reality%20technology%20for%20spatial%20ability%20and%20chemistry%20achievement&amp;journal=J%20Comput%20Assist%20Learn&amp;doi=10.1111%2Fjcal.12018&amp;volume=29&amp;issue=6&amp;pages=579-590&amp;publication_year=2013&amp;author=Merchant%2CZ&amp;author=Goetz%2CET&amp;author=Keeney-Kennicutt%2CW&amp;author=Cifuentes%2CL&amp;author=Kwok%2CO&amp;author=Davis%2CTJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Merriam Webster Dictionary (2017) Definition of IMMERSIVE. Retrieved from https://www.merriamwebster.com/dicti" /><p class="c-article-references__text" id="ref-CR31">Merriam Webster Dictionary (2017) Definition of IMMERSIVE. Retrieved from <a href="https://www.merriamwebster.com/dictionary/immersive">https://www.merriamwebster.com/dictionary/immersive</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="Daniel. Mestre, Jean-Louis. Vercher, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Mestre D, Vercher J-L (2011) Immersion and presence. In: Virtual reality: concepts and technologies. pp 81–96." /><p class="c-article-references__text" id="ref-CR32">Mestre D, Vercher J-L (2011) Immersion and presence. In: Virtual reality: concepts and technologies. pp 81–96. <a href="http://www.ism.univmed.fr/mestre/projects/virtualreality/Pres_2005.pdf">http://www.ism.univmed.fr/mestre/projects/virtualreality/Pres_2005.pdf</a>. Accessed 26 May 2017</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20Reality&amp;publication_year=2011&amp;author=Mestre%2CDaniel&amp;author=Vercher%2CJean-Louis">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Minogue, MG. Jones, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Minogue J, Jones MG (2006) Haptics in education: exploring an untapped sensory modality. Rev Educ Res 76(3):31" /><p class="c-article-references__text" id="ref-CR33">Minogue J, Jones MG (2006) Haptics in education: exploring an untapped sensory modality. Rev Educ Res 76(3):317–348. <a href="https://doi.org/10.3102/00346543076003317">https://doi.org/10.3102/00346543076003317</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3102%2F00346543076003317" aria-label="View reference 33">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Haptics%20in%20education%3A%20exploring%20an%20untapped%20sensory%20modality&amp;journal=Rev%20Educ%20Res&amp;doi=10.3102%2F00346543076003317&amp;volume=76&amp;issue=3&amp;pages=317-348&amp;publication_year=2006&amp;author=Minogue%2CJ&amp;author=Jones%2CMG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Molenda M (2003a) ADDIE model. http://www.nwlink.com/~donclark/history_isd/addie.html#FSU. Accessed 26 May 201" /><p class="c-article-references__text" id="ref-CR34">Molenda M (2003a) ADDIE model. <a href="http://www.nwlink.com/%7edonclark/history_isd/addie.html%23FSU">http://www.nwlink.com/~donclark/history_isd/addie.html#FSU</a>. Accessed 26 May 2017</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Molenda (2003b) ADDIE Timeline. The performance juxtaposition site. Retrieved from http://www.nwlink.com/~donc" /><p class="c-article-references__text" id="ref-CR35">Molenda (2003b) ADDIE Timeline. The performance juxtaposition site. Retrieved from <a href="http://www.nwlink.com/~donclark/history_isd/addie.html#FSU">http://www.nwlink.com/~donclark/history_isd/addie.html#FSU</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Monahan, G. McArdle, M. Bertolotto, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Monahan T, McArdle G, Bertolotto M (2008) Virtual reality for collaborative e-learning. Comput Educ 50(4):1339" /><p class="c-article-references__text" id="ref-CR36">Monahan T, McArdle G, Bertolotto M (2008) Virtual reality for collaborative e-learning. Comput Educ 50(4):1339–1353. <a href="https://doi.org/10.1016/j.compedu.2006.12.008">https://doi.org/10.1016/j.compedu.2006.12.008</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.compedu.2006.12.008" aria-label="View reference 36">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 36 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20for%20collaborative%20e-learning&amp;journal=Comput%20Educ&amp;doi=10.1016%2Fj.compedu.2006.12.008&amp;volume=50&amp;issue=4&amp;pages=1339-1353&amp;publication_year=2008&amp;author=Monahan%2CT&amp;author=McArdle%2CG&amp;author=Bertolotto%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Mujber, T. Szecsi, M. Hashmi, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Mujber T, Szecsi T, Hashmi M (2004) Virtual reality applications in manufacturing process simulation. J Mater " /><p class="c-article-references__text" id="ref-CR37">Mujber T, Szecsi T, Hashmi M (2004) Virtual reality applications in manufacturing process simulation. J Mater Process Technol 155156:1834–1838. <a href="https://doi.org/10.1016/j.jmatprotec.2004.04.401">https://doi.org/10.1016/j.jmatprotec.2004.04.401</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.jmatprotec.2004.04.401" aria-label="View reference 37">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20applications%20in%20manufacturing%20process%20simulation&amp;journal=J%20Mater%20Process%20Technol&amp;doi=10.1016%2Fj.jmatprotec.2004.04.401&amp;volume=155156&amp;pages=1834-1838&amp;publication_year=2004&amp;author=Mujber%2CT&amp;author=Szecsi%2CT&amp;author=Hashmi%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Nakamura, M. Csikszentmihalyi, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Nakamura J, Csikszentmihalyi M (2009) Flow theory and research. Oxf Handb Posit Psychol. https://doi.org/10.10" /><p class="c-article-references__text" id="ref-CR38">Nakamura J, Csikszentmihalyi M (2009) Flow theory and research. Oxf Handb Posit Psychol. <a href="https://doi.org/10.1093/oxfordhb/9780195187243.013.0018">https://doi.org/10.1093/oxfordhb/9780195187243.013.0018</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1093%2Foxfordhb%2F9780195187243.013.0018" aria-label="View reference 38">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 38 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Flow%20theory%20and%20research&amp;journal=Oxf%20Handb%20Posit%20Psychol&amp;doi=10.1093%2Foxfordhb%2F9780195187243.013.0018&amp;publication_year=2009&amp;author=Nakamura%2CJ&amp;author=Csikszentmihalyi%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Norrby, C. Grebner, J. Eriksson, J. Bostrom, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Norrby M, Grebner C, Eriksson J, Bostrom J (2015) Molecular rift: virtual reality for drug designers. J Chem I" /><p class="c-article-references__text" id="ref-CR39">Norrby M, Grebner C, Eriksson J, Bostrom J (2015) Molecular rift: virtual reality for drug designers. J Chem Inf Model 55(11):2475–2484. <a href="https://doi.org/10.1021/acs.jcim.5b00544">https://doi.org/10.1021/acs.jcim.5b00544</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1021%2Facs.jcim.5b00544" aria-label="View reference 39">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Molecular%20rift%3A%20virtual%20reality%20for%20drug%20designers&amp;journal=J%20Chem%20Inf%20Model&amp;doi=10.1021%2Facs.jcim.5b00544&amp;volume=55&amp;issue=11&amp;pages=2475-2484&amp;publication_year=2015&amp;author=Norrby%2CM&amp;author=Grebner%2CC&amp;author=Eriksson%2CJ&amp;author=Bostrom%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Ornstein, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Ornstein A (2006) The frequency of hands-on experimentation and student attitudes toward science: a statistica" /><p class="c-article-references__text" id="ref-CR40">Ornstein A (2006) The frequency of hands-on experimentation and student attitudes toward science: a statistically significant relation (2005-51-ornstein). J Sci Educ Technol 15(3–4):285–297. <a href="https://doi.org/10.1007/s10956-006-9015-5">https://doi.org/10.1007/s10956-006-9015-5</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10956-006-9015-5" aria-label="View reference 40">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 40 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20frequency%20of%20hands-on%20experimentation%20and%20student%20attitudes%20toward%20science%3A%20a%20statistically%20significant%20relation%20%282005-51-ornstein%29&amp;journal=J%20Sci%20Educ%20Technol&amp;doi=10.1007%2Fs10956-006-9015-5&amp;volume=15&amp;issue=3%E2%80%934&amp;pages=285-297&amp;publication_year=2006&amp;author=Ornstein%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="React! Team (2017) React! the organic chemistry board game. Retrieved June 22, 2017, http://reactgame.com/#/. " /><p class="c-article-references__text" id="ref-CR41">React! Team (2017) React! the organic chemistry board game. Retrieved June 22, 2017, <a href="http://reactgame.com/%23/">http://reactgame.com/#/</a>. Accessed 26 May 2017</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Ritter, M. Johnson, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Ritter D, Johnson M (1997) Virtual titrator: a student-oriented instrument. J Chem Educ 74(1):120. https://doi" /><p class="c-article-references__text" id="ref-CR42">Ritter D, Johnson M (1997) Virtual titrator: a student-oriented instrument. J Chem Educ 74(1):120. <a href="https://doi.org/10.1021/ed074p120">https://doi.org/10.1021/ed074p120</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1021%2Fed074p120" aria-label="View reference 42">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 42 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20titrator%3A%20a%20student-oriented%20instrument&amp;journal=J%20Chem%20Educ&amp;doi=10.1021%2Fed074p120&amp;volume=74&amp;issue=1&amp;publication_year=1997&amp;author=Ritter%2CD&amp;author=Johnson%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sanders T, Cairns P (2010) Time perception, immersion and music in videogames. In: Proceedings of the 24th BCS" /><p class="c-article-references__text" id="ref-CR43">Sanders T, Cairns P (2010) Time perception, immersion and music in videogames. In: Proceedings of the 24th BCS interaction specialist group conference, pp 160–167</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Schell Games (2017) SuperChem VR. Retrieved June 20, 2017, https://www.schellgames.com/games/superchem-vr. Acc" /><p class="c-article-references__text" id="ref-CR44">Schell Games (2017) SuperChem VR. Retrieved June 20, 2017, <a href="https://www.schellgames.com/games/superchem-vr">https://www.schellgames.com/games/superchem-vr</a>. Accessed 26 May 2017</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Smith C, Agcaoili K, Kannan A (2016) Chemistry Lab VR. Retrieved May 20, 2017, https://devpost.com/software/ch" /><p class="c-article-references__text" id="ref-CR45">Smith C, Agcaoili K, Kannan A (2016) Chemistry Lab VR. Retrieved May 20, 2017, <a href="https://devpost.com/software/chemistry-lab-vr">https://devpost.com/software/chemistry-lab-vr</a>. Accessed 26 May 2017</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="PM. Stohr-Hunt, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Stohr-Hunt PM (1996) An analysis of frequency of hands-on experience and science achievement. J Res Sci Teach " /><p class="c-article-references__text" id="ref-CR46">Stohr-Hunt PM (1996) An analysis of frequency of hands-on experience and science achievement. J Res Sci Teach 33(1):101–109. <a href="">https://doi.org/10.1002/(SICI)1098-2736(199601)33:1&lt;101::AID-TEA6&gt;3.0.CO;2-Z</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2F%28SICI%291098-2736%28199601%2933%3A1%3C101%3A%3AAID-TEA6%3E3.0.CO%3B2-Z" aria-label="View reference 46">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 46 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20analysis%20of%20frequency%20of%20hands-on%20experience%20and%20science%20achievement&amp;journal=J%20Res%20Sci%20Teach&amp;doi=10.1002%2F%28SICI%291098-2736%28199601%2933%3A1%3C101%3A%3AAID-TEA6%3E3.0.CO%3B2-Z&amp;volume=33&amp;issue=1&amp;pages=101-109&amp;publication_year=1996&amp;author=Stohr-Hunt%2CPM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DC. Stone, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Stone DC (2007) Teaching chromatography using virtual laboratory exercises. J Chem Educ 84(9):1488–1495. https" /><p class="c-article-references__text" id="ref-CR47">Stone DC (2007) Teaching chromatography using virtual laboratory exercises. J Chem Educ 84(9):1488–1495. <a href="https://doi.org/10.1021/ed084p1488">https://doi.org/10.1021/ed084p1488</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1021%2Fed084p1488" aria-label="View reference 47">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 47 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Teaching%20chromatography%20using%20virtual%20laboratory%20exercises&amp;journal=J%20Chem%20Educ&amp;doi=10.1021%2Fed084p1488&amp;volume=84&amp;issue=9&amp;pages=1488-1495&amp;publication_year=2007&amp;author=Stone%2CDC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AT. Stull, T. Barrett, M. Hegarty, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Stull AT, Barrett T, Hegarty M (2013) Usability of concrete and virtual models in chemistry instruction. Compu" /><p class="c-article-references__text" id="ref-CR48">Stull AT, Barrett T, Hegarty M (2013) Usability of concrete and virtual models in chemistry instruction. Comput Hum Behav 29(6):2546–2556</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.chb.2013.06.012" aria-label="View reference 48">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 48 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Usability%20of%20concrete%20and%20virtual%20models%20in%20chemistry%20instruction&amp;journal=Comput%20Hum%20Behav&amp;volume=29&amp;issue=6&amp;pages=2546-2556&amp;publication_year=2013&amp;author=Stull%2CAT&amp;author=Barrett%2CT&amp;author=Hegarty%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DJ. Turk, K. Gillespie-Smith, OE. Krigolson, C. Havard, MA. Conway, SJ. Cunningham, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Turk DJ, Gillespie-Smith K, Krigolson OE, Havard C, Conway MA, Cunningham SJ (2015) Selfish learning: the impa" /><p class="c-article-references__text" id="ref-CR49">Turk DJ, Gillespie-Smith K, Krigolson OE, Havard C, Conway MA, Cunningham SJ (2015) Selfish learning: the impact of self-referential encoding on children’s literacy attainment. Learn Instr 40:54–60. <a href="https://doi.org/10.1016/j.learninstruc.2015.08.001">https://doi.org/10.1016/j.learninstruc.2015.08.001</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.learninstruc.2015.08.001" aria-label="View reference 49">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 49 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Selfish%20learning%3A%20the%20impact%20of%20self-referential%20encoding%20on%20children%E2%80%99s%20literacy%20attainment&amp;journal=Learn%20Instr&amp;doi=10.1016%2Fj.learninstruc.2015.08.001&amp;volume=40&amp;pages=54-60&amp;publication_year=2015&amp;author=Turk%2CDJ&amp;author=Gillespie-Smith%2CK&amp;author=Krigolson%2COE&amp;author=Havard%2CC&amp;author=Conway%2CMA&amp;author=Cunningham%2CSJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Tuveri E, Macis L, Sorrentino F, Spano LD, Scateni R (2016) Fitmersive games: fitness gamification through imm" /><p class="c-article-references__text" id="ref-CR50">Tuveri E, Macis L, Sorrentino F, Spano LD, Scateni R (2016) Fitmersive games: fitness gamification through immersive VR. In Proceedings of the international working conference on advanced visual interfaces-AVI’16. pp 212–215. <a href="https://doi.org/10.1145/2909132.2909287">https://doi.org/10.1145/2909132.2909287</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Unimersiv (2016) Chemistry VR. Retrieved June 20, 2017, https://unimersiv.com/review/chemistry-vr/&#xA;           " /><p class="c-article-references__text" id="ref-CR51">Unimersiv (2016) Chemistry VR. Retrieved June 20, 2017, <a href="https://unimersiv.com/review/chemistry-vr/">https://unimersiv.com/review/chemistry-vr/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Whitson C, Consoli J (2009) Flow theory and student engagement. J Cross-Discip Perspect Educ 2(1):40–49. http:" /><p class="c-article-references__text" id="ref-CR52">Whitson C, Consoli J (2009) Flow theory and student engagement. J Cross-Discip Perspect Educ 2(1):40–49. <a href="http://jcpe.wmwikis.net/file/view/whitsonconsoli.pdf">http://jcpe.wmwikis.net/file/view/whitsonconsoli.pdf</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Winkelmann, M. Scott, D. Wong, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Winkelmann K, Scott M, Wong D (2014) A study of high school students’ performance of a chemistry experiment wi" /><p class="c-article-references__text" id="ref-CR53">Winkelmann K, Scott M, Wong D (2014) A study of high school students’ performance of a chemistry experiment within the virtual world of second life. J Chem Educ 91(9):1432–1438. <a href="https://doi.org/10.1021/ed500009e">https://doi.org/10.1021/ed500009e</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1021%2Fed500009e" aria-label="View reference 53">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 53 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20study%20of%20high%20school%20students%E2%80%99%20performance%20of%20a%20chemistry%20experiment%20within%20the%20virtual%20world%20of%20second%20life&amp;journal=J%20Chem%20Educ&amp;doi=10.1021%2Fed500009e&amp;volume=91&amp;issue=9&amp;pages=1432-1438&amp;publication_year=2014&amp;author=Winkelmann%2CK&amp;author=Scott%2CM&amp;author=Wong%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Winter, M. Wentzel, S. Ahluwalia, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Winter J, Wentzel M, Ahluwalia S (2016) Chairs!: a mobile game for organic chemistry students to learn the rin" /><p class="c-article-references__text" id="ref-CR54">Winter J, Wentzel M, Ahluwalia S (2016) Chairs!: a mobile game for organic chemistry students to learn the ring flip of cyclohexane. J Chem Educ 93(9):1657–1659. <a href="https://doi.org/10.1021/acs.jchemed.5b00872">https://doi.org/10.1021/acs.jchemed.5b00872</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1021%2Facs.jchemed.5b00872" aria-label="View reference 54">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 54 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Chairs%21%3A%20a%20mobile%20game%20for%20organic%20chemistry%20students%20to%20learn%20the%20ring%20flip%20of%20cyclohexane&amp;journal=J%20Chem%20Educ&amp;doi=10.1021%2Facs.jchemed.5b00872&amp;volume=93&amp;issue=9&amp;pages=1657-1659&amp;publication_year=2016&amp;author=Winter%2CJ&amp;author=Wentzel%2CM&amp;author=Ahluwalia%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Woolley J, Sheeley J, Sheeley S (2010) Organic molecule game. http://chem.illinois.edu/omg/index.html. Accesse" /><p class="c-article-references__text" id="ref-CR55">Woolley J, Sheeley J, Sheeley S (2010) Organic molecule game. <a href="http://chem.illinois.edu/omg/index.html">http://chem.illinois.edu/omg/index.html</a>. Accessed 26 May 2017</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="E. Yiannakopoulou, N. Nikiteas, D. Perrea, C. Tsigris, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Yiannakopoulou E, Nikiteas N, Perrea D, Tsigris C (2015) Virtual reality simulators and training in laparoscop" /><p class="c-article-references__text" id="ref-CR56">Yiannakopoulou E, Nikiteas N, Perrea D, Tsigris C (2015) Virtual reality simulators and training in laparoscopic surgery. Int J Surg 13:60–64. <a href="https://doi.org/10.1016/j.ijsu.2014.11.014">https://doi.org/10.1016/j.ijsu.2014.11.014</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.ijsu.2014.11.014" aria-label="View reference 56">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 56 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20simulators%20and%20training%20in%20laparoscopic%20surgery&amp;journal=Int%20J%20Surg&amp;doi=10.1016%2Fj.ijsu.2014.11.014&amp;volume=13&amp;pages=60-64&amp;publication_year=2015&amp;author=Yiannakopoulou%2CE&amp;author=Nikiteas%2CN&amp;author=Perrea%2CD&amp;author=Tsigris%2CC">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-018-0345-4-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Imagineering Institute, Medini Mall, 79200, Iskandar Puteri, Johor, Malaysia</p><p class="c-article-author-affiliation__authors-list">Bosede Iyiade Edwards, Kevin S. Bielawski &amp; Adrian David Cheok</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">City, University of London, Northampton Square, Clerkenwell, London, EC1V 0HB, UK</p><p class="c-article-author-affiliation__authors-list">Bosede Iyiade Edwards, Kevin S. Bielawski &amp; Adrian David Cheok</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal</p><p class="c-article-author-affiliation__authors-list">Rui Prada</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Bosede_Iyiade-Edwards"><span class="c-article-authors-search__title u-h3 js-search-name">Bosede Iyiade Edwards</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Bosede Iyiade+Edwards&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Bosede Iyiade+Edwards" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Bosede Iyiade+Edwards%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Kevin_S_-Bielawski"><span class="c-article-authors-search__title u-h3 js-search-name">Kevin S. Bielawski</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Kevin S.+Bielawski&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Kevin S.+Bielawski" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Kevin S.+Bielawski%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Rui-Prada"><span class="c-article-authors-search__title u-h3 js-search-name">Rui Prada</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Rui+Prada&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Rui+Prada" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Rui+Prada%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Adrian_David-Cheok"><span class="c-article-authors-search__title u-h3 js-search-name">Adrian David Cheok</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Adrian David+Cheok&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Adrian David+Cheok" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Adrian David+Cheok%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-018-0345-4/email/correspondent/c1/new">Bosede Iyiade Edwards</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Haptic%20virtual%20reality%20and%20immersive%20learning%20for%20enhanced%20organic%20chemistry%20instruction&amp;author=Bosede%20Iyiade%20Edwards%20et%20al&amp;contentID=10.1007%2Fs10055-018-0345-4&amp;publication=1359-4338&amp;publicationDate=2018-06-15&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-018-0345-4" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-018-0345-4" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Edwards, B.I., Bielawski, K.S., Prada, R. <i>et al.</i> Haptic virtual reality and immersive learning for enhanced organic chemistry instruction.
                    <i>Virtual Reality</i> <b>23, </b>363–373 (2019). https://doi.org/10.1007/s10055-018-0345-4</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-018-0345-4.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2017-11-09">09 November 2017</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-05-02">02 May 2018</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-06-15">15 June 2018</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2019-12">December 2019</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-018-0345-4" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-018-0345-4</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Virtual reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Immersive learning</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Haptics</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Chemistry education</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Organic chemistry</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Hydrocarbons</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Middle school science</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Introductory chemistry</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Hands-on learning</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Gamification</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-018-0345-4.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=345;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

