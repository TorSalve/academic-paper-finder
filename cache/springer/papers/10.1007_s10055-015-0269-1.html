<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="A cross-cultural comparison of salient perceptual characteristics of h"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Perceptual characteristics of virtual auditory environments from three listener groups were compared. To generate convincing and pleasing virtual auditory environments, acoustic impulse responses..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/19/3.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="A cross-cultural comparison of salient perceptual characteristics of height channels for a virtual auditory environment"/>

    <meta name="dc.source" content="Virtual Reality 2015 19:3"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2015-08-12"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2015 Springer-Verlag London"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Perceptual characteristics of virtual auditory environments from three listener groups were compared. To generate convincing and pleasing virtual auditory environments, acoustic impulse responses were measured in two venues using an innovative microphone array and convolved with two anechoic recordings. Subsequently, the convolved sound sources were assigned to loudspeakers (five horizontal channels and four height channels), and inter-channel level balances were optimized. The authors conducted a controlled listening test with two variables: height-channel configurations (eight conditions) and stimuli (four conditions&#8212;two musical selections times and two target venues) to determine the influence of (1) two control variables on the perceived appropriateness of virtual auditory environments and (2) the cultural background of three listener groups composed of participants from Canada (group&#160;1, 11 subjects), the USA (group&#160;2, 12 subjects), and Japan (group&#160;3, 14 subjects). The data analysis revealed that the configuration variable (the height position of the loudspeakers) has a greater influence on perceived appropriateness than the stimulus variable for all three groups. In addition, the results showed that although group 1 data had a similar listening response pattern to group&#160;2, the response of group&#160;3 was different. A subsequent analysis of reported descriptors found that groups&#160;1 and 2 chose height configurations that generated a &#8220;frontal&#8221; and &#8220;narrow&#8221; impression as a more appropriate virtual auditory environment, while group&#160;3 chose the same characteristics but as a less appropriate environment. Groups&#160;1 and 2 also described a less appropriate auditory environment with &#8220;wide, spacious, and surrounding&#8221; images that again were described by group&#160;3 as more appropriate. While room acoustics and loudspeaker size also contributed to the overall modulation of listeners&#8217; judgment, the findings support the idea that cultural background affects perceptual responses to spatial sound and is therefore important in rendering a homogeneous experience of a virtual auditory environment for listeners in remote spaces."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2015-08-12"/>

    <meta name="prism.volume" content="19"/>

    <meta name="prism.number" content="3"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="149"/>

    <meta name="prism.endingPage" content="160"/>

    <meta name="prism.copyright" content="2015 Springer-Verlag London"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-015-0269-1"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-015-0269-1"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-015-0269-1.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-015-0269-1"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="A cross-cultural comparison of salient perceptual characteristics of height channels for a virtual auditory environment"/>

    <meta name="citation_volume" content="19"/>

    <meta name="citation_issue" content="3"/>

    <meta name="citation_publication_date" content="2015/11"/>

    <meta name="citation_online_date" content="2015/08/12"/>

    <meta name="citation_firstpage" content="149"/>

    <meta name="citation_lastpage" content="160"/>

    <meta name="citation_article_type" content="SI: SPATIAL SOUND"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-015-0269-1"/>

    <meta name="DOI" content="10.1007/s10055-015-0269-1"/>

    <meta name="citation_doi" content="10.1007/s10055-015-0269-1"/>

    <meta name="description" content="Perceptual characteristics of virtual auditory environments from three listener groups were compared. To generate convincing and pleasing virtual auditory "/>

    <meta name="dc.creator" content="Sungyoung Kim"/>

    <meta name="dc.creator" content="Richard King"/>

    <meta name="dc.creator" content="Toru Kamekawa"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=Public Opin Q; citation_title=The measurement of values in surveys: a comparison of ratings and rankings; citation_author=DF Alwin, JA Krosnick; citation_volume=49; citation_issue=4; citation_publication_date=1985; citation_pages=535-552; citation_doi=10.1086/268949; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_journal_title=J Arboric; citation_title=Effects of vegetation on human response to sound; citation_author=LM Anderson, BE Mulligan, LS Goodman; citation_volume=10; citation_issue=2; citation_publication_date=1984; citation_pages=45-49; citation_id=CR2"/>

    <meta name="citation_reference" content="AURO Technologies (2013) AURO 3D listening formats. 
                    http://www.auro-technologies.com/system/listening-formats
                    
                  . As of April 2014"/>

    <meta name="citation_reference" content="citation_title=Spaces speaks, are you listening? experiencing aural architecture; citation_publication_date=2006; citation_id=CR4; citation_author=B Blesser; citation_author=L Salter; citation_publisher=The MIT Press"/>

    <meta name="citation_reference" content="Feys J (2015) npIntFactRep: nonparametric interaction tests for factorial designs with repeated measures. 
                    http://cran.r-project.org/web/packages/npIntFactRep/index.html
                    
                  . As of April 2015"/>

    <meta name="citation_reference" content="Giragama CNW, Martens WL, Herath S, Wanasinghe DR, Sabbir AM (2003) Relating multilingual semantic scales to a common timbre space - Part II. In: Proceedings of audio engineering society 115th international convention, New York, USA. AES. Preprint 5895"/>

    <meta name="citation_reference" content="Hamasaki K, Hiyama K, Okumura R (2005) The 22.2 Multichannel Sound System and Its Application. In: Proceedings of audio engineering society 118th international convention, Barcelona, Spain. AES. Preprint 6406"/>

    <meta name="citation_reference" content="citation_journal_title=J Serv Mark; citation_title=Effects of music in service environments: a field study; citation_author=JD Herrington; citation_volume=10; citation_issue=2; citation_publication_date=1996; citation_pages=26-41; citation_doi=10.1108/08876049610114249; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_title=5.1 Surround sound, up and running. Music technology series; citation_publication_date=2007; citation_id=CR9; citation_author=T Holman; citation_publisher=Focal Press"/>

    <meta name="citation_reference" content="ITU-R (2012) Recommendation BS.775-3, multi-channel stereophonic sound system with or without accompanying picture. International telecommunications union radiocommunication assembly, Geneva, Switzerland"/>

    <meta name="citation_reference" content="citation_journal_title=J Acoust Soc Jpn (E); citation_title=A comparison between Japanese and Chinese adjectives which express auditory impressions; citation_author=S Iwamiya, M Zhan; citation_volume=18; citation_issue=6; citation_publication_date=1997; citation_pages=319-323; citation_doi=10.1250/ast.18.319; citation_id=CR11"/>

    <meta name="citation_reference" content="citation_journal_title=J Acoust Soc Am; citation_title=Significance of height loudspeaker positioning for perceived immersive sound field reproduction; citation_author=A Karampourniotis, S Kim, D Ko, R King, B Leonard; citation_volume=135; citation_publication_date=2014; citation_pages=2282; citation_doi=10.1121/1.4877483; citation_id=CR12"/>

    <meta name="citation_reference" content="Kim S, DeFrancisco M, Walker K, Marui A, Martens WL (2006) An examination of the influence of musical selection on listener preferences for multichannel microphone technique. In: Proceedings of audio engineering society 28th international conference on the future of audio technology&#8212;surround sound and beyond, Pite&#229;, Sweden. AES"/>

    <meta name="citation_reference" content="Kim S, Ko D, Nagendra A, Woszczyk W (2013) Subjective evaluation of multichannel sound with surround-height channels . In: Proceedings of audio engineering society 135th international convention, New York, USA. AES"/>

    <meta name="citation_reference" content="Kim S, Walker K, Martens WL (2007) Cross-cultural descriptive analysis of multichannel auditory imagery: a comparison of Japanese and English adjectives. In: Proceedings of the 13th regional convention of AES, Tokyo, Japan. AES"/>

    <meta name="citation_reference" content="Koichiro H, Hiyama S, Hamasaki K (2002) The minimum number of loudspeakers and its arrangement for reproducing the spatial impression of diffuse sound field. In: Proceedings of audio engineering society 113th international convention AES"/>

    <meta name="citation_reference" content="Martens WL, Kim S (2007) Verbal elicitation and scale construction for evaluating perceptual differences between four multichannel microphone techniques. In: Proceedings of audio engineering society 122nd international convention, Vienna, Austria. AES"/>

    <meta name="citation_reference" content="citation_journal_title=J Acoust Soc Am; citation_title=Comparison of Japanese and English language descriptions of piano performances captured using popular multichannel microphone arrays; citation_author=WL Martens, S Kim, A Marui; citation_volume=123; citation_issue=5; citation_publication_date=2008; citation_pages=3690; citation_doi=10.1121/1.2935071; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=J Acoust Soc Jpn (E); citation_title=Verbal expression of emotional impression of sound: a cross-cultural study; citation_author=S Namba, S Kuwano, T Hashimoto, B Berglund, ZD Rui, A Schick, H Hoege, M Florentine; citation_volume=12; citation_issue=1; citation_publication_date=1991; citation_pages=19-29; citation_doi=10.1250/ast.12.19; citation_id=CR19"/>

    <meta name="citation_reference" content="Olive SE (2004a) A multiple regression model for predicting loudspeaker preference using objective measurements: Part I&#8212;listening test results. In: Proceedings of audio engineering society 116th international convention, Berlin, Germany. AES. Preprint 6113"/>

    <meta name="citation_reference" content="Olive SE (2004b) A multiple regression model for predicting loudspeaker preference using objective measurements: Part II&#8212;development of the model. In: Proceedings of audio engineering society 117th international convention, SanFrancisco, USA. AES. Preprint 6190"/>

    <meta name="citation_reference" content="citation_journal_title=J Audio Eng Soc; citation_title=The detection of reflections in typical rooms; citation_author=SE Olive, FE Toole; citation_volume=37; citation_issue=7; citation_publication_date=1989; citation_pages=539-553; citation_id=CR22"/>

    <meta name="citation_reference" content="Olive SE, Welti T, McMullin E (2014) The influence of listeners&#8217; experience, age, and culture on headphone sound quality preferences. In: Proceedings of audio engineering society 135th international convention, LA, USA. AES"/>

    <meta name="citation_reference" content="citation_title=Spatial audio, music technology series; citation_publication_date=2001; citation_id=CR24; citation_author=F Rumsey; citation_publisher=Focal Press"/>

    <meta name="citation_reference" content="citation_journal_title=Curr Dir Psychol Sci; citation_title=The origin of cultural differences in cognition: evidence for the social orientation hypothesis; citation_author=MEW Varnum, I Grossmann, S Kitayama, RE Nisbett; citation_volume=19; citation_issue=1; citation_publication_date=2010; citation_pages=9-13; citation_doi=10.1177/0963721409359301; citation_id=CR25"/>

    <meta name="citation_reference" content="Woszczyk W, Ko D, Brett L, Benson D (2009) Selection and preparation of multichannel room impulse responses for interactive low-latency rendering of virtual rooms. In: Proceedings of the 16th international conference on sound and vibration, Kralow, Poland"/>

    <meta name="citation_author" content="Sungyoung Kim"/>

    <meta name="citation_author_email" content="sxkiee@rit.edu"/>

    <meta name="citation_author_institution" content="Rochester Institute of Technology, Rochester, USA"/>

    <meta name="citation_author" content="Richard King"/>

    <meta name="citation_author_email" content="richard.king@mcgill.ca"/>

    <meta name="citation_author_institution" content="McGill University, Montreal, Canada"/>

    <meta name="citation_author" content="Toru Kamekawa"/>

    <meta name="citation_author_email" content="kamekawa@ms.geidai.ac.jp"/>

    <meta name="citation_author_institution" content="Tokyo University of the Arts, Tokyo, Japan"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-015-0269-1&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2015/11/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-015-0269-1"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="A cross-cultural comparison of salient perceptual characteristics of height channels for a virtual auditory environment"/>
        <meta property="og:description" content="Perceptual characteristics of virtual auditory environments from three listener groups were compared. To generate convincing and pleasing virtual auditory environments, acoustic impulse responses were measured in two venues using an innovative microphone array and convolved with two anechoic recordings. Subsequently, the convolved sound sources were assigned to loudspeakers (five horizontal channels and four height channels), and inter-channel level balances were optimized. The authors conducted a controlled listening test with two variables: height-channel configurations (eight conditions) and stimuli (four conditions—two musical selections times and two target venues) to determine the influence of (1) two control variables on the perceived appropriateness of virtual auditory environments and (2) the cultural background of three listener groups composed of participants from Canada (group&amp;nbsp;1, 11 subjects), the USA (group&amp;nbsp;2, 12 subjects), and Japan (group&amp;nbsp;3, 14 subjects). The data analysis revealed that the configuration variable (the height position of the loudspeakers) has a greater influence on perceived appropriateness than the stimulus variable for all three groups. In addition, the results showed that although group 1 data had a similar listening response pattern to group&amp;nbsp;2, the response of group&amp;nbsp;3 was different. A subsequent analysis of reported descriptors found that groups&amp;nbsp;1 and 2 chose height configurations that generated a “frontal” and “narrow” impression as a more appropriate virtual auditory environment, while group&amp;nbsp;3 chose the same characteristics but as a less appropriate environment. Groups&amp;nbsp;1 and 2 also described a less appropriate auditory environment with “wide, spacious, and surrounding” images that again were described by group&amp;nbsp;3 as more appropriate. While room acoustics and loudspeaker size also contributed to the overall modulation of listeners’ judgment, the findings support the idea that cultural background affects perceptual responses to spatial sound and is therefore important in rendering a homogeneous experience of a virtual auditory environment for listeners in remote spaces."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>A cross-cultural comparison of salient perceptual characteristics of height channels for a virtual auditory environment | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-015-0269-1","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Height-channel perception, Multichannel-reproduced virtual auditory environment, Cross-cultural comparison","kwrd":["Height-channel_perception","Multichannel-reproduced_virtual_auditory_environment","Cross-cultural_comparison"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-015-0269-1","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-015-0269-1","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=269;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-015-0269-1">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            A cross-cultural comparison of salient perceptual characteristics of height channels for a virtual auditory environment
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-015-0269-1.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-015-0269-1.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">SI: SPATIAL SOUND</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2015-08-12" itemprop="datePublished">12 August 2015</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">A cross-cultural comparison of salient perceptual characteristics of height channels for a virtual auditory environment</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Sungyoung-Kim" data-author-popup="auth-Sungyoung-Kim" data-corresp-id="c1">Sungyoung Kim<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Rochester Institute of Technology" /><meta itemprop="address" content="grid.262613.2, 0000000123233518, Rochester Institute of Technology, Rochester, NY, 14618, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Richard-King" data-author-popup="auth-Richard-King">Richard King</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="McGill University" /><meta itemprop="address" content="grid.14709.3b, 0000000419368649, McGill University, Montreal, Canada" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Toru-Kamekawa" data-author-popup="auth-Toru-Kamekawa">Toru Kamekawa</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Tokyo University of the Arts" /><meta itemprop="address" content="grid.442988.b, Tokyo University of the Arts, Tokyo, Japan" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 19</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">149</span>–<span itemprop="pageEnd">160</span>(<span data-test="article-publication-year">2015</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">278 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">5 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-015-0269-1/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Perceptual characteristics of virtual auditory environments from three listener groups were compared. To generate convincing and pleasing virtual auditory environments, acoustic impulse responses were measured in two venues using an innovative microphone array and convolved with two anechoic recordings. Subsequently, the convolved sound sources were assigned to loudspeakers (five horizontal channels and four height channels), and inter-channel level balances were optimized. The authors conducted a controlled listening test with two variables: height-channel configurations (eight conditions) and stimuli (four conditions—two musical selections times and two target venues) to determine the influence of (1) two control variables on the perceived appropriateness of virtual auditory environments and (2) the cultural background of three listener groups composed of participants from Canada (group 1, 11 subjects), the USA (group 2, 12 subjects), and Japan (group 3, 14 subjects). The data analysis revealed that the configuration variable (the height position of the loudspeakers) has a greater influence on perceived appropriateness than the stimulus variable for all three groups. In addition, the results showed that although group 1 data had a similar listening response pattern to group 2, the response of group 3 was different. A subsequent analysis of reported descriptors found that groups 1 and 2 chose height configurations that generated a “frontal” and “narrow” impression as a more appropriate virtual auditory environment, while group 3 chose the same characteristics but as a less appropriate environment. Groups 1 and 2 also described a less appropriate auditory environment with “wide, spacious, and surrounding” images that again were described by group 3 as more appropriate. While room acoustics and loudspeaker size also contributed to the overall modulation of listeners’ judgment, the findings support the idea that cultural background affects perceptual responses to spatial sound and is therefore important in rendering a homogeneous experience of a virtual auditory environment for listeners in remote spaces.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>A virtual or augmented reality can be enhanced with a seamlessly integrated auditory environment as auditory information strongly influences listeners’ emotions (Anderson et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1984" title="Anderson LM, Mulligan BE, Goodman LS (1984) Effects of vegetation on human response to sound. J Arboric 10(2):45–49" href="/article/10.1007/s10055-015-0269-1#ref-CR2" id="ref-link-section-d13984e394">1984</a>; Herrington <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Herrington JD (1996) Effects of music in service environments: a field study. J Serv Mark 10(2):26–41" href="/article/10.1007/s10055-015-0269-1#ref-CR8" id="ref-link-section-d13984e397">1996</a>) who actively interact with their environment. An auditory environment refers to a space recognized through a collection of acoustical information in which a person can perceive characteristics of the space that he or she inhabits.</p><p>In the past, an auditory environment was confined by the physical characteristics of the space, which interacted with sound sources and changed the timbral and spatial features. For instance, even a prehistoric musician or priest knew that a produced voice in a cave increased the reverential fear of a god Blesser and Salter (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Blesser B, Salter L (2006) Spaces speaks, are you listening? experiencing aural architecture. The MIT Press, Massachusetts" href="/article/10.1007/s10055-015-0269-1#ref-CR4" id="ref-link-section-d13984e403">2006</a>) and that an auditory environment could be created by location. Thus, over centuries, architectural acousticians have endeavored to construct a space and associated auditory environment within which the produced sound field could immerse listeners.</p><p>Music presents an excellent example of the importance of an integrated auditory environment. As music has systematically evolved, both musicians and audiences have found that the acoustic condition of a space influences the appreciation of performed music. Consequently, many composers from Johann Sebastian Bach to Richard Wagner often considered the acoustics of certain venues and composed specific musical pieces for certain auditory environments Blesser and Salter (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Blesser B, Salter L (2006) Spaces speaks, are you listening? experiencing aural architecture. The MIT Press, Massachusetts" href="/article/10.1007/s10055-015-0269-1#ref-CR4" id="ref-link-section-d13984e409">2006</a>).</p><p>On the other hand, recent audio engineering technologies have enabled the creation of a virtual auditory environment and delivery to listeners. Through an electroacoustic system, a virtual auditory environment can provide listeners with a new auditory space and a new set of auditory characteristics that are distinctly different from the inherent acoustics of the original room.</p><p>Listeners today can experience a virtual auditory environment in various ways. For example, listening to music with headphones separates listeners from their physical auditory environment, placing them in a new environment circumscribed by the auditory components of the music. Similarly, listeners in a movie theater can be immersed in virtual auditory environments such as a car interior, underwater, or on a battlefield, for example, using a multichannel sound system.</p><p>Although not yet widely adopted, various electroacoustic system formats with an increasing number of channels and loudspeakers [from 5.1-channel ITU-R (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="ITU-R (2012) Recommendation BS.775-3, multi-channel stereophonic sound system with or without accompanying picture. International telecommunications union radiocommunication assembly, Geneva, Switzerland" href="/article/10.1007/s10055-015-0269-1#ref-CR10" id="ref-link-section-d13984e422">2012</a>) to 22.2-channel formats Hamasaki et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Hamasaki K, Hiyama K, Okumura R (2005) The 22.2 Multichannel Sound System and Its Application. In: Proceedings of audio engineering society 118th international convention, Barcelona, Spain. AES. Preprint 6406" href="/article/10.1007/s10055-015-0269-1#ref-CR7" id="ref-link-section-d13984e425">2005</a>)] are available for the consumer market.</p><p>According to the current recommendation from the Radiocommunication Sector of the International Telecommunication Union (ITU-R), loudspeakers located at the rear-side and front-center can deliver an auditory environment that surrounds and envelopes a listener with enhanced localization via for enhanced perceived realism and presence Rumsey (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Rumsey F (2001) Spatial audio, music technology series. Focal Press, Oxford" href="/article/10.1007/s10055-015-0269-1#ref-CR24" id="ref-link-section-d13984e431">2001</a>). As architectural acousticians build physical enclosures that bring optimal auditory environments to musicians and listeners, multichannel electroacoustic formats create a virtually optimal auditory environment.</p><p>However, the enhanced impression of “being in a virtual environment” is limited to a horizontal space; that is, when a salient sound source radiates from above or below the listening position, the current recommendation fails to precisely reconstruct the target acoustical information and the associated virtual auditory environment. Researchers have thus explored a new electroacoustic system using height channels that vertically extend the virtual auditory environment for enhanced listening experiences (Holman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Holman T (2007) 5.1 Surround sound, up and running. Music technology series, 2nd edn. Focal Press, Oxford" href="/article/10.1007/s10055-015-0269-1#ref-CR9" id="ref-link-section-d13984e437">2007</a>; Hamasaki et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Hamasaki K, Hiyama K, Okumura R (2005) The 22.2 Multichannel Sound System and Its Application. In: Proceedings of audio engineering society 118th international convention, Barcelona, Spain. AES. Preprint 6406" href="/article/10.1007/s10055-015-0269-1#ref-CR7" id="ref-link-section-d13984e440">2005</a>; AURO Technologies <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="AURO Technologies (2013) AURO 3D listening formats. &#xA;                    http://www.auro-technologies.com/system/listening-formats&#xA;                    &#xA;                  . As of April 2014" href="/article/10.1007/s10055-015-0269-1#ref-CR3" id="ref-link-section-d13984e443">2013</a>).</p><p>Although many formats have been proposed with regards to the placement of height loudspeakers, the perceptual influence associated with the configuration of the height channels on rendering a virtual auditory environment has not been thoroughly investigated. In the current study, the authors attempt to better understand the salient factors that influence the rendering of a convincing virtual auditory environment through a series of controlled listening tests.</p><p>A pilot study Karampourniotis et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Karampourniotis A, Kim S, Ko D, King R, Leonard B (2014) Significance of height loudspeaker positioning for perceived immersive sound field reproduction. J Acoust Soc Am 135:2282" href="/article/10.1007/s10055-015-0269-1#ref-CR12" id="ref-link-section-d13984e452">2014</a>) found that the height loudspeaker configuration has a greater influence on the sound quality than the content (reverberation type and/or musical selection) of height-channel signals. The current study is the validation experiment of the aforementioned pilot study and uses three listener groups to determine whether the configuration is significant regardless of the geometric, electroacoustic, and cultural differences of the groups. Consequently, the authors collected and compared the groups’ responses to various auditory environments in three locations—Canada, the USA, and Japan.</p><p>Moreover, the authors wanted to investigate whether the cultural differences of the listener groups would influence the perceptual characteristics of a virtual auditory environment. According to Blesser and Salter (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Blesser B, Salter L (2006) Spaces speaks, are you listening? experiencing aural architecture. The MIT Press, Massachusetts" href="/article/10.1007/s10055-015-0269-1#ref-CR4" id="ref-link-section-d13984e459">2006</a>) a listener “selects specific aural attributes of a space based on what is desirable in a particular cultural framework” to describe a given auditory environment<sup><a href="#Fn1"><span class="u-visually-hidden">Footnote </span>1</a></sup>, thus indicating the significance of a listener’s cultural background.</p><p>To date, several research projects have investigated cultural inuences on the perceived quality of sound sources ranging from noise Namba et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Namba S, Kuwano S, Hashimoto T, Berglund B, Rui ZD, Schick A, Hoege H, Florentine M (1991) Verbal expression of emotional impression of sound: a cross-cultural study. J Acoust Soc Jpn (E) 12(1):19–29" href="/article/10.1007/s10055-015-0269-1#ref-CR19" id="ref-link-section-d13984e474">1991</a>) to multichannel-reproduced piano music Kim et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Kim S, Walker K, Martens WL (2007) Cross-cultural descriptive analysis of multichannel auditory imagery: a comparison of Japanese and English adjectives. In: Proceedings of the 13th regional convention of AES, Tokyo, Japan. AES" href="/article/10.1007/s10055-015-0269-1#ref-CR15" id="ref-link-section-d13984e477">2007</a>). Some studies have concluded that elicited descriptors had the same literal meanings regardless of language differences (Iwamiya and Zhan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Iwamiya S, Zhan M (1997) A comparison between Japanese and Chinese adjectives which express auditory impressions. J Acoust Soc Jpn (E) 18(6):319–323" href="/article/10.1007/s10055-015-0269-1#ref-CR11" id="ref-link-section-d13984e480">1997</a>; Martens et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Martens WL, Kim S, Marui A (2008) Comparison of Japanese and English language descriptions of piano performances captured using popular multichannel microphone arrays. J Acoust Soc Am 123(5):3690" href="/article/10.1007/s10055-015-0269-1#ref-CR18" id="ref-link-section-d13984e483">2008</a>; Olive et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Olive SE, Welti T, McMullin E (2014) The influence of listeners’ experience, age, and culture on headphone sound quality preferences. In: Proceedings of audio engineering society 135th international convention, LA, USA. AES" href="/article/10.1007/s10055-015-0269-1#ref-CR23" id="ref-link-section-d13984e486">2014</a>); however, other studies have found that the same perceptual dimensions were described differently by two language groups (Namba et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Namba S, Kuwano S, Hashimoto T, Berglund B, Rui ZD, Schick A, Hoege H, Florentine M (1991) Verbal expression of emotional impression of sound: a cross-cultural study. J Acoust Soc Jpn (E) 12(1):19–29" href="/article/10.1007/s10055-015-0269-1#ref-CR19" id="ref-link-section-d13984e490">1991</a>; Giragama et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Giragama CNW, Martens WL, Herath S, Wanasinghe DR, Sabbir AM (2003) Relating multilingual semantic scales to a common timbre space - Part II. In: Proceedings of audio engineering society 115th international convention, New York, USA. AES. Preprint 5895" href="/article/10.1007/s10055-015-0269-1#ref-CR6" id="ref-link-section-d13984e493">2003</a>; Kim et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Kim S, Walker K, Martens WL (2007) Cross-cultural descriptive analysis of multichannel auditory imagery: a comparison of Japanese and English adjectives. In: Proceedings of the 13th regional convention of AES, Tokyo, Japan. AES" href="/article/10.1007/s10055-015-0269-1#ref-CR15" id="ref-link-section-d13984e496">2007</a>).</p><p>If a perceptual aspect was recognized differently and resulted in different descriptors based on linguistics, communicating and exchanging information through various language groups would require careful translation. For instance, Namba et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Namba S, Kuwano S, Hashimoto T, Berglund B, Rui ZD, Schick A, Hoege H, Florentine M (1991) Verbal expression of emotional impression of sound: a cross-cultural study. J Acoust Soc Jpn (E) 12(1):19–29" href="/article/10.1007/s10055-015-0269-1#ref-CR19" id="ref-link-section-d13984e502">1991</a>) found that Japanese, Swedish, and Chinese listeners had a neutral attitude toward the use of “loud” while German and North American listeners had a negative attitude. In this context, “loudness” should be an important factor for overall sound quality for these two groups and might influence their emotional responses. A study by Giragama et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Giragama CNW, Martens WL, Herath S, Wanasinghe DR, Sabbir AM (2003) Relating multilingual semantic scales to a common timbre space - Part II. In: Proceedings of audio engineering society 115th international convention, New York, USA. AES. Preprint 5895" href="/article/10.1007/s10055-015-0269-1#ref-CR6" id="ref-link-section-d13984e505">2003</a>) also asserted a semantic difference between Indo-European languages (English, Bengali, and Sinhala) and a non-Indo-European language (Japanese).</p><p>This is a practically important issue for listeners in a virtual auditory environment, who can enter to a shared virtual environment through a high-speed telecommunication technology and collaborate with other listeners from different linguistic background. Networked performance of music is a good example. If two (or more) virtual auditory environments cannot provide homogenous atmosphere for remote musicians, they would find it difficult to perform as an ensemble.</p><p>In the current study, it would have been ideal to conduct the three listener group experiments in one location in order to minimize the influence of room acoustics. Olive and Toole (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1989" title="Olive SE, Toole FE (1989) The detection of reflections in typical rooms. J Audio Eng Soc 37(7):539–553" href="/article/10.1007/s10055-015-0269-1#ref-CR22" id="ref-link-section-d13984e514">1989</a>) showed that room reflections could change perceived sound images of reproduced sound fields. Thus, three rooms should have homogeneous acoustical and electroacoustical conditions for three groups of listeners. Unfortunately, this requirement is hard to accomplish. Moreover, to completely remove the influence of room acoustics, the experiment should also be conducted in an anechoic chamber, which could reduce the ecological validity of the study results. Thus, as an alternative, the authors set an anchor condition—the listening room—without any acoustical treatment and compared the results with the other two treated rooms.</p><p>In the remainder of this paper, methods are described to render sound stimuli for a virtual auditory environment. The following section provides an explanation of the subjective evaluation, which is then followed by two sections on data analysis and results. The paper finishes with a discussion and conclusion.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Stimuli preparation</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Capturing the acoustical impulse responses of two target spaces</h3>
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0269-1/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0269-1/MediaObjects/10055_2015_269_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0269-1/MediaObjects/10055_2015_269_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>(<i>Upper panel</i>) Photograph of a eight-microphone array located in a space to capture the IRs. (<i>Lower panel</i>) A <i>top-view</i> illustration of eight microphones (FL, FR, RL, RR, FC, RC, HL and HR) in the array. The <i>circle</i> indicates an omnidirectional microphone, while a <i>symbol of eight</i> indicates a bidirectional microphone</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0269-1/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Various methods exist to render a virtual auditory environment using discrete multi-loudspeaker layers. A typical method is to render the acoustical information of a target space and reproduce it via loudspeakers. The information is an acoustic impulse response (IR), that is, the response of a space to a delta function. An IR can be computationally simulated using the geometric information of the space. Whereas the simulation provides users with positional exibility and controlled repeatability, it is computationally expensive to fully simulate an IR’s complex and long tails, and thus researchers have sampled various venues and generated a database that contains measured IRs at various venue positions. The IRs are then convolved with the anechoic recordings to create sound sources of the reproduction channels (loudspeakers) for a virtual auditory environment.</p><p>The quality of an IR is significant to the authenticity of the rendered virtual auditory environment. For the current study, the authors measured IRs from two selected venues with excellent acoustic quality and distinct physical characters. One venue has a medium reverberation time (1.40 s <span class="mathjax-tex">\(RT_{60}\)</span>
                           <sup><a href="#Fn2"><span class="u-visually-hidden">Footnote </span>2</a></sup> at 500 Hz), while the other has a long reverberation time (2.51 s <span class="mathjax-tex">\(RT_{60}\)</span>). An innovative eight-channel surround microphone array (illustrated in the upper panel of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0269-1#Fig1">1</a>) was used to capture the IRs of the two venues. The lower panel illustrates the positions and types of the eight microphones; a circle indicates an omnidirectional microphone, while a figure-eight (8) indicates a bidirectional microphone. In order to capture height information, the array has two figure-eight microphones with azimuths of <span class="mathjax-tex">\(\pm\)</span>90<span class="mathjax-tex">\(^\circ\)</span> and elevations of +45<span class="mathjax-tex">\(^\circ\)</span>. These two height-channel microphones—height-left (HL) and height-right (HR)—were above a 2-m by 2-m array of four omnidirectional microphones at front-left (FL), front-right (FR), rear-left (RL), and rear-right (RR) positions. Two additional figure-eight microphones—front-center (FC) and rear-center (RC)—were positioned in the front (azimuth of 0<span class="mathjax-tex">\(^\circ\)</span>) and rear wall (azimuth of 180<span class="mathjax-tex">\(^\circ\)</span>).</p><p>The IRs were measured at three positions. In the space of the medium reverberation time, the microphone array was located at a 2-, 3.5-, and 5-m distance from the sound source, and 3-, 6.5-, and 10-m distance in the long reverberant space. At each position, the height of the microphone array was changed (2, 3, and 4m). In each venue, a total of 72 IRs (3 heights <span class="mathjax-tex">\(\times\)</span> 3 positions <span class="mathjax-tex">\(\times\)</span> 8 mics) were measured. More details of the IR measurement and process for virtual room rendering are explained in Woszczyk et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Woszczyk W, Ko D, Brett L, Benson D (2009) Selection and preparation of multichannel room impulse responses for interactive low-latency rendering of virtual rooms. In: Proceedings of the 16th international conference on sound and vibration, Kralow, Poland" href="/article/10.1007/s10055-015-0269-1#ref-CR26" id="ref-link-section-d13984e844">2009</a>).</p><p>We wanted to recreate a virtual auditory environment of a concert venue and thus chose musical stimuli instead of static noise or speech. After convolving many anechoic musical selections, two sound sources (a clarinet solo and a male chorus) were selected for the listening experiment as these sources caused less fatigue in a long and repetitive process.</p><h3 class="c-article__sub-heading" id="Sec4">Reproduction condition</h3><p>The experiment utilized two layers of loudspeakers. Five loudspeakers were located at the listener’s ear height (1.2 m) as per the ITU-R recommendation. Twelve loudspeakers were positioned with an elevation of 30<span class="mathjax-tex">\(^\circ\)</span> (2-m height) and azimuths of <span class="mathjax-tex">\(\pm\)</span>30<span class="mathjax-tex">\(^\circ\)</span>, <span class="mathjax-tex">\(\pm\)</span>50<span class="mathjax-tex">\(^\circ\)</span>, <span class="mathjax-tex">\(\pm\)</span>70<span class="mathjax-tex">\(^\circ\)</span>, <span class="mathjax-tex">\(\pm\)</span>90<span class="mathjax-tex">\(^\circ\)</span>, <span class="mathjax-tex">\(\pm\)</span>110<span class="mathjax-tex">\(^\circ\)</span>, and <span class="mathjax-tex">\(\pm\)</span>130<span class="mathjax-tex">\(^\circ\)</span>, respectively. The loudspeaker positions are illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0269-1#Fig2">2</a>. The height angle was chosen based on an empirical observation that 30<span class="mathjax-tex">\(^\circ\)</span> is the maximum vertical elevation in a typical living room. Each height loudspeaker was pitched down (<span class="mathjax-tex">\(-\)</span>30<span class="mathjax-tex">\(^\circ\)</span>) to a listening position.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0269-1/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0269-1/MediaObjects/10055_2015_269_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0269-1/MediaObjects/10055_2015_269_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>An illustration of the reproduction room and loudspeaker positions. Twelve height loudspeakers were located at azimuths of <span class="mathjax-tex">\(\pm\)</span>30<span class="mathjax-tex">\(^\circ\)</span>, <span class="mathjax-tex">\(\pm\)</span>50<span class="mathjax-tex">\(^\circ\)</span>, <span class="mathjax-tex">\(\pm\)</span>70<span class="mathjax-tex">\(^\circ\)</span>, <span class="mathjax-tex">\(\pm\)</span>90<span class="mathjax-tex">\(^\circ\)</span>, <span class="mathjax-tex">\(\pm\)</span>110<span class="mathjax-tex">\(^\circ\)</span>, and <span class="mathjax-tex">\(\pm\)</span>130<span class="mathjax-tex">\(^\circ\)</span> with an elevation of 30<span class="mathjax-tex">\(^\circ\)</span> and five <i>horizontal</i> loudspeakers were located according to ITU-R BS 775.3 ITU-R (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="ITU-R (2012) Recommendation BS.775-3, multi-channel stereophonic sound system with or without accompanying picture. International telecommunications union radiocommunication assembly, Geneva, Switzerland" href="/article/10.1007/s10055-015-0269-1#ref-CR10" id="ref-link-section-d13984e1511">2012</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0269-1/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Listening tests were conducted at three locations: the Immersive Presence Laboratory (A820) of the Centre for Interdisciplinary Research in Music Media and Technology (CIRMMT) at McGill University (Canada: group 1), the CAST Conference Room at the Rochester Institute of Technology (US: group 2), and Studio B on the Senju Campus of Tokyo University of the Arts (Japan: group 3). Two rooms (McGill University and Tokyo University of the Arts) were acoustically treated to reduce the influence of strong reflections from the walls and excessive standing waves, while the other room was not acoustically treated and was chosen to represent a normal listening environment. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0269-1#Fig3">3</a> shows the rooms used for the listening experiments—CIRMMT A820, the CAST Conference Room, and Studio B with loudspeakers. Room dimensions, reverberation times, and noise criterion (NC) are listed in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0269-1#Tab1">1</a>. The CAST Conference Room has the smallest volume but a longer reverberation time and a higher noise level than the other two rooms.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0269-1/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0269-1/MediaObjects/10055_2015_269_Fig3_HTML.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0269-1/MediaObjects/10055_2015_269_Fig3_HTML.jpg" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>The three listening rooms (CIRMMT A820, RIT CAST Conference Room, and Studio B). Seventeen loudspeakers were positioned as illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0269-1#Fig2">2</a>
                                    </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0269-1/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The authors chose three different models of active Genelec loudspeakers for the three locations. In the CAST Conference Room, 17 Genelec 8020B loudspeakers were used and 17 Genelec 8030Bs were used in the CIRMMT A820. In Studio B (group 3), five Genelec 8260A loudspeakers were used for the horizontal layers and 12 Genelec 8020Bs for the height layers. The output level of each loudspeaker was fixed to have 79 dB(A) at the listening position. The Genelec 8260A has a flatter magnitude response [29 Hz–21 kHz (<span class="mathjax-tex">\(\pm\)</span>1 dB)] than the 8030B [58 Hz–20 kHz (<span class="mathjax-tex">\(\pm\)</span>2 dB)] and the 8020B [66 Hz– 20 kHz (<span class="mathjax-tex">\(\pm\)</span>3 dB)]. We informally compared the 8020B with the 8030B and found that the 8020B showed a lack of tightness in the low frequency (bass) and a relatively weak presence in the mid-frequency range (around 2 kHz). Practical limitations (i.e., multiple pairs of loudspeakers in one location) prevented us from examining whether the subtle differences in loudspeakers would cause a significant influence on listeners’ perceived spatial integrity.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Dimensions, reverberation times, and noise criterion of the three listening rooms</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-015-0269-1/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec5">Rendering the inter-channel level balance for an optimal virtual auditory environment</h3><p>Before the main experiment (perceptual characteristics of height channel and the cross-cultural influence), the authors conducted a pilot study that investigated the influence of height loudspeaker signals and positions Kim et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Kim S, Ko D, Nagendra A, Woszczyk W (2013) Subjective evaluation of multichannel sound with surround-height channels . In: Proceedings of audio engineering society 135th international convention, New York, USA. AES" href="/article/10.1007/s10055-015-0269-1#ref-CR14" id="ref-link-section-d13984e2028">2013</a>) on perceived immersiveness and appropriateness.</p><p>However, one missing aspect of the pilot study was external validity and legitimacy of the used stimuli and, in particular, the balance of signals over the loudspeakers for a convincing virtual auditory environment. After the pilot experiment, listeners provided comments such as “a lack of realistic impression being in a large space,” “too much reverberant,” “hard to localize the source position,” among others. Therefore, the authors carefully chose proper sound sources and mixed the correct balance to generate a new set of stimuli for the current listening experiment.</p><p>First, the authors convolved all 72 IRs with anechoic music to create the sound sources. The second author, who is a professional music recording engineer/producer and a multi-Grammy awardee, then selected appropriate sound sources for each of the nine loudspeakers and subsequently optimized the balance of the entire sound field for a convincing and realistic concert hall experience. In many spatial sound reproduction studies, researchers often fail to include this optimization process and reach conclusions without considering the importance of the perceived sound quality. While debatable, “human-centric” is a key concept in virtual reality-related studies, and the current study was focused on generating very valid stimuli for a virtual auditory environment wherein listeners could enjoy the provided auditory scenes.</p><p>The authors selected the reference positions of the height loudspeakers for this optimization and chose four height channels based on a previous study result that found a four-channel height was the minimum number required to deliver diffusive sound impressions Koichiro et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Koichiro H, Hiyama S, Hamasaki K (2002) The minimum number of loudspeakers and its arrangement for reproducing the spatial impression of diffuse sound field. In: Proceedings of audio engineering society 113th international convention AES" href="/article/10.1007/s10055-015-0269-1#ref-CR16" id="ref-link-section-d13984e2040">2002</a>). The positions of the four loudspeakers followed the Auro3D height positions (<span class="mathjax-tex">\(\pm\)</span>30<span class="mathjax-tex">\(^\circ\)</span> and <span class="mathjax-tex">\(\pm\)</span>110<span class="mathjax-tex">\(^\circ\)</span> that are directly above the left-, right-, left-surround and right-surround loudspeaker of the ITU-recommended horizontal loudspeaker position). With the nine-channel loudspeakers, four multichannel mixes (two sound sources, clarinet and male choir, and two venues) were generated and used for the listening experiment.</p><p>At this point, the authors posed the question: should the optimization process be done strictly according to personal taste or should a professional recording/mixing engineer (or Tonmeister) rely upon an objective standard that is based upon some consensus derived from his or her training? This question has been thoroughly studied via a series of previous investigations (Kim et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Kim S, DeFrancisco M, Walker K, Marui A, Martens WL (2006) An examination of the influence of musical selection on listener preferences for multichannel microphone technique. In: Proceedings of audio engineering society 28th international conference on the future of audio technology—surround sound and beyond, Piteå, Sweden. AES" href="/article/10.1007/s10055-015-0269-1#ref-CR13" id="ref-link-section-d13984e2133">2006</a>; Martens and Kim <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Martens WL, Kim S (2007) Verbal elicitation and scale construction for evaluating perceptual differences between four multichannel microphone techniques. In: Proceedings of audio engineering society 122nd international convention, Vienna, Austria. AES" href="/article/10.1007/s10055-015-0269-1#ref-CR17" id="ref-link-section-d13984e2136">2007</a>) that have resulted in some salient (and common) perceptual and physical grounds for a hedonic judgment. As the first author wrote Kim et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Kim S, DeFrancisco M, Walker K, Marui A, Martens WL (2006) An examination of the influence of musical selection on listener preferences for multichannel microphone technique. In: Proceedings of audio engineering society 28th international conference on the future of audio technology—surround sound and beyond, Piteå, Sweden. AES" href="/article/10.1007/s10055-015-0269-1#ref-CR13" id="ref-link-section-d13984e2139">2006</a>), “Tonmeisters participate in a discipline which may be described primarily as <i>recreative</i>, meaning that its esthetic aim is the recreation of natural acoustical properties of original sound sources in recording spaces. Tonmeisters, therefore, are not free to make optimizations according to any whim or fancy; instead they employ a skill of representation built over years of experience, aural training, and natural observation.”</p></div></div></section><section aria-labelledby="Sec6"><div class="c-article-section" id="Sec6-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec6">Listening experiment</h2><div class="c-article-section__content" id="Sec6-content"><p>The experiment used the nine-channel music reproduced via five horizontal loudspeakers and four height loudspeakers. The five horizontal loudspeakers were set according to the ITU-recommended configuration and the four height loudspeakers were selected from 12 height loudspeakers. While it was possible to have a total of 15 configurations for four height channels (without considering asymmetric positions), eight configurations were used in the experiment (listed in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0269-1#Tab2">2</a>), and some configurations were excluded. For instance, the configuration with four height loudspeakers located at <span class="mathjax-tex">\(\pm 30^\circ\)</span> and <span class="mathjax-tex">\(\pm 50^\circ\)</span> was not meaningful due to the frontal-focused positions.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Eight reproduction configurations of four height channels</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-015-0269-1/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>As previously stated, the experiment was conducted in three locations (Canada: group 1, USA: group 2, and Japan: group 3). Eleven trained listeners that comprised group 1 were master’s students or faculty members of the Sound Recording Area at McGill University and trained as classical recording engineers/producers with multichannel audio-mixing experience. Twelve students from various disciplines formed group 2 and represented ordinary listeners and consumers. While not experienced, the listeners of group 2 had taken a fundamental technical ear-training course before the experiment. In Japan, 14 listeners participated in the listening experiment (group 3). These were students and faculty members of the Tokyo University of the Arts who studied and taught sound recording and psychoacoustics. This group also represented an experienced listener group. Although the authors did not conduct a formal audiometry test, none of the listeners had difficulties in either everyday listening or critical listening for music production.</p><p>Listeners in all locations had the same instructions: to compare eight different configurations of height channels (listed in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0269-1#Tab2">2</a>) with the same five horizontal channels and to evaluate the sound quality of the given stimulus. Some listeners found it hard to define the sound quality and in such cases, the authors asked them to judge how well one configuration appropriately integrated the music with the listener. Using that definition of sound quality, each listener was asked to rank 8 configurations using an ordinal scale ranging from 1 (least appropriate) to 8 (most appropriate). A ranking system was used in order to compel listeners to differentiate the eight reproduction conditions, which prevented listeners from evaluating all (or some) of the conditions as the same. Ranking was also chosen because, according to Alwin and Krosnick (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1985" title="Alwin DF, Krosnick JA (1985) The measurement of values in surveys: a comparison of ratings and rankings. Public Opin Q 49(4):535–552" href="/article/10.1007/s10055-015-0269-1#ref-CR1" id="ref-link-section-d13984e3127">1985</a>), rating and ranking methods “are judged to be similar with respect to ordering the aggregate preferences of the sample.”</p><p>After the ranking, each listener was asked to describe perceptual characteristics that he or she had used to base the differences in the eight configurations. The authors used a triadic comparison in which each listener listened to three configurations—the highest-ranked configuration, the lowest-ranked configuration, and the reference of mixing (configuration 2 (<span class="mathjax-tex">\(\pm 30^\circ\)</span> and <span class="mathjax-tex">\(\pm 110^\circ\)</span>). A listener first indicated which of the three versions of the virtual auditory environment was most different from the other two and then suggested a term or phrase that described the way in which that stimulus differed. Before hearing the next three stimuli, each listener also provided a term that might be considered an appropriate antonym for the previously chosen term.</p></div></div></section><section aria-labelledby="Sec7"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7">Result I: Rank data analysis</h2><div class="c-article-section__content" id="Sec7-content">
                <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Mean rank of each configuration for the three listener groups</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-015-0269-1/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0269-1#Tab3">3</a> shows the mean ranks of each reproduction configuration. These descriptive statistics support at least two findings: (1) the collected rank data were modulated over the reproduction configurations, and (2) groups 1 and 2 had a similar rank pattern that differed from group 3. These mean ranks are overlaid in the Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0269-1#Fig4">4</a> to illustrate the rank pattern.</p><p>Furthermore, the authors conducted a Friedman test—a nonparametric statistical analysis—on the listeners’ rank data to test a null hypothesis that the medians of the eight configurations were the same and to determine the significance of the height-channel configuration. Since the experiment was repeated for four stimuli, a nonparametric test similar to a two-way ANOVA test was necessary. According to the MATLAB statistic toolbox documentation, a Friedman test “is similar to classical balanced two-way ANOVA, but it tests only for column effects after adjusting for possible row effects. It does not test for row effects or interaction effects.” Since a single Friedman test cannot determine both the column and row effects, two Friedman tests were separately conducted for the two variables—the height configuration and the stimulus. Moreover, an additional analysis was done to test the significance of interaction between the two variables using an R program–npIntFactRep Feys (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Feys J (2015) npIntFactRep: nonparametric interaction tests for factorial designs with repeated measures. &#xA;                    http://cran.r-project.org/web/packages/npIntFactRep/index.html&#xA;                    &#xA;                  . As of April 2015" href="/article/10.1007/s10055-015-0269-1#ref-CR5" id="ref-link-section-d13984e3456">2015</a>).</p><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0269-1#Tab4">4</a> summarizes the first Friedman test results of the three listener groups that rejected the null hypotheses for all groups [<span class="mathjax-tex">\(p = 0.0439\)</span> (group 1), <span class="mathjax-tex">\(p\,=\,0\)</span> (group 2), and <span class="mathjax-tex">\(p\,=\,0.0125\)</span> (group 3)]. In other words, the columns (reproduction configuration) significantly influenced the listeners’ rank data after adjusting for possible effects from the rows (stimulus) in all groups. In contrast, in the second Friedman test, the data was transposed, the columns indicated the stimulus type, and the rows indicated the reproduction configuration. The results showed that the columns (stimulus) were not a significant factor for all groups [<span class="mathjax-tex">\(p\,=\,0.9942\)</span> (group 1), <span class="mathjax-tex">\(p\,=\,0.9998\)</span> (group 2), and <span class="mathjax-tex">\(p\,=\,0.9997\)</span> (group 3)]. The interaction test results showed that only data from group 2 data were significantly influenced by the interaction between the height configuration and the stimulus [<span class="mathjax-tex">\(p\,=\,0.9563\)</span> (group 1), <span class="mathjax-tex">\(p\,=\,0.014\)</span> (group 2), and <span class="mathjax-tex">\(p\,=\,0.7646\)</span> (group 3)].</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 Friedman test summary table for the eight height configurations (columns) on the listeners’ rank data</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-015-0269-1/tables/4"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     
                <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0269-1/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0269-1/MediaObjects/10055_2015_269_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0269-1/MediaObjects/10055_2015_269_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>The <i>boxplots</i> of the three groups for the eight height-channel configurations. On each <i>box</i>, the central mark is the median and the edges of the box are the 25th and 75th ‰. In addition, each figure also plots a multiple-comparison test result such that the <i>asterisk symbol</i> represents a significantly different configuration from the symbol <i>square</i>. The figure also plots the mean ranks of the Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0269-1#Tab3">3</a> as <i>dotted lines</i> to display rank patterns of three listener groups</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0269-1/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>Subsequently, we conducted a post-hoc test (a multiple comparison) to determine significantly different pairs. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0269-1#Fig4">4</a> shows three sets of boxplots illustrating the median ranks of the eight height configurations for the three listener groups. The figure also includes the multiple-comparison test results. Configurations with median values symbolized by a marker were significantly different from configurations with a square marker. For group 1, configuration 6 (C6, <span class="mathjax-tex">\(\pm 50^\circ\)</span> &amp; <span class="mathjax-tex">\(\pm 130^\circ\)</span>) was significantly different from configuration 7 (C7, <span class="mathjax-tex">\(\pm 70^\circ\)</span> and <span class="mathjax-tex">\(\pm 110^\circ\)</span>), while configuration 1 (C1, <span class="mathjax-tex">\(\pm 30^\circ\)</span> and <span class="mathjax-tex">\(\pm 90^\circ\)</span>) and 4 (C4, <span class="mathjax-tex">\(\pm 50^\circ\)</span> and <span class="mathjax-tex">\(\pm 90^\circ\)</span>) were significantly different from configuration 6 (C6), 3 (C3, <span class="mathjax-tex">\(\pm 30^\circ\)</span> and <span class="mathjax-tex">\(\pm 130^\circ\)</span>), and 8 (C8, <span class="mathjax-tex">\(\pm 70^\circ\)</span> and <span class="mathjax-tex">\(\pm 130^\circ\)</span>) in group 2. Furthermore, configuration 1 (C1) was significantly different from configurations 3 (C3), 6 (C6), and 7 (C7) in group 3. The figure also plots the mean ranks of the Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0269-1#Tab3">3</a> as dotted lines to display rank patterns of three listener groups.</p></div></div></section><section aria-labelledby="Sec8"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Result II: Analysis of perceptual characteristics</h2><div class="c-article-section__content" id="Sec8-content"><p>Why did the groups differ on their choice of configurations for an appropriate virtual auditory environment? Was it because one listener group perceived idiosyncratically different characteristics from the same configuration due to the reproduction condition differences (such as room acoustics or loudspeakers used)? Or was it because of the group differences from their inherent (training and culturally associated) differences even though they perceived similar percepts for configurations? To better understand listeners’ perceptual foundations of the different rank order among the groups and to answer these questions, the authors analyzed the collected descriptors associated with each configuration.</p><p>In this analysis, the authors combined groups 1 and 2 and used them as a single group because the mean rank data of these two groups was similar—and the listeners spoke the same language—while group 3 was different (as shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0269-1#Tab3">3</a>).</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 Terms reported during the triadic comparison trials along with their frequency of occurrence</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-015-0269-1/tables/5"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     
                <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-015-0269-1/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0269-1/MediaObjects/10055_2015_269_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-015-0269-1/MediaObjects/10055_2015_269_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>The relative percentages of occurrence of high-ranked configurations and low-ranked configurations for each salient term. The <i>top panel</i> is associated with group 1 and 2 and the <i>bottom panel</i> is associated with group 3</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-015-0269-1/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-015-0269-1#Tab5">5</a> lists the reported terms in the order based upon their frequency of occurrence during the triadic comparison trials. The left two columns indicate representative terms and frequencies of groups 1 and 2 and the right three columns are equivalent English terms, frequencies, and the original Japanese terms of group 3. Terms that were mentioned fewer than two times do not appear.</p><p>If a group used a specific term more frequently, it was an indication that the term had been a perceptual basis that differentiated height configurations among the members. For instance, groups 1 and 2 most frequently used the term “frontal” (9.6 %), indicating that these listeners discriminated eight configurations based on whether each configuration brought a frontal image. In contrast, group 3 used “enveloping” (12 %) most frequently, which might be the most salient percept for the group.</p><p>The top six frequent terms for groups 1 and 2 were “frontal,” “wide,” “narrow,” “spacious,” “surround,” and “full” (together used about 50 %) while “enveloping,” “clear,” “wide,” “reverberant,” “frontal,” and “narrow” were used about 57 % by group 3.</p><p>Subsequently, we observed how frequently the top six terms were used to describe the high-ranked configurations and low-ranked configurations, respectively. The upper panel of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0269-1#Fig5">5</a> shows the relative percentage of occurrence of each salient term for groups 1 and 2. The dark-gray bars represent the percentage of the high-ranked configurations (C1, C4, and C7) and the light-gray bars represent the percentage of the low-ranked configurations (C3, C6, and C8). For instance, “frontal” comprised 30 % of all used terms in configurations 1, 4, and 7, while for configurations 3, 6, and 8, it was used 12 %. The results imply that groups 1 and 2 ranked the configurations associated with “frontal” and “narrow” images as high while they ranked the “wide,” “spacious,” and “surrounding” configurations as low. The bottom panel of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0269-1#Fig5">5</a> shows the results from group 3, which are opposite from the two previous groups; that is, “enveloping and wide” configurations (C3, C6, and C7) received high ranking while “frontal” and “narrow” configuration (C1) received low ranking.</p><p>The two graphs in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-015-0269-1#Fig5">5</a> show that listeners associated similar perceptual characteristics to describe the same height configurations, yet their higher-level judgments (such as hedonic or a preferential decisions) did not coincide. This result reinforces the supposition that each group’s rank judgement might be influenced by cultural and linguistic differences.</p><p>On the other hand, all three groups gave configuration 7 (<span class="mathjax-tex">\(\pm 70^\circ\)</span> and <span class="mathjax-tex">\(\pm 110^\circ\)</span>) relatively high ranking. However, the terms describing the configuration were not consistent over the groups. Groups 1 and 2 ranked the configuration 7 highly because it generated a “narrow” image, while group 3 did so because of a “wide” and “spacious” image. This implies that the external conditions of the experiment (room acoustics and loudspeaker size) differentiated perceptual characteristics of each listener group.</p><p>To summarize, the analysis of collected descriptions revealed an inter-group difference in perceiving virtual auditory environments. The difference is related to both (1) the cultural and linguistic backgrounds of the listener groups and (2) the external conditions of the experiment.</p></div></div></section><section aria-labelledby="Sec9"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">Discussion</h2><div class="c-article-section__content" id="Sec9-content"><p>Previous study results have shown that external conditions are important in sound quality evaluation (the loudspeaker type and associated characteristics, for instance, in (Olive <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004a" title="Olive SE (2004a) A multiple regression model for predicting loudspeaker preference using objective measurements: Part I—listening test results. In: Proceedings of audio engineering society 116th international convention, Berlin, Germany. AES. Preprint 6113" href="/article/10.1007/s10055-015-0269-1#ref-CR20" id="ref-link-section-d13984e5575">2004a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Olive SE (2004b) A multiple regression model for predicting loudspeaker preference using objective measurements: Part II—development of the model. In: Proceedings of audio engineering society 117th international convention, SanFrancisco, USA. AES. Preprint 6190" href="/article/10.1007/s10055-015-0269-1#ref-CR21" id="ref-link-section-d13984e5578">b</a>). Moreover, cultural diversity did not significantly influence sound quality judgement when the listeners used the same peripherals (i.e., when external conditions were controlled) Olive et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Olive SE, Welti T, McMullin E (2014) The influence of listeners’ experience, age, and culture on headphone sound quality preferences. In: Proceedings of audio engineering society 135th international convention, LA, USA. AES" href="/article/10.1007/s10055-015-0269-1#ref-CR23" id="ref-link-section-d13984e5581">2014</a>). These previous study results could lead one to conclude that listener group inherency is relatively less significant and could be a nuisance variable.</p><p>However, sound quality in the aforementioned studies was strongly associated with timbral attributes. “Timbre” can be directly related to the magnitude of spectral responses, and therefore it can be reliably compared to a reference—a flat spectrum. On the other hand, spatial attributes have no specific references and/or consistent anchors points for many listeners. For instance, it is hard to define the width of an appropriate width, and therefore, a listener in a large room might tend to judge the width of a sound field wider than a listener in a small room. The current study found that a group difference appeared when the listeners tried to characterize the physical dimensions of rendered virtual auditory scenes and influenced the listeners’ high-level hedonic judgments as well. If the external conditions were a more dominant factor, group 2 would have been different from the two other groups due to untreated room acoustics. However, the results showed that group 3 responses tended to be consistently different from the other two groups. Therefore, the cultural and linguistic background was not a nuisance variable in the perception of a virtual auditory environment at least for the listeners participating in this experiment.</p><p>Moreover, another previous cross-cultural comparative study of subjects’ perspective found cognitive differences between American and Japanese participants that stemmed from differences in social orientation Varnum et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Varnum MEW, Grossmann I, Kitayama S, Nisbett RE (2010) The origin of cultural differences in cognition: evidence for the social orientation hypothesis. Curr Dir Psychol Sci 19(1):9–13" href="/article/10.1007/s10055-015-0269-1#ref-CR25" id="ref-link-section-d13984e5590">2010</a>), with Americans being more likely to endorse the value of independence and Japanese tending to respect the social value of interdependence. Similarly, it might be possible for a North American to enter a virtual auditory environment and recognize the environment as a personal space while a Japanese listener might consider the environment as a shared space with neighbors, thus creating different cognitive results for the same perceptual characteristics.</p><p>Further investigations should be conducted to confirm this hypothetical listener dependency in the relationship between spatial attributes and cognitive idiosyncrasies. Previous studies on sound quality evaluation have justified their results by constructing a regression model that could objectively predict reported sound quality. With such a prediction model, the external validity of the current study results could possibly be improved. For example, Studio B (group 3) had components such as high ceilings and large loudspeakers, which differed from the other two listening scenarios. With physical parameters that account for such factors, a follow-up experiment could test whether two groups’ responses are influenced by physical parameters (even without placing listeners in two different locations). For this investigation, the authors are currently simulating room dimensions, acoustical characteristics, and loudspeaker directivity, as well as calculating physical characteristics at the listening positions.</p></div></div></section><section aria-labelledby="Sec10"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Conclusion</h2><div class="c-article-section__content" id="Sec10-content"><p>A subjective evaluation of four virtual auditory environments rendered from nine discrete loudspeakers was conducted for three listener groups. When asked to choose more appropriate height channels for a convincing virtual auditory environment, the position of the height channel was a significant factor in the listeners’ judgment. Subsequent analyses showed that the two North American groups compared, judged, and differentiated the various virtual auditory environments based on the following perceptions: frontal, wide, narrow, spacious, surround, and full, while the Japanese group differentiated by the following perceptions: enveloping, clear, wide, reverberant, frontal, and narrow. The North American listeners favored height loudspeaker configurations that delivered frontal and narrow sound images as more appropriate for the given virtual auditory environment but the Japanese listeners did not favor the same configurations and percepts. The findings support the existence of inter-group differences in recognition of a virtual auditory environment, which stems from the groups’ cultural and social backgrounds. Thus, to achieve a convincing rendering of a virtual auditory environment, not only should external conditions (such as room acoustics and loudspeaker type) be carefully considered, but also each listening group’s cultural and social background. The current work provides a foundation for subsequent related studies of effective rendering of a homogeneous virtual auditory environment for multiple listener groups.</p></div></div></section>
                        
                    

                    <section aria-labelledby="notes"><div class="c-article-section" id="notes-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="notes">Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1"><span class="c-article-footnote--listed__index">1.</span><div class="c-article-footnote--listed__content"><p>In their book Blesser and Salter (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Blesser B, Salter L (2006) Spaces speaks, are you listening? experiencing aural architecture. The MIT Press, Massachusetts" href="/article/10.1007/s10055-015-0269-1#ref-CR4" id="ref-link-section-d13984e466">2006</a>), Blesser and Salter used the term “aural architecture” as equivalent to an auditory environment and “aural architect” to a listener who reports aural attributes of a space.</p></div></li><li class="c-article-footnote--listed__item" id="Fn2"><span class="c-article-footnote--listed__index">2.</span><div class="c-article-footnote--listed__content"><p>
                                 <span class="mathjax-tex">\(RT_{60}\)</span> indicates a time for the initial excitation of acoustic energy to reduce <span class="mathjax-tex">\(-\)</span>60 dB and is a standard metric to indicate a reverberation time of a space.</p></div></li></ol></div></div></section><section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DF. Alwin, JA. Krosnick, " /><meta itemprop="datePublished" content="1985" /><meta itemprop="headline" content="Alwin DF, Krosnick JA (1985) The measurement of values in surveys: a comparison of ratings and rankings. Publi" /><p class="c-article-references__text" id="ref-CR1">Alwin DF, Krosnick JA (1985) The measurement of values in surveys: a comparison of ratings and rankings. Public Opin Q 49(4):535–552</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1086%2F268949" aria-label="View reference 1">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20measurement%20of%20values%20in%20surveys%3A%20a%20comparison%20of%20ratings%20and%20rankings&amp;journal=Public%20Opin%20Q&amp;volume=49&amp;issue=4&amp;pages=535-552&amp;publication_year=1985&amp;author=Alwin%2CDF&amp;author=Krosnick%2CJA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="LM. Anderson, BE. Mulligan, LS. Goodman, " /><meta itemprop="datePublished" content="1984" /><meta itemprop="headline" content="Anderson LM, Mulligan BE, Goodman LS (1984) Effects of vegetation on human response to sound. J Arboric 10(2):" /><p class="c-article-references__text" id="ref-CR2">Anderson LM, Mulligan BE, Goodman LS (1984) Effects of vegetation on human response to sound. J Arboric 10(2):45–49</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Effects%20of%20vegetation%20on%20human%20response%20to%20sound&amp;journal=J%20Arboric&amp;volume=10&amp;issue=2&amp;pages=45-49&amp;publication_year=1984&amp;author=Anderson%2CLM&amp;author=Mulligan%2CBE&amp;author=Goodman%2CLS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="AURO Technologies (2013) AURO 3D listening formats. http://www.auro-technologies.com/system/listening-formats." /><p class="c-article-references__text" id="ref-CR3">AURO Technologies (2013) AURO 3D listening formats. <a href="http://www.auro-technologies.com/system/listening-formats">http://www.auro-technologies.com/system/listening-formats</a>. As of April 2014</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="B. Blesser, L. Salter, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Blesser B, Salter L (2006) Spaces speaks, are you listening? experiencing aural architecture. The MIT Press, M" /><p class="c-article-references__text" id="ref-CR4">Blesser B, Salter L (2006) Spaces speaks, are you listening? experiencing aural architecture. The MIT Press, Massachusetts</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Spaces%20speaks%2C%20are%20you%20listening%3F%20experiencing%20aural%20architecture&amp;publication_year=2006&amp;author=Blesser%2CB&amp;author=Salter%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Feys J (2015) npIntFactRep: nonparametric interaction tests for factorial designs with repeated measures. http" /><p class="c-article-references__text" id="ref-CR5">Feys J (2015) npIntFactRep: nonparametric interaction tests for factorial designs with repeated measures. <a href="http://cran.r-project.org/web/packages/npIntFactRep/index.html">http://cran.r-project.org/web/packages/npIntFactRep/index.html</a>. As of April 2015</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Giragama CNW, Martens WL, Herath S, Wanasinghe DR, Sabbir AM (2003) Relating multilingual semantic scales to a" /><p class="c-article-references__text" id="ref-CR6">Giragama CNW, Martens WL, Herath S, Wanasinghe DR, Sabbir AM (2003) Relating multilingual semantic scales to a common timbre space - Part II. In: Proceedings of audio engineering society 115th international convention, New York, USA. AES. Preprint 5895</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hamasaki K, Hiyama K, Okumura R (2005) The 22.2 Multichannel Sound System and Its Application. In: Proceedings" /><p class="c-article-references__text" id="ref-CR7">Hamasaki K, Hiyama K, Okumura R (2005) The 22.2 Multichannel Sound System and Its Application. In: Proceedings of audio engineering society 118th international convention, Barcelona, Spain. AES. Preprint 6406</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JD. Herrington, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Herrington JD (1996) Effects of music in service environments: a field study. J Serv Mark 10(2):26–41" /><p class="c-article-references__text" id="ref-CR8">Herrington JD (1996) Effects of music in service environments: a field study. J Serv Mark 10(2):26–41</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1108%2F08876049610114249" aria-label="View reference 8">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Effects%20of%20music%20in%20service%20environments%3A%20a%20field%20study&amp;journal=J%20Serv%20Mark&amp;volume=10&amp;issue=2&amp;pages=26-41&amp;publication_year=1996&amp;author=Herrington%2CJD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="T. Holman, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Holman T (2007) 5.1 Surround sound, up and running. Music technology series, 2nd edn. Focal Press, Oxford" /><p class="c-article-references__text" id="ref-CR9">Holman T (2007) 5.1 Surround sound, up and running. Music technology series, 2nd edn. Focal Press, Oxford</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=5.1%20Surround%20sound%2C%20up%20and%20running.%20Music%20technology%20series&amp;publication_year=2007&amp;author=Holman%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="ITU-R (2012) Recommendation BS.775-3, multi-channel stereophonic sound system with or without accompanying pic" /><p class="c-article-references__text" id="ref-CR10">ITU-R (2012) Recommendation BS.775-3, multi-channel stereophonic sound system with or without accompanying picture. International telecommunications union radiocommunication assembly, Geneva, Switzerland</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Iwamiya, M. Zhan, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Iwamiya S, Zhan M (1997) A comparison between Japanese and Chinese adjectives which express auditory impressio" /><p class="c-article-references__text" id="ref-CR11">Iwamiya S, Zhan M (1997) A comparison between Japanese and Chinese adjectives which express auditory impressions. J Acoust Soc Jpn (E) 18(6):319–323</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1250%2Fast.18.319" aria-label="View reference 11">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20comparison%20between%20Japanese%20and%20Chinese%20adjectives%20which%20express%20auditory%20impressions&amp;journal=J%20Acoust%20Soc%20Jpn%20%28E%29&amp;volume=18&amp;issue=6&amp;pages=319-323&amp;publication_year=1997&amp;author=Iwamiya%2CS&amp;author=Zhan%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Karampourniotis, S. Kim, D. Ko, R. King, B. Leonard, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Karampourniotis A, Kim S, Ko D, King R, Leonard B (2014) Significance of height loudspeaker positioning for pe" /><p class="c-article-references__text" id="ref-CR12">Karampourniotis A, Kim S, Ko D, King R, Leonard B (2014) Significance of height loudspeaker positioning for perceived immersive sound field reproduction. J Acoust Soc Am 135:2282</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1121%2F1.4877483" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Significance%20of%20height%20loudspeaker%20positioning%20for%20perceived%20immersive%20sound%20field%20reproduction&amp;journal=J%20Acoust%20Soc%20Am&amp;volume=135&amp;publication_year=2014&amp;author=Karampourniotis%2CA&amp;author=Kim%2CS&amp;author=Ko%2CD&amp;author=King%2CR&amp;author=Leonard%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kim S, DeFrancisco M, Walker K, Marui A, Martens WL (2006) An examination of the influence of musical selectio" /><p class="c-article-references__text" id="ref-CR13">Kim S, DeFrancisco M, Walker K, Marui A, Martens WL (2006) An examination of the influence of musical selection on listener preferences for multichannel microphone technique. In: Proceedings of audio engineering society 28th international conference on the future of audio technology—surround sound and beyond, Piteå, Sweden. AES</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kim S, Ko D, Nagendra A, Woszczyk W (2013) Subjective evaluation of multichannel sound with surround-height ch" /><p class="c-article-references__text" id="ref-CR14">Kim S, Ko D, Nagendra A, Woszczyk W (2013) Subjective evaluation of multichannel sound with surround-height channels . In: Proceedings of audio engineering society 135th international convention, New York, USA. AES</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kim S, Walker K, Martens WL (2007) Cross-cultural descriptive analysis of multichannel auditory imagery: a com" /><p class="c-article-references__text" id="ref-CR15">Kim S, Walker K, Martens WL (2007) Cross-cultural descriptive analysis of multichannel auditory imagery: a comparison of Japanese and English adjectives. In: Proceedings of the 13th regional convention of AES, Tokyo, Japan. AES</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Koichiro H, Hiyama S, Hamasaki K (2002) The minimum number of loudspeakers and its arrangement for reproducing" /><p class="c-article-references__text" id="ref-CR16">Koichiro H, Hiyama S, Hamasaki K (2002) The minimum number of loudspeakers and its arrangement for reproducing the spatial impression of diffuse sound field. In: Proceedings of audio engineering society 113th international convention AES</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Martens WL, Kim S (2007) Verbal elicitation and scale construction for evaluating perceptual differences betwe" /><p class="c-article-references__text" id="ref-CR17">Martens WL, Kim S (2007) Verbal elicitation and scale construction for evaluating perceptual differences between four multichannel microphone techniques. In: Proceedings of audio engineering society 122nd international convention, Vienna, Austria. AES</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="WL. Martens, S. Kim, A. Marui, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Martens WL, Kim S, Marui A (2008) Comparison of Japanese and English language descriptions of piano performanc" /><p class="c-article-references__text" id="ref-CR18">Martens WL, Kim S, Marui A (2008) Comparison of Japanese and English language descriptions of piano performances captured using popular multichannel microphone arrays. J Acoust Soc Am 123(5):3690</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1121%2F1.2935071" aria-label="View reference 18">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Comparison%20of%20Japanese%20and%20English%20language%20descriptions%20of%20piano%20performances%20captured%20using%20popular%20multichannel%20microphone%20arrays&amp;journal=J%20Acoust%20Soc%20Am&amp;volume=123&amp;issue=5&amp;publication_year=2008&amp;author=Martens%2CWL&amp;author=Kim%2CS&amp;author=Marui%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Namba, S. Kuwano, T. Hashimoto, B. Berglund, ZD. Rui, A. Schick, H. Hoege, M. Florentine, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="Namba S, Kuwano S, Hashimoto T, Berglund B, Rui ZD, Schick A, Hoege H, Florentine M (1991) Verbal expression o" /><p class="c-article-references__text" id="ref-CR19">Namba S, Kuwano S, Hashimoto T, Berglund B, Rui ZD, Schick A, Hoege H, Florentine M (1991) Verbal expression of emotional impression of sound: a cross-cultural study. J Acoust Soc Jpn (E) 12(1):19–29</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1250%2Fast.12.19" aria-label="View reference 19">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Verbal%20expression%20of%20emotional%20impression%20of%20sound%3A%20a%20cross-cultural%20study&amp;journal=J%20Acoust%20Soc%20Jpn%20%28E%29&amp;volume=12&amp;issue=1&amp;pages=19-29&amp;publication_year=1991&amp;author=Namba%2CS&amp;author=Kuwano%2CS&amp;author=Hashimoto%2CT&amp;author=Berglund%2CB&amp;author=Rui%2CZD&amp;author=Schick%2CA&amp;author=Hoege%2CH&amp;author=Florentine%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Olive SE (2004a) A multiple regression model for predicting loudspeaker preference using objective measurement" /><p class="c-article-references__text" id="ref-CR20">Olive SE (2004a) A multiple regression model for predicting loudspeaker preference using objective measurements: Part I—listening test results. In: Proceedings of audio engineering society 116th international convention, Berlin, Germany. AES. Preprint 6113</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Olive SE (2004b) A multiple regression model for predicting loudspeaker preference using objective measurement" /><p class="c-article-references__text" id="ref-CR21">Olive SE (2004b) A multiple regression model for predicting loudspeaker preference using objective measurements: Part II—development of the model. In: Proceedings of audio engineering society 117th international convention, SanFrancisco, USA. AES. Preprint 6190</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SE. Olive, FE. Toole, " /><meta itemprop="datePublished" content="1989" /><meta itemprop="headline" content="Olive SE, Toole FE (1989) The detection of reflections in typical rooms. J Audio Eng Soc 37(7):539–553" /><p class="c-article-references__text" id="ref-CR22">Olive SE, Toole FE (1989) The detection of reflections in typical rooms. J Audio Eng Soc 37(7):539–553</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20detection%20of%20reflections%20in%20typical%20rooms&amp;journal=J%20Audio%20Eng%20Soc&amp;volume=37&amp;issue=7&amp;pages=539-553&amp;publication_year=1989&amp;author=Olive%2CSE&amp;author=Toole%2CFE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Olive SE, Welti T, McMullin E (2014) The influence of listeners’ experience, age, and culture on headphone sou" /><p class="c-article-references__text" id="ref-CR23">Olive SE, Welti T, McMullin E (2014) The influence of listeners’ experience, age, and culture on headphone sound quality preferences. In: Proceedings of audio engineering society 135th international convention, LA, USA. AES</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="F. Rumsey, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Rumsey F (2001) Spatial audio, music technology series. Focal Press, Oxford" /><p class="c-article-references__text" id="ref-CR24">Rumsey F (2001) Spatial audio, music technology series. Focal Press, Oxford</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatial%20audio%2C%20music%20technology%20series&amp;publication_year=2001&amp;author=Rumsey%2CF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MEW. Varnum, I. Grossmann, S. Kitayama, RE. Nisbett, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Varnum MEW, Grossmann I, Kitayama S, Nisbett RE (2010) The origin of cultural differences in cognition: eviden" /><p class="c-article-references__text" id="ref-CR25">Varnum MEW, Grossmann I, Kitayama S, Nisbett RE (2010) The origin of cultural differences in cognition: evidence for the social orientation hypothesis. Curr Dir Psychol Sci 19(1):9–13</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1177%2F0963721409359301" aria-label="View reference 25">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20origin%20of%20cultural%20differences%20in%20cognition%3A%20evidence%20for%20the%20social%20orientation%20hypothesis&amp;journal=Curr%20Dir%20Psychol%20Sci&amp;volume=19&amp;issue=1&amp;pages=9-13&amp;publication_year=2010&amp;author=Varnum%2CMEW&amp;author=Grossmann%2CI&amp;author=Kitayama%2CS&amp;author=Nisbett%2CRE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Woszczyk W, Ko D, Brett L, Benson D (2009) Selection and preparation of multichannel room impulse responses fo" /><p class="c-article-references__text" id="ref-CR26">Woszczyk W, Ko D, Brett L, Benson D (2009) Selection and preparation of multichannel room impulse responses for interactive low-latency rendering of virtual rooms. In: Proceedings of the 16th international conference on sound and vibration, Kralow, Poland</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-015-0269-1-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Rochester Institute of Technology, Rochester, NY, 14618, USA</p><p class="c-article-author-affiliation__authors-list">Sungyoung Kim</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">McGill University, Montreal, Canada</p><p class="c-article-author-affiliation__authors-list">Richard King</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Tokyo University of the Arts, Tokyo, Japan</p><p class="c-article-author-affiliation__authors-list">Toru Kamekawa</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Sungyoung-Kim"><span class="c-article-authors-search__title u-h3 js-search-name">Sungyoung Kim</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Sungyoung+Kim&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Sungyoung+Kim" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Sungyoung+Kim%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Richard-King"><span class="c-article-authors-search__title u-h3 js-search-name">Richard King</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Richard+King&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Richard+King" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Richard+King%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Toru-Kamekawa"><span class="c-article-authors-search__title u-h3 js-search-name">Toru Kamekawa</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Toru+Kamekawa&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Toru+Kamekawa" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Toru+Kamekawa%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-015-0269-1/email/correspondent/c1/new">Sungyoung Kim</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=A%20cross-cultural%20comparison%20of%20salient%20perceptual%20characteristics%20of%20height%20channels%20for%20a%20virtual%20auditory%20environment&amp;author=Sungyoung%20Kim%20et%20al&amp;contentID=10.1007%2Fs10055-015-0269-1&amp;publication=1359-4338&amp;publicationDate=2015-08-12&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-015-0269-1" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-015-0269-1" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Kim, S., King, R. &amp; Kamekawa, T. A cross-cultural comparison of salient perceptual characteristics of height channels for a virtual auditory environment.
                    <i>Virtual Reality</i> <b>19, </b>149–160 (2015). https://doi.org/10.1007/s10055-015-0269-1</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-015-0269-1.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-02-03">03 February 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-08-04">04 August 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-08-12">12 August 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-11">November 2015</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-015-0269-1" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-015-0269-1</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Height-channel perception</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Multichannel-reproduced virtual auditory environment</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Cross-cultural comparison</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-015-0269-1.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=269;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

