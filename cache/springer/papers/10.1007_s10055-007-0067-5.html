<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Sensory-motor enhancement in a virtual therapeutic environment"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="The sensory-motor skills of persons with neuromuscular disabilities have been shown to be enhanced by intensive and repetitive therapeutic interventions. This paper describes a form of low..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/12/2.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Sensory-motor enhancement in a virtual therapeutic environment"/>

    <meta name="dc.source" content="Virtual Reality 2007 12:2"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2007-03-28"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2007 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="The sensory-motor skills of persons with neuromuscular disabilities have been shown to be enhanced by intensive and repetitive therapeutic interventions. This paper describes a form of low immersion virtual reality and a prototype, open source system that allow a user with significant physical disability to actively interact with computer-generated objects whose behaviors promote a game-like interaction. Unlike fully immersive and haptic virtual reality, this approach frees the user from head-mounted displays and gloves. It extracts the user&#8217;s real-time silhouette from the output of a remote video camera and uses that two-dimensional outline to interact with graphical objects on screen. In contrast to video games that have been modified with specialized interfaces, this virtual interaction system promotes the repetitive use of goal directed movements of the arms and body, which are essential to promote cortical reorganization, as well as discourage unwanted changes in muscle tissue that result in contracture. A prototype system demonstrates the potential of low immersion technology to motivate users and encourage participation in therapy. It also offers the potential of accommodating the sensory-motor skills of individuals with very significant impairment. The behaviors of the computer-generated graphics can be altered to allow use by those with very limited range of motion and/or motor control. These behaviors can be adjusted to provide a continuing challenge as the user&#8217;s skills improve. This prototype is described in terms of functional capabilities that include a silhouette extraction from a video image, and generation of graphical objects that interact with the silhouette. The work is extended with a discussion of a more sophisticated region of interest detection algorithm that can select specific parts of the body."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2007-03-28"/>

    <meta name="prism.volume" content="12"/>

    <meta name="prism.number" content="2"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="87"/>

    <meta name="prism.endingPage" content="97"/>

    <meta name="prism.copyright" content="2007 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-007-0067-5"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-007-0067-5"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-007-0067-5.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-007-0067-5"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Sensory-motor enhancement in a virtual therapeutic environment"/>

    <meta name="citation_volume" content="12"/>

    <meta name="citation_issue" content="2"/>

    <meta name="citation_publication_date" content="2008/06"/>

    <meta name="citation_online_date" content="2007/03/28"/>

    <meta name="citation_firstpage" content="87"/>

    <meta name="citation_lastpage" content="97"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-007-0067-5"/>

    <meta name="DOI" content="10.1007/s10055-007-0067-5"/>

    <meta name="citation_doi" content="10.1007/s10055-007-0067-5"/>

    <meta name="description" content="The sensory-motor skills of persons with neuromuscular disabilities have been shown to be enhanced by intensive and repetitive therapeutic interventions. T"/>

    <meta name="dc.creator" content="Richard A. Foulds"/>

    <meta name="dc.creator" content="David M. Saxe"/>

    <meta name="dc.creator" content="Arthur W. Joyce"/>

    <meta name="dc.creator" content="Sergei Adamovich"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Ahmad S (1994) A usable real-time 3D hand tracker. In: conference record of the Asilomar conference on signals, systems and computers, pp 1257&#8211;1261"/>

    <meta name="citation_reference" content="citation_journal_title=Presence; citation_title=The KidsRoom: a perceptually-based interactive and immersive story environment.; citation_author=AF Bobick, SS Intille, JW Davis, F Baird, C Pinhanez, LW Campbell, YA Ivanov, A Schutte, A Wilson; citation_volume=8; citation_issue=4; citation_publication_date=1999; citation_pages=369-393; citation_doi=10.1162/105474699566297; citation_id=CR2"/>

    <meta name="citation_reference" content="citation_journal_title=Neuroscience; citation_title=Nervous system reorganization following injury.; citation_author=R Chen, LG Cohen, M Hallet; citation_volume=111; citation_issue=4; citation_publication_date=2002; citation_pages=761-73; citation_doi=10.1016/S0306-4522(02)00025-8; citation_id=CR3"/>

    <meta name="citation_reference" content="Dougall F (1996) Video image based control system, US patent number 5534917"/>

    <meta name="citation_reference" content="citation_journal_title=Technol Disabil; citation_title=Stroke survivors&#8217; perception of a leisure-based virtual reality program.; citation_author=S Farrow, D Reid; citation_volume=16; citation_publication_date=2004; citation_pages=69-81; citation_id=CR5"/>

    <meta name="citation_reference" content="citation_journal_title=Artif Intell Med; citation_title=Augmenting reality in rehabilitation.; citation_author=WJ Greenleaf, M.A. MA Tovar; citation_volume=6; citation_issue=4; citation_publication_date=1994; citation_pages=289-299; citation_doi=10.1016/0933-3657(94)90034-5; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_journal_title=Can J Occup Ther Revue Canadienne d Ergotherapie; citation_title=The influence of virtual reality play on children&#8217;s motivation.; citation_author=K Harris, D Reid; citation_volume=72; citation_issue=1; citation_publication_date=2005; citation_pages=21-29; citation_id=CR7"/>

    <meta name="citation_reference" content="citation_journal_title=Educ Technol; citation_title=Virtual reality and education.; citation_author=S Helsel; citation_volume=32; citation_issue=5; citation_publication_date=1992; citation_pages=38-42; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Neural Syst Rehabil Eng; citation_title=Virtual reality-enhanced stroke rehabilitation.; citation_author=D Jack, R Boian, AS Merians, M Tremaine, GC Burdea, SV Adamovich, M Recce, H Poizner; citation_volume=9; citation_issue=3; citation_publication_date=2001; citation_pages=308-318; citation_doi=10.1109/7333.948460; citation_id=CR9"/>

    <meta name="citation_reference" content="citation_journal_title=[Controlled Clinical Trial. Journal Article] Arch Phys Med Rehabil; citation_title=Cortical reorganization and associated functional motor recovery after virtual reality in patients with chronic stroke: an experimenter-blind preliminary study.; citation_author=SH Jang, SH You, M Hallett, YW Cho, CM Park, SH Cho, HY Lee, TH Kim; citation_volume=86; citation_issue=11; citation_publication_date=2005; citation_pages=2218-2223; citation_doi=10.1016/j.apmr.2005.04.015; citation_id=CR10"/>

    <meta name="citation_reference" content="Jenkins W, Merzenich M (1987) Reorganization of neocortical representation after brain injury: a neurophysiological model of the bases of recovery from stroke. In: Sneil F, Herbert E, Carlson B (eds) Progress in Brain. Elsevier, New York"/>

    <meta name="citation_reference" content="Joyce AW, Phalangas AC (1995) Virtual interaction: an interface for individuals with disabilities. In: Proceedings of RESNA &#8217;95, pp 425&#8211;427"/>

    <meta name="citation_reference" content="Joyce AW, Phalangas AC (1998) The implementation and capabilities of a virtual interaction system. In: Proceedings of European conference on disabilities, virtual reality and associated technologies, Skovde, Sweden, pp 237&#8211;245"/>

    <meta name="citation_reference" content="Kizony R, Katz N, Weingarden H, Weiss PL (2002a) Immersion without encumbrance: adapting a virtual reality system for the rehabilitation of individuals with stroke and spinal cord injury. In: Proceedings of the 4th international conference on disability, virtual reality and associated technology. Vresprem, Hungary, pp 55&#8211;61"/>

    <meta name="citation_reference" content="Kizony R, Katz N, Weiss PL (2002b) Adapting a virtual reality system for the rehabilitation of individuals with stroke and spinal cord injury. In: Proceedings of the 1st international workshop on virtual reality in rehabilitation. Lausanne, Switzerland, pp 223&#8211;232"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Rehabil Eng; citation_title=Robot-aided neurorehabilitation.
                           ; citation_author=H.I Krebs, N Hogan, ML Aisen, BT Volpe; citation_volume=6; citation_issue=1; citation_publication_date=1998; citation_pages=75-87; citation_doi=10.1109/86.662623; citation_id=CR16"/>

    <meta name="citation_reference" content="Krueger M (1990) Artificial reality II. Addison-Wesley, Reading"/>

    <meta name="citation_reference" content="citation_journal_title=Commun ACM; citation_title=Environmental technology: making the real world virtual.; citation_author=M Krueger; citation_volume=36; citation_publication_date=1993; citation_pages=36-37; citation_doi=10.1145/159544.159563; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Biol Med; citation_title=Virtual reality for physically disabled people.
                           ; citation_author=T Kuhlen, C Dohle; citation_volume=25; citation_issue=2; citation_publication_date=1995; citation_pages=205-211; citation_doi=10.1016/0010-4825(94)00039-S; citation_id=CR19"/>

    <meta name="citation_reference" content="Lachapelle T, Foulds R (1992) Design of a low-immersion virtual reality system for children with disabilities. In: Proceedings of RESNA&#8217;92"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Rehabil Eng; citation_title=The bimanual lifting rehabilitator: an adaptive approach for therapy stroke patients.; citation_author=SP Lum, SL Lehman, DJ Reinkensmeyer; citation_volume=3; citation_issue=2; citation_publication_date=1995; citation_pages=166-174; citation_doi=10.1109/86.392371; citation_id=CR21"/>

    <meta name="citation_reference" content="Maes P, Darrell B, Pentland A (1995) The ALIVE system: wireless, full-body interaction with autonomous agents. Perceptual computing. MIT Media Laboratory, technical report no. 257 "/>

    <meta name="citation_reference" content="citation_journal_title=Stud Health Technol Inf; citation_title=Current uses of virtual reality for children with disabilities.; citation_author=J McComas, J Pivak, M Laflamme; citation_volume=58; citation_publication_date=1998; citation_pages=161-169; citation_id=CR23"/>

    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Neural substrates for the effects of rehabilitative training on motor recovery after ischemic infarction.; citation_author=RJ Nudo; citation_volume=272; citation_publication_date=1996; citation_pages=1791-1794; citation_doi=10.1126/science.272.5269.1791; citation_id=CR24"/>

    <meta name="citation_reference" content="citation_journal_title=Curr Opin Neurol; citation_title=Reflex hyperexcitability and muscle contracture in relation to spastic hypertonia.; citation_author=NJ O&#8217;Dwyer, L Ada; citation_volume=9; citation_issue=6; citation_publication_date=1996; citation_pages=451-455; citation_doi=10.1097/00019052-199612000-00010; citation_id=CR25"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Math Appl; citation_title=Integrating performance, live electronics and interactive video.; citation_author=S Pengilly; citation_volume=32; citation_issue=1; citation_publication_date=1996; citation_pages=75-77; citation_doi=10.1016/0898-1221(96)00088-0; citation_id=CR26"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Inf Technol Biomed; citation_title=Orthopedic telerehabilitation with virtual force feedback.; citation_author=V Popescu, G Burdea, M Bouzit, M Girone, V Hentz; citation_volume=4; citation_publication_date=2000; citation_pages=45-51; citation_doi=10.1109/4233.826858; citation_id=CR27"/>

    <meta name="citation_reference" content="citation_journal_title=Technol Disabil; citation_title=The use of virtual reality to improve upper-extremity efficiency skills iin children with cerebral palsy: a pilot study.; citation_author=D Reid; citation_volume=14; citation_publication_date=2002; citation_pages=53-61; citation_id=CR28"/>

    <meta name="citation_reference" content="citation_journal_title=Occup Ther Int; citation_title=The influence of virtual reality on playfulness in children with cerebral palsy: a pilot study.; citation_author=D Reid; citation_volume=11; citation_issue=3; citation_publication_date=2004; citation_pages=131-144; citation_doi=10.1002/oti.202; citation_id=CR29"/>

    <meta name="citation_reference" content="citation_journal_title=Pediatr Rehabil; citation_title=Benefits of a virtual play rehabilitation environment for children with cerebral palsy on perceptions of self-efficacy: a pilot study.; citation_author=DT Reid; citation_volume=5; citation_issue=3; citation_publication_date=2002; citation_pages=141-148; citation_doi=10.1080/1363849021000039344; citation_id=CR30"/>

    <meta name="citation_reference" content="citation_journal_title=Methods Inf Med; citation_title=Applications of virtual environments in medicine.; citation_author=G Riva; citation_volume=42; citation_issue=5; citation_publication_date=2003; citation_pages=524-534; citation_id=CR31"/>

    <meta name="citation_reference" content="citation_journal_title=Stud Health Technol Inf; citation_title=The status of virtual reality for the cognitive rehabilitation of persons with neurological disorders and acquired brain injury.; citation_author=AA Rizzo, JG Buckwalter; citation_volume=39; citation_publication_date=1997; citation_pages=22-33; citation_id=CR32"/>

    <meta name="citation_reference" content="Saxe D (1999) Virtual interaction using robust color skin detection. In: Proceedings of SIGCHI 1999, pp 330&#8211;331"/>

    <meta name="citation_reference" content="Saxe DM, Foulds RA (1996) Toward robust skin identification in video images. In: Proceedings of the 2nd conference on automatic face and gesture recognition. Killington, Vermont, pp 379&#8211;384"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Inf Technol Biomed; citation_title=Robust region of interest coding for improved sign language telecommunication.; citation_author=DM Saxe, RA Foulds; citation_volume=6; citation_issue=3; citation_publication_date=2002; citation_pages=310-316; citation_doi=10.1109/TITB.2002.806094; citation_id=CR35"/>

    <meta name="citation_reference" content="citation_journal_title=Stud Health Technol Inf; citation_title=Computer assisted therapy for multiple sclerosis and spinal cord injury patients: application of virtual reality.; citation_author=M Stefin; citation_volume=39; citation_publication_date=1997; citation_pages=64-72; citation_id=CR36"/>

    <meta name="citation_reference" content="citation_journal_title=J NeuroEngineering Rehabil; citation_title=Motor rehabilitation using virtual reality.; citation_author=H Sveistrup; citation_volume=1; citation_publication_date=2004; citation_pages=10; citation_doi=10.1186/1743-0003-1-10; citation_id=CR37"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Comput Vis; citation_title=Color indexing.; citation_author=MJ Swain, DH Ballard; citation_volume=7; citation_issue=1; citation_publication_date=1991; citation_pages=1-32; citation_doi=10.1007/BF00130487; citation_id=CR38"/>

    <meta name="citation_reference" content="citation_journal_title=Baillieres Clin Neurol; citation_title=Motor skill learning in cerebral palsy: movement, action, and computer-enhanced therapy.; citation_author=JP Wann, JD Turnbull; citation_volume=2; citation_issue=1; citation_publication_date=1993; citation_pages=15-28; citation_id=CR40"/>

    <meta name="citation_reference" content="citation_journal_title=J Neuroengineering Rehabil; citation_title=Video capture virtual reality as a flexible and effective rehabilitation tool.; citation_author=P Weiss, D Rand, N Katz, R Kizony; citation_volume=1; citation_publication_date=2004; citation_pages=12; citation_doi=10.1186/1743-0003-1-12; citation_id=CR41"/>

    <meta name="citation_reference" content="citation_journal_title=Dev Med Child Neurol; citation_title=Cortical reorganization induced by virtual reality therapy in a child with hemiparetic cerebral palsy.]; citation_author=SH You, SH Jang, YH Kim, YH Kwon, I Barrow, M Hallett; citation_volume=47; citation_issue=9; citation_publication_date=2005; citation_pages=628-635; citation_doi=10.1017/S0012162205001234; citation_id=CR42"/>

    <meta name="citation_author" content="Richard A. Foulds"/>

    <meta name="citation_author_email" content="foulds@njit.edu"/>

    <meta name="citation_author_institution" content="Department of Biomedical Engineering, New Jersey Institute of Technology, University Heights, Newark, USA"/>

    <meta name="citation_author" content="David M. Saxe"/>

    <meta name="citation_author_institution" content="Department of Biomedical Engineering, New Jersey Institute of Technology, University Heights, Newark, USA"/>

    <meta name="citation_author" content="Arthur W. Joyce"/>

    <meta name="citation_author_institution" content="Romeo Tango Software, Bear, USA"/>

    <meta name="citation_author" content="Sergei Adamovich"/>

    <meta name="citation_author_institution" content="Department of Biomedical Engineering, New Jersey Institute of Technology, University Heights, Newark, USA"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-007-0067-5&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2008/06/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-007-0067-5"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Sensory-motor enhancement in a virtual therapeutic environment"/>
        <meta property="og:description" content="The sensory-motor skills of persons with neuromuscular disabilities have been shown to be enhanced by intensive and repetitive therapeutic interventions. This paper describes a form of low immersion virtual reality and a prototype, open source system that allow a user with significant physical disability to actively interact with computer-generated objects whose behaviors promote a game-like interaction. Unlike fully immersive and haptic virtual reality, this approach frees the user from head-mounted displays and gloves. It extracts the user’s real-time silhouette from the output of a remote video camera and uses that two-dimensional outline to interact with graphical objects on screen. In contrast to video games that have been modified with specialized interfaces, this virtual interaction system promotes the repetitive use of goal directed movements of the arms and body, which are essential to promote cortical reorganization, as well as discourage unwanted changes in muscle tissue that result in contracture. A prototype system demonstrates the potential of low immersion technology to motivate users and encourage participation in therapy. It also offers the potential of accommodating the sensory-motor skills of individuals with very significant impairment. The behaviors of the computer-generated graphics can be altered to allow use by those with very limited range of motion and/or motor control. These behaviors can be adjusted to provide a continuing challenge as the user’s skills improve. This prototype is described in terms of functional capabilities that include a silhouette extraction from a video image, and generation of graphical objects that interact with the silhouette. The work is extended with a discussion of a more sophisticated region of interest detection algorithm that can select specific parts of the body."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Sensory-motor enhancement in a virtual therapeutic environment | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-007-0067-5","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Low-immersion, Rehabilitation, Cortical reorganization, Therapy, Sensory-motor skills, Biomedical engineering","kwrd":["Low-immersion","Rehabilitation","Cortical_reorganization","Therapy","Sensory-motor_skills","Biomedical_engineering"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"external-glitch","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-007-0067-5","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-007-0067-5","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=67;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-007-0067-5">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Sensory-motor enhancement in a virtual therapeutic environment
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-007-0067-5.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-007-0067-5.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2007-03-28" itemprop="datePublished">28 March 2007</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Sensory-motor enhancement in a virtual therapeutic environment</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Richard_A_-Foulds" data-author-popup="auth-Richard_A_-Foulds" data-corresp-id="c1">Richard A. Foulds<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University Heights" /><meta itemprop="address" content="grid.412499.3, Department of Biomedical Engineering, New Jersey Institute of Technology, University Heights, Newark, NJ, 07102-1982, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-David_M_-Saxe" data-author-popup="auth-David_M_-Saxe">David M. Saxe</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University Heights" /><meta itemprop="address" content="grid.412499.3, Department of Biomedical Engineering, New Jersey Institute of Technology, University Heights, Newark, NJ, 07102-1982, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Arthur_W_-Joyce" data-author-popup="auth-Arthur_W_-Joyce">Arthur W. Joyce III</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Romeo Tango Software" /><meta itemprop="address" content="Romeo Tango Software, P.O. Box 1501, Bear, DE, 19701-1501, USA" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Sergei-Adamovich" data-author-popup="auth-Sergei-Adamovich">Sergei Adamovich</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University Heights" /><meta itemprop="address" content="grid.412499.3, Department of Biomedical Engineering, New Jersey Institute of Technology, University Heights, Newark, NJ, 07102-1982, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 12</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">87</span>–<span itemprop="pageEnd">97</span>(<span data-test="article-publication-year">2008</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">201 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">2 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-007-0067-5/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>The sensory-motor skills of persons with neuromuscular disabilities have been shown to be enhanced by intensive and repetitive therapeutic interventions. This paper describes a form of low immersion virtual reality and a prototype, open source system that allow a user with significant physical disability to actively interact with computer-generated objects whose behaviors promote a game-like interaction. Unlike fully immersive and haptic virtual reality, this approach frees the user from head-mounted displays and gloves. It extracts the user’s real-time silhouette from the output of a remote video camera and uses that two-dimensional outline to interact with graphical objects on screen. In contrast to video games that have been modified with specialized interfaces, this virtual interaction system promotes the repetitive use of goal directed movements of the arms and body, which are essential to promote cortical reorganization, as well as discourage unwanted changes in muscle tissue that result in contracture. A prototype system demonstrates the potential of low immersion technology to motivate users and encourage participation in therapy. It also offers the potential of accommodating the sensory-motor skills of individuals with very significant impairment. The behaviors of the computer-generated graphics can be altered to allow use by those with very limited range of motion and/or motor control. These behaviors can be adjusted to provide a continuing challenge as the user’s skills improve. This prototype is described in terms of functional capabilities that include a silhouette extraction from a video image, and generation of graphical objects that interact with the silhouette. The work is extended with a discussion of a more sophisticated region of interest detection algorithm that can select specific parts of the body.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Enhancement of the sensory-motor skills of persons with significant neuromuscular disabilities (e.g. cerebral palsy, stroke and brain injury) is the objective of many therapeutic interventions in rehabilitation. An emerging body of literature suggests that intensive and repetitive training may modify neural organization and provide improved sensory-motor function by encouraging healthy neurons to assume the role of those cells that are damaged (Jenkins and Merzenich <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Jenkins W, Merzenich M (1987) Reorganization of neocortical representation after brain injury: a neurophysiological model of the bases of recovery from stroke. In: Sneil F, Herbert E, Carlson B (eds) Progress in Brain. Elsevier, New York" href="/article/10.1007/s10055-007-0067-5#ref-CR11" id="ref-link-section-d7950e343">1987</a>; Nudo <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Nudo RJ (1996) Neural substrates for the effects of rehabilitative training on motor recovery after ischemic infarction. Science 272:1791–1794" href="/article/10.1007/s10055-007-0067-5#ref-CR24" id="ref-link-section-d7950e346">1996</a>; Chen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Chen R, Cohen LG, Hallet M (2002) Nervous system reorganization following injury. Neuroscience 111(4):761–73" href="/article/10.1007/s10055-007-0067-5#ref-CR3" id="ref-link-section-d7950e349">2002</a>; O’Dwyer and Ada <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="O’Dwyer NJ, Ada L (1996) Reflex hyperexcitability and muscle contracture in relation to spastic hypertonia. Curr Opin Neurol 9(6):451–455" href="/article/10.1007/s10055-007-0067-5#ref-CR25" id="ref-link-section-d7950e352">1996</a>; Krebs et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Krebs H.I, Hogan N, Aisen ML, Volpe BT (1998) Robot-aided neurorehabilitation. IEEE Trans Rehabil Eng 6(1):75–87" href="/article/10.1007/s10055-007-0067-5#ref-CR16" id="ref-link-section-d7950e355">1998</a>). It is becoming clear that such neuroplasticity is less evident following passive movement of the limbs, and is more likely when the individual voluntarily begins and attempts to control the movement. Neural learning occurs most strongly when intention is confirmed by visual and proprioceptive feedback of movement to the brain. Additional clinical literature notes that changes in muscle tissue may contribute to the paresis or movement impairment in these individuals. When muscles are not used throughout their normal range of extension and contraction, as is often the case in persons with movement limitations, the muscle is biologically remodeled by reducing the number of sarcomeres and can no longer function over its original range of movement. This results in greatly reduced range of joint movement, known as a contracture. Prevention of contracture requires continual use of the limbs throughout their normal range of motion, while recovery from contracture can be encouraged by repeated use of the joints at the extremes of their compromised range of motion. O’Dwyer and Ada (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="O’Dwyer NJ, Ada L (1996) Reflex hyperexcitability and muscle contracture in relation to spastic hypertonia. Curr Opin Neurol 9(6):451–455" href="/article/10.1007/s10055-007-0067-5#ref-CR25" id="ref-link-section-d7950e359">1996</a>) offer an excellent review of contracture as it relates to neurological impairment.</p><p>A number of emerging therapeutic interventions make use of specialized exercise devices, modified robotic systems, and a number of virtual reality approaches. These technologies have the potential to provide repeatable and measurable training, increase the duration of the intervention by extending it from the clinical setting to the home, and allow for individualized interventions that address user-specific goals along a continuum of treatment. Krebs et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Krebs H.I, Hogan N, Aisen ML, Volpe BT (1998) Robot-aided neurorehabilitation. IEEE Trans Rehabil Eng 6(1):75–87" href="/article/10.1007/s10055-007-0067-5#ref-CR16" id="ref-link-section-d7950e365">1998</a>) and Lum et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Lum SP, Lehman SL, Reinkensmeyer DJ (1995) The bimanual lifting rehabilitator: an adaptive approach for therapy stroke patients. IEEE Trans Rehabil Eng 3(2):166–174" href="/article/10.1007/s10055-007-0067-5#ref-CR21" id="ref-link-section-d7950e368">1995</a>) have applied robotic manipulators in the rehabilitation of persons with stroke. These technologies offer electromechanical support for movement of the paretic limb along desired trajectories, external resistance to unwanted movements and haptic sensations that reinforce the feedback to the user. A combination of physical intervention with virtual reality is described by Jack et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Jack D, Boian R, Merians AS, Tremaine M, Burdea GC, Adamovich SV, Recce M, Poizner H (2001) Virtual reality-enhanced stroke rehabilitation. IEEE Trans Neural Syst Rehabil Eng 9(3):308–318" href="/article/10.1007/s10055-007-0067-5#ref-CR9" id="ref-link-section-d7950e371">2001</a>) in which persons with stroke interact with virtual objects that are presented visually with computer graphics, and haptically use a force reflecting glove. Use of virtual reality-based therapy for persons with cerebral palsy is described by Wann and Turnbull (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Wann JP, Turnbull JD (1993) Motor skill learning in cerebral palsy: movement, action, and computer-enhanced therapy. Baillieres Clin Neurol 2(1):15–28" href="/article/10.1007/s10055-007-0067-5#ref-CR40" id="ref-link-section-d7950e374">1993</a>), with head injury by Rizzo and Buckwalter (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Rizzo AA, Buckwalter JG (1997) The status of virtual reality for the cognitive rehabilitation of persons with neurological disorders and acquired brain injury. Stud Health Technol Inf 39:22–33" href="/article/10.1007/s10055-007-0067-5#ref-CR32" id="ref-link-section-d7950e377">1997</a>), and with multiple sclerosis by Stefin (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Stefin M (1997) Computer assisted therapy for multiple sclerosis and spinal cord injury patients: application of virtual reality. Stud Health Technol Inf 39:64–72" href="/article/10.1007/s10055-007-0067-5#ref-CR36" id="ref-link-section-d7950e381">1997</a>). Telerehabilitation of orthopedic disabilities are reported by Popescu et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Popescu V, Burdea G, Bouzit M, Girone M, Hentz V (2000) Orthopedic telerehabilitation with virtual force feedback. IEEE Trans Inf Technol Biomed 4:45–51" href="/article/10.1007/s10055-007-0067-5#ref-CR27" id="ref-link-section-d7950e384">2000</a>). Additional reports on the use of virtual reality include the use of game-like technologies to increase the motivation of children with disabilities (McComas et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="McComas J, Pivak J, Laflamme M (1998) Current uses of virtual reality for children with disabilities. Stud Health Technol Inf 58:161–169" href="/article/10.1007/s10055-007-0067-5#ref-CR23" id="ref-link-section-d7950e387">1998</a>; Helsel <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Helsel S (1992) Virtual reality and education. Educ Technol 32(5):38–42" href="/article/10.1007/s10055-007-0067-5#ref-CR8" id="ref-link-section-d7950e390">1992</a>). Reviews of early applications of virtual reality in rehabilitation are provided by Greenleaf and Tovar (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Greenleaf WJ, M.A. Tovar MA (1994) Augmenting reality in rehabilitation. Artif Intell Med 6(4):289–299" href="/article/10.1007/s10055-007-0067-5#ref-CR6" id="ref-link-section-d7950e393">1994</a>) and Kuhlen and Dohle (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Kuhlen T, Dohle C (1995) Virtual reality for physically disabled people. Comput Biol Med 25(2):205–211" href="/article/10.1007/s10055-007-0067-5#ref-CR19" id="ref-link-section-d7950e396">1995</a>). More current reviews are provided by Riva (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Riva G (2003) Applications of virtual environments in medicine. Methods Inf Med 42(5):524–534" href="/article/10.1007/s10055-007-0067-5#ref-CR31" id="ref-link-section-d7950e400">2003</a>) and Sveistrup (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Sveistrup H (2004) Motor rehabilitation using virtual reality. J NeuroEngineering Rehabil 1:10" href="/article/10.1007/s10055-007-0067-5#ref-CR37" id="ref-link-section-d7950e403">2004</a>).</p><p>Many of these examples require immersive technologies that include head-mounted displays to create the sensation of being in a virtual environment. Others provide a sense of presence by means of haptic representation of virtual objects and forces. The latter is especially important when the therapeutic intervention requires tactile feedback to the user. Jack et al. discuss the importance of force feedback in grasping and manipulation tasks among persons with stroke. Similarly, strong arguments can be made for the use of immersive systems employing head-mounted displays that present 3D graphical environments with considerable fidelity.</p><p>This paper describes an approach to the rehabilitation of persons with neuromuscular disabilities, which is based on fundamentally different technologies. Low immersion virtual reality systems, using remotely located video cameras, reduce the invasiveness of the technology while providing highly individualized, intensive and repeated practice of goal-directed movements. In such systems, users view themselves participating in virtual worlds, consisting of computer-generated graphics with visual and auditory real-time interactions. The prototype system, described in this paper, may be used to create interactive environments that are highly motivating and provide therapy that is tailored to each user’s interests and physical abilities. In contrast to force generating technologies, this system encourages structured physical activity for individuals with disabilities without requiring contact with physical objects, or the virtual representation of such forces. While emphasizing goal directed or reaching movements, it can be quite tolerant of movement errors typically present among people with cerebral palsy and brain injury. The absence of physical contact makes the system considerably more applicable to individuals (e.g. those with cerebral palsy) who may have difficulty grasping. This virtual interaction approach does not require the user to wear or come in contact with special apparatus. Thus, it avoids the problems associated with high-immersion virtual reality systems, such as motion sickness and cumbersome equipment. Since it employs video display and tracking technology, it offers the potential for visual user feedback and recording of clinically relevant performance information.</p><p>Low immersion technology provides a significant advantage over more common video game systems that are traditionally operated via a user interface such as a joystick or a keyboard. While it is possible to employ assistive technology to adapt a commercial video game so that it can be used by a person with a neuromuscular disability, the motivation provided by the game is not matched by therapeutic benefits. Conventional video games, even when adapted for use, encourage very limited movements that may not generalize to improved sensory-motor control. They most certainly do not provide the range of flexion and extension necessary to address the issue of muscle contracture. Low immersion systems dramatically alter the user’s interaction with a video game. Rather than participate somewhat passively (from the neuromotor perspective) by means of an interface with the action on the screen, a low immersion system user becomes a participant in the action. One can contrast these approaches by comparing a pinball game in which the user controls the flappers by hitting a switch, with one in which the user is embedded in the game with his/her hands serving as the flappers. The degree of physical interaction is greatly increased.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Background on low-immersion systems</h2><div class="c-article-section__content" id="Sec2-content"><p>In the early 1970s, Krueger (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1990" title="Krueger M (1990) Artificial reality II. Addison-Wesley, Reading" href="/article/10.1007/s10055-007-0067-5#ref-CR17" id="ref-link-section-d7950e421">1990</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993)" title="Krueger M (1993) Environmental technology: making the real world virtual. Commun ACM 36:36–37" href="/article/10.1007/s10055-007-0067-5#ref-CR18" id="ref-link-section-d7950e424">1993)</a> developed a low immersion virtual reality system known as VideoPlace, which provided a novel form of interaction between users and computer-generated graphics. The users were backlit to provide a strong contrast, allowing a nearly binary signal to be detected by a video camera. Each video frame was easily separated into foreground (user’s silhouette) and background. The boundary of the silhouette was computed in real time, thus allowing interaction with computer-generated graphics that replaced the background. Krueger noted that users were highly motivated to control the movements of their silhouette to participate in these new video games, and were quite curious to explore how the computer-generated objects responded to changes in their movements. While his system was essentially recreational, Krueger hypothesized that the engrossing nature of the activity could be used in physical therapy to provide distraction from repetitious and tedious exercises. He believed that individuals with disabilities could be motivated to push their capabilities in order to interact with a virtual environment.</p><p>A more advanced version of Krueger’s system was commercially introduced by the Vivid Group (Toronto, Canada). Its early Mandala VR used a blue backdrop and a chroma key to separate the user’s image from the background. That image was overlaid in a computer-generated scene that would interact with the user’s image. This provided a full color image of the user replacing Krueger’s silhouette. A number of interactive games and entertainment experiences were produced and used primarily in museums and recreational settings (Dougall <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Dougall F (1996) Video image based control system, US patent number 5534917" href="/article/10.1007/s10055-007-0067-5#ref-CR4" id="ref-link-section-d7950e430">1996</a>; Pengilly <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Pengilly S (1996) Integrating performance, live electronics and interactive video. Comput Math Appl 32(1):75–77" href="/article/10.1007/s10055-007-0067-5#ref-CR26" id="ref-link-section-d7950e433">1996</a>). While the Mandala system was not originally intended for therapeutic purposes, newer versions that are now produced by GestureTek have been used as therapeutic tools.</p><p>Researchers at the Massachusetts Institute of Technology have developed the IVE (Interactive Video Environment) and the ALIVE (Artificial Life IVE) systems (Maes et al <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Maes P, Darrell B, Pentland A (1995) The ALIVE system: wireless, full-body interaction with autonomous agents. Perceptual computing. MIT Media Laboratory, technical report no. 257 " href="/article/10.1007/s10055-007-0067-5#ref-CR22" id="ref-link-section-d7950e439">1995</a>; Bobick et al <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Bobick AF, Intille SS, Davis JW, Baird F, Pinhanez C, Campbell LW, Ivanov YA, Schutte A, Wilson A (1999) The KidsRoom: a perceptually-based interactive and immersive story environment. Presence 8(4):369–393" href="/article/10.1007/s10055-007-0067-5#ref-CR2" id="ref-link-section-d7950e442">1999</a>). These systems use color segmentation to separate the user’s silhouette from the background without any special backdrops. This work has focused primarily on intelligent, artificial creatures that react to the user’s gestures. The users see themselves in their physical surroundings along with the computer-generated characters. The graphical characters are generated with three-dimensional movement characteristics so that they may move both in front of and behind the user.</p><p>Sony has introduced a lower-cost system known as Eye-Toy that introduces low-immersion virtual reality to its Playstation technology. This uses a USB camera to capture the user’s image, which is integrated into a software-generated background.</p><p>The work described in this paper was inspired by Krueger’s speculation that low immersion virtual reality technology might be useful in rehabilitation. Effort to develop a recreational video game system for children with significant physical disabilities began at the Alfred I. duPont Hospital for Children in the early 1990s (Lachapelle and Foulds <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Lachapelle T, Foulds R (1992) Design of a low-immersion virtual reality system for children with disabilities. In: Proceedings of RESNA’92" href="/article/10.1007/s10055-007-0067-5#ref-CR20" id="ref-link-section-d7950e451">1992</a>; Joyce and Phalangas <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Joyce AW, Phalangas AC (1995) Virtual interaction: an interface for individuals with disabilities. In: Proceedings of RESNA ’95, pp 425–427" href="/article/10.1007/s10055-007-0067-5#ref-CR12" id="ref-link-section-d7950e454">1995</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998)" title="Joyce AW, Phalangas AC (1998) The implementation and capabilities of a virtual interaction system. In: Proceedings of European conference on disabilities, virtual reality and associated technologies, Skovde, Sweden, pp 237–245" href="/article/10.1007/s10055-007-0067-5#ref-CR13" id="ref-link-section-d7950e457">1998)</a>. This work continues to investigate the use of similar non-contact, low-immersion technology for both therapy and recreation at the New Jersey Institute of Technology. This project has the goal of further exploring the benefits noted by Krueger with an open-source and customizable system that is assembled from commercial off-the-shelf technology. The latter will promote its use in the home and in clinical settings.</p><p>The initial 1993 implementation began as an undergraduate senior project and used an Amiga computer configured as a Video Toaster to conveniently support the video screen output. Later funded work adopted the PC as its platform and has progressed from a custom video-processing card to commercial video cards. Several example therapeutic environments have been developed in C++ and informally evaluated with individuals with disabilities.</p><p>As this work has progressed, there has been an impressive level of activity supporting the use of such low immersion technology for persons with disability. These studies have employed the Mandala Gesture Extreme or its rehabilitation version marketed by IREX. The IREX product has been modified to offer a degree of accommodation to the movements of the disabled users as well as a method of recording data that can be used for clinical analysis.</p><p>Reid and her colleagues in Toronto (Farrow and Reid <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Farrow S, Reid D (2004) Stroke survivors’ perception of a leisure-based virtual reality program. Technol Disabil 16:69–81" href="/article/10.1007/s10055-007-0067-5#ref-CR5" id="ref-link-section-d7950e467">2004</a>) have demonstrated the effectiveness of the GX with older persons who have had a stroke. The same group has conducted studies, which suggest that low immersion VR technology may improve upper extremity function in children with cerebral palsy (Reid <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Reid D (2002) The use of virtual reality to improve upper-extremity efficiency skills iin children with cerebral palsy: a pilot study. Technol Disabil 14:53–61" href="/article/10.1007/s10055-007-0067-5#ref-CR28" id="ref-link-section-d7950e470">2002</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Reid D (2004) The influence of virtual reality on playfulness in children with cerebral palsy: a pilot study. Occup Ther Int 11(3):131–144" href="/article/10.1007/s10055-007-0067-5#ref-CR29" id="ref-link-section-d7950e473">2004</a>; D. T. Reid <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Reid DT (2002) Benefits of a virtual play rehabilitation environment for children with cerebral palsy on perceptions of self-efficacy: a pilot study. Pediatr Rehabil 5(3):141–148" href="/article/10.1007/s10055-007-0067-5#ref-CR30" id="ref-link-section-d7950e476">2002</a>; Harris and Reid <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Harris K, Reid D (2005) The influence of virtual reality play on children’s motivation. Can J Occup Ther Revue Canadienne d Ergotherapie 72(1):21–29" href="/article/10.1007/s10055-007-0067-5#ref-CR7" id="ref-link-section-d7950e479">2005</a>). Weiss et al. in Israel have used the GX for people with spinal cord injury and stroke and have found it to be an effective rehabilitation tool (Kizony et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002a" title="Kizony R, Katz N, Weingarden H, Weiss PL (2002a) Immersion without encumbrance: adapting a virtual reality system for the rehabilitation of individuals with stroke and spinal cord injury. In: Proceedings of the 4th international conference on disability, virtual reality and associated technology. Vresprem, Hungary, pp 55–61" href="/article/10.1007/s10055-007-0067-5#ref-CR14" id="ref-link-section-d7950e483">2002a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Kizony R, Katz N, Weiss PL (2002b) Adapting a virtual reality system for the rehabilitation of individuals with stroke and spinal cord injury. In: Proceedings of the 1st international workshop on virtual reality in rehabilitation. Lausanne, Switzerland, pp 223–232" href="/article/10.1007/s10055-007-0067-5#ref-CR15" id="ref-link-section-d7950e486">b</a>). The same group also compared the performance of the GX with the Sony EyeToy and found that many of the features were equally useful with populations of disabled people, but concluded that the clinical flexibility of the GX outweighed the much lower cost and greater availability of the EyeToy (Weiss et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Weiss P, Rand D, Katz N, Kizony R (2004) Video capture virtual reality as a flexible and effective rehabilitation tool. J Neuroengineering Rehabil 1:12" href="/article/10.1007/s10055-007-0067-5#ref-CR41" id="ref-link-section-d7950e489">2004</a>). At this time, Sony does not make development tools available for its product.</p><p>These two research groups have used clinically proven outcome measures to evaluate the effectiveness of the technology. Some of these findings are based on user acceptance and preference, whereas others involve measures of upper extremity function. Their results are consistent with expected neural reorganization that may result from use of the VR system. Two studies in the US by You et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="You SH, Jang SH, Kim YH, Kwon YH, Barrow I, Hallett M (2005) Cortical reorganization induced by virtual reality therapy in a child with hemiparetic cerebral palsy.] Dev Med Child Neurol 47(9):628–635" href="/article/10.1007/s10055-007-0067-5#ref-CR42" id="ref-link-section-d7950e495">2005</a>) and Jang et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Jang SH, You SH, Hallett M, Cho YW, Park CM, Cho SH, Lee HY, Kim TH (2005) Cortical reorganization and associated functional motor recovery after virtual reality in patients with chronic stroke: an experimenter-blind preliminary study. [Controlled Clinical Trial. Journal Article] Arch Phys Med Rehabil 86(11):2218–2223" href="/article/10.1007/s10055-007-0067-5#ref-CR10" id="ref-link-section-d7950e498">2005</a>) provide stronger support for successful motor learning by persons with disabilities. One complete study used the GX system with a group of older people who were hemipelegic (disabled primarily on one side of the body) due to a stroke. Subjects in this study showed statistically significant improvement in ambulation that can be attributed to therapy provided by low immersion VR. They also self-reported noticeable changes in function of their affected limb with dramatic improvement in activities of daily living such as dressing and stepping onto and off of a curb. The study says that these tasks were successfully accomplished after the use of the low-immersion VR therapy, but were not possible prior to the intervention. The investigators also employed functional magnetic resonance imaging (fMRI) to assess changes in neural organization that could confirm the benefit of the therapy. The fMRI studies showed a shift in neural activation that is consistent with other studies and may be the result of practice-dependent neuroplasticity. This same group has also published a single-subject of a child with hemiplegic cerebral palsy. They report fMRI data that show a change in neural organization that is consistent with their observations of improved control of the affected arm in tasks such as reaching, dressing and eating.</p></div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Implementation of a virtual interaction therapy system</h2><div class="c-article-section__content" id="Sec3-content"><p>The prototype described in this paper offers a similar low immersion capability as the GX, with potentially much lower cost, use of off-the-shelf technology and greater flexibilty due to its open source design. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0067-5#Fig1">1</a>a shows a stylized configuration that includes a personal computer equipped with a VigraVision video processing card (VisiCom, San Diego, CA, USA), a video camera, a television and a blue backdrop. The user sits in front of the blue backdrop facing the television so that his/her extended arms cover approximately 90% of the horizontal video field. This typically results in a distance of 1.5 to 2 m from the camera. Residential or office lighting has been found to be acceptable for the system. The virtual world, depicted in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0067-5#Fig1">1</a>b, shows the user’s mirror image superimposed on the monitor with computer-generated graphics. The computer images are produced by a C++ program, which controls both their behaviors and computes the location of the outline of the user’s image. Graphical objects can be programmed to respond to the user’s movements in a number of ways. They can be deflected according to the laws of physics, with their velocity and direction determined by the velocity and direction of the user’s movement at the point of contact. They can also be programmed to accommodate the user’s disability and respond to varying degrees of accuracy of the user. This latter feature is especially important in early use by a person with limited range of motion or limited movement control. While many physical and virtual tasks require moderate accuracy to achieve modest success, a virtual reality therapy system can suspend physical reality and allow successful interaction in ways that are not possible with real objects. It is possible to allow a user to achieve initial success even with severe incoordination of the limbs. The difficulty of the task can be increased as the user demonstrates improvement. This allows the system to provide an individualized challenge to each user. In addition to movement features, each graphical object can also have sound attributes. User interactions with those objects can be described with different sounds. Since the system provides no haptic representation, the addition of sound augments the visual feedback of successful interaction. For instance, sound can indicate the contact between the user and a visual object. Similarly, variations in sound loudness can be equated to the force of impact.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0067-5/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0067-5/MediaObjects/10055_2007_67_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0067-5/MediaObjects/10055_2007_67_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>The virtual interaction system. <b>a</b> Depicts the user seated in front of a video-<i>blue backdrop</i>, facing a video monitor. The video camera and monitor are connected to a personal computer with a commercial vide frame grabber. <b>b</b> The user views him/herself in mirror image on the monitor with interactive graphics (in this case space aliens) superimposed</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0067-5/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>An example of a simple virtual world superimposes the user on a screen of computer-generated flying space aliens as depicted in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0067-5#Fig1">1</a>b. The aliens are programmed with special behaviors. When the user initiates a move that contacts an alien, the alien can be made to bounce off the user’s body in a direction controlled by the user’s movement (allowing the user to play alien billiards), or to be directed on a specific path regardless of the user’s coordination abilities. Alternatively, the alien could be made to explode upon impact with a corresponding graphical flash and sound. In some instances, it may be desirable to include behaviors that are affected by gravitational and other physical forces. In others, it may be desirable to suspend natural laws.</p><p>The initial path of the graphical objects can also be controlled by software. For a user with limited range of motion, the aliens can be made to fly within the user’s range. As the therapy improves the range of movement, the task of intercepting aliens can be made more difficult as a way of encouraging the user to extend his/her reach or coordination.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0067-5#Fig2">2</a>c shows an example of the virtual interaction implementation of the well-known video game, Breakout. Atari introduced Breakout as an arcade game in 1976. A ball bounces between a paddle and a wall of bricks. Each time the ball hits a brick, that brick is removed. (In order to create a more playable game, the bricks have been moved from their original vertical orientation to the brick ceiling shown in the pictures.) The user becomes the paddle. The player directs the ball toward the remaining bricks while trying to keep the ball from hitting the bottom of the screen. This figure shows the user attempting to hit the ball with his hand; however, any segment of his body would deflect the ball.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0067-5/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0067-5/MediaObjects/10055_2007_67_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0067-5/MediaObjects/10055_2007_67_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Images from different stages of the virtual interaction system. The live video with the blue screen removed for clarity is shown on the <i>left</i> (<b>a</b>). The silhouette generated by the chroma key is the <i>middle image</i>. It is this silhouette that is used to control the interactions of the user with the superimposed graphics. The <i>far right image</i> is a screen-shot of an example final interaction screen as seen by the user</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0067-5/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>An application that uses a drag and drop interaction is an anagram unscrambling game. The computer presents a set of letters, which the user touches and drags into their proper sequence. The drag and drop action represents another form of interaction between the user and the graphical objects. In this mode, an object sticks to the user when touched and follows the movement of the user’s silhouette. The object remains attached to that point on the silhouette until it is dropped. Dropping can be initiated by reaching a location, zero velocity of the user’s silhouette, or by rapid acceleration/deceleration of the user (shaking off the object).</p><p>Systems such as this also have potential in cognitive and educational applications (Saxe <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Saxe D (1999) Virtual interaction using robust color skin detection. In: Proceedings of SIGCHI 1999, pp 330–331" href="/article/10.1007/s10055-007-0067-5#ref-CR33" id="ref-link-section-d7950e594">1999</a>). An example of a simple cognitive exercise is the virtual interaction implementation inspired by the Milton Bradley game Simon<sup>™</sup>. This memory game presents a sequence of button presses and accompanying sounds generated by the computer. The player must repeat the sequence. The complexity of the sequence increases with succeeding rounds of the game. In this implementation, the user views him/herself surrounded by computer-generated keys. In keeping with the therapeutic philosophy, the location and size of the keys can accommodate the user’s range of motion and coordination. The sequence is generated with the keys changing shape or color with accompanying sounds. The user repeats the sequence by ‘touching’ the virtual keys. While this was developed as an exercise to reinforce memory and sequencing skills, it can also incorporate manual coordination aspects by moving the targets to encourage greater range of motion, or reducing their size to develop improved accuracy.</p><h3 class="c-article__sub-heading" id="Sec4">Logical processes overview</h3><p>The virtual interaction system displays a user’s real-time video image that interacts with on-screen computer-generated graphics. The processes associated with this are shown in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0067-5#Fig2">2</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0067-5#Fig3">3</a>. Live video, acquired from a camera is segmented by a chroma key, which identifies the outline of the user against the blue backdrop. (The advanced region-of-interest segmentation block represents the newly implemented skin color segmentation algorithm, which is used to better specify the interaction regions and is described in a later section.) Computer software generates graphical animation and audio overlays. At each video frame, interactions between the objects and the user are determined. This is accomplished by a simple collision detection scheme. These interactions are based on the silhouette of the user when only the chroma key is used, or with more selective regions when using the advanced region-of-interest skin segmentation. Finally, the live video, which is mirrored, and the graphics are merged and displayed to the user. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0067-5#Fig4">4</a> shows a young woman using the prototype system with the “breakout” game. She views her mirrored, full color image on the monitor, while the system computes collisions between graphically generated objects and her silhouette.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0067-5/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0067-5/MediaObjects/10055_2007_67_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0067-5/MediaObjects/10055_2007_67_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Block diagram of the virtual interaction system. Live video from the camera is captured and processed to determine the user’s silhouette. In a later version, the video stream is also processed to determine the locations of the hands and face (ROI Detection indicated by <i>dashed lines</i>). Therapeutic game graphics are generated and collisions between the graphics and the user’s silhouette are determined. These collisions are used to compute the response of the game graphics and sound to the user’s movements. External adjustment of response is provided to allow alteration of the game to meet the therapeutic needs of the individual. The live video and game graphics are superimposed and output to the video monitor. Audio output is via a sound card. <i>Gray blocks with solid borders</i> are functions of the host computer. <i>Gray blocks with triple-line borders</i> are functions of the VigraVision card</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0067-5/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0067-5/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0067-5/MediaObjects/10055_2007_67_Fig4_HTML.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0067-5/MediaObjects/10055_2007_67_Fig4_HTML.jpg" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Young woman with cerebral palsy uses the prototype system in a game of “breakout”. Her color image is mirrored on the video monitor in real time. The system computes the boundary of her silhouette and uses that information to determine the interactions with a graphically generated ball. The speed and direction of the ball can be made to follow the laws of physics, or they can be altered to accommodate the user’s degree of disability. Thus, the action of the game can be adjusted to provide an appropriate challenge to the user. As the user becomes more proficient, the actions of the game can be modified to maintain the same degree of challenge and provide motivation for increased motor training</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0067-5/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec5">Hardware implementation</h3><p>The demands for video capture, graphics overlay, NTSC output, the time critical image processing of the foreground–background separation and collision detection require that a portion of the application be implemented in supplemental hardware. The original prototype involved a custom board using field programmable gate arrays (FPGA; Bobick et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Bobick AF, Intille SS, Davis JW, Baird F, Pinhanez C, Campbell LW, Ivanov YA, Schutte A, Wilson A (1999) The KidsRoom: a perceptually-based interactive and immersive story environment. Presence 8(4):369–393" href="/article/10.1007/s10055-007-0067-5#ref-CR2" id="ref-link-section-d7950e669">1999</a>). The card was installed on the ISA bus of a standard personal computer, and provided all image capture, image processing and video output functions.</p><p>The current prototype has replaced the custom video card with a commercially available image-processing card. The VigraVision card (VisiCom) provides video capture, chroma keying, NTSC/PAL output, fast access to the video buffer, and can be set to mirror the video output. The card has a capture and overlay system that is displayed on the television screen and at the upper left corner of the computer’s monitor. The high resolution of the computer display allows control functions and performance monitoring to be displayed simultaneously.</p><p>In addition to the video capture and overlay requirements, this card provides the ability to generate graphics and create smooth animation It incorporates the features of a modern video card with double buffering and a graphics accelerator, as well as the requisite live video overlay to meet these requirements. This also makes it possible to use the computer’s monitor as an output rather than requiring a separate television monitor.</p><p>The implementation of low immersion virtual reality in therapy is not dependent upon this particular hardware. The marketplace has provided an ample array of alternatives that include competing video capture and processing cards as well as Firewire-based technologies.</p><h3 class="c-article__sub-heading" id="Sec6">Computational aspects of interactions</h3><p>The implementation of Breakout uses a bounce interaction, which tests for the silhouette in the path of the ball (or any other object using the bounce interaction). The program tests at several points around the periphery of the ball in order to detect a glancing blow as well as frontal contact. For a medium speed game, the ball moves approximately 6 pixels during a 33 ms frame period. (This equates to moving across the screen in about 3–4 s.) Therefore the bounce interaction tests approximately 30 pixels per frame period. When a contact is made, further checks are performed to eliminate spurious noise, and the normal to the silhouette is calculated. The dot product of the normal and the motion vector produces the magnitude of the impact. Adding twice that amount of motion in the direction of the normal gives a mirror-like deflection. The addition of a collision sound as the ball bounces off the user’s silhouette enhances the illusion that the purely graphical ball actually made physical contact with the user. Sound is associated with the expenditure of energy and provides the user with the sense that a physical, energetic collision occurred. The Simon-like game described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0067-5#Sec3">3</a> uses fixed regions of the display as switches. The program tests for an overlap by the user’s silhouette in one of those regions. Each switch is tied to a different musical note, which is played though the MIDI interface by a Sound Blaster FM Synthesizer. In order to debounce a switch, the program tests a small region for activation and tests a larger, overlapping region once activated. The silhouette must move well outside of the activation region before the switch is reset, and a new switch contact can be initiated.</p><p>Two additional interactions, the drag and drop and the swat involve additional image processing. For the drag and drop interaction, rather than using any location of the user’s silhouette, the silhouette is processed to locate a reaching appendage, which is defined as being longer than it is wide. Relative dimensions can be provided to determine appendages that are the size of an arm or a finger. The most extreme point along the appendage is used as the tip and is the location of the drag point. The swat interface must not only determine that the ball has been hit, but also where the silhouette was before it hit the ball. The program uses an anticipatory proximity measure, which identifies the direction and velocity of the point of contact on the silhouette. When contact is made, changes in the proximity measurement determine the magnitude and direction of the deflection. Rapid hand motions by the user may be on the order of 30 pixels in a single frame period (assuming a typical upper body and arm span camera view). This is about the same as the diameter of the ball or the thickness of the hand viewed edgewise. Because the silhouette can come from any direction, looking ahead by two frame periods requires the program to examine regions that are about 150 pixels on a side. A sparse search is used to find the silhouette and then the estimate of the closest point is progressively refined. Because of the high-speed access to the video buffer, the VigraVision and similar systems are able to store the raw video and delay the search until contact has been made.</p></div></div></section><section aria-labelledby="Sec7"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7">Robust skin detection algorithm</h2><div class="c-article-section__content" id="Sec7-content"><p>With each of the virtual interaction applications presented in the previous section, the hands and possibly the face of the individual represent the regions of interest. The applications have been successful using the user’s silhouette to control the interaction; however, in observing interactions during experiments, it was observed that in all cases an endpoint (i.e. face or hand) was chosen as the source of interaction by the user. In upper extremity rehabilitation exercises, it can be important to measure not only the outstretched arm movement, but also the movements of the arm in front of the subject’s body. This cannot be accomplished with the silhouette method alone.</p><p>A robust skin detector has been added to detect and separate the skin regions of a video image from the background. The approach used to segment the images is robust in that it can accommodate variations in skin pigmentation in a single subject, as well as differences in pigmentation across multiple subjects. This approach is also relatively insensitive to complex backgrounds and varying illumination. Saxe (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Saxe D (1999) Virtual interaction using robust color skin detection. In: Proceedings of SIGCHI 1999, pp 330–331" href="/article/10.1007/s10055-007-0067-5#ref-CR33" id="ref-link-section-d7950e702">1999</a>) discusses a more detailed explanation of this algorithm.</p><p>Swain and Ballard (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Swain MJ, Ballard DH (1991) Color indexing. Int J Comput Vis 7(1):1–32" href="/article/10.1007/s10055-007-0067-5#ref-CR38" id="ref-link-section-d7950e708">1991</a>) showed that color histogram intersection is an effective method for color-based segmentation. This technique, based on the RGB color space is, however, sensitive to ambient lighting conditions. Ahmad (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Ahmad S (1994) A usable real-time 3D hand tracker. In: conference record of the Asilomar conference on signals, systems and computers, pp 1257–1261" href="/article/10.1007/s10055-007-0067-5#ref-CR1" id="ref-link-section-d7950e711">1994</a>) used this straightforward histogram matching technique, and robustness problems were addressed in Saxe and Foulds (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Saxe DM, Foulds RA (1996) Toward robust skin identification in video images. In: Proceedings of the 2nd conference on automatic face and gesture recognition. Killington, Vermont, pp 379–384" href="/article/10.1007/s10055-007-0067-5#ref-CR34" id="ref-link-section-d7950e714">1996</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002)" title="Saxe DM, Foulds RA (2002) Robust region of interest coding for improved sign language telecommunication. IEEE Trans Inf Technol Biomed 6(3):310–316" href="/article/10.1007/s10055-007-0067-5#ref-CR35" id="ref-link-section-d7950e717">2002)</a>. A modified approach, developed by the authors and based on color histograms, is employed for this algorithm. The HSV (hue, saturation, value) color model was introduced to account for differences in lighting within a single frame as well as across multiple frames. The HSV values correspond to wavelength, excitation and illumination, respectively. Hue and saturation, invariant to changes in illumination, are used to construct the color histograms and provide robustness to illumination. An adaptive control histogram allows for tighter thresholds to be set, thereby enhancing the segmentation from complex backgrounds.</p><p>The image, represented in RGB is converted to HSV. Hue is represented as an angle (0–360°) and saturation as a real number 0 to 1. The histogram’s two axes (hue and saturation) are dynamically discretized into N × M bins. A given patch’s histogram is populated by incrementing the value that represents each pixel’s hue and saturation values. To segment the image, the algorithm compares each patch from the image with the two control patches separately. The match score is the number of instances in common between two histograms C and I. A hit, signifying that two patches match, occurs when the match score is greater than a preset threshold value.</p><p>Training consists of identifying an initial region of skin in the first video image to create the Static Control Histogram. No further training is required. In fact, since the algorithm is relatively insensitive to day-to-day lighting changes, a single control patch can be stored for each user, and no training will be necessary for subsequent uses. Each patch in the image is intersected with this control patch to segment the image. The original skin detection algorithm described in Saxe (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Saxe D (1999) Virtual interaction using robust color skin detection. In: Proceedings of SIGCHI 1999, pp 330–331" href="/article/10.1007/s10055-007-0067-5#ref-CR33" id="ref-link-section-d7950e726">1999</a>) uses iteration in each frame of the video sequence. For execution speed, this implementation is adaptive not by iterating a single frame, but by updating the control patch over multiple frames. In other words, two control histograms are maintained: the static histogram is created by using the patch chosen from the first image (or by using the stored patch), and remains constant throughout the interaction. The adaptive histogram, on the other hand, varies from frame to frame to help account for shadows and illumination changes.</p><p>After the segmentation, the algorithm makes a smart choice as to which control patch to use as the adaptive histogram for the next frame. A patch that matches the static control patch at or near the threshold level is chosen to account for shadowing or inconsistent illumination. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0067-5#Fig5">5</a> shows selected images from a video stream before (top row) and after (bottom row) processing. The video sequence was captured in front of a reddish colored wood-grained door. Because of the similar primary color, clothing and background with these properties presents a particular challenge for color skin segmentation. Unlike other color segmentation algorithms that select a large number of false pixels on the door, this new robust algorithm is relatively insensitive to backgrounds of similar color.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0067-5/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0067-5/MediaObjects/10055_2007_67_Fig5_HTML.jpg?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0067-5/MediaObjects/10055_2007_67_Fig5_HTML.jpg" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Four pairs are arranged vertically of raw and region of interest segmented images from a video sequence of a moving hand in front of a challenging background</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0067-5/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <h3 class="c-article__sub-heading" id="Sec8">Skin detector integration</h3><p>While the regions found by skin detection will define the interaction, the chroma key component is not abandoned. For immediate application, the foreground–background separation mask created by the chroma key alerts the skin detection algorithm to which parts of the image need to be searched. Since the skin detection algorithm is computationally intensive, it is not possible to search each entire image for skin regions. Tracking and prediction algorithms have been successfully used in some applications to limit search space; however, these algorithms are not appropriate here. They traditionally require the user to initialize their position in a predefined posture and maintain steady movement always within the screen boundaries. These tasks are not always feasible for a patient population. In addition, the added complexity of tracking three objects (i.e. hands and face) can be more time consuming than searching the entire chroma keyed region. An example of the skin detection results is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0067-5#Fig6">6</a>. The mask generated by the skin detector for this particular image, shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0067-5#Fig6">6</a>c, is a little below average quality for a typical image due to poor overhead lighting. The interaction process can readily handle the jagged edges by smoothing, but has more trouble compensating for holes in the mask, such as those found on the fourth finger of the subject’s left hand. In cases such as these, a lighting adjustment can usually relieve the problem.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0067-5/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0067-5/MediaObjects/10055_2007_67_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0067-5/MediaObjects/10055_2007_67_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Various stages of the skin detection process. <b>a</b> is generated by the chroma key process and serves as input to the skin detector. The patches found to be skin are denoted in <b>b</b> with the output mask used by the interaction process shown in <b>c</b>
                                    </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0067-5/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        </div></div></section><section aria-labelledby="Sec9"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">Discussion</h2><div class="c-article-section__content" id="Sec9-content"><p>A low immersion virtual reality system that allows users to interact with a computer-generated world using their silhouette, hands and/or face is discussed. The system has been implemented to allow people with a disability a means of achieving physical exercise and movement in a virtual environment. Games such as <i>Breakout</i> and <i>Simon</i> are used to provide challenges that are both therapeutic and recreational. The inclusion of the robust skin detector allows the system to be more versatile in that it can require the use of visible skin (hands and face) and encourages users to become more accurate in their movements.</p><p>The current prototype achieves its performance with commercially off-the-shelf technology that includes a personal computer, video camera and image processing card. The system’s software has been developed in C++, using DirectX and is scalable to more powerful computing and image processing technologies. The current software has been used to develop several therapeutic games that have been informally evaluated with children at the duPont Hospital for Children. These prototype games include sufficient flexibility to accommodate a wide range of user manual skills. The use of C++ allows the refinement of these exercises and the development of others.</p><p>While the system has been designed to be open-source to allow users to develop their own programs, it remains a prototype. Programming requires knowledge of C++ and considerable knowledge of the technology. In addition to different games and environments, the system flexibility includes the ability to modify the functioning of the game to accommodate the individual physical capabilities of the users. Beyond reducing the overall speed of the action, clinicians can specify regions of interest in which the action slows or in which the need for movement accuracy is greatly decreased. This allows the therapy to target the less affected arm of a person with hemiplegia. Movements of the computer-generated objects can also be controlled to encourage initial success and to challenge the user as skills improve. Continued evaluation will determine which clinical features are most useful.</p><p>Although the work reported in this paper does not present experimental data, the anecdotal observations of the authors of user response to the system are consistent with the findings of other groups who are examining the potential benefits of low immersion VR in rehabilitation. Informal trials of the prototype were approved by the institutional human investigation review committee for recreation only. There was no attempt to induce functional changes because that was outside the approved protocol. Many users of the prototype reported that this was the first time they were able to play a video game of any kind. Motivation to use the prototype was very high, leading a number of users to spend considerable time. This supports the notion that this technology can retain the interest of its users for the time sufficient for effective therapy. The flexibility of the system allowed the difficulty of the task to be increased as the users became more proficient, giving an informal indication that either motor control might be improving with use, or that contracture may be decreasing.</p><p>The design of this system supports the needs described in Weiss et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Weiss P, Rand D, Katz N, Kizony R (2004) Video capture virtual reality as a flexible and effective rehabilitation tool. J Neuroengineering Rehabil 1:12" href="/article/10.1007/s10055-007-0067-5#ref-CR41" id="ref-link-section-d7950e819">2004</a>) who observed that low immersion VR therapy is not in wide clinical use due to the cost of existing technology. In addition, they suggest that cost is also an impediment for home use that will be necessary for the therapy to have its desired effect. In addition, they call for an open source architecture that allows not only clinical adjustment of therapeutic parameters, but also for greater opportunity to develop new therapeutic environments and games.</p><h3 class="c-article__sub-heading" id="Sec10">Future goals</h3><p>The use of commercially off-the-shelf technology must be matched by software improvements that provide an environment that facilitates the development of new therapeutic exercises and games. In addition, a user interface must be added to allow therapists to set parameters (speed of interaction, accuracy, range of movement, object behavior, etc.) that can accommodate the physical and cognitive skills of the potential user, without modifying C++ programs.</p><p>Future system development can explore more sophisticated interactions. The current system is limited to two-dimensional information. The addition of a skin detector, however, allows for efficient stereo vision techniques to be used to determine approximate three-dimensional hand and face position. The centroid of each of the hands and face can be used as correspondence points for depth calculations, thereby increasing the ranges of motion possible during the interactions.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ahmad S (1994) A usable real-time 3D hand tracker. In: conference record of the Asilomar conference on signals" /><p class="c-article-references__text" id="ref-CR1">Ahmad S (1994) A usable real-time 3D hand tracker. In: conference record of the Asilomar conference on signals, systems and computers, pp 1257–1261</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AF. Bobick, SS. Intille, JW. Davis, F. Baird, C. Pinhanez, LW. Campbell, YA. Ivanov, A. Schutte, A. Wilson, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Bobick AF, Intille SS, Davis JW, Baird F, Pinhanez C, Campbell LW, Ivanov YA, Schutte A, Wilson A (1999) The K" /><p class="c-article-references__text" id="ref-CR2">Bobick AF, Intille SS, Davis JW, Baird F, Pinhanez C, Campbell LW, Ivanov YA, Schutte A, Wilson A (1999) The KidsRoom: a perceptually-based interactive and immersive story environment. Presence 8(4):369–393</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474699566297" aria-label="View reference 2">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20KidsRoom%3A%20a%20perceptually-based%20interactive%20and%20immersive%20story%20environment.&amp;journal=Presence&amp;volume=8&amp;issue=4&amp;pages=369-393&amp;publication_year=1999&amp;author=Bobick%2CAF&amp;author=Intille%2CSS&amp;author=Davis%2CJW&amp;author=Baird%2CF&amp;author=Pinhanez%2CC&amp;author=Campbell%2CLW&amp;author=Ivanov%2CYA&amp;author=Schutte%2CA&amp;author=Wilson%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Chen, LG. Cohen, M. Hallet, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Chen R, Cohen LG, Hallet M (2002) Nervous system reorganization following injury. Neuroscience 111(4):761–73" /><p class="c-article-references__text" id="ref-CR3">Chen R, Cohen LG, Hallet M (2002) Nervous system reorganization following injury. Neuroscience 111(4):761–73</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0306-4522%2802%2900025-8" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Nervous%20system%20reorganization%20following%20injury.&amp;journal=Neuroscience&amp;volume=111&amp;issue=4&amp;pages=761-73&amp;publication_year=2002&amp;author=Chen%2CR&amp;author=Cohen%2CLG&amp;author=Hallet%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dougall F (1996) Video image based control system, US patent number 5534917" /><p class="c-article-references__text" id="ref-CR4">Dougall F (1996) Video image based control system, US patent number 5534917</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Farrow, D. Reid, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Farrow S, Reid D (2004) Stroke survivors’ perception of a leisure-based virtual reality program. Technol Disab" /><p class="c-article-references__text" id="ref-CR5">Farrow S, Reid D (2004) Stroke survivors’ perception of a leisure-based virtual reality program. Technol Disabil 16:69–81</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Stroke%20survivors%E2%80%99%20perception%20of%20a%20leisure-based%20virtual%20reality%20program.&amp;journal=Technol%20Disabil&amp;volume=16&amp;pages=69-81&amp;publication_year=2004&amp;author=Farrow%2CS&amp;author=Reid%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="WJ. Greenleaf, M.A. MA. Tovar, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Greenleaf WJ, M.A. Tovar MA (1994) Augmenting reality in rehabilitation. Artif Intell Med 6(4):289–299" /><p class="c-article-references__text" id="ref-CR6">Greenleaf WJ, M.A. Tovar MA (1994) Augmenting reality in rehabilitation. Artif Intell Med 6(4):289–299</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2F0933-3657%2894%2990034-5" aria-label="View reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Augmenting%20reality%20in%20rehabilitation.&amp;journal=Artif%20Intell%20Med&amp;volume=6&amp;issue=4&amp;pages=289-299&amp;publication_year=1994&amp;author=Greenleaf%2CWJ&amp;author=Tovar%2CM.A.%20MA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Harris, D. Reid, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Harris K, Reid D (2005) The influence of virtual reality play on children’s motivation. Can J Occup Ther Revue" /><p class="c-article-references__text" id="ref-CR7">Harris K, Reid D (2005) The influence of virtual reality play on children’s motivation. Can J Occup Ther Revue Canadienne d Ergotherapie 72(1):21–29</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20influence%20of%20virtual%20reality%20play%20on%20children%E2%80%99s%20motivation.&amp;journal=Can%20J%20Occup%20Ther%20Revue%20Canadienne%20d%20Ergotherapie&amp;volume=72&amp;issue=1&amp;pages=21-29&amp;publication_year=2005&amp;author=Harris%2CK&amp;author=Reid%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Helsel, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Helsel S (1992) Virtual reality and education. Educ Technol 32(5):38–42" /><p class="c-article-references__text" id="ref-CR8">Helsel S (1992) Virtual reality and education. Educ Technol 32(5):38–42</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20and%20education.&amp;journal=Educ%20Technol&amp;volume=32&amp;issue=5&amp;pages=38-42&amp;publication_year=1992&amp;author=Helsel%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Jack, R. Boian, AS. Merians, M. Tremaine, GC. Burdea, SV. Adamovich, M. Recce, H. Poizner, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Jack D, Boian R, Merians AS, Tremaine M, Burdea GC, Adamovich SV, Recce M, Poizner H (2001) Virtual reality-en" /><p class="c-article-references__text" id="ref-CR9">Jack D, Boian R, Merians AS, Tremaine M, Burdea GC, Adamovich SV, Recce M, Poizner H (2001) Virtual reality-enhanced stroke rehabilitation. IEEE Trans Neural Syst Rehabil Eng 9(3):308–318</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F7333.948460" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality-enhanced%20stroke%20rehabilitation.&amp;journal=IEEE%20Trans%20Neural%20Syst%20Rehabil%20Eng&amp;volume=9&amp;issue=3&amp;pages=308-318&amp;publication_year=2001&amp;author=Jack%2CD&amp;author=Boian%2CR&amp;author=Merians%2CAS&amp;author=Tremaine%2CM&amp;author=Burdea%2CGC&amp;author=Adamovich%2CSV&amp;author=Recce%2CM&amp;author=Poizner%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SH. Jang, SH. You, M. Hallett, YW. Cho, CM. Park, SH. Cho, HY. Lee, TH. Kim, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Jang SH, You SH, Hallett M, Cho YW, Park CM, Cho SH, Lee HY, Kim TH (2005) Cortical reorganization and associa" /><p class="c-article-references__text" id="ref-CR10">Jang SH, You SH, Hallett M, Cho YW, Park CM, Cho SH, Lee HY, Kim TH (2005) Cortical reorganization and associated functional motor recovery after virtual reality in patients with chronic stroke: an experimenter-blind preliminary study. [Controlled Clinical Trial. Journal Article] Arch Phys Med Rehabil 86(11):2218–2223</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.apmr.2005.04.015" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Cortical%20reorganization%20and%20associated%20functional%20motor%20recovery%20after%20virtual%20reality%20in%20patients%20with%20chronic%20stroke%3A%20an%20experimenter-blind%20preliminary%20study.&amp;journal=%5BControlled%20Clinical%20Trial.%20Journal%20Article%5D%20Arch%20Phys%20Med%20Rehabil&amp;volume=86&amp;issue=11&amp;pages=2218-2223&amp;publication_year=2005&amp;author=Jang%2CSH&amp;author=You%2CSH&amp;author=Hallett%2CM&amp;author=Cho%2CYW&amp;author=Park%2CCM&amp;author=Cho%2CSH&amp;author=Lee%2CHY&amp;author=Kim%2CTH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Jenkins W, Merzenich M (1987) Reorganization of neocortical representation after brain injury: a neurophysiolo" /><p class="c-article-references__text" id="ref-CR11">Jenkins W, Merzenich M (1987) Reorganization of neocortical representation after brain injury: a neurophysiological model of the bases of recovery from stroke. In: Sneil F, Herbert E, Carlson B (eds) Progress in Brain. Elsevier, New York</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Joyce AW, Phalangas AC (1995) Virtual interaction: an interface for individuals with disabilities. In: Proceed" /><p class="c-article-references__text" id="ref-CR12">Joyce AW, Phalangas AC (1995) Virtual interaction: an interface for individuals with disabilities. In: Proceedings of RESNA ’95, pp 425–427</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Joyce AW, Phalangas AC (1998) The implementation and capabilities of a virtual interaction system. In: Proceed" /><p class="c-article-references__text" id="ref-CR13">Joyce AW, Phalangas AC (1998) The implementation and capabilities of a virtual interaction system. In: Proceedings of European conference on disabilities, virtual reality and associated technologies, Skovde, Sweden, pp 237–245</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kizony R, Katz N, Weingarden H, Weiss PL (2002a) Immersion without encumbrance: adapting a virtual reality sys" /><p class="c-article-references__text" id="ref-CR14">Kizony R, Katz N, Weingarden H, Weiss PL (2002a) Immersion without encumbrance: adapting a virtual reality system for the rehabilitation of individuals with stroke and spinal cord injury. In: Proceedings of the 4th international conference on disability, virtual reality and associated technology. Vresprem, Hungary, pp 55–61</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kizony R, Katz N, Weiss PL (2002b) Adapting a virtual reality system for the rehabilitation of individuals wit" /><p class="c-article-references__text" id="ref-CR15">Kizony R, Katz N, Weiss PL (2002b) Adapting a virtual reality system for the rehabilitation of individuals with stroke and spinal cord injury. In: Proceedings of the 1<sup>st</sup> international workshop on virtual reality in rehabilitation. Lausanne, Switzerland, pp 223–232</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H.I. Krebs, N. Hogan, ML. Aisen, BT. Volpe, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Krebs H.I, Hogan N, Aisen ML, Volpe BT (1998) Robot-aided neurorehabilitation. IEEE Trans Rehabil Eng 6(1):75–" /><p class="c-article-references__text" id="ref-CR16">Krebs H.I, Hogan N, Aisen ML, Volpe BT (1998) Robot-aided neurorehabilitation<i>.</i> IEEE Trans Rehabil Eng 6(1):75–87</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F86.662623" aria-label="View reference 16">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Robot-aided%20neurorehabilitation.&amp;journal=IEEE%20Trans%20Rehabil%20Eng&amp;volume=6&amp;issue=1&amp;pages=75-87&amp;publication_year=1998&amp;author=Krebs%2CH.I&amp;author=Hogan%2CN&amp;author=Aisen%2CML&amp;author=Volpe%2CBT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Krueger M (1990) Artificial reality II. Addison-Wesley, Reading" /><p class="c-article-references__text" id="ref-CR17">Krueger M (1990) Artificial reality II. Addison-Wesley, Reading</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Krueger, " /><meta itemprop="datePublished" content="1993" /><meta itemprop="headline" content="Krueger M (1993) Environmental technology: making the real world virtual. Commun ACM 36:36–37" /><p class="c-article-references__text" id="ref-CR18">Krueger M (1993) Environmental technology: making the real world virtual. Commun ACM 36:36–37</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F159544.159563" aria-label="View reference 18">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Environmental%20technology%3A%20making%20the%20real%20world%20virtual.&amp;journal=Commun%20ACM&amp;volume=36&amp;pages=36-37&amp;publication_year=1993&amp;author=Krueger%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Kuhlen, C. Dohle, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Kuhlen T, Dohle C (1995) Virtual reality for physically disabled people. Comput Biol Med 25(2):205–211" /><p class="c-article-references__text" id="ref-CR19">Kuhlen T, Dohle C (1995) Virtual reality for physically disabled people<i>.</i> Comput Biol Med 25(2):205–211</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2F0010-4825%2894%2900039-S" aria-label="View reference 19">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20for%20physically%20disabled%20people.&amp;journal=Comput%20Biol%20Med&amp;volume=25&amp;issue=2&amp;pages=205-211&amp;publication_year=1995&amp;author=Kuhlen%2CT&amp;author=Dohle%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lachapelle T, Foulds R (1992) Design of a low-immersion virtual reality system for children with disabilities." /><p class="c-article-references__text" id="ref-CR20">Lachapelle T, Foulds R (1992) Design of a low-immersion virtual reality system for children with disabilities. In: Proceedings of RESNA’92</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SP. Lum, SL. Lehman, DJ. Reinkensmeyer, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Lum SP, Lehman SL, Reinkensmeyer DJ (1995) The bimanual lifting rehabilitator: an adaptive approach for therap" /><p class="c-article-references__text" id="ref-CR21">Lum SP, Lehman SL, Reinkensmeyer DJ (1995) The bimanual lifting rehabilitator: an adaptive approach for therapy stroke patients. IEEE Trans Rehabil Eng 3(2):166–174</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F86.392371" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20bimanual%20lifting%20rehabilitator%3A%20an%20adaptive%20approach%20for%20therapy%20stroke%20patients.&amp;journal=IEEE%20Trans%20Rehabil%20Eng&amp;volume=3&amp;issue=2&amp;pages=166-174&amp;publication_year=1995&amp;author=Lum%2CSP&amp;author=Lehman%2CSL&amp;author=Reinkensmeyer%2CDJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Maes P, Darrell B, Pentland A (1995) The ALIVE system: wireless, full-body interaction with autonomous agents." /><p class="c-article-references__text" id="ref-CR22">Maes P, Darrell B, Pentland A (1995) The ALIVE system: wireless, full-body interaction with autonomous agents. Perceptual computing. MIT Media Laboratory, technical report no. 257 </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. McComas, J. Pivak, M. Laflamme, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="McComas J, Pivak J, Laflamme M (1998) Current uses of virtual reality for children with disabilities. Stud Hea" /><p class="c-article-references__text" id="ref-CR23">McComas J, Pivak J, Laflamme M (1998) Current uses of virtual reality for children with disabilities. Stud Health Technol Inf 58:161–169</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Current%20uses%20of%20virtual%20reality%20for%20children%20with%20disabilities.&amp;journal=Stud%20Health%20Technol%20Inf&amp;volume=58&amp;pages=161-169&amp;publication_year=1998&amp;author=McComas%2CJ&amp;author=Pivak%2CJ&amp;author=Laflamme%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RJ. Nudo, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Nudo RJ (1996) Neural substrates for the effects of rehabilitative training on motor recovery after ischemic i" /><p class="c-article-references__text" id="ref-CR24">Nudo RJ (1996) Neural substrates for the effects of rehabilitative training on motor recovery after ischemic infarction. Science 272:1791–1794</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1126%2Fscience.272.5269.1791" aria-label="View reference 24">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20substrates%20for%20the%20effects%20of%20rehabilitative%20training%20on%20motor%20recovery%20after%20ischemic%20infarction.&amp;journal=Science&amp;volume=272&amp;pages=1791-1794&amp;publication_year=1996&amp;author=Nudo%2CRJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="NJ. O’Dwyer, L. Ada, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="O’Dwyer NJ, Ada L (1996) Reflex hyperexcitability and muscle contracture in relation to spastic hypertonia. Cu" /><p class="c-article-references__text" id="ref-CR25">O’Dwyer NJ, Ada L (1996) Reflex hyperexcitability and muscle contracture in relation to spastic hypertonia. Curr Opin Neurol 9(6):451–455</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1097%2F00019052-199612000-00010" aria-label="View reference 25">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Reflex%20hyperexcitability%20and%20muscle%20contracture%20in%20relation%20to%20spastic%20hypertonia.&amp;journal=Curr%20Opin%20Neurol&amp;volume=9&amp;issue=6&amp;pages=451-455&amp;publication_year=1996&amp;author=O%E2%80%99Dwyer%2CNJ&amp;author=Ada%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Pengilly, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Pengilly S (1996) Integrating performance, live electronics and interactive video. Comput Math Appl 32(1):75–7" /><p class="c-article-references__text" id="ref-CR26">Pengilly S (1996) Integrating performance, live electronics and interactive video. Comput Math Appl 32(1):75–77</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2F0898-1221%2896%2900088-0" aria-label="View reference 26">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1398259" aria-label="View reference 26 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Integrating%20performance%2C%20live%20electronics%20and%20interactive%20video.&amp;journal=Comput%20Math%20Appl&amp;volume=32&amp;issue=1&amp;pages=75-77&amp;publication_year=1996&amp;author=Pengilly%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="V. Popescu, G. Burdea, M. Bouzit, M. Girone, V. Hentz, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Popescu V, Burdea G, Bouzit M, Girone M, Hentz V (2000) Orthopedic telerehabilitation with virtual force feedb" /><p class="c-article-references__text" id="ref-CR27">Popescu V, Burdea G, Bouzit M, Girone M, Hentz V (2000) Orthopedic telerehabilitation with virtual force feedback. IEEE Trans Inf Technol Biomed 4:45–51</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F4233.826858" aria-label="View reference 27">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Orthopedic%20telerehabilitation%20with%20virtual%20force%20feedback.&amp;journal=IEEE%20Trans%20Inf%20Technol%20Biomed&amp;volume=4&amp;pages=45-51&amp;publication_year=2000&amp;author=Popescu%2CV&amp;author=Burdea%2CG&amp;author=Bouzit%2CM&amp;author=Girone%2CM&amp;author=Hentz%2CV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Reid, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Reid D (2002) The use of virtual reality to improve upper-extremity efficiency skills iin children with cerebr" /><p class="c-article-references__text" id="ref-CR28">Reid D (2002) The use of virtual reality to improve upper-extremity efficiency skills iin children with cerebral palsy: a pilot study. Technol Disabil 14:53–61</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20use%20of%20virtual%20reality%20to%20improve%20upper-extremity%20efficiency%20skills%20iin%20children%20with%20cerebral%20palsy%3A%20a%20pilot%20study.&amp;journal=Technol%20Disabil&amp;volume=14&amp;pages=53-61&amp;publication_year=2002&amp;author=Reid%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Reid, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Reid D (2004) The influence of virtual reality on playfulness in children with cerebral palsy: a pilot study. " /><p class="c-article-references__text" id="ref-CR29">Reid D (2004) The influence of virtual reality on playfulness in children with cerebral palsy: a pilot study. Occup Ther Int 11(3):131–144</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2Foti.202" aria-label="View reference 29">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20influence%20of%20virtual%20reality%20on%20playfulness%20in%20children%20with%20cerebral%20palsy%3A%20a%20pilot%20study.&amp;journal=Occup%20Ther%20Int&amp;volume=11&amp;issue=3&amp;pages=131-144&amp;publication_year=2004&amp;author=Reid%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DT. Reid, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Reid DT (2002) Benefits of a virtual play rehabilitation environment for children with cerebral palsy on perce" /><p class="c-article-references__text" id="ref-CR30">Reid DT (2002) Benefits of a virtual play rehabilitation environment for children with cerebral palsy on perceptions of self-efficacy: a pilot study. Pediatr Rehabil 5(3):141–148</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F1363849021000039344" aria-label="View reference 30">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Benefits%20of%20a%20virtual%20play%20rehabilitation%20environment%20for%20children%20with%20cerebral%20palsy%20on%20perceptions%20of%20self-efficacy%3A%20a%20pilot%20study.&amp;journal=Pediatr%20Rehabil&amp;volume=5&amp;issue=3&amp;pages=141-148&amp;publication_year=2002&amp;author=Reid%2CDT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Riva, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Riva G (2003) Applications of virtual environments in medicine. Methods Inf Med 42(5):524–534" /><p class="c-article-references__text" id="ref-CR31">Riva G (2003) Applications of virtual environments in medicine. Methods Inf Med 42(5):524–534</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Applications%20of%20virtual%20environments%20in%20medicine.&amp;journal=Methods%20Inf%20Med&amp;volume=42&amp;issue=5&amp;pages=524-534&amp;publication_year=2003&amp;author=Riva%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AA. Rizzo, JG. Buckwalter, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Rizzo AA, Buckwalter JG (1997) The status of virtual reality for the cognitive rehabilitation of persons with " /><p class="c-article-references__text" id="ref-CR32">Rizzo AA, Buckwalter JG (1997) The status of virtual reality for the cognitive rehabilitation of persons with neurological disorders and acquired brain injury. Stud Health Technol Inf 39:22–33</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20status%20of%20virtual%20reality%20for%20the%20cognitive%20rehabilitation%20of%20persons%20with%20neurological%20disorders%20and%20acquired%20brain%20injury.&amp;journal=Stud%20Health%20Technol%20Inf&amp;volume=39&amp;pages=22-33&amp;publication_year=1997&amp;author=Rizzo%2CAA&amp;author=Buckwalter%2CJG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Saxe D (1999) Virtual interaction using robust color skin detection. In: Proceedings of SIGCHI 1999, pp 330–33" /><p class="c-article-references__text" id="ref-CR33">Saxe D (1999) Virtual interaction using robust color skin detection. In: Proceedings of SIGCHI 1999, pp 330–331</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Saxe DM, Foulds RA (1996) Toward robust skin identification in video images. In: Proceedings of the 2nd confer" /><p class="c-article-references__text" id="ref-CR34">Saxe DM, Foulds RA (1996) Toward robust skin identification in video images. In: Proceedings of the 2nd conference on automatic face and gesture recognition. Killington, Vermont, pp 379–384</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DM. Saxe, RA. Foulds, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Saxe DM, Foulds RA (2002) Robust region of interest coding for improved sign language telecommunication. IEEE " /><p class="c-article-references__text" id="ref-CR35">Saxe DM, Foulds RA (2002) Robust region of interest coding for improved sign language telecommunication. IEEE Trans Inf Technol Biomed 6(3):310–316</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTITB.2002.806094" aria-label="View reference 35">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Robust%20region%20of%20interest%20coding%20for%20improved%20sign%20language%20telecommunication.&amp;journal=IEEE%20Trans%20Inf%20Technol%20Biomed&amp;volume=6&amp;issue=3&amp;pages=310-316&amp;publication_year=2002&amp;author=Saxe%2CDM&amp;author=Foulds%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Stefin, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Stefin M (1997) Computer assisted therapy for multiple sclerosis and spinal cord injury patients: application " /><p class="c-article-references__text" id="ref-CR36">Stefin M (1997) Computer assisted therapy for multiple sclerosis and spinal cord injury patients: application of virtual reality. Stud Health Technol Inf 39:64–72</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 36 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Computer%20assisted%20therapy%20for%20multiple%20sclerosis%20and%20spinal%20cord%20injury%20patients%3A%20application%20of%20virtual%20reality.&amp;journal=Stud%20Health%20Technol%20Inf&amp;volume=39&amp;pages=64-72&amp;publication_year=1997&amp;author=Stefin%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Sveistrup, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Sveistrup H (2004) Motor rehabilitation using virtual reality. J NeuroEngineering Rehabil 1:10" /><p class="c-article-references__text" id="ref-CR37">Sveistrup H (2004) Motor rehabilitation using virtual reality. J NeuroEngineering Rehabil 1:10</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1186%2F1743-0003-1-10" aria-label="View reference 37">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Motor%20rehabilitation%20using%20virtual%20reality.&amp;journal=J%20NeuroEngineering%20Rehabil&amp;volume=1&amp;publication_year=2004&amp;author=Sveistrup%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MJ. Swain, DH. Ballard, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="Swain MJ, Ballard DH (1991) Color indexing. Int J Comput Vis 7(1):1–32" /><p class="c-article-references__text" id="ref-CR38">Swain MJ, Ballard DH (1991) Color indexing. Int J Comput Vis 7(1):1–32</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2FBF00130487" aria-label="View reference 38">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 38 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Color%20indexing.&amp;journal=Int%20J%20Comput%20Vis&amp;volume=7&amp;issue=1&amp;pages=1-32&amp;publication_year=1991&amp;author=Swain%2CMJ&amp;author=Ballard%2CDH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JP. Wann, JD. Turnbull, " /><meta itemprop="datePublished" content="1993" /><meta itemprop="headline" content="Wann JP, Turnbull JD (1993) Motor skill learning in cerebral palsy: movement, action, and computer-enhanced th" /><p class="c-article-references__text" id="ref-CR40">Wann JP, Turnbull JD (1993) Motor skill learning in cerebral palsy: movement, action, and computer-enhanced therapy. Baillieres Clin Neurol 2(1):15–28</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Motor%20skill%20learning%20in%20cerebral%20palsy%3A%20movement%2C%20action%2C%20and%20computer-enhanced%20therapy.&amp;journal=Baillieres%20Clin%20Neurol&amp;volume=2&amp;issue=1&amp;pages=15-28&amp;publication_year=1993&amp;author=Wann%2CJP&amp;author=Turnbull%2CJD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Weiss, D. Rand, N. Katz, R. Kizony, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Weiss P, Rand D, Katz N, Kizony R (2004) Video capture virtual reality as a flexible and effective rehabilitat" /><p class="c-article-references__text" id="ref-CR41">Weiss P, Rand D, Katz N, Kizony R (2004) Video capture virtual reality as a flexible and effective rehabilitation tool. J Neuroengineering Rehabil 1:12</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1186%2F1743-0003-1-12" aria-label="View reference 40">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 40 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Video%20capture%20virtual%20reality%20as%20a%20flexible%20and%20effective%20rehabilitation%20tool.&amp;journal=J%20Neuroengineering%20Rehabil&amp;volume=1&amp;publication_year=2004&amp;author=Weiss%2CP&amp;author=Rand%2CD&amp;author=Katz%2CN&amp;author=Kizony%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SH. You, SH. Jang, YH. Kim, YH. Kwon, I. Barrow, M. Hallett, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="You SH, Jang SH, Kim YH, Kwon YH, Barrow I, Hallett M (2005) Cortical reorganization induced by virtual realit" /><p class="c-article-references__text" id="ref-CR42">You SH, Jang SH, Kim YH, Kwon YH, Barrow I, Hallett M (2005) Cortical reorganization induced by virtual reality therapy in a child with hemiparetic cerebral palsy.] Dev Med Child Neurol 47(9):628–635</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1017%2FS0012162205001234" aria-label="View reference 41">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 41 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Cortical%20reorganization%20induced%20by%20virtual%20reality%20therapy%20in%20a%20child%20with%20hemiparetic%20cerebral%20palsy.%5D&amp;journal=Dev%20Med%20Child%20Neurol&amp;volume=47&amp;issue=9&amp;pages=628-635&amp;publication_year=2005&amp;author=You%2CSH&amp;author=Jang%2CSH&amp;author=Kim%2CYH&amp;author=Kwon%2CYH&amp;author=Barrow%2CI&amp;author=Hallett%2CM">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-007-0067-5-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgments</h2><div class="c-article-section__content" id="Ack1-content"><p>This work has been supported by US National Science Foundation grant HRD 9800175 with additional support from the Rehabilitation Engineering Research Center on Augmentative Communication (University of Delaware) and by the Rehabilitation Engineering Research Center on Technology for Children with Orthopedic Disabilities (New Jersey Institute of Technology) both from the US National Institute on Disability.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Department of Biomedical Engineering, New Jersey Institute of Technology, University Heights, Newark, NJ, 07102-1982, USA</p><p class="c-article-author-affiliation__authors-list">Richard A. Foulds, David M. Saxe &amp; Sergei Adamovich</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Romeo Tango Software, P.O. Box 1501, Bear, DE, 19701-1501, USA</p><p class="c-article-author-affiliation__authors-list">Arthur W. Joyce III</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Richard_A_-Foulds"><span class="c-article-authors-search__title u-h3 js-search-name">Richard A. Foulds</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Richard A.+Foulds&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Richard A.+Foulds" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Richard A.+Foulds%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-David_M_-Saxe"><span class="c-article-authors-search__title u-h3 js-search-name">David M. Saxe</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;David M.+Saxe&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=David M.+Saxe" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22David M.+Saxe%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Arthur_W_-Joyce"><span class="c-article-authors-search__title u-h3 js-search-name">Arthur W. Joyce III</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Arthur W.+Joyce&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Arthur W.+Joyce" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Arthur W.+Joyce%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Sergei-Adamovich"><span class="c-article-authors-search__title u-h3 js-search-name">Sergei Adamovich</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Sergei+Adamovich&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Sergei+Adamovich" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Sergei+Adamovich%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-007-0067-5/email/correspondent/c1/new">Richard A. Foulds</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Sensory-motor%20enhancement%20in%20a%20virtual%20therapeutic%20environment&amp;author=Richard%20A.%20Foulds%20et%20al&amp;contentID=10.1007%2Fs10055-007-0067-5&amp;publication=1359-4338&amp;publicationDate=2007-03-28&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Foulds, R.A., Saxe, D.M., Joyce, A.W. <i>et al.</i> Sensory-motor enhancement in a virtual therapeutic environment.
                    <i>Virtual Reality</i> <b>12, </b>87–97 (2008). https://doi.org/10.1007/s10055-007-0067-5</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-007-0067-5.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2002-11-08">08 November 2002</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2007-02-23">23 February 2007</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2007-03-28">28 March 2007</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-06">June 2008</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-007-0067-5" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-007-0067-5</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Low-immersion</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Rehabilitation</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Cortical reorganization</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Therapy</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Sensory-motor skills</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Biomedical engineering</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-007-0067-5.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=67;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

