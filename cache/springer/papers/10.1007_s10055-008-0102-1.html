<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="The Visible Human &#174; at the University of Colorado 15&#160;years l"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="The Visible Human has come through ages, providing a foundation of photorealistic anatomy for learner-centered, interactive education. Pathways for improvement of the Visible Human process for..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/12/4.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="The Visible Human &#174; at the University of Colorado 15&#160;years later"/>

    <meta name="dc.source" content="Virtual Reality 2008 12:4"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2008-11-20"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2008 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="The Visible Human has come through ages, providing a foundation of photorealistic anatomy for learner-centered, interactive education. Pathways for improvement of the Visible Human process for reverse engineering the macrostructure of the human body have been developed to provide higher resolution and decreased production time for segmentation and modeling human form. The assignment of physical properties, the development of algorithms for the interaction of surgical tools with this virtual anatomy and the availability of high-fidelity haptic interfaces provide the basis for fully immersive surgical training and certification in an environment that is zero direct-risk to patients. Interactive journal publishing, 3D stereoscopic anatomical visualization software and surgical simulators, all based on the Visible Human, the history of the Project and its utilization and provide a framework for its evolution and role in delivering education, training, certification and credentialing through virtual reality to the health care workforce of tomorrow."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2008-11-20"/>

    <meta name="prism.volume" content="12"/>

    <meta name="prism.number" content="4"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="191"/>

    <meta name="prism.endingPage" content="200"/>

    <meta name="prism.copyright" content="2008 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-008-0102-1"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-008-0102-1"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-008-0102-1.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-008-0102-1"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="The Visible Human &#174; at the University of Colorado 15&#160;years later"/>

    <meta name="citation_volume" content="12"/>

    <meta name="citation_issue" content="4"/>

    <meta name="citation_publication_date" content="2008/12"/>

    <meta name="citation_online_date" content="2008/11/20"/>

    <meta name="citation_firstpage" content="191"/>

    <meta name="citation_lastpage" content="200"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-008-0102-1"/>

    <meta name="DOI" content="10.1007/s10055-008-0102-1"/>

    <meta name="citation_doi" content="10.1007/s10055-008-0102-1"/>

    <meta name="description" content="The Visible Human has come through ages, providing a foundation of photorealistic anatomy for learner-centered, interactive education. Pathways for improve"/>

    <meta name="dc.creator" content="Victor M. Spitzer"/>

    <meta name="dc.creator" content="Michael J. Ackerman"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="The Visible Human&#8212;with 912 citations from January 1987 through March 2007. 
                    http://www.nlm.nih.gov/pubs/cbm/visible_human_2007.html
                    
                  
                        "/>

    <meta name="citation_reference" content="Elevator display of the visible human. 
                    http://www.aec.at/en/futurelab/projects_sub.asp?iProjectID=2735
                    
                  
                        "/>

    <meta name="citation_reference" content="University of Colorado Interactive Atlas (requires GL4JAVA). 
                    http://www.vhjoe.com/VHInteractiveAtlas.htm
                    
                  
                        "/>

    <meta name="citation_reference" content="Other interactive slice viewers. 
                    http://www.npac.syr.edu/projects/vishuman/VisibleHuman.html
                    
                  ; 
                    http://www.meddean.luc.edu/lumen/meded/grossAnatomy/x_sec/mainx_sec.htm
                    
                  ; 
                    http://www.barrodale.com/grid_Demo/GridBladeApplet.html
                    
                  
                        "/>

    <meta name="citation_reference" content="The Visible Human Journal of Endoscopy. 
                    http://www.vhjoe.com/
                    
                  
                        "/>

    <meta name="citation_reference" content="The University of Colorado Center for Human Simulation. 
                    http://www.visiblehuman.org/
                    
                  
                        "/>

    <meta name="citation_reference" content="The WELLS Center. 
                    http://www.wellssimulationcenter.org/
                    
                  
                        "/>

    <meta name="citation_reference" content="VR can be a detrimental &#8220;crutch&#8221;"/>

    <meta name="citation_reference" content="citation_journal_title=Hum Factors; citation_title=Continuous concurrent feedback degrades skill learning: implications for training and simulation; citation_author=RA Schmidt, H Wulf; citation_volume=39; citation_issue=4; citation_publication_date=1997; citation_pages=509-525; citation_doi=10.1518/001872097778667979; citation_id=CR9"/>

    <meta name="citation_author" content="Victor M. Spitzer"/>

    <meta name="citation_author_email" content="vic.spitzer@uchsc.edu"/>

    <meta name="citation_author_institution" content="University of Colorado Center for Human Simulation, Aurora, USA"/>

    <meta name="citation_author" content="Michael J. Ackerman"/>

    <meta name="citation_author_institution" content="National Library of Medicine, Bethesda, USA"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-008-0102-1&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2008/12/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-008-0102-1"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="The Visible Human ® at the University of Colorado 15 years later"/>
        <meta property="og:description" content="The Visible Human has come through ages, providing a foundation of photorealistic anatomy for learner-centered, interactive education. Pathways for improvement of the Visible Human process for reverse engineering the macrostructure of the human body have been developed to provide higher resolution and decreased production time for segmentation and modeling human form. The assignment of physical properties, the development of algorithms for the interaction of surgical tools with this virtual anatomy and the availability of high-fidelity haptic interfaces provide the basis for fully immersive surgical training and certification in an environment that is zero direct-risk to patients. Interactive journal publishing, 3D stereoscopic anatomical visualization software and surgical simulators, all based on the Visible Human, the history of the Project and its utilization and provide a framework for its evolution and role in delivering education, training, certification and credentialing through virtual reality to the health care workforce of tomorrow."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>The Visible Human ® at the University of Colorado 15 years later | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-008-0102-1","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Virtual anatomy, Surgical simulation, Visible Human, Medical education, Anatomy","kwrd":["Virtual_anatomy","Surgical_simulation","Visible_Human","Medical_education","Anatomy"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-008-0102-1","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-008-0102-1","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=102;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-008-0102-1">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            The Visible Human<sup>®</sup> at the University of Colorado 15 years later
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-008-0102-1.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-008-0102-1.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2008-11-20" itemprop="datePublished">20 November 2008</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">The Visible Human<sup>®</sup> at the University of Colorado 15 years later</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Victor_M_-Spitzer" data-author-popup="auth-Victor_M_-Spitzer" data-corresp-id="c1">Victor M. Spitzer<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Colorado Center for Human Simulation" /><meta itemprop="address" content="grid.266185.e, 0000000121090824, University of Colorado Center for Human Simulation, PO Box 6508, Mail Stop F-435, Aurora, CO, 80045-0508, USA" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Michael_J_-Ackerman" data-author-popup="auth-Michael_J_-Ackerman">Michael J. Ackerman</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="National Library of Medicine" /><meta itemprop="address" content="grid.280285.5, 0000000405077840, National Library of Medicine, Bethesda, MD, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 12</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">191</span>–<span itemprop="pageEnd">200</span>(<span data-test="article-publication-year">2008</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">170 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">5 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-008-0102-1/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>The Visible Human has come through ages, providing a foundation of photorealistic anatomy for learner-centered, interactive education. Pathways for improvement of the Visible Human process for reverse engineering the macrostructure of the human body have been developed to provide higher resolution and decreased production time for segmentation and modeling human form. The assignment of physical properties, the development of algorithms for the interaction of surgical tools with this virtual anatomy and the availability of high-fidelity haptic interfaces provide the basis for fully immersive surgical training and certification in an environment that is zero direct-risk to patients. Interactive journal publishing, 3D stereoscopic anatomical visualization software and surgical simulators, all based on the Visible Human, the history of the Project and its utilization and provide a framework for its evolution and role in delivering education, training, certification and credentialing through virtual reality to the health care workforce of tomorrow.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Background</h2><div class="c-article-section__content" id="Sec1-content"><p>We follow Visible Human (VH) development, mostly at the University of Colorado Center for Human Simulation (CHS), through the characteristics of virtual reality (immersive and interactive) to the point where these characteristics are tightly coupled in a single environment of surgical simulation to produce a true virtual reality (or augmented reality) experience.</p><p>It was apparent at the introduction of the U.S. National Library of Medicine’s Visible Human<sup>®</sup> in 1994 at the Radiological Society of North America (RSNA) <i>Info</i>RAD in Chicago that rapid display of successive slices of human anatomic photographic images had the “power to immerse” an audience, particularly one as well-versed in cross-sectional anatomy as radiologists. RSNA attendees stood and watched the rapid, sequential display of full-resolution photographic images as they followed structures through sequences of the original transverse images as well as coronal and sagittal reconstructions. The images were played at standard video rates of 30 frames (slices) per second from an HDTV Recordable Laser Disc (provided by Sony Corporation) and displayed on a $50,000 Sony HDTV CRT (things have changed in 15 years). The HDTV format and resolution closely matched that of the Visible Human Male (VHM). The 1,877 transverse cross-sections (including the missing slices at three saw kerfs) were captured with a 2,048 × 2,048 pixel Leaf camera but the image set was cropped to the smallest bounding volume for the anatomical data. The resulting image matrices were 1,760 × 1,024 pixels—within the limits of the Sony HDTV resolution and format of 1,920 × 1,080. The entire trip through the body in the axial direction took just over a minute. The sagittal images were displayed in a horizontal format to use the 1,920×-resolution of the HDTV format to display the 1,877 edges of the Visible Human transverse images (the other dimension of the sagittal images is 1,024). Coronal images were a slight problem—requiring 1,877 × 1,760 pixels. The coronal images were cropped at 1,877 × 1,080 to fit the HDTV format and still maintain their full resolution. This was at the expense of cropping the upper extremities.</p><p>When the Visible Human Female (VHF) with over 5,000 slices was introduced the following year, again at the RSNA <i>Info</i>RAD, the full captured resolution of the transverse cross-sections (the same as the male) was just right for HDTV. However, display of the sagittal and coronal images was far beyond the HDTV standard. Sony, however, again came to the rescue, along with Silicon Graphics, Inc. (SGI) and SMS Data Products Group (SMS). In 1995, there were two Sony 2,048 × 2,048 pixel, high intensity projectors in the US (although we did not know it at the time). Sony provided both projectors to display the VHF—16 feet high in 2,048 × 4,096 resolution—displaying 80% of the full 5,189 vertical pixel dimension of the VHF while completely accommodating her <i>x</i>-axis width. This display certainly immersed attendees in the anatomy of the human body displayed slice by slice in color photographic detail. The VHF data was delivered to the projectors by an SGI Onyx<sup>®</sup>
                        <sup><a href="#Fn1"><span class="u-visually-hidden">Footnote </span>1</a></sup> with an SMS Fibre Channel Enterprise Level RAID. Although one of the fastest data transfer rates available at the time, this still did not provide the required rate of greater than 250 MPixels/s to present the slices at a full video rate (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0102-1#Fig1">1</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig1_HTML.jpg" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Jim Heath (VH photographer), David Whitlock, MD, PhD (co-PI on the Visible Human Project) and Helen Pelster (VH computer scientist) at the 1995 RSNA <i>Info</i>RAD—with the Visible Human Female in full resolution (without her <i>lower legs</i>) in the background</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     </div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Immersive and interactive</h2><div class="c-article-section__content" id="Sec2-content"><p>These two events certainly captured the “immersive” essence of virtual reality but neither of the VH displays was interactive (although the HD Laser Disc could have been). The VHM was immersive because of the rapid flow through the serial images at very high resolution. The VHF was immersive mostly because of the enormity and high resolution of the image display.</p><p>In 1994, Anatomical Visualization Inc. introduced the VHM on <i>LaserDisc</i>
                        <sup>®</sup>
                        <sup><a href="#Fn2"><span class="u-visually-hidden">Footnote </span>2</a></sup> (NTSC) with sections of the disc that were whole body and other sections that were full resolution (for the male). The <i>LaserDisc</i> included all Computed Tomography and Magnetic Resonance Images of the VHM as well as full resolution and whole body coronal and sagittal reconstructions. This media provided an interactive and immersive environment. The experience was a complete journey through the human body in any of three principal directions—with both the direction and speed under user control. Subject specific interactivity (not just play forward or reverse) was provided by bar codes and by SuperCard and HyperCard stacks controlling the <i>LaserDisc</i> to jump to or play through user-selected anatomic structures or regions of the body in transverse, coronal or sagittal format.</p><p>Many other products and demonstrations became available for navigating the cross-sectional anatomy of the Visible Human. Most of these were computer-based with images retrieved from disk, or Internet-based, again with the images retrieved from disk. These cross-sectional navigators are certainly interactive but hardly immersing. On the fringe of cross-sectional navigation interfaces for Visible Human data was an extremely innovative concept that easily qualifies as virtual reality. This interface utilized the position of an elevator in the Ars Electronica Futurelab, Linz, Germany to navigate the video resolution, VHM cross-sections appearing on the floor of the elevator.</p><p>With segmentation of the Visible Human both ray-traced renderings and polygon model, fly-through journeys of organs and systems became available for a “visual” virtual reality exploration of the human body. One to six wall Cave Automatic Virtual Environments were utilized to provide the fantasy of the VR experience exploring the anatomy and 3D relationships of the human body. 3D stereoscopic, single wall projection of the Visible Human is in use in many educational environments around the country. For example, every major higher education institution in Delaware has the Visible Human available in 3D stereo for their human anatomy courses. At the University of Colorado School of Medicine we have four locations, ranging in audience size from 12 to 100, for medical education through 3D Stereoscopic viewing of the fully segmented Visible Human. An additional one-wall, 3D stereoscopic, projection room was built at the Work, Education and Lifelong Learning Simulation (WELLS) Center in partnership with the CHS. The WELLS Center is a private/public venture for accelerating nurse education and experience through simulation. It is collaboratively supported by the United States Department of Labor, the Colorado Department of Labor and Employment and the Colorado Workforce Development Council. At the WELLS Center the Visible Human is utilized in the form of the VH Dissector<sup><a href="#Fn3"><span class="u-visually-hidden">Footnote </span>3</a></sup> Stereo Edition with a clearly defined educational goal of re-teaching the 3D anatomy most important to simulation scenarios that critical care nurses experience on human patient simulators. An 80-h program is utilized by regional hospitals to accelerate new graduate nurses into critical care careers. The program is expanding to cover other specialty nursing areas and other cohorts of career nurses.</p></div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Closer to reality</h2><div class="c-article-section__content" id="Sec3-content"><p>Following the Visible Human Project imaging, the CHS sectioned and imaged a head and neck specimen at 125 μ and a knee at 100 μ. In 2001-02 the CHS, through an Anatomical Methods contract with the NLM (N01-LM-1-3536), improved specimen preparation and cutting methods that would facilitate the generation of Visible Human type image data with higher precision (mechanical and photographic), accuracy and tissue contrast. One of the major outcomes of the Anatomical Methods work was increased automation for many steps of the process. This was all done to predict the success of an eventual sectioning of a next generation, full-body Visible Human and some day extend the Visible Human to a library of human anatomy image data with sufficient diversity to include a useful representation of virtual anatomic and pathologic variation and to support the simulation of an even more diverse population of human form.</p><p>During the past 5 years the CHS has sectioned five human specimens at higher resolution than the VHF but with the same basic techniques used for the Visible Human Project. Listed in the order they were cut, these specimens include:</p><ul class="u-list-style-dash">
                  <li>
                    <p>Thorax including the complete heart (2003) (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0102-1#Fig3">3</a>, left)</p>
                  </li>
                  <li>
                    <p>Knee (2005) (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0102-1#Fig2">2</a>, right)</p>
                  </li>
                  <li>
                    <p>Wrist and Hand (2006) (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0102-1#Fig2">2</a>, left)</p>
                  </li>
                  <li>
                    <p>Prostate in full pelvis (2006) (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0102-1#Fig3">3</a>, right)</p>
                  </li>
                  <li>
                    <p>Foot and ankle (2007)</p>
                  </li>
                </ul>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>The image in the <i>left</i> is a cross-section through a wrist and hand volumetric image dataset developed in collaboration with Dr Jennifer Wolf from the University of Colorado Department of Orthopaedics. This specimen is currently being segmented and classified in preparation for modeling wrist surgery procedures. The cross-section on the right is part of a 100 μ volumetric image dataset of the knee. This data is utilized in the Diagnostic Knee Arthroscopy Simulator described in a later section. The arteries of the knee were injected with colored latex and the knee was sectioned at 100 μ</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig3_HTML.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig3_HTML.jpg" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>The image on the <i>left</i> is a cross-section through an injected (arteries, veins and bronchi) thoracic specimen that was sectioned at the CHS and broadcast live to the 2003 American College of Cardiology Annual Meeting. The sections were spaced at 100 μ and the region of the cardiac valves was sectioned during the meeting. The image on the <i>right</i> is from a specimen imaged at 50 μ in collaboration with Dr Francisco La Rosa from the University of Colorado Department of Pathology. The data is currently being segmented and classified to develop models of the prostate infrastructure and neighboring anatomy. The entire pelvis was sectioned but only the <i>central portion</i>, shown in this figure, was imaged</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The foot and ankle (2007) is the best-sectioned volumetric image dataset to date. The specimen was sectioned at 50 μ (through most of the specimen). It consists of more than 5,000 visible light photographs acquired over a 10-day period. The cutting and imaging process was conducted in five, 4-h, two-person shifts per day (24 h of cutting per day was the goal but personnel were not available to cover the six shifts) (Fig. 4). With a few small improvements in the automation process and with around-the-clock cutting and imaging it is anticipated that a whole-body process can be sped up by at least 20%. At this pace, a complete new Visible Human whole-body specimen can be sectioned at 50 μ in about 2 months (the VHF required 1 year to complete). The sectioning will result in over 36,000 slices each imaged with 80 M pixels of resolution or 480 MB of raw data. Our experience with imaging the foot and ankle with UV was encouraging and therefore increasing this estimate to include two images per slice (one of visible light and one of UV fluorescence) will result in roughly 1 GB of data per image or 36 TB for a six foot body. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig4_HTML.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig4_HTML.jpg" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>This image is part of the more than 5,000 images through a foot and ankle sectioned and imaged in the summer of 2007. The specimen is from a young female. UV images were also acquired although not at each level. The specimen was cut from inferior to superior. Sections through the tarsal bones and below were cut every 50 μ</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>This all leads to our vision for the Next Generation Visible Human and the future of the Visible Human Library of Human Anatomy.</p></div></div></section><section aria-labelledby="Sec4"><div class="c-article-section" id="Sec4-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec4">The next generation visible human</h2><div class="c-article-section__content" id="Sec4-content">
                <ul class="u-list-style-dash">
                  <li>
                    <p>A 6′ specimen requires 36,576 slices (50 μ each)</p>
                  </li>
                  <li>
                    <p>600 slices/day requires 61 days of continuous cutting</p>
                  </li>
                  <li>
                    <p>61 days of continuous cutting requires a cycle time of 2.4 minutes per slice</p>
                  </li>
                  <li>
                    <p>Assuming a 14″ × 22″ cross-section (VHM) requires</p>
                  </li>
                  <li>
                    <p>198,709 sq mm/image ~ 80 M-50 μ pixels/image</p>
                  </li>
                  <li>
                    <p>Assuming 42–48 bit RGB images yields 480 MB/image</p>
                  </li>
                  <li>
                    <p>Assuming two images/slice (visible and UV) yields ~1 GB/image and</p>
                  </li>
                  <li>
                    <p>&gt;36 TB per body.</p>
                  </li>
                </ul>
              <p>The Anatomical Methods work described above enabled continued system improvements so that during the summer of 2007 we were able to section the foot and ankle specimen with the following automated processes (that were not available when the Visible Human was imaged):</p><ul class="u-list-style-dash">
                  <li>
                    <p>Monitoring and maintenance of the cutting environment temperature and humidity</p>
                  </li>
                  <li>
                    <p>Maintenance of the block surface at a constant temperature</p>
                  </li>
                  <li>
                    <p>Debris removal from the block surface</p>
                  </li>
                  <li>
                    <p>Tissue removal from the cutting chamber</p>
                  </li>
                  <li>
                    <p>Image capture, storage and archive</p>
                  </li>
                  <li>
                    <p>Cutting system lubrication</p>
                  </li>
                </ul>
                     <p>The VHF was sectioned in a room temperature environment over an entire year with large fluctuations in block temperature both during and between cutting periods. The foot and ankle specimen cut was sectioned in 2007 in a −10°F freezer with the block surface maintained at −80°C throughout the cutting and non-cutting periods. The result of this improved automation and temperature control is the greatly improved precision of section size (block size) and thickness and consistency of the image color and intensity from slice to slice. Additions of subcomponent redundancy will further insure success for future efforts in this area.</p></div></div></section><section aria-labelledby="Sec5"><div class="c-article-section" id="Sec5-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec5">Virtual reality publishing</h2><div class="c-article-section__content" id="Sec5-content"><p>Interacting with a computer-simulated environment was taken to a new level in the publishing world with the Visible Human Journal of Endoscopy (VHJOE) published by the Center for Human Simulation, John Deutsch, MD, Editor. The Journal contains review articles, case reports and literature reviews of Gastroenterology—primarily focusing on endoscopy. The Journal utilizes images and reconstructions from the Visible Human, hence its name, to illustrate normal anatomy for comparison to the pathologic images in the articles. The Journal brings a unique feature to the publishing industry—The Interactive Figure—a publishing venue for Virtual Reality. Figures that appear to be simple oblique cross-sections through the Visible Human are actually hyperlinked to the Center for Human Simulation’s Interactive Atlas.</p><p>The Interactive Atlas provides the entire volume image data of the VHM and an interface that allows the user (Journal reader) to translate and rotate a cutting plane. The graphical cutting plane responds in real time and when the plane positioning (via mouse) is interrupted on release of the mouse button, the cross-section through the Visible Human defined by that cutting plane is returned (the slice return time depends on Internet speed but on the average takes a few seconds). The cutting plane is positioned relative to a user-selectable set of 3D models of Visible Human anatomy. The cross-section field-of-view is user-controllable from 5 to 25 cm. Structures in the cross-section are identified on mouse roll-over. Utilizing the precision cutting and digital data, measurements are also available trough the interface. Shortcut key-strokes and drop-down menus provide rapid navigation to standard radiologic planes and snap-to orientation of the 3D anatomical models. With the proliferation of both inter- and extracorporeal ultrasound this VR tool should see dramatically greater utilization both with Visible Human and other 3D volumetric, image data.</p><p>The “state” of this interface can be captured (the models used to orient the plane, their orientation and viewing angle and the orientation and viewing angle of the cutting plane). This “state” is published as a url in the Journal underneath a static image of the oblique cross-section. A reader of the Journal article clicks on the hyperlink and is directed to the Interactive Atlas (set to the state saved by the author of the journal article) where they can interact with the anatomy and the cutting plane to investigate the surrounding anatomic neighborhood by varying the cross-section level and orientation. This VR application started with a strong need for cross-sectional anatomy at user defined orientations to match the cross-sectional images of endoscopic ultrasound. The Interactive Atlas can also provide an ultrasound image at the position of the VH cross-section, simulated from the geometry of the Visible Human and the speed of sound in the segmented and classified tissue. We have also implemented the Interactive Atlas on a “local” server so that cross-sections are returned in real time as the cutting plane is moved (not just on mouse—up). With this real time version of the Interactive Atlas, a transducer path can be established to return an animation of photographic cross-sections or simulated ultrasound (Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0102-1#Fig5">5</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0102-1#Fig6">6</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0102-1#Fig7">7</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>VHJOE Table of Contents shows two icons on the Featured Movie at the bottom of the page. The projector icon means there is a movie embedded in the article. The icon of a man with a plane at his waist indicates there is a link to the CHS Interactive Atlas in this article</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig6_HTML.jpg?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig6_HTML.jpg" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>The Interactive Atlas provides cross-sections at user selectable orientations facilitated by the 3D models on the <i>left</i>. The cross-section that is returned is labeled on mouse roll-over and structures can be measured with a click-and-drag motion of the mouse</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig7_HTML.jpg?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig7_HTML.jpg" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>The esophageal ultrasound image on the <i>left</i> was simulated using the anatomy of the Visible Human and tissue specific speed-of-sound measurements from the literature</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     </div></div></section><section aria-labelledby="Sec6"><div class="c-article-section" id="Sec6-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec6">Surgical simulation</h2><div class="c-article-section__content" id="Sec6-content"><p>Shortly after the VHM and VHF imaging was completed, Dr Karl Reinig was utilizing the VH volumetric image data at the CHS as an environment for multi-sense, immersive VR utilizing 3D stereoscopic display for life-like tissue visualization and SensAble Technologies haptic devices to display tissue resistance to touch (palpation) and invasive or remodeling interaction (needles and scalpels). The combination of photorealistic anatomy and the ability to interact with the anatomy provided the first step toward the realism of “seeing” and “feeling” individual tissues of the human body as it would be seen and felt yielding to the blade of a scalpel, piercing of a needle or palpation with one’s own, real finger (in a thimble). These simulated procedures require segmented tissue for the haptic response calculations in order to provide a different feeling for skin, fat, muscle or bone. For the primary haptic response, not accounting for muscle fiber direction, segmentation of individual muscles is not required. The visualization, however, can be done without segmentation (except for segmentation of the skin surface from the embedding gelatin). In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0102-1#Fig8">8</a>, the top surface of the thigh as well as a cut surface produced by the scalpel map pixel colors from the original VH data onto the surfaces.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig8_HTML.jpg?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig8_HTML.jpg" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Real time modification of a polygon model of the VHM thigh provides a view of the cut surface produced by the user-directed scalpel blade. A SensAble Technologies Phantom<sup>®</sup> (Phantom is a registered trademark of SensAble Technologies) coupled to a haptic model of the thigh (co-located with a visual model of the thigh) provides the user with a feeling of drag on the scalpel blade as the cut is made. The drag force is integrated over the contact surface of the blade</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Our first segmentation of the VHM provided a thigh with al the muscles, major vessels and nerves and a femur with sufficient detail for scalpel/anatomy interaction. However, a subsequent surgical simulator was designed to pass a drill through the femur (to cross-pin an intramedullary nail). This required a second level of skeletal segmentation so that the drill might be felt as it enters and exits the cortical bone (twice) and passes through a much different feeling medullary canal. A subsequent segmentation pass through the thigh subdivided the femur into a cortical layer and a medullary canal. Nutrient arteries penetrating the cortical bone and running in the medullary canal were also added. In this clinical procedure the medullary canal was also required for fluoroscopic visualization of the pin placement (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0102-1#Fig9">9</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig9_HTML.jpg?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig9_HTML.jpg" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>The image on the left shows a pin holder in the <i>left</i> hand with a hammer in the <i>right</i> hand for driving the pin through the femur. The hammer and pin holder are both extensions of haptic devices that provide the resistance one would feel when tapping the pin through the femur. The right-hand haptic device also provides gravitational force for the head of the hammer. The image on the right includes the skin surface and a fluoroscopic view of the intramedullary nail and pin</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Applications involving a needle and syringe were also developed. The force of the needle interaction with each tissue interface (as well as the integrated drag through a single tissue) is again, provided by the Phantom. The syringe plunger, however, required another haptic interface to display the force one feels as they push in or pull back on the plunger when the needle tip is in different tissue types—or fluids (including air). This syringe haptic interface was developed at the CHS and complete needle simulation procedures are under development by Touch of Life Technologies. They include arthrocentesis, regional anesthesia and fine needle aspiration biopsy. These needle-based applications, as well as others including phacoemulsification and fasciotomy, run on a Common Platform (CP) simulation workstation with 3D stereoscopic visualization, bi-manual haptic response and fully instrumented syringe response. These applications incorporate Visible Human whole body data and therefore extending their application to other regions of the body is easily accomplished as the whole-body tissue segmentation is available. The second haptic interface on the CP can be used for palpation (using a thimble for the user’s finger) or to simulate an ultrasound probe as a guidance or confirmation aid for needle placement (just beginning to be used in rheumatology).</p><p>Some procedures require body configurations different than those of the Visible Human in the “nearly” anatomical position. For example, paravertebral blocks in the cervical region are generally administered with the neck flexed as much as possible. Therefore to simulate this procedure we work on a cervical model of the Visible Human with the vertebrae and their connecting ligaments limiting the motion during finite element flexion of the vertebral column and soft tissues of the neck. The position of the spinal nerves as they exit the spinal canal generally follows vertebral motion and this approximation to re-configuring the Visible Human for regional anesthesia by cervical paravertebral block is used for the regional anesthesia simulator (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0102-1#Fig10">10</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig10_HTML.jpg?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig10_HTML.jpg" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Virtual Reality Knee Joint Arthrocentesis Simulation running on a Common Platform Simulation Workstation. With a simple data reload the learner can be mentored through the procedure in the shoulder joint. The whole body Visible Human provides the ability to extend this VR training tool to any joint in the body</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>For a complete educational experience the simulator must provide communication and feedback for both a job well done as well as for procedures that would warrant removal of the student from the OR in the “real” world. For this function the visualization is critical for drawing the student’s attention to the anatomy and instrumentation and their relationship to each other in 3D space. An example of this is provided in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0102-1#Fig12">12</a> where the internal anatomy of the shoulder provides a detailed 3D view of the structures relevant for successful arthrocentesis of the the joint or associated bursa and tendons. Other structures may also be added to the VR environment, for example the lungs, to demonstrate the anatomy vulnerable to grossly misguided needle placement. Visualization of neighboring structures can be a major aid to understanding the procedure and are often times only available in the virtual world. The major problem in using such VR-only material is that the support they give may be used as a crutch that actually hampers an un-aided performance of the procedure (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0102-1#Fig11">11</a>; Schmidt and Wulf <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Schmidt RA, Wulf G (1997) Continuous concurrent feedback degrades skill learning: implications for training and simulation. Hum Factors 39(4):509–525" href="/article/10.1007/s10055-008-0102-1#ref-CR9" id="ref-link-section-d75568e832">1997</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig11_HTML.jpg?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig11_HTML.jpg" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>The skin of the VHM is rendered semitransparent to reveal the internal anatomy that is the target of the procedure (the <i>left shoulder</i> joint capsule) as well as the vascular structures that are vulnerable to damage. The location of the cupola of the lung can be imagined from the position of the ribs but the power of VR (and the segmented VH) allows the user to add lung models to the scene and thereby avoid (or explain) a lung collapse</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>A Diagnostic Knee Arthroscopy Simulator (DKAS) development began in 2001 with SBIR funding from the NIH. This simulator was developed by Touch of Life Technologies in partnership with the American Association of Orthopaedic Surgeons (AAOS) and their partners, the American Board of Orthopaedic Surgeons and the Arthroscopy Association of North America. The electronic Mentor for this surgical simulator was developed by the CHS. One component of the basis for this partnership with the AAOS was the visual reality of the Visible Human.</p><p>The simulator is available as a product and is based on the high-resolution knee described in the “Closer to Reality” section. The high-resolution knee provides an image with structural detail of the articular capsule and the related ligaments and tendons that is close to the high magnification images available today in arthroscopy (pre-HDTV standards).</p><p>The DKAS also required the development of another haptic interface—one for applying varus and valgus force to the knee joint in order to open sufficiently the medial and lateral compartments to visualize their articular cartilage of the femur and tibia and to gain access to a greater extent of the posterior compartments of the knee joint. This haptic interface is in the form of a leg, ankle and foot that can be used to apply varus and valgus forces and is also used in a similarly natural way to effect flexion and extension of the knee joint and rotation of the hip joint. The application of knee joint flexion/extension and varus/valgus force is a major and non-trivial part of teaching the overall procedure of diagnostic knee arthroscopy.</p><p>Haptic feedback for the instruments in this DKAS is provided by two Desktop Phantoms. Each Phantom has been modified to connect with an arthroscope and camera or a probe. The camera may be attached to either haptic interface to establish the location or portal (predefined) of the arthroscope. The other haptic interface is available to serve as a surgical probe and provide the tissue response one would encounter when probing articular cartilage, pulling on the ACL or PCL or feeling the hidden surfaces of the meniscus. The instruments are coded for electronic recognition so that the student can be prompted or evaluated for their use of the correct portal (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0102-1#Fig12">12</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig12_HTML.jpg?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0102-1/MediaObjects/10055_2008_102_Fig12_HTML.jpg" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Dr Karl Reinig to the right of the simulator and Dr Peter MacDonald using the Diagnostic Knee Arthroscopy Simulator at the Pan Am Clinic in Winnipeg, Canada</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0102-1/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>An integral part of all of these VR surgical simulators is an electronic Mentor. The Mentor not only explains and guides the user through each step of a complex procedure but also evaluates their progress as they go. The Mentor passes information to the “simulator” for configuration of the anatomy and surgical environment appropriate for a step or task. The simulator passes the complete state of the VR system back to the Mentor for evaluation of the users progress. The benchmark for proficiency with a particular procedure can be established by the community of practicing surgeons most appropriate for the procedure—in this case diagnostic knee arthroscopy. Once a user becomes proficient at all steps comprising a procedure the explanations and “micro-guidance” are withdrawn and the user is evaluated as they perform the procedure in a manner very similar to how it would be performed on a real patient in the operating room.</p></div></div></section><section aria-labelledby="Sec7"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7">Conclusion</h2><div class="c-article-section__content" id="Sec7-content"><p>The Visible Human has come a long way in 15 years but has a long way to go to make the leap from Visible to Virtual Human, from cadaveric anatomy to living anatomy, from sampled anatomy to representational anatomy and from research to commodity education.</p><p>On the mechanical end, more specimens must be created with improved spatial and contrast resolution. More specimens must be cut to provide diversity and serve as a basis for simulated diversity.</p><p>On the algorithmic end, segmentation must be improved to make new specimens useful in a more timely manner. Kinematics must be integrated into the structural anatomy to provide configurable anatomy in the short term and reactive anatomy in the long term.</p></div></div></section>
                        
                    

                    <section aria-labelledby="notes"><div class="c-article-section" id="notes-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="notes">Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1"><span class="c-article-footnote--listed__index">1.</span><div class="c-article-footnote--listed__content"><p>Onyx is a registered trademark of Silicon Graphics, Inc.</p></div></li><li class="c-article-footnote--listed__item" id="Fn2"><span class="c-article-footnote--listed__index">2.</span><div class="c-article-footnote--listed__content"><p>
                              <sup>®</sup>
                              <i>LaserDisc</i> is a registered trademark of Pioneer Electronics.</p></div></li><li class="c-article-footnote--listed__item" id="Fn3"><span class="c-article-footnote--listed__index">3.</span><div class="c-article-footnote--listed__content"><p>VH Dissector is a trademark of Touch of Life Technologies, Inc.</p></div></li></ol></div></div></section><section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="The Visible Human—with 912 citations from January 1987 through March 2007. http://www.nlm.nih.gov/pubs/cbm/vis" /><p class="c-article-references__text" id="ref-CR1">The Visible Human—with 912 citations from January 1987 through March 2007. <a href="http://www.nlm.nih.gov/pubs/cbm/visible_human_2007.html">http://www.nlm.nih.gov/pubs/cbm/visible_human_2007.html</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Elevator display of the visible human. http://www.aec.at/en/futurelab/projects_sub.asp?iProjectID=2735&#xA;       " /><p class="c-article-references__text" id="ref-CR2">Elevator display of the visible human. <a href="http://www.aec.at/en/futurelab/projects_sub.asp?iProjectID=2735">http://www.aec.at/en/futurelab/projects_sub.asp?iProjectID=2735</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="University of Colorado Interactive Atlas (requires GL4JAVA). http://www.vhjoe.com/VHInteractiveAtlas.htm&#xA;     " /><p class="c-article-references__text" id="ref-CR3">University of Colorado Interactive Atlas (requires GL4JAVA). <a href="http://www.vhjoe.com/VHInteractiveAtlas.htm">http://www.vhjoe.com/VHInteractiveAtlas.htm</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Other interactive slice viewers. http://www.npac.syr.edu/projects/vishuman/VisibleHuman.html; http://www.medde" /><p class="c-article-references__text" id="ref-CR4">Other interactive slice viewers. <a href="http://www.npac.syr.edu/projects/vishuman/VisibleHuman.html">http://www.npac.syr.edu/projects/vishuman/VisibleHuman.html</a>; <a href="http://www.meddean.luc.edu/lumen/meded/grossAnatomy/x_sec/mainx_sec.htm">http://www.meddean.luc.edu/lumen/meded/grossAnatomy/x_sec/mainx_sec.htm</a>; <a href="http://www.barrodale.com/grid_Demo/GridBladeApplet.html">http://www.barrodale.com/grid_Demo/GridBladeApplet.html</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="The Visible Human Journal of Endoscopy. http://www.vhjoe.com/&#xA;                        " /><p class="c-article-references__text" id="ref-CR5">The Visible Human Journal of Endoscopy. <a href="http://www.vhjoe.com/">http://www.vhjoe.com/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="The University of Colorado Center for Human Simulation. http://www.visiblehuman.org/&#xA;                        " /><p class="c-article-references__text" id="ref-CR6">The University of Colorado Center for Human Simulation. <a href="http://www.visiblehuman.org/">http://www.visiblehuman.org/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="The WELLS Center. http://www.wellssimulationcenter.org/&#xA;                        " /><p class="c-article-references__text" id="ref-CR7">The WELLS Center. <a href="http://www.wellssimulationcenter.org/">http://www.wellssimulationcenter.org/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="VR can be a detrimental “crutch”" /><p class="c-article-references__text" id="ref-CR8">VR can be a detrimental “crutch”</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Schmidt, H. Wulf, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Schmidt RA, Wulf G (1997) Continuous concurrent feedback degrades skill learning: implications for training an" /><p class="c-article-references__text" id="ref-CR9">Schmidt RA, Wulf G (1997) Continuous concurrent feedback degrades skill learning: implications for training and simulation. Hum Factors 39(4):509–525</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1518%2F001872097778667979" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Continuous%20concurrent%20feedback%20degrades%20skill%20learning%3A%20implications%20for%20training%20and%20simulation&amp;journal=Hum%20Factors&amp;volume=39&amp;issue=4&amp;pages=509-525&amp;publication_year=1997&amp;author=Schmidt%2CRA&amp;author=Wulf%2CH">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-008-0102-1-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">University of Colorado Center for Human Simulation, PO Box 6508, Mail Stop F-435, Aurora, CO, 80045-0508, USA</p><p class="c-article-author-affiliation__authors-list">Victor M. Spitzer</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">National Library of Medicine, Bethesda, MD, USA</p><p class="c-article-author-affiliation__authors-list">Michael J. Ackerman</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Victor_M_-Spitzer"><span class="c-article-authors-search__title u-h3 js-search-name">Victor M. Spitzer</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Victor M.+Spitzer&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Victor M.+Spitzer" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Victor M.+Spitzer%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Michael_J_-Ackerman"><span class="c-article-authors-search__title u-h3 js-search-name">Michael J. Ackerman</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Michael J.+Ackerman&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Michael J.+Ackerman" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Michael J.+Ackerman%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-008-0102-1/email/correspondent/c1/new">Victor M. Spitzer</a>.</p></div></div></section><section aria-labelledby="additional-information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><p>
                        <sup>®</sup>Visible Human is a registered trademark of the U.S. National Library of Medicine.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=The%20Visible%20Human%C2%AE%20at%20the%20University%20of%20Colorado%2015%C2%A0years%20later&amp;author=Victor%20M.%20Spitzer%20et%20al&amp;contentID=10.1007%2Fs10055-008-0102-1&amp;publication=1359-4338&amp;publicationDate=2008-11-20&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Spitzer, V.M., Ackerman, M.J. The Visible Human<sup>®</sup> at the University of Colorado 15 years later.
                    <i>Virtual Reality</i> <b>12, </b>191–200 (2008). https://doi.org/10.1007/s10055-008-0102-1</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-008-0102-1.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-09-08">08 September 2008</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-09-22">22 September 2008</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-11-20">20 November 2008</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-12">December 2008</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-008-0102-1" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-008-0102-1</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Virtual anatomy</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Surgical simulation</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Visible Human</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Medical education</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Anatomy</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-008-0102-1.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=102;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

