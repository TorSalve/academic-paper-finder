<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="A comparison of guidance cues in desktop virtual environments"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Designers of educational and entertainment desktop virtual environments (VEs) have employed a variety of cues for motivating users to perform actions or adopt particular viewpoints. However, there..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/7/3.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="A comparison of guidance cues in desktop virtual environments"/>

    <meta name="dc.source" content="Virtual Reality 2004 7:3"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2004-05-20"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2004 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Designers of educational and entertainment desktop virtual environments (VEs) have employed a variety of cues for motivating users to perform actions or adopt particular viewpoints. However, there has been little formal study comparing user responses to such cues. This paper reports the results of a preliminary study of five cues (agents, signs, man-made landmarks, environmental landmarks, and trails) for motivating actions in virtual environments. Given a sample task of navigating to a target destination, no significant differences between the cues were observed in terms of overall success or speed. However, significant differences between the cues were found on other measures, including minimization of detours (trails) and awareness of guidance (agents, signs, trails). Frequency of desktop VE usage was also found to influence performance."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2004-05-20"/>

    <meta name="prism.volume" content="7"/>

    <meta name="prism.number" content="3"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="140"/>

    <meta name="prism.endingPage" content="147"/>

    <meta name="prism.copyright" content="2004 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-004-0125-1"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-004-0125-1"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-004-0125-1.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-004-0125-1"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="A comparison of guidance cues in desktop virtual environments"/>

    <meta name="citation_volume" content="7"/>

    <meta name="citation_issue" content="3"/>

    <meta name="citation_publication_date" content="2004/06"/>

    <meta name="citation_online_date" content="2004/05/20"/>

    <meta name="citation_firstpage" content="140"/>

    <meta name="citation_lastpage" content="147"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-004-0125-1"/>

    <meta name="DOI" content="10.1007/s10055-004-0125-1"/>

    <meta name="citation_doi" content="10.1007/s10055-004-0125-1"/>

    <meta name="description" content="Designers of educational and entertainment desktop virtual environments (VEs) have employed a variety of cues for motivating users to perform actions or ad"/>

    <meta name="dc.creator" content="Karl E. Steiner"/>

    <meta name="dc.creator" content="Lavanya Voruganti"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Bares WH, Lester JC (1999) Intelligent multi-shot visualization interfaces for dynamic 3D worlds. In: Proceedings of the 1999 international conference on intelligent user interfaces, Los Angeles, California, pp 119&#8211;126"/>

    <meta name="citation_reference" content="Bell B, Feiner S, Hollerer T (2001) View management for virtual and augmented reality. In: Proceedings of the ACM symposium on user interface software and technology, Orlando, Florida, 11&#8211;14 November 2001, pp 101&#8211;110"/>

    <meta name="citation_reference" content="Darken RP, Sibert JL (1996) Wayfinding strategies and behaviors in large virtual worlds. In: Proceedings of the conference on human factors in computing systems, pp 49&#8211;72"/>

    <meta name="citation_reference" content="Drucker SM, Zeltzer D (1995) CamDroid: a system for implementing intelligent camera control. In: Proceedings of the 1995 symposium on interactive 3D graphics, Montery, California, pp 139&#8211;144"/>

    <meta name="citation_reference" content="Galyean TA (1995) Narrative guidance of Interactivity. PhD thesis, School of Architecture and Planning, Massachusetts Institute of Technology"/>

    <meta name="citation_reference" content="Greenhalgh C, Benford S, Taylor I, Bowers J, Walker G, Wyver J (1999) Creating a live broadcast from a virtual environment. In: Proceedings of the ACM SIGGRAPH&#8217;99, pp 375&#8211;384"/>

    <meta name="citation_reference" content="He L-W, Cohen MF, Salesin DH (1996) The virtual cinematographer. In: Proceedings of the 23rd annual conference on computer graphics and interactive techniques, New Orleans, Los Angeles, August 1996, pp 217&#8211;224"/>

    <meta name="citation_reference" content="Hughes S, Lewis M (2000a) Attentive camera navigation in virtual environments. In: Proceedings of the IEEE international conference on systems, man and cybernetics"/>

    <meta name="citation_reference" content="Hughes S, Lewis M (2000b) Attentive interaction techniques for searching virtual environments. In: Proceedings of the Human Factors and Ergonomics Society&#8217;s 46th annual meeting"/>

    <meta name="citation_reference" content="Kiss S, Nijholt A (2003) Viewpoint adaptation during navigation based on stimuli from the virtual environment. In: Beitler MT (ed) Proceedings of the 8th international conference on 3D web technology, pp 19&#8211;26"/>

    <meta name="citation_reference" content="Lester J, Converse S, Kahler S, Barlow S, Stone B, Bhoga R (1997) The Persona effect: affective impact of animated pedagogical agents. In: Proceedings of CHI&#8217;97, ACM Press, New York, pp 359&#8211;366"/>

    <meta name="citation_reference" content="citation_journal_title=At the heart of it; citation_author=null Lombard; citation_volume=all; citation_publication_date=1997; citation_pages=the; citation_id=CR12"/>

    <meta name="citation_reference" content="Magerko B (2002) A proposal for an interactive drama architecture. In: Proceedings of the AAAI Spring symposium on artificial intelligence and interactive entertainment, March 2002"/>

    <meta name="citation_reference" content="Riedl M, Saretto CJ, Young MR (2003) Managing interaction between users and agents in a multi-agent storytelling environment. In: Proceedings of the 2nd international joint conference on autonomous agents and multiagent systems (in press)"/>

    <meta name="citation_reference" content="citation_journal_title=Presence&#8211;Teleop Virt; citation_title=Navigating large-scale &#8220;desktop&#8221; virtual buildings: effects of orientation aids and familiarity; citation_author=RA Ruddle, SJ Payne, DM Jones; citation_volume=7; citation_publication_date=1998; citation_pages=179-192; citation_id=CR15"/>

    <meta name="citation_reference" content="Steiner KE (2003) Adaptive narrative virtual environments. In: Computer graphics and multimedia: applications, problems, and solutions (in press)"/>

    <meta name="citation_reference" content="Steiner KE, Moher TG (2002) Encouraging task-related dialog in 2D and 3D shared narrative workspaces. In: Proceedings of the ACM conference on collaborative virtual environments (CVE &#8216;02), Bonn, Germany, pp 36&#8211;46"/>

    <meta name="citation_reference" content="Vinson N (1999) Design guidelines for landmarks to support navigation in virtual environments. In: Proceedings of CHI &#8216;99, pp 278&#8211;285"/>

    <meta name="citation_reference" content="Wernert E, Hanson A (1999) A framework for assisted exploration with collaboration. In: Proceedings of IEEE Visualization &#8216;99, pp 241&#8211;248"/>

    <meta name="citation_reference" content="Youngblut C (1998) Educational uses of virtual reality technology. Technical report IDA document D-2128, Institute for Defense Analyses, Alexandria, VA"/>

    <meta name="citation_reference" content="Zwiers J et al (2000) Design issues for navigation and assistance agents in virtual environments. In: Nijholt A, Heylen D, Jokinen K (eds) Twente workshop on language technology 17, pp 119&#8211;132"/>

    <meta name="citation_author" content="Karl E. Steiner"/>

    <meta name="citation_author_email" content="steiner@cs.unt.edu"/>

    <meta name="citation_author_institution" content="Department of Computer Science &amp; Engineering, University of North Texas, Denton, USA"/>

    <meta name="citation_author" content="Lavanya Voruganti"/>

    <meta name="citation_author_institution" content="Department of Computer Science &amp; Engineering, University of North Texas, Denton, USA"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-004-0125-1&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2004/06/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-004-0125-1"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="A comparison of guidance cues in desktop virtual environments"/>
        <meta property="og:description" content="Designers of educational and entertainment desktop virtual environments (VEs) have employed a variety of cues for motivating users to perform actions or adopt particular viewpoints. However, there has been little formal study comparing user responses to such cues. This paper reports the results of a preliminary study of five cues (agents, signs, man-made landmarks, environmental landmarks, and trails) for motivating actions in virtual environments. Given a sample task of navigating to a target destination, no significant differences between the cues were observed in terms of overall success or speed. However, significant differences between the cues were found on other measures, including minimization of detours (trails) and awareness of guidance (agents, signs, trails). Frequency of desktop VE usage was also found to influence performance."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>A comparison of guidance cues in desktop virtual environments | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-004-0125-1","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Desktop virtual environment, Virtual reality, Navigation, Guidance cues, User motivation","kwrd":["Desktop_virtual_environment","Virtual_reality","Navigation","Guidance_cues","User_motivation"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-004-0125-1","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-004-0125-1","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=125;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-004-0125-1">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            A comparison of guidance cues in desktop virtual environments
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-004-0125-1.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-004-0125-1.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2004-05-20" itemprop="datePublished">20 May 2004</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">A comparison of guidance cues in desktop virtual environments</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Karl-Steiner" data-author-popup="auth-Karl-Steiner" data-corresp-id="c1">Karl E. Steiner<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of North Texas" /><meta itemprop="address" content="grid.266869.5, 000000011008957X, Department of Computer Science &amp; Engineering, University of North Texas, P.O. Box 311366, Denton, Texas, 76203, USA" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Lavanya-Voruganti" data-author-popup="auth-Lavanya-Voruganti">Lavanya Voruganti</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of North Texas" /><meta itemprop="address" content="grid.266869.5, 000000011008957X, Department of Computer Science &amp; Engineering, University of North Texas, P.O. Box 311366, Denton, Texas, 76203, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 7</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">140</span>–<span itemprop="pageEnd">147</span>(<span data-test="article-publication-year">2004</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">128 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">4 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-004-0125-1/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Designers of educational and entertainment desktop virtual environments (VEs) have employed a variety of cues for motivating users to perform actions or adopt particular viewpoints. However, there has been little formal study comparing user responses to such cues. This paper reports the results of a preliminary study of five cues (agents, signs, man-made landmarks, environmental landmarks, and trails) for motivating actions in virtual environments. Given a sample task of navigating to a target destination, no significant differences between the cues were observed in terms of overall success or speed. However, significant differences between the cues were found on other measures, including minimization of detours (trails) and awareness of guidance (agents, signs, trails). Frequency of desktop VE usage was also found to influence performance.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Introduction</h2><div class="c-article-section__content" id="Sec2-content"><p>Desktop virtual environments (VEs) have matured from novelties used to display static 3D models, to complex tools that can immerse users in dynamic educational or entertainment experiences. Many of these complex VEs incorporate scenarios or narratives that seek to weave a set of events into a coherent experience for the user. A fundamental issue in the design of such environments is the tension between the user’s desire to freely explore and interact with the environment, and the designer’s goals of having users experience particular educational, entertaining, or emotional events. This dynamic has been described elsewhere as the balance of writer flexibility vs. user flexibility [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Magerko B (2002) A proposal for an interactive drama architecture. In: Proceedings of the AAAI Spring symposium on artificial intelligence and interactive entertainment, March 2002" href="/article/10.1007/s10055-004-0125-1#ref-CR13" id="ref-link-section-d92204e290">13</a>], and the conflict between story coherence and user control [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Riedl M, Saretto CJ, Young MR (2003) Managing interaction between users and agents in a multi-agent storytelling environment. In: Proceedings of the 2nd international joint conference on autonomous agents and multiagent systems (in press)" href="/article/10.1007/s10055-004-0125-1#ref-CR14" id="ref-link-section-d92204e293">14</a>].</p><p>Response to this challenge has spanned a range of design philosophies. At one extreme are environments that place little emphasis on presence or the illusion of user-independence. For example, Machinima (or movies created using game engines) typically tell a story by defining everything a user will see in the virtual environment, much like viewing a movie. While this approach ensures that the user will experience events at a time and in a manner of the designer’s choosing, this is achieved by sacrificing the user’s illusion of control and interactivity. Other environments, striving for a compromise, employ rigid views at some points and flexible navigation at others. For example, in many 3D games, the user is able to exercise full control over location, view and other interactions during much of the game. However, at key points in the scenario, interactivity is suspended so that the player must observe a pre-scripted cut-scene that typically advances the plot in some way. Some environments, however, strive to maximize the sense of presence and user control. In order to maintain the illusion that the user is present in an internally consistent virtual world, interactivity cannot be suspended and instructions must be presented in a contextually appropriate manner. For example, in a simulated police training scenario, the instructions that the user move from his squad car to the convenience store might come from an agent representing his partner, rather than from on-screen text or from a disembodied narrator. We have chosen to explore the educational and entertainment opportunities in VEs of this type.</p><p>Desktop VE simulations and games continue to strive for higher levels of presence, not just in terms of 3D graphics, but also in terms of the scenarios and ranges of interactions supported. A frequently used casual definition of<i> presence</i> is the sense of “being in” a virtual environment. Perhaps more relevant for us is the definition given by Lombard and Ditton [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Lombard M, Ditton T (1997) At the heart of it all: the concept of presence. J Comput Mediated Commun 3(2)" href="/article/10.1007/s10055-004-0125-1#ref-CR12" id="ref-link-section-d92204e304">12</a>]—presence is “the perceptual illusion of non-mediation.” Benefits of VE presence and interactivity include enhanced motivation, support for visual learning styles, and facilitation of constructivist learning [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Youngblut C (1998) Educational uses of virtual reality technology. Technical report IDA document D-2128, Institute for Defense Analyses, Alexandria, VA" href="/article/10.1007/s10055-004-0125-1#ref-CR20" id="ref-link-section-d92204e307">20</a>]. However, the sense of presence is often strained or broken when users need direction or assistance within a VE. Anecdotal reports indicate challenges involved in providing directions in VEs, such as users losing context when requesting help, or failing to assume the views necessary to watch key events. Several research efforts have explored solutions, such as view management techniques, that work either by limiting interactivity (e.g., automatically moving the user to a location or locking the view in a particular direction), or by introducing out-of-context elements (e.g., introducing 3D labels for important objects, or highlighting significant locations using spotlights). Many of these techniques have demonstrated value in improving recognition of important objects and in improving navigation and wayfinding. However, by their nature, they may be at odds with enhancing the sense of presence.</p><p>We are interested in guidelines or frameworks that might assist designers in selecting or employing cues that direct user attention whilst maintaining high levels of presence and “the perceptual illusion of non-mediation.” However, little work has been done that specifically addresses this area. As a result, we decided to conduct a preliminary investigation comparing the performance of some of the cues that meet our criteria and are common in educational and entertainment desktop VEs. In particular, we were motivated by the following questions: </p><ul class="u-list-style-dash">
                  <li>
                    <p>What cues are common in desktop VE education and entertainment applications?</p>
                  </li>
                  <li>
                    <p>Do users recognize and respond to these cues?</p>
                  </li>
                  <li>
                    <p>Do users realize they are being “guided” when these cues are present?</p>
                  </li>
                  <li>
                    <p>Does experience with other desktop VEs influence user response to these cues?</p>
                  </li>
                </ul>
</div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Background</h2><div class="c-article-section__content" id="Sec3-content"><p>While the issue of managing user attention using cues of this nature has not been specifically addressed in great detail, there has been considerable research done in related areas, such as techniques for supporting wayfinding and navigation, the use of agents as guides, and techniques for controlling cameras and views.</p><h3 class="c-article__sub-heading" id="Sec4">Prior work</h3><p>People experience difficulties navigating through VEs for a variety of reasons. These can include the difficulties common to navigation in real-world environments, as well as some problems unique to VEs, such as lack of landmarks, reduced level of details, lack of exposure (users often visit a given VE infrequently), and the fact that virtual environments are frequently dynamic [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Ruddle RA, Payne SJ, Jones DM (1998) Navigating large-scale “desktop” virtual buildings: effects of orientation aids and familiarity. Presence–Teleop Virt 7:179–192" href="/article/10.1007/s10055-004-0125-1#ref-CR15" id="ref-link-section-d92204e350">15</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Darken RP, Sibert JL (1996) Wayfinding strategies and behaviors in large virtual worlds. In: Proceedings of the conference on human factors in computing systems, pp 49–72" href="/article/10.1007/s10055-004-0125-1#ref-CR3" id="ref-link-section-d92204e353">3</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Zwiers J et al (2000) Design issues for navigation and assistance agents in virtual environments. In: Nijholt A, Heylen D, Jokinen K (eds) Twente workshop on language technology 17, pp 119–132" href="/article/10.1007/s10055-004-0125-1#ref-CR21" id="ref-link-section-d92204e356">21</a>]. Methods for supporting navigation in VEs have been proposed by a number of authors. Techniques include a set of guidelines for including landmarks [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Vinson N (1999) Design guidelines for landmarks to support navigation in virtual environments. In: Proceedings of CHI ‘99, pp 278–285" href="/article/10.1007/s10055-004-0125-1#ref-CR18" id="ref-link-section-d92204e359">18</a>] as well as design techniques for organizing the layout of VEs [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Darken RP, Sibert JL (1996) Wayfinding strategies and behaviors in large virtual worlds. In: Proceedings of the conference on human factors in computing systems, pp 49–72" href="/article/10.1007/s10055-004-0125-1#ref-CR3" id="ref-link-section-d92204e362">3</a>]. While these works provide a great deal of insight into how to assist users in the tasks of navigation and wayfinding, they do not directly address the question of how to motivate a user to navigate to one location rather than another.</p><p>Agents provide an alternative method of supporting navigation (and other user interactions) in VEs. For example, agents can give directions or transport users to locations [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Darken RP, Sibert JL (1996) Wayfinding strategies and behaviors in large virtual worlds. In: Proceedings of the conference on human factors in computing systems, pp 49–72" href="/article/10.1007/s10055-004-0125-1#ref-CR3" id="ref-link-section-d92204e368">3</a>]. Agents may also orient the user, point to interesting objects, and automatically direct their view [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Wernert E, Hanson A (1999) A framework for assisted exploration with collaboration. In: Proceedings of IEEE Visualization ‘99, pp 241–248" href="/article/10.1007/s10055-004-0125-1#ref-CR19" id="ref-link-section-d92204e371">19</a>]. Agents may provide services beyond navigation. For example, they may answer questions, support learning, and even enhance user motivation [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Darken RP, Sibert JL (1996) Wayfinding strategies and behaviors in large virtual worlds. In: Proceedings of the conference on human factors in computing systems, pp 49–72" href="/article/10.1007/s10055-004-0125-1#ref-CR3" id="ref-link-section-d92204e374">3</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Lester J, Converse S, Kahler S, Barlow S, Stone B, Bhoga R (1997) The Persona effect: affective impact of animated pedagogical agents. In: Proceedings of CHI’97, ACM Press, New York, pp 359–366" href="/article/10.1007/s10055-004-0125-1#ref-CR11" id="ref-link-section-d92204e377">11</a>].</p><p>Camera and view management techniques have fallen into two groups: those that completely control the user’s view, and those that guide or partially control the view. Those that completely control the views often support a “cinematic” experience, similar to viewing a movie. Examples of such work include the ConstraintCam [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Bares WH, Lester JC (1999) Intelligent multi-shot visualization interfaces for dynamic 3D worlds. In: Proceedings of the 1999 international conference on intelligent user interfaces, Los Angeles, California, pp 119–126" href="/article/10.1007/s10055-004-0125-1#ref-CR1" id="ref-link-section-d92204e383">1</a>] that dynamically generates optimal camera angles to support explicitly stated user viewing or task goals, as well as CamDroid [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Drucker SM, Zeltzer D (1995) CamDroid: a system for implementing intelligent camera control. In: Proceedings of the 1995 symposium on interactive 3D graphics, Montery, California, pp 139–144" href="/article/10.1007/s10055-004-0125-1#ref-CR4" id="ref-link-section-d92204e386">4</a>] and the Virtual Cinematographer [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="He L-W, Cohen MF, Salesin DH (1996) The virtual cinematographer. In: Proceedings of the 23rd annual conference on computer graphics and interactive techniques, New Orleans, Los Angeles, August 1996, pp 217–224" href="/article/10.1007/s10055-004-0125-1#ref-CR7" id="ref-link-section-d92204e389">7</a>]. The systems that partially guide views typically allow users to change locations and views freely until certain conditions are met, such as proximity to an object of interest, at which point the view manager takes over. In some of these systems, the view manager can be over-ridden, allowing the user to maintain control of the view. In others, the view manager has the final word on what the user must view. The elements that influence what is to be viewed may include features of the environment [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Kiss S, Nijholt A (2003) Viewpoint adaptation during navigation based on stimuli from the virtual environment. In: Beitler MT (ed) Proceedings of the 8th international conference on 3D web technology, pp 19–26" href="/article/10.1007/s10055-004-0125-1#ref-CR10" id="ref-link-section-d92204e392">10</a>], the location and orientation of a “guide” agent [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Wernert E, Hanson A (1999) A framework for assisted exploration with collaboration. In: Proceedings of IEEE Visualization ‘99, pp 241–248" href="/article/10.1007/s10055-004-0125-1#ref-CR19" id="ref-link-section-d92204e395">19</a>], predefined objects within the environment [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Hughes S, Lewis M (2000a) Attentive camera navigation in virtual environments. In: Proceedings of the IEEE international conference on systems, man and cybernetics" href="/article/10.1007/s10055-004-0125-1#ref-CR8" id="ref-link-section-d92204e399">8</a>], narrative goals [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Galyean TA (1995) Narrative guidance of Interactivity. PhD thesis, School of Architecture and Planning, Massachusetts Institute of Technology" href="/article/10.1007/s10055-004-0125-1#ref-CR5" id="ref-link-section-d92204e402">5</a>], or task goals [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Bares WH, Lester JC (1999) Intelligent multi-shot visualization interfaces for dynamic 3D worlds. In: Proceedings of the 1999 international conference on intelligent user interfaces, Los Angeles, California, pp 119–126" href="/article/10.1007/s10055-004-0125-1#ref-CR1" id="ref-link-section-d92204e405">1</a>].</p><p>A variation on these are view management techniques that do not limit interactivity but augment the environment in other ways. For example, labels can be added to items in the VE to better identify them [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Bell B, Feiner S, Hollerer T (2001) View management for virtual and augmented reality. In: Proceedings of the ACM symposium on user interface software and technology, Orlando, Florida, 11–14 November 2001, pp 101–110" href="/article/10.1007/s10055-004-0125-1#ref-CR2" id="ref-link-section-d92204e411">2</a>], or a “flashlight” effect can be used to indicate objects of interest [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Hughes S, Lewis M (2000b) Attentive interaction techniques for searching virtual environments. In: Proceedings of the Human Factors and Ergonomics Society’s 46th annual meeting" href="/article/10.1007/s10055-004-0125-1#ref-CR9" id="ref-link-section-d92204e414">9</a>]. While these techniques are closer in spirit to our proposed work, they rely on solutions that would not occur in a similar real-world setting and reinforce the notion of an external mediator. Our goal is to explore some of the same questions of how to draw user attention to particular locations, but to do so using less “visible” cues.</p><h3 class="c-article__sub-heading" id="Sec5">System architecture</h3><p>This work is an extension of our development of a platform for managing and presenting interactive narratives in a VE [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Steiner KE (2003) Adaptive narrative virtual environments. In: Computer graphics and multimedia: applications, problems, and solutions (in press)" href="/article/10.1007/s10055-004-0125-1#ref-CR16" id="ref-link-section-d92204e425">16</a>]. This platform currently includes a 3D engine, VE world state management, story state management, and event adaptation (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0125-1#Fig1">1</a>). Work is also underway on dynamic event generation and user modeling components. An earlier version of the platform was used to support our exploration of children’s collaboration in narrative environments [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Steiner KE, Moher TG (2002) Encouraging task-related dialog in 2D and 3D shared narrative workspaces. In: Proceedings of the ACM conference on collaborative virtual environments (CVE ‘02), Bonn, Germany, pp 36–46" href="/article/10.1007/s10055-004-0125-1#ref-CR17" id="ref-link-section-d92204e431">17</a>]. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-004-0125-1/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0125-1/MediaObjects/s10055-004-0125-1flb1.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0125-1/MediaObjects/s10055-004-0125-1flb1.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p> System architecture</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-004-0125-1/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>An important component of this system is a facility for managing and presenting scenario (or narrative) events. An event describes character–character or character–object interactions, and includes information regarding the primitive actions that make up the event, as well as meta-data for further categorizing the event and its presentation. Also associated with each event are a set of conditions (triggers) that determine when the event can be presented. These conditions include time, location, other elements of world or story state, or combinations of the above. Once an event has been activated, the adaptation manager selects an appropriate way in which to present the event.</p><p>We have also developed data structures and sensors that allow us to track key information regarding the conditions in the 3D environment (world state). This includes immediate information such as object and user location, as well as relationships between objects (e.g., Is the user near the Smith house? Can the user see the tower?). Additional information about the user is managed as well, including a history of activities.</p><p>As our interest in VE focuses more on interaction and less on 3D rendering, we decided to take advantage of a commercial 3D game engine. We use the A6 3D engine from Conitec. The engine and related development tools support 3D world-building and display, allowing us to devote the majority of our attention to developing support for narrative events, interactions, and presentation.</p><p>One of the central questions behind our recent work has been consideration of how to make scenarios and narratives presented in VEs more comprehensible. One technique is to embed intelligence regarding event presentation into an active “adaptation manager.” This, in effect, aims to bring the events to the user. The alternative is to bring the user to the events. This current work was motivated by our desire to better understand this second alternative.</p><h3 class="c-article__sub-heading" id="Sec6">Our approach</h3><p>To begin our study, we assembled a representative collection of techniques for cueing users of desktop VEs to take an action. As our sample task, we chose motivating movement to a particular building within a VE. For the purposes of this study, we were looking specifically for techniques that did not limit interactivity. This eliminated any technique that would take control of navigation or views away from the user. We also required that the techniques did not add new elements to the VE that appeared out-of-context. So, cues such as hard-copy instructions, text instruction overlays, map or pointer overlays, and voice-over instructions were eliminated. Finally, we desired that the cues should be contextually appropriate. We did not want to introduce elements that were not consistent with the appearance or tone of the world. Our survey of a number of commercial and research-oriented VEs produced a set of commonly employed cues (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-004-0125-1#Tab1">1</a>). </p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1  Sample cues</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-004-0125-1/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
</div></div></section><section aria-labelledby="Sec7"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7">Study</h2><div class="c-article-section__content" id="Sec7-content"><p>We wanted to compare subject performance when presented with these various cues, as well as the performance of subjects with differing exposure amounts to desktop VEs. We also wanted to examine which cues were the most transparent to subjects, that is, which cues motivated subjects without being noticed.</p><h3 class="c-article__sub-heading" id="Sec8">Hypotheses</h3><p>It was our belief that more explicit cues (i.e., written signs and speaking agents) would lead to better performance. We expected that the verbal and written cues would be likely to lead to faster travel times to target buildings, and fewer interruptions in the travel. Given that the cues we chose were similar to those employed in other VEs, we expected that past experience with VEs would have an impact on performance. And finally, we expected that while the landmarks may be less effective in prompting fast, uninterrupted movement, they would be less “visible” to our subjects.</p><h3 class="c-article__sub-heading" id="Sec9">Subjects</h3><p>Thirty-one college students volunteered to participate in the study. Most were computer science students, although backgrounds and experience with virtual environments and computer games varied. Theirs ages ranged from 18 to 35. While participants were drawn from a variety of sources with equal attention paid to both genders, the vast number of volunteers (27 out of 31) were male.</p><h3 class="c-article__sub-heading" id="Sec10">Materials</h3><p>In order to explore our hypotheses, six virtual environments were created as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0125-1#Fig2">2</a> and Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-004-0125-1#Tab2">2</a>. The environments were kept simple, and all six included similar (but not identical) objects and layouts. The environments included a number of simple buildings (15) representing locations to be explored, and clusters of trees positioned to obscure the direct view of the buildings. The buildings were similar, providing no unique visible attributes when viewed from a distance. Each building had a small placard indicating the name of the residents of this building (Smith, Jones, Potter, etc.) that could be viewed as the subject came closer. Buildings were clustered in five groups of three. Beyond these basics, the environments differed in the cues they provided to direct subjects to visit a particular location. All of the environments were laid out according to similar plans, and distances from the subjects’ starting positions to the target locations were identical in all cases. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-004-0125-1/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0125-1/MediaObjects/s10055-004-0125-1fhb2.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0125-1/MediaObjects/s10055-004-0125-1fhb2.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p> Test environments. See Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-004-0125-1#Tab2">2</a> for explanations</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-004-0125-1/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2  Test environments</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-004-0125-1/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>The subject was presented with a first-person desktop 3D interface. The simulated first-person view occupied the entire screen. The subject was given controls for movement (cursor keys) and view (mouse). The environment was tooled to log all subject interactions, keeping a record of all subject movements, as well as recording and time-stamping other events (e.g., approach to buildings).</p><p>In addition to the testing environments, we also developed a training environment. This provided controls that were identical to the other environments, although the landscape was simpler, containing only a few trees, a single building, and no cues.</p><h3 class="c-article__sub-heading" id="Sec11">Method</h3><p>Test subjects received introductory information regarding their participation in a study of navigation in desktop 3D environments and completed a short questionnaire regarding their background. A key question asked how often the subject experienced desktop VEs, including 3D computer games. Before beginning the study, subjects were allowed to spend as much time as they wanted familiarizing themselves with the controls in the test environment.</p><p>Each subject then visited each of the six virtual environments. They were instructed to “explore” the environments but given no explicit instructions to either look for, or comply with, the cues that were present in each environment. This task differs from the search tasks commonly studied in navigation and wayfinding experiments in that our subjects were not explicitly given target locations. Subjects were placed in each environment at a location where the cue was immediately visible. They were given two minutes to explore the environment and visit whichever locations they chose, and in any order. The order in which the environments and cues were presented to the subjects was varied but evenly distributed, so similar numbers of subjects started with each environment and cue. After completing each environment, subjects answered a few questions regarding their impressions of the environment and the visibility of the cues. Analysis of variance (ANOVA) analysis was conducted using cues and frequency of VE use as independent variables.</p><h3 class="c-article__sub-heading" id="Sec12">Results</h3><p>The order in which subjects visited the environments was randomized and distributed so that similar numbers of subjects started with each environment. An analysis of our test measures found that there were no significant differences based on the order in which subjects experienced the environments.</p><p>When looking only at whether or not a subject would eventually visit a target location, there was no clear distinction between the cues (as shown in the top-left chart in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0125-1#Fig3">3</a>, “Mean Target Visits by Cue”). All of the results clustered around 75%, ranging from a high of 81% for the tower condition to a low of 70% for the fire. There were no statistically significant differences between the conditions. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-004-0125-1/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0125-1/MediaObjects/s10055-004-0125-1flb3.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0125-1/MediaObjects/s10055-004-0125-1flb3.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p> Results</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-004-0125-1/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>There were larger differences when examining how quickly subjects visited the target location (note that, due to the VE software used, time is measured in units of 1/16th of a second). Subjects required the shortest times to reach the target when presented with the tower and the sign (684 and 727), the agent and the fire took the longest (948 and 915), and the trail was in the middle (793). While the differences in this measure were more pronounced, again, no statistically significant differences were reached (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0125-1#Fig3">3</a>, top-right chart, “Mean Time to Visit Target by Cue”).</p><p>Significant differences (<i>p</i>&lt;0.01) were achieved when measuring which cue was most likely to lead to visiting a target location before any other locations. Although, on the average, subjects visited the tower target location more rapidly, the trail target location had a higher level of first visits. For example, in the trail condition, approximately 90% of the subjects went directly to the trail target location without visiting other locations first. Less than half the subjects in the agent and the fire conditions visited their targets first (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0125-1#Fig3">3</a>, left-middle chart, “Mean Target Initial Visits by Cue”).</p><p>Significant differences (<i>p</i>&lt;0.01) were again achieved when examining the level of guidance that subjects reported under the various conditions (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0125-1#Fig3">3</a>, middle-right chart, “Mean Guidance by Cue”). Subjects rated the level of visibility of each condition on a 5-point scale, with 5 indicating a high level of awareness of guidance, and 1 indicating no awareness of guidance. The agent, sign, and trail cues were viewed as more visible than the fire or the tower cues.</p><p>The frequency of desktop VE use had a direct and significant effect on the likelihood that an individual subject would visit targets (<i>p</i>&lt;0.01). On average, subjects who experienced desktop VE daily visited the target locations over 90% of the time, while those who experience monthly were at 63%, and less frequent users were less than 50% (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0125-1#Fig3">3</a>,bottom-left chart, “Mean Target Visits by Frequency”).</p><p>Frequent desktop VE users differed from less frequent users in another significant manner. While all groups scored similarly when asked whether or not they had set goal locations to visit in the different environments, and all groups scored similarly in terms of actually visiting the designated target locations, the frequent desktop VE users were more confident that they had successfully reached their goals (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0125-1#Fig3">3</a>, bottom-right chart, “Mean Confidence by Frequency”). While the actual numeric difference here appears low, the results were, nevertheless, statistically significant (<i>p</i>&lt;0.05).</p><p>In an environment where all of the cues were employed, there was a significant difference in the location subjects chose to visit first (<i>p</i>&lt;0.01). The largest number chose to follow the trail. Substantially fewer visited the fire or the tower target locations (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0125-1#Fig4">4</a>). </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-004-0125-1/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0125-1/MediaObjects/s10055-004-0125-1flb4.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0125-1/MediaObjects/s10055-004-0125-1flb4.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p> Mix initial visits</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-004-0125-1/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
</div></div></section><section aria-labelledby="Sec13"><div class="c-article-section" id="Sec13-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec13">Discussion</h2><div class="c-article-section__content" id="Sec13-content"><p>This was a preliminary study of limited VEs. In the interests of efficiency, we created six relatively small environments, each with an obvious target location. Few subjects experienced difficulties in eventually locating target locations (even when they were not confident they had done so). The cues we employed appeared equally likely to motivate subjects to search for the target locations, and there were no differences when evaluating subjects’ success in reaching their locations.</p><p>Given our relatively small environment with obvious target locations, the differences that were observed in terms of “time to target” and “visiting the target first” may be attributed, at least in part, to the design details related to the cues. For example, we had expected that the more verbally explicit cues—the sign and the agent that refer to locations by name—would be the most motivational, leading to shorter times to target and higher first visit levels. However, the results were mixed. While distances between all of the locations were similar, subjects reached the tower location faster than they reached the sign location. Subjects mentioned that the tower provided an obvious landmark to which they could directly navigate, whereas both the agent and the sign, whilst giving directional cues, were not as precise. Subjects also mentioned that having the dynamic agent point towards the target location was less useful than having a static sign point towards the target. Many subjects mentioned that the trail provided an obvious cue to a specific location, and, not surprisingly, this led to high levels of first visits for the trail. The slower times recorded for the trail may be due, in part, to the somewhat meandering path we plotted for it (it was not a straight line to the target), as well as the novelty of following a path of colored stones. Given the similar “landmark” statuses of the tower and the fire, we expected similar results for both; however, the tower led to much shorter measures of time to target and much higher levels of first visits. This may have been due to the implementation of our fire. While the side effects of the fire (smoke, flames, sound of burning) may have been realistic and occupied dimensions similar to those of the tower, they may not have afforded the necessary visual and audible cues. Some subjects explained that the smoke was difficult to see against the sky, and that the smoke did not rise high enough.</p><p>Despite these issues, a number of interesting results emerged. Although all of the cues appeared equally likely to lead the subject to their target eventually, not all cues were equally likely to be recognized as playing a role in guidance. The trail, agent, and sign had significantly higher guidance ratings than the fire or tower. That is, subjects seemed to feel that the fire and the tower, while still being worthy of exploration, were less likely to be deliberate cues. This result may suggest that designers seeking to subtly motivate users may want to focus more on architectural and environmental landmarks, and that the presence of agents, signs, and paths are more likely to be seen as explicit attempts to motivate users to particular actions or locations. Another intriguing result concerns differences related to the frequency of desktop VE use. The frequency of use was highly correlated with the probability of reaching the target locations. Frequent users were also more likely to recognize the achievement of their goals. These results offer some preliminary quantitative measures of the ways in which experienced desktop VE users differ from less experienced users.</p><p>We are interested in pursuing follow-up studies that incorporate larger and more complex environments, less obvious locations or interactions, and more robust cues (e.g., mobile and highly animated agents). We also plan to conduct follow-up studies that compare presence-supporting cues, similar to those described in this paper, to other techniques, such as hard-copy instructions, on-screen instructions, and non-contextual instructions.</p></div></div></section><section aria-labelledby="Sec14"><div class="c-article-section" id="Sec14-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec14">Conclusion</h2><div class="c-article-section__content" id="Sec14-content"><p>This paper reports the results of a preliminary study of motivational cues that support presence and “the perceptual illusion of non-mediation” in desktop VEs. We believe that these results, while preliminary, have some interesting implications for VE designers and suggest a number of potential areas for follow-up study. While the results regarding the performance differences between the cues appear inconclusive, we uncovered intriguing differences in the user perception of the visibility of these cues. Differences were also noted based on the frequency of VE usage. These preliminary findings illustrate some of the potential of cues that enhance presence, and suggest a number of areas for future study.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bares WH, Lester JC (1999) Intelligent multi-shot visualization interfaces for dynamic 3D worlds. In: Proceedi" /><span class="c-article-references__counter">1.</span><p class="c-article-references__text" id="ref-CR1">Bares WH, Lester JC (1999) Intelligent multi-shot visualization interfaces for dynamic 3D worlds. In: Proceedings of the 1999 international conference on intelligent user interfaces, Los Angeles, California, pp 119–126</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bell B, Feiner S, Hollerer T (2001) View management for virtual and augmented reality. In: Proceedings of the " /><span class="c-article-references__counter">2.</span><p class="c-article-references__text" id="ref-CR2">Bell B, Feiner S, Hollerer T (2001) View management for virtual and augmented reality. In: Proceedings of the ACM symposium on user interface software and technology, Orlando, Florida, 11–14 November 2001, pp 101–110</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Darken RP, Sibert JL (1996) Wayfinding strategies and behaviors in large virtual worlds. In: Proceedings of th" /><span class="c-article-references__counter">3.</span><p class="c-article-references__text" id="ref-CR3">Darken RP, Sibert JL (1996) Wayfinding strategies and behaviors in large virtual worlds. In: Proceedings of the conference on human factors in computing systems, pp 49–72</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Drucker SM, Zeltzer D (1995) CamDroid: a system for implementing intelligent camera control. In: Proceedings o" /><span class="c-article-references__counter">4.</span><p class="c-article-references__text" id="ref-CR4">Drucker SM, Zeltzer D (1995) CamDroid: a system for implementing intelligent camera control. In: Proceedings of the 1995 symposium on interactive 3D graphics, Montery, California, pp 139–144</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Galyean TA (1995) Narrative guidance of Interactivity. PhD thesis, School of Architecture and Planning, Massac" /><span class="c-article-references__counter">5.</span><p class="c-article-references__text" id="ref-CR5">Galyean TA (1995) Narrative guidance of Interactivity. PhD thesis, School of Architecture and Planning, Massachusetts Institute of Technology</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Greenhalgh C, Benford S, Taylor I, Bowers J, Walker G, Wyver J (1999) Creating a live broadcast from a virtual" /><span class="c-article-references__counter">6.</span><p class="c-article-references__text" id="ref-CR6">Greenhalgh C, Benford S, Taylor I, Bowers J, Walker G, Wyver J (1999) Creating a live broadcast from a virtual environment. In: Proceedings of the ACM SIGGRAPH’99, pp 375–384</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="He L-W, Cohen MF, Salesin DH (1996) The virtual cinematographer. In: Proceedings of the 23rd annual conference" /><span class="c-article-references__counter">7.</span><p class="c-article-references__text" id="ref-CR7">He L-W, Cohen MF, Salesin DH (1996) The virtual cinematographer. In: Proceedings of the 23rd annual conference on computer graphics and interactive techniques, New Orleans, Los Angeles, August 1996, pp 217–224</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hughes S, Lewis M (2000a) Attentive camera navigation in virtual environments. In: Proceedings of the IEEE int" /><span class="c-article-references__counter">8.</span><p class="c-article-references__text" id="ref-CR8">Hughes S, Lewis M (2000a) Attentive camera navigation in virtual environments. In: Proceedings of the IEEE international conference on systems, man and cybernetics</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hughes S, Lewis M (2000b) Attentive interaction techniques for searching virtual environments. In: Proceedings" /><span class="c-article-references__counter">9.</span><p class="c-article-references__text" id="ref-CR9">Hughes S, Lewis M (2000b) Attentive interaction techniques for searching virtual environments. In: Proceedings of the Human Factors and Ergonomics Society’s 46th annual meeting</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kiss S, Nijholt A (2003) Viewpoint adaptation during navigation based on stimuli from the virtual environment." /><span class="c-article-references__counter">10.</span><p class="c-article-references__text" id="ref-CR10">Kiss S, Nijholt A (2003) Viewpoint adaptation during navigation based on stimuli from the virtual environment. In: Beitler MT (ed) Proceedings of the 8th international conference on 3D web technology, pp 19–26</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lester J, Converse S, Kahler S, Barlow S, Stone B, Bhoga R (1997) The Persona effect: affective impact of anim" /><span class="c-article-references__counter">11.</span><p class="c-article-references__text" id="ref-CR11">Lester J, Converse S, Kahler S, Barlow S, Stone B, Bhoga R (1997) The Persona effect: affective impact of animated pedagogical agents. In: Proceedings of CHI’97, ACM Press, New York, pp 359–366</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content=". Lombard, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Lombard M, Ditton T (1997) At the heart of it all: the concept of presence. J Comput Mediated Commun 3(2)" /><span class="c-article-references__counter">12.</span><p class="c-article-references__text" id="ref-CR12">Lombard M, Ditton T (1997) At the heart of it all: the concept of presence. J Comput Mediated Commun 3(2)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=At%20the%20heart%20of%20it&amp;volume=all&amp;publication_year=1997&amp;author=Lombard%2C">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Magerko B (2002) A proposal for an interactive drama architecture. In: Proceedings of the AAAI Spring symposiu" /><span class="c-article-references__counter">13.</span><p class="c-article-references__text" id="ref-CR13">Magerko B (2002) A proposal for an interactive drama architecture. In: Proceedings of the AAAI Spring symposium on artificial intelligence and interactive entertainment, March 2002</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Riedl M, Saretto CJ, Young MR (2003) Managing interaction between users and agents in a multi-agent storytelli" /><span class="c-article-references__counter">14.</span><p class="c-article-references__text" id="ref-CR14">Riedl M, Saretto CJ, Young MR (2003) Managing interaction between users and agents in a multi-agent storytelling environment. In: Proceedings of the 2nd international joint conference on autonomous agents and multiagent systems (in press)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Ruddle, SJ. Payne, DM. Jones, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Ruddle RA, Payne SJ, Jones DM (1998) Navigating large-scale “desktop” virtual buildings: effects of orientatio" /><span class="c-article-references__counter">15.</span><p class="c-article-references__text" id="ref-CR15">Ruddle RA, Payne SJ, Jones DM (1998) Navigating large-scale “desktop” virtual buildings: effects of orientation aids and familiarity. Presence–Teleop Virt 7:179–192</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Navigating%20large-scale%20%E2%80%9Cdesktop%E2%80%9D%20virtual%20buildings%3A%20effects%20of%20orientation%20aids%20and%20familiarity&amp;journal=Presence%E2%80%93Teleop%20Virt&amp;volume=7&amp;pages=179-192&amp;publication_year=1998&amp;author=Ruddle%2CRA&amp;author=Payne%2CSJ&amp;author=Jones%2CDM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Steiner KE (2003) Adaptive narrative virtual environments. In: Computer graphics and multimedia: applications," /><span class="c-article-references__counter">16.</span><p class="c-article-references__text" id="ref-CR16">Steiner KE (2003) Adaptive narrative virtual environments. In: Computer graphics and multimedia: applications, problems, and solutions (in press)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Steiner KE, Moher TG (2002) Encouraging task-related dialog in 2D and 3D shared narrative workspaces. In: Proc" /><span class="c-article-references__counter">17.</span><p class="c-article-references__text" id="ref-CR17">Steiner KE, Moher TG (2002) Encouraging task-related dialog in 2D and 3D shared narrative workspaces. In: Proceedings of the ACM conference on collaborative virtual environments (CVE ‘02), Bonn, Germany, pp 36–46</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Vinson N (1999) Design guidelines for landmarks to support navigation in virtual environments. In: Proceedings" /><span class="c-article-references__counter">18.</span><p class="c-article-references__text" id="ref-CR18">Vinson N (1999) Design guidelines for landmarks to support navigation in virtual environments. In: Proceedings of CHI ‘99, pp 278–285</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Wernert E, Hanson A (1999) A framework for assisted exploration with collaboration. In: Proceedings of IEEE Vi" /><span class="c-article-references__counter">19.</span><p class="c-article-references__text" id="ref-CR19">Wernert E, Hanson A (1999) A framework for assisted exploration with collaboration. In: Proceedings of IEEE Visualization ‘99, pp 241–248</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Youngblut C (1998) Educational uses of virtual reality technology. Technical report IDA document D-2128, Insti" /><span class="c-article-references__counter">20.</span><p class="c-article-references__text" id="ref-CR20">Youngblut C (1998) Educational uses of virtual reality technology. Technical report IDA document D-2128, Institute for Defense Analyses, Alexandria, VA</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zwiers J et al (2000) Design issues for navigation and assistance agents in virtual environments. In: Nijholt " /><span class="c-article-references__counter">21.</span><p class="c-article-references__text" id="ref-CR21">Zwiers J et al (2000) Design issues for navigation and assistance agents in virtual environments. In: Nijholt A, Heylen D, Jokinen K (eds) Twente workshop on language technology 17, pp 119–132</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-004-0125-1-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Department of Computer Science &amp; Engineering, University of North Texas, P.O. Box 311366, Denton, Texas, 76203, USA</p><p class="c-article-author-affiliation__authors-list">Karl E. Steiner &amp; Lavanya Voruganti</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Karl-Steiner"><span class="c-article-authors-search__title u-h3 js-search-name">Karl E. Steiner</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Karl+E.+Steiner&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Karl+E.+Steiner" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Karl+E.+Steiner%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Lavanya-Voruganti"><span class="c-article-authors-search__title u-h3 js-search-name">Lavanya Voruganti</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Lavanya+Voruganti&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Lavanya+Voruganti" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Lavanya+Voruganti%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-004-0125-1/email/correspondent/c1/new">Karl E. Steiner</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=A%20comparison%20of%20guidance%20cues%20in%20desktop%20virtual%20environments&amp;author=Karl%20E.%20Steiner%20et%20al&amp;contentID=10.1007%2Fs10055-004-0125-1&amp;publication=1359-4338&amp;publicationDate=2004-05-20&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">E. Steiner, K., Voruganti, L. A comparison of guidance cues in desktop virtual environments.
                    <i>Virtual Reality</i> <b>7, </b>140–147 (2004). https://doi.org/10.1007/s10055-004-0125-1</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-004-0125-1.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2003-12-12">12 December 2003</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2004-03-29">29 March 2004</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2004-05-20">20 May 2004</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2004-06">June 2004</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-004-0125-1" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-004-0125-1</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Desktop virtual environment</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Virtual reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Navigation</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Guidance cues</span></li><li class="c-article-subject-list__subject"><span itemprop="about">User motivation</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-004-0125-1.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=125;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

