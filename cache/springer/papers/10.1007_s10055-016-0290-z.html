<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="An evaluation of asymmetric interfaces for bimanual virtual assembly w"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Immersive computing technology provides a human&#8211;computer interface to support natural human interaction with digital data and models. One application for this technology is product assembly..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/20/4.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="An evaluation of asymmetric interfaces for bimanual virtual assembly with haptics"/>

    <meta name="dc.source" content="Virtual Reality 2016 20:4"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2016-07-07"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2016 Springer-Verlag London"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Immersive computing technology provides a human&#8211;computer interface to support natural human interaction with digital data and models. One application for this technology is product assembly methods planning and validation. This paper presents the results of a user study which explores the effectiveness of various bimanual interaction device configurations for virtual assembly tasks. Participants completed two assembly tasks with two device configurations in five randomized bimanual treatment conditions (within subjects). A Phantom Omni&#174; with and without haptics enabled and a 5DT Data Glove were used. Participant performance, as measured by time to assemble, was the evaluation metric. The results revealed that there was no significant difference in performance between the five treatment conditions. However, half of the participants chose the 5DT Data Glove and the haptic-enabled Phantom Omni&#174;&#160;as their preferred device configuration. In addition, qualitative comments support both the preference of haptics during the assembly process and comments confirming Guiard&#8217;s kinematic chain model."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2016-07-07"/>

    <meta name="prism.volume" content="20"/>

    <meta name="prism.number" content="4"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="193"/>

    <meta name="prism.endingPage" content="201"/>

    <meta name="prism.copyright" content="2016 Springer-Verlag London"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-016-0290-z"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-016-0290-z"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-016-0290-z.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-016-0290-z"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="An evaluation of asymmetric interfaces for bimanual virtual assembly with haptics"/>

    <meta name="citation_volume" content="20"/>

    <meta name="citation_issue" content="4"/>

    <meta name="citation_publication_date" content="2016/11"/>

    <meta name="citation_online_date" content="2016/07/07"/>

    <meta name="citation_firstpage" content="193"/>

    <meta name="citation_lastpage" content="201"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-016-0290-z"/>

    <meta name="DOI" content="10.1007/s10055-016-0290-z"/>

    <meta name="citation_doi" content="10.1007/s10055-016-0290-z"/>

    <meta name="description" content="Immersive computing technology provides a human&#8211;computer interface to support natural human interaction with digital data and models. One application"/>

    <meta name="dc.creator" content="Patrick Carlson"/>

    <meta name="dc.creator" content="Judy M. Vance"/>

    <meta name="dc.creator" content="Meisha Berg"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Balakrishnan R, Hinckley K (2000) Symmetric bimanual interaction. In: CHI &#8217;00: proceedings of the SIGCHI conference on human factors in computing systems, ACM, New York, NY, USA, pp 33&#8211;40. doi:
                    10.1145/332040.332404
                    
                  
                        "/>

    <meta name="citation_reference" content="Balakrishnan R, Kurtenbach G (1999) Exploring bimanual camera control and object manipulation in 3D graphics interfaces. In: CHI &#8217;99: proceedings of the SIGCHI conference on human factors in computing systems, ACM, New York, NY, USA, pp 56&#8211;62. doi:
                    10.1145/302979.302991
                    
                  
                        "/>

    <meta name="citation_reference" content="Bowman DA, Hodges LF (1997) An evaluation of techniques for grabbing and manipulating remote objects in immersive virtual environments. In: SI3D &#8217;97: proceedings of the 1997 symposium on Interactive 3D graphics, ACM, New York, NY, USA, pp 35&#8211;ff. doi:
                    10.1145/253284.253301
                    
                  
                        "/>

    <meta name="citation_reference" content="Crossan A, Brewster S (2006) Two-handed navigation in a haptic virtual environment. In: CHI &#8217;06 extended abstracts on human factors in computing systems, ACM, New York, NY, USA, pp 676&#8211;681. doi:
                    10.1145/1125451.1125589
                    
                  
                        "/>

    <meta name="citation_reference" content="Dominjon L, L&#233;cuyer A, Burkhardt JM, Andrade-Barroso G, Richir S (2005) The &#8220;bubble&#8221; technique: interacting with large virtual environments using haptic devices with limited workspace. In: First joint eurohaptics conference and symposium on haptic interfaces for virtual environment, Pisa, Italy, pp 639&#8211;640. doi:
                    10.1109/WHC.2005.126
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Comput Aided Des; citation_title=Improving bi-manual 3D input in cad modelling by part rotation optimisation; citation_author=M Fiorentino, A Uva, MD Fabiano, G Monno; citation_volume=42; citation_issue=5; citation_publication_date=2010; citation_pages=462-470; citation_doi=10.1016/j.cad.2008.12.002; citation_id=CR6"/>

    <meta name="citation_reference" content="Fischer AA, Vance JM (2003) Phantom haptic device implemented in a projection screen virtual environment. In: IPT/EGVE workshop proceedings. Zurich, Switzerland, pp 225&#8211;230"/>

    <meta name="citation_reference" content="Giachritsis C, Barrio J, Ferre M, Wing A, Ortego J (2009) Evaluation of weight perception during unimanual and bimanual manipulation of virtual objects. In: World haptics 2009 - third joint EuroHaptics conference and symposium on Haptic interfaces for virtual environment and teleoperator systems, Salt Lake City, UT, pp 629&#8211;634"/>

    <meta name="citation_reference" content="Gonz&#225;lez-Badillo G, Medell&#237;n-Castillo H, Fletcher C, Lim T, Ritchie J, Garbaya S (2012) Effect of weight perception on human performance in a haptic-enabled virtual assembly platform. In: 37th International MATADOR conference, Manchester, England, pp 231&#8211;234. doi:
                    10.1007/978-1-4471-4480-9
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=J Motor Behav; citation_title=Asymmetric division of labor in human skilled bimanual action: the kinematic chain as a model; citation_author=Y Guiard; citation_volume=19; citation_issue=4; citation_publication_date=1987; citation_pages=486-517; citation_doi=10.1080/00222895.1987.10735426; citation_id=CR10"/>

    <meta name="citation_reference" content="Gunn C (2006) Collaborative virtual sculpting with haptic feedback. Virtual Real 10:73&#8211;83. doi:
                    10.1007/s10055-006-0044-4
                    
                  . 
                    http://portal.acm.org/citation.cfm?id=1164941.1164943
                    
                  
                        "/>

    <meta name="citation_reference" content="Hinckley K, Pausch R, Proffitt D, Patten J, Kassell N (1997) Cooperative bimanual action. In: CHI &#8217;97: proceedings of the SIGCHI conference on human factors in computing systems, ACM, pp 27&#8211;34. doi:
                    10.1145/258549.258571
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Comput Hum Interact; citation_title=Two-handed virtual manipulation; citation_author=K Hinckley, R Pausch, D Proffitt, NF Kassell; citation_volume=5; citation_publication_date=1998; citation_pages=260-302; citation_doi=10.1145/292834.292849; citation_id=CR13"/>

    <meta name="citation_reference" content="Isshiki M, Sezaki T, Akahane K, Hashimoto N, Sato M (2008) A proposal of a clutch mechanism for 6dof haptic devices. In: Proceedings of the 18th international conference on artificial reality and telexistence, Yokohama, Japan, pp 57&#8211;63"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Int Conf Robot Autom; citation_title=Disposal of explosive ordnances by use of a bimanual haptic telepresence system; citation_author=A Kron, G Schmidt, B Petzold, M Zah, P Hinterseer, E Steinbach; citation_volume=2; citation_publication_date=2004; citation_pages=1968-1973; citation_id=CR15"/>

    <meta name="citation_reference" content="Linn MC, Petersen AC (1985) Emergence and characterization of sex differences in spatial ability: a meta-analysis. Child Dev 56(6):1479&#8211;1498. 
                    http://www.jstor.org/stable/1130467
                    
                  
                        "/>

    <meta name="citation_reference" content="Loftus EF, Hoffman HG (1989) Misinformation and memory: the creation of new memories. J Exp Psychol Gen 118(1):100&#8211;104. 
                    http://psycnet.apa.org/psycinfo/1989-24881-001
                    
                  
                        "/>

    <meta name="citation_reference" content="Loftus EF, Miller DG, Burns HJ (1978) Semantic integration of verbal information into a visual memory. J Exp Psychol Hum Learn Memory 4(1):19&#8211;31. 
                    http://psycnet.apa.org/journals/xlm/4/1/19/
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Q J Exp Psychol; citation_title=Bimanual movement control: information processing and interaction effects; citation_author=RG Marteniuk, CL MacKenzie, DM Baba; citation_volume=36; citation_issue=2; citation_publication_date=1984; citation_pages=335-365; citation_doi=10.1080/14640748408402163; citation_id=CR19"/>

    <meta name="citation_reference" content="McNeely WA, Puterbaugh KD, Troy JJ (1999) Six degree-of-freedom haptic rendering using voxel sampling. In: Proceedings of the 26th annual conference on computer graphics and interactive techniques&#8212;SIGGRAPH &#8217;99, ACM Press, New York, New York, USA, pp 401&#8211;408. doi:
                    10.1145/311535.311600
                    
                  . 
                    http://portal.acm.org/citation.cfm?doid=311535.311600
                    
                  
                        "/>

    <meta name="citation_reference" content="OpenSceneGraph (2013) Openscenegraph. 
                    http://www.openscenegraph.org
                    
                  
                        "/>

    <meta name="citation_reference" content="Owen R, Kurtenbach G, Fitzmaurice G, Baudel T, Buxton B (2005) When it gets more difficult, use both hands: exploring bimanual curve manipulation. In: In GI 2005 proceedings, pp 17&#8211;24"/>

    <meta name="citation_reference" content="Pavlik RA, Vance JM (2011a) Expanding haptic workspace for coupled-object manipulation. In: ASME 2011 world conference on innovative virtual reality, ASME, Milan, Italy. doi:
                    10.1115/WINVR2011-5585
                    
                  
                        "/>

    <meta name="citation_reference" content="Pavlik RA, Vance JM (2011b) VR JuggLua: a framework for VR applications combining Lua, OpenSceneGraph, and VR Juggler. In: Workshop on software engineering and architectures for realtime interactive systems (SEARIS) in IEEE virtual reality, Singapore"/>

    <meta name="citation_reference" content="Pavlik RA, Vance JM (2015) Interacting with grasped objects in expanded haptic workspaces using the bubble technique. ASME J Comput Inf Sci Eng 1&#8211;7. doi:
                    10.1115/1.4031826
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Q J Exp Psychol; citation_title=Constraints in the performance of bimanual tasks and their expression in unskilled and skilled subjects; citation_author=M Peters; citation_volume=37; citation_issue=2; citation_publication_date=1985; citation_pages=171-196; citation_doi=10.1080/14640748508400929; citation_id=CR26"/>

    <meta name="citation_reference" content="citation_journal_title=J Vis Lang Comput; citation_title=Manipulating objects in virtual worlds: categorization and empirical evaluation of interaction techniques; citation_author=I Poupyrev, T Ichikawa; citation_volume=10; citation_issue=1; citation_publication_date=1999; citation_pages=19-35; citation_doi=10.1006/jvlc.1998.0112; citation_id=CR27"/>

    <meta name="citation_reference" content="Shaw C, Green M (1994) Two-handed polygonal surface design. In: Proceedings of UIST 94. Marina del Rey, CA, pp 205&#8211;212"/>

    <meta name="citation_reference" content="Talvas A, Marchal M, Cirio G, L&#233;cuyer A (2013) 3D interaction techniques for bimanual haptics in virtual environments. In: Ferre GM (ed) Multi-finger haptic interaction. Springer series on touch and haptic systems, chap&#160;3, pp 31&#8211;53"/>

    <meta name="citation_reference" content="V&#233;laz Y, Lozano-Rodero A, Suescun A, Guti&#233;rrez T (2014) Natural and hybrid bimanual interaction for virtual assembly tasks. Virtual Real J 18(3):161&#8211;171. 
                    http://link.springer.com/article/10.1007
                    
                  
                        "/>

    <meta name="citation_reference" content="VRJuggler (2013) Vrjuggler. 
                    http://vrjuggler.org
                    
                  
                        "/>

    <meta name="citation_reference" content="Vyawahare VS, Stone RT (2012) Asymmetric interface and interactions for bimanual virtual assembly with haptics. In: Proceedings of the ASME 2012 international design engineering technical conferences and computers and information in engineering conference. ASME, Chicago, Illinois, pp 1&#8211;9"/>

    <meta name="citation_reference" content="Vyawahare VS, Stone RT (2013) Evaluation of bimanual stretched-string single object manipulation for virtual assembly with haptics. In: Proceedings of the ASME 2013 international design engineering technical conferences and computers and information in engineering conference (IDETC/CIE 2013). ASME, Portland, Oregon, pp 1&#8211;10"/>

    <meta name="citation_reference" content="Vyawahare VS, Vance JM (2009) Human centered multimodal 3D user interface for desktop VR assembly. In: Proceedings of the emerging technologies conference 2009, ETC"/>

    <meta name="citation_author" content="Patrick Carlson"/>

    <meta name="citation_author_email" content="carlson2442@gmail.com"/>

    <meta name="citation_author_institution" content="Human-Computer Interaction, Iowa State University, Ames, USA"/>

    <meta name="citation_author" content="Judy M. Vance"/>

    <meta name="citation_author_email" content="jmvance@iastate.edu"/>

    <meta name="citation_author_institution" content="Human-Computer Interaction, Iowa State University, Ames, USA"/>

    <meta name="citation_author" content="Meisha Berg"/>

    <meta name="citation_author_email" content="meisha.berg@gmail.com"/>

    <meta name="citation_author_institution" content="Human-Computer Interaction, Iowa State University, Ames, USA"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-016-0290-z&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2016/11/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-016-0290-z"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="An evaluation of asymmetric interfaces for bimanual virtual assembly with haptics"/>
        <meta property="og:description" content="Immersive computing technology provides a human–computer interface to support natural human interaction with digital data and models. One application for this technology is product assembly methods planning and validation. This paper presents the results of a user study which explores the effectiveness of various bimanual interaction device configurations for virtual assembly tasks. Participants completed two assembly tasks with two device configurations in five randomized bimanual treatment conditions (within subjects). A Phantom Omni® with and without haptics enabled and a 5DT Data Glove were used. Participant performance, as measured by time to assemble, was the evaluation metric. The results revealed that there was no significant difference in performance between the five treatment conditions. However, half of the participants chose the 5DT Data Glove and the haptic-enabled Phantom Omni®&amp;nbsp;as their preferred device configuration. In addition, qualitative comments support both the preference of haptics during the assembly process and comments confirming Guiard’s kinematic chain model."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>An evaluation of asymmetric interfaces for bimanual virtual assembly with haptics | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-016-0290-z","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Haptic devices, Virtual reality, Interaction devices, Interaction techniques, Human–computer interaction (HCI), Bimanual interaction","kwrd":["Haptic_devices","Virtual_reality","Interaction_devices","Interaction_techniques","Human–computer_interaction_(HCI)","Bimanual_interaction"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-016-0290-z","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-016-0290-z","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=290;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-016-0290-z">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            An evaluation of asymmetric interfaces for bimanual virtual assembly with haptics
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-016-0290-z.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-016-0290-z.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2016-07-07" itemprop="datePublished">07 July 2016</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">An evaluation of asymmetric interfaces for bimanual virtual assembly with haptics</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Patrick-Carlson" data-author-popup="auth-Patrick-Carlson">Patrick Carlson</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Iowa State University" /><meta itemprop="address" content="grid.34421.30, 0000000419367312, Human-Computer Interaction, Iowa State University, 1620 Howe Hall, Ames, IA, 50011, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Judy_M_-Vance" data-author-popup="auth-Judy_M_-Vance" data-corresp-id="c1">Judy M. Vance<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Iowa State University" /><meta itemprop="address" content="grid.34421.30, 0000000419367312, Human-Computer Interaction, Iowa State University, 1620 Howe Hall, Ames, IA, 50011, USA" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Meisha-Berg" data-author-popup="auth-Meisha-Berg">Meisha Berg</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Iowa State University" /><meta itemprop="address" content="grid.34421.30, 0000000419367312, Human-Computer Interaction, Iowa State University, 1620 Howe Hall, Ames, IA, 50011, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 20</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">193</span>–<span itemprop="pageEnd">201</span>(<span data-test="article-publication-year">2016</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">597 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">4 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-016-0290-z/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Immersive computing technology provides a human–computer interface to support natural human interaction with digital data and models. One application for this technology is product assembly methods planning and validation. This paper presents the results of a user study which explores the effectiveness of various bimanual interaction device configurations for virtual assembly tasks. Participants completed two assembly tasks with two device configurations in five randomized bimanual treatment conditions (within subjects). A Phantom Omni<sup>®</sup> with and without haptics enabled and a 5DT Data Glove were used. Participant performance, as measured by time to assemble, was the evaluation metric. The results revealed that there was no significant difference in performance between the five treatment conditions. However, half of the participants chose the 5DT Data Glove and the haptic-enabled Phantom Omni<sup>®</sup> as their preferred device configuration. In addition, qualitative comments support both the preference of haptics during the assembly process and comments confirming Guiard’s kinematic chain model.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Understanding product assemblies is important throughout the development and life cycle of a product. Virtual assembly employs cutting edge hardware in the creation, design, and evaluation of assemblies. As part of this technology, bimanual haptics renders realistic force feedback to create an immersive experience for manipulation. Bimanual haptic applications have been used for a wide variety of purposes from explosive ordnance disposal (Kron et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Kron A, Schmidt G, Petzold B, Zah M, Hinterseer P, Steinbach E (2004) Disposal of explosive ordnances by use of a bimanual haptic telepresence system. IEEE Int Conf Robot Autom 2:1968–1973. doi:&#xA;                    10.1109/ROBOT.2004.1308112&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR15" id="ref-link-section-d72010e341">2004</a>), to surgical training (Hinckley et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Hinckley K, Pausch R, Proffitt D, Kassell NF (1998) Two-handed virtual manipulation. ACM Trans Comput Hum Interact 5:260–302" href="/article/10.1007/s10055-016-0290-z#ref-CR13" id="ref-link-section-d72010e344">1998</a>) and surface and curve manipulation (Owen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Owen R, Kurtenbach G, Fitzmaurice G, Baudel T, Buxton B (2005) When it gets more difficult, use both hands: exploring bimanual curve manipulation. In: In GI 2005 proceedings, pp 17–24" href="/article/10.1007/s10055-016-0290-z#ref-CR22" id="ref-link-section-d72010e347">2005</a>; Shaw and Green <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Shaw C, Green M (1994) Two-handed polygonal surface design. In: Proceedings of UIST 94. Marina del Rey, CA, pp 205–212" href="/article/10.1007/s10055-016-0290-z#ref-CR28" id="ref-link-section-d72010e350">1994</a>). They have also been used for 3-D object manipulation and interaction in virtual environments (Balakrishnan and Kurtenbach <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Balakrishnan R, Kurtenbach G (1999) Exploring bimanual camera control and object manipulation in 3D graphics interfaces. In: CHI ’99: proceedings of the SIGCHI conference on human factors in computing systems, ACM, New York, NY, USA, pp 56–62. doi:&#xA;                    10.1145/302979.302991&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR2" id="ref-link-section-d72010e353">1999</a>; Bowman and Hodges <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Bowman DA, Hodges LF (1997) An evaluation of techniques for grabbing and manipulating remote objects in immersive virtual environments. In: SI3D ’97: proceedings of the 1997 symposium on Interactive 3D graphics, ACM, New York, NY, USA, pp 35–ff. doi:&#xA;                    10.1145/253284.253301&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR3" id="ref-link-section-d72010e357">1997</a>; Poupyrev and Ichikawa <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Poupyrev I, Ichikawa T (1999) Manipulating objects in virtual worlds: categorization and empirical evaluation of interaction techniques. J Vis Lang Comput 10(1):19–35. doi:&#xA;                    10.1006/jvlc.1998.0112&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR27" id="ref-link-section-d72010e360">1999</a>). Fiorentino et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Fiorentino M, Uva A, Fabiano MD, Monno G (2010) Improving bi-manual 3D input in cad modelling by part rotation optimisation. Comput Aided Des 42(5):462–470. doi:&#xA;                    10.1016/j.cad.2008.12.002&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR6" id="ref-link-section-d72010e363">2010</a>) found that the incorporation of bimanual haptics aided CAD designers in model creation. Talvas et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Talvas A, Marchal M, Cirio G, Lécuyer A (2013) 3D interaction techniques for bimanual haptics in virtual environments. In: Ferre GM (ed) Multi-finger haptic interaction. Springer series on touch and haptic systems, chap 3, pp 31–53" href="/article/10.1007/s10055-016-0290-z#ref-CR29" id="ref-link-section-d72010e366">2013</a>) describe a wide range of bimanual haptic interaction techniques</p><p>Bimanual virtual assembly has been found to outperform unimanual virtual assembly in a variety of situations, including perception of weight (Giachritsis et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Giachritsis C, Barrio J, Ferre M, Wing A, Ortego J (2009) Evaluation of weight perception during unimanual and bimanual manipulation of virtual objects. In: World haptics 2009 - third joint EuroHaptics conference and symposium on Haptic interfaces for virtual environment and teleoperator systems, Salt Lake City, UT, pp 629–634" href="/article/10.1007/s10055-016-0290-z#ref-CR8" id="ref-link-section-d72010e372">2009</a>; Owen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Owen R, Kurtenbach G, Fitzmaurice G, Baudel T, Buxton B (2005) When it gets more difficult, use both hands: exploring bimanual curve manipulation. In: In GI 2005 proceedings, pp 17–24" href="/article/10.1007/s10055-016-0290-z#ref-CR22" id="ref-link-section-d72010e375">2005</a>), virtual navigation for the visually impaired (Crossan and Brewster <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Crossan A, Brewster S (2006) Two-handed navigation in a haptic virtual environment. In: CHI ’06 extended abstracts on human factors in computing systems, ACM, New York, NY, USA, pp 676–681. doi:&#xA;                    10.1145/1125451.1125589&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR4" id="ref-link-section-d72010e378">2006</a>), and cooperative tasks (Gunn <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Gunn C (2006) Collaborative virtual sculpting with haptic feedback. Virtual Real 10:73–83. doi:&#xA;                    10.1007/s10055-006-0044-4&#xA;                    &#xA;                  . &#xA;                    http://portal.acm.org/citation.cfm?id=1164941.1164943&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR11" id="ref-link-section-d72010e381">2006</a>; Hinckley et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Hinckley K, Pausch R, Proffitt D, Patten J, Kassell N (1997) Cooperative bimanual action. In: CHI ’97: proceedings of the SIGCHI conference on human factors in computing systems, ACM, pp 27–34. doi:&#xA;                    10.1145/258549.258571&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR12" id="ref-link-section-d72010e384">1997</a>). The increased performance of bimanual assembly has been explained using a framework that models the two hands as two motors connected in series. This model, known as the kinematic chain model (Guiard <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Guiard Y (1987) Asymmetric division of labor in human skilled bimanual action: the kinematic chain as a model. J Motor Behav 19(4):486–517" href="/article/10.1007/s10055-016-0290-z#ref-CR10" id="ref-link-section-d72010e388">1987</a>), emphasizes an asymmetric division of labor between the two hands where the dominant hand moves in reference to the non-dominant hand. An asymmetric task is a task in which each hand does a uniquely different task while a symmetric task is where each hand does the same task. For example, simultaneously opening two oppositely hinged cupboard doors is a symmetric task while dealing playing cards is an asymmetric task.</p><p>Studies of asymmetric and symmetric bimanual tasks have resulted in a series of insights into the way humans use both hands when completing various tasks. According to Hinckley et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Hinckley K, Pausch R, Proffitt D, Patten J, Kassell N (1997) Cooperative bimanual action. In: CHI ’97: proceedings of the SIGCHI conference on human factors in computing systems, ACM, pp 27–34. doi:&#xA;                    10.1145/258549.258571&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR12" id="ref-link-section-d72010e394">1997</a>), bimanual interaction is optimal when each hand assumes its most effective role. In a 2-D bimanual symmetric tracking task, divided attention, task difficulty, and a lack of visual integration can decrease performance (Balakrishnan and Hinckley <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Balakrishnan R, Hinckley K (2000) Symmetric bimanual interaction. In: CHI ’00: proceedings of the SIGCHI conference on human factors in computing systems, ACM, New York, NY, USA, pp 33–40. doi:&#xA;                    10.1145/332040.332404&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR1" id="ref-link-section-d72010e397">2000</a>). However, the most common bimanual interaction is one in which the non-dominant hand is responsible for gross motor movements while the dominant hand performs more fine motor positioning (Hinckley et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Hinckley K, Pausch R, Proffitt D, Kassell NF (1998) Two-handed virtual manipulation. ACM Trans Comput Hum Interact 5:260–302" href="/article/10.1007/s10055-016-0290-z#ref-CR13" id="ref-link-section-d72010e400">1998</a>; Marteniuk et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1984" title="Marteniuk RG, MacKenzie CL, Baba DM (1984) Bimanual movement control: information processing and interaction effects. Q J Exp Psychol 36(2):335–365" href="/article/10.1007/s10055-016-0290-z#ref-CR19" id="ref-link-section-d72010e403">1984</a>). Supporting research indicates that the non-dominant hand is generally used for lower-frequency and higher-amplitude movements and the dominant hand is used for higher-frequency and lower-amplitude movements (Peters <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1985" title="Peters M (1985) Constraints in the performance of bimanual tasks and their expression in unskilled and skilled subjects. Q J Exp Psychol 37(2):171–196" href="/article/10.1007/s10055-016-0290-z#ref-CR26" id="ref-link-section-d72010e406">1985</a>). This has led to research into the use of devices for bimanual assembly in virtual reality.</p><p>
Vyawahare and Vance (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Vyawahare VS, Vance JM (2009) Human centered multimodal 3D user interface for desktop VR assembly. In: Proceedings of the emerging technologies conference 2009, ETC" href="/article/10.1007/s10055-016-0290-z#ref-CR34" id="ref-link-section-d72010e412">2009</a>) proposed a bimanual device configuration that incorporates haptic feedback by using a position-tracked glove on the one hand and a haptic device on the other hand. Referencing Hinckley’s model of bimanual interaction, the glove (non-haptic) would be placed on the non-dominant hand and be used to select and position virtual objects and the haptic device would be controlled by the dominant hand where the user would perform fine positioning movements. The main benefit in implementing this configuration is that the user is able to feel haptic feedback during crucial assembly operations and able to reach parts beyond the haptic workspace. In this way, task performance in the configuration supports haptic, kinesthetic, and visual representation of the bimanual assembly process.</p><p>A more recent paper outlines a similar asymmetric interface using haptics and a Razer Hydra™ (Vyawahare and Stone <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Vyawahare VS, Stone RT (2012) Asymmetric interface and interactions for bimanual virtual assembly with haptics. In: Proceedings of the ASME 2012 international design engineering technical conferences and computers and information in engineering conference. ASME, Chicago, Illinois, pp 1–9" href="/article/10.1007/s10055-016-0290-z#ref-CR32" id="ref-link-section-d72010e419">2012</a>). The Hydra provides two controllers with button and joystick input on each controller that are tracked using a magnetic tracking base. Originally created and marketed for video games, the Hydra has been adopted and extended by virtual reality researchers as a tracking and input device. Vyawahare and Stone used the large workspace of the Hydra to augment the interaction method and provide asymmetric interaction. An evaluation of this interface and the interaction method was performed and the utility of these methods was shown to be useful for a variety of tasks (Vyawahare and Stone <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Vyawahare VS, Stone RT (2013) Evaluation of bimanual stretched-string single object manipulation for virtual assembly with haptics. In: Proceedings of the ASME 2013 international design engineering technical conferences and computers and information in engineering conference (IDETC/CIE 2013). ASME, Portland, Oregon, pp 1–10" href="/article/10.1007/s10055-016-0290-z#ref-CR33" id="ref-link-section-d72010e422">2013</a>).</p><p>The desire to use one haptic device rather than two for desktop assembly is motivated by three factors. The first of these is cost reduction. Adding haptic force feedback to a simulation increases the cost because of the need for additional equipment. If the use of a haptic device coupled with a non-haptic device yields similar or better performance than two haptic-enabled devices, costs would be reduced by choosing the less expensive configuration. Vélaz et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Vélaz Y, Lozano-Rodero A, Suescun A, Gutiérrez T (2014) Natural and hybrid bimanual interaction for virtual assembly tasks. Virtual Real J 18(3):161–171. &#xA;                    http://link.springer.com/article/10.1007&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR30" id="ref-link-section-d72010e428">2014</a>) explored three different hardware configurations for bimanual virtual assembly. Their results indicated that a hybrid configuration of a haptic device on the one hand and a non-haptic device with markerless motion capture on the other hand produced the shortest time of completion for the assembly task. They concluded that the hybrid configuration was sufficient to perform virtual assembly of parts where precision fit is not critical. The research presented here compliments their work by exploring a reduced-cost configuration for bimanual assembly of precision fit parts.</p><p>The second factor is the desire to improve realism. Replacing a haptic probe with a glove provides the user with the visual representation of finger motion during grasping. However, most current glove interfaces do not have haptic feedback, but support more natural hand motion and interaction than existing haptic devices. Instead of learning how to use an entirely new device, a user can grab, select, and release objects when wearing the glove in a manner similar to the way they would handle objects in the real world.</p><p>Finally, desktop haptic devices have limited workspaces. Talvas et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Talvas A, Marchal M, Cirio G, Lécuyer A (2013) 3D interaction techniques for bimanual haptics in virtual environments. In: Ferre GM (ed) Multi-finger haptic interaction. Springer series on touch and haptic systems, chap 3, pp 31–53" href="/article/10.1007/s10055-016-0290-z#ref-CR29" id="ref-link-section-d72010e437">2013</a>) point out that this limitation can be addressed by developing unique software algorithms or by using unique hardware configurations. One software algorithm that expands the usable haptic workspace is the bubble technique proposed by Dominjon et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Dominjon L, Lécuyer A, Burkhardt JM, Andrade-Barroso G, Richir S (2005) The “bubble” technique: interacting with large virtual environments using haptic devices with limited workspace. In: First joint eurohaptics conference and symposium on haptic interfaces for virtual environment, Pisa, Italy, pp 639–640. doi:&#xA;                    10.1109/WHC.2005.126&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR5" id="ref-link-section-d72010e440">2005</a>) and modified to accommodate bimanual interaction by Talvas et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Talvas A, Marchal M, Cirio G, Lécuyer A (2013) 3D interaction techniques for bimanual haptics in virtual environments. In: Ferre GM (ed) Multi-finger haptic interaction. Springer series on touch and haptic systems, chap 3, pp 31–53" href="/article/10.1007/s10055-016-0290-z#ref-CR29" id="ref-link-section-d72010e443">2013</a>). This technique provides the user with an intuitive means of essentially moving the haptic device within the entire virtual environment, allowing for haptic interaction at any place within the environment without the need for haptic clutching. Pavlik and Vance (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Pavlik RA, Vance JM (2015) Interacting with grasped objects in expanded haptic workspaces using the bubble technique. ASME J Comput Inf Sci Eng 1–7. doi:&#xA;                    10.1115/1.4031826&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR25" id="ref-link-section-d72010e446">2015</a>) expanded on the bubble technique to allow grasping parts with the haptic device while simultaneously moving within the environment. Other techniques such as scaling the virtual environment (Fischer and Vance <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Fischer AA, Vance JM (2003) Phantom haptic device implemented in a projection screen virtual environment. In: IPT/EGVE workshop proceedings. Zurich, Switzerland, pp 225–230" href="/article/10.1007/s10055-016-0290-z#ref-CR7" id="ref-link-section-d72010e449">2003</a>) and haptic clutching (Isshiki et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Isshiki M, Sezaki T, Akahane K, Hashimoto N, Sato M (2008) A proposal of a clutch mechanism for 6dof haptic devices. In: Proceedings of the 18th international conference on artificial reality and telexistence, Yokohama, Japan, pp 57–63" href="/article/10.1007/s10055-016-0290-z#ref-CR14" id="ref-link-section-d72010e453">2008</a>) have also been investigated.</p><p>The study described in this paper is an evaluation of the Vyawahare and Vance (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Vyawahare VS, Vance JM (2009) Human centered multimodal 3D user interface for desktop VR assembly. In: Proceedings of the emerging technologies conference 2009, ETC" href="/article/10.1007/s10055-016-0290-z#ref-CR34" id="ref-link-section-d72010e459">2009</a>) proposed bimanual device configuration for precise fit haptic assembly. Two different assembly tasks are performed using various combinations of desktop haptic devices and a position-tracked glove.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Methodology</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Software</h3><p>The application was developed using SPARTA (Scriptable Platform for Advanced Research in Teaching and Assembly). SPARTA combines VR Juggler (VRJuggler <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="VRJuggler (2013) Vrjuggler. &#xA;                    http://vrjuggler.org&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR31" id="ref-link-section-d72010e474">2013</a>) for stereoscopic rendering and position tracking management, OpenSceneGraph (OpenSceneGraph <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="OpenSceneGraph (2013) Openscenegraph. &#xA;                    http://www.openscenegraph.org&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR21" id="ref-link-section-d72010e477">2013</a>) for graphics, Voxmap PointShell (VPS) (McNeely et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="McNeely WA, Puterbaugh KD, Troy JJ (1999) Six degree-of-freedom haptic rendering using voxel sampling. In: Proceedings of the 26th annual conference on computer graphics and interactive techniques—SIGGRAPH ’99, ACM Press, New York, New York, USA, pp 401–408. doi:&#xA;                    10.1145/311535.311600&#xA;                    &#xA;                  . &#xA;                    http://portal.acm.org/citation.cfm?doid=311535.311600&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR20" id="ref-link-section-d72010e480">1999</a>) for physics calculations, and VR JuggLua (Pavlik and Vance <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011b" title="Pavlik RA, Vance JM (2011b) VR JuggLua: a framework for VR applications combining Lua, OpenSceneGraph, and VR Juggler. In: Workshop on software engineering and architectures for realtime interactive systems (SEARIS) in IEEE virtual reality, Singapore" href="/article/10.1007/s10055-016-0290-z#ref-CR24" id="ref-link-section-d72010e483">2011b</a>) for easy scripting and content creation. SPARTA supports multiple input and output devices including position trackers, stereo glasses, stereo projection systems, gloves and haptic devices (Pavlik and Vance <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011a" title="Pavlik RA, Vance JM (2011a) Expanding haptic workspace for coupled-object manipulation. In: ASME 2011 world conference on innovative virtual reality, ASME, Milan, Italy. doi:&#xA;                    10.1115/WINVR2011-5585&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR23" id="ref-link-section-d72010e486">2011a</a>). It was developed by researchers at the Virtual Reality Applications Center at Iowa State University.</p><h3 class="c-article__sub-heading" id="Sec4">Hardware</h3><p>The two hardware devices that were used in this study are the Phantom Omni<sup>®</sup> haptic device and the 5DT Data Glove 5 Ultra. The Phantom Omni<sup>®</sup> is priced around $2000 USD and the 5DT Data Glove 5 Ultra is priced around $995 USD. The Phantom Omni<sup>®</sup> provides the ability to enable or disable haptic force feedback while the glove does not have haptic force feedback . For completeness, we included the haptic disabled Omni device configuration in our treatments.</p><p>The user wore position-tracked stereo glasses to view the rear projected stereo image on the desktop screen. The glasses were tracked using an InterSense IS-900 hybrid inertial and ultrasonic tracking system. The gloved hand was tracked using a Polhemus Patriot magnetic tracker. Both commercial tracking systems have low latency with the IS-900 at around 4 ms and the Patriot at around 17 ms.</p><p>Interaction using the Omni allows the user to have a full 6 degrees of freedom (DOF) in tracking and movement, along with three DOF haptic force feedback (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0290-z#Fig1">1</a>). The user’s interactions in this study consisted of moving a virtual cursor around the scene. Once the cursor intersected a part, the part turned slightly transparent indicating that it could be selected. A button on the Omni could then be pressed to select the part and subsequent movement would move the virtual part.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0290-z/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0290-z/MediaObjects/10055_2016_290_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0290-z/MediaObjects/10055_2016_290_Fig1_HTML.jpg" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Dual Phantom Omni<sup>®</sup> configuration</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0290-z/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Interaction using the 5DT glove was similar to the Omni, also providing six DOF in tracking and movement; however, no forces are rendered to the user’s hand with the Data Glove (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0290-z#Fig2">2</a>). In this interaction, a virtual hand representation acted as a cursor that could be moved around the scene. Intersection of the virtual hand with a part turned the part slightly transparent indicating that it could be selected. The user then made a fist gesture to grab the part and move the virtual part in the environment.</p><p>The six DOF movement and tracking of both systems provides a natural interaction that mimics real physical assembly. No scaling of movement was applied to either device to ensure that it matched real-life interaction.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0290-z/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0290-z/MediaObjects/10055_2016_290_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0290-z/MediaObjects/10055_2016_290_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Desktop setup showing the 5DT Data Glove and the Phantom Omni<sup>®</sup> configuration</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0290-z/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec5">User study</h3><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec6">Study design</h4><p>The two independent variables were the device configurations (five treatment conditions) and the task difficulty (easy and hard). The dependent variable was performance as measured by task completion time. Examining the effect of device configuration on performance time was a within-subject variable. Task difficulty was a between-subject variable. The five device configurations are listed in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0290-z#Tab1">1</a>.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Treatment conditions</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0290-z/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Each participant was randomly assigned to one of the two task difficulties and asked to perform the assembly using each of the five treatment conditions. The order of the five treatment conditions was randomized to account for fatigue and learning. The easy task consisted of insertion of one virtual object into another (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0290-z#Fig3">3</a>). This required orientation and insertion of the object. The difficult task required object orientation, insertion, rotation, and finally insertion (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0290-z#Fig4">4</a>). This task is similar to the insertion of a key into a lock, followed by rotation of the key in the lock.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0290-z/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0290-z/MediaObjects/10055_2016_290_Fig3_HTML.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0290-z/MediaObjects/10055_2016_290_Fig3_HTML.jpg" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Unassembled individual objects for the easy task</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0290-z/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                              <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0290-z/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0290-z/MediaObjects/10055_2016_290_Fig4_HTML.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0290-z/MediaObjects/10055_2016_290_Fig4_HTML.jpg" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Unassembled individual objects for the difficult task</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0290-z/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>The assembly of these two simple parts was designed to represent common motions of assembly. Sliding a pin into a sleeve is a common motion that occurs in many assembly operations. In a virtual environment, this is more difficult than in real life, especially if the virtual environment does not impose artificial axial constraints between the two parts. The motion of rotation can also be difficult to perform in virtual reality due to the existence of a virtual spring between the haptic device and the rigid body combined with the need to rotate and re-grasp.</p><p>Upon arriving, participants filled out a consent form. Participants then completed a short pre-study questionnaire that gathered basic demographic information along with a self-assessment of previous computer and VR experience. Next, participants watched a short video demonstrating the equipment that they would be using and the interface for interacting with the virtual parts. Participants were given two minutes to become familiar with using the equipment and the application. Different models than the test models were used during this practice period and all participants used the Omni in their dominant hand and the 5DT Data Glove in their non-dominant hand. This let participants experience both hardware devices. Next, the timed data were gathered as participants used each of the five randomized device configurations to perform the assigned task. The piece that resembles a key was always placed on the left in the scene and the other piece was placed on the right. For each configuration, they were instructed to complete the assembly twice. In total, each participant completed ten assembly operations. A picture of the disassembled and assembled objects was placed on the table for reference but no other instructions were given during the treatments. Upon completion of the trials, participants completed a short exit questionnaire to gather preferential data.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec7">Participants</h4><p>Fifty-two participants (39 males and 13 females) completed the study. While participants were not compensated, some did receive class credit. The participants were recruited mostly from undergraduate engineering and psychology classes. The ages ranged from 17 to 36 years with a mean (<i>M</i>) of 22.17 and a standard deviation (SD) of 4.48. Forty-eight participants were right-handed and four participants were left-handed. No participants indicated that they were ambidextrous. The participants were divided into two groups (easy task and difficult task) resulting in 26 participants in each group. Self-reported computer experience was reported on a Likert scale between 0 (no experience) and 10 (high computer experience) (<i>M</i> = 5.73, SD = 2.57). Most of the participants had little experience with virtual reality as was self-reported on a Likert scale between 1 (none or little experience) and 10 (significant experience) (<i>M</i> = 2.94, SD = 2.38). Prior experience was low as self-reported on a Likert scale between 1 (none or little experience) and 10 (significant experience) regarding both virtual assembly operations (<i>M</i> = 2.01, SD = 1.79) and haptic force feedback devices (<i>M</i> = 1.67, SD = 1.2).</p><p>Within the participant pool, there was a significant difference in self-reported computer experience between males and females. The results of an independent two-sample <i>t</i> test, <i>t</i>(50) = −2.70, <i>p</i> = 0.009 indicated a significant difference between groups with males reporting their computer experience as being higher than females.</p></div></div></section><section aria-labelledby="Sec8"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Results</h2><div class="c-article-section__content" id="Sec8-content"><h3 class="c-article__sub-heading" id="Sec9">Quantitative</h3><p>For each treatment, the participants completed the assembly task twice. For purposes of data analysis, the overall completion time was calculated as the average of the two task times. A comparison of task completion time for each treatment is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0290-z#Fig5">5</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0290-z/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0290-z/MediaObjects/10055_2016_290_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0290-z/MediaObjects/10055_2016_290_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Average task completion times for each device configuration</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0290-z/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>In order to run a balanced ANOVA, five participants who did not finish all five device configurations because of a technical glitch were removed. All five of these participants were right-handed. This left 47 participants who completed all the device configurations. Levene’s test was not significant <i>F</i>(4, 230) = 0.39, <i>p</i> = 0.81 signifying that the assumption around equality of variances was not violated. The results of an Omnibus ANOVA were not significant, <i>F</i>(4, 184) = 0.10, <i>p</i> = 0.97, indicating that there was little difference in performance between the different treatments not including the variable of task difficulty. When including the interaction of task difficulty in comparing the five treatments, this was also not significant, <i>F</i>(4, 1739) = 0.41, <i>p</i> = 0.80. Since the Omnibus ANOVA was not significant, more specific planned linear contrasts that would examine the details of individual device configurations could not be performed. The effect of devices used during the practice session at the beginning was not considered in the analysis since all participants used the same configuration.</p><p>In examining the total time taken to finish the tasks between the easy and difficult task assignments, there was a significant difference when running an independent two-sample <i>t</i> test, <i>t</i> (233) = −4.36, <i>p</i> &lt; 0.001 with the more difficult task taking longer.</p><p>Irrespective of treatment, in general, the participants exhibited a slight learning effect as they progressed through the study (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0290-z#Fig6">6</a>). In particular, the increase in their performance from the first task that they completed to the second task is evident.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0290-z/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0290-z/MediaObjects/10055_2016_290_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0290-z/MediaObjects/10055_2016_290_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Times for each of the five trials regardless of device configuration and task assignment</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0290-z/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>There was no significant difference in the total time taken to finish the task between groups of left-handed and right-handed participants, <i>t</i>(233) = −1.41, <i>p</i> = 0.16 irrespective of task difficulty.</p><p>In comparing the time taken to finish the tasks between males and females, there was a significant difference when running an independent two-sample <i>t</i> test, <i>t</i>(66.22) = 5.34, <i>p</i> &lt; 0.001 with males participants completing the task faster. The results are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0290-z#Fig7">7</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0290-z/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0290-z/MediaObjects/10055_2016_290_Fig7_HTML.gif?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0290-z/MediaObjects/10055_2016_290_Fig7_HTML.gif" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Differences in time taken based on gender</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0290-z/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>In the exit questionnaire, participants were asked to pick their preferred device setup from any possible combination of bimanual or unimanual device combinations and dominant or non-dominant hand. There was little difference based on handedness preference; therefore, these groupings were combined and a summary of the responses is presented in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0290-z#Tab2">2</a>. Given the multitude of possible device combinations and the low number of participants, a Chi-squared goodness of fit test was not performed.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Preferred device combinations</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0290-z/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>While participants were not able to try every possible bimanual or unimanual device configuration, they were able to experience both the Glove and Haptic/NoHaptic Omni. Interestingly, the majority of participants preferred at least one haptic device (42 out of 52 responses) as given in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0290-z#Tab2">2</a>. Twenty-six of the 52 participants chose the Glove and the Omni. Additionally, participants rated the use of haptic force feedback beneficial in assembling the objects on a Likert scale between 1 (useless) and 10 (useful) (<i>M</i> = 7.55, SD = 2.06). They also rated each of the devices on a Likert scale for helping in the assembly process: Omni (<i>M</i> = 7.26, SD = 2.03), NoHaptic Omni (<i>M</i> = 5.36, SD = 1.84), and Glove (<i>M</i> = 6.55, SD = 2.65).</p><p>In general, participants had a favorable view of the hardware being useful in day-to-day use when asked to rate it on a Likert scale between 1 (useless) and 10 (useful) (<i>M</i> = 6.82, SD = 1.98). Almost three-fourths of the participants (72 %) said that if the technology was available they would use it daily. Most (71 %) felt the haptic force feedback increased their ability to assemble the objects with some (12 %) saying it decreased their ability and others (17 %) saying it had no effect. When asked about the use of the haptic device in their dominant hand and their ability to assemble the objects, it was gauged as being quite helpful (<i>M</i> = 7.94, SD = 1.92). Multiple devices were also considered to be quite helpful in the overall simulation experience (<i>M</i> = 7.32, SD = 1.99). When asked how natural they felt their interactions with the environment seemed, participants had a favorable view (<i>M</i> = 6.84, SD = 2.14) and in addition they felt that the sense of moving around was compelling (<i>M</i> = 7.48, SD = 1.70). In general, the virtual reality experience was deemed moderately realistic when compared to the real-world experience of assembling the objects (<i>M</i> = 6.07, SD = 1.93).</p><h3 class="c-article__sub-heading" id="Sec10">Qualitative</h3><p>The benefit of this study design was that it gave participants experience with many device configurations and they were able to try both haptic and non-haptic devices. This helped temper their qualitative comments and responses. The last section in the final exit questionnaire was open-ended and asked participants if they had any comments about their overall experience. In general, participants had a favorable opinion and seemed to prefer the haptic Omni as given in the comments in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0290-z#Tab3">3</a>. In addition, comments from participants seemed to echo the theory of the kinematic chain model as given in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0290-z#Tab4">4</a>.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Participant comments regarding device preference</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0290-z/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 Participant comments confirming kinematic chain</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0290-z/tables/4"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>In general, participants were supportive of the experience saying that they, “enjoyed it.” One participant said, “I thought it was awesome! I thought once I got the hang of how to do it that it was a lot of fun to work with! I am amazed that this is possible!”. Participants even thought of additional use cases for the devices besides virtual assembly such as gaming. One participant said, “The device is great and I hope this device can be obtained at an affordable price because I know people in my country with drawing and designing objects would have their work time lightened with this piece of technology”.</p></div></div></section><section aria-labelledby="Sec11"><div class="c-article-section" id="Sec11-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec11">Discussion</h2><div class="c-article-section__content" id="Sec11-content"><p>Although not shown to be statistically significant, the study results show that the use of the Glove in the non-dominant hand and the Omni in the dominant hand for bimanual assembly resulted in similar performance when compared to the other configurations that were tested for this specific task. In general, participants performed equally well through all five of the treatment conditions. However, in answer to the open-ended question, several participants indicated that having one glove and one haptic device was their favored configuration.</p><p>While not quantitatively measured, anecdotal observation of the participants indicated that the participants who performed the task in the shortest time were those that used both hands at the same time. The task given to the participants did not require two-handed manipulation. Perhaps a redesigned task which includes a gravity force and therefore requires the use of both hands may have produced different results across treatments. González-Badillo et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="González-Badillo G, Medellín-Castillo H, Fletcher C, Lim T, Ritchie J, Garbaya S (2012) Effect of weight perception on human performance in a haptic-enabled virtual assembly platform. In: 37th International MATADOR conference, Manchester, England, pp 231–234. doi:&#xA;                    10.1007/978-1-4471-4480-9&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR9" id="ref-link-section-d72010e1458">2012</a>) found that including the weight of the virtual objects affects the task completion time in bimanual virtual assembly tasks. Another interesting aspect to explore would be to examine the number of movements needed to assemble the part.</p><p>There is a marked challenge in comparing haptic and non-haptic devices that differ in a variety of different factors (workspace, accuracy, force feedback , etc.). These differences result in potential confounding variables that can be difficult to account for. The additional testing of other configurations of devices would be beneficial in understanding when it is appropriate to use certain configurations of devices. Additionally, it would be helpful to identify the factors that contribute to task difficulty. The lack of torsion feedback for the Phantom Omni could potentially have been a factor in task performance as well as participant device preference. Future testing could compare the 3DOF versus torsional force utilized during different types of assemblies by users.</p><p>The significant differences in task time between males and females is an interesting result. It could be due to the reported difference in computer experience between the genders or perhaps a difference in spatial ability. Gender differences in spatial ability has been identified in other studies. Men have been shown to score higher on spatial tests relative to women (Linn and Petersen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1985" title="Linn MC, Petersen AC (1985) Emergence and characterization of sex differences in spatial ability: a meta-analysis. Child Dev 56(6):1479–1498. &#xA;                    http://www.jstor.org/stable/1130467&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR16" id="ref-link-section-d72010e1467">1985</a>). The importance of spatial ability in virtual assembly needs further investigation.</p><p>There appears to be an incongruity between the time it took participants to put together the objects in the different treatments and their self-reported preference for hardware configurations. One would think that performance would be related to preference; however, participants seemed to predominantly prefer haptics and felt that it was quite beneficial in helping them assemble the objects. Why is it then that participants had a clear preference irrespective of their performance? One possible explanation is the misinformation effect.</p><p>The misinformation effect says that presenting information, whether correct or incorrect, between the encoding of an event and recall can influence the memory of the event and impair the ability to accurately recall details about it (Loftus and Hoffman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1989" title="Loftus EF, Hoffman HG (1989) Misinformation and memory: the creation of new memories. J Exp Psychol Gen 118(1):100–104. &#xA;                    http://psycnet.apa.org/psycinfo/1989-24881-001&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR17" id="ref-link-section-d72010e1477">1989</a>; Loftus et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1978" title="Loftus EF, Miller DG, Burns HJ (1978) Semantic integration of verbal information into a visual memory. J Exp Psychol Hum Learn Memory 4(1):19–31. &#xA;                    http://psycnet.apa.org/journals/xlm/4/1/19/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0290-z#ref-CR18" id="ref-link-section-d72010e1480">1978</a>). In this case, there was no purposeful misinformation provided to confuse participants but the constant changing of device configurations through switching hands and hardware may have been confusing to participants. Participants were told at the start of each task which device configuration they would be using; however, this misinformation effect may have influenced their memory of the treatments. In addition, because most participants did not have prior experience with virtual reality or haptic devices, the novelty of the devices could have played a role in determining what they remembered.</p></div></div></section><section aria-labelledby="Sec12"><div class="c-article-section" id="Sec12-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec12">Conclusion and future work</h2><div class="c-article-section__content" id="Sec12-content"><p>In an effort to evaluate the usefulness of five bimanual virtual assembly device configurations, a user study was performed. The results indicated that there were no significant differences in task completion times for the five bimanual configurations tested and that male participants had faster completion times than female participants. This may be attributed to a difference in computer experience between genders. Participants also indicated that haptic feedback was beneficial in their ability to assemble virtual products and the majority of the participants preferred using at least one haptic device.</p><p>There are additional variables that were not included in this study that we would like to examine in future work. In the present study, performance was measured by the time taken to perform the task. However, the motivation for the study was to evaluate a bimanual interface that includes haptics yet expands the ability to manipulate objects to an area larger than that of the haptic device. In addition, we wanted to give participants the flexibility to perform the task in their own desired way. To better evaluate the performance, it would be beneficial to save the location and orientation of the objects to determine how users are orienting and positioning the objects prior to insertion to see whether there are differences in the way they assemble parts when using different hardware configurations as well as how much of the workspace of the glove participants used. This additional information could be used in comparing the potential benefits of the expanded workspace enabled through glove interaction as compared to a haptic device with a smaller workspace. Another possible improvement would be to force the assembly process as a bimanual task that would require use of both hands at the same time. This might be a good configuration when addressing performance characteristics of the devices. The downside of forcing the user to use both hands like that is that the experience becomes less natural and may not necessarily mimic real-world assembly.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Balakrishnan R, Hinckley K (2000) Symmetric bimanual interaction. In: CHI ’00: proceedings of the SIGCHI confe" /><p class="c-article-references__text" id="ref-CR1">Balakrishnan R, Hinckley K (2000) Symmetric bimanual interaction. In: CHI ’00: proceedings of the SIGCHI conference on human factors in computing systems, ACM, New York, NY, USA, pp 33–40. doi:<a href="https://doi.org/10.1145/332040.332404">10.1145/332040.332404</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Balakrishnan R, Kurtenbach G (1999) Exploring bimanual camera control and object manipulation in 3D graphics i" /><p class="c-article-references__text" id="ref-CR2">Balakrishnan R, Kurtenbach G (1999) Exploring bimanual camera control and object manipulation in 3D graphics interfaces. In: CHI ’99: proceedings of the SIGCHI conference on human factors in computing systems, ACM, New York, NY, USA, pp 56–62. doi:<a href="https://doi.org/10.1145/302979.302991">10.1145/302979.302991</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bowman DA, Hodges LF (1997) An evaluation of techniques for grabbing and manipulating remote objects in immers" /><p class="c-article-references__text" id="ref-CR3">Bowman DA, Hodges LF (1997) An evaluation of techniques for grabbing and manipulating remote objects in immersive virtual environments. In: SI3D ’97: proceedings of the 1997 symposium on Interactive 3D graphics, ACM, New York, NY, USA, pp 35–ff. doi:<a href="https://doi.org/10.1145/253284.253301">10.1145/253284.253301</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Crossan A, Brewster S (2006) Two-handed navigation in a haptic virtual environment. In: CHI ’06 extended abstr" /><p class="c-article-references__text" id="ref-CR4">Crossan A, Brewster S (2006) Two-handed navigation in a haptic virtual environment. In: CHI ’06 extended abstracts on human factors in computing systems, ACM, New York, NY, USA, pp 676–681. doi:<a href="https://doi.org/10.1145/1125451.1125589">10.1145/1125451.1125589</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dominjon L, Lécuyer A, Burkhardt JM, Andrade-Barroso G, Richir S (2005) The “bubble” technique: interacting wi" /><p class="c-article-references__text" id="ref-CR5">Dominjon L, Lécuyer A, Burkhardt JM, Andrade-Barroso G, Richir S (2005) The “bubble” technique: interacting with large virtual environments using haptic devices with limited workspace. In: First joint eurohaptics conference and symposium on haptic interfaces for virtual environment, Pisa, Italy, pp 639–640. doi:<a href="https://doi.org/10.1109/WHC.2005.126">10.1109/WHC.2005.126</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Fiorentino, A. Uva, MD. Fabiano, G. Monno, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Fiorentino M, Uva A, Fabiano MD, Monno G (2010) Improving bi-manual 3D input in cad modelling by part rotation" /><p class="c-article-references__text" id="ref-CR6">Fiorentino M, Uva A, Fabiano MD, Monno G (2010) Improving bi-manual 3D input in cad modelling by part rotation optimisation. Comput Aided Des 42(5):462–470. doi:<a href="https://doi.org/10.1016/j.cad.2008.12.002">10.1016/j.cad.2008.12.002</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.cad.2008.12.002" aria-label="View reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Improving%20bi-manual%203D%20input%20in%20cad%20modelling%20by%20part%20rotation%20optimisation&amp;journal=Comput%20Aided%20Des&amp;doi=10.1016%2Fj.cad.2008.12.002&amp;volume=42&amp;issue=5&amp;pages=462-470&amp;publication_year=2010&amp;author=Fiorentino%2CM&amp;author=Uva%2CA&amp;author=Fabiano%2CMD&amp;author=Monno%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fischer AA, Vance JM (2003) Phantom haptic device implemented in a projection screen virtual environment. In: " /><p class="c-article-references__text" id="ref-CR7">Fischer AA, Vance JM (2003) Phantom haptic device implemented in a projection screen virtual environment. In: IPT/EGVE workshop proceedings. Zurich, Switzerland, pp 225–230</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Giachritsis C, Barrio J, Ferre M, Wing A, Ortego J (2009) Evaluation of weight perception during unimanual and" /><p class="c-article-references__text" id="ref-CR8">Giachritsis C, Barrio J, Ferre M, Wing A, Ortego J (2009) Evaluation of weight perception during unimanual and bimanual manipulation of virtual objects. In: World haptics 2009 - third joint EuroHaptics conference and symposium on Haptic interfaces for virtual environment and teleoperator systems, Salt Lake City, UT, pp 629–634</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="González-Badillo G, Medellín-Castillo H, Fletcher C, Lim T, Ritchie J, Garbaya S (2012) Effect of weight perce" /><p class="c-article-references__text" id="ref-CR9">González-Badillo G, Medellín-Castillo H, Fletcher C, Lim T, Ritchie J, Garbaya S (2012) Effect of weight perception on human performance in a haptic-enabled virtual assembly platform. In: 37th International MATADOR conference, Manchester, England, pp 231–234. doi:<a href="https://doi.org/10.1007/978-1-4471-4480-9">10.1007/978-1-4471-4480-9</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. Guiard, " /><meta itemprop="datePublished" content="1987" /><meta itemprop="headline" content="Guiard Y (1987) Asymmetric division of labor in human skilled bimanual action: the kinematic chain as a model." /><p class="c-article-references__text" id="ref-CR10">Guiard Y (1987) Asymmetric division of labor in human skilled bimanual action: the kinematic chain as a model. J Motor Behav 19(4):486–517</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F00222895.1987.10735426" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Asymmetric%20division%20of%20labor%20in%20human%20skilled%20bimanual%20action%3A%20the%20kinematic%20chain%20as%20a%20model&amp;journal=J%20Motor%20Behav&amp;volume=19&amp;issue=4&amp;pages=486-517&amp;publication_year=1987&amp;author=Guiard%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gunn C (2006) Collaborative virtual sculpting with haptic feedback. Virtual Real 10:73–83. doi:10.1007/s10055-" /><p class="c-article-references__text" id="ref-CR11">Gunn C (2006) Collaborative virtual sculpting with haptic feedback. Virtual Real 10:73–83. doi:<a href="https://doi.org/10.1007/s10055-006-0044-4">10.1007/s10055-006-0044-4</a>. <a href="http://portal.acm.org/citation.cfm?id=1164941.1164943">http://portal.acm.org/citation.cfm?id=1164941.1164943</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hinckley K, Pausch R, Proffitt D, Patten J, Kassell N (1997) Cooperative bimanual action. In: CHI ’97: proceed" /><p class="c-article-references__text" id="ref-CR12">Hinckley K, Pausch R, Proffitt D, Patten J, Kassell N (1997) Cooperative bimanual action. In: CHI ’97: proceedings of the SIGCHI conference on human factors in computing systems, ACM, pp 27–34. doi:<a href="https://doi.org/10.1145/258549.258571">10.1145/258549.258571</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Hinckley, R. Pausch, D. Proffitt, NF. Kassell, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Hinckley K, Pausch R, Proffitt D, Kassell NF (1998) Two-handed virtual manipulation. ACM Trans Comput Hum Inte" /><p class="c-article-references__text" id="ref-CR13">Hinckley K, Pausch R, Proffitt D, Kassell NF (1998) Two-handed virtual manipulation. ACM Trans Comput Hum Interact 5:260–302</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F292834.292849" aria-label="View reference 13">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Two-handed%20virtual%20manipulation&amp;journal=ACM%20Trans%20Comput%20Hum%20Interact&amp;volume=5&amp;pages=260-302&amp;publication_year=1998&amp;author=Hinckley%2CK&amp;author=Pausch%2CR&amp;author=Proffitt%2CD&amp;author=Kassell%2CNF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Isshiki M, Sezaki T, Akahane K, Hashimoto N, Sato M (2008) A proposal of a clutch mechanism for 6dof haptic de" /><p class="c-article-references__text" id="ref-CR14">Isshiki M, Sezaki T, Akahane K, Hashimoto N, Sato M (2008) A proposal of a clutch mechanism for 6dof haptic devices. In: Proceedings of the 18th international conference on artificial reality and telexistence, Yokohama, Japan, pp 57–63</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Kron, G. Schmidt, B. Petzold, M. Zah, P. Hinterseer, E. Steinbach, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Kron A, Schmidt G, Petzold B, Zah M, Hinterseer P, Steinbach E (2004) Disposal of explosive ordnances by use o" /><p class="c-article-references__text" id="ref-CR15">Kron A, Schmidt G, Petzold B, Zah M, Hinterseer P, Steinbach E (2004) Disposal of explosive ordnances by use of a bimanual haptic telepresence system. IEEE Int Conf Robot Autom 2:1968–1973. doi:<a href="https://doi.org/10.1109/ROBOT.2004.1308112">10.1109/ROBOT.2004.1308112</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Disposal%20of%20explosive%20ordnances%20by%20use%20of%20a%20bimanual%20haptic%20telepresence%20system&amp;journal=IEEE%20Int%20Conf%20Robot%20Autom&amp;doi=10.1109%2FROBOT.2004.1308112&amp;volume=2&amp;pages=1968-1973&amp;publication_year=2004&amp;author=Kron%2CA&amp;author=Schmidt%2CG&amp;author=Petzold%2CB&amp;author=Zah%2CM&amp;author=Hinterseer%2CP&amp;author=Steinbach%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Linn MC, Petersen AC (1985) Emergence and characterization of sex differences in spatial ability: a meta-analy" /><p class="c-article-references__text" id="ref-CR16">Linn MC, Petersen AC (1985) Emergence and characterization of sex differences in spatial ability: a meta-analysis. Child Dev 56(6):1479–1498. <a href="http://www.jstor.org/stable/1130467">http://www.jstor.org/stable/1130467</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Loftus EF, Hoffman HG (1989) Misinformation and memory: the creation of new memories. J Exp Psychol Gen 118(1)" /><p class="c-article-references__text" id="ref-CR17">Loftus EF, Hoffman HG (1989) Misinformation and memory: the creation of new memories. J Exp Psychol Gen 118(1):100–104. <a href="http://psycnet.apa.org/psycinfo/1989-24881-001">http://psycnet.apa.org/psycinfo/1989-24881-001</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Loftus EF, Miller DG, Burns HJ (1978) Semantic integration of verbal information into a visual memory. J Exp P" /><p class="c-article-references__text" id="ref-CR18">Loftus EF, Miller DG, Burns HJ (1978) Semantic integration of verbal information into a visual memory. J Exp Psychol Hum Learn Memory 4(1):19–31. <a href="http://psycnet.apa.org/journals/xlm/4/1/19/">http://psycnet.apa.org/journals/xlm/4/1/19/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RG. Marteniuk, CL. MacKenzie, DM. Baba, " /><meta itemprop="datePublished" content="1984" /><meta itemprop="headline" content="Marteniuk RG, MacKenzie CL, Baba DM (1984) Bimanual movement control: information processing and interaction e" /><p class="c-article-references__text" id="ref-CR19">Marteniuk RG, MacKenzie CL, Baba DM (1984) Bimanual movement control: information processing and interaction effects. Q J Exp Psychol 36(2):335–365</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F14640748408402163" aria-label="View reference 19">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Bimanual%20movement%20control%3A%20information%20processing%20and%20interaction%20effects&amp;journal=Q%20J%20Exp%20Psychol&amp;volume=36&amp;issue=2&amp;pages=335-365&amp;publication_year=1984&amp;author=Marteniuk%2CRG&amp;author=MacKenzie%2CCL&amp;author=Baba%2CDM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="McNeely WA, Puterbaugh KD, Troy JJ (1999) Six degree-of-freedom haptic rendering using voxel sampling. In: Pro" /><p class="c-article-references__text" id="ref-CR20">McNeely WA, Puterbaugh KD, Troy JJ (1999) Six degree-of-freedom haptic rendering using voxel sampling. In: Proceedings of the 26th annual conference on computer graphics and interactive techniques—SIGGRAPH ’99, ACM Press, New York, New York, USA, pp 401–408. doi:<a href="https://doi.org/10.1145/311535.311600">10.1145/311535.311600</a>. <a href="http://portal.acm.org/citation.cfm?doid=311535.311600">http://portal.acm.org/citation.cfm?doid=311535.311600</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="OpenSceneGraph (2013) Openscenegraph. http://www.openscenegraph.org&#xA;                        " /><p class="c-article-references__text" id="ref-CR21">OpenSceneGraph (2013) Openscenegraph. <a href="http://www.openscenegraph.org">http://www.openscenegraph.org</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Owen R, Kurtenbach G, Fitzmaurice G, Baudel T, Buxton B (2005) When it gets more difficult, use both hands: ex" /><p class="c-article-references__text" id="ref-CR22">Owen R, Kurtenbach G, Fitzmaurice G, Baudel T, Buxton B (2005) When it gets more difficult, use both hands: exploring bimanual curve manipulation. In: In GI 2005 proceedings, pp 17–24</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pavlik RA, Vance JM (2011a) Expanding haptic workspace for coupled-object manipulation. In: ASME 2011 world co" /><p class="c-article-references__text" id="ref-CR23">Pavlik RA, Vance JM (2011a) Expanding haptic workspace for coupled-object manipulation. In: ASME 2011 world conference on innovative virtual reality, ASME, Milan, Italy. doi:<a href="https://doi.org/10.1115/WINVR2011-5585">10.1115/WINVR2011-5585</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pavlik RA, Vance JM (2011b) VR JuggLua: a framework for VR applications combining Lua, OpenSceneGraph, and VR " /><p class="c-article-references__text" id="ref-CR24">Pavlik RA, Vance JM (2011b) VR JuggLua: a framework for VR applications combining Lua, OpenSceneGraph, and VR Juggler. In: Workshop on software engineering and architectures for realtime interactive systems (SEARIS) in IEEE virtual reality, Singapore</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pavlik RA, Vance JM (2015) Interacting with grasped objects in expanded haptic workspaces using the bubble tec" /><p class="c-article-references__text" id="ref-CR25">Pavlik RA, Vance JM (2015) Interacting with grasped objects in expanded haptic workspaces using the bubble technique. ASME J Comput Inf Sci Eng 1–7. doi:<a href="https://doi.org/10.1115/1.4031826">10.1115/1.4031826</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Peters, " /><meta itemprop="datePublished" content="1985" /><meta itemprop="headline" content="Peters M (1985) Constraints in the performance of bimanual tasks and their expression in unskilled and skilled" /><p class="c-article-references__text" id="ref-CR26">Peters M (1985) Constraints in the performance of bimanual tasks and their expression in unskilled and skilled subjects. Q J Exp Psychol 37(2):171–196</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F14640748508400929" aria-label="View reference 26">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Constraints%20in%20the%20performance%20of%20bimanual%20tasks%20and%20their%20expression%20in%20unskilled%20and%20skilled%20subjects&amp;journal=Q%20J%20Exp%20Psychol&amp;volume=37&amp;issue=2&amp;pages=171-196&amp;publication_year=1985&amp;author=Peters%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="I. Poupyrev, T. Ichikawa, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Poupyrev I, Ichikawa T (1999) Manipulating objects in virtual worlds: categorization and empirical evaluation " /><p class="c-article-references__text" id="ref-CR27">Poupyrev I, Ichikawa T (1999) Manipulating objects in virtual worlds: categorization and empirical evaluation of interaction techniques. J Vis Lang Comput 10(1):19–35. doi:<a href="https://doi.org/10.1006/jvlc.1998.0112">10.1006/jvlc.1998.0112</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1006%2Fjvlc.1998.0112" aria-label="View reference 27">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Manipulating%20objects%20in%20virtual%20worlds%3A%20categorization%20and%20empirical%20evaluation%20of%20interaction%20techniques&amp;journal=J%20Vis%20Lang%20Comput&amp;doi=10.1006%2Fjvlc.1998.0112&amp;volume=10&amp;issue=1&amp;pages=19-35&amp;publication_year=1999&amp;author=Poupyrev%2CI&amp;author=Ichikawa%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Shaw C, Green M (1994) Two-handed polygonal surface design. In: Proceedings of UIST 94. Marina del Rey, CA, pp" /><p class="c-article-references__text" id="ref-CR28">Shaw C, Green M (1994) Two-handed polygonal surface design. In: Proceedings of UIST 94. Marina del Rey, CA, pp 205–212</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Talvas A, Marchal M, Cirio G, Lécuyer A (2013) 3D interaction techniques for bimanual haptics in virtual envir" /><p class="c-article-references__text" id="ref-CR29">Talvas A, Marchal M, Cirio G, Lécuyer A (2013) 3D interaction techniques for bimanual haptics in virtual environments. In: Ferre GM (ed) Multi-finger haptic interaction. Springer series on touch and haptic systems, chap 3, pp 31–53</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Vélaz Y, Lozano-Rodero A, Suescun A, Gutiérrez T (2014) Natural and hybrid bimanual interaction for virtual as" /><p class="c-article-references__text" id="ref-CR30">Vélaz Y, Lozano-Rodero A, Suescun A, Gutiérrez T (2014) Natural and hybrid bimanual interaction for virtual assembly tasks. Virtual Real J 18(3):161–171. <a href="http://link.springer.com/article/10.1007">http://link.springer.com/article/10.1007</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="VRJuggler (2013) Vrjuggler. http://vrjuggler.org&#xA;                        " /><p class="c-article-references__text" id="ref-CR31">VRJuggler (2013) Vrjuggler. <a href="http://vrjuggler.org">http://vrjuggler.org</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Vyawahare VS, Stone RT (2012) Asymmetric interface and interactions for bimanual virtual assembly with haptics" /><p class="c-article-references__text" id="ref-CR32">Vyawahare VS, <b>Stone</b> RT (2012) Asymmetric interface and interactions for bimanual virtual assembly with haptics. In: Proceedings of the ASME 2012 international design engineering technical conferences and computers and information in engineering conference. ASME, Chicago, Illinois, pp 1–9</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Vyawahare VS, Stone RT (2013) Evaluation of bimanual stretched-string single object manipulation for virtual a" /><p class="c-article-references__text" id="ref-CR33">Vyawahare VS, Stone RT (2013) Evaluation of bimanual stretched-string single object manipulation for virtual assembly with haptics. In: Proceedings of the ASME 2013 international design engineering technical conferences and computers and information in engineering conference (IDETC/CIE 2013). ASME, Portland, Oregon, pp 1–10</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Vyawahare VS, Vance JM (2009) Human centered multimodal 3D user interface for desktop VR assembly. In: Proceed" /><p class="c-article-references__text" id="ref-CR34">Vyawahare VS, Vance JM (2009) Human centered multimodal 3D user interface for desktop VR assembly. In: Proceedings of the emerging technologies conference 2009, ETC</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-016-0290-z-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgments</h2><div class="c-article-section__content" id="Ack1-content"><p>This work was performed at the Virtual Reality Applications Center at Iowa State University as part of research funded by the National Science Foundation award CMMI-0928774.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Human-Computer Interaction, Iowa State University, 1620 Howe Hall, Ames, IA, 50011, USA</p><p class="c-article-author-affiliation__authors-list">Patrick Carlson, Judy M. Vance &amp; Meisha Berg</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Patrick-Carlson"><span class="c-article-authors-search__title u-h3 js-search-name">Patrick Carlson</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Patrick+Carlson&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Patrick+Carlson" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Patrick+Carlson%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Judy_M_-Vance"><span class="c-article-authors-search__title u-h3 js-search-name">Judy M. Vance</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Judy M.+Vance&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Judy M.+Vance" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Judy M.+Vance%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Meisha-Berg"><span class="c-article-authors-search__title u-h3 js-search-name">Meisha Berg</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Meisha+Berg&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Meisha+Berg" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Meisha+Berg%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-016-0290-z/email/correspondent/c1/new">Judy M. Vance</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=An%20evaluation%20of%20asymmetric%20interfaces%20for%20bimanual%20virtual%20assembly%20with%20haptics&amp;author=Patrick%20Carlson%20et%20al&amp;contentID=10.1007%2Fs10055-016-0290-z&amp;publication=1359-4338&amp;publicationDate=2016-07-07&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-016-0290-z" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-016-0290-z" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Carlson, P., Vance, J.M. &amp; Berg, M. An evaluation of asymmetric interfaces for bimanual virtual assembly with haptics.
                    <i>Virtual Reality</i> <b>20, </b>193–201 (2016). https://doi.org/10.1007/s10055-016-0290-z</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-016-0290-z.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-11-01">01 November 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-06-27">27 June 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-07-07">07 July 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-11">November 2016</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-016-0290-z" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-016-0290-z</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Haptic devices</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Virtual reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Interaction devices</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Interaction techniques</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Human–computer interaction (HCI)</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Bimanual interaction</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-016-0290-z.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=290;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

