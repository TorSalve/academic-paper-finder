<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="The affect of contact force sensations on user performance in virtual "/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="The development of a realistic virtual assembly environment is challenging because of the complexity of the physical processes and the limitation of available VR technology. Many research..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/11/4.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="The affect of contact force sensations on user performance in virtual assembly tasks"/>

    <meta name="dc.source" content="Virtual Reality 2007 11:4"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2007-05-09"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2007 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="The development of a realistic virtual assembly environment is challenging because of the complexity of the physical processes and the limitation of available VR technology. Many research activities in this domain primarily focused on particular aspects of the assembly task such as the feasibility of assembly operations in terms of interference between the manipulated parts. The virtual assembly environment reported in this research is focused on mechanical part assembly. The approach presented addresses the problem of part-to-part contacts during the mating phase of assembly tasks. The system described calculates contact force sensations by making their intensity dependent on the depth of penetration. However the penetration is not visible to the user who sees a separate model, which does not intersect the mating part model. The two 3D models of the part, the off-screen rendered model and the on-screen rendered model are connected by a spring-dumper arrangement. The force calculated is felt by the operator through the haptic interface when parts come in contact during the mating phase of the assembly task. An evaluation study investigating the effect of contact force sensation on user performance during part-to-part interface was conducted. The results showed statistically significant effect of contact force sensation on user performance in terms of task completion time. The subjective evaluation based on feedback from users confirmed that contact force sensation is a useful cue for the operator to find the relative positions of components in the final assembly state."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2007-05-09"/>

    <meta name="prism.volume" content="11"/>

    <meta name="prism.number" content="4"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="287"/>

    <meta name="prism.endingPage" content="299"/>

    <meta name="prism.copyright" content="2007 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-007-0075-5"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-007-0075-5"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-007-0075-5.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-007-0075-5"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="The affect of contact force sensations on user performance in virtual assembly tasks"/>

    <meta name="citation_volume" content="11"/>

    <meta name="citation_issue" content="4"/>

    <meta name="citation_publication_date" content="2007/10"/>

    <meta name="citation_online_date" content="2007/05/09"/>

    <meta name="citation_firstpage" content="287"/>

    <meta name="citation_lastpage" content="299"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-007-0075-5"/>

    <meta name="DOI" content="10.1007/s10055-007-0075-5"/>

    <meta name="citation_doi" content="10.1007/s10055-007-0075-5"/>

    <meta name="description" content="The development of a realistic virtual assembly environment is challenging because of the complexity of the physical processes and the limitation of availa"/>

    <meta name="dc.creator" content="Samir Garbaya"/>

    <meta name="dc.creator" content="U. Zaldivar-Colado"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=Proc IEEE Int Conf Syst Man Cybern; citation_title=A training system using virtual machines for teaching assembling/disassembling operations to novices.; citation_author=N Abe, JY Zhang, K Tanaka, H Taki; citation_volume=3; citation_publication_date=1996; citation_pages=2096-2101; citation_id=CR1"/>

    <meta name="citation_reference" content="Adams RJ, Hannaford B (1998) A two-port framework for the design of unconditionally stable haptic interfaces. In: Proceedings IROS, Anaheim, CA"/>

    <meta name="citation_reference" content="citation_journal_title=Human Factor; citation_title=Conceptualising in assembly tasks; citation_author=P Baggett, A Ehrenfeucht; citation_volume=30; citation_issue=3; citation_publication_date=1988; citation_pages=269-284; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Industr Ergon; citation_title=Building physical and mental models in assembly tasks; citation_author=P Baggett, A Ehrenfeucht; citation_volume=7; citation_issue=3; citation_publication_date=1991; citation_pages=217-227; citation_doi=10.1016/0169-8141(91)90005-7; citation_id=CR4"/>

    <meta name="citation_reference" content="Borst CW, Indugula P (2005) Realistic virtual grasping. In: Proceedings IEEE virtual reality conference (VR&#8217;05). Bonn, Germany, pp 91&#8211;98, 320"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=A spring model for whole-hand virtual grasping; citation_author=CW Borst, AP Indugula; citation_volume=15; citation_issue=1; citation_publication_date=2006; citation_pages=47-61; citation_doi=10.1162/pres.2006.15.1.47; citation_id=CR6"/>

    <meta name="citation_reference" content="Carmel R, Ullrich C, Silver J (2001) VirtualHand v2.5 programmer&#8217;s guide. Technical Report, Virtual Technologies"/>

    <meta name="citation_reference" content="Carpenter ID, Dewar RG, Ritchie JM, Simmons JEL (1996) Enhancing a virtual environment for manual assembly. In: Proceedings 12th international conference on CAD/CAM robotics and factories of the future, Middlesex University, UK, pp 1067&#8211;1072"/>

    <meta name="citation_reference" content="citation_journal_title=Robot Comput Integr Manuf; citation_title=A virtual reality-based experimentation environment for the verification of human-related factors in assembly processes.; citation_author=G Chryssolouris, D Mavrikios, D Fragos, V Karabatsou; citation_volume=16; citation_issue=4; citation_publication_date=2000; citation_pages=267-276; citation_doi=10.1016/S0736-5845(00)00013-2; citation_id=CR9"/>

    <meta name="citation_reference" content="Colgate JE, Grafing PE, Stanley MC, Schenkel G (1993) Implementation of stiff virtual walls in force-reflecting interfaces. In: Proceedings IEEE virtual reality annual international symposium (VRAIS), Seattle, WA, pp 202&#8211;208"/>

    <meta name="citation_reference" content="citation_title=Computer-aided mechanical assembly planning; citation_publication_date=1991; citation_id=CR11; citation_author=LS Homen Mello; citation_author=S Lee; citation_publisher=Kluwer"/>

    <meta name="citation_reference" content="citation_title=Computer aided assembly planning; citation_publication_date=1992; citation_id=CR12; citation_author=A Delchambre; citation_publisher=Chapman and Hall"/>

    <meta name="citation_reference" content="Dewar RG, Carpenter ID, Ritchie JM, Simmons JEL (1997) Assembly planning in a virtual environment. In: Proceedings PICMET&#8217;97, Portland, USA, pp 664&#8211;667"/>

    <meta name="citation_reference" content="Dewar RG (1998) Assembly plans from virtual environments. PhD Thesis, Heriot-Watt University, UK"/>

    <meta name="citation_reference" content="citation_journal_title=Exp Psychol; citation_title=The information capacity of the human motor system in controlling the amplitude of movement; citation_author=PM Fitts; citation_volume=47; citation_publication_date=1954; citation_pages=381-391; citation_doi=10.1037/h0055392; citation_id=CR15"/>

    <meta name="citation_reference" content="Garbaya S, Coiffet Ph, Blazevic P (2003) Experiments of assembly planning in virtual environment. In: Proceedings 5th IEEE international symposium on assembly and task planning (ISATP &#8216;03), France"/>

    <meta name="citation_reference" content="Garbaya S, Coiffet Ph, Blazevic P (2001) Integrating computerised assembly planning with virtual assembly environment. In: Proceedings virtual reality in mechanical and production engineering (VR-Mech&#8217;01). Brussels, Belgium"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Visual cues for perceiving distances from objects to surfaces.; citation_author=HH Hu, AA Gooch, SH Creem-regehr, WB Tompson; citation_volume=11; citation_publication_date=2002; citation_pages=652-664; citation_doi=10.1162/105474602321050758; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=Presence; citation_title=Experiments using multimodal virtual environments in design for assembly analysis; citation_author=R Gupta, T Sheridan, D Whitney; citation_volume=6; citation_issue=3; citation_publication_date=1997; citation_pages=318-338; citation_id=CR19"/>

    <meta name="citation_reference" content="citation_journal_title=Comput-Aid Des; citation_title=Prototyping and design for assembly analysis using multimodal virtual environments.; citation_author=R Gupta, D Whitney, D Zeltzer; citation_volume=29; citation_issue=8; citation_publication_date=1997; citation_pages=585-597; citation_doi=10.1016/S0010-4485(96)00093-0; citation_id=CR20"/>

    <meta name="citation_reference" content="citation_journal_title=Comput-Aid Des; citation_title=Virtual assembly using virtual reality techniques.; citation_author=S Jarayam, H Connacher, K Lyons; citation_volume=29; citation_issue=8; citation_publication_date=1997; citation_pages=575-584; citation_doi=10.1016/S0010-4485(96)00094-2; citation_id=CR21"/>

    <meta name="citation_reference" content="Kokkevis E, Metaxas D, Badler NI (1996) User-controlled physics-based animation for articulated figures. In: Proceedings Computer Animation, Geneva, Switzerland, pp 16&#8211;26"/>

    <meta name="citation_reference" content="Koutek M, Post FH (2001) Spring-based manipulation tools for virtual environments. In: Proceedings immersive projection technology and virtual environments. Springer, Stuttgart, pp 61&#8211;70"/>

    <meta name="citation_reference" content="McNeely W, Puterbaugh D, James J (1999) Six degrees-of-freedom haptic rendering using Voxel sampling. In: Proceedings SIGGRAPH 99, ISBN 020148-560-5, LA, CA, USA, pp 401&#8211;408"/>

    <meta name="citation_reference" content="citation_journal_title=Automatic; citation_title=Assembly research; citation_author=JL Nevins, DE Whitney; citation_volume=16; citation_publication_date=1980; citation_pages=595-613; citation_doi=10.1016/0005-1098(80)90003-5; citation_id=CR25"/>

    <meta name="citation_reference" content="Westenhofer W, Hahn J (1996) Using kinematic clones to control the dynamic simulation of articulated figures. In: Proceedings Computer Graphics International, Pohang, Korea, pp 26&#8211;37"/>

    <meta name="citation_reference" content="citation_journal_title=Ergonomics; citation_title=Virtual environments and ergonomics: needs and opportunities; citation_author=J R Wilson; citation_volume=40; citation_issue=10; citation_publication_date=1998; citation_pages=1057-1077; citation_doi=10.1080/001401397187603; citation_id=CR27"/>

    <meta name="citation_reference" content="Zachmann G, Rettig A (2001) Natural and robust interaction in virtual assembly simulation. In: Proceedings 8th ISPE international conference on concurrent engineering: research and applications. Anaheim, CA"/>

    <meta name="citation_reference" content="Zorriassatine F, Wykes R, Parkin R, Gindy N (2003) A survey of virtual prototyping techniques for mechanical product development. In: Proceedings Inst. Mech. Engineers. Part B: J Eng Manuf 217(4):513&#8211;530 "/>

    <meta name="citation_author" content="Samir Garbaya"/>

    <meta name="citation_author_email" content="garbaya@robot.uvsq.fr"/>

    <meta name="citation_author_institution" content="Robotics Laboratory of Versailles, The University of Versailles, Velizy, France"/>

    <meta name="citation_author" content="U. Zaldivar-Colado"/>

    <meta name="citation_author_institution" content="Robotics Laboratory of Versailles, The University of Versailles, Velizy, France"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-007-0075-5&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2007/10/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-007-0075-5"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="The affect of contact force sensations on user performance in virtual assembly tasks"/>
        <meta property="og:description" content="The development of a realistic virtual assembly environment is challenging because of the complexity of the physical processes and the limitation of available VR technology. Many research activities in this domain primarily focused on particular aspects of the assembly task such as the feasibility of assembly operations in terms of interference between the manipulated parts. The virtual assembly environment reported in this research is focused on mechanical part assembly. The approach presented addresses the problem of part-to-part contacts during the mating phase of assembly tasks. The system described calculates contact force sensations by making their intensity dependent on the depth of penetration. However the penetration is not visible to the user who sees a separate model, which does not intersect the mating part model. The two 3D models of the part, the off-screen rendered model and the on-screen rendered model are connected by a spring-dumper arrangement. The force calculated is felt by the operator through the haptic interface when parts come in contact during the mating phase of the assembly task. An evaluation study investigating the effect of contact force sensation on user performance during part-to-part interface was conducted. The results showed statistically significant effect of contact force sensation on user performance in terms of task completion time. The subjective evaluation based on feedback from users confirmed that contact force sensation is a useful cue for the operator to find the relative positions of components in the final assembly state."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>The affect of contact force sensations on user performance in virtual assembly tasks | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-007-0075-5","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Virtual assembly, Spring-damper model, Haptic interface, Human performance","kwrd":["Virtual_assembly","Spring-damper_model","Haptic_interface","Human_performance"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-007-0075-5","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-007-0075-5","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=75;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-007-0075-5">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            The affect of contact force sensations on user performance in virtual assembly tasks
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-007-0075-5.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-007-0075-5.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2007-05-09" itemprop="datePublished">09 May 2007</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">The affect of contact force sensations on user performance in virtual assembly tasks</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Samir-Garbaya" data-author-popup="auth-Samir-Garbaya" data-corresp-id="c1">Samir Garbaya<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="The University of Versailles" /><meta itemprop="address" content="grid.12832.3a, 0000000123230229, Robotics Laboratory of Versailles, The University of Versailles, 10-12 Avenue de l’Europe, 78140, Velizy, France" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-U_-Zaldivar_Colado" data-author-popup="auth-U_-Zaldivar_Colado">U. Zaldivar-Colado</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="The University of Versailles" /><meta itemprop="address" content="grid.12832.3a, 0000000123230229, Robotics Laboratory of Versailles, The University of Versailles, 10-12 Avenue de l’Europe, 78140, Velizy, France" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 11</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">287</span>–<span itemprop="pageEnd">299</span>(<span data-test="article-publication-year">2007</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">422 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">39 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-007-0075-5/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>The development of a realistic virtual assembly environment is challenging because of the complexity of the physical processes and the limitation of available VR technology. Many research activities in this domain primarily focused on particular aspects of the assembly task such as the feasibility of assembly operations in terms of interference between the manipulated parts. The virtual assembly environment reported in this research is focused on mechanical part assembly. The approach presented addresses the problem of part-to-part contacts during the mating phase of assembly tasks. The system described calculates contact force sensations by making their intensity dependent on the depth of penetration. However the penetration is not visible to the user who sees a separate model, which does not intersect the mating part model. The two 3D models of the part, the off-screen rendered model and the on-screen rendered model are connected by a spring-dumper arrangement. The force calculated is felt by the operator through the haptic interface when parts come in contact during the mating phase of the assembly task. An evaluation study investigating the effect of contact force sensation on user performance during part-to-part interface was conducted. The results showed statistically significant effect of contact force sensation on user performance in terms of task completion time. The subjective evaluation based on feedback from users confirmed that contact force sensation is a useful cue for the operator to find the relative positions of components in the final assembly state.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Global competition has forced manufacturers to reduce production cycles and increases product design agility. Generally, a manufacturing process is divided into product design, process design and assembly. Consequently assembly is an important sector in manufacturing industry. It constitutes the production bottleneck in many fields. About 40% of the cost of the European manufactured products is attributable to assembly. Assembly consists of putting parts together to create end products and is considered amongst the most complex processes in industry. It applies to some 20 different procedures that a human operator is able to perform when equipped with adequate tools. The human combines logic and perception of the environment, and has two sophisticated tools, the hands, to perform the task (Delchambre <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Delchambre A (1992) Computer aided assembly planning. Chapman and Hall, London" href="/article/10.1007/s10055-007-0075-5#ref-CR12" id="ref-link-section-d17466e293">1992</a>). Attempts to accelerate the process through the development of computer aided assembly planning systems have not, in general, been successful even when the design has been carried out using a modern CAD system (Homen De Mello and Lee <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Homen De Mello LS, Lee S (1991) Computer-aided mechanical assembly planning. Kluwer, Dordrecht, pp 217–242" href="/article/10.1007/s10055-007-0075-5#ref-CR11" id="ref-link-section-d17466e296">1991</a>). One of the main reasons for this lack of success is that assembly is dependent on a great deal of expert knowledge which has proved very difficult to formalize (Dewar et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Dewar RG, Carpenter ID, Ritchie JM, Simmons JEL (1997) Assembly planning in a virtual environment. In: Proceedings PICMET’97, Portland, USA, pp 664–667" href="/article/10.1007/s10055-007-0075-5#ref-CR13" id="ref-link-section-d17466e299">1997</a>; Nevins and Whitney (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1980" title="Nevins JL, Whitney DE (1980) Assembly research. Automatic 16:595–613" href="/article/10.1007/s10055-007-0075-5#ref-CR25" id="ref-link-section-d17466e302">1980</a>).</p><p>The problems facing conventional systems which generate assembly plans for manual operations are related to their limitation in the degree to which they prune down the combinatorial explosion of feasible sequences that are inevitably produced, they generally require human inputs (geometric constraint data) during the process of assembly sequence generation (Homen De Mello and Lee <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Homen De Mello LS, Lee S (1991) Computer-aided mechanical assembly planning. Kluwer, Dordrecht, pp 217–242" href="/article/10.1007/s10055-007-0075-5#ref-CR11" id="ref-link-section-d17466e308">1991</a>). A design system which minimizes the information acquisition overhead while maximizing information content is needed (Jarayam <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Jarayam S, Connacher H, Lyons K (1997) Virtual assembly using virtual reality techniques. Comput-Aid Des 29(8):575–584" href="/article/10.1007/s10055-007-0075-5#ref-CR21" id="ref-link-section-d17466e311">1997</a>). The significant advances in virtual reality technology enable more multidisciplinary approaches, notably virtual mechanical assembly operation and planning. Instead of abstract algorithmic assembly planning, an engineer can perform the assembly intuitively in virtual environment using VR hardware and software (Gupta et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997a" title="Gupta R, Sheridan T, Whitney D (1997a) Experiments using multimodal virtual environments in design for assembly analysis. Presence 6(3):318–338" href="/article/10.1007/s10055-007-0075-5#ref-CR19" id="ref-link-section-d17466e314">1997a</a>).</p><p>Virtual assembly is based on the use of computer generated environment to perform the task of assembling 3D models of parts. The first objective is to test the feasibility of assembly operations at the design stage of the product. Product assemblability can be tested and optimized by refining the design without the requirement to build physical prototypes (Zorriassatine et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Zorriassatine F, Wykes R, Parkin R, Gindy N (2003) A survey of virtual prototyping techniques for mechanical product development. In: Proceedings Inst. Mech. Engineers. Part B: J Eng Manuf 217(4):513–530 " href="/article/10.1007/s10055-007-0075-5#ref-CR29" id="ref-link-section-d17466e320">2003</a>).</p><p>The second objective of virtual assembly is to generate a product assembly plan at its design stage. This approach allows proactive production planning in terms of resource allocation, assembly time and cost estimation and assembly operators’ training before producing real products. The planning and cost estimation of maintenance operations can be made at the design stage of the product. Virtual assembly offers the advantage of training assembly personnel by conducting assembly manipulation trials using digital mockup of the product. The overall objective of using virtual reality technology in product assembly planning and operation is the shortening in the product development cycle; hence reducing the all important time-to-market (Garbaya et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Garbaya S, Coiffet Ph, Blazevic P (2003) Experiments of assembly planning in virtual environment. In: Proceedings 5th IEEE international symposium on assembly and task planning (ISATP ‘03), France" href="/article/10.1007/s10055-007-0075-5#ref-CR16" id="ref-link-section-d17466e326">2003</a>).</p><p>Virtual reality (VR) offers different interaction strategies; however, each virtual task requires a specific interaction technique tailored to the type of activity to carry out in the virtual environment. The perception of the user and human related factors are considered important issues in the validation of any application using virtual reality technology.</p><p>The research reported here focuses on aspects related to human performance during the execution of virtual assembly tasks. In this framework, a spring-damper modelling technique was used to represent the “visual dynamic” behaviour of parts in the mating phase of assembly operations.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Related work</h2><div class="c-article-section__content" id="Sec2-content"><p>Since the emergence of VR technology, many academic and industrial research groups are interested in the application of VR in assembly planning and operation.</p><p>Jayaram et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Jarayam S, Connacher H, Lyons K (1997) Virtual assembly using virtual reality techniques. Comput-Aid Des 29(8):575–584" href="/article/10.1007/s10055-007-0075-5#ref-CR21" id="ref-link-section-d17466e344">1997</a>) developed a virtual assembly design environment “VADE” that allows an engineer to test parts’ tolerances, select optimal assembly sequence, generate assembly and disassembly plans of mechanical systems early in their design phase. The VADE project aimed at developing a system that aids assembly planning, design for assembly and design for maintainability.</p><p>Gupta et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997b" title="Gupta R, Whitney D, Zeltzer D (1997b) Prototyping and design for assembly analysis using multimodal virtual environments. Comput-Aid Des 29(8):585–597" href="/article/10.1007/s10055-007-0075-5#ref-CR20" id="ref-link-section-d17466e350">1997b</a>) carried out a study focusing on the use VR in mechanical assembly task. They investigated the differences between assembly completion times in real and virtual environment. Their performance evaluation study was based on the handling and insertion times for a peg-in-a-hole task. The task was performed using either a PHANTOM force-feedback device to manipulate a virtual peg, or a real peg into a hole. The real and virtual tasks have the same size, weight, frictional characteristics and index of difficulty as defined by Fitts’ law (Fitts <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1954" title="Fitts PM (1954) The information capacity of the human motor system in controlling the amplitude of movement. Exp Psychol 47:381–391" href="/article/10.1007/s10055-007-0075-5#ref-CR15" id="ref-link-section-d17466e353">1954</a>). The authors reported that task-completion times in multi-modal virtual environment were approximately twice that of the real world. The results showed that the provision of force feedback improved the user performance, particularly in the insertion phase of assembly task (assembly times were increased by a factor of 1.3 with the absence of force feedback).</p><p>Carpenter et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Carpenter ID, Dewar RG, Ritchie JM, Simmons JEL (1996) Enhancing a virtual environment for manual assembly. In: Proceedings 12th international conference on CAD/CAM robotics and factories of the future, Middlesex University, UK, pp 1067–1072" href="/article/10.1007/s10055-007-0075-5#ref-CR8" id="ref-link-section-d17466e359">1996</a>) developed a virtual assembly system that caters for the collisions between parts to be assembled. To assemble parts, they developed collision snapping and proximity snapping where an immersive toolbox was used interactively in order to define contact relationships between the colliding objects.</p><p>Abe et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Abe N, Zhang JY, Tanaka K, Taki H (1996) A training system using virtual machines for teaching assembling/disassembling operations to novices. Proc IEEE Int Conf Syst Man Cybern 3:2096–2101" href="/article/10.1007/s10055-007-0075-5#ref-CR1" id="ref-link-section-d17466e366">1996</a>) developed an immersive virtual training system in which a novice operator is trained to perform an assembly task. The system integrates spoken commands that indicate to the user which part should be selected in order to complete the assembly sequence. The directions of parts travel are represented by auxiliary lines (lines decrease when the part is assembled and increase when the part is disassembled). The operator is instructed to stop moving a part when the assembly position is reached, and the next part requiring assembly is indicated. The system is purely dedicated for training and the operator has to follow predetermined behaviour.</p><p>Garbaya et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Garbaya S, Coiffet Ph, Blazevic P (2001) Integrating computerised assembly planning with virtual assembly environment. In: Proceedings virtual reality in mechanical and production engineering (VR-Mech’01). Brussels, Belgium" href="/article/10.1007/s10055-007-0075-5#ref-CR17" id="ref-link-section-d17466e372">2001</a>) developed a virtual environment for design an assembly planning (VEDAP) based on the approach of integrating computer-aided assembly planning system (CAAP) called Motech™ with a virtual assembly environment. This integration was motivated by the fact that most CAAP systems did not achieve to perform robust geometric reasoning in conformity with precedence constraints. The system integrates audio feedback cues associated with the collision detection algorithm and swept volume generation for moving parts. Assembly trials carried out in virtual environment allow the identification of precedence relationships that are communicated to the CAAP system in order to build the AND/OR graph of the product. The operator conducts the assembly task in virtual environment and observes the progress of the decomposition sequence being generated by the CAAP system. This approach provided the operator with the product structure cue that improved his performance in executing the assembly task.</p><p>Natural interaction and virtual environment realism have an important affect on human performance during assembly task execution (Zachmann and Rettig <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Zachmann G, Rettig A (2001) Natural and robust interaction in virtual assembly simulation. In: Proceedings 8th ISPE international conference on concurrent engineering: research and applications. Anaheim, CA" href="/article/10.1007/s10055-007-0075-5#ref-CR28" id="ref-link-section-d17466e378">2001</a>). Physical behaviour of virtual objects and haptic sensation play important role in human perception (Gupta et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997b" title="Gupta R, Whitney D, Zeltzer D (1997b) Prototyping and design for assembly analysis using multimodal virtual environments. Comput-Aid Des 29(8):585–597" href="/article/10.1007/s10055-007-0075-5#ref-CR20" id="ref-link-section-d17466e381">1997b</a>). During the termination phase of an assembly operation, part-to-part interface take place to locate parts such that the relative position and orientation of assembled parts correspond to the final assembly state. While the user is manipulating a part to get it close enough to another part for joining to take place, 3D models of parts pass through each other. This is visually distracting to the user and does not occur with physical objects in real world.</p><p>When the operator manipulates mechanical parts in a virtual environment (VE), virtual hand behaviour represents the operator’s real hand actions, hence his presence in the VE. Physically-based modelling intends to include real world functionalities in VEs. For example, object grasping can be carried out without having the visually distracting hand passing through 3D models of parts. This approach allowed a suitable solution for simple virtual scenes but the computation load is very important for complex virtual environments made of large number of objects. Different techniques were developed in order to solve this problem.</p><p>Borst and Indugula (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Borst CW, Indugula P (2005) Realistic virtual grasping. In: Proceedings IEEE virtual reality conference (VR’05). Bonn, Germany, pp 91–98, 320" href="/article/10.1007/s10055-007-0075-5#ref-CR5" id="ref-link-section-d17466e389">2005</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Borst CW, Indugula AP (2006) A spring model for whole-hand virtual grasping. Presence Teleoperators Virtual Environ 15(1):47–61" href="/article/10.1007/s10055-007-0075-5#ref-CR6" id="ref-link-section-d17466e392">2006</a>) developed a spring model for virtual grasping that couples tracked hand configuration to a virtual hand model controlled by physical simulation. The spring model consists of 21 torsional spring-dampers and 6 linear spring-dampers. They used one torsional element for each of the 20 hand model joint angles, one torsional element and one linear element for the base of the hand, and one linear element for each of the five fingertips. This model allowed the formulation of a new force rendering equation that uses the forces and torques of the spring model to render forces for haptic feedback gloves. Their approach allowed whole-hand grasping and manipulation of virtual objects while preventing hand/object interpenetration but did not include the object–object interface.</p><p>McNeely et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="McNeely W, Puterbaugh D, James J (1999) Six degrees-of-freedom haptic rendering using Voxel sampling. In: Proceedings SIGGRAPH 99, ISBN 020148-560-5, LA, CA, USA, pp 401–408" href="/article/10.1007/s10055-007-0075-5#ref-CR24" id="ref-link-section-d17466e398">1999</a>) published a work about a voxel-based approach to 6-DOF haptic rendering that enables the manipulation of rigid objects within a complex environment of static rigid objects. The system renders a short-range force field surrounding the static objects, which repels the manipulated object and maintains a voxel-scale minimum separation distance that precludes exact surface interpenetration. The size of the moving object (i.e. the number of points in the point shell) is limited by the processor speed and the size of the static environment is limited by the memory.</p><p>A force model was developed using the interaction of the moving object’s surface normals with the static voxmap to create forces and torques. In order to enhance haptic stability of force rendering they used what is called the “virtual coupler” scheme in which a 6-DOF spring-damper connects the user’s haptic motions with the motions of the dynamic object in the virtual scene. The system was tested by haptically rendering the motion of the dynamic object “a small teapot” through simulated aircraft geometry, with beams, tubes, wires, etc., voxelised at 5 mm resolution. The authors reported that the implementation of this approach on a 6-DOF haptic device showed acceptable manipulation performance in terms of force and torque rendering provided that the task tolerates voxel-level accuracy. However, the paper did not mention applications in mechanical assembly that involve parts’ mating.</p><p>Dewar (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Dewar RG (1998) Assembly plans from virtual environments. PhD Thesis, Heriot-Watt University, UK" href="/article/10.1007/s10055-007-0075-5#ref-CR14" id="ref-link-section-d17466e407">1998</a>) developed proximity snapping as a tool for mating parts together in virtual assembly planning system called Unbelievable Vehicle for Assembling Virtual Units (UVAVU). According to the description of this system, based on dVISE™ software, the grasped object is snapped to its mating object if the differences between their positions are within certain tolerances of the values they have in their final assembled state. Haptic feedback was not included in this system since the operator manipulates components by following valid routes in order to satisfy precedence relationship rules.</p><p>Garbaya et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Garbaya S, Coiffet Ph, Blazevic P (2003) Experiments of assembly planning in virtual environment. In: Proceedings 5th IEEE international symposium on assembly and task planning (ISATP ‘03), France" href="/article/10.1007/s10055-007-0075-5#ref-CR16" id="ref-link-section-d17466e413">2003</a>) used event based modelling to represent part grasping. Their approach is based on collision detection and event-action mode of behaviour. When a collision is detected between the virtual hand and the 3D model of the part, the system sends a hand-close action that animates the virtual hand in order to produce grasping posture and stops hand movement. This metaphoric representation of grasping is used when neither physically based behaviour nor haptic rendering are included in virtual assembly environment. Part-to-part interfacing used the technique of sending collision events to position parts in final assembly positions and orientations, defined in the CAD system during the design of parts. The interaction was visual- and auditory-based feedback and did not include haptic rendering.</p><p>Koutek and Post (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Koutek M, Post FH (2001) Spring-based manipulation tools for virtual environments. In: Proceedings immersive projection technology and virtual environments. Springer, Stuttgart, pp 61–70" href="/article/10.1007/s10055-007-0075-5#ref-CR23" id="ref-link-section-d17466e419">2001</a>) developed a system called spring-fork tools to control translational and rotational motions of virtual objects. By attaching the springs to the virtual part and performing 6-DOF motion in VE, the user can perceive the illusion of mass and substance. The experimental study consisted of manipulating boxes and spheres and showed that this spring-based manipulation tool allowed realistic visual force feedback.</p><p>Virtual grasping occurs at the beginning of an assembly operation. It is performed before part-to-part interfacing and deals with the interface between the virtual hand and the virtual parts. When the virtual part is grasped and moved by the user’s hand close to another part or subassembly for the joining phase, called the parts’ mating phase of the assembly task, and part-to-part interfacing occurs. Realistic contact between parts is required in order to locate parts in final assembly position and orientation. This sequence of actions occurs when the assembly task is carried out in real world.</p><p>In order to obtain realistic dynamic behaviour during the contact between virtual parts a spring-damper model was adopted based on using an artificial coupling between the haptic display and the VE. This technique was originally proposed by Colgate et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Colgate JE, Grafing PE, Stanley MC, Schenkel G (1993) Implementation of stiff virtual walls in force-reflecting interfaces. In: Proceedings IEEE virtual reality annual international symposium (VRAIS), Seattle, WA, pp 202–208" href="/article/10.1007/s10055-007-0075-5#ref-CR10" id="ref-link-section-d17466e427">1993</a>) and recently elaborated by Adams and Hannaford (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Adams RJ, Hannaford B (1998) A two-port framework for the design of unconditionally stable haptic interfaces. In: Proceedings IROS, Anaheim, CA" href="/article/10.1007/s10055-007-0075-5#ref-CR2" id="ref-link-section-d17466e430">1998</a>). Borst and Indugula (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Borst CW, Indugula P (2005) Realistic virtual grasping. In: Proceedings IEEE virtual reality conference (VR’05). Bonn, Germany, pp 91–98, 320" href="/article/10.1007/s10055-007-0075-5#ref-CR5" id="ref-link-section-d17466e433">2005</a>) applied the technique of a spring-damper model to the virtual hand in order to produce virtual realistic grasping. Our approach is mainly based on the spring-damper model but focuses on part-to-part interfacing and contact force rendering during the mating phase of the virtual mechanical parts assembly in the VE. Each part of the mechanical system to be assembled is represented in the VE by two 3D models coupled by a virtual linear spring and a virtual torsional spring. These models are called the tracked part and the visual part [analogous to the tracked hand and the visual hand developed in Borst and Indugula (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Borst CW, Indugula P (2005) Realistic virtual grasping. In: Proceedings IEEE virtual reality conference (VR’05). Bonn, Germany, pp 91–98, 320" href="/article/10.1007/s10055-007-0075-5#ref-CR5" id="ref-link-section-d17466e436">2005</a>)]. During the manipulation of parts, the tracked part follows the operator hand’s position and orientation. The visual part is the rendered 3D model of the part in the virtual scene. It mimics real part dynamic behaviour during the mating phase. The tracked part is an off-screen rendered model used to compute the contact force between parts.</p><p>In the following section of this paper, the software architecture and the techniques used in modelling the virtual assembly environment are presented. The dynamic modelling based on the concept of spring damper model to represent the dynamic behaviour of parts during part-to-part interface is detailed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0075-5#Sec7">4</a>. The force feedback system used for virtual assembly task execution is described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0075-5#Sec10">5</a>. The technique used to formulate the contact force equation is presented in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0075-5#Sec11">6</a>. In order to evaluate the effect of the contact force sensation on user performance, an experimental study was conducted. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0075-5#Sec12">7</a> presents the experimental work and the analysis of the obtained results. Finally, the conclusion and research perspectives are given in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0075-5#Sec20">8</a>.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig1_HTML.jpg" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Virtual assembly system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     </div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">System architecture</h2><div class="c-article-section__content" id="Sec3-content"><p>The software used to develop the virtual assembly environment runs on a PC workstation with dual 2.6 GHz Xeon processors and NVIDIA QUADRO FX1000 graphics card with 128 MB of video RAM. The virtual assembly software environment was created using the Virtual Hand Toolkit™ (VHT) developed by the Immersion Corporation, the PhysX engine from Ageia™ and used the SolidWorks CAD software for 3D modelling of parts. Virtual parts are created by the automatic conversion of CAD files to polygonal mesh. The 3D interaction device used in this work is made of a CyberGlove™ for hand animation in the virtual scene and a CyberGrasp™ and CyberForce™ system from Immersion Corporation for the haptic rendering (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0075-5#Fig2">2</a>).
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>System architecture</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <h3 class="c-article__sub-heading" id="Sec4">Virtual object modelling</h3><p>Virtual parts and objects are created in the CAD system and then converted into a polygonal mesh for visualization in the VE using OpenGL render. The VE is made of a room, a work table, the virtual hand representing the user presence in VE, and the parts of the product to assemble.</p><p>Special texture is mapped on the floor of the virtual room and shadows projection is included in order to enhance the realism of the VE as described in Hu et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Hu HH, Gooch AA, Creem-regehr SH, Tompson WB (2002) Visual cues for perceiving distances from objects to surfaces. Presence Teleoperators Virtual Environ 11:652–664" href="/article/10.1007/s10055-007-0075-5#ref-CR18" id="ref-link-section-d17466e515">2002</a>).</p><p>The virtual hand is composed of 16 triangle-based geometry shapes to represent three phalanxes per finger and the palm. A 22-sensor CyberGlove™ is used to track the operator’s real hand kinematics and represent the virtual hand accordingly (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0075-5#Fig1">1</a>). The mechanical product created in the virtual environment is a transmission system made of eight virtual mechanical parts (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0075-5#Fig3">3</a>a, b).
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>
                                       <b>a</b> Virtual assembly environment, <b>b</b> Transmission system created in CAD system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec5">Mechanical parts representation</h3><p>Virtual parts are created in the Solidworks CAD system and the CAD files converted to polygonal mesh files for visualization in the VE. The collision detection system incorporated in Virtual Hand Toolkit™ is based on V-CLIP algorithm and is restricted to convex shapes. VHT creates equivalent convex shapes for parts having non-convex shapes. Parts with non-convex shapes are created in the freely available software PhysX™ (<a href="http://www.ageia.com">http://www.ageia.com</a>). This system provides better support for polygon meshes. It includes convex and non-convex shape collision detection based on the bounding volume technique and includes physically-based behaviour of virtual parts. The source code of this software is not available and minimal information is known about the approaches it uses.</p><p>Since our approach is based on attaching the two 3D models of each part by a virtual linear spring and tortional spring, each part is represented in virtual environment by the tracked part and the visual part. The tracked part belongs to the VirtualHand software toolkit (VHT) and the visual part belongs to PhysX™ software.</p><p>During the manipulation of virtual parts, the virtual scene is made of PhysX shapes only. It is visualized using OpenGL render. VHT convex shapes are off-screen rendered objects. They are included for the implementation of the spring-damper model to render realistic parts behaviour and contact force sensation during the mating phase of assembly operations (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0075-5#Fig4">4</a>a, b).
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig4_HTML.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig4_HTML.jpg" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>
                                       <b>a</b> Non-convex shapes of parts, <b>b</b> convex shapes of parts</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec6">Virtual hand representation</h3><p>The visually distracting affect of parts’ interpenetration can occur between the virtual hand and the virtual part. The realistic grasping problem has been addressed in graphics research using virtual springs to drive dynamic simulations based on human input (Kokkevis et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Kokkevis E, Metaxas D, Badler NI (1996) User-controlled physics-based animation for articulated figures. In: Proceedings Computer Animation, Geneva, Switzerland, pp 16–26" href="/article/10.1007/s10055-007-0075-5#ref-CR22" id="ref-link-section-d17466e608">1996</a>; Westenhofer and Hahn <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Westenhofer W, Hahn J (1996) Using kinematic clones to control the dynamic simulation of articulated figures. In: Proceedings Computer Graphics International, Pohang, Korea, pp 26–37" href="/article/10.1007/s10055-007-0075-5#ref-CR26" id="ref-link-section-d17466e611">1996</a>). Different approaches using the same concept were developed in order to produce the most natural grasping simulation (Borst and Indugula <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Borst CW, Indugula P (2005) Realistic virtual grasping. In: Proceedings IEEE virtual reality conference (VR’05). Bonn, Germany, pp 91–98, 320" href="/article/10.1007/s10055-007-0075-5#ref-CR5" id="ref-link-section-d17466e614">2005</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Borst CW, Indugula AP (2006) A spring model for whole-hand virtual grasping. Presence Teleoperators Virtual Environ 15(1):47–61" href="/article/10.1007/s10055-007-0075-5#ref-CR6" id="ref-link-section-d17466e617">2006</a>). The virtual assembly environment can include small and large parts with heavy weights. Small parts are graspable but big parts are manipulated using metaphors and toolboxes (Jarayam <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Jarayam S, Connacher H, Lyons K (1997) Virtual assembly using virtual reality techniques. Comput-Aid Des 29(8):575–584" href="/article/10.1007/s10055-007-0075-5#ref-CR21" id="ref-link-section-d17466e620">1997</a>). Exact representation of parts’ grasping is not the main objective of the work presented in this paper. A simple approach is proposed which allows the rendering of a visual feedback different from the exact representation of real hand configuration but that is sufficiently convincing to the user.</p><p>In our approach, the virtual hand is represented by two models, the tracked hand model and the visual hand model. The tracked model is created by default in VHT library and used by the VHT engine. The spatial configuration of this hand model is obtained implicitly in this library using data input from the 22 sensor-glove. The VHT engine can report collision detection information between the tracked hand model and objects in the 3D scene. VHT library allows object grasping when the virtual hand collides with 3D shapes; the phalanxes and the palm generate collision information and surface normal at collision points. If the surface normal provides a pre-fixed friction value, the component is attached to the virtual hand (Carmel et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Carmel R, Ullrich C, Silver J (2001) VirtualHand v2.5 programmer’s guide. Technical Report, Virtual Technologies" href="/article/10.1007/s10055-007-0075-5#ref-CR7" id="ref-link-section-d17466e626">2001</a>).</p><p>The visual hand model is explicitly created in the PhysX engine by 16 polygonal shapes representing the 15 phalanxes and the palm of the hand. This hand model and the tracked hand have the same spatial configuration. Before grasping takes place, both hand models (the visual hand and the tracked hand) have the same position and orientation. They appear as one model of the hand (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0075-5#Fig5">5</a>b). The visual hand follows the tracked hand and reproduces the same position and orientation without passing through the visual part. The visual hand is attached to the visual part whilst keeping the geometric configuration posture of grasping of the overlapped hand models at the moment when a collision with the visual part is detected.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig5_HTML.jpg?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig5_HTML.jpg" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Representation of the tracked and the visual hand before grasping (<b>a</b>) and after grasping (<b>b</b>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>In order to provide the user with force feedback sensation during parts’ manipulation, the VHT engine uses the penetration distance of the tracked hand into the visual part to calculate the grasping forces sent to the CyberGrasp system (Carmel et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Carmel R, Ullrich C, Silver J (2001) VirtualHand v2.5 programmer’s guide. Technical Report, Virtual Technologies" href="/article/10.1007/s10055-007-0075-5#ref-CR7" id="ref-link-section-d17466e663">2001</a>). The penetration of the tracked hand model into the visual part is not rendered on the screen. This technique was implemented by recording the position and orientation of the tracked hand when grasping is initiated and by applying appropriate transformations to the visual hand relative to the world’s frame of reference.</p></div></div></section><section aria-labelledby="Sec7"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7">Part-to-part interface</h2><div class="c-article-section__content" id="Sec7-content"><p>During the mating phase, the contact between the parts must have a dynamic behaviour that represents the interaction between physical parts in real world. In order to provide the user with this sensation of realism, the concept of coupling the visual part and the tracked part by a system of virtual linear and torsional spring-dampers was adopted (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0075-5#Fig6">6</a>a, b). This technique is inspired from the use of virtual springs to couple a dynamic hand simulation to the tracked hand configuration in order to perform realistic whole hand grasping developed by Borst and Indugula (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Borst CW, Indugula P (2005) Realistic virtual grasping. In: Proceedings IEEE virtual reality conference (VR’05). Bonn, Germany, pp 91–98, 320" href="/article/10.1007/s10055-007-0075-5#ref-CR5" id="ref-link-section-d17466e678">2005</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Borst CW, Indugula AP (2006) A spring model for whole-hand virtual grasping. Presence Teleoperators Virtual Environ 15(1):47–61" href="/article/10.1007/s10055-007-0075-5#ref-CR6" id="ref-link-section-d17466e681">2006</a>) and the “virtual coupler” scheme originally proposed by Colgate et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Colgate JE, Grafing PE, Stanley MC, Schenkel G (1993) Implementation of stiff virtual walls in force-reflecting interfaces. In: Proceedings IEEE virtual reality annual international symposium (VRAIS), Seattle, WA, pp 202–208" href="/article/10.1007/s10055-007-0075-5#ref-CR10" id="ref-link-section-d17466e684">1993</a>).
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>
                                    <b>a</b> Linear spring damper model, <b>b </b>Torsional Spring-Damper</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>In coupling the visual part and the tracked part by virtual springs, realistic manipulation of parts is obtained by visually preventing 3D models to pass through each other. Contact force rendering is computed using the penetration value of the tracked model of the grasped part into its mating part (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-007-0075-5#Sec11">6</a>). The spring-damper model is made of the visual part and the tracked part linked by one torsional spring-damper and one linear spring-damper.</p><p>When the user moves a part, the visual part tends to follow the tracked part. Collision detection and the associated response prevent the visual part from penetrating into other objects in the scene.</p><h3 class="c-article__sub-heading" id="Sec8">Torsional and linear springs</h3><p>The visual part is controlled by both torsional and linear spring-dampers so that it keeps following the tracked part grasped by the operator. For the calculation of the force and torque, the same computation model developed in (Borst and Indugula <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Borst CW, Indugula P (2005) Realistic virtual grasping. In: Proceedings IEEE virtual reality conference (VR’05). Bonn, Germany, pp 91–98, 320" href="/article/10.1007/s10055-007-0075-5#ref-CR5" id="ref-link-section-d17466e727">2005</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Borst CW, Indugula AP (2006) A spring model for whole-hand virtual grasping. Presence Teleoperators Virtual Environ 15(1):47–61" href="/article/10.1007/s10055-007-0075-5#ref-CR6" id="ref-link-section-d17466e730">2006</a>) was adopted. The linear spring-damper produces a translational force that we call the linear component <i>F</i>. The direction is oriented to the centre of mass of the tracked part. </p><div id="Equa" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$ F = k_{{\text{T}}} {\left( {p_{{\text{t}}} - p_{{\text{v}}} } \right)} - b_{{\text{T}}} {\left( {v_{{\text{v}}} - v_{{\text{t}}} } \right)} $$</span></div></div><p>where:<dl class="c-abbreviation_list"><dt class="c-abbreviation_list__term"><dfn>
                        <i>F</i>
                      :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>is the force applied to the visual part in order to follow the tracked part by performing translational movement.</p>
                      </dd><dt class="c-abbreviation_list__term"><dfn>
                        <i>k</i>
                        <sub>T</sub>
                      :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>is the translational spring constant.</p>
                      </dd><dt class="c-abbreviation_list__term"><dfn>
                        <i>b</i>
                        <sub>T</sub>
                      :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>is the translational damping constant.</p>
                      </dd><dt class="c-abbreviation_list__term"><dfn>
                        <i>p</i>
                        <sub>t</sub>
                        <i>, p</i>
                        <sub>v</sub>
                      :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>are the positions of the tracked and visual parts.</p>
                      </dd><dt class="c-abbreviation_list__term"><dfn>
                        <i>v</i>
                        <sub>t</sub>
                        <i>, v</i>
                        <sub>v</sub>
                      :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>are the velocities of the tracked and visual parts.</p>
                      </dd></dl>The values of <i>k</i>
                           <sub>T</sub> and <i>b</i>
                           <sub>T</sub> are obtained empirically by testing different values until stable and smooth dynamic behaviour of the visual part is obtained. </p><div id="Equb" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$ v_{{\text{v}}} = \frac{{p^{k}_{{\text{v}}} - p^{{k - 1}}_{{\text{v}}} }} {{\Delta t}}\quad {\text{and}}\,v_{{\text{t}}} = \frac{{p^{k}_{{\text{t}}} - p^{{k - 1}}_{{\text{t}}} }} {{\Delta t}} $$</span></div></div><p>where:<dl class="c-abbreviation_list"><dt class="c-abbreviation_list__term"><dfn>
                                    <span class="mathjax-tex">\( p^{k}_{{\text{v}}} \)</span> and <span class="mathjax-tex">\( p^{k}_{{\text{t}}} \)</span>
                                 :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>are the current position of the visual part and the tracked part respectively.</p>
                      </dd><dt class="c-abbreviation_list__term"><dfn>
                                    <span class="mathjax-tex">\( p^{{k - 1}}_{{\text{v}}} \)</span> and <span class="mathjax-tex">\( p^{{k - 1}}_{{\text{t}}} \)</span>
                                 :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>are the previous position of the visual part and the tracked part.</p>
                      </dd><dt class="c-abbreviation_list__term"><dfn>Δ<i>t</i>
                                 :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>is the elapsed time between the position at <i>k</i> and at (<i>k</i> − 1).</p>
                      </dd></dl>The torsional component is made of two elements: the restoring torque and the damping torque. These torque vectors do not generally have the same direction. 3D transformations are expressed in quaternion coordinate system. <i>q</i>
                           <sub>t</sub> and <i>q</i>
                           <sub>v</sub> represent the current orientation of the tracked part and the visual part relative to the fixed frame of reference. The tracked part orientation with respect to the visual part is computed as follows:</p><div id="Equc" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ q = q^{*}_{{\text{v}}} q_{{\text{t}}} $$</span></div></div>
                        <p>Then the torque is computed by: </p><div id="Equd" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ T_{{{\text{spring}}}} = k_{{\text{R}}} {\left( {\text{Ang}{\left( q \right)}} \right)} $$</span></div></div><p>where: <dl class="c-abbreviation_list"><dt class="c-abbreviation_list__term"><dfn>
                        <i>T</i>
                        <sub>spring</sub>
                      :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>is the magnitude of the torque applied to the visual part about the rotation axis Axis(<i>q</i>) extracted from <i>q</i>.</p>
                      </dd><dt class="c-abbreviation_list__term"><dfn>
                        <i>k</i>
                        <sub>R</sub>
                      :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>is the translational spring constant.</p>
                      </dd><dt class="c-abbreviation_list__term"><dfn>Ang(<i>q</i>):</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>is the rotation angle extracted from <i>q</i>.</p>
                      </dd></dl>In order to calculate the damping term, the angular velocity of the tracked part (<i>q</i>
                           <sub>wt</sub>) and the visual part (<i>q</i>
                           <sub>wv</sub>) were computed with respect to the world frame of reference.</p><div id="Eque" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ \begin{aligned}{} &amp; {\text{Ang}}{\left( {q_{{{\text{wt}}}} } \right)} = \frac{{{\text{Ang}}{\left( {q^{{*k}}_{{\text{t}}} q^{{k - 1}}_{{\text{t}}} } \right)}}} {{\Delta t}}, \\ &amp; {\text{Axis}}{\left( {q_{{{\text{wt}}}} } \right)} = {\text{Axis}}{\left( {q^{{*k}}_{{\text{t}}} q^{{k - 1}}_{{\text{t}}} } \right)} \\ \end{aligned} $$</span></div></div><p>where:<dl class="c-abbreviation_list"><dt class="c-abbreviation_list__term"><dfn>Ang(<i>q</i>
                                    <sub>wt</sub>):</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>is the rotation angle of the angular velocity of the tracked part.</p>
                      </dd><dt class="c-abbreviation_list__term"><dfn>Axis(<i>q</i>
                                    <sub>wt</sub>):</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>is the rotation axis of the angular velocity of the tracked part.</p>
                      </dd><dt class="c-abbreviation_list__term"><dfn>
                        <i>q</i>
                        <sub>wt</sub>
                      :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>is the quaternion representing the angular velocity of the tracked part.</p>
                      </dd><dt class="c-abbreviation_list__term"><dfn>
                        <span class="mathjax-tex">\( q^{{*k}}_{{\text{t}}} \)</span>
                      :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>is the conjugated quaternion of the current orientation of the tracked part.</p>
                      </dd><dt class="c-abbreviation_list__term"><dfn>
                        <span class="mathjax-tex">\( q^{{k - 1}}_{{\text{t}}} \)</span>
                      :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>is the quaternion representing the previous orientation of the tracked part.</p>
                      </dd><dt class="c-abbreviation_list__term"><dfn>Δ<i>t</i>
                                 :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>is the elapsed time between <i>k</i> − 1 and <i>k</i> situations.</p>
                      </dd></dl>Using the same formulation for <i>q</i>
                           <sub>wv</sub>, we obtain: </p><div id="Equf" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ {\text{Ang}}{\left( {q_{{{\text{wv}}}} } \right)} = \frac{{{\text{Ang}}{\left( {q^{{*k}}_{{\text{v}}} q^{{k - 1}}_{{\text{v}}} } \right)}}} {{\Delta t}},\quad {\text{Axis}}{\left( {q_{{{\text{wv}}}} } \right)} = {\text{Axis}}{\left( {q^{{*k}}_{{\text{v}}} q^{{k - 1}}_{{\text{v}}} } \right)}. $$</span></div></div><p> The damping value is obtained by: </p><div id="Equg" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ T_{{{\text{damping}}}} = - b_{{\text{R}}} {\left( {{\text{Ang}}{\left( {q_{{{\text{wv}}}} q^{*}_{{{\text{wt}}}} } \right)}} \right)} $$</span></div></div><p>where:<dl class="c-abbreviation_list"><dt class="c-abbreviation_list__term"><dfn>
                        <i>b</i>
                        <sub>R</sub>
                      :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>is the rotational damping constant.</p>
                      </dd><dt class="c-abbreviation_list__term"><dfn>
                        <span class="mathjax-tex">\( {\text{Ang}}{\left( {q_{{{\text{wv}}}} q^{*}_{{{\text{wt}}}} } \right)} \)</span>
                      :</dfn></dt><dd class="c-abbreviation_list__description">
                        <p>is the relative velocity.</p>
                      </dd></dl>The value of <i>T</i>
                           <sub>damping</sub> represents the magnitude of the torque applied to the visual part relative to the rotation axis:<span class="mathjax-tex">\( {\text{Axis}}{\left( {q_{{{\text{wv}}}} q^{*}_{{{\text{wt}}}} } \right)} \)</span>, extracted from <span class="mathjax-tex">\( q_{{{\text{wv}}}} q^{*}_{{{\text{wt}}}} \)</span>.</p><p>In applying the linear force <i>F</i> and the torque <i>T</i> to the visual part, it keeps following the tracked part moved by the operator without the interpenetration of parts. The visual part has a dynamic behaviour that mimics the real world interaction of parts.</p><h3 class="c-article__sub-heading" id="Sec9">Spring and damping constants</h3><p>The values of spring constant and damping constant are obtained by performing parts’ manipulation trials. These values are adjusted so that smooth and stable movement of the manipulated part is obtained. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-007-0075-5#Tab1">1</a> contains the values of spring and damping constants corresponding to the parts of the product showed in the Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0075-5#Fig3">3</a>b.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Spring and damping constants of eight parts</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-007-0075-5/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        </div></div></section><section aria-labelledby="Sec10"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Force feedback</h2><div class="c-article-section__content" id="Sec10-content"><p>In order to provide the user with a haptic sensation during the execution of assembly task, a force feedback system from Immersion Corporation was used. The system is made of a CyberGrasp™ system that provides the rendering of contact forces on the operator’s fingertips and a 6-DOF desktop grounded force feedback device called CyberForce™ that simulates the weight and inertia of the manipulated object. The CyberForce provides force feedback in three translational degrees-of-freedom with a maximum positional force of 8.8 N (6.6 N minimum) without torque rendering. The workspace is 12′′ × 12′′ square swept through 133° with radius of 19.5′′. Force rendering update rate is maintained by VHT-SDK control law at 1,000 Hz.</p><p>The values of mass and inertia of parts are entered by the programmer in VirtualHand API. The weight of the grasped object is rendered by the CyberForce that applies a force on the palm of the user’s hand. Force calculation can be made using two different methods in VHT library: the impedance mode or the force control mode. In impedance mode, the VHT library computes the force values based on collision detection information. The forces applied on the user fingertips are computed using the contact patch information when the hand distal phalanxes collide with the virtual object. The contact patches are based on the measure of distal phalanxes’ penetration into the touched object. Stiffness and damping parameters can be adjusted in these contact patches so that realistic contact sensation is obtained.</p><p>In force control mode, the force sent to the CyberForce is obtained by specific computation model defined by the programmer.</p></div></div></section><section aria-labelledby="Sec11"><div class="c-article-section" id="Sec11-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec11">Contact force sensation</h2><div class="c-article-section__content" id="Sec11-content"><p>When the operator brings parts close to each other during the mating phase, the force generated from the contact between parts are sent through the CyberForce to the user’s real hand. The calculation of forces transmitted to the user by the CyberForce is made by two operating modes: impedance mode and the force control mode. The first mode is active when the virtual object is touched or grasped by the user. Even though the computation model is identical to the model used by the CyberGrasp, described in the previous section, the CyberForce takes into account the penetration of other hand parts such as phalanx and the palm into the virtual object. The force control mode is active by default when part grasping is completed and part-to-part contact is initiated. It computes and renders contact force sensation to the operator through the CyberForce system. When the part is grasped and moved by the user’s hand in the virtual space, the visual part and the tracked part have the same position and orientation. They appear to the user as one virtual part.</p><p>When the operator brings the grasped part into contact with another part, the visual model and the tracked model of the grasped part change position and orientation. The tracked part penetrates into its mating part but the visual part keeps the position and orientation it had when it came into contact with the mating part. The assumption made considers the distance moved by the tracked part inside its mating part, since the first recorded contact between their respective 3D models, represents a “measure” of intensity of the contact force between the manipulated parts. The contact force transmitted to the user hand through the CyberForce system is computed by using the difference between the centre of mass positions of the visual part and the tracked part.</p><p>The contact force can be formulated by: </p><div id="Equh" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ F_{{{\text{contact}}}} = \alpha {\left( {p_{{\text{t}}} - p_{{\text{v}}} } \right)} $$</span></div></div><p>where: <dl class="c-abbreviation_list"><dt class="c-abbreviation_list__term"><dfn>α:</dfn></dt><dd class="c-abbreviation_list__description">
                      <p>is the force resolution <span class="mathjax-tex">\( 1 \le \alpha \le 3 \)</span>.</p>
                    </dd><dt class="c-abbreviation_list__term"><dfn>
                                 <i>p</i>
                                 <sub>t</sub>, <i>p</i>
                                 <sub>v</sub>
                              :</dfn></dt><dd class="c-abbreviation_list__description">
                      <p>are the centre of mass positions of the tracked part and the visual part, respectively.</p>
                    </dd></dl>The force value felt by the operator depends on the force resolution α and the distance (<i>p</i>
                        <sub>t</sub> − <i>p</i>
                        <sub>v</sub>). The coefficient α is empirically determined carrying out manipulation trials by increasing the value of α by increments of 0.2 until a stable force sensation is obtained. The force value sent to the CyberForce and applied on the palm of the operator’s hand during the contact between the grasped part and its mating part is represented by a vector leaving from the centre of mass of the hand palm (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0075-5#Fig7">7</a>a, b). The direction of the force is determined by the algebraic difference between the positions of the visual part and the tracked part.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig7_HTML.jpg?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig7_HTML.jpg" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>
                                    <b>a</b> Visual and tracked models of the parts and the virtual hand, <b>b</b> Visual models of the hand and the manipulated parts</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>When the user grasps a part without being in contact with another part, the tracked and visual parts are completely overlapped. The same is for the tracked hand and visual hand (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0075-5#Fig5">5</a>b). In this condition, the contact force value is equal to zero: </p><div id="Equi" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$ F_{{{\text{contact}}}} = 0,\quad {\left( {p_{{\text{t}}} - p_{{\text{v}}} } \right)} = 0. $$</span></div></div><p>The simulation of the assembly task in the VE requires a high level of user perception acquired by natural and intuitive interaction (Baggett and Ehrenfeucht <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Baggett P, Ehrenfeucht A (1988) Conceptualising in assembly tasks. Human Factor 30(3):269–284" href="/article/10.1007/s10055-007-0075-5#ref-CR3" id="ref-link-section-d17466e1825">1988</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Baggett P, Ehrenfeucht A (1991) Building physical and mental models in assembly tasks. Int J Industr Ergon 7(3):217–227" href="/article/10.1007/s10055-007-0075-5#ref-CR4" id="ref-link-section-d17466e1828">1991</a>; Wilson <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Wilson J R (1998) Virtual environments and ergonomics: needs and opportunities. Ergonomics 40(10):1057–1077" href="/article/10.1007/s10055-007-0075-5#ref-CR27" id="ref-link-section-d17466e1831">1998</a>; Chryssolouris et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Chryssolouris G, Mavrikios D, Fragos D, Karabatsou V (2000) A virtual reality-based experimentation environment for the verification of human-related factors in assembly processes. Robot Comput Integr Manuf 16(4):267–276" href="/article/10.1007/s10055-007-0075-5#ref-CR9" id="ref-link-section-d17466e1835">2000</a>). During the virtual task, the manipulation of parts with specific 3D interaction devices has important affect on the user performance and the corresponding sensation of realism (Gupta et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997a" title="Gupta R, Sheridan T, Whitney D (1997a) Experiments using multimodal virtual environments in design for assembly analysis. Presence 6(3):318–338" href="/article/10.1007/s10055-007-0075-5#ref-CR19" id="ref-link-section-d17466e1838">1997a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Gupta R, Whitney D, Zeltzer D (1997b) Prototyping and design for assembly analysis using multimodal virtual environments. Comput-Aid Des 29(8):585–597" href="/article/10.1007/s10055-007-0075-5#ref-CR20" id="ref-link-section-d17466e1841">b</a>). Contact force sensation and virtual parts’ dynamic behaviour enhance the user presence in the VE, hence his performance during the assembly task execution. A quantitative and qualitative evaluation of the interaction technique was carried out in the framework of the research presented in this paper. The following section describes the experimental work and the analysis of user performance.</p></div></div></section><section aria-labelledby="Sec12"><div class="c-article-section" id="Sec12-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec12">Experimental design</h2><div class="c-article-section__content" id="Sec12-content"><p>The experimental study assumes that task completion time can be considered as an indicator of human performance in assembly task execution. The hypothesis made considers that haptic sensation of contact forces improves the user perception during the mating phase, hence his performance. The experimental study aims at evaluating the added value of the developed interaction technique and investigates its affect on user performance in a virtual assembly task.</p><h3 class="c-article__sub-heading" id="Sec13">Procedure</h3><p>In order to determine the added value of the interaction technique that includes contact force sensation during the mating phase of virtual mechanical parts, a set of experiments were designed and carried out in the VE and in the real world. The experimental setup is based on the concept of repeated measures design, counterbalanced by conditions. Three experimental conditions were defined: C1, C2 and RW. The user executes the assembly task in virtual environment without contact force sensation (C1), and then executes the same task with the provision of contact force sensation (C2), and finally the user carries out the assembly task in real world by manipulating real parts (RW).</p><p>In virtual environment, the scene was constructed from approximately 6K polygons, maintained at a frame rate of 50 fps. The current version of the system is used for desktop interaction with the virtual scene visualized on a 21 in. monitor. In order to allow the user setting appropriate angle of view during the manipulation of virtual parts, particularly for the insertion phase, the system incorporates a POLHEMUS™ Fastrack system that tracks the user’s head physical movements (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0075-5#Fig8">8</a>). The user’s hand is tracked using a tracker (ForceTrack) integrated in the CyberForce system.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig8_HTML.jpg?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig8_HTML.jpg" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Assembly task in the virtual environment </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The experiment consists of grasping the part H (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0075-5#Fig9">9</a>), moving the part towards the part A and assembling the parts by introducing the part H into the part A. The time taken to complete the task is recorded for the analysis of user performance.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig9_HTML.jpg?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig9_HTML.jpg" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Virtual parts used in experiments C1 and C2</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The feedback from users is a subjective evaluation of the interaction technique and realism of the virtual assembly environment developed in this work. After completing the experiment, each participant was asked to answer a questionnaire about his own appreciation of the system.</p><h3 class="c-article__sub-heading" id="Sec14">Subjects</h3><p>Eleven subjects from the laboratory community without prior experience with virtual reality systems participated to the experiment. They are all males, right handed and aged between 25 and 43 years of age. The same group of subjects participated to the three experimental conditions (C1, C2 and RW) to carry out the assembly test. The time interval between running different experiments in different conditions is 1 week.</p><h3 class="c-article__sub-heading" id="Sec15">Experiment C1</h3><p>The user performs the assembly task with haptic feedback that allows the sensation of the parts’ weight and the contact forces, applied on the operator’s fingertips during the grasping phase. In this experiment, the user does not feel the contact forces between parts. He has to execute the task with visual guidance. The final positioning of parts is automatically made using snap fitting approach developed by Dewar et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Dewar RG, Carpenter ID, Ritchie JM, Simmons JEL (1997) Assembly planning in a virtual environment. In: Proceedings PICMET’97, Portland, USA, pp 664–667" href="/article/10.1007/s10055-007-0075-5#ref-CR13" id="ref-link-section-d17466e1922">1997</a>). When the parts are close to each other within a prefixed tolerance (2 mm) the system adjusts the parts in their final assembly positions. Before participating in the experiment using the VE, each subject had to go through an intensive training session of 15 min in order to become familiar with the interaction technique and the haptic system. The experimenter explains the objective of the experiment and provides the subject with a detailed description of the assembly operation. When the subject is ready to do the test, the experimenter gives the start signal and observes the subject executing the assembly task. When the parts are located in assembly position, the system produces a special audio feedback indicating that parts are mated together and the task completion time is recorded for further analysis (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-007-0075-5#Tab2">2</a>).
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Recorded data from three experiments</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-007-0075-5/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec16">Experiment C2</h3><p>The same group of subjects who participated in the previous experiment is asked to carry out the assembly task but providing the user with the sensation of the contact forces between parts during the mating phase. When the operator manipulates the grasped part (the primary part) and brings it into contact with another part (the secondary part), he is guided by the contact forces in the determination of the correct position and orientation of the grasped part relative to its mating part. The final phase of the assembly operation is carried out with a continuous visuo-haptic sensation not present in the experiment C1.</p><p>Each subject is asked to carry out the task after an explanation made by the experimenter in order to illustrate the difference in conditions with the previous experiment. The time necessary to complete the assembly task (TCT, Task Completion Time) is recorded for each subject. The data collected from this experiment are presented in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-007-0075-5#Tab2">2</a>.</p><h3 class="c-article__sub-heading" id="Sec17">Experiment RW</h3><p>The same group of subjects was asked to carry out the experiment in the real world. Each subject had to assemble a real prototype comprising parts used in the previous experiments (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0075-5#Fig10">10</a>).
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig10_HTML.jpg?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig10_HTML.jpg" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Real parts in start positions</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The real world environment is made of a chair, a table and the parts to assemble. The location, position and orientation of parts in real world are representative of the perspective within the virtual environment.</p><p>Since the manipulation in the VE was carried out using one hand, the secondary part was fixed on the table. The subject grasps the part H from its start position; moves it close to the part A and finally assembles the two parts by inserting the part H in part A (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0075-5#Fig11">11</a>). The time to complete the task is recorded using a chronometer.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig11_HTML.jpg?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig11_HTML.jpg" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Assembly task execution in real world</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec18">Data analysis and results</h3><p>In order to test the affect of force sensation on user performance, the data collected from experiments C1 and C2 were used to perform ANOVA analysis on the TCT and factors the experimental condition. The results show a significant main effect of experimental condition on task completion time with a confidence level of 95% [<i>F</i>(1, 21) = 61.55, <i>P</i> &lt; 0.05].</p><p>The difference between the interaction conditions C1 and C2 is the sensation of contact forces by the operator during the mating phase. The study of experimental conditions and statistical results confirm that the main effect on assembly time comes from contact force sensation. The analysis of assembly times obtained from the experiments ascertain to reliability of the difference in human performance in terms of task completion time. These results show that contact forces can be considered as cues which assist the operator in finding the appropriate position and orientation of mechanical parts during the mating phase in an assembly task.</p><p>This result was confirmed by the study of experimental conditions C1 and the real world (RW). An ANOVA was carried out on TCT and factors the experimental conditions C1 and RW. The analysis shows a significant main effect of the mode of interaction in real world at the confidence level of 95% [<i>F</i>(1, 21) = 54.06, <i>P</i> &lt; 0.05]. The analysis of the difference between the experimental conditions C1 and RW should investigate the affect of other factors inherent in the interaction with VE. The sensation of contact forces, included in the experimental conditions C2 and naturally present in real world manipulation, is not the only factor that affects human performance. Among these factors are, the nature of interaction with virtual environment, the difference in perception levels between task execution in real world and in computer generated environment, human factors and ergonomic issues, and other considerations related to the effects of human computer interaction. Nevertheless, this analysis shows that task execution with conditions C2 provides more natural interaction than experimental conditions C1. The charts represented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-007-0075-5#Fig12">12</a> show that task completion times tend to be more realistic in experiment C2 than in experiment C1 even though task duration in real world is shorter.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig12_HTML.gif?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-007-0075-5/MediaObjects/10055_2007_75_Fig12_HTML.gif" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Recorded times of three experimental conditions C1, C2 and RW</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-007-0075-5/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Human performance is improved when cues from real world are included in the interaction with virtual environment. Contact forces between virtual parts during assembly operation can be considered as a cue that improves the user perception and task performance.</p><p>The analysis of data obtained from the experiments C2 and RW confirms that more developments are necessary in order to reach the realism and user performance of real world interaction. ANOVA test was carried on the variable of TCT and factors the experimental condition showed significant main effect of the real world interaction conditions [<i>F</i>(1, 21) = 22.28, <i>P</i> &lt; 0.05] at a confidence level of 95%. This confirms the assumption that factors affecting human performance in the interaction with the VE are diverse. The development of specific interaction techniques can contribute to the improvement of task performance, particularly when the manipulation requires a high level of perception. Assembling mechanical parts is not simply joining 3D models of parts. The operator needs to receive natural sensations of physical interfaces between parts in performing the task. Contact forces can be considered as one of theses sensations, necessary for the virtual task execution, in order to find the relative positions and orientations of components in the final assembly state.</p><h3 class="c-article__sub-heading" id="Sec19">Subjective evaluation</h3><p>In order to get feedback from users after their participation to the experiments a subjective evaluation procedure was used. Each participant was asked to fill in a questionnaire reporting on their opinions about interaction modes C1 and C2 in comparison with the task execution in RW. Ten out of 11 subjects indicated that contact force sensation in the interaction mode C2 allowed them better movement control in positioning part H and in finding the correct relative position and orientation of parts during the mating phase.</p><p>Nine subjects consider that interaction mode C2 is more realistic than C1 in terms of part-to-part interface and seven subjects indicated that they experienced particular difficulties in locating the part H relative to part A in experiment C1. They experienced difficulties in finding the part’s location in the positional interval that allows snap fitting. Finally six subjects reported that reaction forces are very high in the interaction mode C2 compared to real world task where they could easily fit part H with the cylindrical mating shape of part A. The feedback from users confirms the real effect of contact sensation on the realism of interaction and its positive impact on the user performance.</p></div></div></section><section aria-labelledby="Sec20"><div class="c-article-section" id="Sec20-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec20">Conclusions and perspectives</h2><div class="c-article-section__content" id="Sec20-content"><p>An assembly task is described by the relationship of parts or subassemblies, translation of constraints and operation restrictions. The geometric constraints between parts determine the degree of complexity of the mating phase. This research showed that when the operator is provided with the sensation of forces generated by the contact between parts during the mating phase, he demonstrated better performance compared to the situation where haptic sensation is limited to the forces applied on his fingertips representing the contact between his hand and the virtual part. The results obtained from this study showed that despite the significant increase in user performance obtained by including contact force sensation in the interaction technique designed for the experimental conditions C2, the user performance in real world is considerably higher than obtained in simulated environment. The development of appropriate interaction techniques inspired from real world interaction is part of the perspectives of our research.</p><p>The interaction technique based on the concept of a spring-damper model allowed the production of a representation of dynamic behaviour of parts that enhanced the realism of the interaction and precluded the visually distracting aspect of interpenetration of parts during the mating phase of assembly task. The assembly operation studied concerned the manipulation of cylindrical parts. It is intended to extend this research to include the manipulation of parts with a variety of shapes in order to refine the model of contact force computation developed.</p><p>The virtual assembly environment developed in the framework of this research is mainly intended for assembly design and planning. Our system does not include predefined rules to satisfy geometric constraints. Geometric reasoning is performed by the user in order to identify precedence relationships by manipulating parts and performing assembly trials in VE. Part-to-part interfacing represents an important “segment” of the assembly operation since it determines its feasibility and affects the user performance in terms of assembly execution time and the generation of valid assembly plans.</p><p>As consequence of these results, our research will be extended to include the development of two-handed manipulation, the simulation of fixing operations after locating the parts in their final assembly position and the development of validation tools for assembly plans generated from the virtual assembly environment.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="N. Abe, JY. Zhang, K. Tanaka, H. Taki, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Abe N, Zhang JY, Tanaka K, Taki H (1996) A training system using virtual machines for teaching assembling/disa" /><p class="c-article-references__text" id="ref-CR1">Abe N, Zhang JY, Tanaka K, Taki H (1996) A training system using virtual machines for teaching assembling/disassembling operations to novices. Proc IEEE Int Conf Syst Man Cybern 3:2096–2101</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20training%20system%20using%20virtual%20machines%20for%20teaching%20assembling%2Fdisassembling%20operations%20to%20novices.&amp;journal=Proc%20IEEE%20Int%20Conf%20Syst%20Man%20Cybern&amp;volume=3&amp;pages=2096-2101&amp;publication_year=1996&amp;author=Abe%2CN&amp;author=Zhang%2CJY&amp;author=Tanaka%2CK&amp;author=Taki%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Adams RJ, Hannaford B (1998) A two-port framework for the design of unconditionally stable haptic interfaces. " /><p class="c-article-references__text" id="ref-CR2">Adams RJ, Hannaford B (1998) A two-port framework for the design of unconditionally stable haptic interfaces. In: Proceedings IROS, Anaheim, CA</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Baggett, A. Ehrenfeucht, " /><meta itemprop="datePublished" content="1988" /><meta itemprop="headline" content="Baggett P, Ehrenfeucht A (1988) Conceptualising in assembly tasks. Human Factor 30(3):269–284" /><p class="c-article-references__text" id="ref-CR3">Baggett P, Ehrenfeucht A (1988) Conceptualising in assembly tasks. Human Factor 30(3):269–284</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Conceptualising%20in%20assembly%20tasks&amp;journal=Human%20Factor&amp;volume=30&amp;issue=3&amp;pages=269-284&amp;publication_year=1988&amp;author=Baggett%2CP&amp;author=Ehrenfeucht%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Baggett, A. Ehrenfeucht, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="Baggett P, Ehrenfeucht A (1991) Building physical and mental models in assembly tasks. Int J Industr Ergon 7(3" /><p class="c-article-references__text" id="ref-CR4">Baggett P, Ehrenfeucht A (1991) Building physical and mental models in assembly tasks. Int J Industr Ergon 7(3):217–227</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2F0169-8141%2891%2990005-7" aria-label="View reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Building%20physical%20and%20mental%20models%20in%20assembly%20tasks&amp;journal=Int%20J%20Industr%20Ergon&amp;volume=7&amp;issue=3&amp;pages=217-227&amp;publication_year=1991&amp;author=Baggett%2CP&amp;author=Ehrenfeucht%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Borst CW, Indugula P (2005) Realistic virtual grasping. In: Proceedings IEEE virtual reality conference (VR’05" /><p class="c-article-references__text" id="ref-CR5">Borst CW, Indugula P (2005) Realistic virtual grasping. In: Proceedings IEEE virtual reality conference (VR’05). Bonn, Germany, pp 91–98, 320</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="CW. Borst, AP. Indugula, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Borst CW, Indugula AP (2006) A spring model for whole-hand virtual grasping. Presence Teleoperators Virtual En" /><p class="c-article-references__text" id="ref-CR6">Borst CW, Indugula AP (2006) A spring model for whole-hand virtual grasping. Presence Teleoperators Virtual Environ 15(1):47–61</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2Fpres.2006.15.1.47" aria-label="View reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20spring%20model%20for%20whole-hand%20virtual%20grasping&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=15&amp;issue=1&amp;pages=47-61&amp;publication_year=2006&amp;author=Borst%2CCW&amp;author=Indugula%2CAP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Carmel R, Ullrich C, Silver J (2001) VirtualHand v2.5 programmer’s guide. Technical Report, Virtual Technologi" /><p class="c-article-references__text" id="ref-CR7">Carmel R, Ullrich C, Silver J (2001) VirtualHand v2.5 programmer’s guide. Technical Report, Virtual Technologies</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Carpenter ID, Dewar RG, Ritchie JM, Simmons JEL (1996) Enhancing a virtual environment for manual assembly. In" /><p class="c-article-references__text" id="ref-CR8">Carpenter ID, Dewar RG, Ritchie JM, Simmons JEL (1996) Enhancing a virtual environment for manual assembly. In: Proceedings 12th international conference on CAD/CAM robotics and factories of the future, Middlesex University, UK, pp 1067–1072</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Chryssolouris, D. Mavrikios, D. Fragos, V. Karabatsou, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Chryssolouris G, Mavrikios D, Fragos D, Karabatsou V (2000) A virtual reality-based experimentation environmen" /><p class="c-article-references__text" id="ref-CR9">Chryssolouris G, Mavrikios D, Fragos D, Karabatsou V (2000) A virtual reality-based experimentation environment for the verification of human-related factors in assembly processes. Robot Comput Integr Manuf 16(4):267–276</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0736-5845%2800%2900013-2" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20virtual%20reality-based%20experimentation%20environment%20for%20the%20verification%20of%20human-related%20factors%20in%20assembly%20processes.&amp;journal=Robot%20Comput%20Integr%20Manuf&amp;volume=16&amp;issue=4&amp;pages=267-276&amp;publication_year=2000&amp;author=Chryssolouris%2CG&amp;author=Mavrikios%2CD&amp;author=Fragos%2CD&amp;author=Karabatsou%2CV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Colgate JE, Grafing PE, Stanley MC, Schenkel G (1993) Implementation of stiff virtual walls in force-reflectin" /><p class="c-article-references__text" id="ref-CR10">Colgate JE, Grafing PE, Stanley MC, Schenkel G (1993) Implementation of stiff virtual walls in force-reflecting interfaces. In: Proceedings IEEE virtual reality annual international symposium (VRAIS), Seattle, WA, pp 202–208</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="LS. Homen Mello, S. Lee, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="Homen De Mello LS, Lee S (1991) Computer-aided mechanical assembly planning. Kluwer, Dordrecht, pp 217–242" /><p class="c-article-references__text" id="ref-CR11">Homen De Mello LS, Lee S (1991) Computer-aided mechanical assembly planning. Kluwer, Dordrecht, pp 217–242</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Computer-aided%20mechanical%20assembly%20planning&amp;pages=217-242&amp;publication_year=1991&amp;author=Homen%20Mello%2CLS&amp;author=Lee%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="A. Delchambre, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Delchambre A (1992) Computer aided assembly planning. Chapman and Hall, London" /><p class="c-article-references__text" id="ref-CR12">Delchambre A (1992) Computer aided assembly planning. Chapman and Hall, London</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Computer%20aided%20assembly%20planning&amp;publication_year=1992&amp;author=Delchambre%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dewar RG, Carpenter ID, Ritchie JM, Simmons JEL (1997) Assembly planning in a virtual environment. In: Proceed" /><p class="c-article-references__text" id="ref-CR13">Dewar RG, Carpenter ID, Ritchie JM, Simmons JEL (1997) Assembly planning in a virtual environment. In: Proceedings PICMET’97, Portland, USA, pp 664–667</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dewar RG (1998) Assembly plans from virtual environments. PhD Thesis, Heriot-Watt University, UK" /><p class="c-article-references__text" id="ref-CR14">Dewar RG (1998) Assembly plans from virtual environments. PhD Thesis, Heriot-Watt University, UK</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="PM. Fitts, " /><meta itemprop="datePublished" content="1954" /><meta itemprop="headline" content="Fitts PM (1954) The information capacity of the human motor system in controlling the amplitude of movement. E" /><p class="c-article-references__text" id="ref-CR15">Fitts PM (1954) The information capacity of the human motor system in controlling the amplitude of movement. Exp Psychol 47:381–391</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2Fh0055392" aria-label="View reference 15">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20information%20capacity%20of%20the%20human%20motor%20system%20in%20controlling%20the%20amplitude%20of%20movement&amp;journal=Exp%20Psychol&amp;volume=47&amp;pages=381-391&amp;publication_year=1954&amp;author=Fitts%2CPM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Garbaya S, Coiffet Ph, Blazevic P (2003) Experiments of assembly planning in virtual environment. In: Proceedi" /><p class="c-article-references__text" id="ref-CR16">Garbaya S, Coiffet Ph, Blazevic P (2003) Experiments of assembly planning in virtual environment. In: Proceedings 5th IEEE international symposium on assembly and task planning (ISATP ‘03), France</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Garbaya S, Coiffet Ph, Blazevic P (2001) Integrating computerised assembly planning with virtual assembly envi" /><p class="c-article-references__text" id="ref-CR17">Garbaya S, Coiffet Ph, Blazevic P (2001) Integrating computerised assembly planning with virtual assembly environment. In: Proceedings virtual reality in mechanical and production engineering (VR-Mech’01). Brussels, Belgium</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HH. Hu, AA. Gooch, SH. Creem-regehr, WB. Tompson, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Hu HH, Gooch AA, Creem-regehr SH, Tompson WB (2002) Visual cues for perceiving distances from objects to surfa" /><p class="c-article-references__text" id="ref-CR18">Hu HH, Gooch AA, Creem-regehr SH, Tompson WB (2002) Visual cues for perceiving distances from objects to surfaces. Presence Teleoperators Virtual Environ 11:652–664</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474602321050758" aria-label="View reference 18">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20cues%20for%20perceiving%20distances%20from%20objects%20to%20surfaces.&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=11&amp;pages=652-664&amp;publication_year=2002&amp;author=Hu%2CHH&amp;author=Gooch%2CAA&amp;author=Creem-regehr%2CSH&amp;author=Tompson%2CWB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Gupta, T. Sheridan, D. Whitney, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Gupta R, Sheridan T, Whitney D (1997a) Experiments using multimodal virtual environments in design for assembl" /><p class="c-article-references__text" id="ref-CR19">Gupta R, Sheridan T, Whitney D (1997a) Experiments using multimodal virtual environments in design for assembly analysis. Presence 6(3):318–338</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Experiments%20using%20multimodal%20virtual%20environments%20in%20design%20for%20assembly%20analysis&amp;journal=Presence&amp;volume=6&amp;issue=3&amp;pages=318-338&amp;publication_year=1997&amp;author=Gupta%2CR&amp;author=Sheridan%2CT&amp;author=Whitney%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Gupta, D. Whitney, D. Zeltzer, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Gupta R, Whitney D, Zeltzer D (1997b) Prototyping and design for assembly analysis using multimodal virtual en" /><p class="c-article-references__text" id="ref-CR20">Gupta R, Whitney D, Zeltzer D (1997b) Prototyping and design for assembly analysis using multimodal virtual environments. Comput-Aid Des 29(8):585–597</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0010-4485%2896%2900093-0" aria-label="View reference 20">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Prototyping%20and%20design%20for%20assembly%20analysis%20using%20multimodal%20virtual%20environments.&amp;journal=Comput-Aid%20Des&amp;volume=29&amp;issue=8&amp;pages=585-597&amp;publication_year=1997&amp;author=Gupta%2CR&amp;author=Whitney%2CD&amp;author=Zeltzer%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Jarayam, H. Connacher, K. Lyons, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Jarayam S, Connacher H, Lyons K (1997) Virtual assembly using virtual reality techniques. Comput-Aid Des 29(8)" /><p class="c-article-references__text" id="ref-CR21">Jarayam S, Connacher H, Lyons K (1997) Virtual assembly using virtual reality techniques. Comput-Aid Des 29(8):575–584</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0010-4485%2896%2900094-2" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20assembly%20using%20virtual%20reality%20techniques.&amp;journal=Comput-Aid%20Des&amp;volume=29&amp;issue=8&amp;pages=575-584&amp;publication_year=1997&amp;author=Jarayam%2CS&amp;author=Connacher%2CH&amp;author=Lyons%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kokkevis E, Metaxas D, Badler NI (1996) User-controlled physics-based animation for articulated figures. In: P" /><p class="c-article-references__text" id="ref-CR22">Kokkevis E, Metaxas D, Badler NI (1996) User-controlled physics-based animation for articulated figures. In: Proceedings Computer Animation, Geneva, Switzerland, pp 16–26</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Koutek M, Post FH (2001) Spring-based manipulation tools for virtual environments. In: Proceedings immersive p" /><p class="c-article-references__text" id="ref-CR23">Koutek M, Post FH (2001) Spring-based manipulation tools for virtual environments. In: Proceedings immersive projection technology and virtual environments. Springer, Stuttgart, pp 61–70</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="McNeely W, Puterbaugh D, James J (1999) Six degrees-of-freedom haptic rendering using Voxel sampling. In: Proc" /><p class="c-article-references__text" id="ref-CR24">McNeely W, Puterbaugh D, James J (1999) Six degrees-of-freedom haptic rendering using Voxel sampling. In: Proceedings SIGGRAPH 99, ISBN 020148-560-5, LA, CA, USA, pp 401–408</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JL. Nevins, DE. Whitney, " /><meta itemprop="datePublished" content="1980" /><meta itemprop="headline" content="Nevins JL, Whitney DE (1980) Assembly research. Automatic 16:595–613" /><p class="c-article-references__text" id="ref-CR25">Nevins JL, Whitney DE (1980) Assembly research. Automatic 16:595–613</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2F0005-1098%2880%2990003-5" aria-label="View reference 25">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Assembly%20research&amp;journal=Automatic&amp;volume=16&amp;pages=595-613&amp;publication_year=1980&amp;author=Nevins%2CJL&amp;author=Whitney%2CDE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Westenhofer W, Hahn J (1996) Using kinematic clones to control the dynamic simulation of articulated figures. " /><p class="c-article-references__text" id="ref-CR26">Westenhofer W, Hahn J (1996) Using kinematic clones to control the dynamic simulation of articulated figures. In: Proceedings Computer Graphics International, Pohang, Korea, pp 26–37</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J R. Wilson, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Wilson J R (1998) Virtual environments and ergonomics: needs and opportunities. Ergonomics 40(10):1057–1077" /><p class="c-article-references__text" id="ref-CR27">Wilson J R (1998) Virtual environments and ergonomics: needs and opportunities. Ergonomics 40(10):1057–1077</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F001401397187603" aria-label="View reference 27">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20environments%20and%20ergonomics%3A%20needs%20and%20opportunities&amp;journal=Ergonomics&amp;volume=40&amp;issue=10&amp;pages=1057-1077&amp;publication_year=1998&amp;author=Wilson%2CJ%20R">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zachmann G, Rettig A (2001) Natural and robust interaction in virtual assembly simulation. In: Proceedings 8th" /><p class="c-article-references__text" id="ref-CR28">Zachmann G, Rettig A (2001) Natural and robust interaction in virtual assembly simulation. In: Proceedings 8th ISPE international conference on concurrent engineering: research and applications. Anaheim, CA</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zorriassatine F, Wykes R, Parkin R, Gindy N (2003) A survey of virtual prototyping techniques for mechanical p" /><p class="c-article-references__text" id="ref-CR29">Zorriassatine F, Wykes R, Parkin R, Gindy N (2003) A survey of virtual prototyping techniques for mechanical product development. In: Proceedings Inst. Mech. Engineers. Part B: J Eng Manuf 217(4):513–530 </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-007-0075-5-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Robotics Laboratory of Versailles, The University of Versailles, 10-12 Avenue de l’Europe, 78140, Velizy, France</p><p class="c-article-author-affiliation__authors-list">Samir Garbaya &amp; U. Zaldivar-Colado</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Samir-Garbaya"><span class="c-article-authors-search__title u-h3 js-search-name">Samir Garbaya</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Samir+Garbaya&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Samir+Garbaya" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Samir+Garbaya%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-U_-Zaldivar_Colado"><span class="c-article-authors-search__title u-h3 js-search-name">U. Zaldivar-Colado</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;U.+Zaldivar-Colado&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=U.+Zaldivar-Colado" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22U.+Zaldivar-Colado%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-007-0075-5/email/correspondent/c1/new">Samir Garbaya</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=The%20affect%20of%20contact%20force%20sensations%20on%20user%20performance%20in%20virtual%20assembly%20tasks&amp;author=Samir%20Garbaya%20et%20al&amp;contentID=10.1007%2Fs10055-007-0075-5&amp;publication=1359-4338&amp;publicationDate=2007-05-09&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Garbaya, S., Zaldivar-Colado, U. The affect of contact force sensations on user performance in virtual assembly tasks.
                    <i>Virtual Reality</i> <b>11, </b>287–299 (2007). https://doi.org/10.1007/s10055-007-0075-5</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-007-0075-5.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-10-03">03 October 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2007-03-19">19 March 2007</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2007-05-09">09 May 2007</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2007-10">October 2007</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-007-0075-5" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-007-0075-5</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Virtual assembly</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Spring-damper model</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Haptic interface</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Human performance</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-007-0075-5.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=75;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

