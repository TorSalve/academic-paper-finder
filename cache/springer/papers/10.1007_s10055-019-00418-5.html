<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="The value of being there: toward a science of immersive virtual field "/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="With immersive experiences becoming a medium for mass communication, we need pedagogies as well as scientific, evidence-based design principles for immersive learning. To foster evidence-based..."/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="The value of being there: toward a science of immersive virtual field trips"/>

    <meta name="dc.source" content="Virtual Reality 2019"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2019-12-21"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2019 Springer-Verlag London Ltd., part of Springer Nature"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="With immersive experiences becoming a medium for mass communication, we need pedagogies as well as scientific, evidence-based design principles for immersive learning. To foster evidence-based designs of immersive learning, we detail an empirical evaluation of a geosciences field trip, common in undergraduate education across numerous disciplines. The study builds on a previously proposed research framework in which we detailed a basic taxonomy of virtual field trips distinguishing between basic, plus, and advanced immersive virtual field trip experiences. The experiment reported here expands the original evaluation of basic field trips into the realm of plus versions using pseudo-aerial $$360^{\circ }$$ imagery to provide embodied experiences that are not possible during the actual field trip. We also refined our original experimental design placing a stronger focus on the qualitative feedback elicited from the students. Results show an overwhelmingly positive response of students to virtual field trips with significantly higher-valued learning experience and enjoyment. Furthermore, the introduction of pseudo-aerial imagery (together with higher image resolution) shows a significant improvement in the participants spatial situation model. As contextualizing and spatially grounding is essential for place-based learning experiences, plus versions of virtual field trips have the potential to add value to the learning outcome and immersive virtual field trip experience. We discuss these encouraging results as well as critical feedback from the participants, such as the absence of touch in virtual experiences, and lay out our vision for the future of immersive learning experiences across environmental sciences."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2019-12-21"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="1"/>

    <meta name="prism.endingPage" content="18"/>

    <meta name="prism.copyright" content="2019 Springer-Verlag London Ltd., part of Springer Nature"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-019-00418-5"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-019-00418-5"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-019-00418-5.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-019-00418-5"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="The value of being there: toward a science of immersive virtual field trips"/>

    <meta name="citation_online_date" content="2019/12/21"/>

    <meta name="citation_firstpage" content="1"/>

    <meta name="citation_lastpage" content="18"/>

    <meta name="citation_article_type" content="S.I.: XR (VR, AR, MR) and Immersive Learning Environments"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-019-00418-5"/>

    <meta name="DOI" content="10.1007/s10055-019-00418-5"/>

    <meta name="citation_doi" content="10.1007/s10055-019-00418-5"/>

    <meta name="description" content="With immersive experiences becoming a medium for mass communication, we need pedagogies as well as scientific, evidence-based design principles for immersi"/>

    <meta name="dc.creator" content="Alexander Klippel"/>

    <meta name="dc.creator" content="Jiayan Zhao"/>

    <meta name="dc.creator" content="Danielle Oprean"/>

    <meta name="dc.creator" content="Jan Oliver Wallgr&#252;n"/>

    <meta name="dc.creator" content="Chris Stubbs"/>

    <meta name="dc.creator" content="Peter La Femina"/>

    <meta name="dc.creator" content="Kathy L. Jackson"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=Res Learn Technol; citation_title=Learning in virtual reality: effects on performance, emotion and engagement; citation_author=D Allcoat, A M&#252;hlenen; citation_publication_date=2018; citation_doi=10.25304/rlt.v26.2140; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_title=Infinite reality: avatars, eternal life, new worlds, and the dawn of the virtual revolution; citation_publication_date=2011; citation_id=CR2; citation_author=J Blascovich; citation_author=J Bailenson; citation_publisher=William Morrow"/>

    <meta name="citation_reference" content="citation_journal_title=Multimodal Technol Interact; citation_title=The new era of virtual reality locomotion: a systematic literature review of techniques and a proposed typology; citation_author=C Boletsis; citation_volume=1; citation_issue=4; citation_publication_date=2017; citation_pages=24; citation_doi=10.3390/mti1040024; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_journal_title=Computer; citation_title=Virtual reality: how much immersion is enough?; citation_author=DA Bowman, RP McMahan; citation_volume=40; citation_issue=7; citation_publication_date=2007; citation_pages=36-43; citation_doi=10.1109/MC.2007.257; citation_id=CR4"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoper Virtual Environ; citation_title=Badre AN maintaining spatial orientation during travel in an immersive virtual environment; citation_author=DA Bowman, ET Davis, LF Hodges; citation_volume=8; citation_issue=6; citation_publication_date=1999; citation_pages=618-631; citation_doi=10.1162/105474699566521; citation_id=CR5"/>

    <meta name="citation_reference" content="citation_journal_title=TechTrends; citation_title=Virtual reality: low-cost tools and resources for the classroom; citation_author=A Brown, T Green; citation_volume=60; citation_issue=5; citation_publication_date=2016; citation_pages=517-519; citation_doi=10.1007/s11528-016-0102-z; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_journal_title=GSA Today; citation_title=Increasing undergraduate interest to learn geoscience with GPS-based augmented reality field trips on students&#8217; own smartphones; citation_author=N Bursztyn, B Shelton, A Walker, J Pederson; citation_volume=27; citation_publication_date=2017; citation_pages=4-10; citation_doi=10.1130/GSATG304A.1; citation_id=CR7"/>

    <meta name="citation_reference" content="citation_journal_title=J Geogr High Educ; citation_title=Landscape interpretation with augmented reality and maps to improve spatial orientation skill; citation_author=C Carbonell Carrera, LA Bermejo Asensio; citation_volume=41; citation_issue=1; citation_publication_date=2017; citation_pages=119-133; citation_doi=10.1080/03098265.2016.1260530; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_title=Structure from motion in the geosciences; citation_publication_date=2016; citation_id=CR9; citation_author=JL Carrivick; citation_author=MW Smith; citation_author=DJ Quincey; citation_publisher=Wiley"/>

    <meta name="citation_reference" content="citation_journal_title=Front Psychol; citation_title=Designing awe in virtual reality: an experimental study; citation_author=A Chirico, F Ferrise, L Cordella, A Gaggioli; citation_volume=8; citation_publication_date=2017; citation_pages=2351; citation_doi=10.3389/fpsyg.2017.02351; citation_id=CR10"/>

    <meta name="citation_reference" content="citation_journal_title=Cognit Res Princ Implic; citation_title=Design of embodied interfaces for engaging spatial cognition; citation_author=PG Clifton, JSK Chang, G Yeboah, A Doucette, S Chandrasekharan, M Nitsche, T Welsh, A Mazalek; citation_volume=1; citation_issue=1; citation_publication_date=2016; citation_pages=24; citation_doi=10.1186/s41235-016-0032-5; citation_id=CR11"/>

    <meta name="citation_reference" content="citation_journal_title=Educ Comput; citation_title=Learning and instruction with computer simulations; citation_author=T Jong; citation_volume=6; citation_issue=3; citation_publication_date=1991; citation_pages=217-229; citation_doi=10.1016/0167-9287(91)80002-F; citation_id=CR12"/>

    <meta name="citation_reference" content="citation_journal_title=Science (New York, N.Y.); citation_title=Immersive interfaces for engagement and learning; citation_author=C Dede; citation_volume=323; citation_issue=5910; citation_publication_date=2009; citation_pages=66-69; citation_doi=10.1126/science.1167311; citation_id=CR13"/>

    <meta name="citation_reference" content="citation_journal_title=J Geosci Educ; citation_title=Virtual field experiences in introductory geology: addressing a capacity problem, but finding a pedagogical one; citation_author=G Dolphin, A Dutchak, B Karchewski, J Cooper; citation_volume=67; citation_issue=2; citation_publication_date=2019; citation_pages=114-130; citation_doi=10.1080/10899995.2018.1547034; citation_id=CR14"/>

    <meta name="citation_reference" content="citation_journal_title=J Geosci Educ; citation_title=Teaching geology in the field: significant geoscience concept gains in entirely field-based introductory geology courses; citation_author=J Elkins, NML Elkins; citation_volume=55; citation_issue=2; citation_publication_date=2007; citation_pages=126-132; citation_doi=10.5408/1089-9995-55.2.126; citation_id=CR15"/>

    <meta name="citation_reference" content="citation_title=Virtual reality in geography; citation_publication_date=2002; citation_id=CR16; citation_publisher=Taylor &amp; Francis"/>

    <meta name="citation_reference" content="citation_journal_title=Br J Educ Technol; citation_title=Virtual reality and learning: where is the pedagogy?; citation_author=C Fowler; citation_volume=46; citation_issue=2; citation_publication_date=2015; citation_pages=412-422; citation_doi=10.1111/bjet.12135; citation_id=CR17"/>

    <meta name="citation_reference" content="citation_journal_title=Coll Teach; citation_title=A class project in survey sampling; citation_author=A Gelman, D Nolan; citation_volume=50; citation_issue=4; citation_publication_date=2010; citation_pages=151-153; citation_doi=10.1080/87567550209595897; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=Intelligence; citation_title=Development of a self-report measure of environmental spatial ability; citation_author=M Hegarty; citation_volume=30; citation_issue=5; citation_publication_date=2002; citation_pages=425-447; citation_doi=10.1016/S0160-2896(02)00116-2; citation_id=CR19"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Geosci; citation_title=Use of &#8220;virtual&#8221; field trips in teaching introductory geology; citation_author=SD Hurst; citation_volume=24; citation_issue=7; citation_publication_date=1998; citation_pages=653-658; citation_doi=10.1016/S0098-3004(98)00043-0; citation_id=CR20"/>

    <meta name="citation_reference" content="citation_journal_title=Front Robot AI; citation_title=Immersive VR and education: embodied design principles that include gesture and hand controls; citation_author=MC Johnson-Glenberg; citation_volume=5; citation_publication_date=2018; citation_pages=27; citation_doi=10.3389/frobt.2018.00081; citation_id=CR21"/>

    <meta name="citation_reference" content="citation_title=Prompting Connections Between Content and Context: Blending Immersive Virtual Environments and Augmented Reality for Environmental Science Learning; citation_inbook_title=Communications in Computer and Information Science; citation_publication_date=2018; citation_pages=36-54; citation_id=CR22; citation_author=Amy M. Kamarainen; citation_author=Meredith Thompson; citation_author=Shari J. Metcalf; citation_author=Tina A. Grotzer; citation_author=Michael Shane Tutwiler; citation_author=Chris Dede; citation_publisher=Springer International Publishing"/>

    <meta name="citation_reference" content="citation_journal_title=Cognit Emot; citation_title=Approaching awe, a moral, spiritual, and aesthetic emotion; citation_author=D Keltner, J Haidt; citation_volume=17; citation_issue=2; citation_publication_date=2003; citation_pages=297-314; citation_doi=10.1080/02699930302297; citation_id=CR23"/>

    <meta name="citation_reference" content="citation_journal_title=Br J Educ Technol; citation_title=A multi-user virtual environment for building and assessing higher order inquiry skills in science; citation_author=DJ Ketelhut, BC Nelson, J Clarke, C Dede; citation_volume=41; citation_issue=1; citation_publication_date=2010; citation_pages=56-68; citation_doi=10.1111/j.1467-8535.2009.01036.x; citation_id=CR24"/>

    <meta name="citation_reference" content="citation_journal_title=J Educ Comput Res; citation_title=Transforming earth science education through immersive experiences: delivering on a long held promise; citation_author=A Klippel, J Zhao, KL Jackson, P LaFemina, C Stubbs, D Oprean, JO Wallgr&#252;n, J Blair; citation_volume=57; citation_issue=7; citation_publication_date=2019; citation_pages=1745-1771; citation_doi=10.1177/0735633119854025; citation_id=CR25"/>

    <meta name="citation_reference" content="Klippel A, Zhao J, Oprean D, Wallgr&#252;n JO, Chang JSK, Wallgrun JO, Chang JSK (2019b) Research framework for immersive virtual field trips. In: IEEE conference on virtual reality and 3D user interfaces. KELVAR: the fourth IEEE VR workshop on K-12+ embodied learning through virtual and augmented reality. IEEE, pp 1612&#8211;1617. 
https://doi.org/10.1109/VR.2019.8798153


"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=Virtual memory palaces: immersion aids recall; citation_author=E Krokos, C Plaisant, A Varshney; citation_volume=23; citation_publication_date=2018; citation_pages=1-15; citation_doi=10.1007/s10055-018-0360-5; citation_id=CR27"/>

    <meta name="citation_reference" content="citation_journal_title=Front ICT; citation_title=Move the object or move myself? Walking versus manipulation for the examination of 3d scientific data; citation_author=WS Lages, DA Bowman; citation_volume=5; citation_publication_date=2018; citation_pages=236; citation_doi=10.3389/fict.2018.00015; citation_id=CR28"/>

    <meta name="citation_reference" content="citation_title=Situated learning: legitimate peripheral participation. Learning in doing: social, cognitive, and computational perspectives; citation_publication_date=1991; citation_id=CR29; citation_author=J Lave; citation_author=E Wenger; citation_publisher=Cambridge University Press"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Educ; citation_title=Learning with desktop virtual reality: low spatial ability learners are more positively affected; citation_author=EAL Lee, KW Wong; citation_volume=79; citation_publication_date=2014; citation_pages=49-58; citation_doi=10.1016/j.compedu.2014.07.010; citation_id=CR30"/>

    <meta name="citation_reference" content="citation_title=Virtual, augmented, and mixed realities in education. Smart computing and intelligence; citation_publication_date=2017; citation_id=CR31; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Learn Instr; citation_title=Adding immersive virtual reality to a science lab simulation causes more presence but less learning; citation_author=G Makransky, TS Terkildsen, RE Mayer; citation_publication_date=2017; citation_doi=10.1016/j.learninstruc.2017.12.007; citation_id=CR32"/>

    <meta name="citation_reference" content="citation_journal_title=Front Psychol; citation_title=Immersive virtual reality field trips facilitate learning about climate change; citation_author=DM Markowitz, R Laha, BP Perone, RD Pea, JN Bailenson; citation_volume=9; citation_publication_date=2018; citation_pages=2364; citation_doi=10.3389/fpsyg.2018.02364; citation_id=CR33"/>

    <meta name="citation_reference" content="citation_journal_title=J Geosci Educ; citation_title=Immersive, interactive virtual field trips promote science learning; citation_author=C Mead, S Buxner, G Bruce, W Taylor, S Semken, AD Anbar; citation_volume=67; citation_issue=2; citation_publication_date=2019; citation_pages=131-142; citation_doi=10.1080/10899995.2019.1565285; citation_id=CR34"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Educ; citation_title=Effectiveness of virtual reality-based instruction on students&#8217; learning outcomes in k-12 and higher education: a meta-analysis; citation_author=Z Merchant, ET Goetz, L Cifuentes, W Keeney-Kennicutt, TJ Davis; citation_volume=70; citation_publication_date=2014; citation_pages=29-40; citation_doi=10.1016/j.compedu.2013.07.033; citation_id=CR35"/>

    <meta name="citation_reference" content="Minocha S, Tudor AD, Tilling S (2017) Affordances of mobile virtual reality and their role in learning and teaching. In: The 31st British human computer interaction conference, 3&#8211;6 July 2017. University of Sunderland&#8217;s St. Peter&#8217;s Campus, UK, pp 1&#8211;10"/>

    <meta name="citation_reference" content="citation_journal_title=Univ Access Inf Soc; citation_title=Immersive 360 video user experience: impact of different variables in the sense of presence and cybersickness; citation_author=D Narciso, M Bessa, M Melo, A Coelho, J Vasconcelos-Raposo; citation_volume=18; citation_issue=1; citation_publication_date=2019; citation_pages=77-87; citation_doi=10.1007/s10209-017-0581-5; citation_id=CR37"/>

    <meta name="citation_reference" content="citation_title=The psychology of everyday things; citation_publication_date=1980; citation_id=CR38; citation_author=D Norman; citation_publisher=Basic Books"/>

    <meta name="citation_reference" content="citation_title=To understand is to invent: the future of education; citation_publication_date=1974; citation_id=CR39; citation_author=J Piaget; citation_publisher=Viking Press"/>

    <meta name="citation_reference" content="citation_title=The magic school bus wet all over: a book about the water cycle; citation_publication_date=1996; citation_id=CR40; citation_author=P Relf; citation_publisher=Scholastic"/>

    <meta name="citation_reference" content="citation_title=Do We Need to Walk for Effective Virtual Reality Navigation? Physical Rotations Alone May Suffice; citation_inbook_title=Spatial Cognition VII; citation_publication_date=2010; citation_pages=234-247; citation_id=CR41; citation_author=Bernhard E. Riecke; citation_author=Bobby Bodenheimer; citation_author=Timothy P. McNamara; citation_author=Betsy Williams; citation_author=Peng Peng; citation_author=Daniel Feuereissen; citation_publisher=Springer Berlin Heidelberg"/>

    <meta name="citation_reference" content="Ruberto T, Mead C, Semken S, Bruce G, Buxner S, Anbar AD (2017) Proposing a digital teaching network for virtual field experiences [abstract]. In: Proceedings of the geological society of America (GSA); 22&#8211;25 Oct 2017; Seattle, Washington, USA, DC. Geological Society of America abstracts with programs; 2017. vol 49, no 6. 
https://doi.org/10.1130/abs/2017AM-306229


"/>

    <meta name="citation_reference" content="citation_title=Qualitative content analysis in practice; citation_publication_date=2012; citation_id=CR43; citation_author=M Schreier; citation_publisher=SAGE Publishing"/>

    <meta name="citation_reference" content="citation_journal_title=J Geosci Educ; citation_title=Place-based education in geoscience: theory, research, practice, and assessment; citation_author=S Semken, EG Ward, S Moosavi, PWU Chinn; citation_volume=65; citation_issue=4; citation_publication_date=2018; citation_pages=542-562; citation_doi=10.5408/17-276.1; citation_id=CR44"/>

    <meta name="citation_reference" content="citation_title=Implicit learning through embodiment in immersive virtual reality; citation_inbook_title=Virtual, augmented, and mixed realities in education, smart computing and intelligence; citation_publication_date=2017; citation_pages=19-33; citation_id=CR45; citation_author=M Slater; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Front Robot AI; citation_title=Enhancing our lives with immersive virtual reality; citation_author=M Slater, MV Sanchez-Vives; citation_volume=3; citation_publication_date=2016; citation_pages=74; citation_doi=10.3389/frobt.2016.00074; citation_id=CR46"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoper Virtual Environ; citation_title=A framework for immersive virtual environments (five): speculations on the role of presence in virtual environments; citation_author=M Slater, S Wilbur; citation_volume=6; citation_issue=6; citation_publication_date=1997; citation_pages=603-616; citation_doi=10.1162/pres.1997.6.6.603; citation_id=CR47"/>

    <meta name="citation_reference" content="citation_journal_title=Proc Soc Behav Sci; citation_title=Virtual field trips with inquiry learning and critical thinking process: a learning model to enhance students&#8217; science learning outcomes; citation_author=J Sriarunrasmee, P Suwannatthachote, P Dachakupt; citation_volume=197; citation_publication_date=2015; citation_pages=1721-1726; citation_doi=10.1016/j.sbspro.2015.07.226; citation_id=CR48"/>

    <meta name="citation_reference" content="citation_title=Human walking in virtual environments: perception, technology, and applications; citation_publication_date=2013; citation_id=CR49; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=J Geogr High Educ; citation_title=Learning desert geomorphology virtually versus in the field; citation_author=RJ Stumpf, J Douglass, RI Dorn; citation_volume=32; citation_issue=3; citation_publication_date=2008; citation_pages=387-399; citation_doi=10.1080/03098260802221140; citation_id=CR50"/>

    <meta name="citation_reference" content="Unity: Unity3d (2018). 
https://unity3d.com/

. Accessed 3 Apr 2018"/>

    <meta name="citation_reference" content="Vorderer P, Wirth W, Gouveia FR, Biocca F, Saari T, J&#228;ncke F, B&#246;cking S, Schramm H, Gysbers A, Hartmann T, Klimmt C, Laarni J, Ravaja N, Sacau A, Baumgartner T, J&#228;ncke P (2004) MEC spatial presence questionnaire (MEC-SPQ): short documentation and instructions for application. 
https://academic.csuohio.edu/kneuendorf/frames/MECFull.pdf

. Accessed 27 Sept 2017"/>

    <meta name="citation_reference" content="Vygotski&#301; LS, Cole M (1978) Mind in society: the development of higher psychological processes, edited by Michael Cole et al. (translated from the Russian). Harvard University Press, Cambridge, MA and London"/>

    <meta name="citation_reference" content="Zhao J, Klippel A (2019) Scale-unexplored opportunities for immersive technologies in place-based learning. In: 2019 IEEE conference on virtual reality and 3D user interfaces (VR), Osaka, Japan. IEEE, pp 155&#8211;162. 
https://doi.org/10.1109/VR.2019.8797867


"/>

    <meta name="citation_reference" content="Zhao J, Klippel A, Minear M, Newcombe N, Bodenheimer B, McNamara T, Nazareth A, Sensibaugh T (2018) Desktop versus immersive virtual environments: effects on spatial learning [abstract]. In: 7th international conference on spatial cognition (ICSC Rome)"/>

    <meta name="citation_author" content="Alexander Klippel"/>

    <meta name="citation_author_email" content="klippel@psu.edu"/>

    <meta name="citation_author_institution" content="ChoroPhronesis, Department of Geography, The Pennsylvania State University, University Park, USA"/>

    <meta name="citation_author" content="Jiayan Zhao"/>

    <meta name="citation_author_institution" content="ChoroPhronesis, Department of Geography, The Pennsylvania State University, University Park, USA"/>

    <meta name="citation_author" content="Danielle Oprean"/>

    <meta name="citation_author_institution" content="School of Information Science and Learning Technologies, University of Missouri, Columbia, USA"/>

    <meta name="citation_author" content="Jan Oliver Wallgr&#252;n"/>

    <meta name="citation_author_institution" content="ChoroPhronesis, Department of Geography, The Pennsylvania State University, University Park, USA"/>

    <meta name="citation_author" content="Chris Stubbs"/>

    <meta name="citation_author_institution" content="Teaching and Learning with Technology, The Pennsylvania State University, University Park, USA"/>

    <meta name="citation_author" content="Peter La Femina"/>

    <meta name="citation_author_institution" content="Department of Geosciences, The Pennsylvania State University, University Park, USA"/>

    <meta name="citation_author" content="Kathy L. Jackson"/>

    <meta name="citation_author_institution" content="School of Engineering Design, Technology, and Professional Programs, The Pennsylvania State University, State College, USA"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-019-00418-5&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-019-00418-5"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="The value of being there: toward a science of immersive virtual field trips"/>
        <meta property="og:description" content="With immersive experiences becoming a medium for mass communication, we need pedagogies as well as scientific, evidence-based design principles for immersive learning. To foster evidence-based designs of immersive learning, we detail an empirical evaluation of a geosciences field trip, common in undergraduate education across numerous disciplines. The study builds on a previously proposed research framework in which we detailed a basic taxonomy of virtual field trips distinguishing between basic, plus, and advanced immersive virtual field trip experiences. The experiment reported here expands the original evaluation of basic field trips into the realm of plus versions using pseudo-aerial $$360^{\circ }$$360∘ imagery to provide embodied experiences that are not possible during the actual field trip. We also refined our original experimental design placing a stronger focus on the qualitative feedback elicited from the students. Results show an overwhelmingly positive response of students to virtual field trips with significantly higher-valued learning experience and enjoyment. Furthermore, the introduction of pseudo-aerial imagery (together with higher image resolution) shows a significant improvement in the participants spatial situation model. As contextualizing and spatially grounding is essential for place-based learning experiences, plus versions of virtual field trips have the potential to add value to the learning outcome and immersive virtual field trip experience. We discuss these encouraging results as well as critical feedback from the participants, such as the absence of touch in virtual experiences, and lay out our vision for the future of immersive learning experiences across environmental sciences."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>The value of being there: toward a science of immersive virtual field trips | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-019-00418-5","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Immersive learning, Virtual field trips, STEM, Place-based learning","kwrd":["Immersive_learning","Virtual_field_trips","STEM","Place-based_learning"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-019-00418-5","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-019-00418-5","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=418;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-019-00418-5">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            The value of being there: toward a science of immersive virtual field trips
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-019-00418-5.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-019-00418-5.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">S.I.: XR (VR, AR, MR) and Immersive Learning Environments</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2019-12-21" itemprop="datePublished">21 December 2019</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">The value of being there: toward a science of immersive virtual field trips</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Alexander-Klippel" data-author-popup="auth-Alexander-Klippel" data-corresp-id="c1">Alexander Klippel<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><span class="u-js-hide"> 
            <a class="js-orcid" itemprop="url" href="http://orcid.org/0000-0002-7171-492X"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-7171-492X</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="The Pennsylvania State University" /><meta itemprop="address" content="grid.29857.31, 0000 0001 2097 4281, ChoroPhronesis, Department of Geography, The Pennsylvania State University, University Park, PA, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Jiayan-Zhao" data-author-popup="auth-Jiayan-Zhao">Jiayan Zhao</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="The Pennsylvania State University" /><meta itemprop="address" content="grid.29857.31, 0000 0001 2097 4281, ChoroPhronesis, Department of Geography, The Pennsylvania State University, University Park, PA, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Danielle-Oprean" data-author-popup="auth-Danielle-Oprean">Danielle Oprean</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Missouri" /><meta itemprop="address" content="grid.134936.a, 0000 0001 2162 3504, School of Information Science and Learning Technologies, University of Missouri, Columbia, MO, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Jan_Oliver-Wallgr_n" data-author-popup="auth-Jan_Oliver-Wallgr_n">Jan Oliver Wallgrün</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="The Pennsylvania State University" /><meta itemprop="address" content="grid.29857.31, 0000 0001 2097 4281, ChoroPhronesis, Department of Geography, The Pennsylvania State University, University Park, PA, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Chris-Stubbs" data-author-popup="auth-Chris-Stubbs">Chris Stubbs</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="The Pennsylvania State University" /><meta itemprop="address" content="grid.29857.31, 0000 0001 2097 4281, Teaching and Learning with Technology, The Pennsylvania State University, University Park, PA, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Peter-La_Femina" data-author-popup="auth-Peter-La_Femina">Peter La Femina</a></span><sup class="u-js-hide"><a href="#Aff4">4</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="The Pennsylvania State University" /><meta itemprop="address" content="grid.29857.31, 0000 0001 2097 4281, Department of Geosciences, The Pennsylvania State University, University Park, PA, USA" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Kathy_L_-Jackson" data-author-popup="auth-Kathy_L_-Jackson">Kathy L. Jackson</a></span><sup class="u-js-hide"><a href="#Aff5">5</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="The Pennsylvania State University" /><meta itemprop="address" content="grid.29857.31, 0000 0001 2097 4281, School of Engineering Design, Technology, and Professional Programs, The Pennsylvania State University, State College, PA, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            (<span data-test="article-publication-year">2019</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">263 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">2 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-019-00418-5/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>With immersive experiences becoming a medium for mass communication, we need pedagogies as well as scientific, evidence-based design principles for immersive learning. To foster evidence-based designs of immersive learning, we detail an empirical evaluation of a geosciences field trip, common in undergraduate education across numerous disciplines. The study builds on a previously proposed research framework in which we detailed a basic taxonomy of virtual field trips distinguishing between basic, plus, and advanced immersive virtual field trip experiences. The experiment reported here expands the original evaluation of basic field trips into the realm of plus versions using pseudo-aerial <span class="mathjax-tex">\(360^{\circ }\)</span> imagery to provide embodied experiences that are not possible during the actual field trip. We also refined our original experimental design placing a stronger focus on the qualitative feedback elicited from the students. Results show an overwhelmingly positive response of students to virtual field trips with significantly higher-valued learning experience and enjoyment. Furthermore, the introduction of pseudo-aerial imagery (together with higher image resolution) shows a significant improvement in the participants spatial situation model. As contextualizing and spatially grounding is essential for place-based learning experiences, plus versions of virtual field trips have the potential to add value to the learning outcome and immersive virtual field trip experience. We discuss these encouraging results as well as critical feedback from the participants, such as the absence of touch in virtual experiences, and lay out our vision for the future of immersive learning experiences across environmental sciences.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>It is undisputed that contextualized, place-based learning offers a broad spectrum of advantages to students (Semken et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Semken S, Ward EG, Moosavi S, Chinn PWU (2018) Place-based education in geoscience: theory, research, practice, and assessment. J Geosci Educ 65(4):542–562. &#xA;https://doi.org/10.5408/17-276.1&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR44" id="ref-link-section-d41158e419">2018</a>; Dede <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Dede C (2009) Immersive interfaces for engagement and learning. Science (New York, N.Y.) 323(5910):66–69. &#xA;https://doi.org/10.1126/science.1167311&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR13" id="ref-link-section-d41158e422">2009</a>; Elkins and Elkins <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Elkins J, Elkins NML (2007) Teaching geology in the field: significant geoscience concept gains in entirely field-based introductory geology courses. J Geosci Educ 55(2):126–132" href="/article/10.1007/s10055-019-00418-5#ref-CR15" id="ref-link-section-d41158e425">2007</a>). While the number of field trips offered is typically relatively small, they are an integral part of many academic disciplines. Most educators agree that if resources would not be a limiting factor, field trips, as an important aspect of place-based learning, would be offered on a more regular basis, to more remote places, to larger audiences, and include longer stays at a particular site (Elkins and Elkins <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Elkins J, Elkins NML (2007) Teaching geology in the field: significant geoscience concept gains in entirely field-based introductory geology courses. J Geosci Educ 55(2):126–132" href="/article/10.1007/s10055-019-00418-5#ref-CR15" id="ref-link-section-d41158e428">2007</a>). Who would not want to have their learning experiences be as exciting as the Magic School Bus (Relf <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Relf P (1996) The magic school bus wet all over: a book about the water cycle. Scholastic, New York" href="/article/10.1007/s10055-019-00418-5#ref-CR40" id="ref-link-section-d41158e431">1996</a>)? And, in an ideal world, the growing community of online learners or people with physical disabilities would not be left out categorically but rather be able to participate in regular field trips as well.</p><p>Ever since the rise of electronic graphic displays, the concept of virtual field trips has been envisioned in environmental sciences and related disciplines as a means to circumvent the limiting factors and potential risks of actual field trips (Hurst <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Hurst SD (1998) Use of “virtual” field trips in teaching introductory geology. Comput Geosci 24(7):653–658. &#xA;https://doi.org/10.1016/S0098-3004(98)00043-0&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR20" id="ref-link-section-d41158e437">1998</a>; Dolphin et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Dolphin G, Dutchak A, Karchewski B, Cooper J (2019) Virtual field experiences in introductory geology: addressing a capacity problem, but finding a pedagogical one. J Geosci Educ 67(2):114–130. &#xA;https://doi.org/10.1080/10899995.2018.1547034&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR14" id="ref-link-section-d41158e440">2019</a>). Virtual, for the majority of existing examples, means that students do not visit the actual field site but access a representation of it through web-based information: photographs, text, audio, and other media (Mead et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Mead C, Buxner S, Bruce G, Taylor W, Semken S, Anbar AD (2019) Immersive, interactive virtual field trips promote science learning. J Geosci Educ 67(2):131–142. &#xA;https://doi.org/10.1080/10899995.2019.1565285&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR34" id="ref-link-section-d41158e443">2019</a>; Dolphin et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Dolphin G, Dutchak A, Karchewski B, Cooper J (2019) Virtual field experiences in introductory geology: addressing a capacity problem, but finding a pedagogical one. J Geosci Educ 67(2):114–130. &#xA;https://doi.org/10.1080/10899995.2018.1547034&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR14" id="ref-link-section-d41158e446">2019</a>). Panoramas and <span class="mathjax-tex">\(360^{\circ }\)</span> images, as one example, have been used for several decades; only recent developments allow for their collection and use at scale though. Today, access to web-based <span class="mathjax-tex">\(360^{\circ }\)</span> tour creators such as ThinkLink,<sup><a href="#Fn1"><span class="u-visually-hidden">Footnote </span>1</a></sup> Roundme,<sup><a href="#Fn2"><span class="u-visually-hidden">Footnote </span>2</a></sup> or Google Tour Creator<sup><a href="#Fn3"><span class="u-visually-hidden">Footnote </span>3</a></sup> allows everyone with an off-the-shelf <span class="mathjax-tex">\(360^{\circ }\)</span> camera or the patience to stitch individual images to create virtual experiences of places. Web-based <span class="mathjax-tex">\(360^{\circ }\)</span> tours offer a sense of agency through the ability to pan the camera inside the image, changing one’s perspective, and essentially explore a place through a <span class="mathjax-tex">\(360^{\circ }\)</span> view but without physical movement and the option to look around by turning one’s head.</p><p>We can take the concept of agency one step further and change the interface from a static egocentric perspective to a dynamic one through enhanced tracking capabilities (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig1">1</a>). We can use head-mounted displays to afford users the same agency they experience in the physical world, matching a change in viewing direction as the result of turning one’s head with a corresponding change of view they would experience in their natural physical environment. This is an important distinction as it reflects the transformative nature of current developments in immersive technologies instead of being separated from the digital content we use to understand an environment, we are becoming part of the digital representation itself; we are (fully) immersed visually. The possibility to look over one’s shoulder and still experiencing the digital representation of a place has a strong effect on people’s sense of presence (Slater and Sanchez-Vives <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Slater M, Sanchez-Vives MV (2016) Enhancing our lives with immersive virtual reality. Front Robot AI 3:74. &#xA;https://doi.org/10.3389/frobt.2016.00074&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR46" id="ref-link-section-d41158e533">2016</a>; Narciso et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Narciso D, Bessa M, Melo M, Coelho A, Vasconcelos-Raposo J (2019) Immersive 360 video user experience: impact of different variables in the sense of presence and cybersickness. Univ Access Inf Soc 18(1):77–87. &#xA;https://doi.org/10.1007/s10209-017-0581-5&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR37" id="ref-link-section-d41158e536">2019</a>). While presence—the feeling of being there—is not necessarily connected causally to learning, we find active discussions and positive (Krokos et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Krokos E, Plaisant C, Varshney A (2018) Virtual memory palaces: immersion aids recall. Virtual Real 23:1–15. &#xA;https://doi.org/10.1007/s10055-018-0360-5&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR27" id="ref-link-section-d41158e539">2018</a>; Markowitz et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Markowitz DM, Laha R, Perone BP, Pea RD, Bailenson JN (2018) Immersive virtual reality field trips facilitate learning about climate change. Front Psychol 9:2364. &#xA;https://doi.org/10.3389/fpsyg.2018.02364&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR33" id="ref-link-section-d41158e542">2018</a>) as well as adverse effects (Makransky et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Makransky G, Terkildsen TS, Mayer RE (2017) Adding immersive virtual reality to a science lab simulation causes more presence but less learning. Learn Instr. &#xA;https://doi.org/10.1016/j.learninstruc.2017.12.007&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR32" id="ref-link-section-d41158e546">2017</a>). Effects of presence on place-based learning are largely unexplored.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig1_HTML.png?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig1_HTML.png" alt="figure1" loading="lazy" width="685" height="207" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Desktop (left) and immersive VR (right) users apply different interactions to access virtual field sites</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>At this point, agency is still limited to changing one’s viewing direction, not one’s location, an experience we cannot create using <span class="mathjax-tex">\(360^{\circ }\)</span> images other than sequentially teleporting from image to image. If we advance immersive experiences through the use of 3D models and room-scale tracking, we can further increase the degree of agency affording users the freedom to move around in the environment [for locomotion challenges see Steinicke et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Steinicke F, Visell Y, Campos J, Lécuyer A (eds) (2013) Human walking in virtual environments: perception, technology, and applications. Springer, New York" href="/article/10.1007/s10055-019-00418-5#ref-CR49" id="ref-link-section-d41158e570">2013</a>)]. More importantly, 3D models allow for interacting with the environment; they allow to design and perform the kind of activities we would like students to experience at a place such as measuring the thickness of rock layers or the density of plants along transects.</p><p>
Blascovich and Bailenson (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Blascovich J, Bailenson J (2011) Infinite reality: avatars, eternal life, new worlds, and the dawn of the virtual revolution, 1st edn. William Morrow, New York" href="/article/10.1007/s10055-019-00418-5#ref-CR2" id="ref-link-section-d41158e577">2011</a>) point out that VR allows for creating infinite realities. In the case of virtual field trips, we may not want to go as far as creating fantasy worlds, but it is conceivable to create idealized experiences demonstrating critical processes such as the genesis of geomorphological features using simulations that have become prominent in the geo-spatial sciences. We can also afford users access to their physical environments otherwise not possible, something that could also be used to supplement actual field trips (see Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-019-00418-5#Sec10">6</a>). Examples of expanding reality relevant for field trip experiences include access to an environment at different scales through elevated perspectives using drones, balloons, or large tripods. If models are available, users can manipulate environments and look under the hood of an outcrop or warping space and time. For example, students can instantaneously travel to both sides of the Atlantic to experience evidence of plate tectonics, looking at outcrops of the Appalachians and those formed during the same time period in Western Europe i.e., the Caledonian Mountains, within the same lab session to witness the similarities in how each were created.</p><p>These are but a few examples that have been discussed in the past (Fisher and Unwin <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Fisher PF, Unwin D (eds) (2002) Virtual reality in geography. Taylor &amp; Francis, London and New York" href="/article/10.1007/s10055-019-00418-5#ref-CR16" id="ref-link-section-d41158e586">2002</a>) but have not been conceptualized in depth as the technical realities did not provide for an environment where solutions were feasible and affordable [for exceptions see Dede (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Dede C (2009) Immersive interfaces for engagement and learning. Science (New York, N.Y.) 323(5910):66–69. &#xA;https://doi.org/10.1126/science.1167311&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR13" id="ref-link-section-d41158e589">2009</a>)]. Current developments are pushing immersive experiences into the consumer realm, solving technical and affordability issues. We witness both low-cost and high-end solutions for experiencing the world, virtually hitting the market in increasing numbers. Changes in immersive technologies are accompanied by rapid developments in environmental sensing technologies (Carrivick et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Carrivick JL, Smith MW, Quincey DJ (2016) Structure from motion in the geosciences. Wiley, Chichester. &#xA;https://doi.org/10.1002/9781118895818&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR9" id="ref-link-section-d41158e592">2016</a>), a basis for creating realistic and adaptive immersive experiences with a tremendous potential to improve learning. But therein lies the crux: While the technology is rapidly developing and evolving, we lack an empirical grounding of conceptual frameworks for assessing and optimizing immersive learning experiences.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Background</h2><div class="c-article-section__content" id="Sec2-content"><p>Immersive technologies integrate intimately with established principles in learning and learning design. Dede (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Dede C (2009) Immersive interfaces for engagement and learning. Science (New York, N.Y.) 323(5910):66–69. &#xA;https://doi.org/10.1126/science.1167311&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR13" id="ref-link-section-d41158e603">2009</a>) discusses some of the main aspects that have demonstrated validity under empirical scrutiny and can be summarized in the following way: providing multiple perspectives, situating the learner, and allowing for acquiring knowledge that can be transferred. These aspects are deeply grounded in established learning theories and theoretical frameworks of constructivism (Piaget <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1974" title="Piaget J (1974) To understand is to invent: the future of education, 1 viking compass edn. Viking Press, New York" href="/article/10.1007/s10055-019-00418-5#ref-CR39" id="ref-link-section-d41158e606">1974</a>) and, especially, situated learning (Lave and Wenger <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Lave J, Wenger E (1991) Situated learning: legitimate peripheral participation. Learning in doing: social, cognitive, and computational perspectives. Cambridge University Press, Cambridge" href="/article/10.1007/s10055-019-00418-5#ref-CR29" id="ref-link-section-d41158e609">1991</a>) that stress the importance of being active to construct meaning (Vygotskiĭ and Cole <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1978" title="Vygotskiĭ LS, Cole M (1978) Mind in society: the development of higher psychological processes, edited by Michael Cole et al. (translated from the Russian). Harvard University Press, Cambridge, MA and London" href="/article/10.1007/s10055-019-00418-5#ref-CR53" id="ref-link-section-d41158e612">1978</a>). Immersive technologies, in stark contrast to other digital learning technologies, offer opportunities to realize some of the ideals of learning that were not possible before in the digital world. Of particular importance for place-based education are aspects of embodiment and agency (Johnson-Glenberg <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Johnson-Glenberg MC (2018) Immersive VR and education: embodied design principles that include gesture and hand controls. Front Robot AI 5:27. &#xA;https://doi.org/10.3389/frobt.2018.00081&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR21" id="ref-link-section-d41158e615">2018</a>; Minocha et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Minocha S, Tudor AD, Tilling S (2017) Affordances of mobile virtual reality and their role in learning and teaching. In: The 31st British human computer interaction conference, 3–6 July 2017. University of Sunderland’s St. Peter’s Campus, UK, pp 1–10" href="/article/10.1007/s10055-019-00418-5#ref-CR36" id="ref-link-section-d41158e619">2017</a>; Markowitz et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Markowitz DM, Laha R, Perone BP, Pea RD, Bailenson JN (2018) Immersive virtual reality field trips facilitate learning about climate change. Front Psychol 9:2364. &#xA;https://doi.org/10.3389/fpsyg.2018.02364&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR33" id="ref-link-section-d41158e622">2018</a>).</p><p>It is equally important to stress that despite widespread agreement and excitement for immersive technologies on how they cater to general learning theories, there is a lack of empirical studies in educational settings (Markowitz et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Markowitz DM, Laha R, Perone BP, Pea RD, Bailenson JN (2018) Immersive virtual reality field trips facilitate learning about climate change. Front Psychol 9:2364. &#xA;https://doi.org/10.3389/fpsyg.2018.02364&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR33" id="ref-link-section-d41158e628">2018</a>); there is a paucity of design guidelines for how to make optimal educational content (Johnson-Glenberg <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Johnson-Glenberg MC (2018) Immersive VR and education: embodied design principles that include gesture and hand controls. Front Robot AI 5:27. &#xA;https://doi.org/10.3389/frobt.2018.00081&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR21" id="ref-link-section-d41158e631">2018</a>), and there is a lack of relevant pedagogies (Fowler <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Fowler C (2015) Virtual reality and learning: where is the pedagogy? Br J Educ Technol 46(2):412–422. &#xA;https://doi.org/10.1111/bjet.12135&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR17" id="ref-link-section-d41158e634">2015</a>). Equally important, while there are emerging empirical studies that speak to the benefits of immersive technologies (Kamarainen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Kamarainen AM, Thompson M, Metcalf SJ, Grotzer TA, Tutwiler MS, Dede C (2018) Prompting connections between content and context: blending immersive virtual environments and augmented reality for environmental science learning. In: Beck D, Pena-Rios A, Ogle T, Allison C, Morgado L, Pirker J, Richter J, Gütl C (eds) iLRN 2018 Montana: workshop, long and short paper , and poster proceedings from the fourth immersive learning research network conference. Verlag der Technischen Universität Graz, Graz, Austria, pp 36–54. &#xA;https://doi.org/10.1007/978-3-319-93596-6_3&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR22" id="ref-link-section-d41158e637">2018</a>; Bursztyn et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Bursztyn N, Shelton B, Walker A, Pederson J (2017) Increasing undergraduate interest to learn geoscience with GPS-based augmented reality field trips on students’ own smartphones. GSA Today 27:4–10. &#xA;https://doi.org/10.1130/GSATG304A.1&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR7" id="ref-link-section-d41158e640">2017</a>), there are also studies that find no or even negative effects (Makransky et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Makransky G, Terkildsen TS, Mayer RE (2017) Adding immersive virtual reality to a science lab simulation causes more presence but less learning. Learn Instr. &#xA;https://doi.org/10.1016/j.learninstruc.2017.12.007&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR32" id="ref-link-section-d41158e644">2017</a>). On the positive side, we often find there is an increase in engagement and motivation and students are particularly satisfied with their learning experiences (Allcoat and von Mühlenen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Allcoat D, von Mühlenen A (2018) Learning in virtual reality: effects on performance, emotion and engagement. Res Learn Technol. &#xA;https://doi.org/10.25304/rlt.v26.2140&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR1" id="ref-link-section-d41158e647">2018</a>). Yet, it will be a matter of time to separate the excitement from engaging with novel technologies to establish a connection between the affordances of immersive technologies and tangible improvements in learning.</p><p>For place-based learning approaches, there are only a few studies that provide an empirical foundation for the value of immersive education. Focusing on climate change and resulting changes in ocean acidification, Markowitz et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Markowitz DM, Laha R, Perone BP, Pea RD, Bailenson JN (2018) Immersive virtual reality field trips facilitate learning about climate change. Front Psychol 9:2364. &#xA;https://doi.org/10.3389/fpsyg.2018.02364&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR33" id="ref-link-section-d41158e653">2018</a>) conducted a series of four studies. Participants experienced an immersive 3D under-water environment using an Oculus Rift DK2 or an HTC Vive, integrated into existing educational settings or part of a public event, that is, the Tribeca Fim Festival. The results of their studies show generally positive effects of immersive experiences on learning across different settings. Participants showed positive knowledge gains as well as an increase in learning interest about acidification. They were also able to relate the unique characteristics of immersive technologies, that is, the feeling of non-mediation (Slater and Wilbur <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Slater M, Wilbur S (1997) A framework for immersive virtual environments (five): speculations on the role of presence in virtual environments. Presence Teleoper Virtual Environ 6(6):603–616. &#xA;https://doi.org/10.1162/pres.1997.6.6.603&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR47" id="ref-link-section-d41158e656">1997</a>) through a visceral connection with the digital content, with positive learning outcomes. Minocha et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Minocha S, Tudor AD, Tilling S (2017) Affordances of mobile virtual reality and their role in learning and teaching. In: The 31st British human computer interaction conference, 3–6 July 2017. University of Sunderland’s St. Peter’s Campus, UK, pp 1–10" href="/article/10.1007/s10055-019-00418-5#ref-CR36" id="ref-link-section-d41158e659">2017</a>) develop a theoretical underpinning of mobile virtual reality, in particular, Google Expeditions. Their research focus was on school students and compared both in-class and during field trip use of immersive experiences. Their analysis is centered on semi-structured interviews that they evaluated under the theoretical framework of affordances (Norman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1980" title="Norman D (1980) The psychology of everyday things. Basic Books, New York" href="/article/10.1007/s10055-019-00418-5#ref-CR38" id="ref-link-section-d41158e662">1980</a>) of immersive technologies allowing them to outline a comprehensive list of potentially beneficial characteristics of immersive experiences on learning that go beyond what is possible using phone-based VR applications (e.g., 3D fiew, first-person perspective). Looking beyond recent developments and opportunities in immersive technologies, the idea of virtual field trips has great appeal for manifold reasons [see Klippel et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019a" title="Klippel A, Zhao J, Jackson KL, LaFemina P, Stubbs C, Oprean D, Wallgrün JO, Blair J (2019a) Transforming earth science education through immersive experiences: delivering on a long held promise. J Educ Comput Res 57(7):1745–1771. &#xA;https://doi.org/10.1177/0735633119854025&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR25" id="ref-link-section-d41158e665">2019a</a>) and Dolphin et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Dolphin G, Dutchak A, Karchewski B, Cooper J (2019) Virtual field experiences in introductory geology: addressing a capacity problem, but finding a pedagogical one. J Geosci Educ 67(2):114–130. &#xA;https://doi.org/10.1080/10899995.2018.1547034&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR14" id="ref-link-section-d41158e669">2019</a>) for overviews] and non-immersive, often desktop-based VFT have received some empirical scrutiny with slightly positive, but largely mixed results (Ruberto et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Ruberto T, Mead C, Semken S, Bruce G, Buxner S, Anbar AD (2017) Proposing a digital teaching network for virtual field experiences [abstract]. In: Proceedings of the geological society of America (GSA); 22–25 Oct 2017; Seattle, Washington, USA, DC. Geological Society of America abstracts with programs; 2017. vol 49, no 6. &#xA;https://doi.org/10.1130/abs/2017AM-306229&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR42" id="ref-link-section-d41158e672">2017</a>; Stumpf et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Stumpf RJ, Douglass J, Dorn RI (2008) Learning desert geomorphology virtually versus in the field. J Geogr High Educ 32(3):387–399. &#xA;https://doi.org/10.1080/03098260802221140&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR50" id="ref-link-section-d41158e675">2008</a>). More recently, desktop-based VFTs have been combined with adaptive learning technologies, which lead to mostly positive results (Mead et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Mead C, Buxner S, Bruce G, Taylor W, Semken S, Anbar AD (2019) Immersive, interactive virtual field trips promote science learning. J Geosci Educ 67(2):131–142. &#xA;https://doi.org/10.1080/10899995.2019.1565285&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR34" id="ref-link-section-d41158e678">2019</a>). Desktop-based VFTs, however, fall short of catering to the learning environments desired from a learning theoretical perspective laid out above. They do not promote a sense of embodiment and therefore do not provide the same agency of mobility and situatedness that immersive VFTs afford. Given the mouse and keyboard interface of desktop virtuality, these classic VFTs are far from having natural user interfaces with all the associated disadvantages [see Johnson-Glenberg (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Johnson-Glenberg MC (2018) Immersive VR and education: embodied design principles that include gesture and hand controls. Front Robot AI 5:27. &#xA;https://doi.org/10.3389/frobt.2018.00081&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR21" id="ref-link-section-d41158e681">2018</a>) for a review]. That said, the discussion of the positive and/or negative effects of immersive is active and not conclusively answered (Makransky et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Makransky G, Terkildsen TS, Mayer RE (2017) Adding immersive virtual reality to a science lab simulation causes more presence but less learning. Learn Instr. &#xA;https://doi.org/10.1016/j.learninstruc.2017.12.007&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR32" id="ref-link-section-d41158e684">2017</a>; Markowitz et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Markowitz DM, Laha R, Perone BP, Pea RD, Bailenson JN (2018) Immersive virtual reality field trips facilitate learning about climate change. Front Psychol 9:2364. &#xA;https://doi.org/10.3389/fpsyg.2018.02364&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR33" id="ref-link-section-d41158e688">2018</a>; Bowman and McMahan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Bowman DA, McMahan RP (2007) Virtual reality: how much immersion is enough? Computer 40(7):36–43" href="/article/10.1007/s10055-019-00418-5#ref-CR4" id="ref-link-section-d41158e691">2007</a>).</p><p>For augmented reality (AR) technologies, which are not the focus of this article, the results are generally more positive. For example, Carbonell Carrera and Bermejo Asensio (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Carbonell Carrera C, Bermejo Asensio LA (2017) Landscape interpretation with augmented reality and maps to improve spatial orientation skill. J Geogr High Educ 41(1):119–133. &#xA;https://doi.org/10.1080/03098265.2016.1260530&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR8" id="ref-link-section-d41158e697">2017</a>) found that using AR-enhanced topographic maps, compared to standard 2D maps, leads to significantly improved spatial orientation skills. Likewise, Bursztyn et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Bursztyn N, Shelton B, Walker A, Pederson J (2017) Increasing undergraduate interest to learn geoscience with GPS-based augmented reality field trips on students’ own smartphones. GSA Today 27:4–10. &#xA;https://doi.org/10.1130/GSATG304A.1&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR7" id="ref-link-section-d41158e700">2017</a>) found that using an AR experience to teach students the geology of the Grand Canyon (on their own campus) leads to an increase in students’ interest, engagement and has the potential for improved learning outcomes.</p><p>One aspect that has not received any attention is the integration of senses beyond vision and audio into immersive experiences for place-based education and their effects on learning outcomes. While there is research on the benefits of, for example, tangible user interfaces (Clifton et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Clifton PG, Chang JSK, Yeboah G, Doucette A, Chandrasekharan S, Nitsche M, Welsh T, Mazalek A (2016) Design of embodied interfaces for engaging spatial cognition. Cognit Res Princ Implic 1(1):24. &#xA;https://doi.org/10.1186/s41235-016-0032-5&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR11" id="ref-link-section-d41158e707">2016</a>), there is virtually no study on integrating senses such as smell or wind into iVFTs. It is generally believed that the availability of additional increased sensory feedback leads to higher levels of presence (Slater and Sanchez-Vives <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Slater M, Sanchez-Vives MV (2016) Enhancing our lives with immersive virtual reality. Front Robot AI 3:74. &#xA;https://doi.org/10.3389/frobt.2016.00074&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR46" id="ref-link-section-d41158e710">2016</a>), but to the best of our knowledge, there are no studies that would relate the degree of sensory feedback to learning outcomes and experiences. We will discuss in the Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-019-00418-5#Sec10">6</a> opportunities to address this shortcoming.</p><p>In response to many unanswered questions for research on place-based education through immersive experiences, we developed a simple taxonomy [see Klippel et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019a" title="Klippel A, Zhao J, Jackson KL, LaFemina P, Stubbs C, Oprean D, Wallgrün JO, Blair J (2019a) Transforming earth science education through immersive experiences: delivering on a long held promise. J Educ Comput Res 57(7):1745–1771. &#xA;https://doi.org/10.1177/0735633119854025&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR25" id="ref-link-section-d41158e719">2019a</a>)]. This taxonomy provides the basis for conceptual and theoretical considerations of how to design empirical evaluations of iVFTs and supports advancing the science behind iVFTs. The taxonomy is grounded in our own practical work as well as a reflection of critical components in the field of immersive technologies and immersive learning. For example, Blascovich and Bailenson (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Blascovich J, Bailenson J (2011) Infinite reality: avatars, eternal life, new worlds, and the dawn of the virtual revolution, 1st edn. William Morrow, New York" href="/article/10.1007/s10055-019-00418-5#ref-CR2" id="ref-link-section-d41158e722">2011</a>) stress the fact that VR provides us with access to infinite realities, something that is echoed by Slater (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Slater M (2017) Implicit learning through embodiment in immersive virtual reality. In: Liu D, Dede C, Huang R, Richards J (eds) Virtual, augmented, and mixed realities in education, smart computing and intelligence. Springer, Singapore, pp 19–33" href="/article/10.1007/s10055-019-00418-5#ref-CR45" id="ref-link-section-d41158e725">2017</a>) in a recent contribution to a book on immersive learning (Liu et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Liu D, Dede C, Huang R, Richards J (eds) (2017) Virtual, augmented, and mixed realities in education. Smart computing and intelligence. Springer, Singapore" href="/article/10.1007/s10055-019-00418-5#ref-CR31" id="ref-link-section-d41158e728">2017</a>). Dede (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Dede C (2009) Immersive interfaces for engagement and learning. Science (New York, N.Y.) 323(5910):66–69. &#xA;https://doi.org/10.1126/science.1167311&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR13" id="ref-link-section-d41158e731">2009</a>) pointed out that changing one’s perspective, for example, from an egocentric to an exocentric/allocentric frame of reference, is a powerful means of understanding complex phenomena. Furthermore, simulations have long been held in high regard by the education community as they allow learners to test the effect of input variables on outcomes [see de Jong (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="de Jong T (1991) Learning and instruction with computer simulations. Educ Comput 6(3):217–229. &#xA;https://doi.org/10.1016/0167-9287(91)80002-F&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR12" id="ref-link-section-d41158e735">1991</a>); Merchant et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Merchant Z, Goetz ET, Cifuentes L, Keeney-Kennicutt W, Davis TJ (2014) Effectiveness of virtual reality-based instruction on students’ learning outcomes in k-12 and higher education: a meta-analysis. Comput Educ 70:29–40. &#xA;https://doi.org/10.1016/j.compedu.2013.07.033&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR35" id="ref-link-section-d41158e738">2014</a>)], that is, to verify or falsify hypotheses.</p><p>The taxonomy places (immersive) virtual field trips into one of the three general categories: first, those that aim for building a digital version of an actual site, limiting user experiences to similar constraints as someone would face at an actual field site (<i>basic</i>); second, those that build a digital version of a field site but allow for perspectives and access to a site not possible in the physical world such as elevated perspectives or spatially warping distant locations (<i>plus</i>); and, finally, virtual field trips that require models of sites that go beyond the visible physical reality allowing for taking off the hood of, for example, mountains or run simulations of future or past events (<i>advanced</i>). As there is a steep learning curve associated with creating experiences in these three categories, it is essential to start an evaluation with basic virtual field trips and move from there to quantify learning gains by investing into more resource-demanding categories (such as plus or advance field trips). In the current article, we are moving into the realm of plus iVFTs (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig2">2</a>). </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig2_HTML.png?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig2_HTML.png" alt="figure2" loading="lazy" width="685" height="308" /></picture></a><p class="c-article-section__figure-credit text-right c-article-section__figure-credit-right" data-test="figure-credit">Modified from Klippel et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019a" title="Klippel A, Zhao J, Jackson KL, LaFemina P, Stubbs C, Oprean D, Wallgrün JO, Blair J (2019a) Transforming earth science education through immersive experiences: delivering on a long held promise. J Educ Comput Res 57(7):1745–1771. &#xA;https://doi.org/10.1177/0735633119854025&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR25" id="ref-link-section-d41158e764">2019a</a>)</p></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Taxonomy of immersive virtual field trips (iVFTs) from basic, to plus, to advanced. In this study, we are focusing on plus virtual field trips.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>In the current article, we present an empirical evaluation conducted in the Spring of 2018. Building on a previously reported study, we expanded on a basic field trip and moved it from basic into the plus category for an introductory geosciences course. Additionally, we refined and modified our empirical framework which, in the long term, will allow us to systematically evaluate multiple aspects of immersive virtual field trips as a key component of immersive learning. The remainder of the article is structured as follows: We first give an overview of the methods used in this research detailing the immersive experience we created to realize an immersive virtual field trip as well as the experimental setup we used to evaluate its effectiveness. We then provide an analysis of the data we collected, contextualize the results, and offer conclusions and an agenda for future research.</p></div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Methods</h2><div class="c-article-section__content" id="Sec3-content"><p>This immersive virtual field trip (iVFT) study uses a pre-post-post with control group (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig3">3</a>) design to address the following research questions:</p><ul class="u-list-style-bullet"><li><p>Can findings of Klippel et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019a" title="Klippel A, Zhao J, Jackson KL, LaFemina P, Stubbs C, Oprean D, Wallgrün JO, Blair J (2019a) Transforming earth science education through immersive experiences: delivering on a long held promise. J Educ Comput Res 57(7):1745–1771. &#xA;https://doi.org/10.1177/0735633119854025&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR25" id="ref-link-section-d41158e787">2019a</a>) that show positive and largely better learning outcomes for iVFTs compared to actual field trips (AFT) be corroborated?</p></li><li><p>Can the learning experience and other aspects of field site visits be further enhanced by advancing from basic iVFTs to plus iVFTs?</p></li><li><p>What value do immersive virtual experiences have as a preparation for actual field site visits?</p></li><li><p>What aspects of immersive iVFTs fall short compared to AFTs?</p></li></ul><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig3">3</a> provides an overview of the overall study design that we will detail in the following section. In contrast to our previous study (Klippel et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019a" title="Klippel A, Zhao J, Jackson KL, LaFemina P, Stubbs C, Oprean D, Wallgrün JO, Blair J (2019a) Transforming earth science education through immersive experiences: delivering on a long held promise. J Educ Comput Res 57(7):1745–1771. &#xA;https://doi.org/10.1177/0735633119854025&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR25" id="ref-link-section-d41158e803">2019a</a>), all students participated in the AFT, too. This arrangement gave us the opportunity to explore VFTs as preparation for AFTs but was also a result of a request from the extremely supportive instructor who strongly believes in actual field site experiences. We are discussing this challenge in greater detail in the Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-019-00418-5#Sec10">6</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig3_HTML.png?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig3_HTML.png" alt="figure3" loading="lazy" width="685" height="933" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Overview of the study design with the process for the AFT group on the left and the process for the iVFT group on the right</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec4">Concepts and measures/instruments</h3><p>To provide an overview on the comprehensive assessment of the learning experience of students in the iVFT group and how it compares to that of students in the AFT we performed in this study, we summarize the variables, rational, and assessment in form of a table (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-019-00418-5#Tab1">1</a>). We will use this table to structure the analysis and the discussion.</p><p>We used a number of standardized and customized instruments to assess both the learning experience as well as the learning outcome, the actual assignment for the field trip. Specifically, we have access to the grades of the lab assignment that students had to take after the field trip as an objective measure of their performance. We administered the assessments to both groups (iVFT and control) as well as between experiences for the iVFT group (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig3">3</a> for an overview). To assess individual differences (in addition to demographics), we used the Santa Barbara Sense of Direction Scale (Hegarty <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Hegarty M (2002) Development of a self-report measure of environmental spatial ability. Intelligence 30(5):425–447. &#xA;https://doi.org/10.1016/S0160-2896(02)00116-2&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR19" id="ref-link-section-d41158e833">2002</a>) questionnaire as well as questions toward students’ technology attitude from Gelman and Nolan (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Gelman A, Nolan D (2010) A class project in survey sampling. Coll Teach 50(4):151–153. &#xA;https://doi.org/10.1080/87567550209595897&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR18" id="ref-link-section-d41158e836">2010</a>). To assess the effects of the immersive media on students’ sense of presence, we used the MEC-SPQ (Vorderer et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Vorderer P, Wirth W, Gouveia FR, Biocca F, Saari T, Jäncke F, Böcking S, Schramm H, Gysbers A, Hartmann T, Klimmt C, Laarni J, Ravaja N, Sacau A, Baumgartner T, Jäncke P (2004) MEC spatial presence questionnaire (MEC-SPQ): short documentation and instructions for application. &#xA;https://academic.csuohio.edu/kneuendorf/frames/MECFull.pdf&#xA;&#xA;. Accessed 27 Sept 2017" href="/article/10.1007/s10055-019-00418-5#ref-CR52" id="ref-link-section-d41158e839">2004</a>) questionnaire focusing on two aspects, the spatial situation model (SSM) and self-localization. While the MEC-SPQ is a media questionnaire, the part addressing the spatial situation model is applicable to actual field site visits, too. This part was administered to both the iVFT and control group. In addition to standardized instruments, we also tailored a set of open-ended questions to the different experiences where we asked students specifically about their experience with respect to, for example, learning.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Overview of variables and instruments</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-019-00418-5/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec5">Participants</h3><p>We recruited participants from an introductory geosciences course that requires field work. The majority of students are, however, not geosciences majors. Through announcements in class and an online sign-up form, we recruited two groups of participants, one that would be willing to participate in the iVFT before going on the actual trip and one group that would be happy to join the control group participating in the AFT only. We had 55 participants interested in the iVFT, from this pool of participants we randomly sampled 25 participants to be in the iVFT group. All participants not in the iVFT group were given the opportunity to participate in the control group. All participants received 20 clicker points for their participation and were entered into a raffle for four $20 ice cream vouchers. The iVFT participants received $10 for the time they spend in addition to the actual field trip. We had 23 participants in the iVFT group (8 female, average age 19.91) and 32 participants in the control group (15 female, average age 19.91). One participant in the iVFT group and three participants in the control group were removed based on missing data (i.e., they did not submit all questionnaires).</p><h3 class="c-article__sub-heading" id="Sec6">Materials</h3><p>We built upon the iVFT created for this course previously (Klippel et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019a" title="Klippel A, Zhao J, Jackson KL, LaFemina P, Stubbs C, Oprean D, Wallgrün JO, Blair J (2019a) Transforming earth science education through immersive experiences: delivering on a long held promise. J Educ Comput Res 57(7):1745–1771. &#xA;https://doi.org/10.1177/0735633119854025&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR25" id="ref-link-section-d41158e1071">2019a</a>). This field trip leads students to the Reedsville &amp; Bald Eagle formation accessible through an outcrop about 12 miles outside State College in Central Pennsylvania, USA. We used a combination of <span class="mathjax-tex">\(360^{\circ }\)</span> images and 3D models created via structure-from-motion methods to capture the field site digitally. Unity: Unity3d (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Unity: Unity3d (2018). &#xA;https://unity3d.com/&#xA;&#xA;. Accessed 3 Apr 2018" href="/article/10.1007/s10055-019-00418-5#ref-CR51" id="ref-link-section-d41158e1085">2018</a>) in combination with an HTC Vive was used to realize an immersive, interactive experience. We give a brief overview of the materials we created.</p><p>As improvements to the original field trip, we collected the <span class="mathjax-tex">\(360^{\circ }\)</span> images at the site using a high-resolution camera (a Panono with 108K resolution) instead of a Nikon KeyMission to respond to participants comments asking for higher resolution. Additionally, we collected <span class="mathjax-tex">\(360^{\circ }\)</span> images not only at ground level but also at the height of 27<span class="mathjax-tex">\(^{\prime }\)</span> (8.23 m). We have been experimenting with this approach which we call <i>pseudo-aerial</i> for some time (Zhao and Klippel <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Zhao J, Klippel A (2019) Scale-unexplored opportunities for immersive technologies in place-based learning. In: 2019 IEEE conference on virtual reality and 3D user interfaces (VR), Osaka, Japan. IEEE, pp 155–162. &#xA;https://doi.org/10.1109/VR.2019.8797867&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR54" id="ref-link-section-d41158e1127">2019</a>), and the effect often is critical to understanding an environment in that it allows for an elevated perspective that offers access to a larger area, that is, an increased geographic scale. This elevated perspective often reveals, for example, spatial patterns otherwise not visible. While not the same as drone images, the tripod used to create these images still offers a substantial change in perspective and can be used without legal issues as well as in areas restricted for drone flights. For geological outcrops, such as the Reedsville/Bald Eagle one, the elevated perspective has the additional advantage that it allows a view normal, rather than oblique, to the upper stratigraphy of the outcrop. The outcrop itself is about 40<span class="mathjax-tex">\(^{\prime }\)</span> (12.19 m) high such that the upper parts from a ground perspective can only be accessed at an angle and from a greater distance. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig4">4</a> shows a comparison of two high-resolution images, the ground image on the left and an image taken at the same location but in 27<span class="mathjax-tex">\(^{\prime }\)</span> (8.23 m) height on the right.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig4_HTML.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig4_HTML.jpg" alt="figure4" loading="lazy" width="685" height="330" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Comparison of ground level (left) and elevated level (right). The 27<span class="mathjax-tex">\(^{\prime }\)</span> (8.23 m) perspective changes access to the outcrop from an oblique to an orthogonal angle as well as the possibility to access higher parts of the outcrop as close-ups</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Despite the high resolution of the <span class="mathjax-tex">\(360^{\circ }\)</span> images used in this iVFT, we still enhanced students' access to essential details of the outcrop as well as additional information usually found in the field manual through interactive markers embedded in the <span class="mathjax-tex">\(360^{\circ }\)</span> images. Students were able to access this information by using a controller and clicking a marker. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig5">5</a> shows an example of such additional information: a red box (marker) embedded into a <span class="mathjax-tex">\(360^{\circ }\)</span> image; upon selecting the marker students received a high-resolution image taken with a DSLR camera (Nikon D7200) as well as a grain size classification chart to aid the students in identifying grain size on the geologic units.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig5_HTML.jpg?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig5_HTML.jpg" alt="figure5" loading="lazy" width="685" height="338" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Example of combining different resolutions and integrating interactive content. A red marker in a <span class="mathjax-tex">\(360^{\circ }\)</span> image (left) indicates the availability of additional information; here, a high-resolution DSLR image and a grain size chart (colour figure online)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>While <span class="mathjax-tex">\(360^{\circ }\)</span> images are an efficient way to create immersive experiences and allow for some interactivity, many aspects of why field trips are used in environmental sciences education require advanced interactivity offered only through 3D models. To allow students to perform the same activities virtually that they would perform during an AFT, we used structure-from-motion photogrammetry (Carrivick et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Carrivick JL, Smith MW, Quincey DJ (2016) Structure from motion in the geosciences. Wiley, Chichester. &#xA;https://doi.org/10.1002/9781118895818&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR9" id="ref-link-section-d41158e1247">2016</a>) for parts of the outcrop and created a 3D model of the Reedsville formation. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig6">6</a> (top left) provides some details. The exercise that students perform at the actual outcrop is measuring the thickness of layers along a section of the outcrop (location 6, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig7">7</a>). Students were able to change the ruler length and place the ruler onto the outcrop surface to measure thickness of rock layers mimicking measuring activities at the physical site (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig6">6</a>, top right and bottom left). A data board, which displays the set of measured widths, allows students to review, organize and edit the data they collect (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig6">6</a>, bottom right). The thickness data along with a screenshot of the outcrop model are sent to students after the virtual field trip such that they are in a position to complete the official lab assignment, that is, to create a stratigraphic map.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig6_HTML.jpg?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig6_HTML.jpg" alt="figure6" loading="lazy" width="685" height="613" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Example of a 3D model created for parts of the Reedsville &amp; Bald Eagle formation. Top left shows the outcrop model with an indication of which part students were asked to measure. Bottom left shows a close up of the outcrop model with the ruler tool used on top of a HTC Vive controller. Bottom right shows the virtual board on which the measurements are recorded and that students can use to delete measurements. Top right shows a student performing the measurements</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig7">7</a> provides an overview of the Reedsville &amp; Bald Eagle field site in form of an aerial image summarizing the discussion above. The numbers indicate locations at which we took high-resolution <span class="mathjax-tex">\(360^{\circ }\)</span> images. Locations indicated by yellow numbers allow users to experience the outcrop from an elevated perspective (27<span class="mathjax-tex">\(^{\prime }\)</span>—8.23 m), locations with a white circle offered audio information, and the blue arrow shows the location at which students measured the stratigraphy by accessing the 3D model created using structure-from-motion mapping (see also Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig6">6</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig7_HTML.jpg?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig7_HTML.jpg" alt="figure7" loading="lazy" width="685" height="432" /></picture></a><p class="c-article-section__figure-credit text-right c-article-section__figure-credit-right" data-test="figure-credit">(<i>Source</i>: Google Maps) (colour figure online)</p></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Aerial view. There are a total of 20 locations at which <span class="mathjax-tex">\(360^{\circ }\)</span> images were taken. In contrast to our earlier study, we used high-resolution <span class="mathjax-tex">\(360^{\circ }\)</span> imagery and included 15 elevated <span class="mathjax-tex">\(360^{\circ }\)</span> images taken at the height of 27<span class="mathjax-tex">\(^{\prime }\)</span> (8.23 m) using a megamast (yellow numbers). Audio scripts were attached to 12 locations (white circles). Location 6 is the entry to a 3D model of the outcrop used for measuring the stratigraphy (blue arrow) </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>All this information is integrated into a Unity3D project. To allow for basic navigation between locations, arrows are placed on the ground that participants select with their controllers. Arrows are only available in a meaningful, predefined sequence mimicking the storyline of the actual field site visit (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig8">8</a>). In a free exploration phase at the end, all arrows to neighboring locations are activated. The opportunity to access the elevated perspective as well as returning to the ground is indicated through red circles (something we may make more subtle in the future). When looking straight up or straight down, participants see these circles at locations shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig9">9</a>. Clicking on a circle switches a participants perspective from ground to elevated view and vice versa.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig8_HTML.jpg?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig8_HTML.jpg" alt="figure8" loading="lazy" width="685" height="684" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Navigation between <span class="mathjax-tex">\(360^{\circ }\)</span> images is realized by placing arrows to the nearest images on the ground. In the learning/tour phase, only certain arrows mimicking the sequence of locations of the actual field trip are active. In a free exploration phase at the end of the iVFT, all arrows to nearest locations are active and selectable</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig9_HTML.jpg?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig9_HTML.jpg" alt="figure9" loading="lazy" width="685" height="339" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>A 27<span class="mathjax-tex">\(^{\prime }\)</span> perspective was available to participants at most locations (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig7">7</a> for an overview). A red circle at the very top and very bottom allowed for switching between ground and elevated perspective (colour figure online)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec7">Procedure</h3><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig3">3</a> shows an overview of the general design of the study comparing several pre- and post-measures for the control group, which only went to the actual field site (group AFT), and the group that participated in the iVFT before the AFT (group iVFT). Here, we provide more details for each group.</p><p>
                <i>Participants in group iVFT</i>
              </p><p>Students who signed up for the iVFT experience were randomly selected, scheduled individual sessions through a calendar web-form and visited a university-wide accessible VR facility at the authors’ home institution. This is an important change compared to the original experiment in that we moved the iVFT experience from the confines of a controlled lab environment into a more public realm. The ultimate goal is to allow students to flexibly undertake iVFTs in libraries or at their homes. Participants were greeted by a staff member who asked them to provide consent, to fill out the pre-questionnaire, demographic data as well as data on individual differences using the Santa Barbara Sense of Direction Scale (SBSOD; Hegarty <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Hegarty M (2002) Development of a self-report measure of environmental spatial ability. Intelligence 30(5):425–447. &#xA;https://doi.org/10.1016/S0160-2896(02)00116-2&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR19" id="ref-link-section-d41158e1431">2002</a>) and on their attitude toward technology. Participants then went through the iVFT experience without any external guidance. Each participant would start with a basic orientation that took about 3 min to acquaint him or her with the interface. Participants would then visit the 15 images that are part of the core field site experience sequentially and listened to the audio recordings. At locations marked yellow in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig7">7</a>, a second <span class="mathjax-tex">\(360^{\circ }\)</span> image taken at 27<span class="mathjax-tex">\(^{\prime }\)</span> at the same location was available and had to be visited by the students before they were able to proceed to the next location. Ground images had a circle at the very top that students were able to select with a hand controller of the Vive. If students received audio explanations at a location, the audio would continue playing independent of the level of perspective the student would be on (ground or 27<span class="mathjax-tex">\(^{\prime }\)</span>). Before students performed measurements of the stratigraphy of the outcrop, they went through a quick training session that familiarized them with the interface for this exercise.</p><p>The iVFT had two parts, the first was a guided experience through the different locations at the field site mimicking the AFT. The second part was a 5-min free exploration period that allowed participants to return to any of the images they had visited before. The iVFT experience lasted approximately 35 min for each individual session.</p><p>After the iVFT, participants filled out another questionnaire with questions regarding their experience, the spatial presence and spatial situation model, as well as their expectations for the AFT. iVFT participants then went on the AFT(within a week after their iVFT experience) and filled out a third questionnaire after their AFT experience repeating some of the previous questions and were also asked for direct comparisons between the virtual and actual field trip (e.g., “What was different between the virtual field trip and your actual field trip to the Reedsville &amp; Bald Eagle formations?”).</p><p>
                <i>Participants in control group (group AFT)</i>
              </p><p>Students in the control group did not experience the field site virtually. They participated in the AFT only but received two questionnaires, one before and after the field trip. They filled out both questionnaires online. The first online questionnaire contained a link to the study’s consent form and requested participants’ consent. Students were asked demographic questions, standardized instruments, and tailored questions such as “I learned a lot from the field trip” that allowed us to compare different experiences. In the AFT, students typically spent 45 min experiencing the outcrop at the physical site. A teaching assistant guided students in small groups to visit different parts of the outcrop in a similar order as in the iVFTs. We made efforts to ensure the amount of information being provided was comparable between AFT and iVFTs and they all attended the same lectures that prepared them for the field trips.</p></div></div></section><section aria-labelledby="Sec8"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Results</h2><div class="c-article-section__content" id="Sec8-content"><p>We follow, for the most part, the order of variables and measures that we show in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-019-00418-5#Tab1">1</a>. We first compare both AFT and iVFT participants with respect to their overall and individual characteristics using the Santa Barbara Sense of Direction Scale (SBSOD; Hegarty <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Hegarty M (2002) Development of a self-report measure of environmental spatial ability. Intelligence 30(5):425–447. &#xA;https://doi.org/10.1016/S0160-2896(02)00116-2&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR19" id="ref-link-section-d41158e1498">2002</a>) test as well as a self-reported enjoyment of technology assessment [adapted from Gelman and Nolan (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Gelman A, Nolan D (2010) A class project in survey sampling. Coll Teach 50(4):151–153. &#xA;https://doi.org/10.1080/87567550209595897&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR18" id="ref-link-section-d41158e1501">2010</a>)]. Neither assessment yielded significant differences between the two groups: SBSOD: iVFT: <i>M</i> = 3.32; SD = .63; AFT: <i>M</i>= 3.45, SD = .65; <i>t</i>(48.14) = .73, <i>p</i> = .47. Enjoyment of technology: iVFT: <i>M</i> = 4.05, SD = .74; AFT: <i>M</i> = 3.94, SD = .94; <i>t</i>(44.89) = − .48, <i>p</i> = .63.</p><p>We then looked at student expectations with respect to their field trip experience (see <i>individual differences</i> in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-019-00418-5#Tab1">1</a>). The options were listed as follows: “Excited,” “Better than going on an actual field trip,” “Don’t care,” “Not looking forward to it,” “Dreading the experience.” In general, students were excited about the experience (78.3% in the iVFT vs. 59.4% in the AFT). A <span class="mathjax-tex">\(\chi ^{2}\)</span> test of independence was performed to determine the relation between group and field trip expectation. There were no significant differences, <span class="mathjax-tex">\(\chi ^{2}\)</span>(3, <i>N</i> = 55) = 5.27, <i>p</i> = .15.</p><p>Next, we examined whether students changed their opinions and attitudes toward iVFTs after experiencing the iVFT as compared to their expectations (see <i>opinion on virtual field trip</i> in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-019-00418-5#Tab1">1</a>). There was no significant difference (before the iVFT: <i>M</i> = 3.51, <i>SD</i> = .61; after the iVFT: <i>M</i> = 3.8, <i>SD</i> = .55; <i>t</i>(43.66) = −1 .72, <i>p</i> = .09).</p><p>We now focus on the comparison of AFT and iVFT and then compare how iVFT participants assessed their AFT experience after the iVFT experience. Where informative, we also make comparisons to the data reported in Klippel et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019a" title="Klippel A, Zhao J, Jackson KL, LaFemina P, Stubbs C, Oprean D, Wallgrün JO, Blair J (2019a) Transforming earth science education through immersive experiences: delivering on a long held promise. J Educ Comput Res 57(7):1745–1771. &#xA;https://doi.org/10.1177/0735633119854025&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR25" id="ref-link-section-d41158e1598">2019a</a>). We refer to the datasets in the current experiment as:</p><ul class="u-list-style-bullet"><li><p>AFT—participants who only experienced the actual field trip</p></li><li><p>iVFT—participants who experienced the virtual field trip before in addition taking the actual field trip</p></li><li><p>iVFT-AFT—same participants as iVFT after they additionally experienced the actual field trip</p></li></ul><p>The self-reported learning experience of AFT and iVFT as a response to the question “I learned a lot from the (virtual) field trip” resulted in a significantly higher score for the iVFT participants (iVFT: <i>M</i> = 4.3, SD = .97; AFT: <i>M</i> = 3.25, SD = 1.22; <i>t</i>(52.33) = − 3.56, <i>p</i> &lt; .001). It is insightful to additionally look at the distribution of responses (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-019-00418-5#Fig10">10</a>). While participants in the AFT show a broad range of responses almost equally distributed across the range of possible values, iVFT participants, with few exceptions, rate their experience as being highly beneficial for their learning experience.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig10_HTML.png?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-019-00418-5/MediaObjects/10055_2019_418_Fig10_HTML.png" alt="figure10" loading="lazy" width="685" height="317" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Self-assessed learning experience of AFT and iVFT participants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-019-00418-5/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Given that immersive learning experiences are still a rather new phenomenon, we consider responses from individual participants insightful although statistically they might be considered an outlier. For the one participant who indicated that the iVFT experiences was not a beneficial learning experience, we looked into the associated data we collected. The participant is male, 21 years old, majoring in geobiology and not interested in technology/video games at all (“1”). He did not believe in iVFTs as a learning tool but at the same time indicated that he wants to see more use of iVFTs at the University. Looking at his Post-VFT answers (that we will look into in greater depth below for all participants), he acknowledged the value of iVFTs as a good supplement/preparation for AFTs and would like to do the VFT again; he also liked the elevated view. However, he thought he could not learn a lot from the iVFT (“1”), iVFTs could not replace AFTs (“1”), and that he could learn a lot more in AFTs than in iVFTs (“1”). He had a score of 4 on the spatial situation model (SSM) after the iVFT. He emphasized the importance of being able to have actual rocks on hand. Looking at his Post-iVFT-AFT answers: He did not change his mind (iVFTs are a good preparation for but could not replace AFTs, preferred having actual rocks in hand). His SSM score increased to 4.9.</p><p>Lab grades were the objective measure we adopted to assess students’ learning effectiveness toward the field site (see <i>learning</i> in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-019-00418-5#Tab1">1</a>). No significant differences were found on lab grades between iVFT (<i>M</i> = 22.28, <i>SD</i> = 2.03) and AFT (<i>M</i> = 22.01, <i>SD</i> = 1.73), <i>t</i>(42.19) = −.52, <i>p</i> = .61.</p><p>We calculated an enjoyment score based on the combination of three questions (see <i>enjoyment</i> in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-019-00418-5#Tab1">1</a>). All questions individually had significantly more positive responses in favor of the iVFT experience so that the overall significance does not come as a surprise (iVFT: <i>M</i> = 4.38; SD = .66; AFT: <i>M</i> = 3.25, SD = 1.18), <i>t</i>(50.50) = − 4.52, <i>p</i> &lt; .001.</p><p>We assessed spatial situation models (SSMs) as a combination of Likert scale-rated items (see <i>media effects</i> in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-019-00418-5#Tab1">1</a>): There were significant differences between iVFT and AFT in favor of the iVFT experience (iVFT: <i>M</i> = 4.14, SD = .38; AFT: <i>M</i> = 3.48, SD = .69), <i>t</i>(50.16) = − 4.46, <i>p</i> &lt; .001.</p><p>Additional questions only touched upon briefly here focused on the evaluation of the plus aspect of the iVFT, that is, the 27<span class="mathjax-tex">\(^{\prime }\)</span><span class="mathjax-tex">\(360^{\circ }\)</span> imagery, and the direct comparison of virtual and actual field trips provided by the iVFT-AFT participants. We asked iVFT participants three questions regarding experiences at the elevated level (see <i>design choices</i> in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-019-00418-5#Tab1">1</a>). The average scores (<i>M</i> = 4.25, SD = .92) denote a strong preference for the elevated perspective. Overall, students liked the elevated experience and thought this could facilitate learning toward the field site. For the direct comparison between virtual and actual field trips, while there were no significant differences in the SSM and learning experience, iVFT-AFT participants rated their enjoyment of iVFT (<i>M</i> = 4.38, SD = .66) significantly higher than that of AFT (<i>M</i> = 3.61, SD = 1.02), <i>t</i>(22) = 3.59, <i>p</i> = .002.</p><p>One question of interest is whether an iVFT experience could be a beneficial preparation for an AFT. We integrated a question addressing this issues that AFT participants received after their field trip experience and iVFT participants after their AFT experience (iVFT-AFT). Responses to the questions (see <i>preparation for an AFT</i> in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-019-00418-5#Tab1">1</a>) yielded a significantly more positive score for iVFT-AFT participants (<i>M</i> = 4.22, SD = .90) compared to AFT participants (<i>M</i> = 3.12, SD = 1.29), <i>t</i>(52.98) = − 3.70, <i>p</i> &lt; .001.</p><p>
              <i>Qualitative analysis</i>
            </p><p>Students answered several open-ended questions following their respective experiences with the field trips. Two researchers grouped the responses by similar responses to each question to form common categories as a start for a structured inductive content analysis (Schreier <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Schreier M (2012) Qualitative content analysis in practice. SAGE Publishing, Thousand Oaks" href="/article/10.1007/s10055-019-00418-5#ref-CR43" id="ref-link-section-d41158e1789">2012</a>). Each researcher used a line-by-line coding method to identify and verify the same lines were grouped in the same way. The groups were assigned a category and aligned to visualize differences in categories between actual and virtual field trip responses (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-019-00418-5#Tab2">2</a>). </p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Open-ended categories by question (bold for iVFT and italics for AFT)</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-019-00418-5/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Students in the AFT focused on positive reviews toward the mode of authentic learning space, while the iVFT group focused on specific features of the experience. The iVFT was seen as convenient but lacked providing the students’ desire to interact with the rocks more, though interestingly only one response focused on actually touching the rocks, rather the students were focused on seeing and being able to interact with the rocks more. The most noted differences in the responses related to features enabled students to focus on the content in the iVFT and the poor site conditions in the AFT. All of the conditions reported the iVFT would be suitable for removing distractions found in the actual environment, enabling them to focus on what they needed to learn. For both groups, the benefits focused on distinctions between the AFT and the iVFT. Where AFT focused on the tangible aspects, the iVFT responses focused on convenience. The AFT was considered a desirable aspect to get the students out of the classroom for hands-on learning but needed more time and better preparation. Overall, the focus from each group catered to the affordances of either the technology facilitating the experience or the learning approach.</p><p>The iVFT-AFT group were asked an additional two questions to get a sense of the general differences and preferences for field trips from students who are able to evaluate both (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-019-00418-5#Tab3">3</a>). The results confirm the interpretations of the previous responses that students were happy with the educational aspect of iVFTs and they appreciated the convenience and novelty. On the other hand, students missed the ability to control their experience and the quality of the experience which included only a few mentions of other senses. Working in groups was seen as a bonus of AFTs.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 VFT-AFT responses comparing experiences (bold for iVFT)</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-019-00418-5/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div></div></div></section><section aria-labelledby="Sec9"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">Discussion</h2><div class="c-article-section__content" id="Sec9-content"><p>The results overall show a strong positive experience for students who participated in the iVFT. This is important as empirical evaluations of immersive learning experiences are still rare, especially those involving actual field work. We discuss the results and go into more detail with respect to new aspects in comparison with previous studies, that is, having students go through both experiences (iVFT and AFT) with the immersive experience as a preparation for the actual field trip, the use of a public VR spaces, the higher resolution <span class="mathjax-tex">\(360^{\circ }\)</span> imagery, and the introduction of the 27<span class="mathjax-tex">\(^{\prime }\)</span> perspective.</p><p>The non-significant differences in spatial abilities, attitude toward technology, and expectation for the field trip lead us to believe that both groups (AFT and iVFT) are generally comparable and not biased by our sampling strategy or students willingness to participate in the iVFT. We acknowledge there still could be an aspect of self-selection as participation in the iVFT was not mandatory. At this point, where we are still in the exploratory stages of immersive learning experiences, this is unavoidable.</p><p>The assessment of the spatial situation model (SSM) as part of the spatial presence questionnaire (Vorderer et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Vorderer P, Wirth W, Gouveia FR, Biocca F, Saari T, Jäncke F, Böcking S, Schramm H, Gysbers A, Hartmann T, Klimmt C, Laarni J, Ravaja N, Sacau A, Baumgartner T, Jäncke P (2004) MEC spatial presence questionnaire (MEC-SPQ): short documentation and instructions for application. &#xA;https://academic.csuohio.edu/kneuendorf/frames/MECFull.pdf&#xA;&#xA;. Accessed 27 Sept 2017" href="/article/10.1007/s10055-019-00418-5#ref-CR52" id="ref-link-section-d41158e2396">2004</a>) shows a different and improved result in comparison with Klippel et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019a" title="Klippel A, Zhao J, Jackson KL, LaFemina P, Stubbs C, Oprean D, Wallgrün JO, Blair J (2019a) Transforming earth science education through immersive experiences: delivering on a long held promise. J Educ Comput Res 57(7):1745–1771. &#xA;https://doi.org/10.1177/0735633119854025&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR25" id="ref-link-section-d41158e2399">2019a</a>) [an aspect we singled out in a conference paper, see Zhao and Klippel (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Zhao J, Klippel A (2019) Scale-unexplored opportunities for immersive technologies in place-based learning. In: 2019 IEEE conference on virtual reality and 3D user interfaces (VR), Osaka, Japan. IEEE, pp 155–162. &#xA;https://doi.org/10.1109/VR.2019.8797867&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR54" id="ref-link-section-d41158e2402">2019</a>)]. In the basic iVFT of Klippel et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019a" title="Klippel A, Zhao J, Jackson KL, LaFemina P, Stubbs C, Oprean D, Wallgrün JO, Blair J (2019a) Transforming earth science education through immersive experiences: delivering on a long held promise. J Educ Comput Res 57(7):1745–1771. &#xA;https://doi.org/10.1177/0735633119854025&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR25" id="ref-link-section-d41158e2405">2019a</a>), no differences were found between AFT and iVFT. While this is a valuable sign for the effectiveness of iVFTs, it also led to the question whether moving from basic to plus versions might change the scale in favor of the iVFT experience compared to the AFT experience. A direct comparison of the SSM in the current experiment showed that this is indeed the case and that SSM scores are significantly higher for the iVFT participants compared to their AFT counterparts. In contrast, we did not find any additional gain for iVFT students after they participated in the AFT (iVFT-AFT). As there was also a challenge in data collection, the iVFT participants provided answers to the SSM questions directly after the experience while AFT and iVFT-AFT participants filled out the questionnaire when they returned from the field trip, we also compared the SSM scores of Klippel et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019a" title="Klippel A, Zhao J, Jackson KL, LaFemina P, Stubbs C, Oprean D, Wallgrün JO, Blair J (2019a) Transforming earth science education through immersive experiences: delivering on a long held promise. J Educ Comput Res 57(7):1745–1771. &#xA;https://doi.org/10.1177/0735633119854025&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR25" id="ref-link-section-d41158e2408">2019a</a>) and the current experiment. While we saw a rather substantial increase in the score, classic statistics did not provide a significant result. However, applying emerging statistical techniques such as Bayesian statistics, we were able to show that for iVFT participants there is a significant gain in SSM score and the improvements in the current experiment were effective [see Zhao and Klippel (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Zhao J, Klippel A (2019) Scale-unexplored opportunities for immersive technologies in place-based learning. In: 2019 IEEE conference on virtual reality and 3D user interfaces (VR), Osaka, Japan. IEEE, pp 155–162. &#xA;https://doi.org/10.1109/VR.2019.8797867&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR54" id="ref-link-section-d41158e2412">2019</a>) for more details]. It is important to note that we provided overall improvements to the iVFT experience, and the 27<span class="mathjax-tex">\(^{\prime }\)</span> perspective is one of the potential three improvements that could have contributed to the significant difference. The other two improvements were higher resolution <span class="mathjax-tex">\(360^{\circ }\)</span> images and additional locations at the site in comparison with Klippel et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019a" title="Klippel A, Zhao J, Jackson KL, LaFemina P, Stubbs C, Oprean D, Wallgrün JO, Blair J (2019a) Transforming earth science education through immersive experiences: delivering on a long held promise. J Educ Comput Res 57(7):1745–1771. &#xA;https://doi.org/10.1177/0735633119854025&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR25" id="ref-link-section-d41158e2437">2019a</a>). The goal of our educational efforts was to provide the best possible experience to students and not hold back for the purpose of experimental clarity. We are developing, however, a conceptual framework that advocates for a combination of applied and basic research, and the question of quantifying effects of multiple perspectives (e.g., through elevated 360 images) will be addressed in the future.</p><p>The learning experience subjectively assessed from the students’ perspective replicated findings from earlier work (Klippel et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019a" title="Klippel A, Zhao J, Jackson KL, LaFemina P, Stubbs C, Oprean D, Wallgrün JO, Blair J (2019a) Transforming earth science education through immersive experiences: delivering on a long held promise. J Educ Comput Res 57(7):1745–1771. &#xA;https://doi.org/10.1177/0735633119854025&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR25" id="ref-link-section-d41158e2443">2019a</a>), that is, students had an overwhelmingly, significantly more positive experience in the iVFT compared to students who went on the AFT. Several factors might contribute to these results. For field trips in temperate regions, there is always the risk to have less-than-optimal weather conditions. The course instructors try to accommodate spring semester challenges by having field trips later in the semester (compared to the fall when field trips are in the earlier parts of the semester). Although it was April, the weather was not ideal and was identified as the number one aspect perceived as not ideal in the AFT. These numbers are rather different to our previous study that had a field trip in the Fall term and only 2 out of 18 students commented on weather being an issue for the AFT. The second most frequent aspect AFT students identified as challenging is the site itself. As noted in the Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-019-00418-5#Sec6">3.3</a>, the site is accessible but not without challenges. There are parts where students have to take turns and ‘climb’ over unstable ground. It is all manageable but it may not be for everyone. Finally, our local site is a great example of geologic processes and sedimentary rock structures, but may not be as awe inspiring as locations like the Grand Canyon (Keltner and Haidt <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Keltner D, Haidt J (2003) Approaching awe, a moral, spiritual, and aesthetic emotion. Cognit Emot 17(2):297–314. &#xA;https://doi.org/10.1080/02699930302297&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR23" id="ref-link-section-d41158e2449">2003</a>), but is local and accessible. Bottom line, there may be a number of reasons hidden in the criticism of the site.</p><p>The plus iVFT aspect, that is, the elevated perspective, was a noted feature in the responses overall, receiving both positive and some mixed comments. The elevated perspective provided the students with the ability to explore the formation from a perspective not feasible for students in the AFT. Unfortunately, the elevated perspective adversely impacted students with height phobias. While the number of responses to the phobias was minimal, as these studies grow larger and reach more students, these aspects may adversely influence the findings. Ultimately, this highlights the challenge to establish universal design guidelines for iVFT as generally positive features might not work for everyone.</p><p>The direct comparison of AFT and iVFT analyzed through qualitative individual responses provides insights into pros and cons of virtual field trips, for the AFT students liked the interactivity, being outdoors, and the autonomy of the experience. The iVFT students liked the convenience, the focus, and the novelty. One very interesting finding is that almost half of the students described the iVFT as being more educational and the AFT as more observational. Even though the AFT experience elicited more comments relating to the hands-on experience at the actual site, the iVFT responses suggested the focused attention and guided instruction were preferable in learning the content. The study also confirmed an overall wishlist for iVFTs that we started after our first study: Students wanted more activity, students prefer to work in teams, and students want to take notes during the experience. Improvements and solutions for all aspect are now technically possible and in the making. The question of whether including additional modalities as well as other aspects will lead to improved learning outcomes is requiring empirical evaluations, ideally as a combination of applied and basic research.</p><p>One important question that we did not address statistically is the scalability of immersive learning experiences. While there are many avenues possible through mobile VR or even desktop-based versions, the embodiment of room-scale immersive experience is a promising development from the perspective of embodiment and immersive learning (Lages and Bowman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Lages WS, Bowman DA (2018) Move the object or move myself? Walking versus manipulation for the examination of 3d scientific data. Front ICT 5:236. &#xA;https://doi.org/10.3389/fict.2018.00015&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR28" id="ref-link-section-d41158e2462">2018</a>). The authors’ university is in the process of establishing an immersive infrastructure accessible not only at the main campus but throughout the commonwealth, that is, campuses that often operate like 2-year colleges with limited resources, essentially making field trips impossible. By moving the iVFT from our controlled lab into a university-wide accessible space and by not experiencing any difficulties reported by the participants, we are moving one step closer to offering high-end immersive learning to the masses.</p></div></div></section><section aria-labelledby="Sec10"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Conclusions and future work</h2><div class="c-article-section__content" id="Sec10-content"><p>The results of this study add to the growing basis of evidence-based studies on immersive learning (Krokos et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Krokos E, Plaisant C, Varshney A (2018) Virtual memory palaces: immersion aids recall. Virtual Real 23:1–15. &#xA;https://doi.org/10.1007/s10055-018-0360-5&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR27" id="ref-link-section-d41158e2474">2018</a>) and in particular immersive virtual field trips (Bursztyn et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Bursztyn N, Shelton B, Walker A, Pederson J (2017) Increasing undergraduate interest to learn geoscience with GPS-based augmented reality field trips on students’ own smartphones. GSA Today 27:4–10. &#xA;https://doi.org/10.1130/GSATG304A.1&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR7" id="ref-link-section-d41158e2477">2017</a>; Markowitz et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Markowitz DM, Laha R, Perone BP, Pea RD, Bailenson JN (2018) Immersive virtual reality field trips facilitate learning about climate change. Front Psychol 9:2364. &#xA;https://doi.org/10.3389/fpsyg.2018.02364&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR33" id="ref-link-section-d41158e2480">2018</a>; Sriarunrasmee et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Sriarunrasmee J, Suwannatthachote P, Dachakupt P (2015) Virtual field trips with inquiry learning and critical thinking process: a learning model to enhance students’ science learning outcomes. Proc Soc Behav Sci 197:1721–1726. &#xA;https://doi.org/10.1016/j.sbspro.2015.07.226&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR48" id="ref-link-section-d41158e2483">2015</a>). The main findings of our study can be summarized as follows: (a) With the advent of consumer-grade immersive headsets, we are getting into position to deliver place-based learning experiences to a large audience without the need to physically travel [see also Brown and Green (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Brown A, Green T (2016) Virtual reality: low-cost tools and resources for the classroom. TechTrends 60(5):517–519. &#xA;https://doi.org/10.1007/s11528-016-0102-z&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR6" id="ref-link-section-d41158e2486">2016</a>)]. (b) While not perfect, the learning experience as well as learning outcomes of iVFTS are either on par with or exceed those of AFTs. (c) Exploring the opportunities virtual learning environments offer, here moving from a basic iVFT to a plus iVFT, shows that learning can be enhanced beyond what is possible in physical reality. (d) iVFTs are an excellent preparation for AFTs [see also Sriarunrasmee et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Sriarunrasmee J, Suwannatthachote P, Dachakupt P (2015) Virtual field trips with inquiry learning and critical thinking process: a learning model to enhance students’ science learning outcomes. Proc Soc Behav Sci 197:1721–1726. &#xA;https://doi.org/10.1016/j.sbspro.2015.07.226&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR48" id="ref-link-section-d41158e2490">2015</a>)]. (e) While there is room for improvement (see below), the results are encouraging and integrating iVFT into the curriculum is both feasible and desirable.</p><p>In more detail, immersive experiences offer comparable embodied experiences to actual field trips. While currently not all senses are catered to in the same way, for example, touch and smell are still posing challenges, we are approaching high levels of representational fidelity and creative forms of interacting with spatial environments and content. It will be essential, though, to address the effects of multi-sensory experiences on learning experiences and learning outcomes, especially for place-based education, in future empirical studies combining both applied and basic research designs. Additionally, we are witnessing imaginative solutions to expand the limitations of physical reality without loosing the advantages of an embodied experience. What is needed though is a re-conceptualization and re-thinking of what is possible and desirable in the realm of immersive learning in light of rapidly evolving technologies.</p><p>We ventured into this realm by proposing a relatively simple taxonomy that we nonetheless believe to be powerful enough to conceptualize the area of immersive learning, not on a technical but an experiential level. We reflected more deeply on a conceptual framework for a recent workshop combining the taxonomy with what we call SENSATIUM, the sensing-scaling trade-off continuum (Klippel et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019b" title="Klippel A, Zhao J, Oprean D, Wallgrün JO, Chang JSK, Wallgrun JO, Chang JSK (2019b) Research framework for immersive virtual field trips. In: IEEE conference on virtual reality and 3D user interfaces. KELVAR: the fourth IEEE VR workshop on K-12+ embodied learning through virtual and augmented reality. IEEE, pp 1612–1617. &#xA;https://doi.org/10.1109/VR.2019.8798153&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR26" id="ref-link-section-d41158e2499">2019b</a>). SENSATIUM allows for distinguishing different immersive systems as a trade-off of sensing and scalability (e.g., price and space limitations). This combination is guiding our future research aiming for both empirical validation and exploring immersive learning at scale.</p><p>We also believe that a combination is necessary of immersive learning as part of the curriculum and basic research that singles out individual aspects of immersive experiences. In our parallel research, we focus on different kinds of locomotion as well as scale. Such research is necessary as the mode of locomotion can have profound impacts on the way we learn (spatial) information in an immersive environment (Bowman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Bowman DA, Davis ET, Hodges LF (1999) Badre AN maintaining spatial orientation during travel in an immersive virtual environment. Presence Teleoper Virtual Environ 8(6):618–631. &#xA;https://doi.org/10.1162/105474699566521&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR5" id="ref-link-section-d41158e2505">1999</a>; Riecke et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Riecke BE, Bodenheimer B, McNamara TP, Williams B, Peng P, Feuereissen D (2010) Do we need to walk for effective virtual reality navigation? Physical rotations alone may suffice. In: Hölscher C, Shipley TF, Belardinelli MO, Bateman JA, Newcombe NS (eds) Spatial cognition VII. Lecture notes in computer science, vol 6222. Springer, Berlin, pp 234–247. &#xA;https://doi.org/10.1007/978-3-642-14749-4_21&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR41" id="ref-link-section-d41158e2508">2010</a>). Users will almost never be able to explore an immersive space by walking (unless it is room sized), and must rely on teleportation, flying, or other forms of locomotion offered through a system’s interface [see Boletsis (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Boletsis C (2017) The new era of virtual reality locomotion: a systematic literature review of techniques and a proposed typology. Multimodal Technol Interact 1(4):24. &#xA;https://doi.org/10.3390/mti1040024&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR3" id="ref-link-section-d41158e2511">2017</a>) for an overview]. Empirical studies have shown that while teleportation is exceptionally well suited to prevent cyber-sickness, it poses challenges for understanding an environment spatially (e.g., Zhao et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Zhao J, Klippel A, Minear M, Newcombe N, Bodenheimer B, McNamara T, Nazareth A, Sensibaugh T (2018) Desktop versus immersive virtual environments: effects on spatial learning [abstract]. In: 7th international conference on spatial cognition (ICSC Rome)" href="/article/10.1007/s10055-019-00418-5#ref-CR55" id="ref-link-section-d41158e2514">2018</a>).</p><p>Likewise, while we have presented our first results on the effects of changes in (geographic) scale on subjectively assessed spatial situation models (see Results and Discussion), we need more rigorous empirical evidence that offering access to an environment at different scales (essentially moving from basic iVFTs to plus iVFTs) is not just an addition of a cool feature but, that it has the desired impacts on students’ ability to learn an environment spatially and use what they learn as spatial scaffolding for a contextualized learning experience. In order to understand individual aspects of iVFTs such as locomotion and scale, we need basic research closely associated with the broader educational research questions.</p><p>An important aspect in this study to further consider is that our research design differed from previous studies by adopting an AB design, that is, the experimental group had their immersive experience before they went on the actual field trip. That students feel better prepared for the actual field trip is not surprising as they essentially spend additional time with the relevant material. We firmly believe there are aspects of immersive experiences that are superior to traditional classroom settings as the preparation is place-based in the location that the material pertains to. To better capture this distinction, we need to consider other designs best suited to capturing active learning through interventions.</p><p>One of our most prominent current research topics is the longitudinal aspects of immersive learning experiences. It is probably fair to say that most students participating in our and other researchers’ studies are experiencing immersive learning for the first time. To address possibilities of novelty effects and awe (Lee and Wong <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Lee EAL, Wong KW (2014) Learning with desktop virtual reality: low spatial ability learners are more positively affected. Comput Educ 79:49–58. &#xA;https://doi.org/10.1016/j.compedu.2014.07.010&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR30" id="ref-link-section-d41158e2527">2014</a>; Chirico et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Chirico A, Ferrise F, Cordella L, Gaggioli A (2017) Designing awe in virtual reality: an experimental study. Front Psychol 8:2351. &#xA;https://doi.org/10.3389/fpsyg.2017.02351&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR10" id="ref-link-section-d41158e2530">2017</a>) while testing location specific issues, we are in the process of designing learning experiences that students are exposed to at least twice in a semester as part of the same course.</p><p>Although there are numerous additional aspects that will become relevant for immersive learning [see Ketelhut et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Ketelhut DJ, Nelson BC, Clarke J, Dede C (2010) A multi-user virtual environment for building and assessing higher order inquiry skills in science. Br J Educ Technol 41(1):56–68. &#xA;https://doi.org/10.1111/j.1467-8535.2009.01036.x&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR24" id="ref-link-section-d41158e2536">2010</a>), Fowler (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Fowler C (2015) Virtual reality and learning: where is the pedagogy? Br J Educ Technol 46(2):412–422. &#xA;https://doi.org/10.1111/bjet.12135&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR17" id="ref-link-section-d41158e2539">2015</a>), Kamarainen et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Kamarainen AM, Thompson M, Metcalf SJ, Grotzer TA, Tutwiler MS, Dede C (2018) Prompting connections between content and context: blending immersive virtual environments and augmented reality for environmental science learning. In: Beck D, Pena-Rios A, Ogle T, Allison C, Morgado L, Pirker J, Richter J, Gütl C (eds) iLRN 2018 Montana: workshop, long and short paper , and poster proceedings from the fourth immersive learning research network conference. Verlag der Technischen Universität Graz, Graz, Austria, pp 36–54. &#xA;https://doi.org/10.1007/978-3-319-93596-6_3&#xA;&#xA;&#xA;" href="/article/10.1007/s10055-019-00418-5#ref-CR22" id="ref-link-section-d41158e2542">2018</a>) and Minocha et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Minocha S, Tudor AD, Tilling S (2017) Affordances of mobile virtual reality and their role in learning and teaching. In: The 31st British human computer interaction conference, 3–6 July 2017. University of Sunderland’s St. Peter’s Campus, UK, pp 1–10" href="/article/10.1007/s10055-019-00418-5#ref-CR36" id="ref-link-section-d41158e2545">2017</a>)], we believe that systematically evaluating them in real course lab sessions, we will be able to develop a stronger empirical case for immersive learning. We hope to make contributions to the empirical foundations of these aspects of immersive learning in the future.</p></div></div></section>
                        
                    

                    <section aria-labelledby="notes"><div class="c-article-section" id="notes-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="notes">Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1"><span class="c-article-footnote--listed__index">1.</span><div class="c-article-footnote--listed__content"><p><a href="https://www.thinglink.com/">https://www.thinglink.com/</a>.</p></div></li><li class="c-article-footnote--listed__item" id="Fn2"><span class="c-article-footnote--listed__index">2.</span><div class="c-article-footnote--listed__content"><p><a href="https://roundme.com/">https://roundme.com/</a>.</p></div></li><li class="c-article-footnote--listed__item" id="Fn3"><span class="c-article-footnote--listed__index">3.</span><div class="c-article-footnote--listed__content"><p><a href="https://vr.google.com/tourcreator/">https://vr.google.com/tourcreator/</a>.</p></div></li></ol></div></div></section><section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Allcoat, A. Mühlenen, " /><meta itemprop="datePublished" content="2018" /><meta itemprop="headline" content="Allcoat D, von Mühlenen A (2018) Learning in virtual reality: effects on performance, emotion and engagement. " /><p class="c-article-references__text" id="ref-CR1">Allcoat D, von Mühlenen A (2018) Learning in virtual reality: effects on performance, emotion and engagement. Res Learn Technol. <a href="https://doi.org/10.25304/rlt.v26.2140">https://doi.org/10.25304/rlt.v26.2140</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.25304%2Frlt.v26.2140" aria-label="View reference 1">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20in%20virtual%20reality%3A%20effects%20on%20performance%2C%20emotion%20and%20engagement&amp;journal=Res%20Learn%20Technol&amp;doi=10.25304%2Frlt.v26.2140&amp;publication_year=2018&amp;author=Allcoat%2CD&amp;author=M%C3%BChlenen%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="J. Blascovich, J. Bailenson, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Blascovich J, Bailenson J (2011) Infinite reality: avatars, eternal life, new worlds, and the dawn of the virt" /><p class="c-article-references__text" id="ref-CR2">Blascovich J, Bailenson J (2011) Infinite reality: avatars, eternal life, new worlds, and the dawn of the virtual revolution, 1st edn. William Morrow, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Infinite%20reality%3A%20avatars%2C%20eternal%20life%2C%20new%20worlds%2C%20and%20the%20dawn%20of%20the%20virtual%20revolution&amp;publication_year=2011&amp;author=Blascovich%2CJ&amp;author=Bailenson%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Boletsis, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Boletsis C (2017) The new era of virtual reality locomotion: a systematic literature review of techniques and " /><p class="c-article-references__text" id="ref-CR3">Boletsis C (2017) The new era of virtual reality locomotion: a systematic literature review of techniques and a proposed typology. Multimodal Technol Interact 1(4):24. <a href="https://doi.org/10.3390/mti1040024">https://doi.org/10.3390/mti1040024</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3390%2Fmti1040024" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20new%20era%20of%20virtual%20reality%20locomotion%3A%20a%20systematic%20literature%20review%20of%20techniques%20and%20a%20proposed%20typology&amp;journal=Multimodal%20Technol%20Interact&amp;doi=10.3390%2Fmti1040024&amp;volume=1&amp;issue=4&amp;publication_year=2017&amp;author=Boletsis%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DA. Bowman, RP. McMahan, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Bowman DA, McMahan RP (2007) Virtual reality: how much immersion is enough? Computer 40(7):36–43" /><p class="c-article-references__text" id="ref-CR4">Bowman DA, McMahan RP (2007) Virtual reality: how much immersion is enough? Computer 40(7):36–43</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FMC.2007.257" aria-label="View reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%3A%20how%20much%20immersion%20is%20enough%3F&amp;journal=Computer&amp;volume=40&amp;issue=7&amp;pages=36-43&amp;publication_year=2007&amp;author=Bowman%2CDA&amp;author=McMahan%2CRP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DA. Bowman, ET. Davis, LF. Hodges, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Bowman DA, Davis ET, Hodges LF (1999) Badre AN maintaining spatial orientation during travel in an immersive v" /><p class="c-article-references__text" id="ref-CR5">Bowman DA, Davis ET, Hodges LF (1999) Badre AN maintaining spatial orientation during travel in an immersive virtual environment. Presence Teleoper Virtual Environ 8(6):618–631. <a href="https://doi.org/10.1162/105474699566521">https://doi.org/10.1162/105474699566521</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474699566521" aria-label="View reference 5">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Badre%20AN%20maintaining%20spatial%20orientation%20during%20travel%20in%20an%20immersive%20virtual%20environment&amp;journal=Presence%20Teleoper%20Virtual%20Environ&amp;doi=10.1162%2F105474699566521&amp;volume=8&amp;issue=6&amp;pages=618-631&amp;publication_year=1999&amp;author=Bowman%2CDA&amp;author=Davis%2CET&amp;author=Hodges%2CLF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Brown, T. Green, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Brown A, Green T (2016) Virtual reality: low-cost tools and resources for the classroom. TechTrends 60(5):517–" /><p class="c-article-references__text" id="ref-CR6">Brown A, Green T (2016) Virtual reality: low-cost tools and resources for the classroom. TechTrends 60(5):517–519. <a href="https://doi.org/10.1007/s11528-016-0102-z">https://doi.org/10.1007/s11528-016-0102-z</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs11528-016-0102-z" aria-label="View reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%3A%20low-cost%20tools%20and%20resources%20for%20the%20classroom&amp;journal=TechTrends&amp;doi=10.1007%2Fs11528-016-0102-z&amp;volume=60&amp;issue=5&amp;pages=517-519&amp;publication_year=2016&amp;author=Brown%2CA&amp;author=Green%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="N. Bursztyn, B. Shelton, A. Walker, J. Pederson, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Bursztyn N, Shelton B, Walker A, Pederson J (2017) Increasing undergraduate interest to learn geoscience with " /><p class="c-article-references__text" id="ref-CR7">Bursztyn N, Shelton B, Walker A, Pederson J (2017) Increasing undergraduate interest to learn geoscience with GPS-based augmented reality field trips on students’ own smartphones. GSA Today 27:4–10. <a href="https://doi.org/10.1130/GSATG304A.1">https://doi.org/10.1130/GSATG304A.1</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1130%2FGSATG304A.1" aria-label="View reference 7">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Increasing%20undergraduate%20interest%20to%20learn%20geoscience%20with%20GPS-based%20augmented%20reality%20field%20trips%20on%20students%E2%80%99%20own%20smartphones&amp;journal=GSA%20Today&amp;doi=10.1130%2FGSATG304A.1&amp;volume=27&amp;pages=4-10&amp;publication_year=2017&amp;author=Bursztyn%2CN&amp;author=Shelton%2CB&amp;author=Walker%2CA&amp;author=Pederson%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Carbonell Carrera, LA. Bermejo Asensio, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Carbonell Carrera C, Bermejo Asensio LA (2017) Landscape interpretation with augmented reality and maps to imp" /><p class="c-article-references__text" id="ref-CR8">Carbonell Carrera C, Bermejo Asensio LA (2017) Landscape interpretation with augmented reality and maps to improve spatial orientation skill. J Geogr High Educ 41(1):119–133. <a href="https://doi.org/10.1080/03098265.2016.1260530">https://doi.org/10.1080/03098265.2016.1260530</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F03098265.2016.1260530" aria-label="View reference 8">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Landscape%20interpretation%20with%20augmented%20reality%20and%20maps%20to%20improve%20spatial%20orientation%20skill&amp;journal=J%20Geogr%20High%20Educ&amp;doi=10.1080%2F03098265.2016.1260530&amp;volume=41&amp;issue=1&amp;pages=119-133&amp;publication_year=2017&amp;author=Carbonell%20Carrera%2CC&amp;author=Bermejo%20Asensio%2CLA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="JL. Carrivick, MW. Smith, DJ. Quincey, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Carrivick JL, Smith MW, Quincey DJ (2016) Structure from motion in the geosciences. Wiley, Chichester. https:/" /><p class="c-article-references__text" id="ref-CR9">Carrivick JL, Smith MW, Quincey DJ (2016) Structure from motion in the geosciences. Wiley, Chichester. <a href="https://doi.org/10.1002/9781118895818">https://doi.org/10.1002/9781118895818</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Structure%20from%20motion%20in%20the%20geosciences&amp;publication_year=2016&amp;author=Carrivick%2CJL&amp;author=Smith%2CMW&amp;author=Quincey%2CDJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Chirico, F. Ferrise, L. Cordella, A. Gaggioli, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Chirico A, Ferrise F, Cordella L, Gaggioli A (2017) Designing awe in virtual reality: an experimental study. F" /><p class="c-article-references__text" id="ref-CR10">Chirico A, Ferrise F, Cordella L, Gaggioli A (2017) Designing awe in virtual reality: an experimental study. Front Psychol 8:2351. <a href="https://doi.org/10.3389/fpsyg.2017.02351">https://doi.org/10.3389/fpsyg.2017.02351</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3389%2Ffpsyg.2017.02351" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Designing%20awe%20in%20virtual%20reality%3A%20an%20experimental%20study&amp;journal=Front%20Psychol&amp;doi=10.3389%2Ffpsyg.2017.02351&amp;volume=8&amp;publication_year=2017&amp;author=Chirico%2CA&amp;author=Ferrise%2CF&amp;author=Cordella%2CL&amp;author=Gaggioli%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="PG. Clifton, JSK. Chang, G. Yeboah, A. Doucette, S. Chandrasekharan, M. Nitsche, T. Welsh, A. Mazalek, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Clifton PG, Chang JSK, Yeboah G, Doucette A, Chandrasekharan S, Nitsche M, Welsh T, Mazalek A (2016) Design of" /><p class="c-article-references__text" id="ref-CR11">Clifton PG, Chang JSK, Yeboah G, Doucette A, Chandrasekharan S, Nitsche M, Welsh T, Mazalek A (2016) Design of embodied interfaces for engaging spatial cognition. Cognit Res Princ Implic 1(1):24. <a href="https://doi.org/10.1186/s41235-016-0032-5">https://doi.org/10.1186/s41235-016-0032-5</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1186%2Fs41235-016-0032-5" aria-label="View reference 11">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Design%20of%20embodied%20interfaces%20for%20engaging%20spatial%20cognition&amp;journal=Cognit%20Res%20Princ%20Implic&amp;doi=10.1186%2Fs41235-016-0032-5&amp;volume=1&amp;issue=1&amp;publication_year=2016&amp;author=Clifton%2CPG&amp;author=Chang%2CJSK&amp;author=Yeboah%2CG&amp;author=Doucette%2CA&amp;author=Chandrasekharan%2CS&amp;author=Nitsche%2CM&amp;author=Welsh%2CT&amp;author=Mazalek%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Jong, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="de Jong T (1991) Learning and instruction with computer simulations. Educ Comput 6(3):217–229. https://doi.org" /><p class="c-article-references__text" id="ref-CR12">de Jong T (1991) Learning and instruction with computer simulations. Educ Comput 6(3):217–229. <a href="https://doi.org/10.1016/0167-9287(91)80002-F">https://doi.org/10.1016/0167-9287(91)80002-F</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2F0167-9287%2891%2980002-F" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20and%20instruction%20with%20computer%20simulations&amp;journal=Educ%20Comput&amp;doi=10.1016%2F0167-9287%2891%2980002-F&amp;volume=6&amp;issue=3&amp;pages=217-229&amp;publication_year=1991&amp;author=Jong%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Dede, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Dede C (2009) Immersive interfaces for engagement and learning. Science (New York, N.Y.) 323(5910):66–69. http" /><p class="c-article-references__text" id="ref-CR13">Dede C (2009) Immersive interfaces for engagement and learning. Science (New York, N.Y.) 323(5910):66–69. <a href="https://doi.org/10.1126/science.1167311">https://doi.org/10.1126/science.1167311</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1126%2Fscience.1167311" aria-label="View reference 13">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Immersive%20interfaces%20for%20engagement%20and%20learning&amp;journal=Science%20%28New%20York%2C%20N.Y.%29&amp;doi=10.1126%2Fscience.1167311&amp;volume=323&amp;issue=5910&amp;pages=66-69&amp;publication_year=2009&amp;author=Dede%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Dolphin, A. Dutchak, B. Karchewski, J. Cooper, " /><meta itemprop="datePublished" content="2019" /><meta itemprop="headline" content="Dolphin G, Dutchak A, Karchewski B, Cooper J (2019) Virtual field experiences in introductory geology: address" /><p class="c-article-references__text" id="ref-CR14">Dolphin G, Dutchak A, Karchewski B, Cooper J (2019) Virtual field experiences in introductory geology: addressing a capacity problem, but finding a pedagogical one. J Geosci Educ 67(2):114–130. <a href="https://doi.org/10.1080/10899995.2018.1547034">https://doi.org/10.1080/10899995.2018.1547034</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F10899995.2018.1547034" aria-label="View reference 14">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20field%20experiences%20in%20introductory%20geology%3A%20addressing%20a%20capacity%20problem%2C%20but%20finding%20a%20pedagogical%20one&amp;journal=J%20Geosci%20Educ&amp;doi=10.1080%2F10899995.2018.1547034&amp;volume=67&amp;issue=2&amp;pages=114-130&amp;publication_year=2019&amp;author=Dolphin%2CG&amp;author=Dutchak%2CA&amp;author=Karchewski%2CB&amp;author=Cooper%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Elkins, NML. Elkins, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Elkins J, Elkins NML (2007) Teaching geology in the field: significant geoscience concept gains in entirely fi" /><p class="c-article-references__text" id="ref-CR15">Elkins J, Elkins NML (2007) Teaching geology in the field: significant geoscience concept gains in entirely field-based introductory geology courses. J Geosci Educ 55(2):126–132</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.5408%2F1089-9995-55.2.126" aria-label="View reference 15">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Teaching%20geology%20in%20the%20field%3A%20significant%20geoscience%20concept%20gains%20in%20entirely%20field-based%20introductory%20geology%20courses&amp;journal=J%20Geosci%20Educ&amp;volume=55&amp;issue=2&amp;pages=126-132&amp;publication_year=2007&amp;author=Elkins%2CJ&amp;author=Elkins%2CNML">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Fisher PF, Unwin D (eds) (2002) Virtual reality in geography. Taylor &amp; Francis, London and New York" /><p class="c-article-references__text" id="ref-CR16">Fisher PF, Unwin D (eds) (2002) Virtual reality in geography. Taylor &amp; Francis, London and New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20in%20geography&amp;publication_year=2002">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Fowler, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Fowler C (2015) Virtual reality and learning: where is the pedagogy? Br J Educ Technol 46(2):412–422. https://" /><p class="c-article-references__text" id="ref-CR17">Fowler C (2015) Virtual reality and learning: where is the pedagogy? Br J Educ Technol 46(2):412–422. <a href="https://doi.org/10.1111/bjet.12135">https://doi.org/10.1111/bjet.12135</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fbjet.12135" aria-label="View reference 17">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20and%20learning%3A%20where%20is%20the%20pedagogy%3F&amp;journal=Br%20J%20Educ%20Technol&amp;doi=10.1111%2Fbjet.12135&amp;volume=46&amp;issue=2&amp;pages=412-422&amp;publication_year=2015&amp;author=Fowler%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Gelman, D. Nolan, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Gelman A, Nolan D (2010) A class project in survey sampling. Coll Teach 50(4):151–153. https://doi.org/10.1080" /><p class="c-article-references__text" id="ref-CR18">Gelman A, Nolan D (2010) A class project in survey sampling. Coll Teach 50(4):151–153. <a href="https://doi.org/10.1080/87567550209595897">https://doi.org/10.1080/87567550209595897</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F87567550209595897" aria-label="View reference 18">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20class%20project%20in%20survey%20sampling&amp;journal=Coll%20Teach&amp;doi=10.1080%2F87567550209595897&amp;volume=50&amp;issue=4&amp;pages=151-153&amp;publication_year=2010&amp;author=Gelman%2CA&amp;author=Nolan%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Hegarty, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Hegarty M (2002) Development of a self-report measure of environmental spatial ability. Intelligence 30(5):425" /><p class="c-article-references__text" id="ref-CR19">Hegarty M (2002) Development of a self-report measure of environmental spatial ability. Intelligence 30(5):425–447. <a href="https://doi.org/10.1016/S0160-2896(02)00116-2">https://doi.org/10.1016/S0160-2896(02)00116-2</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0160-2896%2802%2900116-2" aria-label="View reference 19">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Development%20of%20a%20self-report%20measure%20of%20environmental%20spatial%20ability&amp;journal=Intelligence&amp;doi=10.1016%2FS0160-2896%2802%2900116-2&amp;volume=30&amp;issue=5&amp;pages=425-447&amp;publication_year=2002&amp;author=Hegarty%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SD. Hurst, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Hurst SD (1998) Use of “virtual” field trips in teaching introductory geology. Comput Geosci 24(7):653–658. ht" /><p class="c-article-references__text" id="ref-CR20">Hurst SD (1998) Use of “virtual” field trips in teaching introductory geology. Comput Geosci 24(7):653–658. <a href="https://doi.org/10.1016/S0098-3004(98)00043-0">https://doi.org/10.1016/S0098-3004(98)00043-0</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0098-3004%2898%2900043-0" aria-label="View reference 20">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Use%20of%20%E2%80%9Cvirtual%E2%80%9D%20field%20trips%20in%20teaching%20introductory%20geology&amp;journal=Comput%20Geosci&amp;doi=10.1016%2FS0098-3004%2898%2900043-0&amp;volume=24&amp;issue=7&amp;pages=653-658&amp;publication_year=1998&amp;author=Hurst%2CSD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MC. Johnson-Glenberg, " /><meta itemprop="datePublished" content="2018" /><meta itemprop="headline" content="Johnson-Glenberg MC (2018) Immersive VR and education: embodied design principles that include gesture and han" /><p class="c-article-references__text" id="ref-CR21">Johnson-Glenberg MC (2018) Immersive VR and education: embodied design principles that include gesture and hand controls. Front Robot AI 5:27. <a href="https://doi.org/10.3389/frobt.2018.00081">https://doi.org/10.3389/frobt.2018.00081</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3389%2Ffrobt.2018.00081" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Immersive%20VR%20and%20education%3A%20embodied%20design%20principles%20that%20include%20gesture%20and%20hand%20controls&amp;journal=Front%20Robot%20AI&amp;doi=10.3389%2Ffrobt.2018.00081&amp;volume=5&amp;publication_year=2018&amp;author=Johnson-Glenberg%2CMC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="Amy M.. Kamarainen, Meredith. Thompson, Shari J.. Metcalf, Tina A.. Grotzer, Michael Shane. Tutwiler, Chris. Dede, " /><meta itemprop="datePublished" content="2018" /><meta itemprop="headline" content="Kamarainen AM, Thompson M, Metcalf SJ, Grotzer TA, Tutwiler MS, Dede C (2018) Prompting connections between co" /><p class="c-article-references__text" id="ref-CR22">Kamarainen AM, Thompson M, Metcalf SJ, Grotzer TA, Tutwiler MS, Dede C (2018) Prompting connections between content and context: blending immersive virtual environments and augmented reality for environmental science learning. In: Beck D, Pena-Rios A, Ogle T, Allison C, Morgado L, Pirker J, Richter J, Gütl C (eds) iLRN 2018 Montana: workshop, long and short paper , and poster proceedings from the fourth immersive learning research network conference. Verlag der Technischen Universität Graz, Graz, Austria, pp 36–54. <a href="https://doi.org/10.1007/978-3-319-93596-6_3">https://doi.org/10.1007/978-3-319-93596-6_3</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Communications%20in%20Computer%20and%20Information%20Science&amp;pages=36-54&amp;publication_year=2018&amp;author=Kamarainen%2CAmy%20M.&amp;author=Thompson%2CMeredith&amp;author=Metcalf%2CShari%20J.&amp;author=Grotzer%2CTina%20A.&amp;author=Tutwiler%2CMichael%20Shane&amp;author=Dede%2CChris">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Keltner, J. Haidt, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Keltner D, Haidt J (2003) Approaching awe, a moral, spiritual, and aesthetic emotion. Cognit Emot 17(2):297–31" /><p class="c-article-references__text" id="ref-CR23">Keltner D, Haidt J (2003) Approaching awe, a moral, spiritual, and aesthetic emotion. Cognit Emot 17(2):297–314. <a href="https://doi.org/10.1080/02699930302297">https://doi.org/10.1080/02699930302297</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F02699930302297" aria-label="View reference 23">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Approaching%20awe%2C%20a%20moral%2C%20spiritual%2C%20and%20aesthetic%20emotion&amp;journal=Cognit%20Emot&amp;doi=10.1080%2F02699930302297&amp;volume=17&amp;issue=2&amp;pages=297-314&amp;publication_year=2003&amp;author=Keltner%2CD&amp;author=Haidt%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DJ. Ketelhut, BC. Nelson, J. Clarke, C. Dede, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Ketelhut DJ, Nelson BC, Clarke J, Dede C (2010) A multi-user virtual environment for building and assessing hi" /><p class="c-article-references__text" id="ref-CR24">Ketelhut DJ, Nelson BC, Clarke J, Dede C (2010) A multi-user virtual environment for building and assessing higher order inquiry skills in science. Br J Educ Technol 41(1):56–68. <a href="https://doi.org/10.1111/j.1467-8535.2009.01036.x">https://doi.org/10.1111/j.1467-8535.2009.01036.x</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fj.1467-8535.2009.01036.x" aria-label="View reference 24">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20multi-user%20virtual%20environment%20for%20building%20and%20assessing%20higher%20order%20inquiry%20skills%20in%20science&amp;journal=Br%20J%20Educ%20Technol&amp;doi=10.1111%2Fj.1467-8535.2009.01036.x&amp;volume=41&amp;issue=1&amp;pages=56-68&amp;publication_year=2010&amp;author=Ketelhut%2CDJ&amp;author=Nelson%2CBC&amp;author=Clarke%2CJ&amp;author=Dede%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Klippel, J. Zhao, KL. Jackson, P. LaFemina, C. Stubbs, D. Oprean, JO. Wallgrün, J. Blair, " /><meta itemprop="datePublished" content="2019" /><meta itemprop="headline" content="Klippel A, Zhao J, Jackson KL, LaFemina P, Stubbs C, Oprean D, Wallgrün JO, Blair J (2019a) Transforming earth" /><p class="c-article-references__text" id="ref-CR25">Klippel A, Zhao J, Jackson KL, LaFemina P, Stubbs C, Oprean D, Wallgrün JO, Blair J (2019a) Transforming earth science education through immersive experiences: delivering on a long held promise. J Educ Comput Res 57(7):1745–1771. <a href="https://doi.org/10.1177/0735633119854025">https://doi.org/10.1177/0735633119854025</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1177%2F0735633119854025" aria-label="View reference 25">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Transforming%20earth%20science%20education%20through%20immersive%20experiences%3A%20delivering%20on%20a%20long%20held%20promise&amp;journal=J%20Educ%20Comput%20Res&amp;doi=10.1177%2F0735633119854025&amp;volume=57&amp;issue=7&amp;pages=1745-1771&amp;publication_year=2019&amp;author=Klippel%2CA&amp;author=Zhao%2CJ&amp;author=Jackson%2CKL&amp;author=LaFemina%2CP&amp;author=Stubbs%2CC&amp;author=Oprean%2CD&amp;author=Wallgr%C3%BCn%2CJO&amp;author=Blair%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Klippel A, Zhao J, Oprean D, Wallgrün JO, Chang JSK, Wallgrun JO, Chang JSK (2019b) Research framework for imm" /><p class="c-article-references__text" id="ref-CR26">Klippel A, Zhao J, Oprean D, Wallgrün JO, Chang JSK, Wallgrun JO, Chang JSK (2019b) Research framework for immersive virtual field trips. In: IEEE conference on virtual reality and 3D user interfaces. KELVAR: the fourth IEEE VR workshop on K-12+ embodied learning through virtual and augmented reality. IEEE, pp 1612–1617. <a href="https://doi.org/10.1109/VR.2019.8798153">https://doi.org/10.1109/VR.2019.8798153</a>
</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="E. Krokos, C. Plaisant, A. Varshney, " /><meta itemprop="datePublished" content="2018" /><meta itemprop="headline" content="Krokos E, Plaisant C, Varshney A (2018) Virtual memory palaces: immersion aids recall. Virtual Real 23:1–15. h" /><p class="c-article-references__text" id="ref-CR27">Krokos E, Plaisant C, Varshney A (2018) Virtual memory palaces: immersion aids recall. Virtual Real 23:1–15. <a href="https://doi.org/10.1007/s10055-018-0360-5">https://doi.org/10.1007/s10055-018-0360-5</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10055-018-0360-5" aria-label="View reference 27">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20memory%20palaces%3A%20immersion%20aids%20recall&amp;journal=Virtual%20Real&amp;doi=10.1007%2Fs10055-018-0360-5&amp;volume=23&amp;pages=1-15&amp;publication_year=2018&amp;author=Krokos%2CE&amp;author=Plaisant%2CC&amp;author=Varshney%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="WS. Lages, DA. Bowman, " /><meta itemprop="datePublished" content="2018" /><meta itemprop="headline" content="Lages WS, Bowman DA (2018) Move the object or move myself? Walking versus manipulation for the examination of " /><p class="c-article-references__text" id="ref-CR28">Lages WS, Bowman DA (2018) Move the object or move myself? Walking versus manipulation for the examination of 3d scientific data. Front ICT 5:236. <a href="https://doi.org/10.3389/fict.2018.00015">https://doi.org/10.3389/fict.2018.00015</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3389%2Ffict.2018.00015" aria-label="View reference 28">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Move%20the%20object%20or%20move%20myself%3F%20Walking%20versus%20manipulation%20for%20the%20examination%20of%203d%20scientific%20data&amp;journal=Front%20ICT&amp;doi=10.3389%2Ffict.2018.00015&amp;volume=5&amp;publication_year=2018&amp;author=Lages%2CWS&amp;author=Bowman%2CDA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="J. Lave, E. Wenger, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="Lave J, Wenger E (1991) Situated learning: legitimate peripheral participation. Learning in doing: social, cog" /><p class="c-article-references__text" id="ref-CR29">Lave J, Wenger E (1991) Situated learning: legitimate peripheral participation. Learning in doing: social, cognitive, and computational perspectives. Cambridge University Press, Cambridge</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Situated%20learning%3A%20legitimate%20peripheral%20participation.%20Learning%20in%20doing%3A%20social%2C%20cognitive%2C%20and%20computational%20perspectives&amp;publication_year=1991&amp;author=Lave%2CJ&amp;author=Wenger%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EAL. Lee, KW. Wong, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Lee EAL, Wong KW (2014) Learning with desktop virtual reality: low spatial ability learners are more positivel" /><p class="c-article-references__text" id="ref-CR30">Lee EAL, Wong KW (2014) Learning with desktop virtual reality: low spatial ability learners are more positively affected. Comput Educ 79:49–58. <a href="https://doi.org/10.1016/j.compedu.2014.07.010">https://doi.org/10.1016/j.compedu.2014.07.010</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.compedu.2014.07.010" aria-label="View reference 30">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20with%20desktop%20virtual%20reality%3A%20low%20spatial%20ability%20learners%20are%20more%20positively%20affected&amp;journal=Comput%20Educ&amp;doi=10.1016%2Fj.compedu.2014.07.010&amp;volume=79&amp;pages=49-58&amp;publication_year=2014&amp;author=Lee%2CEAL&amp;author=Wong%2CKW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Liu D, Dede C, Huang R, Richards J (eds) (2017) Virtual, augmented, and mixed realities in education. Smart co" /><p class="c-article-references__text" id="ref-CR31">Liu D, Dede C, Huang R, Richards J (eds) (2017) Virtual, augmented, and mixed realities in education. Smart computing and intelligence. Springer, Singapore</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%2C%20augmented%2C%20and%20mixed%20realities%20in%20education.%20Smart%20computing%20and%20intelligence&amp;publication_year=2017">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Makransky, TS. Terkildsen, RE. Mayer, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Makransky G, Terkildsen TS, Mayer RE (2017) Adding immersive virtual reality to a science lab simulation cause" /><p class="c-article-references__text" id="ref-CR32">Makransky G, Terkildsen TS, Mayer RE (2017) Adding immersive virtual reality to a science lab simulation causes more presence but less learning. Learn Instr. <a href="https://doi.org/10.1016/j.learninstruc.2017.12.007">https://doi.org/10.1016/j.learninstruc.2017.12.007</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.learninstruc.2017.12.007" aria-label="View reference 32">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Adding%20immersive%20virtual%20reality%20to%20a%20science%20lab%20simulation%20causes%20more%20presence%20but%20less%20learning&amp;journal=Learn%20Instr&amp;doi=10.1016%2Fj.learninstruc.2017.12.007&amp;publication_year=2017&amp;author=Makransky%2CG&amp;author=Terkildsen%2CTS&amp;author=Mayer%2CRE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DM. Markowitz, R. Laha, BP. Perone, RD. Pea, JN. Bailenson, " /><meta itemprop="datePublished" content="2018" /><meta itemprop="headline" content="Markowitz DM, Laha R, Perone BP, Pea RD, Bailenson JN (2018) Immersive virtual reality field trips facilitate " /><p class="c-article-references__text" id="ref-CR33">Markowitz DM, Laha R, Perone BP, Pea RD, Bailenson JN (2018) Immersive virtual reality field trips facilitate learning about climate change. Front Psychol 9:2364. <a href="https://doi.org/10.3389/fpsyg.2018.02364">https://doi.org/10.3389/fpsyg.2018.02364</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3389%2Ffpsyg.2018.02364" aria-label="View reference 33">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Immersive%20virtual%20reality%20field%20trips%20facilitate%20learning%20about%20climate%20change&amp;journal=Front%20Psychol&amp;doi=10.3389%2Ffpsyg.2018.02364&amp;volume=9&amp;publication_year=2018&amp;author=Markowitz%2CDM&amp;author=Laha%2CR&amp;author=Perone%2CBP&amp;author=Pea%2CRD&amp;author=Bailenson%2CJN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Mead, S. Buxner, G. Bruce, W. Taylor, S. Semken, AD. Anbar, " /><meta itemprop="datePublished" content="2019" /><meta itemprop="headline" content="Mead C, Buxner S, Bruce G, Taylor W, Semken S, Anbar AD (2019) Immersive, interactive virtual field trips prom" /><p class="c-article-references__text" id="ref-CR34">Mead C, Buxner S, Bruce G, Taylor W, Semken S, Anbar AD (2019) Immersive, interactive virtual field trips promote science learning. J Geosci Educ 67(2):131–142. <a href="https://doi.org/10.1080/10899995.2019.1565285">https://doi.org/10.1080/10899995.2019.1565285</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F10899995.2019.1565285" aria-label="View reference 34">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Immersive%2C%20interactive%20virtual%20field%20trips%20promote%20science%20learning&amp;journal=J%20Geosci%20Educ&amp;doi=10.1080%2F10899995.2019.1565285&amp;volume=67&amp;issue=2&amp;pages=131-142&amp;publication_year=2019&amp;author=Mead%2CC&amp;author=Buxner%2CS&amp;author=Bruce%2CG&amp;author=Taylor%2CW&amp;author=Semken%2CS&amp;author=Anbar%2CAD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Z. Merchant, ET. Goetz, L. Cifuentes, W. Keeney-Kennicutt, TJ. Davis, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Merchant Z, Goetz ET, Cifuentes L, Keeney-Kennicutt W, Davis TJ (2014) Effectiveness of virtual reality-based " /><p class="c-article-references__text" id="ref-CR35">Merchant Z, Goetz ET, Cifuentes L, Keeney-Kennicutt W, Davis TJ (2014) Effectiveness of virtual reality-based instruction on students’ learning outcomes in k-12 and higher education: a meta-analysis. Comput Educ 70:29–40. <a href="https://doi.org/10.1016/j.compedu.2013.07.033">https://doi.org/10.1016/j.compedu.2013.07.033</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.compedu.2013.07.033" aria-label="View reference 35">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Effectiveness%20of%20virtual%20reality-based%20instruction%20on%20students%E2%80%99%20learning%20outcomes%20in%20k-12%20and%20higher%20education%3A%20a%20meta-analysis&amp;journal=Comput%20Educ&amp;doi=10.1016%2Fj.compedu.2013.07.033&amp;volume=70&amp;pages=29-40&amp;publication_year=2014&amp;author=Merchant%2CZ&amp;author=Goetz%2CET&amp;author=Cifuentes%2CL&amp;author=Keeney-Kennicutt%2CW&amp;author=Davis%2CTJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Minocha S, Tudor AD, Tilling S (2017) Affordances of mobile virtual reality and their role in learning and tea" /><p class="c-article-references__text" id="ref-CR36">Minocha S, Tudor AD, Tilling S (2017) Affordances of mobile virtual reality and their role in learning and teaching. In: The 31st British human computer interaction conference, 3–6 July 2017. University of Sunderland’s St. Peter’s Campus, UK, pp 1–10</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Narciso, M. Bessa, M. Melo, A. Coelho, J. Vasconcelos-Raposo, " /><meta itemprop="datePublished" content="2019" /><meta itemprop="headline" content="Narciso D, Bessa M, Melo M, Coelho A, Vasconcelos-Raposo J (2019) Immersive 360 video user experience: impact " /><p class="c-article-references__text" id="ref-CR37">Narciso D, Bessa M, Melo M, Coelho A, Vasconcelos-Raposo J (2019) Immersive 360 video user experience: impact of different variables in the sense of presence and cybersickness. Univ Access Inf Soc 18(1):77–87. <a href="https://doi.org/10.1007/s10209-017-0581-5">https://doi.org/10.1007/s10209-017-0581-5</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10209-017-0581-5" aria-label="View reference 37">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Immersive%20360%20video%20user%20experience%3A%20impact%20of%20different%20variables%20in%20the%20sense%20of%20presence%20and%20cybersickness&amp;journal=Univ%20Access%20Inf%20Soc&amp;doi=10.1007%2Fs10209-017-0581-5&amp;volume=18&amp;issue=1&amp;pages=77-87&amp;publication_year=2019&amp;author=Narciso%2CD&amp;author=Bessa%2CM&amp;author=Melo%2CM&amp;author=Coelho%2CA&amp;author=Vasconcelos-Raposo%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="D. Norman, " /><meta itemprop="datePublished" content="1980" /><meta itemprop="headline" content="Norman D (1980) The psychology of everyday things. Basic Books, New York" /><p class="c-article-references__text" id="ref-CR38">Norman D (1980) The psychology of everyday things. Basic Books, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 38 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20psychology%20of%20everyday%20things&amp;publication_year=1980&amp;author=Norman%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="J. Piaget, " /><meta itemprop="datePublished" content="1974" /><meta itemprop="headline" content="Piaget J (1974) To understand is to invent: the future of education, 1 viking compass edn. Viking Press, New Y" /><p class="c-article-references__text" id="ref-CR39">Piaget J (1974) To understand is to invent: the future of education, 1 viking compass edn. Viking Press, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=To%20understand%20is%20to%20invent%3A%20the%20future%20of%20education&amp;publication_year=1974&amp;author=Piaget%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="P. Relf, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Relf P (1996) The magic school bus wet all over: a book about the water cycle. Scholastic, New York" /><p class="c-article-references__text" id="ref-CR40">Relf P (1996) The magic school bus wet all over: a book about the water cycle. Scholastic, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 40 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20magic%20school%20bus%20wet%20all%20over%3A%20a%20book%20about%20the%20water%20cycle&amp;publication_year=1996&amp;author=Relf%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="Bernhard E.. Riecke, Bobby. Bodenheimer, Timothy P.. McNamara, Betsy. Williams, Peng. Peng, Daniel. Feuereissen, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Riecke BE, Bodenheimer B, McNamara TP, Williams B, Peng P, Feuereissen D (2010) Do we need to walk for effecti" /><p class="c-article-references__text" id="ref-CR41">Riecke BE, Bodenheimer B, McNamara TP, Williams B, Peng P, Feuereissen D (2010) Do we need to walk for effective virtual reality navigation? Physical rotations alone may suffice. In: Hölscher C, Shipley TF, Belardinelli MO, Bateman JA, Newcombe NS (eds) Spatial cognition VII. Lecture notes in computer science, vol 6222. Springer, Berlin, pp 234–247. <a href="https://doi.org/10.1007/978-3-642-14749-4_21">https://doi.org/10.1007/978-3-642-14749-4_21</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 41 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatial%20Cognition%20VII&amp;pages=234-247&amp;publication_year=2010&amp;author=Riecke%2CBernhard%20E.&amp;author=Bodenheimer%2CBobby&amp;author=McNamara%2CTimothy%20P.&amp;author=Williams%2CBetsy&amp;author=Peng%2CPeng&amp;author=Feuereissen%2CDaniel">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ruberto T, Mead C, Semken S, Bruce G, Buxner S, Anbar AD (2017) Proposing a digital teaching network for virtu" /><p class="c-article-references__text" id="ref-CR42">Ruberto T, Mead C, Semken S, Bruce G, Buxner S, Anbar AD (2017) Proposing a digital teaching network for virtual field experiences [abstract]. In: Proceedings of the geological society of America (GSA); 22–25 Oct 2017; Seattle, Washington, USA, DC. Geological Society of America abstracts with programs; 2017. vol 49, no 6. <a href="https://doi.org/10.1130/abs/2017AM-306229">https://doi.org/10.1130/abs/2017AM-306229</a>
</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="M. Schreier, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Schreier M (2012) Qualitative content analysis in practice. SAGE Publishing, Thousand Oaks" /><p class="c-article-references__text" id="ref-CR43">Schreier M (2012) Qualitative content analysis in practice. SAGE Publishing, Thousand Oaks</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 43 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Qualitative%20content%20analysis%20in%20practice&amp;publication_year=2012&amp;author=Schreier%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Semken, EG. Ward, S. Moosavi, PWU. Chinn, " /><meta itemprop="datePublished" content="2018" /><meta itemprop="headline" content="Semken S, Ward EG, Moosavi S, Chinn PWU (2018) Place-based education in geoscience: theory, research, practice" /><p class="c-article-references__text" id="ref-CR44">Semken S, Ward EG, Moosavi S, Chinn PWU (2018) Place-based education in geoscience: theory, research, practice, and assessment. J Geosci Educ 65(4):542–562. <a href="https://doi.org/10.5408/17-276.1">https://doi.org/10.5408/17-276.1</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.5408%2F17-276.1" aria-label="View reference 44">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 44 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Place-based%20education%20in%20geoscience%3A%20theory%2C%20research%2C%20practice%2C%20and%20assessment&amp;journal=J%20Geosci%20Educ&amp;doi=10.5408%2F17-276.1&amp;volume=65&amp;issue=4&amp;pages=542-562&amp;publication_year=2018&amp;author=Semken%2CS&amp;author=Ward%2CEG&amp;author=Moosavi%2CS&amp;author=Chinn%2CPWU">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="M. Slater, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Slater M (2017) Implicit learning through embodiment in immersive virtual reality. In: Liu D, Dede C, Huang R," /><p class="c-article-references__text" id="ref-CR45">Slater M (2017) Implicit learning through embodiment in immersive virtual reality. In: Liu D, Dede C, Huang R, Richards J (eds) Virtual, augmented, and mixed realities in education, smart computing and intelligence. Springer, Singapore, pp 19–33</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 45 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%2C%20augmented%2C%20and%20mixed%20realities%20in%20education%2C%20smart%20computing%20and%20intelligence&amp;pages=19-33&amp;publication_year=2017&amp;author=Slater%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Slater, MV. Sanchez-Vives, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Slater M, Sanchez-Vives MV (2016) Enhancing our lives with immersive virtual reality. Front Robot AI 3:74. htt" /><p class="c-article-references__text" id="ref-CR46">Slater M, Sanchez-Vives MV (2016) Enhancing our lives with immersive virtual reality. Front Robot AI 3:74. <a href="https://doi.org/10.3389/frobt.2016.00074">https://doi.org/10.3389/frobt.2016.00074</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3389%2Ffrobt.2016.00074" aria-label="View reference 46">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 46 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Enhancing%20our%20lives%20with%20immersive%20virtual%20reality&amp;journal=Front%20Robot%20AI&amp;doi=10.3389%2Ffrobt.2016.00074&amp;volume=3&amp;publication_year=2016&amp;author=Slater%2CM&amp;author=Sanchez-Vives%2CMV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Slater, S. Wilbur, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Slater M, Wilbur S (1997) A framework for immersive virtual environments (five): speculations on the role of p" /><p class="c-article-references__text" id="ref-CR47">Slater M, Wilbur S (1997) A framework for immersive virtual environments (five): speculations on the role of presence in virtual environments. Presence Teleoper Virtual Environ 6(6):603–616. <a href="https://doi.org/10.1162/pres.1997.6.6.603">https://doi.org/10.1162/pres.1997.6.6.603</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2Fpres.1997.6.6.603" aria-label="View reference 47">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 47 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20framework%20for%20immersive%20virtual%20environments%20%28five%29%3A%20speculations%20on%20the%20role%20of%20presence%20in%20virtual%20environments&amp;journal=Presence%20Teleoper%20Virtual%20Environ&amp;doi=10.1162%2Fpres.1997.6.6.603&amp;volume=6&amp;issue=6&amp;pages=603-616&amp;publication_year=1997&amp;author=Slater%2CM&amp;author=Wilbur%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Sriarunrasmee, P. Suwannatthachote, P. Dachakupt, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Sriarunrasmee J, Suwannatthachote P, Dachakupt P (2015) Virtual field trips with inquiry learning and critical" /><p class="c-article-references__text" id="ref-CR48">Sriarunrasmee J, Suwannatthachote P, Dachakupt P (2015) Virtual field trips with inquiry learning and critical thinking process: a learning model to enhance students’ science learning outcomes. Proc Soc Behav Sci 197:1721–1726. <a href="https://doi.org/10.1016/j.sbspro.2015.07.226">https://doi.org/10.1016/j.sbspro.2015.07.226</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.sbspro.2015.07.226" aria-label="View reference 48">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 48 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20field%20trips%20with%20inquiry%20learning%20and%20critical%20thinking%20process%3A%20a%20learning%20model%20to%20enhance%20students%E2%80%99%20science%20learning%20outcomes&amp;journal=Proc%20Soc%20Behav%20Sci&amp;doi=10.1016%2Fj.sbspro.2015.07.226&amp;volume=197&amp;pages=1721-1726&amp;publication_year=2015&amp;author=Sriarunrasmee%2CJ&amp;author=Suwannatthachote%2CP&amp;author=Dachakupt%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Steinicke F, Visell Y, Campos J, Lécuyer A (eds) (2013) Human walking in virtual environments: perception, tec" /><p class="c-article-references__text" id="ref-CR49">Steinicke F, Visell Y, Campos J, Lécuyer A (eds) (2013) Human walking in virtual environments: perception, technology, and applications. Springer, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 49 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20walking%20in%20virtual%20environments%3A%20perception%2C%20technology%2C%20and%20applications&amp;publication_year=2013">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RJ. Stumpf, J. Douglass, RI. Dorn, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Stumpf RJ, Douglass J, Dorn RI (2008) Learning desert geomorphology virtually versus in the field. J Geogr Hig" /><p class="c-article-references__text" id="ref-CR50">Stumpf RJ, Douglass J, Dorn RI (2008) Learning desert geomorphology virtually versus in the field. J Geogr High Educ 32(3):387–399. <a href="https://doi.org/10.1080/03098260802221140">https://doi.org/10.1080/03098260802221140</a>
</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F03098260802221140" aria-label="View reference 50">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 50 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20desert%20geomorphology%20virtually%20versus%20in%20the%20field&amp;journal=J%20Geogr%20High%20Educ&amp;doi=10.1080%2F03098260802221140&amp;volume=32&amp;issue=3&amp;pages=387-399&amp;publication_year=2008&amp;author=Stumpf%2CRJ&amp;author=Douglass%2CJ&amp;author=Dorn%2CRI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Unity: Unity3d (2018). https://unity3d.com/. Accessed 3 Apr 2018" /><p class="c-article-references__text" id="ref-CR51">Unity: Unity3d (2018). <a href="https://unity3d.com/">https://unity3d.com/</a>. Accessed 3 Apr 2018</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Vorderer P, Wirth W, Gouveia FR, Biocca F, Saari T, Jäncke F, Böcking S, Schramm H, Gysbers A, Hartmann T, Kli" /><p class="c-article-references__text" id="ref-CR52">Vorderer P, Wirth W, Gouveia FR, Biocca F, Saari T, Jäncke F, Böcking S, Schramm H, Gysbers A, Hartmann T, Klimmt C, Laarni J, Ravaja N, Sacau A, Baumgartner T, Jäncke P (2004) MEC spatial presence questionnaire (MEC-SPQ): short documentation and instructions for application. <a href="https://academic.csuohio.edu/kneuendorf/frames/MECFull.pdf">https://academic.csuohio.edu/kneuendorf/frames/MECFull.pdf</a>. Accessed 27 Sept 2017</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Vygotskiĭ LS, Cole M (1978) Mind in society: the development of higher psychological processes, edited by Mich" /><p class="c-article-references__text" id="ref-CR53">Vygotskiĭ LS, Cole M (1978) Mind in society: the development of higher psychological processes, edited by Michael Cole et al. (translated from the Russian). Harvard University Press, Cambridge, MA and London</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zhao J, Klippel A (2019) Scale-unexplored opportunities for immersive technologies in place-based learning. In" /><p class="c-article-references__text" id="ref-CR54">Zhao J, Klippel A (2019) Scale-unexplored opportunities for immersive technologies in place-based learning. In: 2019 IEEE conference on virtual reality and 3D user interfaces (VR), Osaka, Japan. IEEE, pp 155–162. <a href="https://doi.org/10.1109/VR.2019.8797867">https://doi.org/10.1109/VR.2019.8797867</a>
</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zhao J, Klippel A, Minear M, Newcombe N, Bodenheimer B, McNamara T, Nazareth A, Sensibaugh T (2018) Desktop ve" /><p class="c-article-references__text" id="ref-CR55">Zhao J, Klippel A, Minear M, Newcombe N, Bodenheimer B, McNamara T, Nazareth A, Sensibaugh T (2018) Desktop versus immersive virtual environments: effects on spatial learning [abstract]. In: 7th international conference on spatial cognition (ICSC Rome)</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-019-00418-5-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>The authors would like to thank students of Geosc 001 for their participation, the instructor, Peter Heaney, for his support, as well as the anonymous reviewers for their deeply insightful comments. This study was funded through a Penn State Strategic Planning award. Dr. Klippel would like to additionally acknowledge funding through the National Science Foundation Grants #1617396 and #1526520.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">ChoroPhronesis, Department of Geography, The Pennsylvania State University, University Park, PA, USA</p><p class="c-article-author-affiliation__authors-list">Alexander Klippel, Jiayan Zhao &amp; Jan Oliver Wallgrün</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">School of Information Science and Learning Technologies, University of Missouri, Columbia, MO, USA</p><p class="c-article-author-affiliation__authors-list">Danielle Oprean</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Teaching and Learning with Technology, The Pennsylvania State University, University Park, PA, USA</p><p class="c-article-author-affiliation__authors-list">Chris Stubbs</p></li><li id="Aff4"><p class="c-article-author-affiliation__address">Department of Geosciences, The Pennsylvania State University, University Park, PA, USA</p><p class="c-article-author-affiliation__authors-list">Peter La Femina</p></li><li id="Aff5"><p class="c-article-author-affiliation__address">School of Engineering Design, Technology, and Professional Programs, The Pennsylvania State University, State College, PA, USA</p><p class="c-article-author-affiliation__authors-list">Kathy L. Jackson</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Alexander-Klippel"><span class="c-article-authors-search__title u-h3 js-search-name">Alexander Klippel</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Alexander+Klippel&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Alexander+Klippel" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Alexander+Klippel%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Jiayan-Zhao"><span class="c-article-authors-search__title u-h3 js-search-name">Jiayan Zhao</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Jiayan+Zhao&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jiayan+Zhao" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jiayan+Zhao%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Danielle-Oprean"><span class="c-article-authors-search__title u-h3 js-search-name">Danielle Oprean</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Danielle+Oprean&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Danielle+Oprean" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Danielle+Oprean%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Jan_Oliver-Wallgr_n"><span class="c-article-authors-search__title u-h3 js-search-name">Jan Oliver Wallgrün</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Jan Oliver+Wallgr%C3%BCn&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jan Oliver+Wallgr%C3%BCn" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jan Oliver+Wallgr%C3%BCn%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Chris-Stubbs"><span class="c-article-authors-search__title u-h3 js-search-name">Chris Stubbs</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Chris+Stubbs&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Chris+Stubbs" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Chris+Stubbs%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Peter-La_Femina"><span class="c-article-authors-search__title u-h3 js-search-name">Peter La Femina</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Peter+La Femina&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Peter+La Femina" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Peter+La Femina%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Kathy_L_-Jackson"><span class="c-article-authors-search__title u-h3 js-search-name">Kathy L. Jackson</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Kathy L.+Jackson&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Kathy L.+Jackson" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Kathy L.+Jackson%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-019-00418-5/email/correspondent/c1/new">Alexander Klippel</a>.</p></div></div></section><section aria-labelledby="additional-information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><h3 class="c-article__sub-heading">Publisher's Note</h3><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=The%20value%20of%20being%20there%3A%20toward%20a%20science%20of%20immersive%20virtual%20field%20trips&amp;author=Alexander%20Klippel%20et%20al&amp;contentID=10.1007%2Fs10055-019-00418-5&amp;publication=1359-4338&amp;publicationDate=2019-12-21&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-019-00418-5" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-019-00418-5" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Klippel, A., Zhao, J., Oprean, D. <i>et al.</i> The value of being there: toward a science of immersive virtual field trips.
                    <i>Virtual Reality</i>  (2019). https://doi.org/10.1007/s10055-019-00418-5</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-019-00418-5.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2019-02-22">22 February 2019</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2019-12-05">05 December 2019</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2019-12-21">21 December 2019</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-019-00418-5" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-019-00418-5</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Immersive learning</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Virtual field trips</span></li><li class="c-article-subject-list__subject"><span itemprop="about">STEM</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Place-based learning</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-019-00418-5.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=418;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

