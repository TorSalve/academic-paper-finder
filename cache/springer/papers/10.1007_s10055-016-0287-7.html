<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="A comparative evaluation of viewing metaphors on psychophysical skills"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="In an empirical evaluation, we examined the effect of viewing condition on psychophysical skills education in an interactive 3D simulation to train users in electrical circuitry. We compared an..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/20/3.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="A comparative evaluation of viewing metaphors on psychophysical skills education in an interactive virtual environment"/>

    <meta name="dc.source" content="Virtual Reality 2016 20:3"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2016-05-14"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2016 Springer-Verlag London"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="In an empirical evaluation, we examined the effect of viewing condition on psychophysical skills education in an interactive 3D simulation to train users in electrical circuitry. We compared an immersive head-mounted display (HMD)-based viewing metaphor versus a limited, desktop-based virtual reality (DVR) viewing metaphor with interaction using a spatial user interface. Psychophysical skills education involves the association of cognitive functions with motor functions to make the task autonomous with repeated practice. In electrical circuitry, this is demonstrated by the fine movements involved in handling and manipulating components on the electrical circuit, particularly while measuring electrical parameters. We created an interactive circuitry simulation (IBAS) where participants could learn about electrical measurement instruments such as the ammeter, voltmeter and multimeter, in a simulated breadboard VR system. Twenty-four participants utilized the simulation (12 in each condition), and the quantitative and qualitative aspects of psychophysical skills education with respect to the viewing metaphor were examined. Each viewing condition in IBAS was head-tracked and non-stereoscopic. Perspective correction was coupled with head-tracking in the DVR condition. The key quantitative measures were cognitive questionnaires addressing different levels of Bloom&#8217;s cognitive taxonomy and a real-world psychophysical task addressing various levels of Dave&#8217;s psychomotor taxonomy. The qualitative measures were the Witmer&#8211;Singer sense of presence questionnaire and self-report. Results suggest that there was a significant increase in cognition post-experiment in both DVR and HMD viewing conditions in levels of knowledge, application, analysis and evaluation. Results also revealed a significant learning benefit with respect to the higher level concepts pertaining to evaluation in the HMD condition as compared to DVR. Participants seem to have enjoyed a greater level of affordance in task performance and spent a larger amount of time to complete the simulated exercises as well as manually maneuvered to further distances in the HMD viewing condition as compared to DVR viewing."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2016-05-14"/>

    <meta name="prism.volume" content="20"/>

    <meta name="prism.number" content="3"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="141"/>

    <meta name="prism.endingPage" content="157"/>

    <meta name="prism.copyright" content="2016 Springer-Verlag London"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-016-0287-7"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-016-0287-7"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-016-0287-7.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-016-0287-7"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="A comparative evaluation of viewing metaphors on psychophysical skills education in an interactive virtual environment"/>

    <meta name="citation_volume" content="20"/>

    <meta name="citation_issue" content="3"/>

    <meta name="citation_publication_date" content="2016/09"/>

    <meta name="citation_online_date" content="2016/05/14"/>

    <meta name="citation_firstpage" content="141"/>

    <meta name="citation_lastpage" content="157"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-016-0287-7"/>

    <meta name="DOI" content="10.1007/s10055-016-0287-7"/>

    <meta name="citation_doi" content="10.1007/s10055-016-0287-7"/>

    <meta name="description" content="In an empirical evaluation, we examined the effect of viewing condition on psychophysical skills education in an interactive 3D simulation to train users i"/>

    <meta name="dc.creator" content="Dhaval Parmar"/>

    <meta name="dc.creator" content="Jeffrey Bertrand"/>

    <meta name="dc.creator" content="Sabarish V. Babu"/>

    <meta name="dc.creator" content="Kapil Madathil"/>

    <meta name="dc.creator" content="Melissa Zelaya"/>

    <meta name="dc.creator" content="Tianwei Wang"/>

    <meta name="dc.creator" content="John Wagner"/>

    <meta name="dc.creator" content="Anand K. Gramopadhye"/>

    <meta name="dc.creator" content="Kristin Frady"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Revista Iberoamericana de Tecnologias del Aprendizaje; citation_title=A platform for testing and measuring based on virtual instrument; citation_author=IO Aguirre, MB Ruiz, JSM Diaz; citation_volume=8; citation_issue=3; citation_publication_date=2013; citation_pages=143-151; citation_doi=10.1109/RITA.2013.2273115; citation_id=CR27"/>

    <meta name="citation_reference" content="citation_journal_title=Acta Astronaut; citation_title=Desktop-vr system for preflight 3d navigation training; citation_author=H Aoki, CM Oman, DA Buckland, A Natapoff; citation_volume=63; citation_issue=7; citation_publication_date=2008; citation_pages=841-847; citation_doi=10.1016/j.actaastro.2007.11.001; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Inf Syst (TOIS); citation_title=Evaluating 3d task performance for fish tank virtual worlds; citation_author=KW Arthur, KS Booth, C Ware; citation_volume=11; citation_issue=3; citation_publication_date=1993; citation_pages=239-265; citation_doi=10.1145/159161.155359; citation_id=CR2"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE MultiMed; citation_title=Using 3d and ancillary media to train construction workers; citation_author=J Assfalg, A Bimbo, E Vicario; citation_volume=9; citation_issue=2; citation_publication_date=2002; citation_pages=88-92; citation_doi=10.1109/93.998075; citation_id=CR3"/>

    <meta name="citation_reference" content="Baheti A, Seshadri S, Kumar A, Srimathveeravalli G, Kesavadas T, Guru K (2008) Ross: virtual reality robotic surgical simulator for the da vinci surgical system. In: IEEE haptics 2008 symposium on haptic interfaces for virtual environment and teleoperator systems, 2008, pp 479&#8211;480"/>

    <meta name="citation_reference" content="citation_journal_title=Ann Arbor; citation_title=Ten steps to developing virtual reality applications for engineering education; citation_author=JT Bell, HS Fogler; citation_volume=48; citation_publication_date=1997; citation_pages=109-2136; citation_id=CR5"/>

    <meta name="citation_reference" content="Bertrand J, Brickler D, Babu S, Madathil K, Zelaya M, Wang T, Wagner J, Gramopadhye A, Luo J (2015) The role of dimensional symmetry on bimanual psychomotor skills education in immersive virtual environments. In: IEEE virtual reality conference, (2015) VR&#8217;15. IEEE"/>

    <meta name="citation_reference" content="Bloom BS, Englehart MD, Furst EJ,  Hill WH, Krathwohl DR (1956) Taxonomy of educational objectives: the classification of educational goals, Handbook 1: The cognitive domain, Longman, New York"/>

    <meta name="citation_reference" content="Crooks TJ (1988) Assessing student performance, Green guide No. 8. Higher Education Research and Development Society of Australasia, Kensington, NSW, Australia"/>

    <meta name="citation_reference" content="citation_title=Developing and writing behavioural objectives; citation_publication_date=1975; citation_id=CR9; citation_author=R Dave; citation_publisher=Educational Innovators Press"/>

    <meta name="citation_reference" content="Demiralp C, Laidlaw DH, Jackson C, Keefe D, Zhang S (2003) Subjective usefulness of cave and fish tank vr display systems for a scientific visualization application. In: IEEE computer society proceedings of the 14th IEEE visualization 2003 (VIS&#8217;03), p 86"/>

    <meta name="citation_reference" content="Ekstrom RB, French JW, Harman HH, Dermen D (1976) Kit of factor-referenced cognitive tests. Educational Testing Service, Princeton, NJ"/>

    <meta name="citation_reference" content="El-Chaar J, Boer C, Pedrazzoli P, Mazzola S, Maso G (2011) Interactive 3d virtual environments for industrial operation training and maintenance. In: 2011 9th International Conference on reliability, maintainability and safety (ICRMS). IEEE, pp 1376&#8211;1381"/>

    <meta name="citation_reference" content="citation_journal_title=Am Psychol; citation_title=Expert performance: its structure and acquisition; citation_author=KA Ericsson, N Charness; citation_volume=49; citation_issue=8; citation_publication_date=1994; citation_pages=725; citation_doi=10.1037/0003-066X.49.8.725; citation_id=CR13"/>

    <meta name="citation_reference" content="citation_journal_title=Phys Rev Spec Top Phys Educ Res; citation_title=When learning about the real world is better done virtually: a study of substituting computer simulations for laboratory equipment; citation_author=N Finkelstein, W Adams, C Keller, P Kohl, K Perkins, N Podolefsky, S Reid, R LeMaster; citation_volume=1; citation_issue=1; citation_publication_date=2005; citation_pages=010,103; citation_doi=10.1103/PhysRevSTPER.1.010103; citation_id=CR14"/>

    <meta name="citation_reference" content="citation_journal_title=Commun ACM; citation_title=A geometric modeling and animation system for virtual reality; citation_author=M Green, S Halliday; citation_volume=39; citation_issue=5; citation_publication_date=1996; citation_pages=46-53; citation_doi=10.1145/229459.229465; citation_id=CR15"/>

    <meta name="citation_reference" content="citation_journal_title=J Appl Psychol; citation_title=The guilford&#8211;zimmerman aptitude survey; citation_author=J Guilford, WS Zimmerman; citation_volume=32; citation_issue=1; citation_publication_date=1948; citation_pages=24; citation_doi=10.1037/h0063610; citation_id=CR16"/>

    <meta name="citation_reference" content="InterSense (2015) InterSense&#8212;precision motion tracking solutions-IS-1200 VisTracker. 
                    http://www.intersense.com/pages/33/198/
                    
                  , Accessed 28 May 2015"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Hum Behav; citation_title=Investigation of effects of virtual reality environments on learning performance of technical skills; citation_author=M Jou, J Wang; citation_volume=29; citation_issue=2; citation_publication_date=2013; citation_pages=433-438; citation_doi=10.1016/j.chb.2012.04.020; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=Educ Inf Technol; citation_title=Construct3d: a virtual reality application for mathematics and geometry education; citation_author=H Kaufmann, D Schmalstieg, M Wagner; citation_volume=5; citation_issue=4; citation_publication_date=2000; citation_pages=263-276; citation_doi=10.1023/A:1012049406877; citation_id=CR19"/>

    <meta name="citation_reference" content="citation_journal_title=Electron Commun Jpn (Part III Fundam Electron Sci); citation_title=Vlego: a simple two-handed 3d modeler in a virtual environment; citation_author=K Kiyokawa, H Takemura, Y Katayama, H Iwasa, N Yokoya; citation_volume=81; citation_issue=11; citation_publication_date=1998; citation_pages=18-28; citation_doi=10.1002/(SICI)1520-6440(199811)81:11&lt;18::AID-ECJC3&gt;3.0.CO;2-N; citation_id=CR20"/>

    <meta name="citation_reference" content="Kotranza A, Lind DS, Pugh CM, Lok B (2009) Real-time in-situ visual feedback of task performance in mixed environments for learning joint psychomotor-cognitive tasks. In: 8th IEEE International Symposium on mixed and augmented reality, 2009. ISMAR 2009. IEEE, pp 125&#8211;134"/>

    <meta name="citation_reference" content="Lingsong H, Wei L (2011) A ria based virtual instrument platform for test and measurement education. In: 2011 IEEE Conference on open systems (ICOS). IEEE, pp 139&#8211;142"/>

    <meta name="citation_reference" content="Menendez LM, Salaverr&#237;a A, Mandado E, Dacosta JG (2006) Virtual electronics laboratory: A new tool to improve industrial electronics learning. In: IECON 2006-32nd Annual Conference on IEEE Industrial Electronics. IEEE, pp 5445&#8211;5448"/>

    <meta name="citation_reference" content="Mizell DW, Jones SP, Slater M, Spanlang B (2002) Comparing immersive virtual reality with other display modes for visualizing complex 3d geometry. University College London, technical report"/>

    <meta name="citation_reference" content="Mlyniec P, Jerald J, Yoganandan A, Seagull FJ, Toledo F, Schultheis U (2011) iMedic: a two-handed immersive medical environment for distributed interactive consultation. In: Westwood JD et al (eds) Medicine Meets Virtual Reality NextMed, IOS Press, Netherland, pp 372&#8211;378. doi:
                    10.3233/978-1-60750-706-2-372
                    
                  
                        "/>

    <meta name="citation_reference" content="Noble RA, Clapworthy GJ (1998) Sculpting and animating in a desktop vr environment. In: Proceedings on computer graphics international, 1998. IEEE, pp 187&#8211;195"/>

    <meta name="citation_reference" content="Parmar D, Bertrand J, Shannon B, Babu SV, Madathil K, Zelaya M, Wang T, Wagner J, Frady K, Gramopadhye AK (2014) Interactive breadboard activity simulation (ibas) for psychomotor skills education in electrical circuitry. In: 2014 IEEE Symposium on 3D user interfaces (3DUI). IEEE, pp 181&#8211;182"/>

    <meta name="citation_reference" content="Pausch R, Proffitt D, Williams G (1997) Quantifying immersion in virtual reality. In: Proceedings of the 24th annual conference on Computer graphics and interactive techniques. ACM Press/Addison-Wesley Publishing Co., pp 13&#8211;18"/>

    <meta name="citation_reference" content="Qi W, Taylor&#160;II RM, Healey CG, Martens JB (2006) A comparison of immersive hmd, fish tank vr and fish tank with haptics displays for volume visualization. In: Proceedings of the 3rd symposium on applied perception in graphics and visualization. ACM, pp 51&#8211;58"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Vis Comput Graph; citation_title=Studying the effects of stereo, head tracking, and field of regard on a small-scale spatial judgment task; citation_author=ED Ragan, R Kopper, P Schuchardt, DA Bowman; citation_volume=19; citation_issue=5; citation_publication_date=2013; citation_pages=886-896; citation_doi=10.1109/TVCG.2012.163; citation_id=CR31"/>

    <meta name="citation_reference" content="Razer (2015) Razer Hydra gaming controller. 
                    http://www.razerzone.com/gaming-controllers/razer-hydra-portal-2-bundle
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Eng Des Graph J; citation_title=A virtual embedded microcontroller laboratory for undergraduate education: Development and evaluation; citation_author=G Richardson, M  Czerwinski, M  Van&#160;Dantzich; citation_volume=74; citation_issue=3; citation_publication_date=1997; citation_pages=1-12; citation_id=CR33"/>

    <meta name="citation_reference" content="Robertson G, Czerwinski M, Van&#160;Dantzich M (1997) Immersion in desktop virtual reality. In: Proceedings of the 10th annual ACM symposium on user interface software and technology. ACM, pp 11&#8211;19"/>

    <meta name="citation_reference" content="citation_journal_title=Annu Rev Psychol; citation_title=Acquisition of intellectual and perceptual-motor skills; citation_author=DA Rosenbaum, RA Carlson, RO Gilmore; citation_volume=52; citation_issue=1; citation_publication_date=2001; citation_pages=453-470; citation_doi=10.1146/annurev.psych.52.1.453; citation_id=CR35"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoper Virtual Environ; citation_title=Navigating large-scale virtual environments: what differences occur between helmet-mounted and desk-top displays?; citation_author=RA Ruddle, SJ Payne, DM Jones; citation_volume=8; citation_issue=2; citation_publication_date=1999; citation_pages=157-168; citation_doi=10.1162/105474699566143; citation_id=CR36"/>

    <meta name="citation_reference" content="citation_journal_title=Multimed Tools Appl; citation_title=Head-mounted display versus desktop for 3d navigation in virtual reality: a user study; citation_author=BS Santos, P Dias, A Pimentel, JW Baggerman, C Ferreira, S Silva, J Madeira; citation_volume=41; citation_issue=1; citation_publication_date=2009; citation_pages=161-181; citation_doi=10.1007/s11042-008-0223-2; citation_id=CR37"/>

    <meta name="citation_reference" content="Schmitz B, Specht M, Klemke R (2012) An analysis of the educational potential of augmented reality games for learning. In: Proceedings of the 11th World conference on mobile and contextual learning, International Association for Mobile Learning, pp 140&#8211;147"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Learn Technol; citation_title=Virtual instrument systems in reality (visir) for remote wiring and measurement of electronic circuits on breadboard; citation_author=M Tawfik, E Sancristobal, S Martin, R Gil, G Diaz, A Colmenar, J Peire, M Castro, K Nilsson, J Zackrisson; citation_volume=6; citation_issue=1; citation_publication_date=2013; citation_pages=60-72; citation_doi=10.1109/TLT.2012.20; citation_id=CR39"/>

    <meta name="citation_reference" content="Unity (2015) Unity-game engine. 
                    http://unity3d.com/
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoper Virtual Environ; citation_title=Measuring presence in virtual environments: a presence questionnaire; citation_author=BG Witmer, MJ Singer; citation_volume=7; citation_issue=3; citation_publication_date=1998; citation_pages=225-240; citation_doi=10.1162/105474698565686; citation_id=CR41"/>

    <meta name="citation_reference" content="citation_journal_title=J Comput Assist Learn; citation_title=Comparing and combining real and virtual experimentation: an effort to enhance students&#8217; conceptual understanding of electric circuits; citation_author=ZC Zacharia; citation_volume=23; citation_issue=2; citation_publication_date=2007; citation_pages=120-132; citation_doi=10.1111/j.1365-2729.2006.00215.x; citation_id=CR42"/>

    <meta name="citation_reference" content="Zanbaka C, Babu S, Xiao D, Ulinski A, Hodges L, Lok B (2004) Effects of travel technique on cognition in virtual environments. In: IEEE proceedings on virtual reality, 2004. IEEE, pp 149&#8211;286"/>

    <meta name="citation_reference" content="ZheMin C, Lingsong H (2009) The software breadboard technique of virtual instrument. In: 2009 WRI World Congress on computer science and information engineering, vol 7. IEEE, pp 585&#8211;589"/>

    <meta name="citation_author" content="Dhaval Parmar"/>

    <meta name="citation_author_email" content="dkparma@clemson.edu"/>

    <meta name="citation_author_institution" content="School of Computing, 120 McAdams Hall, Clemson University, Clemson, USA"/>

    <meta name="citation_author" content="Jeffrey Bertrand"/>

    <meta name="citation_author_institution" content="School of Computing, 120 McAdams Hall, Clemson University, Clemson, USA"/>

    <meta name="citation_author" content="Sabarish V. Babu"/>

    <meta name="citation_author_institution" content="School of Computing, 120 McAdams Hall, Clemson University, Clemson, USA"/>

    <meta name="citation_author" content="Kapil Madathil"/>

    <meta name="citation_author_institution" content="Department of Industrial Engineering, 110 Freeman Hall, Clemson University, Clemson, USA"/>

    <meta name="citation_author" content="Melissa Zelaya"/>

    <meta name="citation_author_institution" content="Department of Industrial Engineering, 110 Freeman Hall, Clemson University, Clemson, USA"/>

    <meta name="citation_author" content="Tianwei Wang"/>

    <meta name="citation_author_institution" content="Department of Mechanical Engineering, 212 Fluor Daniel, Clemson University, Clemson, USA"/>

    <meta name="citation_author" content="John Wagner"/>

    <meta name="citation_author_institution" content="Department of Mechanical Engineering, 212 Fluor Daniel, Clemson University, Clemson, USA"/>

    <meta name="citation_author" content="Anand K. Gramopadhye"/>

    <meta name="citation_author_institution" content="College of Engineering and Science, 109 Riggs Hall, Clemson University, Clemson, USA"/>

    <meta name="citation_author" content="Kristin Frady"/>

    <meta name="citation_author_institution" content="Department of Industrial Engineering, 110 Freeman Hall, Clemson University, Clemson, USA"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-016-0287-7&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2016/09/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-016-0287-7"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="A comparative evaluation of viewing metaphors on psychophysical skills education in an interactive virtual environment"/>
        <meta property="og:description" content="In an empirical evaluation, we examined the effect of viewing condition on psychophysical skills education in an interactive 3D simulation to train users in electrical circuitry. We compared an immersive head-mounted display (HMD)-based viewing metaphor versus a limited, desktop-based virtual reality (DVR) viewing metaphor with interaction using a spatial user interface. Psychophysical skills education involves the association of cognitive functions with motor functions to make the task autonomous with repeated practice. In electrical circuitry, this is demonstrated by the fine movements involved in handling and manipulating components on the electrical circuit, particularly while measuring electrical parameters. We created an interactive circuitry simulation (IBAS) where participants could learn about electrical measurement instruments such as the ammeter, voltmeter and multimeter, in a simulated breadboard VR system. Twenty-four participants utilized the simulation (12 in each condition), and the quantitative and qualitative aspects of psychophysical skills education with respect to the viewing metaphor were examined. Each viewing condition in IBAS was head-tracked and non-stereoscopic. Perspective correction was coupled with head-tracking in the DVR condition. The key quantitative measures were cognitive questionnaires addressing different levels of Bloom’s cognitive taxonomy and a real-world psychophysical task addressing various levels of Dave’s psychomotor taxonomy. The qualitative measures were the Witmer–Singer sense of presence questionnaire and self-report. Results suggest that there was a significant increase in cognition post-experiment in both DVR and HMD viewing conditions in levels of knowledge, application, analysis and evaluation. Results also revealed a significant learning benefit with respect to the higher level concepts pertaining to evaluation in the HMD condition as compared to DVR. Participants seem to have enjoyed a greater level of affordance in task performance and spent a larger amount of time to complete the simulated exercises as well as manually maneuvered to further distances in the HMD viewing condition as compared to DVR viewing."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>A comparative evaluation of viewing metaphors on psychophysical skills education in an interactive virtual environment | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-016-0287-7","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"HMD, Human factors, Education, 3D human–computer interaction","kwrd":["HMD","Human_factors","Education","3D_human–computer_interaction"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-016-0287-7","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-016-0287-7","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=287;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-016-0287-7">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            A comparative evaluation of viewing metaphors on psychophysical skills education in an interactive virtual environment
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-016-0287-7.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-016-0287-7.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2016-05-14" itemprop="datePublished">14 May 2016</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">A comparative evaluation of viewing metaphors on psychophysical skills education in an interactive virtual environment</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Dhaval-Parmar" data-author-popup="auth-Dhaval-Parmar" data-corresp-id="c1">Dhaval Parmar<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Clemson University" /><meta itemprop="address" content="grid.26090.3d, 0000000106650280, School of Computing, 120 McAdams Hall, Clemson University, Clemson, SC, 29634, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Jeffrey-Bertrand" data-author-popup="auth-Jeffrey-Bertrand">Jeffrey Bertrand</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Clemson University" /><meta itemprop="address" content="grid.26090.3d, 0000000106650280, School of Computing, 120 McAdams Hall, Clemson University, Clemson, SC, 29634, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Sabarish_V_-Babu" data-author-popup="auth-Sabarish_V_-Babu">Sabarish V. Babu</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Clemson University" /><meta itemprop="address" content="grid.26090.3d, 0000000106650280, School of Computing, 120 McAdams Hall, Clemson University, Clemson, SC, 29634, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Kapil-Madathil" data-author-popup="auth-Kapil-Madathil">Kapil Madathil</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Clemson University" /><meta itemprop="address" content="grid.26090.3d, 0000000106650280, Department of Industrial Engineering, 110 Freeman Hall, Clemson University, Clemson, SC, 29634, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Melissa-Zelaya" data-author-popup="auth-Melissa-Zelaya">Melissa Zelaya</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Clemson University" /><meta itemprop="address" content="grid.26090.3d, 0000000106650280, Department of Industrial Engineering, 110 Freeman Hall, Clemson University, Clemson, SC, 29634, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Tianwei-Wang" data-author-popup="auth-Tianwei-Wang">Tianwei Wang</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Clemson University" /><meta itemprop="address" content="grid.26090.3d, 0000000106650280, Department of Mechanical Engineering, 212 Fluor Daniel, Clemson University, Clemson, SC, 29634, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-John-Wagner" data-author-popup="auth-John-Wagner">John Wagner</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Clemson University" /><meta itemprop="address" content="grid.26090.3d, 0000000106650280, Department of Mechanical Engineering, 212 Fluor Daniel, Clemson University, Clemson, SC, 29634, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Anand_K_-Gramopadhye" data-author-popup="auth-Anand_K_-Gramopadhye">Anand K. Gramopadhye</a></span><sup class="u-js-hide"><a href="#Aff4">4</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Clemson University" /><meta itemprop="address" content="grid.26090.3d, 0000000106650280, College of Engineering and Science, 109 Riggs Hall, Clemson University, Clemson, SC, 29634, USA" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Kristin-Frady" data-author-popup="auth-Kristin-Frady">Kristin Frady</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Clemson University" /><meta itemprop="address" content="grid.26090.3d, 0000000106650280, Department of Industrial Engineering, 110 Freeman Hall, Clemson University, Clemson, SC, 29634, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 20</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">141</span>–<span itemprop="pageEnd">157</span>(<span data-test="article-publication-year">2016</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">898 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">11 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-016-0287-7/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>In an empirical evaluation, we examined the effect of viewing condition on psychophysical skills education in an interactive 3D simulation to train users in electrical circuitry. We compared an immersive head-mounted display (HMD)-based viewing metaphor versus a limited, desktop-based virtual reality (DVR) viewing metaphor with interaction using a spatial user interface. Psychophysical skills education involves the association of cognitive functions with motor functions to make the task autonomous with repeated practice. In electrical circuitry, this is demonstrated by the fine movements involved in handling and manipulating components on the electrical circuit, particularly while measuring electrical parameters. We created an interactive circuitry simulation (IBAS) where participants could learn about electrical measurement instruments such as the ammeter, voltmeter and multimeter, in a simulated breadboard VR system. Twenty-four participants utilized the simulation (12 in each condition), and the quantitative and qualitative aspects of psychophysical skills education with respect to the viewing metaphor were examined. Each viewing condition in IBAS was head-tracked and non-stereoscopic. Perspective correction was coupled with head-tracking in the DVR condition. The key quantitative measures were cognitive questionnaires addressing different levels of Bloom’s cognitive taxonomy and a real-world psychophysical task addressing various levels of Dave’s psychomotor taxonomy. The qualitative measures were the Witmer–Singer sense of presence questionnaire and self-report. Results suggest that there was a significant increase in cognition post-experiment in both DVR and HMD viewing conditions in levels of knowledge, application, analysis and evaluation. Results also revealed a significant learning benefit with respect to the higher level concepts pertaining to evaluation in the HMD condition as compared to DVR. Participants seem to have enjoyed a greater level of affordance in task performance and spent a larger amount of time to complete the simulated exercises as well as manually maneuvered to further distances in the HMD viewing condition as compared to DVR viewing.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>With the advancements in virtual reality, applications employing bimanual actions to accomplish tasks and educate users are becoming commonplace. VR applications such as the VR surgical simulator the da Vinci surgical system (Baheti et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Baheti A, Seshadri S, Kumar A, Srimathveeravalli G, Kesavadas T, Guru K (2008) Ross: virtual reality robotic surgical simulator for the da vinci surgical system. In: IEEE haptics 2008 symposium on haptic interfaces for virtual environment and teleoperator systems, 2008, pp 479–480" href="/article/10.1007/s10055-016-0287-7#ref-CR4" id="ref-link-section-d25462e459">2008</a>), 3D sculpting, modeling and animation (Noble and Clapworthy <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Noble RA, Clapworthy GJ (1998) Sculpting and animating in a desktop vr environment. In: Proceedings on computer graphics international, 1998. IEEE, pp 187–195" href="/article/10.1007/s10055-016-0287-7#ref-CR26" id="ref-link-section-d25462e462">1998</a>; Green and Halliday <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Green M, Halliday S (1996) A geometric modeling and animation system for virtual reality. Commun ACM 39(5):46–53" href="/article/10.1007/s10055-016-0287-7#ref-CR15" id="ref-link-section-d25462e465">1996</a>; Kiyokawa et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Kiyokawa K, Takemura H, Katayama Y, Iwasa H, Yokoya N (1998) Vlego: a simple two-handed 3d modeler in a virtual environment. Electron Commun Jpn (Part III Fundam Electron Sci) 81(11):18–28" href="/article/10.1007/s10055-016-0287-7#ref-CR20" id="ref-link-section-d25462e468">1998</a>), immersive 3D medical tele-consultation (Mlyniec et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Mlyniec P, Jerald J, Yoganandan A, Seagull FJ, Toledo F, Schultheis U (2011) iMedic: a two-handed immersive medical environment for distributed interactive consultation. In: Westwood JD et al (eds) Medicine Meets Virtual Reality NextMed, IOS Press, Netherland, pp 372–378. doi:&#xA;                    10.3233/978-1-60750-706-2-372&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0287-7#ref-CR25" id="ref-link-section-d25462e471">2011</a>) and mathematics and geometry education (Kaufmann et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Kaufmann H, Schmalstieg D, Wagner M (2000) Construct3d: a virtual reality application for mathematics and geometry education. Educ Inf Technol 5(4):263–276" href="/article/10.1007/s10055-016-0287-7#ref-CR19" id="ref-link-section-d25462e475">2000</a>) employ two-handed interaction within the virtual environment to train users in performing dexterous tasks that require similar two-handed interactions in real world.</p><p>One area where virtual reality has enormous potential is to train users in complex bimanual psychomotor skills in the realm of aviation and automotive technical education. Psychomotor skill is the ability to analyze perceived situations and automatically evoke motor responses to achieve a goal (Rosenbaum et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Rosenbaum DA, Carlson RA, Gilmore RO (2001) Acquisition of intellectual and perceptual-motor skills. Annu Rev Psychol 52(1):453–470" href="/article/10.1007/s10055-016-0287-7#ref-CR35" id="ref-link-section-d25462e481">2001</a>; Ericsson and Charness <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Ericsson KA, Charness N (1994) Expert performance: its structure and acquisition. Am Psychol 49(8):725" href="/article/10.1007/s10055-016-0287-7#ref-CR13" id="ref-link-section-d25462e484">1994</a>). Psychomotor skill learning is the process of acquiring the aforementioned skills with extensive amounts of practice to tie cognition with motor response. Our emphasis is in the aviation and automotive domain, and specifically in electrical circuitry applications, where these skills include careful analysis of the circuits and components, and precision movements while performing diagnostic measurements of electrical parameters and circuit modifications.</p><p>VR can facilitate psychomotor skills learning of these complex tasks involved in electrical circuitry measurement by providing scenarios for extensive practice with multisensory feedback. VR offers the ability to employ interaction principles to accurately simulate real-world performance. Moreover, VR simulations can provide scaffolded learning experience with different step-by-step guided practice scenarios as well as evaluative unguided exercises. It is possible to implement consistent and reliable situations using VR that can be used to train users anytime and anywhere.</p><p>The concept and the simulation was briefly introduced in (Parmar et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Parmar D, Bertrand J, Shannon B, Babu SV, Madathil K, Zelaya M, Wang T, Wagner J, Frady K, Gramopadhye AK (2014) Interactive breadboard activity simulation (ibas) for psychomotor skills education in electrical circuitry. In: 2014 IEEE Symposium on 3D user interfaces (3DUI). IEEE, pp 181–182" href="/article/10.1007/s10055-016-0287-7#ref-CR28" id="ref-link-section-d25462e493">2014</a>). The short poster paper presents the initial idea of the software, and describes a pilot study which found that users effectively learned the psychomotor skills pertaining to electrical circuitry using the interactive breadboard activity simulation (IBAS). This research greatly expands upon the cited work to provide details of the software simulation. Further, this work describes the thorough investigation performed to measure the effect of two common display metaphors: HMD with 6-DOF head-tracking (IBAS-HMD) and Desktop VR display with 3-DOF head-tracking (IBAS-DVR), on psychomotor skills learning with respect to the electrical measurement tasks.</p><p>The goals of this research can be stated as follows:</p><ol class="u-list-style-none">
                  <li>
                    <span class="u-custom-list-number">1.</span>
                    
                      <p>Using scaffolded learning approach, our first goal was to develop a virtual reality simulation for learning psychomotor skills related to electrical circuitry, which could be experienced in one of two different viewing metaphors: IBAS-DVR and IBAS-HMD.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">2.</span>
                    
                      <p>Our next research goal was to investigate overall whether there is an improvement in learning outcomes in the participants as a result of using the simulation. For this goal, we developed an experiment design with pre- and post-cognitive questionnaire conforming to the four condensed levels of Bloom’s cognitive taxonomy.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">3.</span>
                    
                      <p>Further, we wanted to perform a comparative evaluation to assess whether task performance, cognitive learning and psychomotor skills transference was different as a function of the viewing metaphors, based on participant experience in the different viewing conditions.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">4.</span>
                    
                      <p>An additional goal was to assess how well the skills learned in the virtual simulation transfer to the real world, by the means of evaluating real-world task performance at the end of the simulation.</p>
                    
                  </li>
                </ol>
                     </div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Related work</h2><div class="c-article-section__content" id="Sec2-content"><p>Virtual environments have been used extensively to educate users in complex manual tasks. The work of El-Chaar et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="El-Chaar J, Boer C, Pedrazzoli P, Mazzola S, Maso G (2011) Interactive 3d virtual environments for industrial operation training and maintenance. In: 2011 9th International Conference on reliability, maintainability and safety (ICRMS). IEEE, pp 1376–1381" href="/article/10.1007/s10055-016-0287-7#ref-CR12" id="ref-link-section-d25462e555">2011</a>) demonstrates the use of interactive 3D virtual environments for industrial operations training and maintenance. They built a training-centered software platform utilizing 3D modeling, animation and simulation to educate users in complex industrial operations tasks. They found that VR provides enabling circumstances to guide users through most complex and critical operations. Kotranza et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Kotranza A, Lind DS, Pugh CM, Lok B (2009) Real-time in-situ visual feedback of task performance in mixed environments for learning joint psychomotor-cognitive tasks. In: 8th IEEE International Symposium on mixed and augmented reality, 2009. ISMAR 2009. IEEE, pp 125–134" href="/article/10.1007/s10055-016-0287-7#ref-CR21" id="ref-link-section-d25462e558">2009</a>) studied the effects of real-time in situ feedback of task performance in mixed environments for learning joint psychomotor-cognitive tasks with respect to clinical breast exams (CBEs). They found that by integrating real-time visual feedback of learners’ quantitatively measured CBE performance, the mixed VE provides on-demand learning opportunities with more objective, detailed feedback than available with expert observation. Their study highlighted that receiving real-time in situ visual feedback of their performance provides students an advantage, over traditional approaches to learning CBEs, in developing correct psychomotor and cognitive skills. The study of Kaufmann et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Kaufmann H, Schmalstieg D, Wagner M (2000) Construct3d: a virtual reality application for mathematics and geometry education. Educ Inf Technol 5(4):263–276" href="/article/10.1007/s10055-016-0287-7#ref-CR19" id="ref-link-section-d25462e561">2000</a>) utilized Construct3D, a three-dimensional geometric construction tool based on the collaborative augmented reality system ’Studierstube’ to educate users in mathematics and geometry. Their system utilized a stereoscopic HMD and the Personal Interaction Panel, a two-handed 3D interaction tool, and found that the use of VR technology in the form of Construct3D facilitates ease of learning and encourages experimentation with geometric constructions. Baheti et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Baheti A, Seshadri S, Kumar A, Srimathveeravalli G, Kesavadas T, Guru K (2008) Ross: virtual reality robotic surgical simulator for the da vinci surgical system. In: IEEE haptics 2008 symposium on haptic interfaces for virtual environment and teleoperator systems, 2008, pp 479–480" href="/article/10.1007/s10055-016-0287-7#ref-CR4" id="ref-link-section-d25462e564">2008</a>) studied the effects of VR in the form of a VR robotic surgical simulator for the da Vinci surgical system (DVSS). They developed a two-handed 6-DOF VR trainer for acquiring basic psychomotor skills that are needed to perform surgery using the DVSS and found that the VR application provides a suitable beginners training environment for users before they graduate to the actual DVSS device. Assfalg et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Assfalg J, Del Bimbo A, Vicario E (2002) Using 3d and ancillary media to train construction workers. IEEE MultiMed 9(2):88–92" href="/article/10.1007/s10055-016-0287-7#ref-CR3" id="ref-link-section-d25462e567">2002</a>) utilized a 3D VE to train construction workers in a safety training system, and found that subjects showed an increased interest in the combined used of 3D graphics and multimedia, and they appreciated the possibility of seeing such solutions systematically used for their training. In a recent study, we examined the differences in dimensional symmetry by comparing a 3-DOF interaction metaphor to a 6-DOF metaphor (Bertrand et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Bertrand J, Brickler D, Babu S, Madathil K, Zelaya M, Wang T, Wagner J, Gramopadhye A, Luo J (2015) The role of dimensional symmetry on bimanual psychomotor skills education in immersive virtual environments. In: IEEE virtual reality conference, (2015) VR’15. IEEE" href="/article/10.1007/s10055-016-0287-7#ref-CR6" id="ref-link-section-d25462e571">2015</a>) and found that higher degrees of freedom improved skill transference to the real world with respect to the motor aspect of psychomotor skills. This suggests that higher degrees of interaction fidelity may be beneficial for a wide range of training simulations that involve a psychomotor component.</p><p>Also, prior empirical studies have examined the effects of various display metaphors on learning and task performance. Qi et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Qi W, Taylor II RM, Healey CG, Martens JB (2006) A comparison of immersive hmd, fish tank vr and fish tank with haptics displays for volume visualization. In: Proceedings of the 3rd symposium on applied perception in graphics and visualization. ACM, pp 51–58" href="/article/10.1007/s10055-016-0287-7#ref-CR30" id="ref-link-section-d25462e577">2006</a>) compared immersive HMD, DesktopVR (DVR) and DesktopVR with haptics displays for volume visualization and corresponding task performance. Results from their study showed that the DesktopVR and the DesktopVR with haptics groups were significantly more accurate at judging the shape, density, and connectivity of objects and completed the tasks significantly faster than the HMD group. Also, the DesktopVR group was significantly faster than the haptic group, there were no statistical differences in accuracy between the two. Arthur et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Arthur KW, Booth KS, Ware C (1993) Evaluating 3d task performance for fish tank virtual worlds. ACM Trans Inf Syst (TOIS) 11(3):239–265" href="/article/10.1007/s10055-016-0287-7#ref-CR2" id="ref-link-section-d25462e580">1993</a>) evaluated the 3D task performance for Fishtank virtual worlds and traditional workstation graphics displays comparing head-coupled viewing to stereoscopic viewing. They found that most users strongly preferred head-coupled viewing over stereo viewing. Though both head-coupling and stereo contribute to performance, head-coupling helps to a much greater extent. Demiralp et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Demiralp C, Laidlaw DH, Jackson C, Keefe D, Zhang S (2003) Subjective usefulness of cave and fish tank vr display systems for a scientific visualization application. In: IEEE computer society proceedings of the 14th IEEE visualization 2003 (VIS’03), p 86" href="/article/10.1007/s10055-016-0287-7#ref-CR10" id="ref-link-section-d25462e583">2003</a>) performed a qualitative and quantitative comparison between CAVE and DesktopVR displays for scientific visualization. The results of the qualitative study showed that users preferred DesktopVR display to the CAVE system for their scientific visualization application because of perceived higher resolution, brightness and crispness of imagery, as well as comfort of use. The results of the quantitative study showed that users performed an abstract visual search task significantly more quickly and more accurately on the DesktopVR display system than in the CAVE. They concluded that DesktopVR displays are more effective than CAVEs for applications in which the task occurs outside the user’s reference frame, the user views and manipulates the virtual world from the outside in, and the size of the virtual object that the user interacts with is smaller than the user’s body and fits into the DesktopVR display. Aoki et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Aoki H, Oman CM, Buckland DA, Natapoff A (2008) Desktop-vr system for preflight 3d navigation training. Acta Astronaut 63(7):841–847" href="/article/10.1007/s10055-016-0287-7#ref-CR1" id="ref-link-section-d25462e586">2008</a>) studied trainees’ orientation and navigation performance during simulated space station emergency egress tasks, compared while using immersive HMD and desktop VR systems. Their analyses showed no differences in pointing angular-error or egress time among the groups. The HMD group was significantly faster than the desktop group when pointing from destination to start location and from start toward a different destination; however they suggested that this difference may be attributed to differences in the input device used. All other 3D navigation performance measures were similar using the immersive and non-immersive VR systems, suggesting the simpler desktop VR system may be useful for the specific astronaut 3D navigation training.</p><p>Prior research in employing virtual technologies in electrical circuitry include the work of ZheMin and Lingsong (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="ZheMin C, Lingsong H (2009) The software breadboard technique of virtual instrument. In: 2009 WRI World Congress on computer science and information engineering, vol 7. IEEE, pp 585–589" href="/article/10.1007/s10055-016-0287-7#ref-CR44" id="ref-link-section-d25462e592">2009</a>) in creating a 2D virtual instrument IDE utilizing a software breadboard and a pipeline component-based assembling technique. Further, Tawfik et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Tawfik M, Sancristobal E, Martin S, Gil R, Diaz G, Colmenar A, Peire J, Castro M, Nilsson K, Zackrisson J et al (2013) Virtual instrument systems in reality (visir) for remote wiring and measurement of electronic circuits on breadboard. IEEE Trans Learn Technol 6(1):60–72" href="/article/10.1007/s10055-016-0287-7#ref-CR39" id="ref-link-section-d25462e595">2013</a>) describe virtual instrument systems in reality (VISIR) for remote wiring and measurement of electronic circuits on breadboard. Using VISIR, the user designs a circuit via mouse-based interaction on a simulated 2D workbench. Lingsong and Wei (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Lingsong H, Wei L (2011) A ria based virtual instrument platform for test and measurement education. In: 2011 IEEE Conference on open systems (ICOS). IEEE, pp 139–142" href="/article/10.1007/s10055-016-0287-7#ref-CR22" id="ref-link-section-d25462e598">2011</a>) present a rich internet application-based 2D virtual instrument platform for experiment tests and measurements. Oleagordia Aguirre et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Aguirre IO, Ruiz MB, Diaz JSM (2013) A platform for testing and measuring based on virtual instrument. IEEE Revista Iberoamericana de Tecnologias del Aprendizaje 8(3):143–151" href="/article/10.1007/s10055-016-0287-7#ref-CR27" id="ref-link-section-d25462e601">2013</a>) present a similar 2D virtual laboratory setting providing a test bed platform for training and performing practical exercises pertaining to electrical circuitry measurements. Research by Menendez et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Menendez LM, Salaverría A, Mandado E, Dacosta JG (2006) Virtual electronics laboratory: A new tool to improve industrial electronics learning. In: IECON 2006-32nd Annual Conference on IEEE Industrial Electronics. IEEE, pp 5445–5448" href="/article/10.1007/s10055-016-0287-7#ref-CR23" id="ref-link-section-d25462e604">2006</a>) describes a 2D virtual electronics laboratory to improve industrial electronics learning. Richardson and Adamo-Villani (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Richardson JJ, Adamo-Villani N (2011) A virtual embedded microcontroller laboratory for undergraduate education: Development and evaluation. Eng Des Graph J 74(3):1–12" href="/article/10.1007/s10055-016-0287-7#ref-CR33" id="ref-link-section-d25462e608">2011</a>) present a 3D virtual embedded microcontroller laboratory for undergraduate education. They developed and evaluated this virtual learning environment (VLE) in an introductory microcontroller undergraduate course at Purdue University, and found the VLE to be easy to use, engaging, useful, and comparable to a physical laboratory experience. A similar experiment conducted by Finkelstein et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Finkelstein N, Adams W, Keller C, Kohl P, Perkins K, Podolefsky N, Reid S, LeMaster R (2005) When learning about the real world is better done virtually: a study of substituting computer simulations for laboratory equipment. Phys Rev Spec Top Phys Educ Res 1(1):010,103" href="/article/10.1007/s10055-016-0287-7#ref-CR14" id="ref-link-section-d25462e611">2005</a>) looked at substituting VR simulations for laboratory equipment in an introductory physics course. Here, one group of students used a computer simulation that modeled electron flow in a circuit, and another group used real equipment. Students using simulated equipment outperformed their counterparts on surveys as well as tasks of assembling a real circuit and describing how it works. Zacharia (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Zacharia ZC (2007) Comparing and combining real and virtual experimentation: an effort to enhance students’ conceptual understanding of electric circuits. J Comput Assist Learn 23(2):120–132" href="/article/10.1007/s10055-016-0287-7#ref-CR42" id="ref-link-section-d25462e614">2007</a>) looked at investigating the value of combining real experimentation (RE) with virtual experimentation (VE) in students’ conceptual understanding of electrical circuits. A 2D desktop virtual circuits software was used in the RE + VE condition. They found that mixing the technologies enhanced students’ conceptual understanding of electric circuits more than RE alone, and their results were in favor of VE.</p><p>Our work differs from the discussed related work by providing an immersive virtual experience to train students about the fundamentals of electrical circuitry and measurement with the use of scaffolded learning. The immersive visualization, guided learning, and integrated testing is meant to augment classroom education to reduce the load on teachers to teach introductory electrical circuitry and focus on advanced topics. Our study specifically targets the combination of physical and cognitive skill learning pertaining to electrical circuitry measurement training employing an interactive 3D virtual environment. Further, our research provides a novel contribution in comparing the effects of the two common commodity display metaphors (HMD and DesktopVR) on psychomotor skills learning involved in electrical circuitry measurement. Finally, our research introduces a novel and extensible 3D simulation for educating users in electrical circuitry measurement tasks.</p></div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Methods</h2><div class="c-article-section__content" id="Sec3-content"><h3 class="c-article__sub-heading" id="Sec4">Participants</h3><p>The experiment involved 24 volunteer participants, 8 women and 16 men, recruited from the College of Engineering and Science at Clemson University, aged between 19 and 30 (mean = 23, SD =  2.75). The participants had natural or corrected to 20/20 vision for this study, and had little to no prior experience with the instruments covered in the simulation. 10 out of the 24 participants played games frequently (at least once a week) and 7 participants reported familiarity with the Razer Hydra or similar input devices. However, all the participants reported the simulation to be a novel experience.</p><h3 class="c-article__sub-heading" id="Sec5">System design and implementation</h3><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec6">User experience</h4><p>IBAS comprised of three modules, one for each instrument: voltmeter, ammeter and multimeter. Each module was further subdivided into three sections: introduction, guided practice and exercises. IBAS started with a training module for task familiarity. The IBAS system setup is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0287-7#Fig1">1</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig1_HTML.jpg" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Experiment setup for the Interactive Breadboard Activity Simulation in the DesktopVR condition (IBAS-DVR) on the <i>left</i>, and the IBAS-HMD condition on the <i>right</i>. The InterSense IS-1200 tracker is attached to the user’s head, and the user is holding a Razer Hydra controller</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>
                              <i>Training</i> The training section was built specifically for users to get acclimated to the two-handed 3D interactions performed within the VE, specifically picking up and releasing objects, translations and rotations. The users were presented with simple tasks such as picking up a ball and dropping it into a basket, and turning a key inserted into a keyhole. This section also introduced users to head-tracked egocentric viewing through the HMD or head-tracked perspective corrected viewing in case of the DesktopVR condition, and the users could look at the VE from different angles to help them complete the task. They received textual as well as auditory instructions and feedback. Visual feedback was presented in the form of highlights and color changes, and auditory feedback in the form of collision sounds.</p><p>
                              <i>Introduction</i> This was a textual section that introduced users to the electrical instrument to be learned in that particular module, the structure of the oncoming section and what to expect, the learning goals of the particular module, and any new electrical components, methodologies or terminologies that will be encountered within that module (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0287-7#Fig2">2</a>). Reading and navigating through this text- and image-based GUI section of a maximum of five pages, prepared the users for the learning task ahead specifically pertaining to electrical circuitry measurement.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Introduction section. Provides a slideshow-based introduction to the modules within IBAS (voltmeter example shown)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>
                              <i>Guided practice</i> This section provided users with step-by-step guidance in learning and performing actions to successfully measure electrical parameters with the measurement instruments, just like a virtual teacher (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0287-7#Fig3">3</a>). The users were presented with the VE consisting of the instrument, the breadboard, and other electrical components placed on a workbench within a classroom environment, and they interacted with the VE with either hand. Like the training section, users could view the VE from different angles utilizing the head-tracking on the HMD or the desktop monitor. There were textual instructions overlaid on the top of the screen, which the users could read as well as hear that prompted users to perform the required action to complete each step. The simulation advanced to the next instruction only upon correctly completing the current instruction step. In addition to the multisensory feedback described in the training section, feedback was also provided with the instruction background turning green or red depending on the action being performed correctly or incorrectly. There was also a simulated pseudo-haptic feedback in the form of stickiness to the breadboard wells, whereby the probes tended to stick or snap onto the breadboard wells as the user passed over the breadboard. The controllers did not provide any actual haptic feedback, but the participants experienced the need to apply some minimal force to break contact with one breadboard well and move to another. This was done to reduce accuracy errors while placing a probe into a breadboard well. On an average, users took 8 min to complete the guided practice sections (mean = 492.04 s, SD = 137.04 s).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Guided practice section. Provides step-by-step guidance and feedback to successfully perform measurement activities using the instrument. Example is shown for multimeter guided practice. The <i>blue</i> and <i>red spheres</i> indicate virtual positions of the <i>left</i> and <i>right</i> hand respectively (color figure online)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>
                              <i>Exercise</i> This was an open-ended exercise section in which users were presented with tasks similar to the guided practice, but without the helpful step-by-step guided instructions from the guided practice, and with increasing complexity (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0287-7#Fig4">4</a>). There were three exercise tasks in each module, and the users were expected to apply the knowledge gained from the introduction and guided practice sections to perform a successful measurement and answer the question for that particular task. The users were not limited or forced to perform any sequence of steps, and visual feedback was provided for correct or incorrect answers in the form of the question background turning green or red accordingly. Upon successfully completing the exercise, the simulation advanced to the next instrument module. On an average, users took 10 min to complete all the exercises (mean = 601.37 s, SD = 195.28s).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Exercise section. Open-ended section where users are asked to take a measurement and are expected to utilize knowledge gained from previous sections. The above image shows an exercise task from the voltmeter module. The <i>blue</i> and <i>red spheres</i> indicate virtual positions of the <i>left</i> and <i>right</i> hand respectively (color figure online)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec7">Modeling, rendering, and animation</h4><p>We used Unity3D (Unity <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Unity (2015) Unity-game engine. &#xA;                    http://unity3d.com/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0287-7#ref-CR40" id="ref-link-section-d25462e794">2015</a>), a powerful game development and rendering engine, to create IBAS. The 3D objects used in IBAS were modeled using Blender and then imported into Uniy3D. All the animations were performed using scripts within the Unity3D development environment. The system ran on a Windows XP machine with an Intel Core 2 Extreme QX6850 processor, an NVIDIA GeForce 8800 GT graphics card, having 4 GB of DDR2 memory. All the software, system drivers and the BIOS were updated to the latest available versions.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec8">3D user interaction</h4><p>Two-handed 3D user interaction with the VE was enabled using the Razer Hydra gaming controller (Razer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Razer (2015) Razer Hydra gaming controller. &#xA;                    http://www.razerzone.com/gaming-controllers/razer-hydra-portal-2-bundle&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0287-7#ref-CR32" id="ref-link-section-d25462e805">2015</a>) having 6-DOF magnetic motion tracking. We used the Sixense Unity Plug-in to be able to interface with the Hydra from within the unity development environment. Positions and orientations of each Hydra controller were obtained and applied to virtual manipulators, maintaining a constant distance offset from the actual physical position of the controllers. These virtual manipulators were represented using a blue and a red sphere (selector spheres) as shown in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0287-7#Fig3">3</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0287-7#Fig4">4</a>, one for each hand of the user, which were translated and rotated according to the user’s hand movements. All the tasks in IBAS could be performed using either of the hands or both hands simultaneously. Visual feedback was provided when the selector spheres collided with an object in the VE, in the form of a highlighted outline around the object and a change in color of the selector spheres. Interactions such as picking up objects and moving them around could be performed by pressing the trigger button on the Hydra and then holding it pressed. Releasing the trigger button would release the picked up object. Rotations in the 3D VE, such as rotating the circular knob on the multimeter, were performed by first colliding with the object to be rotated, holding the trigger button down to select the object for rotation, and then rotating the hydra along the axis of the desired rotation. The 2 button on the Hydra could be pressed to bring up a number pad to punch in numbers for reporting measurements. The numbers on the number pad were selected by moving the selector spheres over them, and then pressing the trigger button would enter the corresponding digit in the answer text box.</p><p>3D viewing within the VE in both the HMD and DesktopVR conditions was facilitated by head-tracking using the InterSense IS-1200 VisTracker system (InterSense <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="InterSense (2015) InterSense—precision motion tracking solutions-IS-1200 VisTracker. &#xA;                    http://www.intersense.com/pages/33/198/&#xA;                    &#xA;                  , Accessed 28 May 2015" href="/article/10.1007/s10055-016-0287-7#ref-CR17" id="ref-link-section-d25462e817">2015</a>). This system provides 6-DOF tracking using a hybrid of inertial-optical technology. There was a direct-to-scale transfer of the tracker’s position and orientation data to the camera in the VE, with a transform correction to account for the tracker’s position on the head with respect to the user’s eye position. The users experienced natural head-tracked movements in the HMD condition, and a head-tracked perspective corrected viewing in the DesktopVR condition.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec9">Scenario design and generation</h4><p>The scenarios were designed using a hierarchical task requirement analysis for measurements in electrical circuitry for each of the instruments, based on subject matter expert feedback from technical college instructors. The scenarios were developed for beginner-level users, having little or no knowledge of the subject. The introduction section provided all the basic knowledge required to prepare the users for the guided practice and the exercise sections. The guided practice scenario was designed at the lowest level of complexity, focusing on learning the steps of taking a measurement at the most basic level, and the exercises were designed to further the understanding from guided practice with tasks gradually increasing in level of complexity.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec10">Physics and inter-object Interactions</h4><p>Inter-object collisions and interactions were handled using colliders and rigid bodies within the Unity3D physics engine. Rendering the electrical wires was one special case where we used Bezier curves to draw curved lines and dynamically update them while interacting with the wires. Another special case was the simulated pseudo-haptic stickiness of the probes with the breadboard wells, where we used raycasting to find if the probe was hovering over a well and set the probe’s position to that well. The probe would then provide a mild resistance to move to a different well, giving a simulated sense of stickiness to the well and making the movement somewhat discrete instead of smooth and continuous.</p><h3 class="c-article__sub-heading" id="Sec11">Experiment procedure and design</h3><p>Participants were randomly assigned to one of two conditions for the interactive breadboard activity simulation (IBAS) in a between subjects design: IBAS with non-stereoscopic, head-tracked head-mounted display (IBAS-HMD) and IBAS with non-stereoscopic, head-tracked and perspective corrected DesktopVR display (IBAS-DVR).</p><p>The two viewing metaphors (IBAS-DVR and IBAS-HMD) are highly interesting because of the varied VR experiences each provides. On one hand, the IBAS-HMD viewing metaphor is immersive and provides a first person perspective as if you are in the simulated laboratory environment. The IBAS-DVR, on the other hand, provides a non-immersive view of the environment, like looking through a window into the laboratory environment, with a body-based interaction paradigm at the level of head-tracked perspective correction. However, one can argue that the IBAS-DVR is a cheaper alternative, if perspective correction is provided via off the shelf devices such as the Xbox Kinect and a desktop monitor display, as compared to the cost of the eMagin hmd ($1500), although the Oculus HMD is a much cheaper alternative to the eMagin.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec12">Hypothesis and research question</h4><p>Using the two common display metaphors, the study aimed to determine the effects of display metaphors on psychomotor skills learning in an interactive 3D virtual environment pertaining to electrical circuitry measurement. We asked the following research questions:</p><ol class="u-list-style-none">
                      <li>
                        <span class="u-custom-list-number">1.</span>
                        
                          <p>What are the quantitative differences in users’ psychomotor skills learning and task performance with respect to cognition, time to complete task, accuracy, knowledge transfer to real-world and real-world psychophysical task performance, between conditions IBAS-HMD and IBAS-DVR?</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">2.</span>
                        
                          <p>What are the qualitative differences in users’ psychomotor skills learning and task performance with respect to cognition, presence, affordance and acceptance of the VE between the conditions IBAS-HMD and IBAS-DVR?</p>
                        
                      </li>
                    </ol><p>Based on these research questions, we hypothesize the following:</p><ol class="u-list-style-none">
                      <li>
                        <span class="u-custom-list-number">1.</span>
                        
                          <p>The overall learning outcomes of the participants will improve after using IBAS, and will perform quantitatively better in post-cognitive tests as compared to pre cognitive tests.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">2.</span>
                        
                          <p>Participants in the IBAS-HMD condition will perform quantitatively better as compared to those in IBAS-DVR with respect to (a) cognition, (b) psychomotor skills learning, and (c) real-world psychophysical task performance.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">3.</span>
                        
                          <p>Participants will report positively in favor of the IBAS-HMD condition as compared to those in IBAS-DVR with respect to cognition, presence, affordance and acceptance of the VE.</p>
                        
                      </li>
                    </ol>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec13">Materials and apparatus</h4><p>For the IBAS-HMD condition, participants were seated in a chair wearing an eMagin Z800 3DVisor head-mounted display having a 40<span class="mathjax-tex">\(^\circ\)</span> diagonal field of view for each eye at an analog SVGA resolution of 800 <span class="mathjax-tex">\(\times\)</span> 600 at 60 Hz. For the IBAS-DVR condition, participants were seated in a chair 33 in (838.2 mm) away from a 20.4 in (518.4 mm) <span class="mathjax-tex">\(\times\)</span> 12.7 in (324 mm) Dell 2408WFP monitor display to match the field of view of the IBAS-HMD condition. To further keep the viewing conditions consistent, the monitor was set to a resolution of 800 <span class="mathjax-tex">\(\times\)</span> 600 at 60 Hz.</p><p>An InterSense IS1200 6-DOF VisTracker system was attached to the frame of the HMD in the IBAS-HMD condition, or a similar frame without an HMD affixed to the participant’s head in the IBAS-DVR condition for head-tracking. Participants used the two-handed Razer Hydra game controller with 6-DOF magnetic tracking to interact with the VE. The experiment PC was described earlier in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0287-7#Sec7">3.2.2</a>.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec14">Procedure</h4><p>The procedure was composed of the following steps:</p><ol class="u-list-style-none">
                      <li>
                        <span class="u-custom-list-number">1.</span>
                        
                          <p>
                                          <i>Pretrial</i> Upon arrival, participants were provided an informed consent form. Upon receiving consent from the participants, they were asked to complete four pre-experiment questionnaires: (a) the Guilford–Zimmerman (GZ) Spatial Orientation test (Guilford and Zimmerman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1948" title="Guilford J, Zimmerman WS (1948) The guilford–zimmerman aptitude survey. J Appl Psychol 32(1):24" href="/article/10.1007/s10055-016-0287-7#ref-CR16" id="ref-link-section-d25462e1034">1948</a>); (b) the Visual Memory (MV-2) test and (c) the Paper Folding (VZ-2) test of Visualization from the ETS kit of factor-referenced tests (Ekstrom et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1976" title="Ekstrom RB, French JW, Harman HH, Dermen D (1976) Kit of factor-referenced cognitive tests. Educational Testing Service, Princeton, NJ" href="/article/10.1007/s10055-016-0287-7#ref-CR11" id="ref-link-section-d25462e1037">1976</a>); and (d) a pretrial Cognition Questionnaire. Participants were randomly assigned to either the IBAS-HMD or the IBAS-DVR conditions.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">2.</span>
                        
                          <p>
                                          <i>Experiment trial</i> Participants were explained about the two-handed game controller, the HMD (in case of the IBAS-HMD condition) and the head-tracking system, and were asked for permission to place it on their head. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0287-7#Fig1">1</a> shows this experiment setup. The simulation was then started and participants were asked to follow the instructions given in the simulation. IBAS guided the participant first through a training section, where the users performed simple 3D pick and place tasks to acclimatize themselves to the two-handed 3D interaction with the VE, as well as the viewing method. IBAS then led the participant through the introduction, guided practice and exercise sections of each of the instrument modules: analog voltmeter, analog ammeter and digital multimeter. All through the runtime of the experiment, IBAS was collecting position/orientation and event specific data of entities in a separate thread and storing it in an XML file.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">3.</span>
                        
                          <p>
                                          <i>Real-world test</i> After the experiment trial conclusion, participants were asked to perform three real-world psychophysical tasks of taking electrical measurements on a real breadboard circuit, one for each instrument. Video recording of the participants’ actions was performed for this test to later analyze user performance.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">4.</span>
                        
                          <p>
                                          <i>Post-trial</i> Participants were asked to complete two post-experiment questionnaires: (a) a post-trial Cognition Questionnaire; and (b) the Witmer–Singer Presence Questionnaire (Witmer and Singer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Witmer BG, Singer MJ (1998) Measuring presence in virtual environments: a presence questionnaire. Presence Teleoper Virtual Environ 7(3):225–240" href="/article/10.1007/s10055-016-0287-7#ref-CR41" id="ref-link-section-d25462e1085">1998</a>). Finally, the participants were debriefed.</p>
                        
                      </li>
                    </ol>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec15">Measures</h4><p>The independent variables are the two viewing methods: the head-tracked head-mounted display (IBAS-HMD) and the head-tracked perspective corrected DesktopVR display (IBAS-DVR). There were a number of dependent variables that we used to evaluate the effect of viewing metaphors on psychomotor skills learning.</p><ol class="u-list-style-none">
                      <li>
                        <span class="u-custom-list-number">1.</span>
                        
                          <p>Quantitative measures: <i>Bloom’s cognitive taxonomy</i> Bloom’s taxonomy (Bloom et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1956" title="Bloom BS, Englehart MD, Furst EJ,  Hill WH, Krathwohl DR (1956) Taxonomy of educational objectives: the classification of educational goals, Handbook 1: The cognitive domain, Longman, New York" href="/article/10.1007/s10055-016-0287-7#ref-CR7" id="ref-link-section-d25462e1113">1956</a>) is a way to organize the levels of cognitive skills learned in a classroom and similar educational situations. This taxonomy has been popular in VR and education literature, and is utilized frequently to evaluate learning. For example, one study (Jou and Wang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Jou M, Wang J (2013) Investigation of effects of virtual reality environments on learning performance of technical skills. Comput Hum Behav 29(2):433–438" href="/article/10.1007/s10055-016-0287-7#ref-CR18" id="ref-link-section-d25462e1116">2013</a>) investigated the effects of virtual reality environments on learning performance of technical skills in accordance to Bloom’s Taxonomy. Another study (Schmitz et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Schmitz B, Specht M, Klemke R (2012) An analysis of the educational potential of augmented reality games for learning. In: Proceedings of the 11th World conference on mobile and contextual learning, International Association for Mobile Learning, pp 140–147" href="/article/10.1007/s10055-016-0287-7#ref-CR38" id="ref-link-section-d25462e1119">2012</a>) analyzed the educational potential of augmented reality games for learning using the taxonomy. Also, Bloom’s taxonomy was utilized to study the effects of travel technique on cognition in virtual environments (Zanbaka et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Zanbaka C, Babu S, Xiao D, Ulinski A, Hodges L, Lok B (2004) Effects of travel technique on cognition in virtual environments. In: IEEE proceedings on virtual reality, 2004. IEEE, pp 149–286" href="/article/10.1007/s10055-016-0287-7#ref-CR43" id="ref-link-section-d25462e1122">2004</a>).</p>
                          <p>We analyzed and compared scores of each participant from pre- and post-experiment cognition questionnaires, which were based on four condensed levels of Bloom’s Taxonomy (Crook’s condensation) (Crooks <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Crooks TJ (1988) Assessing student performance, Green guide No. 8. Higher Education Research and Development Society of Australasia, Kensington, NSW, Australia" href="/article/10.1007/s10055-016-0287-7#ref-CR8" id="ref-link-section-d25462e1128">1988</a>), namely Knowledge (recall or recognize information), Application (use or apply knowledge), Analysis (interpret elements, analyze or break down) and Evaluation (critical thinking, strategic comparison and review). Below are a few example questions from the questionnaire under each cognitive level:</p>
                          <p>
                            <i>Knowledge</i>
                            </p><ul class="u-list-style-bullet">
                              <li>
                                <p>Identify the measurement instrument shown in the picture.</p>
                              </li>
                              <li>
                                <p>Using the illustration of the analog ammeter scale below, determine (a) the unit of measurement and (b) the number of fractional divisions, or graduations, per unit of measurement.</p>
                              </li>
                            </ul>
                          
                          <p>
                            <i>Application</i>
                            </p><ul class="u-list-style-bullet">
                              <li>
                                <p>Give the steps you would follow to measure an electrical parameter using the given instrument.</p>
                              </li>
                              <li>
                                <p>Explain step-by-step the process that you would follow when measuring voltage across a circuit element using the instrument shown.</p>
                              </li>
                            </ul>
                          
                          <p>
                            <i>Analysis</i>
                            </p><ul class="u-list-style-bullet">
                              <li>
                                <p>Given a scenario of a colleague using a measurement instrument, analyze if the colleague is making any mistakes, and provide explanation and the solution</p>
                              </li>
                              <li>
                                <p>Imagine you saw a colleague grabbing a 0–10V DC voltmeter to measure the current through an electrical circuit. (a) describe the issues you expect your colleague to encounter, and (b) discuss how you would explain to your colleague why this voltmeter is not appropriate for making this measurement.</p>
                              </li>
                            </ul>
                          
                          <p>
                            <i>Evaluation</i>
                            </p><ul class="u-list-style-bullet">
                              <li>
                                <p>Reflect on your personal and work experiences and describe one scenario in which you used or could have used measuring instruments to assist on a task or project.</p>
                              </li>
                            </ul>
                          
                          <p>
                                          <i>Dave’s psychomotor taxonomy</i> Dave’s taxonomy for the psychomotor domain (Dave <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1975" title="Dave R (1975) Developing and writing behavioural objectives. Educational Innovators Press, NY" href="/article/10.1007/s10055-016-0287-7#ref-CR9" id="ref-link-section-d25462e1216">1975</a>) organizes motor skills into the following six categories: Imitation (observe and replicate), Manipulation (reproduce activity from instruction or memory), Precision (execute skill reliably, independent of help), Articulation (adapt and integrate expertise to satisfy a non-standard objective), and Naturalization (automated, unconscious mastery of activity and related skills at strategic level). Psychomotor skills can be assessed by mapping measured variables to these categories and analyzing differences across the categories.</p>
                          <p>We administered three real-world psychophysical tasks to the participants to study the transfer effects of learning in the virtual environment. On a given electrical circuit assembled over a breadboard, the three tasks were (1) to measure the resistance across a particular electrical element, (2) to measure the voltage across a particular section of the circuit, and (3) to measure the current flowing through the circuit. We used the first 3 levels of Dave’s psychomotor taxonomy, namely the imitation, manipulation and precision levels, for evaluating the psychophysical factors. For the imitation level, we looked at the mean time to complete the guided practice tasks to measure the efficiency of imitation of the given instructions. For the manipulation level, we looked at how well the users remembered and followed the steps learned from the guided practice section while performing the real-world psychophysical task, and also the number of mistakes made while performing the task. Finally, for the precision level, we looked at the time to complete the virtual exercises, the time to complete the real-world task, the number of contacts made with the breadboard wells in the virtual exercises, and the distance the virtual probes traveled in the VE.</p>
                          <p>
                                          <i>Performance and visual perspective changes</i> We also analyzed various performance related variables on the movements of end effectors and head position/orientation attest to the perceptual-motor affordances with respect to the DesktopVR versus HMD viewing that learners experienced during simulation-based education of the psychophysical skills related to electrical circuitry.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">2.</span>
                        
                          <p>Qualitative measures: In an attempt to better interpret the quantitative measures, we asked a number of open-ended discussion questions to the participants. These questions were used to assess their overall experience in the simulation. Some examples of these questions are: “how helpful were the step-by-step guided instructions in learning the tasks? and what was the best and worst thing about the simulation?”</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">3.</span>
                        
                          <p>Co-factors: In addition to the main measures described above, we gathered additional information regarding cognitive factors such as the participant’s spatial orientation using the GZ test; visual memory using the MV-2 test; and visualization using the VZ-2 test. We also collected responses from the participants regarding their sense of presence in the VE using the Witmer–Singer presence questionnaire.</p>
                        
                      </li>
                    </ol>
                           </div></div></section><section aria-labelledby="Sec16"><div class="c-article-section" id="Sec16-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec16">Results and analysis</h2><div class="c-article-section__content" id="Sec16-content"><p>Out of a total of 24 participants, 23 were considered for data analysis with 12 in the HMD condition and 11 in the DesktopVR condition. One participant in the DVR condition was excluded due to technical errors in the data collection modules of the experiment. Overall no significant differences were found between spatial orientation (GZ), visual memory (MV-2), or Mental Rotation (VZ-2) scores between participants in the HMD and DVR viewing conditions. Therefore our participant pool in both conditions had very similar backgrounds with respect to their innate spatial abilities.</p><p>For the participants’ sense of presence scores on the Witmer–Singer questionnaire (Witmer and Singer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Witmer BG, Singer MJ (1998) Measuring presence in virtual environments: a presence questionnaire. Presence Teleoper Virtual Environ 7(3):225–240" href="/article/10.1007/s10055-016-0287-7#ref-CR41" id="ref-link-section-d25462e1267">1998</a>), we found a significant difference for the question: “How quickly did you adjust to the virtual environment experience?” between the HMD and DVR conditions. The responses were scored on a seven-point Likert scale (1 = not at all, 7 = less than a minute). Participants adjusted to the simulation significantly quicker in the HMD condition (<i>M</i> = 5.67, SD = 0.88) as compared to the DVR condition (<i>M</i> = 4.33, SD = 1.15), <i>t</i>(22) = −3.17 and <span class="mathjax-tex">\(p\,&lt;\,0.004\)</span>. Since the DVR condition was similar to viewing the environment through a window, the visual disconnect could have been potentially jarring to the participants and could be affecting their closed loop visual-motor response to adjust to the environment. Objects in the DVR condition can appear distorted when trying to position yourself at the right vantage point. This artifact of perspective warping is not present in HMD viewing. There was also no significant difference in participants’ sense of presence scores between the HMD and DVR viewing conditions for any of the remaining questions. The quality of the DVR condition was higher than a regular desktop application due to the presence of head-coupled perspective correction. However, the quality of the HMD condition was lower than the current state-of-the-art technology available with higher FOV and resolution. This could explain why the experience of presence matched among the participants in both the conditions.</p><h3 class="c-article__sub-heading" id="Sec17">Quantitative results</h3><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec18">Cognitive domain</h4><p>We analyzed the differences in the scores of the participants to the cognition questionnaire in each of the four condensed levels of Bloom’s Taxonomy (Crook’s condensation) namely Knowledge, Application, Analysis and Evaluation. In a 2 <span class="mathjax-tex">\(\times\)</span> 2 factorial design, we examined the differences in pre- and post-cognition scores as a within subjects repeated measure in each of the four levels separately, and the two viewing metaphors IBAS-DVR versus IBAS-HMD condition as an external block between subjects factor (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0287-7#Fig5">5</a>). We conducted a 2 <span class="mathjax-tex">\(\times\)</span> 2 mixed model ANOVA analysis and Tukey post hoc HSD to perform follow-up comparisons in the examination of differences due to the individual factors namely the within subjects experiment session (pre versus post), and the between subjects viewing condition (HMD vs. DVR). Assumptions of normality of the interval score data in the dependent variable scores were tested prior to the mixed model ANOVA analysis using a statistical test of normality. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0287-7#Tab1">1</a> shows a summary of the results.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Descriptive statistics and summary of results for quantitative analysis in the cognitive domain</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0287-7/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                              <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Mean participant scores (%) across the four condensed levels of Bloom’s Cognitive Taxonomy for each of the IBAS-DVR and IBAS-HMD conditions</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>In the <i>Knowledge</i> level, the mixed model ANOVA comparing the main effect of experiment session revealed that participants in the pre session scored significantly lower (<i>M</i> = 42 %, SD = 0.27) than the post-session (<i>M</i> = 67 %, SD = 0.19), <i>F</i>(1, 42) = 11.65 and <span class="mathjax-tex">\(p\,=\,.0001\)</span>. Post hoc evaluation revealed that participants in the HMD condition scored significantly higher in the post-session (<i>M</i> = 68 %, SD = 0.18) as compared to the pre session (<i>M</i> = 41 %, SD = 0.30), <i>t</i>(22) = 2.60 and <span class="mathjax-tex">\(p\,=\,0.01\)</span>. Post hoc evaluation also revealed that participants in the DVR condition scored significantly higher in the post-session (<i>M</i> = 66 %, SD = 0.22) as compared to the pre session (<i>M</i> = 43 %, SD = 0.25), <i>t</i>(20) = 2.22 and <span class="mathjax-tex">\(p\,=\,0.03\)</span>. Participants seemed to have improved overall with respect to basic knowledge of the electrical circuitry, and seem to be more consistent in their scores in the post as compared to the pre sessions.</p><p>In the <i>Application</i> level, the mixed model ANOVA comparing the main effect of experiment session revealed that overall participants in the pre session scored significantly lower (<i>M</i> = 17 %, SD = 0.21) than the post-session (<i>M</i> = 88 %, SD = 0.09), <i>F</i>(1, 42) = 247.41 and <span class="mathjax-tex">\(p\,&lt;\,0.0001\)</span>. The ANOVA comparing the main effect of viewing condition also revealed that overall participants in the HMD condition scored significantly higher (<i>M</i> = 58 %, SD = 0.37) than the DVR condition (<i>M</i> = 47 %, SD = 0.40), <i>F</i>(1, 42) = 6.08 and <span class="mathjax-tex">\(p\,=\,0.01\)</span>. Post hoc evaluation revealed that participants in the HMD condition scored significantly higher in the post-session (<i>M</i> = 90 %, SD = 0.08) as compared to the pre session (<i>M</i> = 26 %, SD = 0.26), <i>t</i>(22) = 8.0 and <span class="mathjax-tex">\(p\,&lt;\,0.0001\)</span>. Post hoc evaluation revealed that participants in the DVR condition scored significantly higher in the post-session (<i>M</i> = 86 %, SD = 0.10) as compared to the pre session (<i>M</i> = 8 %, SD = 0.06), <i>t</i>(20) = 21.7 and <span class="mathjax-tex">\(p\,&lt;\,0.0001\)</span>. There was also a significant difference in participants scores in the pre-experiment session in that participants in the HMD condition scored significantly higher (<i>M</i> = 26 %, SD = 0.26) than participants in the DVR condition (<i>M</i> = 8 %, SD = 0.06), <i>t</i>(21) = 2.29 and <span class="mathjax-tex">\(p\,=\,0.03\)</span>. Nevertheless, participants seems to have greatly improved in both conditions with respect to the application domain of electrical circuitry learning, and seem to be more consistent in their scores in the post as compared to the pre sessions.</p><p>In the <i>Analysis</i> level, the mixed model ANOVA comparing the main effect of experiment session revealed that overall participants in the pre session scored significantly lower (<i>M</i> = 16 %, SD = 0.30) than the post-session (<i>M</i> = 72 %, SD = 0.27), <i>F</i>(1, 42) = 43.50 and <span class="mathjax-tex">\(p\,&lt;\,0.0001\)</span>. Post hoc evaluation revealed that participants in the HMD condition scored significantly higher in the post-session (<i>M</i> = 82 %, SD = 0.15) as compared to the pre session (<i>M</i> = 13 %, SD = 0.28), <i>t</i>(22) = 7.41 and <span class="mathjax-tex">\(p\,&lt;\,0.0001\)</span>. Post hoc evaluation revealed that participants in the DVR condition also scored significantly higher in the post-session (<i>M</i> = 60 %, SD = 0.33) as compared to the pre session (<i>M</i> = 20 %, SD = 0.34), <i>t</i>(20) = 2.84 and <span class="mathjax-tex">\(p\,=\,0.01\)</span>. In both viewing conditions, participants seemed to have improved overall with respect to the higher learning process of analysis in the electrical circuitry domain, and seem to be more consistent in their scores in the post as compared to the pre sessions.</p><p>In the <i>Evaluation</i> level, the mixed model ANOVA comparing the main effect of experiment session revealed that overall participants in the pre session scored significantly lower (<i>M</i> = 10 %, SD = 0.26) than the post-session (<i>M</i> = 77 %, SD = 0.28), <i>F</i>(1, 42) = 79.76 and <span class="mathjax-tex">\(p\,&lt;\,0.0001\)</span>. The ANOVA comparing the main effect of viewing condition also revealed that overall participants in the HMD condition scored significantly higher (<i>M</i> = 54 %, SD = 0.43) than the DVR condition (<i>M</i> = 32 %, SD = 0.41), <i>F</i>(1, 42) = 7.95 and <span class="mathjax-tex">\(p\,=\,0.007\)</span>. Post hoc evaluation revealed that participants in the HMD condition scored significantly higher in the post-session (<i>M</i> = 89 %, SD = 0.10) as compared to the pre session (<i>M</i> = 19 %, SD = 0.34), <i>t</i>(22) = 6.7 and <span class="mathjax-tex">\(p\,&lt;\,0.0001\)</span>. Post hoc evaluation revealed that participants in the DVR condition scored significantly higher in the post-session (<i>M</i> = 65 %, SD = 0.36) as compared to the pre session (<i>M</i> = 0, SD = 0), <i>t</i>(20) = 5.91 and <span class="mathjax-tex">\(p\,&lt;\,0.0001\)</span>. There was also a significant difference in participants scores in the post-experiment session in that participants in the HMD condition scored significantly higher (<i>M</i> = 89 %, SD = 0.10) than participants in the DVR condition (<i>M</i> = 65 %, SD = 0.36), <i>t</i>(21) = 2.14 and <span class="mathjax-tex">\(p\,=\,0.04\)</span>. In analysis, participants seem to have greatly improved in both conditions with respect to the higher level learning outcomes pertaining to evaluation. Furthermore, the results indicate that the viewing condition is important in grasping evaluation concepts with psychomotor skills learning in that participants in the IBAS-HMD viewing condition seem to have learned these concepts better than participants in the IBAS-DVR condition.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec19">Psychomotor domain</h4><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0287-7#Tab2">2</a> shows a summary of the results obtained within the psychomotor domain.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Descriptive statistics and summary of results for quantitative analysis in the psychomotor domain</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0287-7/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>For the <i>Imitation</i> level of Dave’s psychomotor taxonomy, we analyzed the mean time to complete the guided practice sessions within the IBAS-HMD and IBAS-DVR conditions (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0287-7#Fig6">6</a>). An independent samples <i>t</i> test revealed that participants in the DVR condition performed significantly faster (<i>M</i> = 391.55 s, SD = 101.32) than those in the HMD condition (<i>M</i> = 586.48, SD = 100.18), <i>t</i>(20) = 4.63, <span class="mathjax-tex">\(p\,&lt;\,0.01\)</span>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Mean time taken (in s) by the participants to complete the guided practice and virtual exercises sections in each of the IBAS-DVR and IBAS-HMD conditions</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>In the <i>Manipulation</i> level of Dave’s psychomotor taxonomy, we used a two-way mixed model ANOVA to analyze the effect of virtual world versus real world as one factor, with HMD and DVR conditions as another factor, on the order of steps performed to complete the task based on that learned in the guided practice sessions. However, the results were not significant.</p><p>In the <i>Precision</i> level of Dave’s psychomotor taxonomy, we analyzed the mean time to complete the virtual world exercises using an independent samples <i>t</i> test (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0287-7#Fig6">6</a>). Results showed that participants in the DVR condition completed the exercises significantly faster (<i>M</i> = 161.26 s, SD = 52.31) than participants in the HMD condition (<i>M</i> = 242.02, SD = 50.36), <i>t</i>(20) = 3.76, <span class="mathjax-tex">\(p\,&lt;\,0.01\)</span>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig7_HTML.gif?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig7_HTML.gif" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Mean number of probe contacts with the breadboard wells in the virtual environment across the IBAS-DVR and IBAS-HMD conditions</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>We also analyzed the mean time to complete the real-world tests across the two conditions of HMD and DVR, using a two-tailed independent samples <i>t</i> test. However, the results did not show a significant difference.</p><p>Further, we analyzed the number of probe contacts made with the breadboard wells in the virtual world across the DVR and HMD conditions (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0287-7#Fig7">7</a>). An independent samples <i>t</i> test revealed that the number of contacts made with the virtual probes were significantly higher in the HMD condition (<i>M</i> = 614, SD = 178) as compared to the DVR condition (<i>M</i> = 468, SD = 96), <i>t</i>(20) = 2.47, <span class="mathjax-tex">\(p\,&lt;\,0.05\)</span>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig8_HTML.gif?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig8_HTML.gif" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Mean distance traveled by the negative and positive instrument probes in the virtual environment across the IBAS-DVR and IBAS-HMD conditions</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Finally, we compared the distance traveled by the negative and positive probes in the virtual world across the two conditions using an independent samples <i>t</i> test (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0287-7#Fig8">8</a>). The distance traveled by the negative probe in the HMD condition was significantly larger (<i>M</i> = 208.01 cm, SD = 69.37) than that in the DVR condition (<i>M</i> = 130.22, SD = 57.99), <i>t</i>(20) = 2.93, <span class="mathjax-tex">\(p\,&lt;\,0.01\)</span>. The distance traveled by the positive probe was also significantly larger in the HMD condition (<i>M</i> = 127.86, SD = 36.10) as compared to that in the DVR condition (<i>M</i> = 82.46, SD = 31.59), <i>t</i>(20) = 3.22, <span class="mathjax-tex">\(p\,&lt;\,0.01\)</span>.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec20">VR performance variables</h4><p>
                              <i>Time to Complete Tasks:</i> An independent samples <i>t</i> test comparing the time to complete in various interactive session of the interactive breadboard activity simulation (IBAS) was done between the two viewing conditions. In the guided practice session, participants in the HMD condition took significantly longer time (<i>M</i> = 586.47 s, SD = 100.17) than participants in the DVR condition (<i>M</i> = 391.55 s, SD = 101.32), <i>t</i>(21) = 4.64 and <span class="mathjax-tex">\(p\,=\,\,0.0001\)</span>. In the Voltmeter open exercise session, participants in the HMD condition took significantly more time (<i>M</i> = 250.50 s, SD = 74.67) than participants in the DVR condition (<i>M</i> = 150.73 s, SD = 37.78), <i>t</i>(21) = 3.98 and <span class="mathjax-tex">\(p\,=\,0.0006\)</span>. In the Ammeter open exercise session, participants in the HMD condition took significantly longer time (<i>M</i> = 272.48 s, SD = 74.39) than participants in the DVR condition (<i>M</i> = 176.69 s, SD = 89.99), <i>t</i>(21) = 2.79 and <span class="mathjax-tex">\(p\,=\,0.01\)</span>. Likewise in the multimeter open exercise session, participants in the HMD condition took significantly more time (<i>M</i> = 203.06 s, SD = 32.29) than participants in the DVR condition (<i>M</i> = 156.33 s, SD = 45.55), <i>t</i>(21) = 2.85 and <span class="mathjax-tex">\(p\,=\,0.009\)</span>.</p><p>
                              <i>Distance covered during bimanual interaction</i> In order to compare the total distances maneuvered by the participants during two-handed interaction (measured in cm) in the simulated breadboard tasks in the open exercise session of IBAS, we conducted an independent samples <i>t</i> test comparing the distances covered by the Razer Hydra effectors in the dominant and non-dominant hand of the participants in the simulation between the two different viewing conditions. We found that total distance covered by the controller in the dominant hand was significantly larger in the Voltmeter open exercise session in the HMD condition (<i>M</i> = 1281.85 cm, SD = 745) than in the DVR condition (<i>M</i> = 696.57 cm, SD = 392), <i>t</i>(21) = 2.32 and <span class="mathjax-tex">\(p\,=\,0.03\)</span>. We also found that total distance covered by the dominant hand controller in the Ammeter open exercise session was again significantly larger in the HMD condition (<i>M</i> = 836.01 cm, SD = 427) than in the DVR condition (<i>M</i> = 417.65 cm, SD = 239.74), <i>t</i>(21) = 2.86 and <span class="mathjax-tex">\(p\,=\,0.009\)</span>.</p><p>
                              <i>Number of virtual probe contacts with the breadboard wells</i> In order to compare the number of contacts that the participant made while placing the probes (+ and −) on the breadboard during two-handed interaction in the simulated breadboard open exercise session, we conducted an independent samples <i>t</i> test comparing the number of virtual probe contact with the breadboard between the two viewing conditions. We found that participants made significantly higher number of contacts with the breadboard in the Voltmeter exercise session in the HMD condition (<i>M</i> = 247.58, SD = 127.89) than in the DVR condition (<i>M</i> = 163.63, SD = 32.69), <i>t</i>(21) = 2.11 and <span class="mathjax-tex">\(p\,=\,0.04\)</span>. Likewise, we also found that participants made significantly higher number of contacts with the breadboard in the Ammeter exercise session in the HMD condition (<i>M</i> = 201.16, SD = 32.84) than in the DVR condition (<i>M</i> = 156.54, SD = 64.04), <i>t</i>(21 = 2.23 and <span class="mathjax-tex">\(p\,=\,0.04\)</span>.</p><p>Although participants could interact with both hands in the simulated breadboard activities in the guided practice and open exercise sessions, we found that participants generally preferred to maneuver the probes, select and manipulate various parts of the simulated breadboard components using their dominant hand. Also, we carefully matched the constant offset in distance between the virtual manipulators and the physical controller in the hand equally in both viewing conditions, in order to be consistent in our experiment design. However, participants seemed to have enjoyed a higher level of perceived affordances in the IBAS-HMD condition as opposed to the IBAS-DVR condition, as evidenced by the significantly higher distances covered, number of virtual probe contacts, and time to complete the task during manual dexterous activities in the IBAS-HMD condition as compared to the IBAS-DVR condition.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec21">Visual perspective changes</h4><p>Here we analyzed participants’ head-tracked position and orientation data, continuously logged by the VR system, in order to ascertain to what extent did participants change their visual perspective and attend to the simulated psychomotor task from a suitable vantage point (Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0287-7#Fig9">9</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0287-7#Fig10">10</a>). We computed the total Euclidian distance covered by the participants’ head as they moved side to side to adjust the viewing angle in the different viewing conditions. We conducted an independent samples <i>t</i> test on the total distance covered by the participants’ head (measured in cm) and total head rotation in degrees about the three separate axes of the world coordinate system, in the open exercise session of IBAS. Note that we ensured that simulation frame rate in both conditions was even at around 40Hz. Participants moved their head a significantly greater distance in the HMD condition (<i>M</i> = 2920 cm, SD = 810.7), than in the DesktopVR condition (<i>M</i> = 1644.47 cm, SD = 895.8), <i>t</i>(21) = 3.58 and <span class="mathjax-tex">\(p\,=\,0.001\)</span>. Participants pitched their heads up and down by a significantly larger amount in the HMD condition (<i>M</i> = 3263.85, SD = 925.87) than in the DesktopVR condition (<i>M</i> = 1173.66, SD = 678.60), <i>t</i>(21) = 6.13 and <span class="mathjax-tex">\(p\,&lt;\,0.0001\)</span>. Participants panned their heads from side to size by a significantly larger amount in the HMD condition (<i>M</i> = 2248.91, SD = 644.23) than in the DesktopVR condition (<i>M</i> = 1058.65, SD = 410.52), <i>t</i>(21) = 5.23 and <span class="mathjax-tex">\(p\,&lt;\,0.0001\)</span>. Also, participants rotated their heads about their viewing direction by a significantly larger amount in the HMD condition (<i>M</i> = 1599.83, SD = 561.76) than the DesktopVR condition (<i>M</i> = 492.92, SD = 373.37), <i>t</i>(21) = 5.50 and <span class="mathjax-tex">\(p\,&lt;\,0.0001\)</span>. Overall, we found that participants exhibited a larger amount of gaze shifts and changes in their visual perspective a significantly larger proportion of time in the HMD condition than in the DesktopVR condition, in performing the psychomotor skills learning activities.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig9_HTML.gif?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig9_HTML.gif" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Mean distance traveled (in cm) through head movements in the virtual environments across the IBAS-DVR and IBAS-HMD conditions</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                              <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig10_HTML.gif?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0287-7/MediaObjects/10055_2016_287_Fig10_HTML.gif" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Mean amounts of head rotation (in <span class="mathjax-tex">\(\circ\)</span>) in the virtual environments across the IBAS-DVR and IBAS-HMD conditions</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0287-7/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h3 class="c-article__sub-heading" id="Sec22">Qualitative results</h3><p>In order to assess the perceived differences in learning the psychomotor skills in the different visual display metaphors, we asked participants to report on the strengths and weaknesses of the HMD and DesktopVR viewing conditions with respect to psychomotor skills learning. We have summarized the responses below by viewing metaphor when asked the question, “what was the best and worst thing about the simulation?”</p><p>Strengths of the HMD viewing metaphor:</p><ul class="u-list-style-bullet">
                    <li>
                      <p>“Practice exercises with feedback after every instrument explanation was very helpful in learning the task step-by-step before the open exercises.”</p>
                    </li>
                    <li>
                      <p>“Best thing is that I can learn various instruments just like sitting in front of the workbench, and the details presented were good.”</p>
                    </li>
                    <li>
                      <p>“Closely resembles the real-world experience!”</p>
                    </li>
                  </ul><p>Weaknesses of the HMD viewing metaphor:</p><ul class="u-list-style-bullet">
                    <li>
                      <p>“Although the interaction and 3D simulation was believable, but the head gear hurts. Would be better if I had a more comfortable and less bulky gear.”</p>
                    </li>
                    <li>
                      <p>“I experienced difficulty placing the probes in the correct wells.”</p>
                    </li>
                    <li>
                      <p>“Difficulty getting used to the device for input, and maybe because I never used it before.”</p>
                    </li>
                  </ul><p>Strengths of the DesktopVR viewing metaphor:</p><ul class="u-list-style-bullet">
                    <li>
                      <p>“Very engaging similar to the real world, good experience to learn a complicated task using the simulation.”</p>
                    </li>
                    <li>
                      <p>“The look and feel of the simulation was excellent and engaging.”</p>
                    </li>
                    <li>
                      <p>“I liked following a series of steps to complete the task with both hands, and then repeating them on my own later.”</p>
                    </li>
                  </ul><p>Weakness of the DesktopVR viewing metaphor:</p><ul class="u-list-style-bullet">
                    <li>
                      <p>“The view of the 3D environment felt a little unfamiliar for me, I had to keep the scene within my window.”</p>
                    </li>
                    <li>
                      <p>“The breadboard was difficult to interact with, and I had a difficult time telling the depth.”</p>
                    </li>
                    <li>
                      <p>“Some of the controls were difficult but easy to adjust to.”</p>
                    </li>
                  </ul><p>Participants generally seemed to prefer the interactive nature of IBAS in learning the psychomotor skills. They liked the guided practice with feedback sessions of the breadboard activities, and the open exercise sessions in fine tuning their performance of the task that they just learned. Although participants mentioned that the HMD gear was bulky and cumbersome, it was realistic in simulating the experience of performing the breadboard task as if sitting in front of an actual workbench. Participants felt that the DesktopVR viewing was just as engaging, but mentioned that the viewing with head-tracked perspective correction in performing the psychomotor task was somewhat unfamiliar (perhaps unnatural) to them. Though viewing conditions were closely matched in both metaphors with respect to resolution, field of view, non-stereoscopic, and incorporated head-coupled viewing, the participants seemed to perceive the psychomotor learning task as more natural in the HMD viewing as compared to the DesktopVR condition.</p><h3 class="c-article__sub-heading" id="Sec23">Discussion</h3><p>This study was aimed at comparing the head-mounted display-based viewing metaphor to a desktop-based viewing metaphor using an empirical evaluation on the learning task of electrical measurement instruments, using the IBAS VR simulation. In general, the participants found the IBAS highly engaging and a great learning experience. They gained significant knowledge and understanding of the topic of basic electrical circuitry and parameter measurement, and the results testify the same (hypothesis 1 was supported). VR, therefore, can be an effective tool for education in basic concepts of electrical circuitry, which can help in preparation ahead of learning advanced concepts within a classroom or a training environment.</p><p>In a two pronged approach for analysis of the participant data, we examined the cognitive effects of IBAS using Bloom’s Cognitive taxonomy, and psychomotor effects using Dave’s Psychomotor taxonomy. Traditional methods of training and teaching tend to focus on the three lower levels of Bloom’s taxonomy knowledge, comprehension and application. VR, however, has the potential to impact higher levels of Bloom’s taxonomy analysis, synthesis and evaluation. Bell and Fogler (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Bell JT, Fogler HS (1997) Ten steps to developing virtual reality applications for engineering education. Ann Arbor 48:109–2136" href="/article/10.1007/s10055-016-0287-7#ref-CR5" id="ref-link-section-d25462e4890">1997</a>) state that these upper levels are more difficult to teach and evaluate than the lower levels, and as a result are not implemented as extensively in most curriculums. For IBAS, with respect to the knowledge and analysis levels, the viewing metaphor had little or no significant effect in learning. However, in the higher levels of analysis and evaluation, participants performed significantly better in the HMD condition than the DVR condition (hypothesis 2a was partially supported). Therefore, choosing a viewing metaphor between the HMD and DVR conditions would greatly depend on the level that a cognitive task is designed for. An example of such a task for electrical measurements would be training in microchip design and troubleshooting, or electronics maintenance in automobile or aviation equipment. In case of tasks designed to focus on psychomotor skills rather than cognitive skills, the opposite of hypothesis 2b was partially supported, in a way that the DVR viewing condition would be preferable, as the results show that participants were better at the imitation and precision levels of Dave’s psychomotor taxonomy in the DVR condition as compared to the HMD condition. Tasks requiring psychomotor precision would include training in medical procedures such as laparoscopic surgery and endoscopy. The study did not find significant effects in virtual world versus real-world task performance across the two conditions, and hypothesis 3 was not supported. One possible reason could be the design and duration of the real-world tasks. A much better design for testing real-world task performance and skill transference is warranted, and a pre versus post-comparison would yield more robust results in this regard.</p><p>The IBAS-DVR condition was a window into the virtual world of the simulation, which limited the user’s vision through it. The field of view was altered through the means of head-tracking and perspective correction to correctly display the elements in the VR, but the user could not see beyond the limits of the desktop screen. Also, peripheral vision was not blocked in the DVR condition, which would reduce the sense of presence for the user. The HMD condition, however, had a 360° field of regard, and the field of view was constant. Further, the peripheral vision was blocked by the HMD assembly, which strengthened the sense of presence. This would explain why participants spent more time exploring the virtual environment with significantly higher head rotations and orientations and significantly higher hand movements in the HMD condition as compared to the DVR condition. This result supports the observations of Ruddle et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Ruddle RA, Payne SJ, Jones DM (1999) Navigating large-scale virtual environments: what differences occur between helmet-mounted and desk-top displays? Presence Teleoper Virtual Environ 8(2):157–168" href="/article/10.1007/s10055-016-0287-7#ref-CR36" id="ref-link-section-d25462e4896">1999</a>) in their navigation study where participants spent less time stationary when using an HMD and looked around significantly more as compared to desktop viewing. They argue that “one explanation for this behavioral difference may be that the HMD provided an interface in which changes in view direction were natural and required less effort.”</p><p>
Santos et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Santos BS, Dias P, Pimentel A, Baggerman JW, Ferreira C, Silva S, Madeira J (2009) Head-mounted display versus desktop for 3d navigation in virtual reality: a user study. Multimed Tools Appl 41(1):161–181" href="/article/10.1007/s10055-016-0287-7#ref-CR37" id="ref-link-section-d25462e4902">2009</a>) examined various studies comparing VR systems using HMDs and desktops (or similar) and learned that the differences between these viewing metaphors accounted in literature are either conflicting or insignificant. For example, Pausch et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Pausch R, Proffitt D, Williams G (1997) Quantifying immersion in virtual reality. In: Proceedings of the 24th annual conference on Computer graphics and interactive techniques. ACM Press/Addison-Wesley Publishing Co., pp 13–18" href="/article/10.1007/s10055-016-0287-7#ref-CR29" id="ref-link-section-d25462e4905">1997</a>) found the HMD condition to be better in a search task in VR, specifically in concluding that the searched target is not present, and no difference in other cases, whereas Robertson et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Robertson G, Czerwinski M, Van Dantzich M (1997) Immersion in desktop virtual reality. In: Proceedings of the 10th annual ACM symposium on user interface software and technology. ACM, pp 11–19" href="/article/10.1007/s10055-016-0287-7#ref-CR34" id="ref-link-section-d25462e4908">1997</a>) found the desktop condition to be better at searching tasks when the target was present, and no difference between the viewing conditions otherwise. Mizell et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Mizell DW, Jones SP, Slater M, Spanlang B (2002) Comparing immersive virtual reality with other display modes for visualizing complex 3d geometry. University College London, technical report" href="/article/10.1007/s10055-016-0287-7#ref-CR24" id="ref-link-section-d25462e4911">2002</a>) found no difference between desktop and HMD conditions in their study. Santos et al, in their study, found that global user performance was better for the desktop as compared to the HMD viewing. This result is similar to our study where we found that in general VR performance, participants in the DVR condition performed the guided practice and exercise sessions significantly faster than those in the HMD condition. However, this result greatly depends on the type of the simulation and design of the task.</p><p>Participants found the VR hardware novel and intriguing, though they seemed to require time and practice in getting acclimated to the VR equipment. Even though the participants enjoyed being immersed in the virtual environment, they stated that they would be more comfortable if the equipment was less bulky. Therefore, for future studies of similar design, care must be taken that either the VR equipment used is comfortable and less bulky, or ample time and practice is provided for getting adjusted to the equipment.</p></div></div></section><section aria-labelledby="Sec24"><div class="c-article-section" id="Sec24-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec24">Conclusion and future work</h2><div class="c-article-section__content" id="Sec24-content"><p>We created an interactive breadboard activity VR simulation (IBAS) to educate users in psychomotor skills pertaining to electrical circuitry. In an empirical evaluation, we compared two popular viewing metaphors (HMD vs. DVR) on psychomotor skills learning using a combination of quantitative variables pertaining to cognition based on Bloom’s taxonomy in knowledge, application, analysis and evaluation levels, objective VR performance variables, psychophysical skills assessment task measures, and qualitative subjective questionnaires. In comparing the pre- and post-experiment cognition questionnaire results, we found that in both viewing conditions, participants effectively learned the psychomotor skills in all condensed levels of Bloom’s taxonomy. However with respect to the highest levels of learning pertaining to Evaluation, participants in HMD viewing condition learned the task significantly better than participants in the DVR condition.</p><p>In the guided practice and open exercises sessions of IBAS, participants in the HMD viewing condition spent more time exploring the psychomotor task, and manually interacted extensively with IBAS as compared to the DVR viewing condition. The performance of the psychomotor learning task in the HMD viewing condition also seemed more natural as reported by participants in the subjective self-reports. An implication of this study for designers and consumers of VR systems for training and education is that if higher level learning pertaining to Evaluation is important in psychomotor skills acquisition, then an HMD viewing metaphor may be preferable as compared to a DVR display.</p><p>In an attempt to carefully match the viewing conditions in the empirical evaluation so as to eliminate confounding variables between the two viewing conditions, several limitations arose with our study that we hope to address in future work. In both viewing conditions the resolution and field of view was limited. Differences in display resolution can be a confounding factor in measurement of performance across different displays, as discussed by Ragan et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Ragan ED, Kopper R, Schuchardt P, Bowman DA (2013) Studying the effects of stereo, head tracking, and field of regard on a small-scale spatial judgment task. IEEE Trans Vis Comput Graph 19(5):886–896" href="/article/10.1007/s10055-016-0287-7#ref-CR31" id="ref-link-section-d25462e4933">2013</a>). While comparing DesktopVR to HMD in a virtual search task, Pausch et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Pausch R, Proffitt D, Williams G (1997) Quantifying immersion in virtual reality. In: Proceedings of the 24th annual conference on Computer graphics and interactive techniques. ACM Press/Addison-Wesley Publishing Co., pp 13–18" href="/article/10.1007/s10055-016-0287-7#ref-CR29" id="ref-link-section-d25462e4936">1997</a>) maintained the same resolution across conditions within their study to hold variables constant. Further, the display conditions in our study were non-stereoscopic to match the HMD condition with the DesktopVR condition, and to keep the study design simple by reducing the factor of stereoscopic vision. The lack of stereoscopic vision, however, affected depth perception in both the scenarios. A controlled environment was primarily motivated by the need for a low-cost VR simulation that we needed to deploy in partnering technical colleges to teach and train users in the electrical circuitry task in aviation and automotive technical education.</p><p>In future studies, we will compare these results against HMD viewing with higher resolution and field of view, and unrestricted desktop and large screen displays, for full ecological validity on psychomotor skills learning. We will also compare and contrast the perceived affordances and learning characteristics in the results from our current binocular non-stereoscopic viewing condition against the binocular stereoscopic viewing (impact of depth perception) on psychomotor skills learning. A real-world-based control group to compare the efficacy of skills transfer in the real world with that in the virtual world will help further generalize our results.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="IO. Aguirre, MB. Ruiz, JSM. Diaz, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Aguirre IO, Ruiz MB, Diaz JSM (2013) A platform for testing and measuring based on virtual instrument. IEEE Re" /><p class="c-article-references__text" id="ref-CR27">Aguirre IO, Ruiz MB, Diaz JSM (2013) A platform for testing and measuring based on virtual instrument. IEEE Revista Iberoamericana de Tecnologias del Aprendizaje 8(3):143–151</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FRITA.2013.2273115" aria-label="View reference 1">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20platform%20for%20testing%20and%20measuring%20based%20on%20virtual%20instrument&amp;journal=IEEE%20Revista%20Iberoamericana%20de%20Tecnologias%20del%20Aprendizaje&amp;volume=8&amp;issue=3&amp;pages=143-151&amp;publication_year=2013&amp;author=Aguirre%2CIO&amp;author=Ruiz%2CMB&amp;author=Diaz%2CJSM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Aoki, CM. Oman, DA. Buckland, A. Natapoff, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Aoki H, Oman CM, Buckland DA, Natapoff A (2008) Desktop-vr system for preflight 3d navigation training. Acta A" /><p class="c-article-references__text" id="ref-CR1">Aoki H, Oman CM, Buckland DA, Natapoff A (2008) Desktop-vr system for preflight 3d navigation training. Acta Astronaut 63(7):841–847</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.actaastro.2007.11.001" aria-label="View reference 2">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Desktop-vr%20system%20for%20preflight%203d%20navigation%20training&amp;journal=Acta%20Astronaut&amp;volume=63&amp;issue=7&amp;pages=841-847&amp;publication_year=2008&amp;author=Aoki%2CH&amp;author=Oman%2CCM&amp;author=Buckland%2CDA&amp;author=Natapoff%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="KW. Arthur, KS. Booth, C. Ware, " /><meta itemprop="datePublished" content="1993" /><meta itemprop="headline" content="Arthur KW, Booth KS, Ware C (1993) Evaluating 3d task performance for fish tank virtual worlds. ACM Trans Inf " /><p class="c-article-references__text" id="ref-CR2">Arthur KW, Booth KS, Ware C (1993) Evaluating 3d task performance for fish tank virtual worlds. ACM Trans Inf Syst (TOIS) 11(3):239–265</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F159161.155359" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Evaluating%203d%20task%20performance%20for%20fish%20tank%20virtual%20worlds&amp;journal=ACM%20Trans%20Inf%20Syst%20%28TOIS%29&amp;volume=11&amp;issue=3&amp;pages=239-265&amp;publication_year=1993&amp;author=Arthur%2CKW&amp;author=Booth%2CKS&amp;author=Ware%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Assfalg, A. Bimbo, E. Vicario, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Assfalg J, Del Bimbo A, Vicario E (2002) Using 3d and ancillary media to train construction workers. IEEE Mult" /><p class="c-article-references__text" id="ref-CR3">Assfalg J, Del Bimbo A, Vicario E (2002) Using 3d and ancillary media to train construction workers. IEEE MultiMed 9(2):88–92</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F93.998075" aria-label="View reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Using%203d%20and%20ancillary%20media%20to%20train%20construction%20workers&amp;journal=IEEE%20MultiMed&amp;volume=9&amp;issue=2&amp;pages=88-92&amp;publication_year=2002&amp;author=Assfalg%2CJ&amp;author=Bimbo%2CA&amp;author=Vicario%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Baheti A, Seshadri S, Kumar A, Srimathveeravalli G, Kesavadas T, Guru K (2008) Ross: virtual reality robotic s" /><p class="c-article-references__text" id="ref-CR4">Baheti A, Seshadri S, Kumar A, Srimathveeravalli G, Kesavadas T, Guru K (2008) Ross: virtual reality robotic surgical simulator for the da vinci surgical system. In: IEEE haptics 2008 symposium on haptic interfaces for virtual environment and teleoperator systems, 2008, pp 479–480</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JT. Bell, HS. Fogler, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Bell JT, Fogler HS (1997) Ten steps to developing virtual reality applications for engineering education. Ann " /><p class="c-article-references__text" id="ref-CR5">Bell JT, Fogler HS (1997) Ten steps to developing virtual reality applications for engineering education. Ann Arbor 48:109–2136</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Ten%20steps%20to%20developing%20virtual%20reality%20applications%20for%20engineering%20education&amp;journal=Ann%20Arbor&amp;volume=48&amp;pages=109-2136&amp;publication_year=1997&amp;author=Bell%2CJT&amp;author=Fogler%2CHS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bertrand J, Brickler D, Babu S, Madathil K, Zelaya M, Wang T, Wagner J, Gramopadhye A, Luo J (2015) The role o" /><p class="c-article-references__text" id="ref-CR6">Bertrand J, Brickler D, Babu S, Madathil K, Zelaya M, Wang T, Wagner J, Gramopadhye A, Luo J (2015) The role of dimensional symmetry on bimanual psychomotor skills education in immersive virtual environments. In: IEEE virtual reality conference, (2015) VR’15. IEEE</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bloom BS, Englehart MD, Furst EJ,  Hill WH, Krathwohl DR (1956) Taxonomy of educational objectives: the classi" /><p class="c-article-references__text" id="ref-CR7">Bloom BS, Englehart MD, Furst EJ,  Hill WH, Krathwohl DR (1956) Taxonomy of educational objectives: the classification of educational goals, Handbook 1: The cognitive domain, Longman, New York</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Crooks TJ (1988) Assessing student performance, Green guide No. 8. Higher Education Research and Development S" /><p class="c-article-references__text" id="ref-CR8">Crooks TJ (1988) Assessing student performance, Green guide No. 8. Higher Education Research and Development Society of Australasia, Kensington, NSW, Australia</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="R. Dave, " /><meta itemprop="datePublished" content="1975" /><meta itemprop="headline" content="Dave R (1975) Developing and writing behavioural objectives. Educational Innovators Press, NY" /><p class="c-article-references__text" id="ref-CR9">Dave R (1975) Developing and writing behavioural objectives. Educational Innovators Press, NY</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Developing%20and%20writing%20behavioural%20objectives&amp;publication_year=1975&amp;author=Dave%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Demiralp C, Laidlaw DH, Jackson C, Keefe D, Zhang S (2003) Subjective usefulness of cave and fish tank vr disp" /><p class="c-article-references__text" id="ref-CR10">Demiralp C, Laidlaw DH, Jackson C, Keefe D, Zhang S (2003) Subjective usefulness of cave and fish tank vr display systems for a scientific visualization application. In: IEEE computer society proceedings of the 14th IEEE visualization 2003 (VIS’03), p 86</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ekstrom RB, French JW, Harman HH, Dermen D (1976) Kit of factor-referenced cognitive tests. Educational Testin" /><p class="c-article-references__text" id="ref-CR11">Ekstrom RB, French JW, Harman HH, Dermen D (1976) Kit of factor-referenced cognitive tests. Educational Testing Service, Princeton, NJ</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="El-Chaar J, Boer C, Pedrazzoli P, Mazzola S, Maso G (2011) Interactive 3d virtual environments for industrial " /><p class="c-article-references__text" id="ref-CR12">El-Chaar J, Boer C, Pedrazzoli P, Mazzola S, Maso G (2011) Interactive 3d virtual environments for industrial operation training and maintenance. In: 2011 9th International Conference on reliability, maintainability and safety (ICRMS). IEEE, pp 1376–1381</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="KA. Ericsson, N. Charness, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Ericsson KA, Charness N (1994) Expert performance: its structure and acquisition. Am Psychol 49(8):725" /><p class="c-article-references__text" id="ref-CR13">Ericsson KA, Charness N (1994) Expert performance: its structure and acquisition. Am Psychol 49(8):725</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2F0003-066X.49.8.725" aria-label="View reference 14">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Expert%20performance%3A%20its%20structure%20and%20acquisition&amp;journal=Am%20Psychol&amp;volume=49&amp;issue=8&amp;publication_year=1994&amp;author=Ericsson%2CKA&amp;author=Charness%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="N. Finkelstein, W. Adams, C. Keller, P. Kohl, K. Perkins, N. Podolefsky, S. Reid, R. LeMaster, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Finkelstein N, Adams W, Keller C, Kohl P, Perkins K, Podolefsky N, Reid S, LeMaster R (2005) When learning abo" /><p class="c-article-references__text" id="ref-CR14">Finkelstein N, Adams W, Keller C, Kohl P, Perkins K, Podolefsky N, Reid S, LeMaster R (2005) When learning about the real world is better done virtually: a study of substituting computer simulations for laboratory equipment. Phys Rev Spec Top Phys Educ Res 1(1):010,103</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1103%2FPhysRevSTPER.1.010103" aria-label="View reference 15">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=When%20learning%20about%20the%20real%20world%20is%20better%20done%20virtually%3A%20a%20study%20of%20substituting%20computer%20simulations%20for%20laboratory%20equipment&amp;journal=Phys%20Rev%20Spec%20Top%20Phys%20Educ%20Res&amp;volume=1&amp;issue=1&amp;publication_year=2005&amp;author=Finkelstein%2CN&amp;author=Adams%2CW&amp;author=Keller%2CC&amp;author=Kohl%2CP&amp;author=Perkins%2CK&amp;author=Podolefsky%2CN&amp;author=Reid%2CS&amp;author=LeMaster%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Green, S. Halliday, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Green M, Halliday S (1996) A geometric modeling and animation system for virtual reality. Commun ACM 39(5):46–" /><p class="c-article-references__text" id="ref-CR15">Green M, Halliday S (1996) A geometric modeling and animation system for virtual reality. Commun ACM 39(5):46–53</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F229459.229465" aria-label="View reference 16">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20geometric%20modeling%20and%20animation%20system%20for%20virtual%20reality&amp;journal=Commun%20ACM&amp;volume=39&amp;issue=5&amp;pages=46-53&amp;publication_year=1996&amp;author=Green%2CM&amp;author=Halliday%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Guilford, WS. Zimmerman, " /><meta itemprop="datePublished" content="1948" /><meta itemprop="headline" content="Guilford J, Zimmerman WS (1948) The guilford–zimmerman aptitude survey. J Appl Psychol 32(1):24" /><p class="c-article-references__text" id="ref-CR16">Guilford J, Zimmerman WS (1948) The guilford–zimmerman aptitude survey. J Appl Psychol 32(1):24</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2Fh0063610" aria-label="View reference 17">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20guilford%E2%80%93zimmerman%20aptitude%20survey&amp;journal=J%20Appl%20Psychol&amp;volume=32&amp;issue=1&amp;publication_year=1948&amp;author=Guilford%2CJ&amp;author=Zimmerman%2CWS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="InterSense (2015) InterSense—precision motion tracking solutions-IS-1200 VisTracker. http://www.intersense.com" /><p class="c-article-references__text" id="ref-CR17">InterSense (2015) InterSense—precision motion tracking solutions-IS-1200 VisTracker. <a href="http://www.intersense.com/pages/33/198/">http://www.intersense.com/pages/33/198/</a>, Accessed 28 May 2015</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Jou, J. Wang, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Jou M, Wang J (2013) Investigation of effects of virtual reality environments on learning performance of techn" /><p class="c-article-references__text" id="ref-CR18">Jou M, Wang J (2013) Investigation of effects of virtual reality environments on learning performance of technical skills. Comput Hum Behav 29(2):433–438</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.chb.2012.04.020" aria-label="View reference 19">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Investigation%20of%20effects%20of%20virtual%20reality%20environments%20on%20learning%20performance%20of%20technical%20skills&amp;journal=Comput%20Hum%20Behav&amp;volume=29&amp;issue=2&amp;pages=433-438&amp;publication_year=2013&amp;author=Jou%2CM&amp;author=Wang%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Kaufmann, D. Schmalstieg, M. Wagner, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Kaufmann H, Schmalstieg D, Wagner M (2000) Construct3d: a virtual reality application for mathematics and geom" /><p class="c-article-references__text" id="ref-CR19">Kaufmann H, Schmalstieg D, Wagner M (2000) Construct3d: a virtual reality application for mathematics and geometry education. Educ Inf Technol 5(4):263–276</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1023%2FA%3A1012049406877" aria-label="View reference 20">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Construct3d%3A%20a%20virtual%20reality%20application%20for%20mathematics%20and%20geometry%20education&amp;journal=Educ%20Inf%20Technol&amp;volume=5&amp;issue=4&amp;pages=263-276&amp;publication_year=2000&amp;author=Kaufmann%2CH&amp;author=Schmalstieg%2CD&amp;author=Wagner%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Kiyokawa, H. Takemura, Y. Katayama, H. Iwasa, N. Yokoya, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Kiyokawa K, Takemura H, Katayama Y, Iwasa H, Yokoya N (1998) Vlego: a simple two-handed 3d modeler in a virtua" /><p class="c-article-references__text" id="ref-CR20">Kiyokawa K, Takemura H, Katayama Y, Iwasa H, Yokoya N (1998) Vlego: a simple two-handed 3d modeler in a virtual environment. Electron Commun Jpn (Part III Fundam Electron Sci) 81(11):18–28</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2F%28SICI%291520-6440%28199811%2981%3A11%3C18%3A%3AAID-ECJC3%3E3.0.CO%3B2-N" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Vlego%3A%20a%20simple%20two-handed%203d%20modeler%20in%20a%20virtual%20environment&amp;journal=Electron%20Commun%20Jpn%20%28Part%20III%20Fundam%20Electron%20Sci%29&amp;volume=81&amp;issue=11&amp;pages=18-28&amp;publication_year=1998&amp;author=Kiyokawa%2CK&amp;author=Takemura%2CH&amp;author=Katayama%2CY&amp;author=Iwasa%2CH&amp;author=Yokoya%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kotranza A, Lind DS, Pugh CM, Lok B (2009) Real-time in-situ visual feedback of task performance in mixed envi" /><p class="c-article-references__text" id="ref-CR21">Kotranza A, Lind DS, Pugh CM, Lok B (2009) Real-time in-situ visual feedback of task performance in mixed environments for learning joint psychomotor-cognitive tasks. In: 8th IEEE International Symposium on mixed and augmented reality, 2009. ISMAR 2009. IEEE, pp 125–134</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lingsong H, Wei L (2011) A ria based virtual instrument platform for test and measurement education. In: 2011 " /><p class="c-article-references__text" id="ref-CR22">Lingsong H, Wei L (2011) A ria based virtual instrument platform for test and measurement education. In: 2011 IEEE Conference on open systems (ICOS). IEEE, pp 139–142</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Menendez LM, Salaverría A, Mandado E, Dacosta JG (2006) Virtual electronics laboratory: A new tool to improve " /><p class="c-article-references__text" id="ref-CR23">Menendez LM, Salaverría A, Mandado E, Dacosta JG (2006) Virtual electronics laboratory: A new tool to improve industrial electronics learning. In: IECON 2006-32nd Annual Conference on IEEE Industrial Electronics. IEEE, pp 5445–5448</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mizell DW, Jones SP, Slater M, Spanlang B (2002) Comparing immersive virtual reality with other display modes " /><p class="c-article-references__text" id="ref-CR24">Mizell DW, Jones SP, Slater M, Spanlang B (2002) Comparing immersive virtual reality with other display modes for visualizing complex 3d geometry. University College London, technical report</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mlyniec P, Jerald J, Yoganandan A, Seagull FJ, Toledo F, Schultheis U (2011) iMedic: a two-handed immersive me" /><p class="c-article-references__text" id="ref-CR25">Mlyniec P, Jerald J, Yoganandan A, Seagull FJ, Toledo F, Schultheis U (2011) iMedic: a two-handed immersive medical environment for distributed interactive consultation. In: Westwood JD et al (eds) Medicine Meets Virtual Reality NextMed, IOS Press, Netherland, pp 372–378. doi:<a href="https://doi.org/10.3233/978-1-60750-706-2-372">10.3233/978-1-60750-706-2-372</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Noble RA, Clapworthy GJ (1998) Sculpting and animating in a desktop vr environment. In: Proceedings on compute" /><p class="c-article-references__text" id="ref-CR26">Noble RA, Clapworthy GJ (1998) Sculpting and animating in a desktop vr environment. In: Proceedings on computer graphics international, 1998. IEEE, pp 187–195</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Parmar D, Bertrand J, Shannon B, Babu SV, Madathil K, Zelaya M, Wang T, Wagner J, Frady K, Gramopadhye AK (201" /><p class="c-article-references__text" id="ref-CR28">Parmar D, Bertrand J, Shannon B, Babu SV, Madathil K, Zelaya M, Wang T, Wagner J, Frady K, Gramopadhye AK (2014) Interactive breadboard activity simulation (ibas) for psychomotor skills education in electrical circuitry. In: 2014 IEEE Symposium on 3D user interfaces (3DUI). IEEE, pp 181–182</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pausch R, Proffitt D, Williams G (1997) Quantifying immersion in virtual reality. In: Proceedings of the 24th " /><p class="c-article-references__text" id="ref-CR29">Pausch R, Proffitt D, Williams G (1997) Quantifying immersion in virtual reality. In: Proceedings of the 24th annual conference on Computer graphics and interactive techniques. ACM Press/Addison-Wesley Publishing Co., pp 13–18</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Qi W, Taylor II RM, Healey CG, Martens JB (2006) A comparison of immersive hmd, fish tank vr and fish tank wit" /><p class="c-article-references__text" id="ref-CR30">Qi W, Taylor II RM, Healey CG, Martens JB (2006) A comparison of immersive hmd, fish tank vr and fish tank with haptics displays for volume visualization. In: Proceedings of the 3rd symposium on applied perception in graphics and visualization. ACM, pp 51–58</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="ED. Ragan, R. Kopper, P. Schuchardt, DA. Bowman, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Ragan ED, Kopper R, Schuchardt P, Bowman DA (2013) Studying the effects of stereo, head tracking, and field of" /><p class="c-article-references__text" id="ref-CR31">Ragan ED, Kopper R, Schuchardt P, Bowman DA (2013) Studying the effects of stereo, head tracking, and field of regard on a small-scale spatial judgment task. IEEE Trans Vis Comput Graph 19(5):886–896</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTVCG.2012.163" aria-label="View reference 31">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Studying%20the%20effects%20of%20stereo%2C%20head%20tracking%2C%20and%20field%20of%20regard%20on%20a%20small-scale%20spatial%20judgment%20task&amp;journal=IEEE%20Trans%20Vis%20Comput%20Graph&amp;volume=19&amp;issue=5&amp;pages=886-896&amp;publication_year=2013&amp;author=Ragan%2CED&amp;author=Kopper%2CR&amp;author=Schuchardt%2CP&amp;author=Bowman%2CDA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Razer (2015) Razer Hydra gaming controller. http://www.razerzone.com/gaming-controllers/razer-hydra-portal-2-b" /><p class="c-article-references__text" id="ref-CR32">Razer (2015) Razer Hydra gaming controller. <a href="http://www.razerzone.com/gaming-controllers/razer-hydra-portal-2-bundle">http://www.razerzone.com/gaming-controllers/razer-hydra-portal-2-bundle</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Richardson, M. Czerwinski, M. Van Dantzich, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Richardson JJ, Adamo-Villani N (2011) A virtual embedded microcontroller laboratory for undergraduate educatio" /><p class="c-article-references__text" id="ref-CR33">Richardson JJ, Adamo-Villani N (2011) A virtual embedded microcontroller laboratory for undergraduate education: Development and evaluation. Eng Des Graph J 74(3):1–12</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20virtual%20embedded%20microcontroller%20laboratory%20for%20undergraduate%20education%3A%20Development%20and%20evaluation&amp;journal=Eng%20Des%20Graph%20J&amp;volume=74&amp;issue=3&amp;pages=1-12&amp;publication_year=1997&amp;author=Richardson%2CG&amp;author=Czerwinski%2CM&amp;author=Van%C2%A0Dantzich%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Robertson G, Czerwinski M, Van Dantzich M (1997) Immersion in desktop virtual reality. In: Proceedings of the " /><p class="c-article-references__text" id="ref-CR34">Robertson G, Czerwinski M, Van Dantzich M (1997) Immersion in desktop virtual reality. In: Proceedings of the 10th annual ACM symposium on user interface software and technology. ACM, pp 11–19</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DA. Rosenbaum, RA. Carlson, RO. Gilmore, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Rosenbaum DA, Carlson RA, Gilmore RO (2001) Acquisition of intellectual and perceptual-motor skills. Annu Rev " /><p class="c-article-references__text" id="ref-CR35">Rosenbaum DA, Carlson RA, Gilmore RO (2001) Acquisition of intellectual and perceptual-motor skills. Annu Rev Psychol 52(1):453–470</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1146%2Fannurev.psych.52.1.453" aria-label="View reference 35">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Acquisition%20of%20intellectual%20and%20perceptual-motor%20skills&amp;journal=Annu%20Rev%20Psychol&amp;volume=52&amp;issue=1&amp;pages=453-470&amp;publication_year=2001&amp;author=Rosenbaum%2CDA&amp;author=Carlson%2CRA&amp;author=Gilmore%2CRO">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RA. Ruddle, SJ. Payne, DM. Jones, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Ruddle RA, Payne SJ, Jones DM (1999) Navigating large-scale virtual environments: what differences occur betwe" /><p class="c-article-references__text" id="ref-CR36">Ruddle RA, Payne SJ, Jones DM (1999) Navigating large-scale virtual environments: what differences occur between helmet-mounted and desk-top displays? Presence Teleoper Virtual Environ 8(2):157–168</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474699566143" aria-label="View reference 36">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 36 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Navigating%20large-scale%20virtual%20environments%3A%20what%20differences%20occur%20between%20helmet-mounted%20and%20desk-top%20displays%3F&amp;journal=Presence%20Teleoper%20Virtual%20Environ&amp;volume=8&amp;issue=2&amp;pages=157-168&amp;publication_year=1999&amp;author=Ruddle%2CRA&amp;author=Payne%2CSJ&amp;author=Jones%2CDM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="BS. Santos, P. Dias, A. Pimentel, JW. Baggerman, C. Ferreira, S. Silva, J. Madeira, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Santos BS, Dias P, Pimentel A, Baggerman JW, Ferreira C, Silva S, Madeira J (2009) Head-mounted display versus" /><p class="c-article-references__text" id="ref-CR37">Santos BS, Dias P, Pimentel A, Baggerman JW, Ferreira C, Silva S, Madeira J (2009) Head-mounted display versus desktop for 3d navigation in virtual reality: a user study. Multimed Tools Appl 41(1):161–181</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs11042-008-0223-2" aria-label="View reference 37">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Head-mounted%20display%20versus%20desktop%20for%203d%20navigation%20in%20virtual%20reality%3A%20a%20user%20study&amp;journal=Multimed%20Tools%20Appl&amp;volume=41&amp;issue=1&amp;pages=161-181&amp;publication_year=2009&amp;author=Santos%2CBS&amp;author=Dias%2CP&amp;author=Pimentel%2CA&amp;author=Baggerman%2CJW&amp;author=Ferreira%2CC&amp;author=Silva%2CS&amp;author=Madeira%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Schmitz B, Specht M, Klemke R (2012) An analysis of the educational potential of augmented reality games for l" /><p class="c-article-references__text" id="ref-CR38">Schmitz B, Specht M, Klemke R (2012) An analysis of the educational potential of augmented reality games for learning. In: Proceedings of the 11th World conference on mobile and contextual learning, International Association for Mobile Learning, pp 140–147</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Tawfik, E. Sancristobal, S. Martin, R. Gil, G. Diaz, A. Colmenar, J. Peire, M. Castro, K. Nilsson, J. Zackrisson, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Tawfik M, Sancristobal E, Martin S, Gil R, Diaz G, Colmenar A, Peire J, Castro M, Nilsson K, Zackrisson J et a" /><p class="c-article-references__text" id="ref-CR39">Tawfik M, Sancristobal E, Martin S, Gil R, Diaz G, Colmenar A, Peire J, Castro M, Nilsson K, Zackrisson J et al (2013) Virtual instrument systems in reality (visir) for remote wiring and measurement of electronic circuits on breadboard. IEEE Trans Learn Technol 6(1):60–72</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTLT.2012.20" aria-label="View reference 39">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20instrument%20systems%20in%20reality%20%28visir%29%20for%20remote%20wiring%20and%20measurement%20of%20electronic%20circuits%20on%20breadboard&amp;journal=IEEE%20Trans%20Learn%20Technol&amp;volume=6&amp;issue=1&amp;pages=60-72&amp;publication_year=2013&amp;author=Tawfik%2CM&amp;author=Sancristobal%2CE&amp;author=Martin%2CS&amp;author=Gil%2CR&amp;author=Diaz%2CG&amp;author=Colmenar%2CA&amp;author=Peire%2CJ&amp;author=Castro%2CM&amp;author=Nilsson%2CK&amp;author=Zackrisson%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Unity (2015) Unity-game engine. http://unity3d.com/&#xA;                        " /><p class="c-article-references__text" id="ref-CR40">Unity (2015) Unity-game engine. <a href="http://unity3d.com/">http://unity3d.com/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="BG. Witmer, MJ. Singer, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Witmer BG, Singer MJ (1998) Measuring presence in virtual environments: a presence questionnaire. Presence Tel" /><p class="c-article-references__text" id="ref-CR41">Witmer BG, Singer MJ (1998) Measuring presence in virtual environments: a presence questionnaire. Presence Teleoper Virtual Environ 7(3):225–240</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474698565686" aria-label="View reference 41">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 41 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Measuring%20presence%20in%20virtual%20environments%3A%20a%20presence%20questionnaire&amp;journal=Presence%20Teleoper%20Virtual%20Environ&amp;volume=7&amp;issue=3&amp;pages=225-240&amp;publication_year=1998&amp;author=Witmer%2CBG&amp;author=Singer%2CMJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="ZC. Zacharia, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Zacharia ZC (2007) Comparing and combining real and virtual experimentation: an effort to enhance students’ co" /><p class="c-article-references__text" id="ref-CR42">Zacharia ZC (2007) Comparing and combining real and virtual experimentation: an effort to enhance students’ conceptual understanding of electric circuits. J Comput Assist Learn 23(2):120–132</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fj.1365-2729.2006.00215.x" aria-label="View reference 42">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 42 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Comparing%20and%20combining%20real%20and%20virtual%20experimentation%3A%20an%20effort%20to%20enhance%20students%E2%80%99%20conceptual%20understanding%20of%20electric%20circuits&amp;journal=J%20Comput%20Assist%20Learn&amp;volume=23&amp;issue=2&amp;pages=120-132&amp;publication_year=2007&amp;author=Zacharia%2CZC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zanbaka C, Babu S, Xiao D, Ulinski A, Hodges L, Lok B (2004) Effects of travel technique on cognition in virtu" /><p class="c-article-references__text" id="ref-CR43">Zanbaka C, Babu S, Xiao D, Ulinski A, Hodges L, Lok B (2004) Effects of travel technique on cognition in virtual environments. In: IEEE proceedings on virtual reality, 2004. IEEE, pp 149–286</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="ZheMin C, Lingsong H (2009) The software breadboard technique of virtual instrument. In: 2009 WRI World Congre" /><p class="c-article-references__text" id="ref-CR44">ZheMin C, Lingsong H (2009) The software breadboard technique of virtual instrument. In: 2009 WRI World Congress on computer science and information engineering, vol 7. IEEE, pp 585–589</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-016-0287-7-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgments</h2><div class="c-article-section__content" id="Ack1-content"><p>This work was supported by the National Science Foundation under Grant No. DUE-1104181. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">School of Computing, 120 McAdams Hall, Clemson University, Clemson, SC, 29634, USA</p><p class="c-article-author-affiliation__authors-list">Dhaval Parmar, Jeffrey Bertrand &amp; Sabarish V. Babu</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Department of Industrial Engineering, 110 Freeman Hall, Clemson University, Clemson, SC, 29634, USA</p><p class="c-article-author-affiliation__authors-list">Kapil Madathil, Melissa Zelaya &amp; Kristin Frady</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Department of Mechanical Engineering, 212 Fluor Daniel, Clemson University, Clemson, SC, 29634, USA</p><p class="c-article-author-affiliation__authors-list">Tianwei Wang &amp; John Wagner</p></li><li id="Aff4"><p class="c-article-author-affiliation__address">College of Engineering and Science, 109 Riggs Hall, Clemson University, Clemson, SC, 29634, USA</p><p class="c-article-author-affiliation__authors-list">Anand K. Gramopadhye</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Dhaval-Parmar"><span class="c-article-authors-search__title u-h3 js-search-name">Dhaval Parmar</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Dhaval+Parmar&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Dhaval+Parmar" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Dhaval+Parmar%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Jeffrey-Bertrand"><span class="c-article-authors-search__title u-h3 js-search-name">Jeffrey Bertrand</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Jeffrey+Bertrand&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jeffrey+Bertrand" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jeffrey+Bertrand%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Sabarish_V_-Babu"><span class="c-article-authors-search__title u-h3 js-search-name">Sabarish V. Babu</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Sabarish V.+Babu&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Sabarish V.+Babu" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Sabarish V.+Babu%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Kapil-Madathil"><span class="c-article-authors-search__title u-h3 js-search-name">Kapil Madathil</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Kapil+Madathil&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Kapil+Madathil" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Kapil+Madathil%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Melissa-Zelaya"><span class="c-article-authors-search__title u-h3 js-search-name">Melissa Zelaya</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Melissa+Zelaya&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Melissa+Zelaya" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Melissa+Zelaya%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Tianwei-Wang"><span class="c-article-authors-search__title u-h3 js-search-name">Tianwei Wang</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Tianwei+Wang&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Tianwei+Wang" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Tianwei+Wang%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-John-Wagner"><span class="c-article-authors-search__title u-h3 js-search-name">John Wagner</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;John+Wagner&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=John+Wagner" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22John+Wagner%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Anand_K_-Gramopadhye"><span class="c-article-authors-search__title u-h3 js-search-name">Anand K. Gramopadhye</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Anand K.+Gramopadhye&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Anand K.+Gramopadhye" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Anand K.+Gramopadhye%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Kristin-Frady"><span class="c-article-authors-search__title u-h3 js-search-name">Kristin Frady</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Kristin+Frady&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Kristin+Frady" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Kristin+Frady%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-016-0287-7/email/correspondent/c1/new">Dhaval Parmar</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=A%20comparative%20evaluation%20of%20viewing%20metaphors%20on%20psychophysical%20skills%20education%20in%20an%20interactive%20virtual%20environment&amp;author=Dhaval%20Parmar%20et%20al&amp;contentID=10.1007%2Fs10055-016-0287-7&amp;publication=1359-4338&amp;publicationDate=2016-05-14&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-016-0287-7" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-016-0287-7" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Parmar, D., Bertrand, J., Babu, S.V. <i>et al.</i> A comparative evaluation of viewing metaphors on psychophysical skills education in an interactive virtual environment.
                    <i>Virtual Reality</i> <b>20, </b>141–157 (2016). https://doi.org/10.1007/s10055-016-0287-7</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-016-0287-7.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2014-11-25">25 November 2014</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-04-28">28 April 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-05-14">14 May 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-09">September 2016</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-016-0287-7" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-016-0287-7</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">HMD</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Human factors</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Education</span></li><li class="c-article-subject-list__subject"><span itemprop="about">3D human–computer interaction</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-016-0287-7.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=287;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

