<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="The effect of a virtual reality learning environment on learners&#8217"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="This study employed electroencephalography to record event-related potentials to investigate the difference in learning performance between learners with different levels of spatial ability in a..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/23/4.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="The effect of a virtual reality learning environment on learners&#8217; spatial ability"/>

    <meta name="dc.source" content="Virtual Reality 2018 23:4"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2018-07-03"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2018 Springer-Verlag London Ltd., part of Springer Nature"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="This study employed electroencephalography to record event-related potentials to investigate the difference in learning performance between learners with different levels of spatial ability in a traditional learning environment that utilizes presentation slides and a learning environment that incorporates virtual reality (VR). Thirty-two university students participated in the experiment. The N1 and P2 components were results that indicated selective attention at an early stage; their amplitudes were proportional to the cognitive loads. The experiment results revealed that the main effect of learning environment was significant. The N1 and P2 components had larger amplitudes and indicated higher cognitive loads in the presentation slides-based environment than in the VR-based environment. The main effect of spatial ability was also significant. The N1 and P2 amplitudes evoked in the high spatial ability (HSA) learners were smaller than those evoked in the low spatial ability (LSA) learners, indicating that the LSA learners possessed fewer cognitive resources and bore relatively high cognitive loads. The interaction effect of learning environment and spatial ability was significant. Larger P2 amplitude was observed in LSA learners in the presentation slides-based environment than in the VR-based environment, implying that VR facilitates the reduction of cognitive loads in LSA learners. The P2 amplitude detected in HSA learners did not show any significant difference in both learning environments, indicating that the VR-based learning environment did not enhance their learning. This result supports the ability-as-compensator hypothesis to a certain extent."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2018-07-03"/>

    <meta name="prism.volume" content="23"/>

    <meta name="prism.number" content="4"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="385"/>

    <meta name="prism.endingPage" content="398"/>

    <meta name="prism.copyright" content="2018 Springer-Verlag London Ltd., part of Springer Nature"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-018-0355-2"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-018-0355-2"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-018-0355-2.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-018-0355-2"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="The effect of a virtual reality learning environment on learners&#8217; spatial ability"/>

    <meta name="citation_volume" content="23"/>

    <meta name="citation_issue" content="4"/>

    <meta name="citation_publication_date" content="2019/12"/>

    <meta name="citation_online_date" content="2018/07/03"/>

    <meta name="citation_firstpage" content="385"/>

    <meta name="citation_lastpage" content="398"/>

    <meta name="citation_article_type" content="S.I. : VR in Education"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-018-0355-2"/>

    <meta name="DOI" content="10.1007/s10055-018-0355-2"/>

    <meta name="citation_doi" content="10.1007/s10055-018-0355-2"/>

    <meta name="description" content="This study employed electroencephalography to record event-related potentials to investigate the difference in learning performance between learners with d"/>

    <meta name="dc.creator" content="Rui Sun"/>

    <meta name="dc.creator" content="Yenchun Jim Wu"/>

    <meta name="dc.creator" content="Qian Cai"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Hum Behav; citation_title=A pedagogical model to develop teaching skills. The collaborative learning experience in the immersive virtual world TYMMI; citation_author=MG Badilla, S Meza; citation_volume=51; citation_publication_date=2015; citation_pages=594-603; citation_doi=10.1016/j.chb.2015.03.016; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE; citation_title=The application of virtual reality to (chemical engineering) education; citation_author=JT Bell, HS Fogler; citation_volume=2004; citation_publication_date=2004; citation_pages=27-31; citation_doi=10.1109/VR.2004.1310077; citation_id=CR2"/>

    <meta name="citation_reference" content="citation_journal_title=Learn Instr; citation_title=Static and animated presentations in learning dynamic mechanical systems; citation_author=J-M Boucheix, E Schneider; citation_volume=19; citation_publication_date=2009; citation_pages=112-117; citation_doi=10.1016/j.learninstruc.2008.03.004; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Siggraph Comput Graph; citation_title=Virtual reality learning environments: potentials and challenges; citation_author=M Bricken; citation_volume=25; citation_publication_date=1991; citation_pages=178-184; citation_doi=10.1145/126640.126657; citation_id=CR4"/>

    <meta name="citation_reference" content="citation_journal_title=Educ Psychol; citation_title=Direct measurement of cognitive load in multimedia learning; citation_author=R Brunken, JL Plass, D Leutner; citation_volume=38; citation_publication_date=2003; citation_pages=53-61; citation_doi=10.1207/S15326985EP3801_7; citation_id=CR5"/>

    <meta name="citation_reference" content="citation_journal_title=e-J Instr Sci Technol; citation_title=Are spatial visualization abilities relevant to virtual reality?; citation_author=CJ Chen; citation_volume=9; citation_publication_date=2006; citation_pages=1-16; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_journal_title=Psychol Dev Educ; citation_title=The effect of representational model of information and personality traits of learners on the learning in multimedia environment; citation_author=K Cheng, A Zhou; citation_volume=25; citation_publication_date=2009; citation_pages=83-91; citation_id=CR7"/>

    <meta name="citation_reference" content="citation_journal_title=Interact Learn Environ; citation_title=Exploring the effect of learning styles on learning achievement in a u-Museum; citation_author=CC Chia, YC Chien; citation_volume=7; citation_publication_date=2017; citation_pages=1-18; citation_doi=10.1080/10494820.2017.385488; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Semant Web Inf; citation_title=Ontology-driven interactive visualization of film production complexity using a visual language; citation_author=Y Christodoulou, A Yannopoulos, EJ Bountris, T Varvarigou; citation_volume=12; citation_publication_date=2016; citation_pages=100-122; citation_doi=10.4018/IJSWIS.2016040105; citation_id=CR9"/>

    <meta name="citation_reference" content="citation_journal_title=Mod Distance Educ Res; citation_title=From neo-behaviorisim to neuroscience: perspectives on the origins and future contribution of cognitive load research; citation_author=RE Clark, VP Clark, M Jiang; citation_volume=3; citation_publication_date=2014; citation_pages=52-65; citation_doi=10.1017/CBO9780511844744.012; citation_id=CR10"/>

    <meta name="citation_reference" content="citation_journal_title=J Neural Transm; citation_title=The development of the N1 and N2 components in auditory oddball paradigms: a systematic review with narrative analysis and suggested normative values; citation_author=T David, B Fernando, N Kamila; citation_volume=122; citation_publication_date=2014; citation_pages=375; citation_doi=10.1007/s00702-01401258-3; citation_id=CR11"/>

    <meta name="citation_reference" content="citation_journal_title=Percept Motor Skills; citation_title=About spatial intelligence: I; citation_author=J Eliot; citation_volume=94; citation_publication_date=2002; citation_pages=479; citation_doi=10.2466/PMS.94.2.479-486; citation_id=CR12"/>

    <meta name="citation_reference" content="citation_journal_title=Neuropsychologia; citation_title=Temporal dynamic of neural mechanism involved in empathy for pain: an event-related brain potential study; citation_author=Y Fan, SH Han; citation_volume=46; citation_issue=1; citation_publication_date=2008; citation_pages=160-173; citation_doi=10.1016/j.neuropsychologia.2007.07.023; citation_id=CR13"/>

    <meta name="citation_reference" content="citation_journal_title=Presence; citation_title=Effects of sensory information and prior experience on direct subjective ratings of presence; citation_author=J Freeman, SE Avons, DE Pearson, W IJsselsteijn; citation_volume=8; citation_issue=1; citation_publication_date=1999; citation_pages=1-13; citation_doi=10.1162/105474699566017; citation_id=CR01"/>

    <meta name="citation_reference" content="citation_journal_title=Psychophysiology; citation_title=Target-to-target interval, intensity, and P300 from an auditory single-stimulus task; citation_author=CJ Gonsalvez, RJ Barry, JA Rushby, J Polich; citation_volume=44; citation_publication_date=2007; citation_pages=245-250; citation_doi=10.1111/j.1469-8986.2007.00495.x; citation_id=CR14"/>

    <meta name="citation_reference" content="Goteborg (2015) The benefits of virtual reality in education: a comparison study. Dissertation, University of Gothenburg"/>

    <meta name="citation_reference" content="citation_journal_title=Clin Neurophysiol; citation_title=Gamma band activity in an auditory oddball paradigm studied with the wavelet transform; citation_author=IG Gurtubay, M Alegre, A Labarga, A Malanda, J Iriarte, J Artieda; citation_volume=112; citation_publication_date=2001; citation_pages=1219-1228; citation_doi=10.1016/s1388-2457(01)00557-0; citation_id=CR16"/>

    <meta name="citation_reference" content="citation_title=Virtual reality and passive simulators: the future of fun; citation_inbook_title=Communication in the age of virtual reality; citation_publication_date=1995; citation_pages=159-189; citation_id=CR17; citation_author=DG Hawkins; citation_publisher=Lawrence Erlbaum"/>

    <meta name="citation_reference" content="citation_title=Effects of knowledge and spatial ability on learning from animation; citation_inbook_title=Learning with animation: research implications for design; citation_publication_date=2008; citation_pages=3-29; citation_id=CR18; citation_author=M Hegarty; citation_author=S Kriz; citation_publisher=Cambridge University Press"/>

    <meta name="citation_reference" content="Heiling M (1962) Sensorama simulator. Retrieved from 
                    http://www.mortonheilig.com/
                    
                  . Accessed 9 Oct 2017"/>

    <meta name="citation_reference" content="citation_journal_title=Educ Psychol Rev; citation_title=Spatial ability: its influence on learning with visualization&#8212;a meta-analytic review; citation_author=TN H&#246;ffler; citation_volume=22; citation_publication_date=2010; citation_pages=245-269; citation_doi=10.1007/s10648-010-9126-7; citation_id=CR20"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Hum Behav; citation_title=The role of spatial ability in learning from instructional animations-Evidence for an ability-as-compensator hypothesis; citation_author=TN H&#246;ffler, D Leutner; citation_volume=27; citation_issue=1; citation_publication_date=2011; citation_pages=209-216; citation_doi=10.1016/j.chb.2010.07.042; citation_id=CR21"/>

    <meta name="citation_reference" content="citation_journal_title=Neuropsychologia; citation_title=Assessment of mental workload: a new electrophysiological method based on intra-block averaging of ERP amplitudes; citation_author=SK Horat, FR Herrmann, G Favre, J Terzis; citation_volume=82; citation_publication_date=2015; citation_pages=11-17; citation_doi=10.1016/j.neuropsychologia.2015.12.013; citation_id=CR22"/>

    <meta name="citation_reference" content="citation_journal_title=Educ Psychol; citation_title=The expertise reversal effect; citation_author=S Kalyuga, P Ayres, P Chandler, J Sweller; citation_volume=38; citation_publication_date=2003; citation_pages=23-31; citation_doi=10.1207/S15326985EP3801_4; citation_id=CR23"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=&#8220;Making it real&#8221;: exploring the potential of augmented reality for teaching primary school science; citation_author=L Kerawalla, R Luckin, S Seljeflot, A Woolard; citation_volume=10; citation_issue=3; citation_publication_date=2006; citation_pages=163-174; citation_doi=10.1007/s10055-006-0036-4; citation_id=CR24"/>

    <meta name="citation_reference" content="citation_journal_title=Percept Psychophys; citation_title=Perceptual load as a major determinant of the locus of selection in visual attention; citation_author=N Lavie, Y Tsal; citation_volume=56; citation_publication_date=1994; citation_pages=183-197; citation_doi=10.3758/BF03213897; citation_id=CR25"/>

    <meta name="citation_reference" content="citation_journal_title=J Exp Psychol Gen; citation_title=Load theory of selective attention and cognitive control; citation_author=N Lavie, A Hirst, JW de Focket, E Viding; citation_volume=133; citation_issue=3; citation_publication_date=2004; citation_pages=339-354; citation_doi=10.1037/0096-3445.133.3.339; citation_id=CR04"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Educ; citation_title=Learning with desktop virtual reality: low spatial learners are more positively affected; citation_author=EAL Lee, KW Wong; citation_volume=79; citation_publication_date=2014; citation_pages=49-58; citation_doi=10.1016/j.compedu.2014.07.010; citation_id=CR26"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Educ; citation_title=How does desktop virtual reality enhance learning outcomes? A structural equation modeling approach; citation_author=EAL Lee, KW Wong, CC Fung; citation_volume=55; citation_issue=4; citation_publication_date=2010; citation_pages=1424-1442; citation_doi=10.1016/j.compedu.2010.06.006; citation_id=CR27"/>

    <meta name="citation_reference" content="citation_journal_title=Educ Psychol Meas; citation_title=Attempted validation of the scores of the VARK: learning styles inventory with multitrait multimethod confirmatory factor analysis models; citation_author=WL Leite, M Svinicki, Y Shi; citation_volume=70; citation_issue=2; citation_publication_date=2010; citation_pages=323-339; citation_doi=10.1177/0013164409344507; citation_id=CR28"/>

    <meta name="citation_reference" content="Li W (2014) The influence of animating presentation format and spatial ability on multimedia. Dissertation, School of Educational Information Technology, Central China Normal University"/>

    <meta name="citation_reference" content="citation_journal_title=Educ Technol Soc; citation_title=Outdoor natural science learning with an RFID-supported immersive ubiquitous learning environment; citation_author=T-Y Liu, T-H Tan, Y-L Chu; citation_volume=12; citation_issue=4; citation_publication_date=2009; citation_pages=161-175; citation_id=CR30"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Semant Web Inf; citation_title=Big data and data analytics research: from metaphors to value space for collective wisdom in human decision making and smart machines; citation_author=MD Lytras, V Raghavan, E Damiani; citation_volume=13; citation_issue=1; citation_publication_date=2017; citation_pages=1-10; citation_doi=10.4018/IJSWIS.2017010101; citation_id=CR32"/>

    <meta name="citation_reference" content="citation_title=Pain perception; citation_publication_date=2001; citation_id=CR33; citation_author=RE Mayer; citation_publisher=Cambridge University Press"/>

    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=Pain perception in the self and observation of others: an ERP investigation; citation_author=J Meng, T Jackson, H Chen, L Hu, Z Yang, YH Su, XT Huang; citation_volume=72; citation_publication_date=2013; citation_pages=164-173; citation_doi=10.1016/j.enuroimage.2013.01.024; citation_id=CR34"/>

    <meta name="citation_reference" content="citation_journal_title=J Comput Assist Learn; citation_title=Exploring 3-D virtual reality technology for spatial ability and chemistry achievement; citation_author=Z Merchant, ET Goetz, W Keeny-Kennicutt, L Cifuentes, OK Wok, TJ Davis; citation_volume=29; citation_issue=6; citation_publication_date=2013; citation_pages=579-590; citation_doi=10.1111/jcal.12018; citation_id=CR35"/>

    <meta name="citation_reference" content="citation_journal_title=Psychophysiology; citation_title=Auditory processing that leads to conscious perception: a unique window to central auditory processing opened by the mismatch negativity and related responses; citation_author=R N&#228;&#228;t&#228;nen, T Kujala, I Winkler; citation_volume=48; citation_publication_date=2011; citation_pages=4-22; citation_doi=10.1111/j.1469-8986; citation_id=CR36"/>

    <meta name="citation_reference" content="citation_journal_title=Psychol Rev; citation_title=Telling more than we can know: verbal reports on mental process; citation_author=RE Nisbett, TD Wilson; citation_volume=84; citation_publication_date=1977; citation_pages=231-259; citation_doi=10.1037/0033-295X.84.3.231; citation_id=CR37"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph; citation_title=Virtual reality and mixed reality for virtual learning environments; citation_author=Z Pan, AD Cheok, H Yang, J Zhu, J Shi; citation_volume=30; citation_publication_date=2006; citation_pages=20-28; citation_doi=10.1016/j.cag.2005.10.004; citation_id=CR38"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Hum Behav; citation_title=Cognitive load in reading a foreign language text with multimedia aids and the influence of verbal and spatial abilities; citation_author=JL Plass, DM Chun, RE Mayer, D Leuther; citation_volume=19; citation_publication_date=2003; citation_pages=221-243; citation_doi=10.1016/S0747-5632(02)00015-8; citation_id=CR39"/>

    <meta name="citation_reference" content="citation_journal_title=J Educ Psychol; citation_title=Using computer animated graphics in science instructions with children; citation_author=L Rieber; citation_volume=82; citation_publication_date=1990; citation_pages=135-140; citation_doi=10.1037/0022-0663.82.1.135; citation_id=CR40"/>

    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Averaged evoked responses in vigilance and discrimination: a reassessment; citation_author=W Ritter, HG Vaughan; citation_volume=164; citation_publication_date=1969; citation_pages=326-328; citation_doi=10.1126/science.164.3877.326; citation_id=CR41"/>

    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=The costs of monitoring simultaneously two sensory modalities decrease when dividing attention in space; citation_author=V Santangelo, S Fagioli, E Macaluso; citation_volume=49; citation_publication_date=2010; citation_pages=2717-2727; citation_doi=10.1016/j.neuroimage.2009.10.061; citation_id=CR42"/>

    <meta name="citation_reference" content="citation_journal_title=J Biol Educ; citation_title=Application of virtual reality technology in biology education; citation_author=KC Shim; citation_volume=37; citation_publication_date=2003; citation_pages=71-74; citation_doi=10.1080/00219266.2003.9655854; citation_id=CR43"/>

    <meta name="citation_reference" content="citation_title=So each may learn: integrating learning styles and multiple intelligences; citation_publication_date=2000; citation_id=CR03; citation_author=HF Silver; citation_author=RW Strong; citation_author=MJ Perini; citation_publisher=ASCD"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Semant Web Inf Syst; citation_title=BCWB: a P300 brain-controlled web browser; citation_author=G Sofien, A Nourah, M Hassan, A Hatim, B Kais; citation_volume=13; citation_publication_date=2017; citation_pages=55-73; citation_doi=10.4018/IJSWIS.2017040104; citation_id=CR44"/>

    <meta name="citation_reference" content="citation_journal_title=Spat Cogn Comput; citation_title=Learning routes from visualizations for indoor wayfinding: presentation modes and individual differences; citation_author=C Stahl; citation_volume=11; citation_publication_date=2011; citation_pages=281-312; citation_doi=10.1080/13875868.2011.571326; citation_id=CR45"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Psychophysiol; citation_title=P300 and slow wave from oddball and single-stimulus visual tasks: inter-stimulus interval effects; citation_author=D Struber, J Polich; citation_volume=45; citation_publication_date=2002; citation_pages=187-196; citation_doi=10.1016/S0167-8760(02)00071-5; citation_id=CR46"/>

    <meta name="citation_reference" content="citation_title=Primary mental abilities; citation_publication_date=1938; citation_id=CR47; citation_author=LL Thurstone; citation_publisher=University of Chicago Press"/>

    <meta name="citation_reference" content="citation_journal_title=Percept Mot Skills; citation_title=Mental rotations, a group test of three-dimensional spatial visualization; citation_author=SG Vandenberg, AR Kuse; citation_volume=47; citation_publication_date=1978; citation_pages=599-604; citation_doi=10.2466/pms.1978.47.2.599; citation_id=CR02"/>

    <meta name="citation_reference" content="citation_title=Principle and technique of event-related brain potentials; citation_publication_date=2010; citation_id=CR48; citation_author=JH Wei; citation_author=YJ Luo; citation_publisher=Science Press"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Psychophysiol; citation_title=Olfactory, auditory, and visual ERPs from single trials: no evidence for habituation; citation_author=S Wetter, J Polich, L Vanasse, E Donchin; citation_volume=54; citation_publication_date=2004; citation_pages=263-272; citation_doi=10.1016/j.ijpsycho.2004.04.008; citation_id=CR49"/>

    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Performance of concurrent tasks: a psychophysiological analysis of the reciprocity of information-processing resources; citation_author=C Wickens, A Kramer, L Vanasse, E Donchin; citation_volume=221; citation_publication_date=1983; citation_pages=1080-1082; citation_doi=10.1126/science.6879207; citation_id=CR50"/>

    <meta name="citation_reference" content="Xie YJ (2014) The effects of spatial ability animation types on multimedia learning. Dissertation, Central China Normal University"/>

    <meta name="citation_reference" content="citation_journal_title=Acta Psychol Sin; citation_title=Negative emotion interferes with behavioral inhibitory control: an ERP study; citation_author=Y Xin, H Li, JJ Yuan; citation_volume=42; citation_publication_date=2010; citation_pages=334-341; citation_doi=10.3724/SPJ.1041.2010.00334; citation_id=CR52"/>

    <meta name="citation_reference" content="citation_journal_title=Sci China Life Sci; citation_title=The application of the two-choice oddball paradigm to the research of behavioral inhibitory control; citation_author=JJ Yuan, MM Xu, JM Yang; citation_volume=47; citation_publication_date=2017; citation_pages=1065-1073; citation_doi=10.1360/N052017-00125; citation_id=CR53"/>

    <meta name="citation_author" content="Rui Sun"/>

    <meta name="citation_author_email" content="24891328@qq.com"/>

    <meta name="citation_author_institution" content="College of Business Administration, Huaqiao University, Quanzhou, China"/>

    <meta name="citation_author_institution" content="East Business Management Research Center, Huaqiao University, Quanzhou, China"/>

    <meta name="citation_author" content="Yenchun Jim Wu"/>

    <meta name="citation_author_email" content="wuyenchun@gmail.com"/>

    <meta name="citation_author_institution" content="National Taiwan Normal University, Taipei, Taiwan"/>

    <meta name="citation_author" content="Qian Cai"/>

    <meta name="citation_author_email" content="964388634@qq.com"/>

    <meta name="citation_author_institution" content="College of Business Administration, Huaqiao University, Quanzhou, China"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-018-0355-2&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2019/12/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-018-0355-2"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="The effect of a virtual reality learning environment on learners’ spatial ability"/>
        <meta property="og:description" content="This study employed electroencephalography to record event-related potentials to investigate the difference in learning performance between learners with different levels of spatial ability in a traditional learning environment that utilizes presentation slides and a learning environment that incorporates virtual reality (VR). Thirty-two university students participated in the experiment. The N1 and P2 components were results that indicated selective attention at an early stage; their amplitudes were proportional to the cognitive loads. The experiment results revealed that the main effect of learning environment was significant. The N1 and P2 components had larger amplitudes and indicated higher cognitive loads in the presentation slides-based environment than in the VR-based environment. The main effect of spatial ability was also significant. The N1 and P2 amplitudes evoked in the high spatial ability (HSA) learners were smaller than those evoked in the low spatial ability (LSA) learners, indicating that the LSA learners possessed fewer cognitive resources and bore relatively high cognitive loads. The interaction effect of learning environment and spatial ability was significant. Larger P2 amplitude was observed in LSA learners in the presentation slides-based environment than in the VR-based environment, implying that VR facilitates the reduction of cognitive loads in LSA learners. The P2 amplitude detected in HSA learners did not show any significant difference in both learning environments, indicating that the VR-based learning environment did not enhance their learning. This result supports the ability-as-compensator hypothesis to a certain extent."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>The effect of a virtual reality learning environment on learners’ spatial ability | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-018-0355-2","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Virtual reality (VR), Event-related potential (ERP), Spatial ability, Cognitive load, Education","kwrd":["Virtual_reality_(VR)","Event-related_potential_(ERP)","Spatial_ability","Cognitive_load","Education"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-018-0355-2","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-018-0355-2","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-b0018c9f69.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-c02f1b37f0.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=355;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-018-0355-2">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            The effect of a virtual reality learning environment on learners’ spatial ability
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-018-0355-2.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-018-0355-2.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">S.I. : VR in Education</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2018-07-03" itemprop="datePublished">03 July 2018</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">The effect of a virtual reality learning environment on learners’ spatial ability</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Rui-Sun" data-author-popup="auth-Rui-Sun">Rui Sun</a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Huaqiao University" /><meta itemprop="address" content="grid.411404.4, 0000 0000 8895 903X, College of Business Administration, Huaqiao University, Quanzhou, China" /></span><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Huaqiao University" /><meta itemprop="address" content="grid.411404.4, 0000 0000 8895 903X, East Business Management Research Center, Huaqiao University, Quanzhou, China" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Yenchun_Jim-Wu" data-author-popup="auth-Yenchun_Jim-Wu" data-corresp-id="c1">Yenchun Jim Wu<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><span class="u-js-hide"> 
            <a class="js-orcid" itemprop="url" href="http://orcid.org/0000-0001-5479-2873"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0001-5479-2873</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="National Taiwan Normal University" /><meta itemprop="address" content="grid.412090.e, 0000 0001 2158 7670, National Taiwan Normal University, Taipei, Taiwan" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Qian-Cai" data-author-popup="auth-Qian-Cai">Qian Cai</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Huaqiao University" /><meta itemprop="address" content="grid.411404.4, 0000 0000 8895 903X, College of Business Administration, Huaqiao University, Quanzhou, China" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 23</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">385</span>–<span itemprop="pageEnd">398</span>(<span data-test="article-publication-year">2019</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">1383 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">3 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-018-0355-2/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>This study employed electroencephalography to record event-related potentials to investigate the difference in learning performance between learners with different levels of spatial ability in a traditional learning environment that utilizes presentation slides and a learning environment that incorporates virtual reality (VR). Thirty-two university students participated in the experiment. The N1 and P2 components were results that indicated selective attention at an early stage; their amplitudes were proportional to the cognitive loads. The experiment results revealed that the main effect of learning environment was significant. The N1 and P2 components had larger amplitudes and indicated higher cognitive loads in the presentation slides-based environment than in the VR-based environment. The main effect of spatial ability was also significant. The N1 and P2 amplitudes evoked in the high spatial ability (HSA) learners were smaller than those evoked in the low spatial ability (LSA) learners, indicating that the LSA learners possessed fewer cognitive resources and bore relatively high cognitive loads. The interaction effect of learning environment and spatial ability was significant. Larger P2 amplitude was observed in LSA learners in the presentation slides-based environment than in the VR-based environment, implying that VR facilitates the reduction of cognitive loads in LSA learners. The P2 amplitude detected in HSA learners did not show any significant difference in both learning environments, indicating that the VR-based learning environment did not enhance their learning. This result supports the ability-as-compensator hypothesis to a certain extent.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>The advancement of scientific technology not only brings convenience to daily life but also enables novel applications in education. A new type of educational environment created using virtual reality (VR) technology offers various advantages unavailable in traditional education. For example, VR enables simulation of technical operations and specific scenarios, enhancing the quality of learning and reducing the risks involved in learning. Additionally, it can provide individualized learning environments, facilitate students’ proactive learning, and integrate learning with entertainment.</p><p>VR can simulate a three-dimensional (3D) virtual teaching environment, enabling learners to comprehensively acquire knowledge through the senses of hearing, sight, and touch; VR creates an immersive learning experience. Therefore, spatial ability plays a crucial role in VR education. The effectiveness of using VR for learning differs in learners with dissimilar spatial ability levels. The ability-as-compensator hypothesis in dynamic visualization studies based on cognitive load theory contends that a VR-based learning environment provides a complete representation of external processes or procedures for LSA learners, reducing the cognitive load imposed on them when they formulate mental representation models and thereby allowing them to obtain more learning gains (Hegarty and Kriz <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Hegarty M, Kriz S (2008) Effects of knowledge and spatial ability on learning from animation. In: Lowe R, Schnotz W (eds) Learning with animation: research implications for design. Cambridge University Press, Cambridge, pp 3–29" href="/article/10.1007/s10055-018-0355-2#ref-CR18" id="ref-link-section-d31932e472">2008</a>; Lee and Wong <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Lee EAL, Wong KW (2014) Learning with desktop virtual reality: low spatial learners are more positively affected. Comput Educ 79:49–58. &#xA;                    https://doi.org/10.1016/j.compedu.2014.07.010&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR26" id="ref-link-section-d31932e475">2014</a>; Mayer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Mayer RE (2001) Pain perception. Cambridge University Press, Cambridge" href="/article/10.1007/s10055-018-0355-2#ref-CR33" id="ref-link-section-d31932e478">2001</a>). The hypothesis of ability enhancement maintains that the multichannel learning provided by VR imposes additional cognitive load on LSA learners. By comparison, HSA learners can use VR to strengthen their learning performance because of their strong spatial representation ability and thus increase learning gains (Kalyuga et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Kalyuga S, Ayres P, Chandler P, Sweller J (2003) The expertise reversal effect. Educ Psychol 38:23–31. &#xA;                    https://doi.org/10.1207/S15326985EP3801_4&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR23" id="ref-link-section-d31932e481">2003</a>; Plass et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Plass JL, Chun DM, Mayer RE, Leuther D (2003) Cognitive load in reading a foreign language text with multimedia aids and the influence of verbal and spatial abilities. Comput Hum Behav 19:221–243. &#xA;                    https://doi.org/10.1016/S0747-5632(02)00015-8&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR39" id="ref-link-section-d31932e484">2003</a>; Xie <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Xie YJ (2014) The effects of spatial ability animation types on multimedia learning. Dissertation, Central China Normal University" href="/article/10.1007/s10055-018-0355-2#ref-CR51" id="ref-link-section-d31932e488">2014</a>). Various hypotheses related to VR-based learning have been proposed, but they are only validated by empirical studies (Li <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Li W (2014) The influence of animating presentation format and spatial ability on multimedia. Dissertation, School of Educational Information Technology, Central China Normal University" href="/article/10.1007/s10055-018-0355-2#ref-CR29" id="ref-link-section-d31932e491">2014</a>); therefore, the relationship between spatial ability and learning performance in VR education and the mechanism by which spatial ability influences learning performance under various learning methods presently remain unknown.</p><p>By using the cognitive load theory as the research framework, this study adopted electroencephalography (EEG), a relatively objective physiological measuring method, to explore the influence of various spatial ability levels on learning performance in two environments: a traditional learning environment that uses presentation slides (hereinafter referred to as “the presentation slides-based learning environment”) and a VR-based learning environment. This study inquired whether LSA learners achieve higher performance than HSA learners do in a VR-based learning environment, whether LSA learners experience lower cognitive load in the VR-based environment than in the PPT-based learning environment, and whether an interaction effect exists between learning environment type and spatial ability.</p><p>An experimental research method was adopted. The participants, who were university students, were categorized into the two groups, the HSA and LSA groups, depending on their spatial ability level. Then, we randomly assigned members of the HSA and LSA groups to either the presentation slides or the VR learning environment and ensured that the two learning situations had the same number of subjects with the same spatial ability level. Specifically, a single-stimulus auditory experimental paradigm was adopted to examine the cognitive loads and learning performance levels of the two groups when using PTT and VR-based learning methods.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Theoretical background</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Virtual reality and education</h3><p>The term VR firstly appeared in the 1960s. The emergence of the single-user controller Sensorama marked the birth of highly immersion VR technology (Heiling <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1962" title="Heiling M (1962) Sensorama simulator. Retrieved from &#xA;                    http://www.mortonheilig.com/&#xA;                    &#xA;                  . Accessed 9 Oct 2017" href="/article/10.1007/s10055-018-0355-2#ref-CR19" id="ref-link-section-d31932e512">1962</a>). VR has long been regarded as an immersion technology that creates an interactive environment by integrating 3D imaging systems and various interface devices (Pan et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Pan Z, Cheok AD, Yang H, Zhu J, Shi J (2006) Virtual reality and mixed reality for virtual learning environments. Comput Graph 30:20–28. &#xA;                    https://doi.org/10.1016/j.cag.2005.10.004&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR38" id="ref-link-section-d31932e515">2006</a>). Therefore, the sense of immersion, real-time interaction, and imagination are three major features that VR technology provides. At the beginning of its emergence, VR was primarily used in the entertainment industry. Not until the 1980s did people start to consider VR as a teaching medium that can substantially increase the attractiveness of the learning content and learners’ learning motivation. Since then, VR technology has been applied to professional education and training (Hawkins <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Hawkins DG (1995) Virtual reality and passive simulators: the future of fun. In: Biocca F, Levy MR (eds) Communication in the age of virtual reality. Lawrence Erlbaum, Hillsdale, pp 159–189" href="/article/10.1007/s10055-018-0355-2#ref-CR17" id="ref-link-section-d31932e518">1995</a>). The combination of VR technology and education opens a new approach to learning, which can enhance, guide, and stimulate students’ interest in knowledge and allow students to personally experience the subject matter and obtain sensory and intuitive cognition (Bricken <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Bricken M (1991) Virtual reality learning environments: potentials and challenges. ACM Siggraph Comput Graph 25:178–184. &#xA;                    https://doi.org/10.1145/126640.126657&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR4" id="ref-link-section-d31932e521">1991</a>; Lytras et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Lytras MD, Raghavan V, Damiani E (2017) Big data and data analytics research: from metaphors to value space for collective wisdom in human decision making and smart machines. Int J Semant Web Inf 13(1):1–10" href="/article/10.1007/s10055-018-0355-2#ref-CR32" id="ref-link-section-d31932e524">2017</a>; Shim et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Shim KC et al (2003) Application of virtual reality technology in biology education. J Biol Educ 37:71–74. &#xA;                    https://doi.org/10.1080/00219266.2003.9655854&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR43" id="ref-link-section-d31932e528">2003</a>). For students who favor multichannel learning methods, VR undoubtedly provides an ideal approach to the acquisition of new knowledge (Leite et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Leite WL, Svinicki M, Shi Y (2010) Attempted validation of the scores of the VARK: learning styles inventory with multitrait multimethod confirmatory factor analysis models. Educ Psychol Meas 70(2):323–339" href="/article/10.1007/s10055-018-0355-2#ref-CR28" id="ref-link-section-d31932e531">2010</a>) and allows them to reinforce subject content, which poses a very motivating intellectual and technological challenge (Badilla and Meza <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Badilla MG, Meza S (2015) A pedagogical model to develop teaching skills. The collaborative learning experience in the immersive virtual world TYMMI. Comput Hum Behav 51:594–603. &#xA;                    https://doi.org/10.1016/j.chb.2015.03.016&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR1" id="ref-link-section-d31932e534">2015</a>); for educators, VR creates new opportunities to interact with students (Bell and Fogler <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Bell JT, Fogler HS (2004) The application of virtual reality to (chemical engineering) education. IEEE 2004:27–31. &#xA;                    https://doi.org/10.1109/VR.2004.1310077&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR2" id="ref-link-section-d31932e537">2004</a>). Most crucially, educational VR contents enable learners to learn abstract, unobservable, and even dangerous declarative and procedural knowledge in nonrisky situations (Kerawalla et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Kerawalla L, Luckin R, Seljeflot S, Woolard A (2006) “Making it real”: exploring the potential of augmented reality for teaching primary school science. Virtual Real 10(3):163–174. &#xA;                    https://doi.org/10.1007/s10055-006-0036-4&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR24" id="ref-link-section-d31932e540">2006</a>; Liu et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Liu T-Y, Tan T-H, Chu Y-L (2009) Outdoor natural science learning with an RFID-supported immersive ubiquitous learning environment. Educ Technol Soc 12(4):161–175" href="/article/10.1007/s10055-018-0355-2#ref-CR30" id="ref-link-section-d31932e543">2009</a>).</p><p>Despite the numerous advantages of VR-based education, VR has not been extensively used for educational purposes because of its high cost, immature technique, and lack of supplementary teaching content. In early 2014, Google launched Google Cardboard—a simple VR viewer consisting of a piece of cardboard and optical lenses. This device has reduced people’s unfamiliarity with VR and has promoted VR technology, enabling the public to experience a simple form of VR by using their smart phones. It not only establishes a foundation for the development of head-mounted displays based on infinity optics (Goteborg <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Goteborg (2015) The benefits of virtual reality in education: a comparison study. Dissertation, University of Gothenburg" href="/article/10.1007/s10055-018-0355-2#ref-CR15" id="ref-link-section-d31932e549">2015</a>), but also provides a possibility of extensively applying VR technology to education in the future.</p><h3 class="c-article__sub-heading" id="Sec4">VR and spatial ability</h3><p>Spatial ability is a key component of human cognitive ability and is particularly critical for education and training (Eliot <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Eliot J (2002) About spatial intelligence: I. Percept Motor Skills 94:479. &#xA;                    https://doi.org/10.2466/PMS.94.2.479-486&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR12" id="ref-link-section-d31932e560">2002</a>). It plays a vital role in the learning of academic subjects and thus is an indispensable ability for learners (Thurstone <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1938" title="Thurstone LL (1938) Primary mental abilities. University of Chicago Press, Chicago" href="/article/10.1007/s10055-018-0355-2#ref-CR47" id="ref-link-section-d31932e563">1938</a>; Eliot <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Eliot J (2002) About spatial intelligence: I. Percept Motor Skills 94:479. &#xA;                    https://doi.org/10.2466/PMS.94.2.479-486&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR12" id="ref-link-section-d31932e566">2002</a>). Spatial ability is defined as “the ability to generate, retain, retrieve, and transform well-structured visual images.” Clearly, the difference in spatial ability results in dissimilar learning performance levels under various learning environments (Höffler and Leutner <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Höffler TN, Leutner D (2011) The role of spatial ability in learning from instructional animations-Evidence for an ability-as-compensator hypothesis. Comput Hum Behav 27(1):209–216" href="/article/10.1007/s10055-018-0355-2#ref-CR21" id="ref-link-section-d31932e569">2011</a>; Christodoulou et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Christodoulou Y, Yannopoulos A, Bountris EJ, Varvarigou T (2016) Ontology-driven interactive visualization of film production complexity using a visual language. Int J Semant Web Inf 12:100–122" href="/article/10.1007/s10055-018-0355-2#ref-CR9" id="ref-link-section-d31932e572">2016</a>). Merchant et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Merchant Z, Goetz ET, Keeny-Kennicutt W, Cifuentes L, Wok OK, Davis TJ (2013) Exploring 3-D virtual reality technology for spatial ability and chemistry achievement. J Comput Assist Learn 29(6):579–590. &#xA;                    https://doi.org/10.1111/jcal.12018&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR35" id="ref-link-section-d31932e576">2013</a>) used a 3D virtual game, Second Life, to investigate the interaction of learning environment and spatial ability on students’ chemistry learning achievements. They found that learners with poor spatial ability benefited more and understood the 3D nature of molecules more thoroughly in a 3D VR-based environment than in a two-dimensional image learning environment. Similarly, Lee and Wong (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Lee EAL, Wong KW (2014) Learning with desktop virtual reality: low spatial learners are more positively affected. Comput Educ 79:49–58. &#xA;                    https://doi.org/10.1016/j.compedu.2014.07.010&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR26" id="ref-link-section-d31932e579">2014</a>) indicated that LSA learners showed greater improvement in a VR-based learning environment than in a traditional teaching environment. However, Lee et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Lee EAL, Wong KW, Fung CC (2010) How does desktop virtual reality enhance learning outcomes? A structural equation modeling approach. Comput Educ 55(4):1424–1442. &#xA;                    https://doi.org/10.1016/j.compedu.2010.06.006&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR27" id="ref-link-section-d31932e582">2010</a>) reported that HSA learners emphasized the proactivity and controllability in learning more than ordinary learners did; therefore, they had a relatively high level of learning satisfaction and superior performance in a VR-based desktop learning environment.</p><h3 class="c-article__sub-heading" id="Sec5">Spatial ability and learning effectiveness</h3><p>The aforementioned studies have compared VR-based learning environments with traditional learning environments, but whether the possible benefits of VR-based learning environments are greater for HSA learners or LSA learners remains uncertain. Accordingly, two hypotheses—the ability-as-compensator hypothesis and ability enhancement hypothesis—have been proposed. The ability-as-compensator hypothesis contends that learners with poor spatial ability can be supported by a VR-based learning environment because such an environment provides a form of external representation that facilitates the visualization of knowledge, thereby reducing their cognitive loads during the learning process and assisting them in constructing mental representations. By comparison, in a traditional learning environment, LSA learners tend to have relatively high cognitive loads and find it difficult to form cognitive models by themselves (Mayer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Mayer RE (2001) Pain perception. Cambridge University Press, Cambridge" href="/article/10.1007/s10055-018-0355-2#ref-CR33" id="ref-link-section-d31932e593">2001</a>; Hegarty and Kriz <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Hegarty M, Kriz S (2008) Effects of knowledge and spatial ability on learning from animation. In: Lowe R, Schnotz W (eds) Learning with animation: research implications for design. Cambridge University Press, Cambridge, pp 3–29" href="/article/10.1007/s10055-018-0355-2#ref-CR18" id="ref-link-section-d31932e596">2008</a>). Therefore, they benefit more from a VR-based environment than HSA learners do. Conversely, the hypothesis of ability enhancement argues that the learning content is delivered to learners through various channels in a VR-based environment, which, to a certain extent, increases the cognitive loads of LSA learners, depletes their cognitive resources (Plass et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Plass JL, Chun DM, Mayer RE, Leuther D (2003) Cognitive load in reading a foreign language text with multimedia aids and the influence of verbal and spatial abilities. Comput Hum Behav 19:221–243. &#xA;                    https://doi.org/10.1016/S0747-5632(02)00015-8&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR39" id="ref-link-section-d31932e599">2003</a>), and reduces learning gains. By contrast, HSA learners are able to construct various psychological schemata of learned knowledge and transfer visualized knowledge in both traditional and VR-based learning environments. They have spare cognitive ability with which they can easily construct mental models (or mental representations) (Kalyuga et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Kalyuga S, Ayres P, Chandler P, Sweller J (2003) The expertise reversal effect. Educ Psychol 38:23–31. &#xA;                    https://doi.org/10.1207/S15326985EP3801_4&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR23" id="ref-link-section-d31932e602">2003</a>) and therefore can achieve superior learning performance. Both hypotheses are theoretically and logically reasonable according to cognitive load theory, but they have been supported or disproved in various studies. Currently, most studies related to them have adopted self-report methods, which may cause the research results to be easily influenced by the research participants’ subjective and biased perceptions. This study therefore employed EEG, an objective method, to measure the cognitive loads for learners with different levels of spatial ability in different learning environments.</p><h3 class="c-article__sub-heading" id="Sec6">Cognitive load and event-related potential</h3><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec7">Cognitive load theory</h4><p>Cognition refers to a person’s thought processes and ability to process information. Cognitive load is defined as the total amount of mental activities involved in a person’s working memory when that person is processing information, namely, the total amount of psychological resources that the person requires for information processing. Cognitive load theory states that a person has limited cognitive resources, and he or she must spend a certain amount of cognitive resources during learning. Therefore, when an activity consumes substantial cognitive resources, a diminished quantity of cognitive resources is available for other activities. If the cognitive load exceeds a person’s total amount of cognitive resources, the cognitive resources are unavailable for learning, deeming the learning as ineffective.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec8">Event-related potentials and one-stimulus paradigm</h4><p>Self-report methods are the most commonly used methods for measuring cognitive load induced during the learning process (Clark et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Clark RE, Clark VP, Jiang M (2014) From neo-behaviorisim to neuroscience: perspectives on the origins and future contribution of cognitive load research. Mod Distance Educ Res 3:52–65. &#xA;                    https://doi.org/10.1017/CBO9780511844744.012&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR10" id="ref-link-section-d31932e625">2014</a>). Participants are required to report the efforts they put into their learning (Brunken et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Brunken R, Plass JL, Leutner D (2003) Direct measurement of cognitive load in multimedia learning. Educ Psychol 38:53–61. &#xA;                    https://doi.org/10.1207/S15326985EP3801_7&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR5" id="ref-link-section-d31932e628">2003</a>). However, this subjective measuring method inevitably has disadvantages (Nisbett and Wilson <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1977" title="Nisbett RE, Wilson TD (1977) Telling more than we can know: verbal reports on mental process. Psychol Rev 84:231–259. &#xA;                    https://doi.org/10.1037/0033-295X.84.3.231&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR37" id="ref-link-section-d31932e631">1977</a>). Because most self-reports review the scenarios and participants’ perceptions after an event, the accuracy and stability of the feedback from the participants are considerably low because of the influence of previous experience (Freeman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Freeman J, Avons SE, Pearson DE, IJsselsteijn W (1999) Effects of sensory information and prior experience on direct subjective ratings of presence. Presence 8(1):1–13. &#xA;                    https://doi.org/10.1162/105474699566017&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR01" id="ref-link-section-d31932e634">1999</a>). A more objective method is thus required to strengthen the measurement of cognitive load.</p><p>EEG is one of the most well-known noninvasive methods for measuring brain activity, and it measures electrical differences by placing electrodes on the scalp (Sofien et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Sofien G, Nourah A, Hassan M, Hatim A, Kais B (2017) BCWB: a P300 brain-controlled web browser. Int J Semant Web Inf Syst 13:55–73. &#xA;                    https://doi.org/10.4018/IJSWIS.2017040104&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR44" id="ref-link-section-d31932e640">2017</a>). The EEG measures the spontaneous electrical brain activity, and ERPs are derived by averaging process changes over experimental or cognitive events (Gurtubay et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Gurtubay IG, Alegre M, Labarga A, Malanda A, Iriarte J, Artieda J (2001) Gamma band activity in an auditory oddball paradigm studied with the wavelet transform. Clin Neurophysiol 112:1219–1228. &#xA;                    https://doi.org/10.1016/s1388-2457(01)00557-0&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR16" id="ref-link-section-d31932e643">2001</a>; David et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="David T, Fernando B, Kamila N (2014) The development of the N1 and N2 components in auditory oddball paradigms: a systematic review with narrative analysis and suggested normative values. J Neural Transm 122:375. &#xA;                    https://doi.org/10.1007/s00702-01401258-3&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR11" id="ref-link-section-d31932e646">2014</a>). Therefore, it is widely used for measuring cognitive load. This method was developed by integrating cognitive psychology with the neurophysiology of the cerebral cortex. It reflects the electrical changes related to specific events. Cognitive load is a form of time-limited working memory load (Horat et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Horat SK, Herrmann FR, Favre G, Terzis J (2015) Assessment of mental workload: a new electrophysiological method based on intra-block averaging of ERP amplitudes. Neuropsychologia 82:11–17. &#xA;                    https://doi.org/10.1016/j.neuropsychologia.2015.12.013&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR22" id="ref-link-section-d31932e649">2015</a>) and is positively correlated with the distribution of attention resources. When neural resources are effectively allocated and controlled, cognitive load and resource reservation are negatively correlated (Wickens et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1983" title="Wickens C, Kramer A, Vanasse L, Donchin E (1983) Performance of concurrent tasks: a psychophysiological analysis of the reciprocity of information-processing resources. Science 221:1080–1082" href="/article/10.1007/s10055-018-0355-2#ref-CR50" id="ref-link-section-d31932e652">1983</a>). With a specific learning task, the learning outcome varies with different forms of resource allocation. This study employed a one-stimulus paradigm to measure the cognitive loads of learners with varying levels of spatial ability in two distinct learning environments and investigate the subsequent differences in learning effects.</p><p>The oddball paradigm was first proposed by Ritter and Vaughan (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1969" title="Ritter W, Vaughan HG (1969) Averaged evoked responses in vigilance and discrimination: a reassessment. Science 164:326–328. &#xA;                    https://doi.org/10.1126/science.164.3877.326&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR41" id="ref-link-section-d31932e658">1969</a>). It presents two kinds of stimuli in the same sensory channel, and the probability of these two stimuli is quite different. The large probability stimulus is called the standard stimulus, and the small probability stimulus is called the deviant stimulus. Usually, the probability of the standard stimulus is around 80%, and the probability of the deviant stimulus is around 20% (Wei and Luo <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Wei JH, Luo YJ (2010) Principle and technique of event-related brain potentials. Science Press, Beijing" href="/article/10.1007/s10055-018-0355-2#ref-CR48" id="ref-link-section-d31932e661">2010</a>). The oddball paradigm can be used to study the brain mechanism of habitual behaviors, exogenous attention, and behavioral inhibition (Yuan et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Yuan JJ, Xu MM, Yang JM et al (2017) The application of the two-choice oddball paradigm to the research of behavioral inhibitory control. Sci China Life Sci 47:1065–1073. &#xA;                    https://doi.org/10.1360/N052017-00125&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR53" id="ref-link-section-d31932e664">2017</a>; Xin et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Xin Y, Li H, Yuan JJ (2010) Negative emotion interferes with behavioral inhibitory control: an ERP study. Acta Psychol Sin 42:334–341. &#xA;                    https://doi.org/10.3724/SPJ.1041.2010.00334&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR52" id="ref-link-section-d31932e667">2010</a>). Single-stimulus paradigm is a transformation of the classic oddball paradigm; nontarget tones are replaced with a silent sound in the oddball paradigm.</p><p>A crucial part of the oddball paradigm is to design appropriate interstimulus intervals to maximize ERP components, including P300, N1, and P2; some frequently used interstimulus intervals range from 8 to 20s (Gonsalvez et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Gonsalvez CJ, Barry RJ, Rushby JA, Polich J (2007) Target-to-target interval, intensity, and P300 from an auditory single-stimulus task. Psychophysiology 44:245–250. &#xA;                    https://doi.org/10.1111/j.1469-8986.2007.00495.x&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR14" id="ref-link-section-d31932e673">2007</a>; Struber and Polich <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Struber D, Polich J (2002) P300 and slow wave from oddball and single-stimulus visual tasks: inter-stimulus interval effects. Int J Psychophysiol 45:187–196. &#xA;                    https://doi.org/10.1016/S0167-8760(02)00071-5&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR46" id="ref-link-section-d31932e676">2002</a>). Although single-stimulus and oddball paradigms both generate early components (e.g., P1, N1, and P2) and late components (e.g., P300), these components are more salient and less influenced by other factors in the single-stimulus paradigm (Wetter et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Wetter S, Polich J, Vanasse L, Donchin E (2004) Olfactory, auditory, and visual ERPs from single trials: no evidence for habituation. Int J Psychophysiol 54:263–272" href="/article/10.1007/s10055-018-0355-2#ref-CR49" id="ref-link-section-d31932e679">2004</a>). Therefore, we use a single-stimulus paradigm to measure cognitive load is relatively reliable.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec9">Chapter summary</h4><p>In summary, many scholars have used subjective methods to measure the learning performance of people with different spatial capabilities in the VR environment. As a result, two conflicting hypotheses have emerged—the ability enhancement hypothesis and the ability compensation hypothesis. However, this article uses event-related potentials to collect electrophysiological data generated by learners with different spatial abilities while learning in a VR environment. Therefore, it is the first to solve the problem of “who benefits more in the VR environment” from an objective perspective. In addition, compared with the desktop VR or 3D imaging technology used in the past research, this paper adopted Google Cardboard for the research, which had a higher level of immersion.</p></div></div></section><section aria-labelledby="Sec10"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Methods</h2><div class="c-article-section__content" id="Sec10-content"><h3 class="c-article__sub-heading" id="Sec11">Participants</h3><p>Thirty-two right-handed, healthy university students (16 males) took part in this study. All of them had no history of psychiatric illness and had normal vision or normal vision after correction. Almost half of them had never previously used VR, and the rest had only experienced it once or twice. They were informed of the study purpose of the experiment and signed a consent form before the experiment. Participants received rewards of CNY$35–40 after the experiment. Four participants were excluded from the experiment, of which three were due to excessively numerous data artifacts, and the other was due to failure to complete the experiment. The data of the other 28 participants were valid; this group consisted of 15 female and 13 male participants, with an average age of 22.75 years (standard deviation = 1.86 years).</p><h3 class="c-article__sub-heading" id="Sec12">Experimental design</h3><p>This study adopted a 2 (high and low spatial ability) × 2 (presentation slides and VR-based learning environments) between-group design. The first variable was spatial ability and was measured using the standard mental rotation test developed by Vandenberg and Kuse (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1978" title="Vandenberg SG, Kuse AR (1978) Mental rotations, a group test of three-dimensional spatial visualization. Percept Mot Skills 47:599–604. &#xA;                    https://doi.org/10.2466/pms.1978.47.2.599&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR02" id="ref-link-section-d31932e712">1978</a>); the median was used to differentiate spatial ability levels. The second variable was learning environment, comprising presentation slides and VR-based learning environments. The learning materials for both environments were obtained from VR Astronomy Show software. Except for the form of learning method (i.e., presentation slides or VR-based methods), the learning time, auditory stimuli, and learning content were all controlled to be identical (Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0355-2#Fig1">1</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0355-2#Fig2">2</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig1_HTML.png?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig1_HTML.png" alt="figure1" loading="lazy" width="685" height="177" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Learning materials used in presentation slides-based environment</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig2_HTML.jpg" alt="figure2" loading="lazy" width="685" height="153" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Learning materials used in VR-based environment</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>The VR Astronomy Show was developed by the China Digital Technology Museum; it includes the following four learning modules: Solar System Roaming, Day and Night of Mars, the International Space Station, and the Moon Landing. The Solar System Roaming module introduces the eight planets, asteroids, and their distribution in the solar system; the Day and Night of Mars module gives a brief introduction to the Martian geomorphology and various Mars explorers; the International Space Station module addresses the structure and function of the space station; and the Moon Landing module gives a brief introduction to the moon’s landform and the history of humans landing on the moon. We selected the first three modules for the formal experiment, and we selected the Moon Landing module for pre-experiment practice. In the formal experiment, the Solar System Roaming, Day and Night of Mars, and International Space Station modules lasted 10, 8, and 6 min, respectively.</p><p>According to the level of each subject’s spatial ability, we divided the 32 subjects into two groups, each containing 8 high spatial ability subjects and 8 low spatial ability subjects. There was no significant difference in age, spatial ability, gender, or basic knowledge of astronomy between the two groups. Each subject learned in only one kind of environment. That is, the subjects in the presentation slides group learned only in the presentation slides-based environment and did not learn in a VR-based environment. This was also the case for the VR group.</p><p>In our experiment (the specific experimental framework is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0355-2#Fig3">3</a>), learning material and auditory stimuli were presented simultaneously. According to the assumption that attention is limited, how much attention was assigned to the unrelated auditory stimuli under different learning environments reflects the differences in cognitive load experienced by the subjects in the different learning environments.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig3_HTML.png?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig3_HTML.png" alt="figure3" loading="lazy" width="685" height="565" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Experimental design framework</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>When participants were learning using presentation slides or VR, the auditory stimulus at 1000 Hz with duration of 100 ms and rise and fall time of 5 ms from 60 dB sound pressure level (SPL) was presented at a distance of 50 cm from the participants. The experimental design was based on the classic oddball paradigm; 80% of the nontarget auditory stimulus was replaced with silence; therefore, the target stimulus at 1000 Hz appeared at a probability of 20%. In total, the target auditory stimulus appeared 144 times, comprising 60 times at the first stage, 48 times at the second stage, and 36 times at the third stage.</p><h3 class="c-article__sub-heading" id="Sec13">Experimental procedures</h3><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec14">Spatial ability test and astronomy knowledge test</h4><p>The participants were required to undertake tests of spatial ability and astronomy knowledge 1 week before the formal experiment; the tests lasted for 20 min. For the spatial ability test, a mental rotation test (Vandenberg and Kuse <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1978" title="Vandenberg SG, Kuse AR (1978) Mental rotations, a group test of three-dimensional spatial visualization. Percept Mot Skills 47:599–604. &#xA;                    https://doi.org/10.2466/pms.1978.47.2.599&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR02" id="ref-link-section-d31932e800">1978</a>) was adopted, which consisted of two modules: a practice module and a spatial ability test module. Test items were images of 3D shapes composed of small cubes. The first shape presented was a standard image used as a reference to answer each question. Among the other four shapes, two of them were able to coincide with the standard shape if being rotated correctly, whereas the other two were unable to do so because they were rotated mirror images of the standard shape (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0355-2#Fig4">4</a>). The participants were asked to select the two shapes that could match the standard shapes. No points were given if the participants failed to choose all the correct answers. The test comprised of 24 questions, and the duration was 10 min. An astronomy knowledge test that consisted of 21 questions was performed after the spatial ability test, and its duration was 10 min too. The questions were adopted from the test of the First Astronomical Knowledge Competition held by Qingqing Astronomy Association at Hunan University, China.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig4_HTML.png?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig4_HTML.png" alt="figure4" loading="lazy" width="685" height="131" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Schematic diagram of test items in the mental rotation test</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec15">Experimental procedures of ERPs</h4><p>During the experiment, each participant sat in a quiet, soundproofed, softly lit room with the most comfortable position. Each participant faced a 15-inch color liquid–crystal display screen. In the learning task that used presentation slides, instructions and presentation slides were shown on the center of the computer screen, and the participants were told to learn astronomy-related knowledge in three stages. An instruction was first displayed on the screen: “Please press G to start the first stage of learning.” After the participants pressed the G key, a gazing point appeared on the screen and lasted for 5000 ms to help the participants adjust their moods and concentrate their attention. Subsequently, participants started the presentation slides-based learning (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0355-2#Fig5">5</a>), and an auditory stimulus was presented simultaneously during the learning period (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0355-2#Fig6">6</a>). In this process, the subjects did not need to respond to the auditory stimulus but simply focus on the learning materials. The durations of the three learning stages were 10, 8, and 6 min, respectively.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig5_HTML.png?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig5_HTML.png" alt="figure5" loading="lazy" width="685" height="154" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Presentation of learning materials in presentation slides-based environment</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig6_HTML.png?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig6_HTML.png" alt="figure6" loading="lazy" width="685" height="153" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Auditory stimulation (dashed lines) single-stimulus paradigm</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>In the task for the VR-based learning, learning materials were shown on an MI 6 mobile phone, which was provided by the laboratory. Each participant sat on a swivel chair in a position the participant specified as the most comfortable. The researcher helped the participants to wear and adjust VR glasses (Google Cardboard). Then the participants used the Moon Landing practice module of the VR Astronomy Show to adapt to and familiarize themselves with the VR operation and to understand the experiment requirements. After the participants fully understood and had been adapted to the VR device and related operations, they started the formal VR-based learning (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0355-2#Fig7">7</a>). The participants slightly raised their hands to indicate that the experiment could be started. The researcher played the corresponding auditory stimulus after seeing this indication. In this process, the VR learning materials and auditory stimuli were also presented simultaneously. As in the task for the presentation slides-based learning, subjects did not need to respond to auditory stimuli. The durations of each module in the VR-based learning were the same as those in the presentation slides-based learning; sufficient break time was provided between each experimental stage. The participants were asked to complete a learning effectiveness questionnaire after the experiment finished.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig7_HTML.png?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig7_HTML.png" alt="figure7" loading="lazy" width="685" height="140" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Presentation of learning materials in VR-based environment</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec16">Learning performance test</h4><p>After each participant completed the experiment, we asked him to complete the learning effect test. As the presentation slides-based learning group and the VR-based learning group learned the same content, we used the same test to measure the learning effect in all subjects. The test questions were based on the three modules covered in this study. The questions included sentence completion with correct answers, single-choice questions, and true or false questions. For example, “The main mission of the Curiosity is ______”; “Which one of the following is the largest mountain range in the solar system?” The content validity of these tests was determined by expert judgment. Three experts were asked to review the test questions and make a judgment about how well these items represented the intended content area. They all believed that these questions could accurately measure the students’ learning performance.</p><h3 class="c-article__sub-heading" id="Sec17">Data collection and analysis</h3><p>An ERP recorder and analyzer (Brain Product, Germany) was employed to record the EEG response of the participants. Each of them wore an EEG cap, which was used according to the international 10–20 system. Electrodes were placed on the outer sides of the left and right eyes to record horizontal electrooculogram (EOG), and electrodes were placed above and below the left eye to record vertical EOGs. The data were collected using alternating current, filtered using a band-pass filter at 0.05–100 Hz, and sampled at a frequency of 500 Hz. The impedance between the scalp surface and electrical resistance was smaller than 5 kΩ, and the papillae at the two sides were used as reference. EOG was automatically corrected with a band-pass filter at 0.01–30 Hz, and electrodes with artifact signals at ± 100 µV were eliminated. Data were retrieved for analysis at two periods: 200 ms before the auditory stimulus and 800 ms after the auditory stimulus; the first period was used as the baseline.</p><p>This study examined the cognitive loads of learners with different levels of spatial ability in two different learning environments as well as their impacts on learning performance. Therefore, the ERP statistical analysis only employed data collected between 1000 ms before and after the appearance of the auditory stimulus not used in the main task for the learners. The ERP components N1 and P2 were used for analysis, and electrodes and time windows for component analysis were selected according to the topographic map, waveform diagram, and relevant literature (Fan and Han <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Fan Y, Han SH (2008) Temporal dynamic of neural mechanism involved in empathy for pain: an event-related brain potential study. Neuropsychologia 46(1):160–173. &#xA;                    https://doi.org/10.1016/j.neuropsychologia.2007.07.023&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR13" id="ref-link-section-d31932e914">2008</a>; Meng et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Meng J, Jackson T, Chen H, Hu L, Yang Z, Su YH, Huang XT (2013) Pain perception in the self and observation of others: an ERP investigation. NeuroImage 72:164–173. &#xA;                    https://doi.org/10.1016/j.enuroimage.2013.01.024&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR34" id="ref-link-section-d31932e917">2013</a>). The time window for analyzing N1 was 110–170 ms, and the analyzed electrodes were FCZ, T7, CZ, T8, CPZ, and PZ. The time window for analyzing P2 was 200–260 ms, and the analyzed electrodes were FC1, FCZ, C1, CZ, CPZ, and PZ. IBM SPSS 19 was employed for statistical analysis. Descriptive statistics were all expressed in the form of mean ± standard deviation. Two-way between-group ANOVA was conducted on the scores of the spatial ability test, astronomy knowledge test, and learning performance test; three-way repeated measurement was conducted on the ERP components by using variables of spatial ability (high and low levels), learning environment (presentation slides and VR-based environments), and electrode. The degree of freedom of the <i>F</i> value was tested and corrected through the Greenhouse–Geisser correction.</p></div></div></section><section aria-labelledby="Sec18"><div class="c-article-section" id="Sec18-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec18">Results</h2><div class="c-article-section__content" id="Sec18-content"><h3 class="c-article__sub-heading" id="Sec19">Results of spatial ability and astronomy knowledge tests</h3><p>This study used the median score to determine the participants’ spatial ability (Mayer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Mayer RE (2001) Pain perception. Cambridge University Press, Cambridge" href="/article/10.1007/s10055-018-0355-2#ref-CR33" id="ref-link-section-d31932e936">2001</a>). The median score for the spatial ability test was 9, which was used as the grouping criterion. Participants who obtained a score of 9 or lower were assigned to the LSA group, whereas those whose scores were higher than 9 were assigned to the HSA group. The analysis of the test results showed that the two groups significantly differed in spatial ability (HSA group: 13.36 ± 0.964; LSA group: 6.36 ± 0.464; <i>F</i> (1, 27) = 8.550, <i>p</i> &lt; .001). Between participants using the PTT and VR-based learning methods, no significant difference was observed in spatial ability (VR group: 9.64 ± 1.156; PTT group: 10.07 ± 1.299; <i>F</i> (1, 27) = 0.128, <i>p</i> = .807) and astronomy knowledge (VR group: 10.14 ± 0.907; PTT group: 9.43 ± 0.810; <i>F</i> (1, 27) = 0.276, <i>p</i> = .562). In addition, the HSA and LSA groups also differed nonsignificantly in the level of astronomy knowledge (HSA group: 10.07 ± 0.923; LSA group: 9.5 ± 0.797; <i>F</i> (1, 27) = 0.421, <i>p</i> = .643).</p><h3 class="c-article__sub-heading" id="Sec20">Learning performance data</h3><p>By conducting 2 (high and low spatial ability) × 2 (presentation slides and VR-based learning environments) two-way between-group ANOVA, this study found that the main effect of spatial ability was significant: <i>F</i> (1, 24) = 5.308; <i>p</i> = .03; partial eta squared (<i>η</i><sup>2</sup>) = 0.181. The learning performance of the HSA participants (79.29 ± 2.19) was superior to the LSA participants (72.14 ± 2.19). However, no significant difference in learning performance existed between the two learning environments. The interaction effect of spatial ability and learning environment was significant: <i>F</i> (1, 24) = 4.69; <i>p</i> = .04; partial <i>η</i><sup>2</sup> = 0.163 (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0355-2#Tab1">1</a>).</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Summary of ANOVA regarding the between-subjects effects</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0355-2/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>The simple main effects of spatial ability, learning environment, and learning performance were tested. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0355-2#Tab2">2</a> demonstrates that the interaction effect of spatial ability and learning environment on learning performance differed with learning conditions. In the presentation slides-based learning environment, participants with different levels of spatial ability exhibited significant differences in learning performance. According to Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0355-2#Tab3">3</a>, in the presentation slides-based learning environment, the learning performance of HSA participants (83.57 ± 3.09) was significantly higher than that of LSA participants (69.71 ± 3.09). However, when the condition was restricted to a VR-based learning environment, no significant difference in learning performance was detected between HSA and LSA participants. Then this study analyzed the influence of learning environment on the learning performance of participants with different levels of spatial ability. For HSA participants, learning environment exerted relatively large influences on their learning performance. Their learning performance in the presentation slides-based learning environment (83.57 ± 2.70) was significantly higher than that in the VR-based learning environment (75 ± 2.70), as shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0355-2#Tab3">3</a>. By comparison, LSA participants did not significantly differ in learning performance under different learning environments.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Summary of ANOVA regarding the simple main effects</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0355-2/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Mean values for the four conditions, mean differences between different learning environments and spatial ability levels, and marginal means for learning environments</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0355-2/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 Result of Mauchly’s sphericity test of N1 and P2 potentials</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0355-2/tables/4"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec21">Electrophysiological data</h3><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0355-2#Tab5">5</a> summarizes the statistical outcomes, which were corrected according to Greenhouse–Geisser’s method because the dependent variable (electrode) did not follow a spherical distribution (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0355-2#Tab4">4</a>).</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 Summary of the three-factor (spatial ability × learning environment × electrode) repeated-measures analyses of variance applied to the mean amplitude for each component and electrode</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0355-2/tables/5"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>The main effect of the electrodes for N1 was significant: <i>F</i> (5, 120) = 60.972, <i>p</i> &lt; .001, and partial <i>η</i><sup>2</sup> = 0.895. The main effects of T7 (− 3.55 ± 0.31 µV), T8 (− 3.52 ± 0.39 µV), and PZ (− 4.72 ± 0.44 µV) were significantly smaller than that of CZ (− 7.69 ± 0.58 µV), FCZ (− 8.41 ± 0.58 µV), and CPZ (− 6.43 ± 0.53 µV). The interaction effect of learning environment and electrode was also significant: <i>F</i> (5, 120) = 3.17, <i>p</i> = .04, and partial <i>η</i><sup>2</sup> = 0.117. The PPT-based learning environment (− 6.07 ± 0.59 µV) evoked a larger amplitude than did the VR-based learning environment (− 5.37 ± 0.59 µV). The amplitude difference between various electrodes in the VR-based environment (<i>p</i> = .004) was smaller than that in the PPT-based environment (<i>p</i> = &lt; .001). Although the interaction effect of spatial ability * electrode position did not reach significance, it reaches a marginal significance (<i>p</i> = .078). The amplitude evoked by HSA participants (− 5.42 ± 0.59 µV) was smaller than that evoked by LSA participants (− 6.07 ± 0.59 µV). There was a tendency that the difference in N1 amplitude between the spatial ability groups was most pronounced over central electrode positions (Cz, CPz) (see Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0355-2#Fig8">8</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0355-2#Fig9">9</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0355-2#Fig10">10</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0355-2#Fig11">11</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig8_HTML.png?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig8_HTML.png" alt="figure8" loading="lazy" width="685" height="320" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Mean area amplitudes of N1, presented separately for HAS and LSA group from the FCZ, T7, CZ, T8, CPZ, PZ electrodes</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig9_HTML.png?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig9_HTML.png" alt="figure9" loading="lazy" width="685" height="377" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>N1 and P2 at the CPZ electrode</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig10_HTML.png?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig10_HTML.png" alt="figure10" loading="lazy" width="685" height="422" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>N1 and P2 at the CZ electrode</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig11_HTML.png?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0355-2/MediaObjects/10055_2018_355_Fig11_HTML.png" alt="figure11" loading="lazy" width="685" height="357" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Topographic map of N1 and P2 under the four learning conditions</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0355-2/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>The main effect of electrodes for P2 was significant: <i>F</i> (5, 120) = 19.67, <i>p</i> = &lt; .001, and partial <i>η</i><sup>2</sup> = 0.45. The amplitudes of FC1 (4.51 ± 0.40 µV), FCZ (4.80 ± 0.41 µV), C1 (4.37 ± 0.4 µV), and CZ (4.73 ± 0.33 µV) were significantly larger than that of CPZ (4.00 ± 0.39 µV) and PZ (2.95 ± 0.28 µV). The interaction effect of spatial ability and electrode was significant: <i>F</i> (5, 120) = 4.622, <i>p</i> = .016, and partial <i>η</i><sup>2</sup> = 0.082. At the FC1 and FCZ electrodes, the amplitude evoked by LSA participants was significantly larger than that evoked by HSA participants (FC1: <i>p</i> = .046; FCZ: <i>p</i> = .037). The main effect of the learning environment was significant: <i>F</i> (1, 24) = 7.147, <i>p</i> = .013, and partial <i>η</i><sup>2</sup> = 0.229. The PPT-based environment (5.15 ± 0.49 µV) evoked positive waves with amplitude larger than those of the VR-based environment (3.31 ± 0.49 µV). The main effect of spatial ability was also significant: <i>F</i> (1, 24) = 4.411, <i>p</i> = .046, and partial <i>η</i><sup>2</sup> = 0.155. The amplitude evoked by LSA participants (4.95 ± 0.49 µV) was larger than that evoked by HSA participants (3.51 ± 0.49 µV). The interaction effect of the learning environment type and spatial ability was significant: <i>F</i> (1, 24) = 4.416, <i>p</i> = .046, and partial <i>η</i><sup>2</sup> = 0.155. The results of simple effect analysis are displayed in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0355-2#Tab6">6</a>.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-6"><figure><figcaption class="c-article-table__figcaption"><b id="Tab6" data-test="table-caption">Table 6 Simple effect analysis on spatial ability and learning environment for P2 component</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0355-2/tables/6"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>According to Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0355-2#Tab6">6</a>, participants with different levels of spatial ability in the PPT-based learning environment resulted in different amplitude levels. LSA participants (6.59 ± 0.78 µV) evoked larger amplitude than did HSA participants (3.70 ± 0.78 µV). This result is consistent with the result regarding the main effect of spatial ability, but the amplitude difference between the two groups is larger. Similarly, the PPT-based environment (6.59 ± 0.71 µV) evoked significantly larger P2 amplitude than the VR-based environment did (3.31 ± 0.71 µV) in LSA participants. In the PPT-based environment, the interaction effect of spatial ability and electrodes was significant. The level of P2 amplitude induced by LSA participants was significantly higher than that induced by HSA participants at all electrodes (Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0355-2#Fig9">9</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0355-2#Fig10">10</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0355-2#Fig11">11</a>).</p></div></div></section><section aria-labelledby="Sec22"><div class="c-article-section" id="Sec22-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec22">Discussion</h2><div class="c-article-section__content" id="Sec22-content"><p>In this study, auditory stimulus unrelated to the task evoked early N1 and P2 in all four learning conditions. The early-component amplitude in the PPT-based environment was found to be larger than those in the VR-based environment; additionally, the amplitude induced by LSA participants was larger than that induced by HSA participants. The amplitude of P2 achieved the level of significance.</p><p>The N1 component reflects the characteristics of a person’s various perceptions of a stimulus. Although the N1 amplitude differed with different learning environments and spatial abilities, the difference was nonsignificant. This verified that, in different learning environments, this experiment effectively controlled the learning content to be equal, thus ensuring that the difference in other components derives from the differences in learners’ attention allocation rather than the physical characteristics of the learning materials.</p><p>The P2 component is a result that suggests selective attention at an early stage, reflecting the allocation of attention resources and the automatic processing of the characteristics of the stimulus (Näätänen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Näätänen R, Kujala T, Winkler I (2011) Auditory processing that leads to conscious perception: a unique window to central auditory processing opened by the mismatch negativity and related responses. Psychophysiology 48:4–22. &#xA;                    https://doi.org/10.1111/j.1469-8986&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR36" id="ref-link-section-d31932e2632">2011</a>). According to cognitive resource theory, cognitive resources are limited in human beings. When the cognitive load is high, the high-order cognitive resources used for attention allocation are occupied; thus, learners become unable to effectively inhibit their response to task-irrelevant stimuli and subsequently are easily disturbed by task-irrelevant stimuli. This was observed in this experiment from the increase of the N1 and P2 amplitude in the PPT-based environment. By contrast, when the cognitive load was low, learners have sufficient cognitive resources to inhibit their responses to task-irrelevant stimuli and therefore can concentrate their attention on learning tasks (Lavie and Tsal <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Lavie N, Tsal Y (1994) Perceptual load as a major determinant of the locus of selection in visual attention. Percept Psychophys 56:183–197. &#xA;                    https://doi.org/10.3758/BF03213897&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR25" id="ref-link-section-d31932e2635">1994</a>; Lavie et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Lavie N, Hirst A, de Focket JW, Viding E (2004) Load theory of selective attention and cognitive control. J Exp Psychol Gen 133(3):339–354. &#xA;                    https://doi.org/10.1037/0096-3445.133.3.339&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR04" id="ref-link-section-d31932e2638">2004</a>). Although different learning environments result in dissimilar cognitive loads and learning effects, learners’ individual differences also influence their learning performance levels in various learning environments (Stahl <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Stahl C (2011) Learning routes from visualizations for indoor wayfinding: presentation modes and individual differences. Spat Cogn Comput 11:281–312. &#xA;                    https://doi.org/10.1080/13875868.2011.571326&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR45" id="ref-link-section-d31932e2641">2011</a>). Numerous studies have reported that different individuals’ spatial ability positively predicts their performance in tasks that require visual space-related information processing (Boucheix and Schneider <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Boucheix J-M, Schneider E (2009) Static and animated presentations in learning dynamic mechanical systems. Learn Instr 19:112–117. &#xA;                    https://doi.org/10.1016/j.learninstruc.2008.03.004&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR3" id="ref-link-section-d31932e2644">2009</a>). Those with high spatial ability can satisfactorily generate, maintain, and control the external representations provided by learning materials and transform them into their internal, or mental, representations, thus achieving favorable learning performance (Höffler <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Höffler TN (2010) Spatial ability: its influence on learning with visualization—a meta-analytic review. Educ Psychol Rev 22:245–269" href="/article/10.1007/s10055-018-0355-2#ref-CR20" id="ref-link-section-d31932e2648">2010</a>). Therefore, they are less subject to disturbances of irrelevant stimuli, resulting in relatively low N1 and P2 amplitude. Conversely, people with low spatial ability consume more cognitive resources only for generating and maintaining external representations; no cognitive resources are left for them to resist the disturbances of irrelevant stimuli. Therefore, the N1 and P2 amplitudes evoked by task-irrelevant stimuli are high, which is consistent with the results of this study.</p><p>The interaction effect of the learning environment and spatial ability was further analyzed by focusing on the P2 component. This study found that the P2 amplitude elicited by LSA participants was larger than that elicited by HSA participants in the PPT-based environment. However, in the VR-based environment, the P2 amplitude elicited in these two groups did not differ significantly. This is because LSA learners are unable to adequately form their mental models like their counterparts are in a PPT-based learning environment; therefore, they experience higher cognitive loads (Höffler <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Höffler TN (2010) Spatial ability: its influence on learning with visualization—a meta-analytic review. Educ Psychol Rev 22:245–269" href="/article/10.1007/s10055-018-0355-2#ref-CR20" id="ref-link-section-d31932e2654">2010</a>). Moreover, in the PPT-based learning environment, images are presented statically, and learners must match language information with the corresponding image information to construct their mental models; this process requires repeated processing of the language and image information, increasing the learners’ workloads and demanding large amounts of cognitive resources (Rieber <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1990" title="Rieber L (1990) Using computer animated graphics in science instructions with children. J Educ Psychol 82:135–140. &#xA;                    https://doi.org/10.1037/0022-0663.82.1.135&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR40" id="ref-link-section-d31932e2657">1990</a>; Xie <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Xie YJ (2014) The effects of spatial ability animation types on multimedia learning. Dissertation, Central China Normal University" href="/article/10.1007/s10055-018-0355-2#ref-CR51" id="ref-link-section-d31932e2660">2014</a>). Accordingly, LSA learners do not have extra cognitive resources to resist disturbances of task-irrelevant stimuli. By comparison, the VR-based learning environment, which features dynamic and consecutive image presentation and the complementation of multiple sensory channels, provides the process of spatial information transformation for LSA learners, reducing their extra cognitive loads and facilitating their establishment of mental models (Chen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Chen CJ (2006) Are spatial visualization abilities relevant to virtual reality? e-J Instr Sci Technol 9:1–16" href="/article/10.1007/s10055-018-0355-2#ref-CR6" id="ref-link-section-d31932e2663">2006</a>).</p><p>The P2 amplitude corresponds to the level of cognitive resource input. For HSA participants, the P2 amplitude did not differ significantly in the presentation slides and VR-based environments. This indicates that the cognitive loads imposed on them did not exceed their total cognitive resources. This is because HSA learners have extensive spatial intelligence and are adept in managing dynamic information regarding space and processes (Cheng and Zhou <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Cheng K, Zhou A (2009) The effect of representational model of information and personality traits of learners on the learning in multimedia environment. Psychol Dev Educ 25:83–91" href="/article/10.1007/s10055-018-0355-2#ref-CR7" id="ref-link-section-d31932e2670">2009</a>). In addition, the conceptual and procedural knowledge presented in the VR-based learning environment requires less working memory for learners to build the mental representations of the learning content (Kalyuga et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Kalyuga S, Ayres P, Chandler P, Sweller J (2003) The expertise reversal effect. Educ Psychol 38:23–31. &#xA;                    https://doi.org/10.1207/S15326985EP3801_4&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR23" id="ref-link-section-d31932e2673">2003</a>; Lee and Wong <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Lee EAL, Wong KW (2014) Learning with desktop virtual reality: low spatial learners are more positively affected. Comput Educ 79:49–58. &#xA;                    https://doi.org/10.1016/j.compedu.2014.07.010&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR26" id="ref-link-section-d31932e2676">2014</a>). Thus, HSA learners possess sufficient cognitive resources for learning in both learning environments; for them, VR-based learning is not necessary required to compensate for the lack of cognitive resources in traditional learning.</p><p>The cognitive load imposed on HSA participants did not exceed their total cognitive resources in both learning environments. However, to a certain extent, VR tasks, which require the use of multisensory channels, may still consume a larger amount of cognitive resources for HSA learners who are able to satisfactorily complete learning tasks in the static PPT-based learning environment (Santangelo et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Santangelo V, Fagioli S, Macaluso E (2010) The costs of monitoring simultaneously two sensory modalities decrease when dividing attention in space. NeuroImage 49:2717–2727. &#xA;                    https://doi.org/10.1016/j.neuroimage.2009.10.061&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR42" id="ref-link-section-d31932e2682">2010</a>). Thus, HSA participants in this experiment had lower learning performance in the VR-based environment than in the PPT-based environment.</p></div></div></section><section aria-labelledby="Sec23"><div class="c-article-section" id="Sec23-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec23">Conclusion</h2><div class="c-article-section__content" id="Sec23-content"><p>This study used an EEG experiment to preliminarily investigate the influence of VR-based learning on the learning performance and cognitive loads of learners with different levels of spatial ability. LSA learners were identified as have significantly reduced cognitive loads and improved learning performance in the VR-based learning environment. By comparison, HSA learners did not show significant differences of cognitive load in the presentation slides and VR-based learning environments, but they had lower learning performance in the VR-based environment. This result is consistent with the ability-as-compensator hypothesis; the electrophysiological evidence serves to confirm the theory. It also helps us to understand the potential of applying VR in education and reveals the impact of students’ individual differences on the effects of VR-based teaching. Therefore, educators can apply these findings to provide differentiated instruction and to develop individualized teaching, thereby improving students’ learning performance.</p><h3 class="c-article__sub-heading" id="Sec24">Limitations and expectation</h3><p>The learning content in the experiment focused on astronomical knowledge about the solar system and eight major planets; this declarative knowledge mainly requires memorization and lacks interactivity. Therefore, some of the characteristics of VR cannot be considered in such experiments; whether the results can be generalized to other learning content and interactive VR-based learning methods is still worth further investigation. Moreover, besides the spatial ability and previous learning experiences, numerous other factors may influence learner’s learning performance, such as cognitive style and learning style. Previous studies have shown that when teaching methods match students’ learning styles, their potential can be fully explored (Silver et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Silver HF, Strong RW, Perini MJ (2000) So each may learn: integrating learning styles and multiple intelligences. ASCD, Alexandria, VA, USA" href="/article/10.1007/s10055-018-0355-2#ref-CR03" id="ref-link-section-d31932e2701">2000</a>). Otherwise, the learning performance will decrease. However, Chia and Chien’s (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Chia CC, Chien YC (2017) Exploring the effect of learning styles on learning achievement in a u-Museum. Interact Learn Environ 7:1–18. &#xA;                    https://doi.org/10.1080/10494820.2017.385488&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR8" id="ref-link-section-d31932e2704">2017</a>) study showed that, under the design of the human–computer interface, the learning performance of students with both “Active” and “Reflective” learning styles improved. Chia and Chien (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Chia CC, Chien YC (2017) Exploring the effect of learning styles on learning achievement in a u-Museum. Interact Learn Environ 7:1–18. &#xA;                    https://doi.org/10.1080/10494820.2017.385488&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0355-2#ref-CR8" id="ref-link-section-d31932e2707">2017</a>) attributed the improvement to the high level of participation in the human–computer interface design. Therefore, it can be further investigated that which characteristics of virtual reality technology play a key role in leading to high immersion. In addition, how do different learning styles of students affect their learning performance? And the relationships among these factors, as well as their mutual influences resulting in various learning performance levels and should be further discussed.</p><p>Finally, most of the subjects in this paper were exposed to VR for the first time, so a novelty effect cannot be ruled out in this experiment. As a new technology, VR may attract more attention, stimulate learners’ curiosity, and further mobilize enthusiasm, which will undoubtedly improve the learning effect. Therefore, in future research, we can combine behavioral experiments with EEG experiments and extend the time of learning to one or two semesters, thus eliminating the difference in learning performance introduced by novelty.</p><p>In future research, scholars may consider investigating the difference in cognitive load and learning performance between learners with different learning styles in the VR-based and presentation slides-based environment and study whether a teacher’s guidance can reduce this difference. VR gives active learners the opportunity to choose the learning order and construct the knowledge framework freely so as to better match their own original knowledge framework and enhance their learning performance. However, the knowledge displayed by VR is integrated, and one picture may often contain various knowledge points, so it is easy to omit information, thus reducing the learning performance. Passive learners prefer nonanalytical, general, or overall perceptual methods that often fail to distinguish a number of elements from complex situations. Therefore, the integration of VR increases their cognitive load. However, previous studies have shown that the meticulous processing of learning materials, that is, increasing information related to memory materials, contributes to knowledge learning and memory. Therefore, scholar can also tackle the single-stimulus paradigm in future research to explore the learning performance and cognitive load of people with different learning styles in different learning situations and to use the “Wizard” function provided by the Google Expeditions program to study whether a teacher’s guidance in the VR environment would improve the learning performance of learners via the two learning strategies.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MG. Badilla, S. Meza, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Badilla MG, Meza S (2015) A pedagogical model to develop teaching skills. The collaborative learning experienc" /><p class="c-article-references__text" id="ref-CR1">Badilla MG, Meza S (2015) A pedagogical model to develop teaching skills. The collaborative learning experience in the immersive virtual world TYMMI. Comput Hum Behav 51:594–603. <a href="https://doi.org/10.1016/j.chb.2015.03.016">https://doi.org/10.1016/j.chb.2015.03.016</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.chb.2015.03.016" aria-label="View reference 1">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20pedagogical%20model%20to%20develop%20teaching%20skills.%20The%20collaborative%20learning%20experience%20in%20the%20immersive%20virtual%20world%20TYMMI&amp;journal=Comput%20Hum%20Behav&amp;doi=10.1016%2Fj.chb.2015.03.016&amp;volume=51&amp;pages=594-603&amp;publication_year=2015&amp;author=Badilla%2CMG&amp;author=Meza%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JT. Bell, HS. Fogler, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Bell JT, Fogler HS (2004) The application of virtual reality to (chemical engineering) education. IEEE 2004:27" /><p class="c-article-references__text" id="ref-CR2">Bell JT, Fogler HS (2004) The application of virtual reality to (chemical engineering) education. IEEE 2004:27–31. <a href="https://doi.org/10.1109/VR.2004.1310077">https://doi.org/10.1109/VR.2004.1310077</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FVR.2004.1310077" aria-label="View reference 2">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20application%20of%20virtual%20reality%20to%20%28chemical%20engineering%29%20education&amp;journal=IEEE&amp;doi=10.1109%2FVR.2004.1310077&amp;volume=2004&amp;pages=27-31&amp;publication_year=2004&amp;author=Bell%2CJT&amp;author=Fogler%2CHS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J-M. Boucheix, E. Schneider, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Boucheix J-M, Schneider E (2009) Static and animated presentations in learning dynamic mechanical systems. Lea" /><p class="c-article-references__text" id="ref-CR3">Boucheix J-M, Schneider E (2009) Static and animated presentations in learning dynamic mechanical systems. Learn Instr 19:112–117. <a href="https://doi.org/10.1016/j.learninstruc.2008.03.004">https://doi.org/10.1016/j.learninstruc.2008.03.004</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.learninstruc.2008.03.004" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Static%20and%20animated%20presentations%20in%20learning%20dynamic%20mechanical%20systems&amp;journal=Learn%20Instr&amp;doi=10.1016%2Fj.learninstruc.2008.03.004&amp;volume=19&amp;pages=112-117&amp;publication_year=2009&amp;author=Boucheix%2CJ-M&amp;author=Schneider%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Bricken, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="Bricken M (1991) Virtual reality learning environments: potentials and challenges. ACM Siggraph Comput Graph 2" /><p class="c-article-references__text" id="ref-CR4">Bricken M (1991) Virtual reality learning environments: potentials and challenges. ACM Siggraph Comput Graph 25:178–184. <a href="https://doi.org/10.1145/126640.126657">https://doi.org/10.1145/126640.126657</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F126640.126657" aria-label="View reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20learning%20environments%3A%20potentials%20and%20challenges&amp;journal=ACM%20Siggraph%20Comput%20Graph&amp;doi=10.1145%2F126640.126657&amp;volume=25&amp;pages=178-184&amp;publication_year=1991&amp;author=Bricken%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Brunken, JL. Plass, D. Leutner, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Brunken R, Plass JL, Leutner D (2003) Direct measurement of cognitive load in multimedia learning. Educ Psycho" /><p class="c-article-references__text" id="ref-CR5">Brunken R, Plass JL, Leutner D (2003) Direct measurement of cognitive load in multimedia learning. Educ Psychol 38:53–61. <a href="https://doi.org/10.1207/S15326985EP3801_7">https://doi.org/10.1207/S15326985EP3801_7</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1207%2FS15326985EP3801_7" aria-label="View reference 5">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Direct%20measurement%20of%20cognitive%20load%20in%20multimedia%20learning&amp;journal=Educ%20Psychol&amp;doi=10.1207%2FS15326985EP3801_7&amp;volume=38&amp;pages=53-61&amp;publication_year=2003&amp;author=Brunken%2CR&amp;author=Plass%2CJL&amp;author=Leutner%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="CJ. Chen, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Chen CJ (2006) Are spatial visualization abilities relevant to virtual reality? e-J Instr Sci Technol 9:1–16" /><p class="c-article-references__text" id="ref-CR6">Chen CJ (2006) Are spatial visualization abilities relevant to virtual reality? e-J Instr Sci Technol 9:1–16</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Are%20spatial%20visualization%20abilities%20relevant%20to%20virtual%20reality%3F&amp;journal=e-J%20Instr%20Sci%20Technol&amp;volume=9&amp;pages=1-16&amp;publication_year=2006&amp;author=Chen%2CCJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Cheng, A. Zhou, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Cheng K, Zhou A (2009) The effect of representational model of information and personality traits of learners " /><p class="c-article-references__text" id="ref-CR7">Cheng K, Zhou A (2009) The effect of representational model of information and personality traits of learners on the learning in multimedia environment. Psychol Dev Educ 25:83–91</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effect%20of%20representational%20model%20of%20information%20and%20personality%20traits%20of%20learners%20on%20the%20learning%20in%20multimedia%20environment&amp;journal=Psychol%20Dev%20Educ&amp;volume=25&amp;pages=83-91&amp;publication_year=2009&amp;author=Cheng%2CK&amp;author=Zhou%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="CC. Chia, YC. Chien, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Chia CC, Chien YC (2017) Exploring the effect of learning styles on learning achievement in a u-Museum. Intera" /><p class="c-article-references__text" id="ref-CR8">Chia CC, Chien YC (2017) Exploring the effect of learning styles on learning achievement in a u-Museum. Interact Learn Environ 7:1–18. <a href="https://doi.org/10.1080/10494820.2017.385488">https://doi.org/10.1080/10494820.2017.385488</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F10494820.2017.385488" aria-label="View reference 8">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Exploring%20the%20effect%20of%20learning%20styles%20on%20learning%20achievement%20in%20a%20u-Museum&amp;journal=Interact%20Learn%20Environ&amp;doi=10.1080%2F10494820.2017.385488&amp;volume=7&amp;pages=1-18&amp;publication_year=2017&amp;author=Chia%2CCC&amp;author=Chien%2CYC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. Christodoulou, A. Yannopoulos, EJ. Bountris, T. Varvarigou, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Christodoulou Y, Yannopoulos A, Bountris EJ, Varvarigou T (2016) Ontology-driven interactive visualization of " /><p class="c-article-references__text" id="ref-CR9">Christodoulou Y, Yannopoulos A, Bountris EJ, Varvarigou T (2016) Ontology-driven interactive visualization of film production complexity using a visual language. Int J Semant Web Inf 12:100–122</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.4018%2FIJSWIS.2016040105" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Ontology-driven%20interactive%20visualization%20of%20film%20production%20complexity%20using%20a%20visual%20language&amp;journal=Int%20J%20Semant%20Web%20Inf&amp;volume=12&amp;pages=100-122&amp;publication_year=2016&amp;author=Christodoulou%2CY&amp;author=Yannopoulos%2CA&amp;author=Bountris%2CEJ&amp;author=Varvarigou%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RE. Clark, VP. Clark, M. Jiang, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Clark RE, Clark VP, Jiang M (2014) From neo-behaviorisim to neuroscience: perspectives on the origins and futu" /><p class="c-article-references__text" id="ref-CR10">Clark RE, Clark VP, Jiang M (2014) From neo-behaviorisim to neuroscience: perspectives on the origins and future contribution of cognitive load research. Mod Distance Educ Res 3:52–65. <a href="https://doi.org/10.1017/CBO9780511844744.012">https://doi.org/10.1017/CBO9780511844744.012</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1017%2FCBO9780511844744.012" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=From%20neo-behaviorisim%20to%20neuroscience%3A%20perspectives%20on%20the%20origins%20and%20future%20contribution%20of%20cognitive%20load%20research&amp;journal=Mod%20Distance%20Educ%20Res&amp;doi=10.1017%2FCBO9780511844744.012&amp;volume=3&amp;pages=52-65&amp;publication_year=2014&amp;author=Clark%2CRE&amp;author=Clark%2CVP&amp;author=Jiang%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. David, B. Fernando, N. Kamila, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="David T, Fernando B, Kamila N (2014) The development of the N1 and N2 components in auditory oddball paradigms" /><p class="c-article-references__text" id="ref-CR11">David T, Fernando B, Kamila N (2014) The development of the N1 and N2 components in auditory oddball paradigms: a systematic review with narrative analysis and suggested normative values. J Neural Transm 122:375. <a href="https://doi.org/10.1007/s00702-01401258-3">https://doi.org/10.1007/s00702-01401258-3</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs00702-01401258-3" aria-label="View reference 11">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20development%20of%20the%20N1%20and%20N2%20components%20in%20auditory%20oddball%20paradigms%3A%20a%20systematic%20review%20with%20narrative%20analysis%20and%20suggested%20normative%20values&amp;journal=J%20Neural%20Transm&amp;doi=10.1007%2Fs00702-01401258-3&amp;volume=122&amp;publication_year=2014&amp;author=David%2CT&amp;author=Fernando%2CB&amp;author=Kamila%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Eliot, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Eliot J (2002) About spatial intelligence: I. Percept Motor Skills 94:479. https://doi.org/10.2466/PMS.94.2.47" /><p class="c-article-references__text" id="ref-CR12">Eliot J (2002) About spatial intelligence: I. Percept Motor Skills 94:479. <a href="https://doi.org/10.2466/PMS.94.2.479-486">https://doi.org/10.2466/PMS.94.2.479-486</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.2466%2FPMS.94.2.479-486" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=About%20spatial%20intelligence%3A%20I&amp;journal=Percept%20Motor%20Skills&amp;doi=10.2466%2FPMS.94.2.479-486&amp;volume=94&amp;publication_year=2002&amp;author=Eliot%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. Fan, SH. Han, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Fan Y, Han SH (2008) Temporal dynamic of neural mechanism involved in empathy for pain: an event-related brain" /><p class="c-article-references__text" id="ref-CR13">Fan Y, Han SH (2008) Temporal dynamic of neural mechanism involved in empathy for pain: an event-related brain potential study. Neuropsychologia 46(1):160–173. <a href="https://doi.org/10.1016/j.neuropsychologia.2007.07.023">https://doi.org/10.1016/j.neuropsychologia.2007.07.023</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.neuropsychologia.2007.07.023" aria-label="View reference 13">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Temporal%20dynamic%20of%20neural%20mechanism%20involved%20in%20empathy%20for%20pain%3A%20an%20event-related%20brain%20potential%20study&amp;journal=Neuropsychologia&amp;doi=10.1016%2Fj.neuropsychologia.2007.07.023&amp;volume=46&amp;issue=1&amp;pages=160-173&amp;publication_year=2008&amp;author=Fan%2CY&amp;author=Han%2CSH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Freeman, SE. Avons, DE. Pearson, W. IJsselsteijn, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Freeman J, Avons SE, Pearson DE, IJsselsteijn W (1999) Effects of sensory information and prior experience on " /><p class="c-article-references__text" id="ref-CR01">Freeman J, Avons SE, Pearson DE, IJsselsteijn W (1999) Effects of sensory information and prior experience on direct subjective ratings of presence. Presence 8(1):1–13. <a href="https://doi.org/10.1162/105474699566017">https://doi.org/10.1162/105474699566017</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474699566017" aria-label="View reference 14">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Effects%20of%20sensory%20information%20and%20prior%20experience%20on%20direct%20subjective%20ratings%20of%20presence&amp;journal=Presence&amp;doi=10.1162%2F105474699566017&amp;volume=8&amp;issue=1&amp;pages=1-13&amp;publication_year=1999&amp;author=Freeman%2CJ&amp;author=Avons%2CSE&amp;author=Pearson%2CDE&amp;author=IJsselsteijn%2CW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="CJ. Gonsalvez, RJ. Barry, JA. Rushby, J. Polich, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Gonsalvez CJ, Barry RJ, Rushby JA, Polich J (2007) Target-to-target interval, intensity, and P300 from an audi" /><p class="c-article-references__text" id="ref-CR14">Gonsalvez CJ, Barry RJ, Rushby JA, Polich J (2007) Target-to-target interval, intensity, and P300 from an auditory single-stimulus task. Psychophysiology 44:245–250. <a href="https://doi.org/10.1111/j.1469-8986.2007.00495.x">https://doi.org/10.1111/j.1469-8986.2007.00495.x</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fj.1469-8986.2007.00495.x" aria-label="View reference 15">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Target-to-target%20interval%2C%20intensity%2C%20and%20P300%20from%20an%20auditory%20single-stimulus%20task&amp;journal=Psychophysiology&amp;doi=10.1111%2Fj.1469-8986.2007.00495.x&amp;volume=44&amp;pages=245-250&amp;publication_year=2007&amp;author=Gonsalvez%2CCJ&amp;author=Barry%2CRJ&amp;author=Rushby%2CJA&amp;author=Polich%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Goteborg (2015) The benefits of virtual reality in education: a comparison study. Dissertation, University of " /><p class="c-article-references__text" id="ref-CR15">Goteborg (2015) The benefits of virtual reality in education: a comparison study. Dissertation, University of Gothenburg</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="IG. Gurtubay, M. Alegre, A. Labarga, A. Malanda, J. Iriarte, J. Artieda, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Gurtubay IG, Alegre M, Labarga A, Malanda A, Iriarte J, Artieda J (2001) Gamma band activity in an auditory od" /><p class="c-article-references__text" id="ref-CR16">Gurtubay IG, Alegre M, Labarga A, Malanda A, Iriarte J, Artieda J (2001) Gamma band activity in an auditory oddball paradigm studied with the wavelet transform. Clin Neurophysiol 112:1219–1228. <a href="https://doi.org/10.1016/s1388-2457(01)00557-0">https://doi.org/10.1016/s1388-2457(01)00557-0</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fs1388-2457%2801%2900557-0" aria-label="View reference 17">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Gamma%20band%20activity%20in%20an%20auditory%20oddball%20paradigm%20studied%20with%20the%20wavelet%20transform&amp;journal=Clin%20Neurophysiol&amp;doi=10.1016%2Fs1388-2457%2801%2900557-0&amp;volume=112&amp;pages=1219-1228&amp;publication_year=2001&amp;author=Gurtubay%2CIG&amp;author=Alegre%2CM&amp;author=Labarga%2CA&amp;author=Malanda%2CA&amp;author=Iriarte%2CJ&amp;author=Artieda%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="DG. Hawkins, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Hawkins DG (1995) Virtual reality and passive simulators: the future of fun. In: Biocca F, Levy MR (eds) Commu" /><p class="c-article-references__text" id="ref-CR17">Hawkins DG (1995) Virtual reality and passive simulators: the future of fun. In: Biocca F, Levy MR (eds) Communication in the age of virtual reality. Lawrence Erlbaum, Hillsdale, pp 159–189</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Communication%20in%20the%20age%20of%20virtual%20reality&amp;pages=159-189&amp;publication_year=1995&amp;author=Hawkins%2CDG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="M. Hegarty, S. Kriz, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Hegarty M, Kriz S (2008) Effects of knowledge and spatial ability on learning from animation. In: Lowe R, Schn" /><p class="c-article-references__text" id="ref-CR18">Hegarty M, Kriz S (2008) Effects of knowledge and spatial ability on learning from animation. In: Lowe R, Schnotz W (eds) Learning with animation: research implications for design. Cambridge University Press, Cambridge, pp 3–29</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20with%20animation%3A%20research%20implications%20for%20design&amp;pages=3-29&amp;publication_year=2008&amp;author=Hegarty%2CM&amp;author=Kriz%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Heiling M (1962) Sensorama simulator. Retrieved from http://www.mortonheilig.com/. Accessed 9 Oct 2017" /><p class="c-article-references__text" id="ref-CR19">Heiling M (1962) Sensorama simulator. Retrieved from <a href="http://www.mortonheilig.com/">http://www.mortonheilig.com/</a>. Accessed 9 Oct 2017</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="TN. Höffler, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Höffler TN (2010) Spatial ability: its influence on learning with visualization—a meta-analytic review. Educ P" /><p class="c-article-references__text" id="ref-CR20">Höffler TN (2010) Spatial ability: its influence on learning with visualization—a meta-analytic review. Educ Psychol Rev 22:245–269</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10648-010-9126-7" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatial%20ability%3A%20its%20influence%20on%20learning%20with%20visualization%E2%80%94a%20meta-analytic%20review&amp;journal=Educ%20Psychol%20Rev&amp;volume=22&amp;pages=245-269&amp;publication_year=2010&amp;author=H%C3%B6ffler%2CTN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="TN. Höffler, D. Leutner, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Höffler TN, Leutner D (2011) The role of spatial ability in learning from instructional animations-Evidence fo" /><p class="c-article-references__text" id="ref-CR21">Höffler TN, Leutner D (2011) The role of spatial ability in learning from instructional animations-Evidence for an ability-as-compensator hypothesis. Comput Hum Behav 27(1):209–216</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.chb.2010.07.042" aria-label="View reference 22">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20role%20of%20spatial%20ability%20in%20learning%20from%20instructional%20animations-Evidence%20for%20an%20ability-as-compensator%20hypothesis&amp;journal=Comput%20Hum%20Behav&amp;volume=27&amp;issue=1&amp;pages=209-216&amp;publication_year=2011&amp;author=H%C3%B6ffler%2CTN&amp;author=Leutner%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SK. Horat, FR. Herrmann, G. Favre, J. Terzis, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Horat SK, Herrmann FR, Favre G, Terzis J (2015) Assessment of mental workload: a new electrophysiological meth" /><p class="c-article-references__text" id="ref-CR22">Horat SK, Herrmann FR, Favre G, Terzis J (2015) Assessment of mental workload: a new electrophysiological method based on intra-block averaging of ERP amplitudes. Neuropsychologia 82:11–17. <a href="https://doi.org/10.1016/j.neuropsychologia.2015.12.013">https://doi.org/10.1016/j.neuropsychologia.2015.12.013</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.neuropsychologia.2015.12.013" aria-label="View reference 23">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Assessment%20of%20mental%20workload%3A%20a%20new%20electrophysiological%20method%20based%20on%20intra-block%20averaging%20of%20ERP%20amplitudes&amp;journal=Neuropsychologia&amp;doi=10.1016%2Fj.neuropsychologia.2015.12.013&amp;volume=82&amp;pages=11-17&amp;publication_year=2015&amp;author=Horat%2CSK&amp;author=Herrmann%2CFR&amp;author=Favre%2CG&amp;author=Terzis%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Kalyuga, P. Ayres, P. Chandler, J. Sweller, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Kalyuga S, Ayres P, Chandler P, Sweller J (2003) The expertise reversal effect. Educ Psychol 38:23–31. https:/" /><p class="c-article-references__text" id="ref-CR23">Kalyuga S, Ayres P, Chandler P, Sweller J (2003) The expertise reversal effect. Educ Psychol 38:23–31. <a href="https://doi.org/10.1207/S15326985EP3801_4">https://doi.org/10.1207/S15326985EP3801_4</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1207%2FS15326985EP3801_4" aria-label="View reference 24">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20expertise%20reversal%20effect&amp;journal=Educ%20Psychol&amp;doi=10.1207%2FS15326985EP3801_4&amp;volume=38&amp;pages=23-31&amp;publication_year=2003&amp;author=Kalyuga%2CS&amp;author=Ayres%2CP&amp;author=Chandler%2CP&amp;author=Sweller%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Kerawalla, R. Luckin, S. Seljeflot, A. Woolard, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Kerawalla L, Luckin R, Seljeflot S, Woolard A (2006) “Making it real”: exploring the potential of augmented re" /><p class="c-article-references__text" id="ref-CR24">Kerawalla L, Luckin R, Seljeflot S, Woolard A (2006) “Making it real”: exploring the potential of augmented reality for teaching primary school science. Virtual Real 10(3):163–174. <a href="https://doi.org/10.1007/s10055-006-0036-4">https://doi.org/10.1007/s10055-006-0036-4</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10055-006-0036-4" aria-label="View reference 25">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=%E2%80%9CMaking%20it%20real%E2%80%9D%3A%20exploring%20the%20potential%20of%20augmented%20reality%20for%20teaching%20primary%20school%20science&amp;journal=Virtual%20Real&amp;doi=10.1007%2Fs10055-006-0036-4&amp;volume=10&amp;issue=3&amp;pages=163-174&amp;publication_year=2006&amp;author=Kerawalla%2CL&amp;author=Luckin%2CR&amp;author=Seljeflot%2CS&amp;author=Woolard%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="N. Lavie, Y. Tsal, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Lavie N, Tsal Y (1994) Perceptual load as a major determinant of the locus of selection in visual attention. P" /><p class="c-article-references__text" id="ref-CR25">Lavie N, Tsal Y (1994) Perceptual load as a major determinant of the locus of selection in visual attention. Percept Psychophys 56:183–197. <a href="https://doi.org/10.3758/BF03213897">https://doi.org/10.3758/BF03213897</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3758%2FBF03213897" aria-label="View reference 26">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Perceptual%20load%20as%20a%20major%20determinant%20of%20the%20locus%20of%20selection%20in%20visual%20attention&amp;journal=Percept%20Psychophys&amp;doi=10.3758%2FBF03213897&amp;volume=56&amp;pages=183-197&amp;publication_year=1994&amp;author=Lavie%2CN&amp;author=Tsal%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="N. Lavie, A. Hirst, JW. de Focket, E. Viding, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Lavie N, Hirst A, de Focket JW, Viding E (2004) Load theory of selective attention and cognitive control. J Ex" /><p class="c-article-references__text" id="ref-CR04">Lavie N, Hirst A, de Focket JW, Viding E (2004) Load theory of selective attention and cognitive control. J Exp Psychol Gen 133(3):339–354. <a href="https://doi.org/10.1037/0096-3445.133.3.339">https://doi.org/10.1037/0096-3445.133.3.339</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2F0096-3445.133.3.339" aria-label="View reference 27">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Load%20theory%20of%20selective%20attention%20and%20cognitive%20control&amp;journal=J%20Exp%20Psychol%20Gen&amp;doi=10.1037%2F0096-3445.133.3.339&amp;volume=133&amp;issue=3&amp;pages=339-354&amp;publication_year=2004&amp;author=Lavie%2CN&amp;author=Hirst%2CA&amp;author=de%20Focket%2CJW&amp;author=Viding%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EAL. Lee, KW. Wong, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Lee EAL, Wong KW (2014) Learning with desktop virtual reality: low spatial learners are more positively affect" /><p class="c-article-references__text" id="ref-CR26">Lee EAL, Wong KW (2014) Learning with desktop virtual reality: low spatial learners are more positively affected. Comput Educ 79:49–58. <a href="https://doi.org/10.1016/j.compedu.2014.07.010">https://doi.org/10.1016/j.compedu.2014.07.010</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.compedu.2014.07.010" aria-label="View reference 28">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20with%20desktop%20virtual%20reality%3A%20low%20spatial%20learners%20are%20more%20positively%20affected&amp;journal=Comput%20Educ&amp;doi=10.1016%2Fj.compedu.2014.07.010&amp;volume=79&amp;pages=49-58&amp;publication_year=2014&amp;author=Lee%2CEAL&amp;author=Wong%2CKW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EAL. Lee, KW. Wong, CC. Fung, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Lee EAL, Wong KW, Fung CC (2010) How does desktop virtual reality enhance learning outcomes? A structural equa" /><p class="c-article-references__text" id="ref-CR27">Lee EAL, Wong KW, Fung CC (2010) How does desktop virtual reality enhance learning outcomes? A structural equation modeling approach. Comput Educ 55(4):1424–1442. <a href="https://doi.org/10.1016/j.compedu.2010.06.006">https://doi.org/10.1016/j.compedu.2010.06.006</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.compedu.2010.06.006" aria-label="View reference 29">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=How%20does%20desktop%20virtual%20reality%20enhance%20learning%20outcomes%3F%20A%20structural%20equation%20modeling%20approach&amp;journal=Comput%20Educ&amp;doi=10.1016%2Fj.compedu.2010.06.006&amp;volume=55&amp;issue=4&amp;pages=1424-1442&amp;publication_year=2010&amp;author=Lee%2CEAL&amp;author=Wong%2CKW&amp;author=Fung%2CCC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="WL. Leite, M. Svinicki, Y. Shi, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Leite WL, Svinicki M, Shi Y (2010) Attempted validation of the scores of the VARK: learning styles inventory w" /><p class="c-article-references__text" id="ref-CR28">Leite WL, Svinicki M, Shi Y (2010) Attempted validation of the scores of the VARK: learning styles inventory with multitrait multimethod confirmatory factor analysis models. Educ Psychol Meas 70(2):323–339</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1177%2F0013164409344507" aria-label="View reference 30">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Attempted%20validation%20of%20the%20scores%20of%20the%20VARK%3A%20learning%20styles%20inventory%20with%20multitrait%20multimethod%20confirmatory%20factor%20analysis%20models&amp;journal=Educ%20Psychol%20Meas&amp;volume=70&amp;issue=2&amp;pages=323-339&amp;publication_year=2010&amp;author=Leite%2CWL&amp;author=Svinicki%2CM&amp;author=Shi%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Li W (2014) The influence of animating presentation format and spatial ability on multimedia. Dissertation, Sc" /><p class="c-article-references__text" id="ref-CR29">Li W (2014) The influence of animating presentation format and spatial ability on multimedia. Dissertation, School of Educational Information Technology, Central China Normal University</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T-Y. Liu, T-H. Tan, Y-L. Chu, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Liu T-Y, Tan T-H, Chu Y-L (2009) Outdoor natural science learning with an RFID-supported immersive ubiquitous " /><p class="c-article-references__text" id="ref-CR30">Liu T-Y, Tan T-H, Chu Y-L (2009) Outdoor natural science learning with an RFID-supported immersive ubiquitous learning environment. Educ Technol Soc 12(4):161–175</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Outdoor%20natural%20science%20learning%20with%20an%20RFID-supported%20immersive%20ubiquitous%20learning%20environment&amp;journal=Educ%20Technol%20Soc&amp;volume=12&amp;issue=4&amp;pages=161-175&amp;publication_year=2009&amp;author=Liu%2CT-Y&amp;author=Tan%2CT-H&amp;author=Chu%2CY-L">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MD. Lytras, V. Raghavan, E. Damiani, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Lytras MD, Raghavan V, Damiani E (2017) Big data and data analytics research: from metaphors to value space fo" /><p class="c-article-references__text" id="ref-CR32">Lytras MD, Raghavan V, Damiani E (2017) Big data and data analytics research: from metaphors to value space for collective wisdom in human decision making and smart machines. Int J Semant Web Inf 13(1):1–10</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.4018%2FIJSWIS.2017010101" aria-label="View reference 33">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Big%20data%20and%20data%20analytics%20research%3A%20from%20metaphors%20to%20value%20space%20for%20collective%20wisdom%20in%20human%20decision%20making%20and%20smart%20machines&amp;journal=Int%20J%20Semant%20Web%20Inf&amp;volume=13&amp;issue=1&amp;pages=1-10&amp;publication_year=2017&amp;author=Lytras%2CMD&amp;author=Raghavan%2CV&amp;author=Damiani%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="RE. Mayer, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Mayer RE (2001) Pain perception. Cambridge University Press, Cambridge" /><p class="c-article-references__text" id="ref-CR33">Mayer RE (2001) Pain perception. Cambridge University Press, Cambridge</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Pain%20perception&amp;publication_year=2001&amp;author=Mayer%2CRE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Meng, T. Jackson, H. Chen, L. Hu, Z. Yang, YH. Su, XT. Huang, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Meng J, Jackson T, Chen H, Hu L, Yang Z, Su YH, Huang XT (2013) Pain perception in the self and observation of" /><p class="c-article-references__text" id="ref-CR34">Meng J, Jackson T, Chen H, Hu L, Yang Z, Su YH, Huang XT (2013) Pain perception in the self and observation of others: an ERP investigation. NeuroImage 72:164–173. <a href="https://doi.org/10.1016/j.enuroimage.2013.01.024">https://doi.org/10.1016/j.enuroimage.2013.01.024</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.enuroimage.2013.01.024" aria-label="View reference 35">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Pain%20perception%20in%20the%20self%20and%20observation%20of%20others%3A%20an%20ERP%20investigation&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.enuroimage.2013.01.024&amp;volume=72&amp;pages=164-173&amp;publication_year=2013&amp;author=Meng%2CJ&amp;author=Jackson%2CT&amp;author=Chen%2CH&amp;author=Hu%2CL&amp;author=Yang%2CZ&amp;author=Su%2CYH&amp;author=Huang%2CXT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Z. Merchant, ET. Goetz, W. Keeny-Kennicutt, L. Cifuentes, OK. Wok, TJ. Davis, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Merchant Z, Goetz ET, Keeny-Kennicutt W, Cifuentes L, Wok OK, Davis TJ (2013) Exploring 3-D virtual reality te" /><p class="c-article-references__text" id="ref-CR35">Merchant Z, Goetz ET, Keeny-Kennicutt W, Cifuentes L, Wok OK, Davis TJ (2013) Exploring 3-D virtual reality technology for spatial ability and chemistry achievement. J Comput Assist Learn 29(6):579–590. <a href="https://doi.org/10.1111/jcal.12018">https://doi.org/10.1111/jcal.12018</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fjcal.12018" aria-label="View reference 36">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 36 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Exploring%203-D%20virtual%20reality%20technology%20for%20spatial%20ability%20and%20chemistry%20achievement&amp;journal=J%20Comput%20Assist%20Learn&amp;doi=10.1111%2Fjcal.12018&amp;volume=29&amp;issue=6&amp;pages=579-590&amp;publication_year=2013&amp;author=Merchant%2CZ&amp;author=Goetz%2CET&amp;author=Keeny-Kennicutt%2CW&amp;author=Cifuentes%2CL&amp;author=Wok%2COK&amp;author=Davis%2CTJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Näätänen, T. Kujala, I. Winkler, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Näätänen R, Kujala T, Winkler I (2011) Auditory processing that leads to conscious perception: a unique window" /><p class="c-article-references__text" id="ref-CR36">Näätänen R, Kujala T, Winkler I (2011) Auditory processing that leads to conscious perception: a unique window to central auditory processing opened by the mismatch negativity and related responses. Psychophysiology 48:4–22. <a href="https://doi.org/10.1111/j.1469-8986">https://doi.org/10.1111/j.1469-8986</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fj.1469-8986" aria-label="View reference 37">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Auditory%20processing%20that%20leads%20to%20conscious%20perception%3A%20a%20unique%20window%20to%20central%20auditory%20processing%20opened%20by%20the%20mismatch%20negativity%20and%20related%20responses&amp;journal=Psychophysiology&amp;doi=10.1111%2Fj.1469-8986&amp;volume=48&amp;pages=4-22&amp;publication_year=2011&amp;author=N%C3%A4%C3%A4t%C3%A4nen%2CR&amp;author=Kujala%2CT&amp;author=Winkler%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RE. Nisbett, TD. Wilson, " /><meta itemprop="datePublished" content="1977" /><meta itemprop="headline" content="Nisbett RE, Wilson TD (1977) Telling more than we can know: verbal reports on mental process. Psychol Rev 84:2" /><p class="c-article-references__text" id="ref-CR37">Nisbett RE, Wilson TD (1977) Telling more than we can know: verbal reports on mental process. Psychol Rev 84:231–259. <a href="https://doi.org/10.1037/0033-295X.84.3.231">https://doi.org/10.1037/0033-295X.84.3.231</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2F0033-295X.84.3.231" aria-label="View reference 38">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 38 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Telling%20more%20than%20we%20can%20know%3A%20verbal%20reports%20on%20mental%20process&amp;journal=Psychol%20Rev&amp;doi=10.1037%2F0033-295X.84.3.231&amp;volume=84&amp;pages=231-259&amp;publication_year=1977&amp;author=Nisbett%2CRE&amp;author=Wilson%2CTD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Z. Pan, AD. Cheok, H. Yang, J. Zhu, J. Shi, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Pan Z, Cheok AD, Yang H, Zhu J, Shi J (2006) Virtual reality and mixed reality for virtual learning environmen" /><p class="c-article-references__text" id="ref-CR38">Pan Z, Cheok AD, Yang H, Zhu J, Shi J (2006) Virtual reality and mixed reality for virtual learning environments. Comput Graph 30:20–28. <a href="https://doi.org/10.1016/j.cag.2005.10.004">https://doi.org/10.1016/j.cag.2005.10.004</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.cag.2005.10.004" aria-label="View reference 39">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20and%20mixed%20reality%20for%20virtual%20learning%20environments&amp;journal=Comput%20Graph&amp;doi=10.1016%2Fj.cag.2005.10.004&amp;volume=30&amp;pages=20-28&amp;publication_year=2006&amp;author=Pan%2CZ&amp;author=Cheok%2CAD&amp;author=Yang%2CH&amp;author=Zhu%2CJ&amp;author=Shi%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JL. Plass, DM. Chun, RE. Mayer, D. Leuther, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Plass JL, Chun DM, Mayer RE, Leuther D (2003) Cognitive load in reading a foreign language text with multimedi" /><p class="c-article-references__text" id="ref-CR39">Plass JL, Chun DM, Mayer RE, Leuther D (2003) Cognitive load in reading a foreign language text with multimedia aids and the influence of verbal and spatial abilities. Comput Hum Behav 19:221–243. <a href="https://doi.org/10.1016/S0747-5632(02)00015-8">https://doi.org/10.1016/S0747-5632(02)00015-8</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0747-5632%2802%2900015-8" aria-label="View reference 40">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 40 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Cognitive%20load%20in%20reading%20a%20foreign%20language%20text%20with%20multimedia%20aids%20and%20the%20influence%20of%20verbal%20and%20spatial%20abilities&amp;journal=Comput%20Hum%20Behav&amp;doi=10.1016%2FS0747-5632%2802%2900015-8&amp;volume=19&amp;pages=221-243&amp;publication_year=2003&amp;author=Plass%2CJL&amp;author=Chun%2CDM&amp;author=Mayer%2CRE&amp;author=Leuther%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Rieber, " /><meta itemprop="datePublished" content="1990" /><meta itemprop="headline" content="Rieber L (1990) Using computer animated graphics in science instructions with children. J Educ Psychol 82:135–" /><p class="c-article-references__text" id="ref-CR40">Rieber L (1990) Using computer animated graphics in science instructions with children. J Educ Psychol 82:135–140. <a href="https://doi.org/10.1037/0022-0663.82.1.135">https://doi.org/10.1037/0022-0663.82.1.135</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2F0022-0663.82.1.135" aria-label="View reference 41">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 41 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Using%20computer%20animated%20graphics%20in%20science%20instructions%20with%20children&amp;journal=J%20Educ%20Psychol&amp;doi=10.1037%2F0022-0663.82.1.135&amp;volume=82&amp;pages=135-140&amp;publication_year=1990&amp;author=Rieber%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="W. Ritter, HG. Vaughan, " /><meta itemprop="datePublished" content="1969" /><meta itemprop="headline" content="Ritter W, Vaughan HG (1969) Averaged evoked responses in vigilance and discrimination: a reassessment. Science" /><p class="c-article-references__text" id="ref-CR41">Ritter W, Vaughan HG (1969) Averaged evoked responses in vigilance and discrimination: a reassessment. Science 164:326–328. <a href="https://doi.org/10.1126/science.164.3877.326">https://doi.org/10.1126/science.164.3877.326</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1126%2Fscience.164.3877.326" aria-label="View reference 42">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 42 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Averaged%20evoked%20responses%20in%20vigilance%20and%20discrimination%3A%20a%20reassessment&amp;journal=Science&amp;doi=10.1126%2Fscience.164.3877.326&amp;volume=164&amp;pages=326-328&amp;publication_year=1969&amp;author=Ritter%2CW&amp;author=Vaughan%2CHG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="V. Santangelo, S. Fagioli, E. Macaluso, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Santangelo V, Fagioli S, Macaluso E (2010) The costs of monitoring simultaneously two sensory modalities decre" /><p class="c-article-references__text" id="ref-CR42">Santangelo V, Fagioli S, Macaluso E (2010) The costs of monitoring simultaneously two sensory modalities decrease when dividing attention in space. NeuroImage 49:2717–2727. <a href="https://doi.org/10.1016/j.neuroimage.2009.10.061">https://doi.org/10.1016/j.neuroimage.2009.10.061</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.neuroimage.2009.10.061" aria-label="View reference 43">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 43 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20costs%20of%20monitoring%20simultaneously%20two%20sensory%20modalities%20decrease%20when%20dividing%20attention%20in%20space&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2009.10.061&amp;volume=49&amp;pages=2717-2727&amp;publication_year=2010&amp;author=Santangelo%2CV&amp;author=Fagioli%2CS&amp;author=Macaluso%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="KC. Shim, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Shim KC et al (2003) Application of virtual reality technology in biology education. J Biol Educ 37:71–74. htt" /><p class="c-article-references__text" id="ref-CR43">Shim KC et al (2003) Application of virtual reality technology in biology education. J Biol Educ 37:71–74. <a href="https://doi.org/10.1080/00219266.2003.9655854">https://doi.org/10.1080/00219266.2003.9655854</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F00219266.2003.9655854" aria-label="View reference 44">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 44 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Application%20of%20virtual%20reality%20technology%20in%20biology%20education&amp;journal=J%20Biol%20Educ&amp;doi=10.1080%2F00219266.2003.9655854&amp;volume=37&amp;pages=71-74&amp;publication_year=2003&amp;author=Shim%2CKC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="HF. Silver, RW. Strong, MJ. Perini, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Silver HF, Strong RW, Perini MJ (2000) So each may learn: integrating learning styles and multiple intelligenc" /><p class="c-article-references__text" id="ref-CR03">Silver HF, Strong RW, Perini MJ (2000) So each may learn: integrating learning styles and multiple intelligences. ASCD, Alexandria, VA, USA</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 45 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=So%20each%20may%20learn%3A%20integrating%20learning%20styles%20and%20multiple%20intelligences&amp;publication_year=2000&amp;author=Silver%2CHF&amp;author=Strong%2CRW&amp;author=Perini%2CMJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Sofien, A. Nourah, M. Hassan, A. Hatim, B. Kais, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Sofien G, Nourah A, Hassan M, Hatim A, Kais B (2017) BCWB: a P300 brain-controlled web browser. Int J Semant W" /><p class="c-article-references__text" id="ref-CR44">Sofien G, Nourah A, Hassan M, Hatim A, Kais B (2017) BCWB: a P300 brain-controlled web browser. Int J Semant Web Inf Syst 13:55–73. <a href="https://doi.org/10.4018/IJSWIS.2017040104">https://doi.org/10.4018/IJSWIS.2017040104</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.4018%2FIJSWIS.2017040104" aria-label="View reference 46">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 46 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=BCWB%3A%20a%20P300%20brain-controlled%20web%20browser&amp;journal=Int%20J%20Semant%20Web%20Inf%20Syst&amp;doi=10.4018%2FIJSWIS.2017040104&amp;volume=13&amp;pages=55-73&amp;publication_year=2017&amp;author=Sofien%2CG&amp;author=Nourah%2CA&amp;author=Hassan%2CM&amp;author=Hatim%2CA&amp;author=Kais%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Stahl, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Stahl C (2011) Learning routes from visualizations for indoor wayfinding: presentation modes and individual di" /><p class="c-article-references__text" id="ref-CR45">Stahl C (2011) Learning routes from visualizations for indoor wayfinding: presentation modes and individual differences. Spat Cogn Comput 11:281–312. <a href="https://doi.org/10.1080/13875868.2011.571326">https://doi.org/10.1080/13875868.2011.571326</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F13875868.2011.571326" aria-label="View reference 47">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 47 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20routes%20from%20visualizations%20for%20indoor%20wayfinding%3A%20presentation%20modes%20and%20individual%20differences&amp;journal=Spat%20Cogn%20Comput&amp;doi=10.1080%2F13875868.2011.571326&amp;volume=11&amp;pages=281-312&amp;publication_year=2011&amp;author=Stahl%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Struber, J. Polich, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Struber D, Polich J (2002) P300 and slow wave from oddball and single-stimulus visual tasks: inter-stimulus in" /><p class="c-article-references__text" id="ref-CR46">Struber D, Polich J (2002) P300 and slow wave from oddball and single-stimulus visual tasks: inter-stimulus interval effects. Int J Psychophysiol 45:187–196. <a href="https://doi.org/10.1016/S0167-8760(02)00071-5">https://doi.org/10.1016/S0167-8760(02)00071-5</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0167-8760%2802%2900071-5" aria-label="View reference 48">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 48 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=P300%20and%20slow%20wave%20from%20oddball%20and%20single-stimulus%20visual%20tasks%3A%20inter-stimulus%20interval%20effects&amp;journal=Int%20J%20Psychophysiol&amp;doi=10.1016%2FS0167-8760%2802%2900071-5&amp;volume=45&amp;pages=187-196&amp;publication_year=2002&amp;author=Struber%2CD&amp;author=Polich%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="LL. Thurstone, " /><meta itemprop="datePublished" content="1938" /><meta itemprop="headline" content="Thurstone LL (1938) Primary mental abilities. University of Chicago Press, Chicago" /><p class="c-article-references__text" id="ref-CR47">Thurstone LL (1938) Primary mental abilities. University of Chicago Press, Chicago</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 49 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Primary%20mental%20abilities&amp;publication_year=1938&amp;author=Thurstone%2CLL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SG. Vandenberg, AR. Kuse, " /><meta itemprop="datePublished" content="1978" /><meta itemprop="headline" content="Vandenberg SG, Kuse AR (1978) Mental rotations, a group test of three-dimensional spatial visualization. Perce" /><p class="c-article-references__text" id="ref-CR02">Vandenberg SG, Kuse AR (1978) Mental rotations, a group test of three-dimensional spatial visualization. Percept Mot Skills 47:599–604. <a href="https://doi.org/10.2466/pms.1978.47.2.599">https://doi.org/10.2466/pms.1978.47.2.599</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.2466%2Fpms.1978.47.2.599" aria-label="View reference 50">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 50 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Mental%20rotations%2C%20a%20group%20test%20of%20three-dimensional%20spatial%20visualization&amp;journal=Percept%20Mot%20Skills&amp;doi=10.2466%2Fpms.1978.47.2.599&amp;volume=47&amp;pages=599-604&amp;publication_year=1978&amp;author=Vandenberg%2CSG&amp;author=Kuse%2CAR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="JH. Wei, YJ. Luo, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Wei JH, Luo YJ (2010) Principle and technique of event-related brain potentials. Science Press, Beijing" /><p class="c-article-references__text" id="ref-CR48">Wei JH, Luo YJ (2010) Principle and technique of event-related brain potentials. Science Press, Beijing</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 51 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Principle%20and%20technique%20of%20event-related%20brain%20potentials&amp;publication_year=2010&amp;author=Wei%2CJH&amp;author=Luo%2CYJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Wetter, J. Polich, L. Vanasse, E. Donchin, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Wetter S, Polich J, Vanasse L, Donchin E (2004) Olfactory, auditory, and visual ERPs from single trials: no ev" /><p class="c-article-references__text" id="ref-CR49">Wetter S, Polich J, Vanasse L, Donchin E (2004) Olfactory, auditory, and visual ERPs from single trials: no evidence for habituation. Int J Psychophysiol 54:263–272</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.ijpsycho.2004.04.008" aria-label="View reference 52">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 52 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Olfactory%2C%20auditory%2C%20and%20visual%20ERPs%20from%20single%20trials%3A%20no%20evidence%20for%20habituation&amp;journal=Int%20J%20Psychophysiol&amp;volume=54&amp;pages=263-272&amp;publication_year=2004&amp;author=Wetter%2CS&amp;author=Polich%2CJ&amp;author=Vanasse%2CL&amp;author=Donchin%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Wickens, A. Kramer, L. Vanasse, E. Donchin, " /><meta itemprop="datePublished" content="1983" /><meta itemprop="headline" content="Wickens C, Kramer A, Vanasse L, Donchin E (1983) Performance of concurrent tasks: a psychophysiological analys" /><p class="c-article-references__text" id="ref-CR50">Wickens C, Kramer A, Vanasse L, Donchin E (1983) Performance of concurrent tasks: a psychophysiological analysis of the reciprocity of information-processing resources. Science 221:1080–1082</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1126%2Fscience.6879207" aria-label="View reference 53">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 53 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Performance%20of%20concurrent%20tasks%3A%20a%20psychophysiological%20analysis%20of%20the%20reciprocity%20of%20information-processing%20resources&amp;journal=Science&amp;volume=221&amp;pages=1080-1082&amp;publication_year=1983&amp;author=Wickens%2CC&amp;author=Kramer%2CA&amp;author=Vanasse%2CL&amp;author=Donchin%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Xie YJ (2014) The effects of spatial ability animation types on multimedia learning. Dissertation, Central Chi" /><p class="c-article-references__text" id="ref-CR51">Xie YJ (2014) The effects of spatial ability animation types on multimedia learning. Dissertation, Central China Normal University</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. Xin, H. Li, JJ. Yuan, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Xin Y, Li H, Yuan JJ (2010) Negative emotion interferes with behavioral inhibitory control: an ERP study. Acta" /><p class="c-article-references__text" id="ref-CR52">Xin Y, Li H, Yuan JJ (2010) Negative emotion interferes with behavioral inhibitory control: an ERP study. Acta Psychol Sin 42:334–341. <a href="https://doi.org/10.3724/SPJ.1041.2010.00334">https://doi.org/10.3724/SPJ.1041.2010.00334</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3724%2FSPJ.1041.2010.00334" aria-label="View reference 55">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 55 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Negative%20emotion%20interferes%20with%20behavioral%20inhibitory%20control%3A%20an%20ERP%20study&amp;journal=Acta%20Psychol%20Sin&amp;doi=10.3724%2FSPJ.1041.2010.00334&amp;volume=42&amp;pages=334-341&amp;publication_year=2010&amp;author=Xin%2CY&amp;author=Li%2CH&amp;author=Yuan%2CJJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JJ. Yuan, MM. Xu, JM. Yang, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Yuan JJ, Xu MM, Yang JM et al (2017) The application of the two-choice oddball paradigm to the research of beh" /><p class="c-article-references__text" id="ref-CR53">Yuan JJ, Xu MM, Yang JM et al (2017) The application of the two-choice oddball paradigm to the research of behavioral inhibitory control. Sci China Life Sci 47:1065–1073. <a href="https://doi.org/10.1360/N052017-00125">https://doi.org/10.1360/N052017-00125</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1360%2FN052017-00125" aria-label="View reference 56">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 56 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20application%20of%20the%20two-choice%20oddball%20paradigm%20to%20the%20research%20of%20behavioral%20inhibitory%20control&amp;journal=Sci%20China%20Life%20Sci&amp;doi=10.1360%2FN052017-00125&amp;volume=47&amp;pages=1065-1073&amp;publication_year=2017&amp;author=Yuan%2CJJ&amp;author=Xu%2CMM&amp;author=Yang%2CJM">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-018-0355-2-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>Funding was provided by Ministry of Science and Technology, Taiwan (Grant No. MOST 106-2511-S-003 -029 -MY3).</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">College of Business Administration, Huaqiao University, Quanzhou, China</p><p class="c-article-author-affiliation__authors-list">Rui Sun &amp; Qian Cai</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">East Business Management Research Center, Huaqiao University, Quanzhou, China</p><p class="c-article-author-affiliation__authors-list">Rui Sun</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">National Taiwan Normal University, Taipei, Taiwan</p><p class="c-article-author-affiliation__authors-list">Yenchun Jim Wu</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Rui-Sun"><span class="c-article-authors-search__title u-h3 js-search-name">Rui Sun</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Rui+Sun&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Rui+Sun" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Rui+Sun%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Yenchun_Jim-Wu"><span class="c-article-authors-search__title u-h3 js-search-name">Yenchun Jim Wu</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Yenchun Jim+Wu&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Yenchun Jim+Wu" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Yenchun Jim+Wu%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Qian-Cai"><span class="c-article-authors-search__title u-h3 js-search-name">Qian Cai</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Qian+Cai&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Qian+Cai" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Qian+Cai%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-018-0355-2/email/correspondent/c1/new">Yenchun Jim Wu</a>.</p></div></div></section><section aria-labelledby="ethics"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
              
                <h3 class="c-article__sub-heading">Conflict of interest</h3>
                <p>The authors declare that they have no conflicts of interest.</p>
              
            </div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=The%20effect%20of%20a%20virtual%20reality%20learning%20environment%20on%20learners%E2%80%99%20spatial%20ability&amp;author=Rui%20Sun%20et%20al&amp;contentID=10.1007%2Fs10055-018-0355-2&amp;publication=1359-4338&amp;publicationDate=2018-07-03&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-018-0355-2" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-018-0355-2" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Sun, R., Wu, Y.J. &amp; Cai, Q. The effect of a virtual reality learning environment on learners’ spatial ability.
                    <i>Virtual Reality</i> <b>23, </b>385–398 (2019). https://doi.org/10.1007/s10055-018-0355-2</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-018-0355-2.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2017-11-27">27 November 2017</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-06-28">28 June 2018</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-07-03">03 July 2018</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2019-12">December 2019</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-018-0355-2" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-018-0355-2</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Virtual reality (VR)</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Event-related potential (ERP)</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Spatial ability</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Cognitive load</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Education</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-018-0355-2.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=355;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

