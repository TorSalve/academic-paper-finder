<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Illuminating the past: state of the art"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Virtual reconstruction and representation of historical environments and objects have been of research interest for nearly two decades. Physically based and historically accurate illumination..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/14/3.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Illuminating the past: state of the art"/>

    <meta name="dc.source" content="Virtual Reality 2010 14:3"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2010-02-20"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2010 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Virtual reconstruction and representation of historical environments and objects have been of research interest for nearly two decades. Physically based and historically accurate illumination allows archaeologists and historians to authentically visualise a past environment to deduce new knowledge. This report reviews the current state of illuminating cultural heritage sites and objects using computer graphics for scientific, preservation and research purposes. We present the most noteworthy and up-to-date examples of reconstructions employing appropriate illumination models in object and image space, and in the visual perception domain. Finally, we also discuss the difficulties in rendering, documentation, validation and identify probable research challenges for the future. The report is aimed for researchers new to cultural heritage reconstruction who wish to learn about methods to illuminate the past."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2010-02-20"/>

    <meta name="prism.volume" content="14"/>

    <meta name="prism.number" content="3"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="155"/>

    <meta name="prism.endingPage" content="182"/>

    <meta name="prism.copyright" content="2010 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-010-0154-x"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-010-0154-x"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-010-0154-x.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-010-0154-x"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Illuminating the past: state of the art"/>

    <meta name="citation_volume" content="14"/>

    <meta name="citation_issue" content="3"/>

    <meta name="citation_publication_date" content="2010/09"/>

    <meta name="citation_online_date" content="2010/02/20"/>

    <meta name="citation_firstpage" content="155"/>

    <meta name="citation_lastpage" content="182"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-010-0154-x"/>

    <meta name="DOI" content="10.1007/s10055-010-0154-x"/>

    <meta name="citation_doi" content="10.1007/s10055-010-0154-x"/>

    <meta name="description" content="Virtual reconstruction and representation of historical environments and objects have been of research interest for nearly two decades. Physically based an"/>

    <meta name="dc.creator" content="Jassim Happa"/>

    <meta name="dc.creator" content="Mark Mudge"/>

    <meta name="dc.creator" content="Kurt Debattista"/>

    <meta name="dc.creator" content="Alessandro Artusi"/>

    <meta name="dc.creator" content="Alexandrino Gon&#231;alves"/>

    <meta name="dc.creator" content="Alan Chalmers"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_title=Real-time rendering; citation_publication_date=2008; citation_id=CR4; citation_author=T Akenine-Moller; citation_author=E Haines; citation_author=N Hoffman; citation_publisher=A. K. Peters"/>

    <meta name="citation_reference" content="Aliaga DG, Law AJ, Yeung YH (2008) A virtual restoration stage for real-world objects. In: SIGGRAPH Asia &#39;08: ACM SIGGRAPH Asia 2008 papers. ACM, Newyork, pp 1&#8211;10"/>

    <meta name="citation_reference" content="Appel A (1968) Some techniques for shading machine renderings of solids. In: Proceedings of the spring joint computer conference"/>

    <meta name="citation_reference" content="Archaeological Computing Research Group, University of Southampton (2009) A polynomial texture map of an amazon statue, interactive demo. 
                    http://www.soton.ac.uk/archaeology/acrg/acrg_research_amazon.html
                    
                  
                        "/>

    <meta name="citation_reference" content="Arnold D, Geser G (2007) Research agenda for the applications of ict to cultural heritage. EPOCH publications"/>

    <meta name="citation_reference" content="Artusi A, Chetverikov D (2007) A survey of specularity removal methods. Technical Report"/>

    <meta name="citation_reference" content="Autodesk (2009a) 3DS Max website. 
                    http://www.autodesk.com/3dsmax
                    
                  
                        "/>

    <meta name="citation_reference" content="Autodesk (2009b) Maya website. 
                    http://www.autodesk.com/maya
                    
                  
                        "/>

    <meta name="citation_reference" content="Baba M, Asada N (2003) Shadow removal from a real picture. In: SIGGRAPH &#8217;03: ACM SIGGRAPH sketches &amp; applications"/>

    <meta name="citation_reference" content="Baba M, Mukunoki M, Asada N (2004) Shadow removal from a real image based on shadow density. In: SIGGRAPH &#8217;04: ACM SIGGRAPH posters"/>

    <meta name="citation_reference" content="Barbosa J, Sobral JL, Proena AJ (2007) Imaging techniques to simplify the ptm generation of a bas-relief. In: VAST &#8217;07: proceedings of the symposium on virtual reality, archaeology and cultural heritage"/>

    <meta name="citation_reference" content="Barrow H, Tanenbaum J (1978) Recovering intrinsic scene characteristic from images. Comput Vis Syst"/>

    <meta name="citation_reference" content="Beaudoin P, Paquet S, Poulin P (2001) Realistic and controllable fire simulation. In: GRIN&#8217;01: no description on graphics interface 2001"/>

    <meta name="citation_reference" content="Beraldin J-A, Picard M, El-Hakim SF, Godin G, Latouche C, Valzano V, Bandiera A (2002) Exploring a byzantine crypt through a high-resolution texture mapped 3d model: combining range data and photogrammetry. In: Proceedings of ISPRS/CIPA international workshop scanning for cultural heritage recording"/>

    <meta name="citation_reference" content="Blinn JF, Newell ME (1976) Texture and reflection in computer generated images. Commun ACM"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Graph; citation_title=The Direct3D 10 system; citation_author=D Blythe; citation_volume=25; citation_issue=3; citation_publication_date=2006; citation_pages=724-734; citation_id=CR12"/>

    <meta name="citation_reference" content="Bridault-Louchez F, Leblond M, Rousselle F (2006) Enhanced illumination of reconstructed dynamic environments using a real-time flame model. In: AFRIGRAPH &#8217;06: proceedings of the 4th international conference on computer graphics, virtual reality, visualisation and interaction in Africa"/>

    <meta name="citation_reference" content="Bridault F, Lebond M, Rousselle F, Renaud C (2007) Real-time rendering and animation of plentiful flames. In: Proceedings of the 3rd Eurographics workshop on natural phenomena"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph; citation_title=A realtime immersive application with realistic lighting: the Parthenon; citation_author=M Callieri, P Debevec, J Pair, R Scopigno; citation_volume=30; citation_issue=3; citation_publication_date=2006; citation_pages=368-376; citation_id=CR21"/>

    <meta name="citation_reference" content="Chalmers A (2002) Very realistic graphics for visualising archaeological site reconstructions. In: Proceedings of 18th spring conference on computer graphics"/>

    <meta name="citation_reference" content="Chalmers A, Green C, Hall M (2000) Firelight: graphics and archaeology. SIGGRAPH Electronic Theatre"/>

    <meta name="citation_reference" content="Chalmers A, Devlin K, Brown D, Debevec P, Martinez P, Ward G (2002) Recreating the Past. SIGGRAPH Course"/>

    <meta name="citation_reference" content="Chalmers A, Roussos I, Ledda P (2006) Authentic illumination of archaeological site reconstructions. In: CGIV&#8217;2006: IS&amp;T&#8217;s third European conference on color in graphics, imaging and vision"/>

    <meta name="citation_reference" content="Chandrasekhar S (1960) Radiative transfer. Dover Publications, New York"/>

    <meta name="citation_reference" content="Cline D, Talbot J, Egbert P (2005) Energy redistribution path tracing. In: SIGGRAPH &#8217;05: proceedings of the 32nd annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Cohen MF, Wallace J, Hanrahan P (1993) Radiosity and realistic image synthesis. Academic Press Professional, San Diego"/>

    <meta name="citation_reference" content="Cook RL, Torrance KE (1982) A reflectance model for computer graphics. ACM Trans Graph"/>

    <meta name="citation_reference" content="Cook RL, Porter T, Carpenter L (1984) Distributed ray tracing. In: SIGGRAPH &#8217;84: proceedings of the 11th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph Forum; citation_title=Stereo light probe; citation_author=M Corsini, M Callieri, P Cignoni; citation_volume=27; citation_issue=2; citation_publication_date=2008; citation_pages=291-300; citation_id=CR19"/>

    <meta name="citation_reference" content="Cucchiara R, Grana C, Piccardi M, Prati A, Sirotti S (2001) Improving shadow suppression in moving object detection with HSV color information. In: Proceedings of intelligent transportation systems"/>

    <meta name="citation_reference" content="Cultural Heritage Imaging (2009) CHI Webpage. 
                    http://www.c-h-i.org/featured_projects/featured_projects.html
                    
                  
                        "/>

    <meta name="citation_reference" content="Dachsbacher C, Stamminger M, Drettakis G, Durand F (2007) Implicit visibility and antiradiance for interactive global illumination. In: SIGGRAPH &#8217;07: proceedings of the 34th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Daubert K, Schirmacher H, Sillion F, Drettakis G (1997) Hierarchical lighting simulation for outdoor scenes. In: Proceedings of the Eurographics workshop on rendering"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph Forum; citation_title=Instant caching for interactive global illumination; citation_author=K Debattista, P Dubla, F Banterle, LP Santos, A Chalmers; citation_volume=28; citation_issue=8; citation_publication_date=2009; citation_pages=2216-2228; citation_id=CR37"/>

    <meta name="citation_reference" content="Debevec P (1998) Rendering synthetic objects into real scenes: bridging traditional and image-based graphics with global illumination and high dynamic range photography. In: SIGGRAPH &#8217;98: proceedings of the 25th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Debevec P (2001) Light probe image gallery. 
                    http://www.debevec.org/probes/
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph Appl IEEE; citation_title=Image-based lighting; citation_author=P Debevec; citation_volume=22; citation_issue=2; citation_publication_date=2002; citation_pages=26-34; citation_id=CR41"/>

    <meta name="citation_reference" content="Debevec P (2003) Image-based techniques for digitizing environments and artifacts. 3DIM: invited paper for the 4th international conference on 3-D digital imaging and modeling"/>

    <meta name="citation_reference" content="Debevec P (2005) Making &#8216;The Parthenon&#8217;. Invited paper: VAST &#8217;05: International symposium on virtual reality, archaeology, and cultural heritage"/>

    <meta name="citation_reference" content="Debevec P (2006) High resolution light probe gallery. 
                    http://www.gl.ict.usc.edu/Data/HighResProbes/
                    
                  
                        "/>

    <meta name="citation_reference" content="Debevec P, Malik J (1997) Recovering high dynamic range radiance maps from photographs. In: SIGGRAPH &#8217;97: proceedings of the 24th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Debevec P, Hawkins T, Tchou C, Duiker H-P, Sarokin W, Sagar M (2000) Acquiring the reflectance field of a human face. In: SIGGRAPH &#8217;00: proceedings of the 27th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Debevec P, Tchou C, Gardner A, Hawkins T, Poullis C, Stumpfel J, Jones A, Yun N, Einarsson P, Lundgren T, Fajardo M, Martinez P (2004) Estimating surface reflectance properties of a complex scene under captured natural illumination. In USC ICT technical report ICT-TR-06.2004"/>

    <meta name="citation_reference" content="Dellepiane M, Corsini M, Callieri M, Scopigno R (2006) High quality PTM acquisition: reflection transformation imaging for large objects. In: VAST &#8217;06: proceedings of the symposium on virtual reality, archaeology and cultural heritage"/>

    <meta name="citation_reference" content="Devlin K, Chalmers A (2001) Realistic visualisation of the pompeii frescoes. In: AFRIGRAPH &#8217;01: proceedings of the 1st international conference on computer graphics, virtual reality, visualisation and interaction in Africa"/>

    <meta name="citation_reference" content="Devlin K, Chalmers A, Brown D (2002a) Predictive lighting and perception in archaeological representations. In: UNESCO &#8220;World Heritage in the Digital Age&#8221; 30th Anniversary Digital Congress, UNESCO World Heritage Centre"/>

    <meta name="citation_reference" content="Devlin K, Chalmers A, Wilkie A, Purgathofer W (2002b) STAR report on tone reproduction and physically based spectral rendering. Eurographics"/>

    <meta name="citation_reference" content="DiCarlo JC, Wandell BA (2000) Rendering high dynamic range images. SPIE conferences"/>

    <meta name="citation_reference" content="Dorsey J, Rushmeier H, Sillion F (2008) Digital modeling of the appearance of materials. Morgan Kaufmann, San Francisco"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph Forum; citation_title=Adaptive interleaved sampling for interactive high fidelity rendering; citation_author=P Dubla, K Debattista, A Chalmers; citation_volume=28; citation_issue=8; citation_publication_date=2009; citation_pages=2117-2130; citation_id=CR38"/>

    <meta name="citation_reference" content="Earl GP (2005) Wandering the house of the birds: reconstruction and perception at roman italica. In: VAST &#8217;05: Symposium on virtual reality, archaeology and cultural heritage, short papers"/>

    <meta name="citation_reference" content="Earl CPGP (2009a) Structural and lighting models for the minoan cemetery at Phourni, crete. In: VAST &#8217;09: proceedings of the symposium on virtual reality, archaeology and cultural heritage"/>

    <meta name="citation_reference" content="Earl GP (2009b) In press physical and photo-realism: the herculaneum amazon. In: Plenary session: fundamentos tericos de la Arqueologa virtual. Proceedings of Arqueologica 2.0 Seville"/>

    <meta name="citation_reference" content="Earl GP, Keay SJ, Beale G (2008) Computer graphic modelling at portus: analysis, reconstruction and representation of the claudian and trajanic harbours. In: Proceedings of EARSEL SIG remote sensing for archaeology and cultural heritage"/>

    <meta name="citation_reference" content="Earl GP, Beale G, Happa J, Williams M, Turley G, Martinez K, Chalmers A (2009) A repainted amazon. In: Proceedings of the EVA London conference"/>

    <meta name="citation_reference" content="Egan F (1999) Fine bronze oil lamps. 
                    http://www.eganbronze.com/Pages/lamps.html
                    
                  
                        "/>

    <meta name="citation_reference" content="Einarsson P, Hawkins T, Debevec P (2004) Photometric stereo for archeological inscriptions. In: SIGGRAPH &#8217;04: ACM SIGGRAPH 2004 Sketches"/>

    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Decoding the ancient greek astronomical calculator known as the antikythera mechanism; citation_author=T Freeth, Y Bitsakis, X Moussas, J Seiradakis, A Tselikas, H Mangou, M Zafeiropoulou, R Hadland, D Bate, A Ramsey, M Allen, A Crawley, P Hockley, T Malzbender, D Gelb, W Ambrisco, M Edmunds; citation_volume=444; citation_publication_date=2006; citation_pages=587-591; citation_id=CR61"/>

    <meta name="citation_reference" content="Frischer B, Abernathy D, Guidi G, Myers J, Thibodeau C, Salvemini A, M&#252;ller P, Hofstee P, Minor B (2008) Rome reborn. In: SIGGRAPH &#8217;08: ACM SIGGRAPH new tech demos"/>

    <meta name="citation_reference" content="citation_title=Studies in ancient technology; citation_publication_date=1966; citation_id=CR62; citation_author=JR Forbes; citation_publisher=Leiden &amp; Brill"/>

    <meta name="citation_reference" content="Foni A, Papagiannakis G, Magnenat-Thalmann N (2002) Virtual hagia sophia: restitution, visualization and virtual life simulation. Presented at the UNESCO World Heritage Congress"/>

    <meta name="citation_reference" content="citation_title=Virtual archaeology: re-creating ancient worlds; citation_publication_date=1997; citation_id=CR64; citation_author=M Forte; citation_author=A Siliotti; citation_author=C Renfrew; citation_publisher=Harry N Abrams"/>

    <meta name="citation_reference" content="Gardner A, Tchou C, Hawkins T, Debevec P (2003) Linear light source reflectometry. SIGGRAPH &#8217;03: Proceedings of the 30th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Gautron P, Krivanek  J, Pattanaik S, Bouatouch K (2004) A novel hemispherical basis for accurate and efficient rendering. In: Rendering techniques 2004, Eurographics symposium on rendering"/>

    <meta name="citation_reference" content="Gautron P, Bouatouch K, Pattanaik S (2007) Temporal radiance caching. IEEE Trans Vis Comput Graph"/>

    <meta name="citation_reference" content="Glassner A (1994) Principles of digital image synthesis. Morgan Kaufmann, San Francisco"/>

    <meta name="citation_reference" content="Goodrick G, Gillings M (2000) Constructs, simulations and hyperreal worlds: the role of virtual reality (vr) in archaeological research. On the theory and practice of archaeological computing"/>

    <meta name="citation_reference" content="Gon&#231;alves A, Magalhes L, Moura J, Chalmers A (2007) Metodologia para gerao de imagens high dynamic range em iluminao romana. In: Proceedings of international association for the scientific knowledge InterTIC&#8217;07"/>

    <meta name="citation_reference" content="Gon&#231;alves A, Magalhes L, Moura J, Chalmers A (2008) Accurate modelling of roman lamps in conimbriga using high dynamic range. In: VAST &#8217;08: proceedings of the symposium on virtual reality, archaeology and cultural heritage"/>

    <meta name="citation_reference" content="Gon&#231;alves A, Magalhes L, Moura J, Chalmers A (2009) High dynamic range&#8212;a gateway for predictive ancient lighting. ACM J Comput Cult Herit"/>

    <meta name="citation_reference" content="Gutierrez D, Sundstedt V, Gomez F, Chalmers A (2006) Dust and light: predictive virtual archaeology. J Cult Herit"/>

    <meta name="citation_reference" content="Gutierrez D, Sundstedt V, Gomez F, Chalmers A (2008) Modeling light scattering for virtual heritage. J Comput Cult Herit"/>

    <meta name="citation_reference" content="Glencross M, Ward G, Melendez F, Jay C, Liu J, Hubbold R (2008) A perceptually validated model for surface depth hallucination. In: SIGGRAPH &#8217;08: proceedings of the 35th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Goral CM, Torrance KE, Greenberg DP, Battaile B (1984) Modeling the interaction of light between diffuse surfaces. In: SIGGRAPH &#8217;84: proceedings of the 11th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Gutierrez D, Seron F, Magallon J, Sobreviela E, Latorre P (2004) Archaeological and cultural heritage: bringing life to an unearthed muslim suburb in an immersive environment. J Cult Herit"/>

    <meta name="citation_reference" content="Happa J, Artusi A, Dubla P, Bashford-Rogers T, Debattista K, Hulusi&#263; V, Chalmers A (2009) The virtual reconstruction and daylight illumination of the panagia angeloktisti. In: VAST &#8217;09: proceedings of the symposium on virtual reality, archaeology and cultural heritage"/>

    <meta name="citation_reference" content="Hawkins T, Cohen J, Debevec P (2001) A photometric approach to digitizing cultural artifacts. In: VAST &#8217;01: proceedings of the symposium on virtual reality, archeology, and cultural heritage"/>

    <meta name="citation_reference" content="Hawkins T, Einarsson P, Debevec P (2005) Acquisition of time-varying participating media. In: SIGGRAPH &#8217;05: proceedings of the 32nd annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Hachisuka T, Ogaki S, Jensen HW (2008) Progressive photon mapping. In: SIGGRAPH Asia &#8217;08: ACM SIGGRAPH Asia papers"/>

    <meta name="citation_reference" content="HDRShop (2001) Example software to research hdri. 
                    http://www.gl.ict.usc.edu/HDRShop/
                    
                  
                        "/>

    <meta name="citation_reference" content="Happa J, Williams M, Turley G, Earl GP, Dubla P, Beale G, Gibbons G, Debattista K, Chalmers A (2009) Virtual relighting of a roman statue head from herculaneum: a case study. In: AFRIGRAPH &#8217;09: proceedings of the 6th international conference on computer graphics, virtual reality, visualisation and interaction in Africa"/>

    <meta name="citation_reference" content="Hasinoff SW, Kutulakos KN (2003) Photo-consistent 3d fire by flame-sheet decomposition. In: ICCV &#8217;03: proceedings of the ninth IEEE international conference on computer vision"/>

    <meta name="citation_reference" content="Hewlett-Packard (2009) Polynomial texture mapping&#8212;interactive relighting software licence. 
                    http://www.hpl.hp.com/research/ptm/downloads/agreement.html
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_title=Sensitivity to light. Handbook of perception and human performance; citation_publication_date=1986; citation_id=CR81; citation_author=D Hood; citation_author=M Finkelstein; citation_publisher=Wiley"/>

    <meta name="citation_reference" content="Igawa N, Koga Y, Matsuzawa T, Nakamura H (2004) Models of sky radiance distribution and sky luminance distribution. Solar Energy"/>

    <meta name="citation_reference" content="Ihrke I, Magnor M (2004) Image-based tomographic reconstruction of flames. In: SCA &#8217;04: proceedings of the ACM SIGGRAPH/Eurographics symposium on computer animation"/>

    <meta name="citation_reference" content="Inakage M (1990) A simple model of flames. In: CG international &#8217;90: proceedings of the eighth international conference of the computer graphics society on CG international &#8217;90: computer graphics around the world"/>

    <meta name="citation_reference" content="Iwasaki K, Dobashi Y, Yoshimoto F, Nishita T (2007) Precomputed radiance transfer for dynamics scene taking into account light inter-reflection. In: Eurographics symposium on rendering"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Graph; citation_title=Radiance caching for participating media; citation_author=W Jarosz, C Donner, M Zwicker, HW Jensen; citation_volume=27; citation_issue=1; citation_publication_date=2008; citation_pages=1-11; citation_id=CR92"/>

    <meta name="citation_reference" content="Jensen HW (2001) Realistic image synthesis using photon mapping. A.K. Peters, Natick"/>

    <meta name="citation_reference" content="Jensen HW, Christensen PH (1998) Efficient simulation of light transport in scences with participating media using photon maps. In: SIGGRAPH &#8217;98: proceedings of the 25th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Jensen HW, Durand F, Stark M, Premoze S, Dorsey J, Shirley P (2001a) A physically based nightsky model. In: SIGGRAPH &#8217;01: proceedings of the 28th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Jensen HW, Marschner SR, Levoy M, Hanrahan P (2001b) A practical model for subsurface light transport. In: SIGGRAPH &#8217;01: proceedings of the 28th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Kang SB, Uyttendaele M, Winder S, Szeliski R (2003) High dynamic range video. ACM Trans Graph"/>

    <meta name="citation_reference" content="Kajiya J (1986) The rendering equation. In: SIGGRAPH &#8217;86: proceedings of the 13th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Keller A (1997) Instant radiosity. In: SIGGRAPH &#8217;97: proceedings of the 24th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Keng S-L, Lee W-Y, Chuang J-H (2006) An efficient caching-based rendering of translucent materials. Vis Comput: Int J Comput Graph"/>

    <meta name="citation_reference" content="Kider JT, Fletcher RL, Yu N, Holod R, Chalmers A, Badler NI (2009) Recreating early islamic glass lamp lighting. In: VAST &#8217;09: proceedings of the symposium on virtual reality, archaeology and cultural heritage"/>

    <meta name="citation_reference" content="Klinker GJ, Shafer SA, Kannade T (1987) Using a color reflection model to separate highlights from object color. In: Proceedings 1st international conference on computer vision, IEEE London"/>

    <meta name="citation_reference" content="Klinker GJ, Shafer SA, Kannade T (1990a) The measurement of highlights in color images. Int J Comput Vis"/>

    <meta name="citation_reference" content="Klinker GJ, Shafer SA, Kannade T (1990b) A physical approach to color image understanding. Int J Comput Vis"/>

    <meta name="citation_reference" content="Kim D, Lin S, Hong K, Shum H (2002) Variational specular separation using color and polarization. In: IAPR workshop on machine vision applications"/>

    <meta name="citation_reference" content="citation_journal_title=J Chromatogr A; citation_title=Analysis of oil used in late roman oil lamps with different mass spectrometric techniques revealed the presence of predominantly olive oil together with traces of animal fat; citation_author=K Kimpe, PA Jacobs, M Waelkens; citation_volume=937; citation_issue=1&#8211;2; citation_publication_date=2001; citation_pages=87-95; citation_id=CR100"/>

    <meta name="citation_reference" content="Koller D, Turitzin M, Levoy M, Tarini M, Croccia G, Cignoni P, Scopigno R (2004) Protected interactive 3d graphics via remote rendering. In: SIGGRAPH &#8217;04: proceedings of the 31st annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="K&#345;iv&#225;nek J, Gautron P, Pattanaik S, Bouatouch K (2005) Radiance caching for efficient global illumination computation. IEEE Trans Vis and Comput Graph"/>

    <meta name="citation_reference" content="citation_journal_title=J Vis Commun Image Represent; citation_title=iCAM06: a refined image appearance model for HDR image rendering; citation_author=J Kuang, GM Johnson, MD Fairchild; citation_volume=18; citation_issue=5; citation_publication_date=2007; citation_pages=406-414; citation_id=CR99"/>

    <meta name="citation_reference" content="Lafortune E, Foo S-C, Torrance K, Greenberg D (1997) Non-linear approximation of reflectance functions. In: SIGGRAPH &#8217;97: proceedings of the 24th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Lai Y-C, Fan SH, Chenney S, Dyer C (2007) Rendering techniques. In: Kautz J, Pattanaik S (eds) Photorealistic image rendering with population Monte Carlo energy redistribution"/>

    <meta name="citation_reference" content="Lamorlette A, Foster N (2002) Structural modeling of flames for a production environment. In: SIGGRAPH &#8217;02: proceedings of the 29th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Ledda P, Santos LP, Chalmers A (2004) A local model of eye adaptation for high dynamic range images. In: AFRIGRAPH &#8217;04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa"/>

    <meta name="citation_reference" content="Lin S, Li Y, Kang SB, Tong X, Shum HY (2002) Diffuse-specular separation and depth recovery from image sequences. In: European conference on computer vision"/>

    <meta name="citation_reference" content="Lin S, Tan P, Quan L (2006) Separation of highlight reflections on texture surfaces. In: IEEE conference on computer vision and pattern recognition 2006"/>

    <meta name="citation_reference" content="Mallick SP, Zickler T, Kriegman DJ, Belhumeur PN (2006) Specularity removal in images and videos: a pde approach. In: Proceedings European conference computer vision"/>

    <meta name="citation_reference" content="Mann S, Picard RW (1995) Being &#8220;undigital&#8221; with digital cameras: extending dynamic range by combining differently exposed pictures. In: Proceedings of IS&amp;T 46th annual conference"/>

    <meta name="citation_reference" content="Malzbender T (2006) Tom malzbender publication list. 
                    http://www.hpl.hp.com/personal/Tom_Malzbender/
                    
                  
                        "/>

    <meta name="citation_reference" content="Malzbender T, Ordentlict E (2005) Maximum entropy lighting for physical objects. Hewlett-Packard Technical Report HPL-2005-68"/>

    <meta name="citation_reference" content="Malzbender T, Gelb D, Wolters H (2001) Polynomial texture maps. In: SIGGRAPH &#8217;01: proceedings of the 28th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Martinez P (2001) Digital realities and archaeology: a difficult relationship or a fruitful marriage? In: VAST &#8217;01: proceedings of the symposium on virtual reality, archeology, and cultural heritage"/>

    <meta name="citation_reference" content="Melek Z, Keyser J (2002) Interactive simulation of fire. Technical Report 2002-7-1, Texas A&amp;M University, Department of Computer Science"/>

    <meta name="citation_reference" content="Mental Images (2009) Mental ray company website. 
                    http://www.mentalimages.com/
                    
                  
                        "/>

    <meta name="citation_reference" content="Mitsunaga T, Nayar S (1999) Radiometric self calibration. In: IEEE conference on computer vision and pattern recognition (CVPR)"/>

    <meta name="citation_reference" content="Mudge M (2004) Implementing digital technology adoption by cultural heritage professionalsl. SIGGRAPH &#8217;04: Conference presentations for cultural heritage and computer graphics panel"/>

    <meta name="citation_reference" content="Mudge M, Voutaz J-P, Schroer C, Lum M (2005) Reflection transformation imaging and virtual representations of coins from the hospice of the grand St. Bernard. In: VAST &#8217;05: proceedings of the symposium on virtual reality, archaeology and cultural heritage"/>

    <meta name="citation_reference" content="Mudge M, Malzbender T, Schroer C, Lum M (2006) New reflection transformation imaging methods for rock art and multiple viewpoint display. VAST &#8217;06: Proceedings of the symposium on virtual reality, archaeology and cultural heritage"/>

    <meta name="citation_reference" content="Mudge M, Malzbender T, Chalmers A, Scopigno R, Davis J, Wang O, Gunawardane P, Ashley M, Doerr M, Proenca A, Barbosa J (2008) Image-based empirical acquisition, scientific reliability, and long-term digital preservation for the natural sciences and cultural heritage. Eurographics Tutorial Notes"/>

    <meta name="citation_reference" content="Nayar S, Branzoi V (2003) Adaptive dynamic range imaging: optical control of pixel exposures over space and time. In: IEEE international conference on computer vision (ICCV)"/>

    <meta name="citation_reference" content="Nayar SK, Fang X, Boult T (1997) Separation of reflection components using color and polarization. Int J Comput Vis"/>

    <meta name="citation_reference" content="Nguyen DQ, Fedkiw R, Jensen HW (2002) Physically based modeling and animation of fire. SIGGRAPH &#8217;02: Proceedings of the 29th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Panoscan (2002) Panoscan MK-3, Company website. 
                    http://www.panoscan.com/
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph Forum; citation_title=Precomputed radiance transfer field for rendering inter-reflections in dynamic scenes; citation_author=M Pan, R Wang, X Liu, Q Peng, H Bao; citation_volume=26; citation_issue=3; citation_publication_date=2007; citation_pages=485-493; citation_id=CR138"/>

    <meta name="citation_reference" content="Perry CH, Picard RW (1994) Synthesizing flames and their spreading. In: Proceedings of the 5th Eurographics workshop on animation and simulation"/>

    <meta name="citation_reference" content="Pegoraro V, Parker SG (2006) Pshysically based realistic fire rendering. In: Proceedings of the 2nd Eurographics workshop on natural phenomena"/>

    <meta name="citation_reference" content="Perez R, Seals R, Ineichen P (1993) An allweather model for skyluminance distribution. Solar Energy"/>

    <meta name="citation_reference" content="citation_title=Physically based rendering: from theory to implementation; citation_publication_date=2004; citation_id=CR132; citation_author=M Pharr; citation_author=G Humphreys; citation_publisher=Morgan Kaufmann"/>

    <meta name="citation_reference" content="Preetham A, Shirley P, Smits B (1999) A practical analytic model for daylight. In: SIGGRAPH &#8217;99: proceedings of the 26th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Raczkowski J (1996) Visual simulation and animation of a laminar candle flame. In: International conference on image processing and computer graphics"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Graph; citation_title=Particle systems&#8212;a technique for modeling a class of fuzzy objects; citation_author=WT Reeves; citation_volume=2; citation_issue=2; citation_publication_date=1983; citation_pages=91-108; citation_id=CR143"/>

    <meta name="citation_reference" content="Reilly P (1991) Towards a virtual archaeology. Comput Appl Quant Methods Archaeol"/>

    <meta name="citation_reference" content="citation_title=High dynamic range imaging: acquisition, display, and image-based lighting; citation_publication_date=2005; citation_id=CR149; citation_author=E Reinhard; citation_author=G Ward; citation_author=S Pattanaik; citation_author=P Debevec; citation_publisher=Morgan Kaufmann"/>

    <meta name="citation_reference" content="Ritschel T, Grosch T, Kim MH, Seidel H-P, Dachsbacher C, Kautz J (2008) Imperfect shadow maps for efficient computation of indirect illumination. SIGGRAPH Asia &#8217;08: ACM SIGGRAPH Asia papers"/>

    <meta name="citation_reference" content="Ritschel T, Ihrke M, Frisvad JR, Coppens J, Myszkowski K, Seidel H-P (2009) Temporal glare: real-time dynamic simulation of the scattering in the human eye. Eurographics"/>

    <meta name="citation_reference" content="Robertson MA, Borman S, Stevenson RL (1999) Dynamic range improvement through multiple exposures. In: Proceedings of the 1999 international conference on image processing (ICIP-99)"/>

    <meta name="citation_reference" content="citation_journal_title=J Electron Imaging; citation_title=Estimation-theoretic approach to dynamic range enhancement using multiple exposures; citation_author=MA Robertson, S Borman, RL Stevenson; citation_volume=12; citation_issue=2; citation_publication_date=2003; citation_pages=219-228; citation_id=CR141"/>

    <meta name="citation_reference" content="Roberts J, Ryan N (1997) Alternative archaeological representations within virtual worlds. In: Proceedings of the 4th UK virtual reality specialist interest group conference&#8212;Brunel University"/>

    <meta name="citation_reference" content="Roussos I, Chalmers A (2003) High fidelity lighting of knossos. In: VAST &#8217;03: proceedings of the symposium on virtual reality, archaeology and intelligent cultural heritage"/>

    <meta name="citation_reference" content="Rushmeier H (1995) Rendering participating media: problems and solutions from application areas. In: Proceedings of the 5th Eurographics workshop on rendering, Springer"/>

    <meta name="citation_reference" content="Salvador E, Ebrahimi T (2001) Shadow identification and classification using invariant color models"/>

    <meta name="citation_reference" content="Sander P (2006) The Parthenon demo preprocessing and real-time rendering techniques for large datasets. SIGGRAPH"/>

    <meta name="citation_reference" content="Schlns K, Teschner M (1995a) Analysis of 2d color spaces for highlight elimination in 3d shape reconstruction. In: Proceedings ACCV"/>

    <meta name="citation_reference" content="Schlns K, Teschner M (1995b) Fast separation of reflection components and its application in 3d shape recovery. In: Proceedings 3rd color imaging conference"/>

    <meta name="citation_reference" content="Seetzen H, Heidrich W, Stuerzlinger W, Ward G, Whitehead L, Trentacoste M, Ghosh A, Vorozcovs A (2004) High dynamic range display systems. In: SIGGRAPH &#39;04: ACM SIGGRAPH 2004 Emerging technologies. ACM, New York, p 8"/>

    <meta name="citation_reference" content="Shafer S (1984) Using color to separate reflection components. Technical Report"/>

    <meta name="citation_reference" content="Shreiner D, Woo M, Neider J, Davis T (2004) OpenGL(R) 1.4 Reference manual, 4th edn. Addison Wesley Longman Publishing Co., Inc"/>

    <meta name="citation_reference" content="Sloan P-P, Kautz J, Snyder J (2002) Precomputed radiance transfer for real-time rendering in dynamic, low-frequency lighting environments. In: SIGGRAPH &#8217;02: proceedings of the 29th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph Forum; citation_title=Into the blue: better caustics through photon relaxation; citation_author=B Spencer, MW Jones; citation_volume=28; citation_issue=2; citation_publication_date=2009; citation_pages=319-328; citation_id=CR156"/>

    <meta name="citation_reference" content="Spheron (2002) SpherOn HDR, Company website. 
                    http://www.spheron.com/
                    
                  
                        "/>

    <meta name="citation_reference" content="Stam J, Fiume E (1995) Depicting fire and other gaseous phenomena using diffusion processes. In: SIGGRAPH &#8217;95: proceedings of the 22nd annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Stumpfel J, Jones A, Wenger A, Tchou C, Hawkins T, Debevec P (2004) Direct HDR capture of the sun and sky. In: AFRIGRAPH &#8217;04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa"/>

    <meta name="citation_reference" content="Sundstedt V, Chalmers A, Martinez P (2004) High fidelity reconstruction of the ancient egyptian temple of kalabsha. In: AFRIGRAPH &#8217;04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa"/>

    <meta name="citation_reference" content="Sundstedt V, Gutierrez D, Gomez F, Chalmers A (2005) Participating media for high-fidelity cultural heritage. In: VAST &#8217;05: proceedings of the symposium on virtual reality, archaeology and cultural heritage"/>

    <meta name="citation_reference" content="Takahashi J-y, Takahashi H, Chiba N (1997) Image synthesis of flickering scenes including simulated flames. IEICE Trans Inf Syst"/>

    <meta name="citation_reference" content="Tan R, Ikeuchi K (2003) Separating reflection components of terxtured surfaces using a single image. In: Proceeding IEEE international conference on computer vision ICCV"/>

    <meta name="citation_reference" content="Tan R, Ikeuchi K (2004) Intrinsic properties of an image with highlights. Meeting on image recognition and understanding MIRU 2004"/>

    <meta name="citation_reference" content="Tan P, Lin S, Quan L (2006) Separation of highlight reflections on texture surfaces. In: IEEE conference on computer vision and pattern recognition"/>

    <meta name="citation_reference" content="Tappen MF, Freeman WT, Adelson EH (2005) Recovering intrinsic images from a single image. IEEE Trans Pattern Anal Mach Intell"/>

    <meta name="citation_reference" content="The reasearch team included Tom Malzbender from HPLabs (1998) James Davis, Oliver Wang and Prabath Gunawardane from the University of California Santa Cruz, Martin Doerr and Steve Stead from The International Council of Museum&#8217;s (ICOM) Documentation Committee&#8217;s (CIDOC) Conceptual Reference Model (CRM) Special Interest Group, Roberto Scopigno, Paolo Cignoni, Massimiliano Corsini and Gianpaolo Palma from the Institute of Information Science and Technology (ISTI), Alberto Proenca and Joao Barbosa from the High Peformance Computing Center at the University of Minho, Alan Chalmers from the University of Warwick, and Holly Rushmeier from Yale"/>

    <meta name="citation_reference" content="Unger J (2009) Incident light fields. PhD thesis, Linkping University"/>

    <meta name="citation_reference" content="Veach E, Guibas LJ (1997) Metropolis light transport. In: SIGGRAPH &#8217;97: proceedings of the 24th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Wang R, Akerlund O (2009) Bidirectional importance sampling for unstructured illuminationn. Eurographics"/>

    <meta name="citation_reference" content="Ward GJ (1992) Measuring and modeling anisotropic reflection. SIGGRAPH &#8217;92: Proceedings of the 19th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Ward G (1994) The radiance lighting simulation and rendering system. In: SIGGRAPH &#8217;94: proceedings of the 21st annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Graph; citation_title=Lightcuts: a scalable approach to illumination; citation_author=B Walter, S Fernandez, A Arbree, K Bala, M Donikian, DP Greenberg; citation_volume=24; citation_issue=3; citation_publication_date=2005; citation_pages=1098-1107; citation_id=CR175"/>

    <meta name="citation_reference" content="Walter B, Arbree A, Bala K, Greenberg DP (2006) Multidimensional lightcuts. ACM Trans Graph"/>

    <meta name="citation_reference" content="Wang O, Gunawardane P, Scher S, Davis J (2009) Material classification using BRDF slices. IEEE conference on computer vision and pattern recognition"/>

    <meta name="citation_reference" content="Wald I, Mark WR, G&#252;nther J, Boulos S, Ize T, Hunt W, Parker SG, Shirley P (2007) State of the art in ray tracing animated scenes. Eurographics"/>

    <meta name="citation_reference" content="Ward G, Shakespeare R (2003) Rendering with radiance: the art and science of lighting visualisation (Revised edition). Morgan Kaufmann, San Francisco"/>

    <meta name="citation_reference" content="Ward G, Rubinstein FM, Clear RD (1988) A ray tracing solution for diffuse inter-reflection. In: SIGGRAPH &#8217;88: proceedings of the 15th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Wang R, Wang R, Zhou K, Pan M, Bao H (2009) An efficient gpu-based approach for interactive global illumination. In: SIGGRAPH &#8217;09: proceedings of the 36th annual conference on computer graphics and interactive techniques"/>

    <meta name="citation_reference" content="Weiss Y (2001) Deriving intrinsic images from image sequences. In: Proceeding IEEE international conference on computer vision ICCV"/>

    <meta name="citation_reference" content="citation_journal_title=Commun ACM; citation_title=An improved illumination model for shaded display; citation_author=T Whitted; citation_volume=23; citation_issue=6; citation_publication_date=1980; citation_pages=343-349; citation_id=CR177"/>

    <meta name="citation_reference" content="Yoon KJ, Choi Y, Kweon IS (2006) Fast separation of reflection components using a specularity-invariant image representation. In: IEEE international conference on image processing ICIP"/>

    <meta name="citation_reference" content="Z&#225;nyi E, Chrysanthou Y, Bashford-Rogers T, Chalmers A (2007a) High dynamic range display of authentically illuminated byzantine art from Cyprus. In: VAST &#8217;07: proceedings of the symposium on virtual reality, archaeology and cultural heritage"/>

    <meta name="citation_reference" content="Z&#225;nyi E, Schroer C, Mudge MAC (2007b) Lighting and byzantine glass tesserae. In: Proceedings of the 2009 EVA London conference"/>

    <meta name="citation_author" content="Jassim Happa"/>

    <meta name="citation_author_email" content="j.happa@warwick.ac.uk"/>

    <meta name="citation_author_institution" content="International Digital Laboratory, University of Warwick, Coventry, UK"/>

    <meta name="citation_author" content="Mark Mudge"/>

    <meta name="citation_author_email" content="mark@c-h-i.org"/>

    <meta name="citation_author_institution" content="Cultural Heritage Imaging, San Francisco, USA"/>

    <meta name="citation_author" content="Kurt Debattista"/>

    <meta name="citation_author_email" content="k.debattista@warwick.ac.uk"/>

    <meta name="citation_author_institution" content="International Digital Laboratory, University of Warwick, Coventry, UK"/>

    <meta name="citation_author" content="Alessandro Artusi"/>

    <meta name="citation_author_email" content="artusialessandro4@googlemail.com"/>

    <meta name="citation_author_institution" content="CASToRC Cyprus Institute, Nicosia, Cyprus"/>

    <meta name="citation_author" content="Alexandrino Gon&#231;alves"/>

    <meta name="citation_author_email" content="alex@estg.ipleiria.pt"/>

    <meta name="citation_author_institution" content="Research Center for Informatics and Communications, Polytechnic Institute of Leiria, Leiria, Portugal"/>

    <meta name="citation_author" content="Alan Chalmers"/>

    <meta name="citation_author_email" content="a.g.chalmers@warwick.ac.uk"/>

    <meta name="citation_author_institution" content="International Digital Laboratory, University of Warwick, Coventry, UK"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-010-0154-x&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2010/09/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-010-0154-x"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Illuminating the past: state of the art"/>
        <meta property="og:description" content="Virtual reconstruction and representation of historical environments and objects have been of research interest for nearly two decades. Physically based and historically accurate illumination allows archaeologists and historians to authentically visualise a past environment to deduce new knowledge. This report reviews the current state of illuminating cultural heritage sites and objects using computer graphics for scientific, preservation and research purposes. We present the most noteworthy and up-to-date examples of reconstructions employing appropriate illumination models in object and image space, and in the visual perception domain. Finally, we also discuss the difficulties in rendering, documentation, validation and identify probable research challenges for the future. The report is aimed for researchers new to cultural heritage reconstruction who wish to learn about methods to illuminate the past."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Illuminating the past: state of the art | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-010-0154-x","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Cultural heritage, Computer graphics, Image-processing, Rendering, Global illumination, Reflectance transformation imaging, High dynamic range imaging, Sky modelling, Flame modelling, Colour science, Visual perception","kwrd":["Cultural_heritage","Computer_graphics","Image-processing","Rendering","Global_illumination","Reflectance_transformation_imaging","High_dynamic_range_imaging","Sky_modelling","Flame_modelling","Colour_science","Visual_perception"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-010-0154-x","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-010-0154-x","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=154;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-010-0154-x">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Illuminating the past: state of the art
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-010-0154-x.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-010-0154-x.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2010-02-20" itemprop="datePublished">20 February 2010</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Illuminating the past: state of the art</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Jassim-Happa" data-author-popup="auth-Jassim-Happa" data-corresp-id="c1">Jassim Happa<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Warwick" /><meta itemprop="address" content="grid.7372.1, 0000000088091613, International Digital Laboratory, University of Warwick, Coventry, UK" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Mark-Mudge" data-author-popup="auth-Mark-Mudge">Mark Mudge</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Cultural Heritage Imaging" /><meta itemprop="address" content="Cultural Heritage Imaging, San Francisco, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Kurt-Debattista" data-author-popup="auth-Kurt-Debattista">Kurt Debattista</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Warwick" /><meta itemprop="address" content="grid.7372.1, 0000000088091613, International Digital Laboratory, University of Warwick, Coventry, UK" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Alessandro-Artusi" data-author-popup="auth-Alessandro-Artusi">Alessandro Artusi</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="CASToRC Cyprus Institute" /><meta itemprop="address" content="grid.426429.f, 0000000405803152, CASToRC Cyprus Institute, Nicosia, Cyprus" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Alexandrino-Gon_alves" data-author-popup="auth-Alexandrino-Gon_alves">Alexandrino Gonçalves</a></span><sup class="u-js-hide"><a href="#Aff4">4</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Polytechnic Institute of Leiria" /><meta itemprop="address" content="grid.36895.31, 0000000121116991, Research Center for Informatics and Communications, Polytechnic Institute of Leiria, Leiria, Portugal" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Alan-Chalmers" data-author-popup="auth-Alan-Chalmers">Alan Chalmers</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Warwick" /><meta itemprop="address" content="grid.7372.1, 0000000088091613, International Digital Laboratory, University of Warwick, Coventry, UK" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 14</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">155</span>–<span itemprop="pageEnd">182</span>(<span data-test="article-publication-year">2010</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">728 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">19 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-010-0154-x/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Virtual reconstruction and representation of historical environments and objects have been of research interest for nearly two decades. Physically based and historically accurate illumination allows archaeologists and historians to authentically visualise a past environment to deduce new knowledge. This report reviews the current state of illuminating cultural heritage sites and objects using computer graphics for scientific, preservation and research purposes. We present the most noteworthy and up-to-date examples of reconstructions employing appropriate illumination models in object and image space, and in the visual perception domain. Finally, we also discuss the difficulties in rendering, documentation, validation and identify probable research challenges for the future. The report is aimed for researchers new to cultural heritage reconstruction who wish to learn about methods to illuminate the past.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Past societies relied entirely on daylight and flames for lighting before electricity became available. Under modern day lighting conditions, ancient environments may appear significantly different from when they were first built and used in the past. Furthermore, the site itself may have changed several times over the years. Computer graphics aid the possibility of reconstructing a site, and its lighting, as it may have appeared at any stage in time.</p><p>Employing computer graphics to reconstruct cultural heritage environments and objects is no longer a novelty (Forte et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Forte M, Siliotti A, Renfrew C (1997) Virtual archaeology: re-creating ancient worlds. Harry N Abrams, New York" href="/article/10.1007/s10055-010-0154-x#ref-CR64" id="ref-link-section-d40580e424">1997</a>; Reilly <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Reilly P (1991) Towards a virtual archaeology. Comput Appl Quant Methods Archaeol" href="/article/10.1007/s10055-010-0154-x#ref-CR144" id="ref-link-section-d40580e427">1991</a>). The first few examples discussing virtual reconstruction of cultural heritage dealt primarily with displaying geometry using simple lighting models. Today, realistic virtual reconstructions are used by the media, the film and computer games industries, museums and researchers. In order for the photorealistic visualisation to be of scientific value, it is necessary to recreate illumination of cultural heritage reconstructions to be both physically and historically accurate as possible. This can be described as <i>Authentic Illumination</i> (Chalmers et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Chalmers A, Roussos I, Ledda P (2006) Authentic illumination of archaeological site reconstructions. In: CGIV’2006: IS&amp;T’s third European conference on color in graphics, imaging and vision" href="/article/10.1007/s10055-010-0154-x#ref-CR28" id="ref-link-section-d40580e433">2006</a>) and can highlight aspects of a reconstruction that would otherwise not be present using simpler lighting models. Great care must be taken to ensure that the illumination model adopted is validated. Due to lack of historical reference material, any model will always be a scientific best-guess, and must be updated each time new data regarding the site or object is found.</p><p>Techniques may also be used to study how the appearance of an object today has deteriorated over time and highlight details on surfaces that would not stand out in natural light today. Such approaches enable us to gain insights about the past that are not possible through any other means. The study of illumination for the past allows us to visualise environments in their former, correct context to further our understanding of how our ancestors lived and experienced the world. This may in turn affect our appreciation of our history and its relation to the modern society and us as individual human beings.</p><p>This report consists of two main parts. Part 1 reviews enabling methods and technologies that can be employed for illuminating virtual reconstructions. In this first part, Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-010-0154-x#Sec2">2</a> presents a summary of existing common technologies for acquiring light data. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-010-0154-x#Sec3">3</a> discusses existing methods of removing lighting artefacts such as specular highlights and shadows in photographs. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-010-0154-x#Sec4">4</a> details the uses of <i>High Dynamic Range Imaging</i> (HDRI). Rendering approaches are presented in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-010-0154-x#Sec5">5</a>. Methods of modelling participating media (fog, smoke, dust etc.) are also summarised in this section. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-010-0154-x#Sec9">6</a> describes techniques for recreating sunlight. <i>Reflectance Transformation Imaging</i> (RTI) and its applications are reviewed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-010-0154-x#Sec11">7</a>. Finally, methods to model flames are described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-010-0154-x#Sec14">8</a>.</p><p>Part 2 of this report presents an overview of existing virtual reconstructions that have a focus on authentic illumination, but also overviews examples of image space approaches and applications of visual perception in the cultural heritage domain. These are all reviewed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-010-0154-x#Sec22">9</a>. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-010-0154-x#Sec29">10</a> discusses the reoccurring primary difficulties in rendering, documentation and validation of reconstructions in a cultural heritage context, and overviews additional applications of authentic illumination for potential future work.</p><p>
                <b>Part 1:</b>
                <b>Enabling methods and technologies</b>
              </p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Common equipment</h2><div class="c-article-section__content" id="Sec2-content"><p>Several technologies today are available for capturing and rendering light. A short list of the most common items used is listed here, while more specialised equipment is detailed in their respective sections:</p><p><i>Single-lens reflex</i> (SLR) cameras are useful for capturing photographic references of a scene. These can be used not only for geometry reference purposes, texture mapping, but also for capturing incident lighting from the scene. A light meter is capable of determining what shutter speed and aperture is best suited for cameras with the current lighting condition in the real world. <i>Spectroradiometers/spectrophotometers</i> are devices capable of measuring attributes of sampled light, this includes <i>Spectral Radiance</i> (wavelengths), <i>Luminance</i> (amount of light emitted from or passing through a particular area) and <i>Chromaticity</i> (the quality of a colour sample, disregarding its luminance). These devices, however, do not provide information about ideal camera settings.</p><p>There are currently many rendering packages available; <i>Radiance</i> (Ward and Shakespeare <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Ward G, Shakespeare R (2003) Rendering with radiance: the art and science of lighting visualisation (Revised edition). Morgan Kaufmann, San Francisco" href="/article/10.1007/s10055-010-0154-x#ref-CR180" id="ref-link-section-d40580e518">2003</a>), <i>3DS Max</i> (Autodesk <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009a" title="Autodesk (2009a) 3DS Max website. &#xA;                    http://www.autodesk.com/3dsmax&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR7" id="ref-link-section-d40580e524">2009a</a>), <i>Maya</i> (Autodesk <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009b" title="Autodesk (2009b) Maya website. &#xA;                    http://www.autodesk.com/maya&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR8" id="ref-link-section-d40580e531">2009b</a>), <i>Mental Ray</i> (Mental <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Mental Images (2009) Mental ray company website. &#xA;                    http://www.mentalimages.com/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR116" id="ref-link-section-d40580e537">2009</a>) and <i>PBRT</i> (Pharr and Humphreys <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Pharr M, Humphreys G (2004) Physically based rendering: from theory to implementation. Morgan Kaufmann, San Francisco" href="/article/10.1007/s10055-010-0154-x#ref-CR132" id="ref-link-section-d40580e543">2004</a>) are some of the most common rendering applications today. Radiance is a suite of programs made for the analysis and visualisation of lighting in design (Ward <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Ward G (1994) The radiance lighting simulation and rendering system. In: SIGGRAPH ’94: proceedings of the 21st annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR173" id="ref-link-section-d40580e546">1994</a>; Ward and Shakespeare <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Ward G, Shakespeare R (2003) Rendering with radiance: the art and science of lighting visualisation (Revised edition). Morgan Kaufmann, San Francisco" href="/article/10.1007/s10055-010-0154-x#ref-CR180" id="ref-link-section-d40580e550">2003</a>). It is open source, has been used for several cultural heritage reconstructions and is widely employed in academic settings. In this report, several examples will be highlighted with Radiance in mind.</p></div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Removing existing lighting and artefacts</h2><div class="c-article-section__content" id="Sec3-content"><p>The acquisition of texture maps using a camera does not capture all material properties and may contain specularities (highlights) or shadows that need to be removed before these textures can be included into a realistic relighting of the virtual reconstruction. Lin et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Lin S, Tan P, Quan L (2006) Separation of highlight reflections on texture surfaces. In: IEEE conference on computer vision and pattern recognition 2006" href="/article/10.1007/s10055-010-0154-x#ref-CR113" id="ref-link-section-d40580e561">2006</a>), Shafer (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1984" title="Shafer S (1984) Using color to separate reflection components. Technical Report" href="/article/10.1007/s10055-010-0154-x#ref-CR154" id="ref-link-section-d40580e564">1984</a>), Tan and Ikeuchi (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Tan R, Ikeuchi K (2004) Intrinsic properties of an image with highlights. Meeting on image recognition and understanding MIRU 2004" href="/article/10.1007/s10055-010-0154-x#ref-CR166" id="ref-link-section-d40580e567">2004</a>) discuss specular removal problems in greater detail. The presence of specular reflections in the real world is inevitable as there exist several materials that will show both diffuse and specular reflections. Shadows are also common artefacts that are determined by the position of a light source when the photograph of the texture is acquired. Failure to remove highlights and shadows from an acquired texture map can significantly alter its appearance. Specular reflections for instance hide surface details and may appear as additional features to the material of the object surface (Tan et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Tan P, Lin S, Quan L (2006) Separation of highlight reflections on texture surfaces. In: IEEE conference on computer vision and pattern recognition" href="/article/10.1007/s10055-010-0154-x#ref-CR133" id="ref-link-section-d40580e570">2006</a>).</p><p>Specularity and shadows removal can be viewed as the problem of extracting information contained in an image and transforming it into a certain meaningful representation (Artusi and Chetverikov <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Artusi A, Chetverikov D (2007) A survey of specularity removal methods. Technical Report" href="/article/10.1007/s10055-010-0154-x#ref-CR1" id="ref-link-section-d40580e576">2007</a>). This representation can describe the intrinsic properties of the input image (Barrow and Tanenbaum <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1978" title="Barrow H, Tanenbaum J (1978) Recovering intrinsic scene characteristic from images. Comput Vis Syst" href="/article/10.1007/s10055-010-0154-x#ref-CR18" id="ref-link-section-d40580e579">1978</a>). For example, in the context of specularity removal, the interface and body reflections are two possible intrinsic image properties.</p><p>Several specularity removal techniques have been published. These differ in the information they use and how this is used. There are two main categories based on the types of input data: <i>Single Image</i> and <i>Multi-Image</i> methods (Lin et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Lin S, Li Y, Kang SB, Tong X, Shum HY (2002) Diffuse-specular separation and depth recovery from image sequences. In: European conference on computer vision" href="/article/10.1007/s10055-010-0154-x#ref-CR111" id="ref-link-section-d40580e591">2002</a>; Weiss <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Weiss Y (2001) Deriving intrinsic images from image sequences. In: Proceeding IEEE international conference on computer vision ICCV" href="/article/10.1007/s10055-010-0154-x#ref-CR174" id="ref-link-section-d40580e594">2001</a>). The first category performs the separation of the reflection components using only a single image. The second category makes use of a sequence of images benefiting from the fact that under varying viewing direction diffuse and specular reflections show different behaviour (Artusi and Chetverikov <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Artusi A, Chetverikov D (2007) A survey of specularity removal methods. Technical Report" href="/article/10.1007/s10055-010-0154-x#ref-CR1" id="ref-link-section-d40580e597">2007</a>).</p><p>The single-image category is further subdivided into the techniques based on the information they use: <i>Neighbourhood Analysis</i> (Mallick et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Mallick SP, Zickler T, Kriegman DJ, Belhumeur PN (2006) Specularity removal in images and videos: a pde approach. In: Proceedings European conference computer vision" href="/article/10.1007/s10055-010-0154-x#ref-CR126" id="ref-link-section-d40580e606">2006</a>; Tan et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Tan P, Lin S, Quan L (2006) Separation of highlight reflections on texture surfaces. In: IEEE conference on computer vision and pattern recognition" href="/article/10.1007/s10055-010-0154-x#ref-CR133" id="ref-link-section-d40580e609">2006</a>; Tappen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Tappen MF, Freeman WT, Adelson EH (2005) Recovering intrinsic images from a single image. IEEE Trans Pattern Anal Mach Intell" href="/article/10.1007/s10055-010-0154-x#ref-CR164" id="ref-link-section-d40580e612">2005</a>; Tan and Ikeuchi <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Tan R, Ikeuchi K (2003) Separating reflection components of terxtured surfaces using a single image. In: Proceeding IEEE international conference on computer vision ICCV" href="/article/10.1007/s10055-010-0154-x#ref-CR165" id="ref-link-section-d40580e615">2003</a>; Yoon et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Yoon KJ, Choi Y, Kweon IS (2006) Fast separation of reflection components using a specularity-invariant image representation. In: IEEE international conference on image processing ICIP" href="/article/10.1007/s10055-010-0154-x#ref-CR182" id="ref-link-section-d40580e619">2006</a>), <i>Colour Space Analysis</i> (Klinker et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Klinker GJ, Shafer SA, Kannade T (1987) Using a color reflection model to separate highlights from object color. In: Proceedings 1st international conference on computer vision, IEEE London" href="/article/10.1007/s10055-010-0154-x#ref-CR103" id="ref-link-section-d40580e625">1987</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1990a" title="Klinker GJ, Shafer SA, Kannade T (1990a) The measurement of highlights in color images. Int J Comput Vis" href="/article/10.1007/s10055-010-0154-x#ref-CR104" id="ref-link-section-d40580e628">1990a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Klinker GJ, Shafer SA, Kannade T (1990b) A physical approach to color image understanding. Int J Comput Vis" href="/article/10.1007/s10055-010-0154-x#ref-CR105" id="ref-link-section-d40580e631">b</a>; Schlns and Teschner <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995a" title="Schlns K, Teschner M (1995a) Analysis of 2d color spaces for highlight elimination in 3d shape reconstruction. In: Proceedings ACCV" href="/article/10.1007/s10055-010-0154-x#ref-CR160" id="ref-link-section-d40580e634">1995a</a>
                        <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Schlns K, Teschner M (1995b) Fast separation of reflection components and its application in 3d shape recovery. In: Proceedings 3rd color imaging conference" href="/article/10.1007/s10055-010-0154-x#ref-CR161" id="ref-link-section-d40580e638">b</a>) and <i>Polarisation</i> (Kim et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Kim D, Lin S, Hong K, Shum H (2002) Variational specular separation using color and polarization. In: IAPR workshop on machine vision applications" href="/article/10.1007/s10055-010-0154-x#ref-CR102" id="ref-link-section-d40580e644">2002</a>; Nayar et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Nayar SK, Fang X, Boult T (1997) Separation of reflection components using color and polarization. Int J Comput Vis" href="/article/10.1007/s10055-010-0154-x#ref-CR128" id="ref-link-section-d40580e647">1997</a>). The first group uses the information of the neighbourhood pixels to compute the pixel diffuse colour. The second group considers colour space to analyse the distribution of the diffuse and specular components and uses this information for the separation. The techniques applying polarisation filters rely on the fact that the specular component is polarised and thus the colour of the specular component can be identified. Besides this classification, one can categorise the approaches as <i>local</i> or <i>global</i> depending on how they use the information contained in the image data. The local methods utilise local pixel interactions to remove the specular reflection, while the global methods estimate diffuse colours of image regions, which implies segmentation (Artusi and Chetverikov <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Artusi A, Chetverikov D (2007) A survey of specularity removal methods. Technical Report" href="/article/10.1007/s10055-010-0154-x#ref-CR1" id="ref-link-section-d40580e657">2007</a>).</p><p>Several shadows removal techniques have been proposed in the past based on colour space analysis such as RGB (Baba and Asada <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Baba M, Asada N (2003) Shadow removal from a real picture. In: SIGGRAPH ’03: ACM SIGGRAPH sketches &amp; applications" href="/article/10.1007/s10055-010-0154-x#ref-CR9" id="ref-link-section-d40580e664">2003</a>) and HVS (Cucchiara et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Cucchiara R, Grana C, Piccardi M, Prati A, Sirotti S (2001) Improving shadow suppression in moving object detection with HSV color information. In: Proceedings of intelligent transportation systems" href="/article/10.1007/s10055-010-0154-x#ref-CR23" id="ref-link-section-d40580e667">2001</a>) colour spaces. Also, invariant colour models (Salvador and Ebrahimi <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Salvador E, Ebrahimi T (2001) Shadow identification and classification using invariant color models" href="/article/10.1007/s10055-010-0154-x#ref-CR59" id="ref-link-section-d40580e670">2001</a>) and the measure of brightness (Baba et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Baba M, Mukunoki M, Asada N (2004) Shadow removal from a real image based on shadow density. In: SIGGRAPH ’04: ACM SIGGRAPH posters" href="/article/10.1007/s10055-010-0154-x#ref-CR13" id="ref-link-section-d40580e673">2004</a>) (shadow density) have been used to classify shadows regions and afterwards removed by modifying the brightness and colour of the input image.</p><p>For texture mapping purposes, it is necessary to colour calibrate existing photographs. This can be done by computing colour compensation based on a colour chart, like the <i>Macbeth Colour Checker</i> using for instance the <i>macbethcal</i> program in Radiance.</p></div></div></section><section aria-labelledby="Sec4"><div class="c-article-section" id="Sec4-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec4">High dynamic range imaging</h2><div class="c-article-section__content" id="Sec4-content"><p>The dynamic range of lighting available in the real world is vast, and the <i>Human Visual System</i> (HVS) is able to adapt to various lighting conditions. Current conventional capturing and display technologies do not support the full dynamic range our eyes are capable of processing. This <i>High Dynamic Range</i> (HDR) of luminance needs to be captured and integrated to increase the reproduced level of realism in any virtual reconstruction. The research field in computer graphics that deals with all aspects of acquiring, processing and displaying HDR content is called <i>High Dynamic Rage Imaging</i> (HDRI). HDRI has become an important research topic for illuminating the past because its adds greater accuracy in terms of lighting than <i>Low Dynamic Range</i> (LDR) content is capable of producing.</p><p>Humans are capable of seeing a large range of light intensities ranging from daylight levels of around 10<sup>8</sup> <i>cd</i>/<i>m</i>
                        <sup>2</sup> to night light conditions of approximately 10<sup>−6</sup> <i>cd</i>/<i>m</i>
                        <sup>2</sup>. Currently, available consumer cameras are limited to capture only 8-bit images or 12-bit images in RAW format, which do not cover the full dynamic range of irradiance values in most environments in real world. The only option today is to take a number of exposures of the same scene to capture details from very dark regions to very bright regions as proposed in (Debevec and Malik <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Debevec P, Malik J (1997) Recovering high dynamic range radiance maps from photographs. In: SIGGRAPH ’97: proceedings of the 24th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR46" id="ref-link-section-d40580e729">1997</a>; Kang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Kang SB, Uyttendaele M, Winder S, Szeliski R (2003) High dynamic range video. ACM Trans Graph" href="/article/10.1007/s10055-010-0154-x#ref-CR107" id="ref-link-section-d40580e732">2003</a>; Mitsunaga and Nayar <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Mitsunaga T, Nayar S (1999) Radiometric self calibration. In: IEEE conference on computer vision and pattern recognition (CVPR)" href="/article/10.1007/s10055-010-0154-x#ref-CR121" id="ref-link-section-d40580e735">1999</a>; Mann and Picard <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Mann S, Picard RW (1995) Being “undigital” with digital cameras: extending dynamic range by combining differently exposed pictures. In: Proceedings of IS&amp;T 46th annual conference" href="/article/10.1007/s10055-010-0154-x#ref-CR123" id="ref-link-section-d40580e739">1995</a>; Nayar and Branzoi <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Nayar S, Branzoi V (2003) Adaptive dynamic range imaging: optical control of pixel exposures over space and time. In: IEEE international conference on computer vision (ICCV)" href="/article/10.1007/s10055-010-0154-x#ref-CR127" id="ref-link-section-d40580e742">2003</a>; Robertson et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Robertson MA, Borman S, Stevenson RL (1999) Dynamic range improvement through multiple exposures. In: Proceedings of the 1999 international conference on image processing (ICIP-99)" href="/article/10.1007/s10055-010-0154-x#ref-CR140" id="ref-link-section-d40580e745">1999</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Robertson MA, Borman S, Stevenson RL (2003) Estimation-theoretic approach to dynamic range enhancement using multiple exposures. J Electron Imaging 12(2):219–228" href="/article/10.1007/s10055-010-0154-x#ref-CR141" id="ref-link-section-d40580e748">2003</a>).</p><p>Conventional display technologies today are not capable of displaying HDR luminance. The HDR values can, however, be converted to better fit its LDR displays. This is known as <i>Tone Mapping</i>. Tone Mapping is an important last step in the reproduction of realistic images and many operators have been proposed, most of which detailed in a EG STAR report by Devlin et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Devlin K, Chalmers A, Wilkie A, Purgathofer W (2002b) STAR report on tone reproduction and physically based spectral rendering. Eurographics" href="/article/10.1007/s10055-010-0154-x#ref-CR36" id="ref-link-section-d40580e757">2002</a>b). There are two categories of TM operators: <i>global</i> and <i>local</i>. These algorithms allow transforming the same pixel intensity of the input image to different display values, or different pixel intensities to the same display value (DiCarlo and Wandell <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="DiCarlo JC, Wandell BA (2000) Rendering high dynamic range images. SPIE conferences" href="/article/10.1007/s10055-010-0154-x#ref-CR51" id="ref-link-section-d40580e766">2000</a>). Recently, the novel colour appearance model iCAM (Kuang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Kuang J, Johnson GM, Fairchild MD (2007) iCAM06: a refined image appearance model for HDR image rendering. J Vis Commun Image Represent 18(5):406–414" href="/article/10.1007/s10055-010-0154-x#ref-CR99" id="ref-link-section-d40580e770">2007</a>) was introduced. It is able to predict a range of colour appearance phenomena that allow to simulate more precisely how the HDR scene will appear to the user. Although HDR display technology is appearing (Seetzen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Seetzen H, Heidrich W, Stuerzlinger W, Ward G, Whitehead L, Trentacoste M, Ghosh A, Vorozcovs A (2004) High dynamic range display systems. In: SIGGRAPH '04: ACM SIGGRAPH 2004 Emerging technologies. ACM, New York, p 8" href="/article/10.1007/s10055-010-0154-x#ref-CR155" id="ref-link-section-d40580e773">2004</a>), it will be a few years before it becomes commonly available. Despite being 10 times darker and 30 times brighter than traditional LDR displays, even HDR displays do not deliver the full range of real world luminance.</p></div></div></section><section aria-labelledby="Sec5"><div class="c-article-section" id="Sec5-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec5">Rendering</h2><div class="c-article-section__content" id="Sec5-content"><p>Computer graphics research has provided a vast number of methods for computing and displaying virtual environments. Most methods can be categorised as being based on one of two techniques: <i>Rasterisation</i> or <i>Ray Tracing</i> (Whitted <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1980" title="Whitted T (1980) An improved illumination model for shaded display. Commun ACM 23(6):343–349" href="/article/10.1007/s10055-010-0154-x#ref-CR177" id="ref-link-section-d40580e790">1980</a>).</p><p>Of the two methods, rasterisation is the most popular, particularly for interactive environments, due to the performance that can now be achieved by employing dedicated graphics hardware. For this reason, and the amount of support there is for it in terms of libraries (Blythe <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Blythe D (2006) The Direct3D 10 system. ACM Trans Graph 25(3):724–734" href="/article/10.1007/s10055-010-0154-x#ref-CR12" id="ref-link-section-d40580e796">2006</a>; Shreiner et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Shreiner D, Woo M, Neider J, Davis T (2004) OpenGL(R) 1.4 Reference manual, 4th edn. Addison Wesley Longman Publishing Co., Inc" href="/article/10.1007/s10055-010-0154-x#ref-CR162" id="ref-link-section-d40580e799">2004</a>), rasterisation is the de facto standard for rendering in the computer graphics industry. Rasterisation renders images by projecting primitives, which are always polygon based, or geometry that can be tesselated, to the image plane using a series of transformations. Once the geometry is projected, the rasterisation phase computes aspects of lighting, texture and visible surface detection before rasterising the primitives. When more complex lighting effects such as shadows, caustics, indirect lighting etc. are required, these are computed using specialised algorithms. Akenine-Moller et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Akenine-Moller T, Haines E, Hoffman N (2008) Real-time rendering. A. K. Peters, Wellesley" href="/article/10.1007/s10055-010-0154-x#ref-CR4" id="ref-link-section-d40580e802">2008</a>) provide a comprehensive overview of rasterisation methods and their extensions.</p><p>Ray tracing (Whitted <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1980" title="Whitted T (1980) An improved illumination model for shaded display. Commun ACM 23(6):343–349" href="/article/10.1007/s10055-010-0154-x#ref-CR177" id="ref-link-section-d40580e808">1980</a>) methods for rendering were originally based on a ray casting method for visible surface detection (Appel <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1968" title="Appel A (1968) Some techniques for shading machine renderings of solids. In: Proceedings of the spring joint computer conference" href="/article/10.1007/s10055-010-0154-x#ref-CR5" id="ref-link-section-d40580e811">1968</a>). More recent ray tracing methods model the geometric optic properties of light by calculating the interactions of photons with geometry and can reproduce more complex lighting effects with little modifications. While ray tracing is computationally expensive, recent algorithmic and hardware advances are making it possible to render scenes at interactive rates (Wald et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Wald I, Mark WR, Günther J, Boulos S, Ize T, Hunt W, Parker SG, Shirley P (2007) State of the art in ray tracing animated scenes. Eurographics" href="/article/10.1007/s10055-010-0154-x#ref-CR178" id="ref-link-section-d40580e814">2007</a>).</p><h3 class="c-article__sub-heading" id="Sec6">Physically based rendering</h3><p>The quality of illumination is highly dependent on the model of the lighting simulation. In order to accurately recreate lighting conditions in virtual environments, physically based rendering is required. Physically based rendering involves the process of modelling physical properties of the materials and lighting in the scene and simulating the local and global components of the light transport. Light reflectance models describe the emission and reflectance of a material. These are responsible for the local illumination component in rendering. The reflectance model describes how light interacts on, around and through a surface, including very small surfaces such as particles in a volume. Complex reflectance functions termed <i>Bi-directional Scattering Surface Reflectance Distribution Functions</i> (BSSRDF) provide a model that describes surfaces that are both reflective and partially translucent (Jensen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001b" title="Jensen HW, Marschner SR, Levoy M, Hanrahan P (2001b) A practical model for subsurface light transport. In: SIGGRAPH ’01: proceedings of the 28th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR94" id="ref-link-section-d40580e827">2001b</a>).</p><p>More commonly used functions are the simplified <i>Bi-directional Reflectance Distribution Functions</i> (BRDFs), that account for surface interactions at the same point, without scattering. A large number of reflectance functions that are physically inspired that are commonly used in illumination for cultural heritage are the Ward BRDF (Ward <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Ward GJ (1992) Measuring and modeling anisotropic reflection. SIGGRAPH ’92: Proceedings of the 19th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR172" id="ref-link-section-d40580e836">1992</a>) and Lafortune BRDF (Lafortune et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Lafortune E, Foo S-C, Torrance K, Greenberg D (1997) Non-linear approximation of reflectance functions. In: SIGGRAPH ’97: proceedings of the 24th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR110" id="ref-link-section-d40580e839">1997</a>). Other analytical solutions also exist, such as the Cook-Torrance model (Cook and Torrance <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1982" title="Cook RL, Torrance KE (1982) A reflectance model for computer graphics. ACM Trans Graph" href="/article/10.1007/s10055-010-0154-x#ref-CR29" id="ref-link-section-d40580e842">1982</a>). Dorsey et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Dorsey J, Rushmeier H, Sillion F (2008) Digital modeling of the appearance of materials. Morgan Kaufmann, San Francisco" href="/article/10.1007/s10055-010-0154-x#ref-CR47" id="ref-link-section-d40580e845">2008</a>) present a detailed discussion on material modelling.</p><h3 class="c-article__sub-heading" id="Sec7">Global illumination</h3><p>The computation of global illumination at any point in a scene, without participating media, is governed by the rendering equation (Kajiya <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1986" title="Kajiya J (1986) The rendering equation. In: SIGGRAPH ’86: proceedings of the 13th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR95" id="ref-link-section-d40580e857">1986</a>). The radiance at a point <i>p</i> in direction <span class="mathjax-tex">\(\Uptheta\)</span> is given by:
</p><div id="Equa" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned}   L(p \to \Uptheta ) =  &amp; L_{e} (p \to \Uptheta ) \\     &amp;  + \int\limits_{{\Upomega _{p} }} {f_{r} } (p,\Uptheta  \leftrightarrow \Uppsi )\cos (N_{p} ,\Uppsi )L_{i} (p \leftarrow \Uppsi )\delta \omega _{\Uppsi }  \\  \end{aligned}$$</span></div></div><p>where <i>L</i>
                           <sub>
                    <i>e</i>
                  </sub> is the emitted radiance, <i>L</i>
                           <sub>
                    <i>i</i>
                  </sub> is the incoming radiance from across the hemisphere, <i>f</i>
                           <sub>
                    <i>r</i>
                  </sub> represents the BRDF. Various solutions have been proposed for calculating the rendering equation. These can be subdivided into two broad categories: finite-element solutions and point-sampling methods.</p><p><i>Finite-element methods</i> were first used to solve the rendering equation with the introduction of Radiosity (Goral et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1984" title="Goral CM, Torrance KE, Greenberg DP, Battaile B (1984) Modeling the interaction of light between diffuse surfaces. In: SIGGRAPH ’84: proceedings of the 11th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR74" id="ref-link-section-d40580e918">1984</a>). Radiosity methods are, for the most part, computed in conjunction with rasterisation for computing the effects of the indirect lighting due to diffuse inter-reflections. A comprehensive overview of radiosity is provided in the paper by Cohen et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Cohen MF, Wallace J, Hanrahan P (1993) Radiosity and realistic image synthesis. Academic Press Professional, San Diego" href="/article/10.1007/s10055-010-0154-x#ref-CR32" id="ref-link-section-d40580e921">1993</a>). Recent extensions of radiosity have made it possible to achieve interactive frame rates (Dachsbacher et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Dachsbacher C, Stamminger M, Drettakis G, Durand F (2007) Implicit visibility and antiradiance for interactive global illumination. In: SIGGRAPH ’07: proceedings of the 34th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR48" id="ref-link-section-d40580e924">2007</a>).</p><p><i>Point-sampling methods</i> are approaches based on the ray tracing method. These methods, for the most part, solve the rendering equation using stochastic methods. <i>Distributed Ray Tracing</i> (Cook et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1984" title="Cook RL, Porter T, Carpenter L (1984) Distributed ray tracing. In: SIGGRAPH ’84: proceedings of the 11th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR27" id="ref-link-section-d40580e935">1984</a>) extended classic ray tracing to render aspects of global illumination effects such as soft shadows, indirect lighting, motion blur etc. Naive distributed ray tracing is characterised by a ray explosion. <i>Path Tracing</i> (Kajiya <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1986" title="Kajiya J (1986) The rendering equation. In: SIGGRAPH ’86: proceedings of the 13th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR95" id="ref-link-section-d40580e941">1986</a>) used a Markov chain random walk to solve the rendering equation. Path tracing does not follow a ray explosion, instead, only one ray is shot at each intersection. <i>Metropolis Light Transport</i> (MLT) (Veach and Guibas <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Veach E, Guibas LJ (1997) Metropolis light transport. In: SIGGRAPH ’97: proceedings of the 24th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR169" id="ref-link-section-d40580e948">1997</a>) uses <i>Metropolis-Hastings</i> sampling by mutating paths (from the eye and the light) over subsequent iterations. These three methods are considered unbiased in that the expected value of the error is zero. Other, more recent unbiased methods such as <i>Energy-Redistribution Path Tracing</i> (ERPT) (Cline et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Cline D, Talbot J, Egbert P (2005) Energy redistribution path tracing. In: SIGGRAPH ’05: proceedings of the 32nd annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR30" id="ref-link-section-d40580e957">2005</a>) and <i>Population Monte Carlo</i> (Lai et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Lai Y-C, Fan SH, Chenney S, Dyer C (2007) Rendering techniques. In: Kautz J, Pattanaik S (eds) Photorealistic image rendering with population Monte Carlo energy redistribution" href="/article/10.1007/s10055-010-0154-x#ref-CR109" id="ref-link-section-d40580e963">2007</a>) are beginning to demonstrate further improvements in performance and additional algorithmic improvements may yet bring unbiased methods to the fore of rendering.</p><p>Other approaches have been used to accelerate ray tracing methods, these methods are considered biased but consistent meaning that the expected value of the error converges towards zero as the number of samples increases. Two of the most popular methods are irradiance caching and photon mapping. <i>Irradiance Caching</i> (Ward et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Ward G, Rubinstein FM, Clear RD (1988) A ray tracing solution for diffuse inter-reflection. In: SIGGRAPH ’88: proceedings of the 15th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR179" id="ref-link-section-d40580e972">1988</a>) accelerates the computation of indirect diffuse inter-reflections by caching computations and interpolating them in object space. Irradiance caching has influenced a large number of new caching schemes for rendering. Methods have been created to be able to re-use computation for glossy and diffuse inter-reflections, a method known as the radiance cache (Křivánek et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Křivánek J, Gautron P, Pattanaik S, Bouatouch K (2005) Radiance caching for efficient global illumination computation. IEEE Trans Vis and Comput Graph" href="/article/10.1007/s10055-010-0154-x#ref-CR98" id="ref-link-section-d40580e975">2005</a>). Caching methods have been used to accelerate the computation of participating media (Jarosz et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Jarosz W, Donner C, Zwicker M, Jensen HW (2008) Radiance caching for participating media. ACM Trans Graph 27(1):1–11" href="/article/10.1007/s10055-010-0154-x#ref-CR92" id="ref-link-section-d40580e978">2008</a>), translucency (Keng et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Keng S-L, Lee W-Y, Chuang J-H (2006) An efficient caching-based rendering of translucent materials. Vis Comput: Int J Comput Graph" href="/article/10.1007/s10055-010-0154-x#ref-CR101" id="ref-link-section-d40580e981">2006</a>) and for temporal coherence (Gautron et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Gautron P, Bouatouch K, Pattanaik S (2007) Temporal radiance caching. IEEE Trans Vis Comput Graph" href="/article/10.1007/s10055-010-0154-x#ref-CR65" id="ref-link-section-d40580e985">2007</a>). <i>Photon Mapping</i> (Jensen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Jensen HW (2001) Realistic image synthesis using photon mapping. A.K. Peters, Natick" href="/article/10.1007/s10055-010-0154-x#ref-CR93" id="ref-link-section-d40580e991">2001</a>) is a bi-directional method that computes indirect inter-reflections and has been very successful at computing caustics. In photon mapping, photons shot from light sources are stored in kd-trees and density estimation is used to compute illumination points visible from the eye. Photon mapping continues to be extended and improved (Hachisuka et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Hachisuka T, Ogaki S, Jensen HW (2008) Progressive photon mapping. In: SIGGRAPH Asia ’08: ACM SIGGRAPH Asia papers" href="/article/10.1007/s10055-010-0154-x#ref-CR83" id="ref-link-section-d40580e994">2008</a>; Spencer and Jones <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Spencer B, Jones MW (2009) Into the blue: better caustics through photon relaxation. Comput Graph Forum 28(2):319–328" href="/article/10.1007/s10055-010-0154-x#ref-CR156" id="ref-link-section-d40580e997">2009</a>). In practice, deterministic approaches are used in conjunction with stochastic approaches such as in Radiance (the rendering application), which uses a combination of distributed ray tracing, irradiance caching and deterministic ray tracing and Mental Ray (Mental <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Mental Images (2009) Mental ray company website. &#xA;                    http://www.mentalimages.com/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR116" id="ref-link-section-d40580e1000">2009</a>) which uses photon mapping.</p><p>Other, recent methods that can also accelerate computation of global illumination are Instant Radiosity techniques (Keller <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Keller A (1997) Instant radiosity. In: SIGGRAPH ’97: proceedings of the 24th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR96" id="ref-link-section-d40580e1007">1997</a>), light/illumination cuts (Walter et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Walter B, Fernandez S, Arbree A, Bala K, Donikian M, Greenberg DP (2005) Lightcuts: a scalable approach to illumination. ACM Trans Graph 24(3):1098–1107" href="/article/10.1007/s10055-010-0154-x#ref-CR175" id="ref-link-section-d40580e1010">2005</a>) and <i>Precomputed Radiance Transfer</i> (PRT) (Sloan et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Sloan P-P, Kautz J, Snyder J (2002) Precomputed radiance transfer for real-time rendering in dynamic, low-frequency lighting environments. In: SIGGRAPH ’02: proceedings of the 29th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR158" id="ref-link-section-d40580e1016">2002</a>). <i>Instant Radiosity</i> is a bi-directional method that, in a first phase has photons, termed <i>Virtual Point Lights</i> (VPLs), emitted from the light sources and a subsequent rendering phase computes illumination using the VPLs as point light sources. Using small number of VPLs (&lt;1024), extensions of instant radiosity, such as <i>Imperfect Shadow Maps</i> (Ritschel et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Ritschel T, Grosch T, Kim MH, Seidel H-P, Dachsbacher C, Kautz J (2008) Imperfect shadow maps for efficient computation of indirect illumination. SIGGRAPH Asia ’08: ACM SIGGRAPH Asia papers" href="/article/10.1007/s10055-010-0154-x#ref-CR145" id="ref-link-section-d40580e1029">2008</a>), have been shown to compute global illumination in real time on modern graphics hardware. Other methods have achieved interactive rates on multi-core CPUs (Debattista et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Debattista K, Dubla P, Banterle F, Santos LP, Chalmers A (2009) Instant caching for interactive global illumination. Comput Graph Forum 28(8):2216–2228" href="/article/10.1007/s10055-010-0154-x#ref-CR37" id="ref-link-section-d40580e1032">2009</a>; Dubla et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Dubla P, Debattista K, Chalmers A (2009) Adaptive interleaved sampling for interactive high fidelity rendering. Comput Graph Forum 28(8):2117–2130" href="/article/10.1007/s10055-010-0154-x#ref-CR38" id="ref-link-section-d40580e1035">2009</a>). <i>Light cuts/Illumination Cuts</i> accelerate computation by clustering similar components (usually light sources or VPLs) that are not deemed that important together to reduce computational costs. Light cuts has often been used in conjunction with instant radiosity methods to further improve performance (Wang and Akerlund <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Wang R, Akerlund O (2009) Bidirectional importance sampling for unstructured illuminationn. Eurographics" href="/article/10.1007/s10055-010-0154-x#ref-CR170" id="ref-link-section-d40580e1042">2009</a>; Walter et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Walter B, Arbree A, Bala K, Greenberg DP (2006) Multidimensional lightcuts. ACM Trans Graph" href="/article/10.1007/s10055-010-0154-x#ref-CR171" id="ref-link-section-d40580e1045">2006</a>). PRT methods use a precomputation step to compute illumination and visibility that subsequently can be efficiently computed in real time on modern graphics hardware. PRT extensions have made it possible to obtain global illumination for dynamic scenes (Iwasaki et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Iwasaki K, Dobashi Y, Yoshimoto F, Nishita T (2007) Precomputed radiance transfer for dynamics scene taking into account light inter-reflection. In: Eurographics symposium on rendering" href="/article/10.1007/s10055-010-0154-x#ref-CR86" id="ref-link-section-d40580e1048">2007</a>; Pan et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Pan M, Wang R, Liu X, Peng Q, Bao H (2007) Precomputed radiance transfer field for rendering inter-reflections in dynamic scenes. Comput Graph Forum 26(3):485–493" href="/article/10.1007/s10055-010-0154-x#ref-CR138" id="ref-link-section-d40580e1051">2007</a>).</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec8">Participating media</h4><p>The assumption is made in many computer graphics applications that light travels through vacuum. In a number of cases, this is a reasonable assumption for realistic synthesised images. However, especially in the past, environments had the intentional and unintentional presence of fog, smoke and visible dust particles. Smoke can stem from burning candles and wood, while dust particles can become highly visible in interior environments, for example, those in Egypt, with sun ray, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig23">23</a>. Examples like this can alter the visual perception of the environment significantly (Gutierrez et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Gutierrez D, Sundstedt V, Gomez F, Chalmers A (2006) Dust and light: predictive virtual archaeology. J Cult Herit" href="/article/10.1007/s10055-010-0154-x#ref-CR71" id="ref-link-section-d40580e1064">2006</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Gutierrez D, Sundstedt V, Gomez F, Chalmers A (2008) Modeling light scattering for virtual heritage. J Comput Cult Herit" href="/article/10.1007/s10055-010-0154-x#ref-CR72" id="ref-link-section-d40580e1067">2008</a>; Hawkins et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Hawkins T, Einarsson P, Debevec P (2005) Acquisition of time-varying participating media. In: SIGGRAPH ’05: proceedings of the 32nd annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR80" id="ref-link-section-d40580e1070">2005</a>; Rushmeier <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Rushmeier H (1995) Rendering participating media: problems and solutions from application areas. In: Proceedings of the 5th Eurographics workshop on rendering, Springer" href="/article/10.1007/s10055-010-0154-x#ref-CR148" id="ref-link-section-d40580e1073">1995</a>; Sundstedt et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Sundstedt V, Gutierrez D, Gomez F, Chalmers A (2005) Participating media for high-fidelity cultural heritage. In: VAST ’05: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR153" id="ref-link-section-d40580e1077">2005</a>).</p><p>Scattering in participating media needs to account for a number of interactions: <i>Emission, Absorption, Out-Scattering and In-Scattering</i>. The rendering equation can be extended to account for participating media (Chandrasekhar <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1960" title="Chandrasekhar S (1960) Radiative transfer. Dover Publications, New York" href="/article/10.1007/s10055-010-0154-x#ref-CR24" id="ref-link-section-d40580e1086">1960</a>; Glassner <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Glassner A (1994) Principles of digital image synthesis. Morgan Kaufmann, San Francisco" href="/article/10.1007/s10055-010-0154-x#ref-CR67" id="ref-link-section-d40580e1089">1994</a>; Pharr and Humphreys <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Pharr M, Humphreys G (2004) Physically based rendering: from theory to implementation. Morgan Kaufmann, San Francisco" href="/article/10.1007/s10055-010-0154-x#ref-CR132" id="ref-link-section-d40580e1092">2004</a>). A number of extensions to the global illumination algorithms have been developed to render global illumination with participating media, such methods include extensions to photon mapping (Jensen and Christensen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Jensen HW, Christensen PH (1998) Efficient simulation of light transport in scences with participating media using photon maps. In: SIGGRAPH ’98: proceedings of the 25th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR90" id="ref-link-section-d40580e1095">1998</a>) and irradiance caching (Jarosz et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Jarosz W, Donner C, Zwicker M, Jensen HW (2008) Radiance caching for participating media. ACM Trans Graph 27(1):1–11" href="/article/10.1007/s10055-010-0154-x#ref-CR92" id="ref-link-section-d40580e1099">2008</a>). Hawkins et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Hawkins T, Einarsson P, Debevec P (2005) Acquisition of time-varying participating media. In: SIGGRAPH ’05: proceedings of the 32nd annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR80" id="ref-link-section-d40580e1102">2005</a>) captures time-varying volumetric data of participating media though a laser sheet that sweeps repeatedly through a volume, using a high-speed camera.</p></div></div></section><section aria-labelledby="Sec9"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">Sky illumination</h2><div class="c-article-section__content" id="Sec9-content"><p>Simulating physically based sky illumination is computationally expensive. This is due to all sky elements that need to be addressed during rendering. Extensive work has been done on modelling the sky, some of which for atmospheric science analysis purposes such as (Igawa et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Igawa N, Koga Y, Matsuzawa T, Nakamura H (2004) Models of sky radiance distribution and sky luminance distribution. Solar Energy" href="/article/10.1007/s10055-010-0154-x#ref-CR87" id="ref-link-section-d40580e1116">2004</a>; Perez et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Perez R, Seals R, Ineichen P (1993) An allweather model for skyluminance distribution. Solar Energy" href="/article/10.1007/s10055-010-0154-x#ref-CR136" id="ref-link-section-d40580e1119">1993</a>), others for realistic image synthesis (Daubert et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Daubert K, Schirmacher H, Sillion F, Drettakis G (1997) Hierarchical lighting simulation for outdoor scenes. In: Proceedings of the Eurographics workshop on rendering" href="/article/10.1007/s10055-010-0154-x#ref-CR49" id="ref-link-section-d40580e1122">1997</a>; Jensen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001a" title="Jensen HW, Durand F, Stark M, Premoze S, Dorsey J, Shirley P (2001a) A physically based nightsky model. In: SIGGRAPH ’01: proceedings of the 28th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR91" id="ref-link-section-d40580e1125">2001a</a>; Preetham et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Preetham A, Shirley P, Smits B (1999) A practical analytic model for daylight. In: SIGGRAPH ’99: proceedings of the 26th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR137" id="ref-link-section-d40580e1128">1999</a>; Stumpfel et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Stumpfel J, Jones A, Wenger A, Tchou C, Hawkins T, Debevec P (2004) Direct HDR capture of the sun and sky. In: AFRIGRAPH ’04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR157" id="ref-link-section-d40580e1132">2004</a>).</p><p>Preetham et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Preetham A, Shirley P, Smits B (1999) A practical analytic model for daylight. In: SIGGRAPH ’99: proceedings of the 26th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR137" id="ref-link-section-d40580e1138">1999</a>) presents an analytic model that approximates the spectrum of daylight for various atmospheric conditions. The model also presents a model that approximates the effects of aerial perspective (atmosphere). Atmospheric data are easily accessible for the atmospheric science community. However, these data are not widely accessible to computer graphics professionals and has, therefore, been provided as an appendix to the paper. Jensen et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001a" title="Jensen HW, Durand F, Stark M, Premoze S, Dorsey J, Shirley P (2001a) A physically based nightsky model. In: SIGGRAPH ’01: proceedings of the 28th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR91" id="ref-link-section-d40580e1141">2001a</a>) presents a physically based model of the night sky for realistic image synthesis rendered with a Monte Carlo ray tracer. The authors describe how to model the appearance and illumination of the night sky with the exception of rare or unpredictable phenomena such as aurora, comets and novas. Similarly, the paper also contains an appendix that present useful formulas for rendering of the night sky.</p><p>Several commercially available and academic rendering software allow physically based simulations of light from the sun, given fixed sets of attributes such as time and position. <i>gensky</i> for instance is a program in Radiance that produces a scene description for the Commission Internationale de l’Eclairage (CIE) standard sky distribution at a given time and position (Ward and Shakespeare <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Ward G, Shakespeare R (2003) Rendering with radiance: the art and science of lighting visualisation (Revised edition). Morgan Kaufmann, San Francisco" href="/article/10.1007/s10055-010-0154-x#ref-CR180" id="ref-link-section-d40580e1150">2003</a>). <i>mkillum</i> is another program in Radiance that computes light sources. Input to the program contains surfaces that act as light sources during rendering. This is useful for computing interior renders for which it is not necessary to compute outdoor light distribution.</p><h3 class="c-article__sub-heading" id="Sec10">Image-based lighting</h3><p>The emergence of HDRI has made it possible to extend the use of capturing HDR photographs to capture radiance maps and use HDR photographs as light sources for a scene. Such images are referred to as <i>Light Probes</i> or <i>Environment Maps</i> and their application is often referred to as <i>Image-Based Lighting</i> (IBL) (Debevec <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Debevec P (1998) Rendering synthetic objects into real scenes: bridging traditional and image-based graphics with global illumination and high dynamic range photography. In: SIGGRAPH ’98: proceedings of the 25th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR39" id="ref-link-section-d40580e1172">1998</a>; Debevec and Malik <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Debevec P, Malik J (1997) Recovering high dynamic range radiance maps from photographs. In: SIGGRAPH ’97: proceedings of the 24th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR46" id="ref-link-section-d40580e1175">1997</a>). Instead of using synthetic light sources, it is possible to use sampled light values from HDR images mapped onto a sphere that acts as a skydome to represent the distant illumination. This is useful in order to relight synthetic objects that occupy the same location as the light probe.</p><p>There are several methods of capturing these HDR environment maps. Debevec (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Debevec P (1998) Rendering synthetic objects into real scenes: bridging traditional and image-based graphics with global illumination and high dynamic range photography. In: SIGGRAPH ’98: proceedings of the 25th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR39" id="ref-link-section-d40580e1181">1998</a>) details the use of a mirrored sphere. Stumpfel et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Stumpfel J, Jones A, Wenger A, Tchou C, Hawkins T, Debevec P (2004) Direct HDR capture of the sun and sky. In: AFRIGRAPH ’04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR157" id="ref-link-section-d40580e1184">2004</a>) discuss the capturing process of HDR hemispherical image of the sun and sky by using an SLR camera with a 180° fish-eye lens. In the commercial field, a few companies provide HDR cameras based on automatic multiple exposure capturing. The two main cameras are Spheron HDR VR camera (Spheron <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Spheron (2002) SpherOn HDR, Company website. &#xA;                    http://www.spheron.com/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR159" id="ref-link-section-d40580e1187">2002</a>) and Panoscan MK-3 (Panoscan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Panoscan (2002) Panoscan MK-3, Company website. &#xA;                    http://www.panoscan.com/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR130" id="ref-link-section-d40580e1190">2002</a>). For example, the Spheron HDR VR can capture 26 f-stops of dynamic range at 50 Megapixels resolution in 30 min (depending on illumination conditions).</p><p>Light probe images can be represented in several formats including the mirrored sphere format (Debevec <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Debevec P (1998) Rendering synthetic objects into real scenes: bridging traditional and image-based graphics with global illumination and high dynamic range photography. In: SIGGRAPH ’98: proceedings of the 25th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR39" id="ref-link-section-d40580e1196">1998</a>), see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig1">1</a>, the vertical cross cube format (Debevec <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Debevec P (2001) Light probe image gallery. &#xA;                    http://www.debevec.org/probes/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR40" id="ref-link-section-d40580e1202">2001</a>) and the latitude–longitude panoramic representation (Blinn and Newell <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1976" title="Blinn JF, Newell ME (1976) Texture and reflection in computer generated images. Commun ACM" href="/article/10.1007/s10055-010-0154-x#ref-CR14" id="ref-link-section-d40580e1205">1976</a>; Debevec <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Debevec P (2006) High resolution light probe gallery. &#xA;                    http://www.gl.ict.usc.edu/Data/HighResProbes/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR44" id="ref-link-section-d40580e1208">2006</a>), see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig2">2</a>. The conversion between these different representations are also described in great detail by Reinhard et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Reinhard E, Ward G, Pattanaik S, Debevec P (2005) High dynamic range imaging: acquisition, display, and image-based lighting. Morgan Kaufmann, San Francisco" href="/article/10.1007/s10055-010-0154-x#ref-CR149" id="ref-link-section-d40580e1215">2005</a>), and easily done by using existing software such as HDRShop (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="HDRShop (2001) Example software to research hdri. &#xA;                    http://www.gl.ict.usc.edu/HDRShop/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR79" id="ref-link-section-d40580e1218">2001</a>). Publicly available galleries of HDR environment maps exist in above-mentioned formats in Debevec (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Debevec P (2001) Light probe image gallery. &#xA;                    http://www.debevec.org/probes/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR40" id="ref-link-section-d40580e1221">2001</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Debevec P (2006) High resolution light probe gallery. &#xA;                    http://www.gl.ict.usc.edu/Data/HighResProbes/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR44" id="ref-link-section-d40580e1224">2006</a>). A tutorial for using IBL in Radiance can be found in Debevec (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Debevec P (2002) Image-based lighting. Comput Graph Appl IEEE 22(2):26–34" href="/article/10.1007/s10055-010-0154-x#ref-CR41" id="ref-link-section-d40580e1227">2002</a>), however, most commercial and open source renderers today also support IBL in the latitude/longitude format.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig1_HTML.jpg" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Examples of light probes. <i>Left</i> St. Peter’s Basilica, Rome. <i>Middle</i> Galileo’s Tomb, Santa Croce, Florence. <i>Right</i> The Uffizi Gallery, Florence (Debevec <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Debevec P (2001) Light probe image gallery. &#xA;                    http://www.debevec.org/probes/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR40" id="ref-link-section-d40580e1250">2001</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Examples of Environment Maps. <i>Top</i> Mount Vesuvius (Happa et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Happa J, Williams M, Turley G, Earl GP, Dubla P, Beale G, Gibbons G, Debattista K, Chalmers A (2009) Virtual relighting of a roman statue head from herculaneum: a case study. In: AFRIGRAPH ’09: proceedings of the 6th international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR85" id="ref-link-section-d40580e1275">2009</a>). <i>Bottom</i> A cloudless morning outside Tanum Church; a mediaeval church in Norway</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The primary concern regarding lighting using light probe images is that a single light probe image is only valid for one point in space. <i>Incident Light Fields</i> allows for capture and rendering of synthetic objects with spatially varying illumination presented by Unger (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Unger J (2009) Incident light fields. PhD thesis, Linkping University" href="/article/10.1007/s10055-010-0154-x#ref-CR168" id="ref-link-section-d40580e1296">2009</a>).</p><p>In cultural heritage, there are several applications of IBL. It is possible to relight objects with illumination that exists within the site. If the aim is to estimate a light probe image that illuminates objects as they appeared in the past, it is necessary to recreate the distant scene to appear as it once did. This includes switching off modern light sources, remove recent additions to the scene and allow light to be projected in the scene as it would have in the past.</p><p>Hawkins et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Hawkins T, Cohen J, Debevec P (2001) A photometric approach to digitizing cultural artifacts. In: VAST ’01: proceedings of the symposium on virtual reality, archeology, and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR78" id="ref-link-section-d40580e1305">2001</a>) extend the application of IBL by presenting a photometry-based approach to digitally document cultural heritage artefacts. Each artefact is represented in terms of how it transforms light into images, this is also known as its <i>Reflectance Field</i>. The technique is data intensive and requires a light stage (Debevec et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Debevec P, Hawkins T, Tchou C, Duiker H-P, Sarokin W, Sagar M (2000) Acquiring the reflectance field of a human face. In: SIGGRAPH ’00: proceedings of the 27th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR45" id="ref-link-section-d40580e1311">2000</a>) and thousands of photographs of the artefact.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig2">2</a> illustrates differences in two spherical panoramas in the latitude/longitude format that show two different illumination conditions of the sky. The top image shows a largely diffuse lighting environment, while the bottom image is an example of an outdoor cloudless morning outside Tanum Church. Rendering objects with the bottom environment map produces much stronger shadows. The presence of shadows is far less noticeable using images similar to the top image. This is similar to how shadows are far more noticeable in sunny days over cloudy ones.</p></div></div></section><section aria-labelledby="Sec11"><div class="c-article-section" id="Sec11-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec11">Reflectance transformation imaging</h2><div class="c-article-section__content" id="Sec11-content"><p>Reflectance data of a real world object can be empirically acquired through a digital photography process called <i>Reflectance Transformation Imaging</i> (RTI). Given a viewpoint, the illumination on an object’s surface varies according to how the surface is illuminated. RTIs are derived from multiple digital photographs of an object shot from a stationary camera position. In each photograph, light is projected from a different position and direction.</p><p>This process produces a series of images of the same object with different highlights and shadows. This information can be captured with conventional digital photographic equipment. After the light has been projected from a representative sample of directions, all lighting information from the images is mathematically synthesised to generate a viewpoint specific, per-pixel reflectance function, enabling a user to interactively re-light the object’s surface. For each RTI-acquired viewpoint of the object, the resulting synthesised file resembles a single 2D photographic image, but with added reflectance information. Each 2D pixel, representing an area on the object’s 3D surface, visualises the 3D direction that is the perpendicular/<i>normal</i> vector to the location of the surface. This ability to document colour and true 3D shape information by using normals is the source of RTI’s documentary power.</p><p>Unlike a typical photograph, reflectance information derived from the 3D shape of the image’s object, encoded in the reflectance function, describes how light will reflect off the image. Each constituent pixel is able to reflect the software’s interactive virtual light from any position the user selects. This changing interplay of light and shadow in the image is used by the human perceptual system to disclose fine details of the object’s 3D surface form.</p><p>RTI information can also be mathematically enhanced. Enhancements have shown to disclose surface features that are difficult or impossible to discern under direct physical examination. RTIs can be captured over a large size range, from several square meters to millimetres, and can acquire a sample density and precision that most 3D scanners are unable to reach. RTIs can capture the surface features of a wide variety of material types, including diffuse objects to highly reflective materials such as jade or gold. For many documentary purposes, RTI also offers cost and precision advantages over other 3D scanning methods.</p><p><i>Polynomial Texture Mapping</i> (PTM) was introduced by Malzbender et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Malzbender T, Gelb D, Wolters H (2001) Polynomial texture maps. In: SIGGRAPH ’01: proceedings of the 28th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR117" id="ref-link-section-d40580e1348">2001</a>). This is considered the original approach to RTI and is a widely available method to mathematically synthesise RTI images. The paper presents a mathematical model describing luminance information for each pixel in an image in terms of a function representing the direction of incident illumination. The illumination direction function is approximated in the form of a bi-quadratic polynomial whose six coefficients are stored along with the colour information of each pixel. PTMFitter, a tool to build PTMs from an image sequence, and PTMViewer, an interactive viewer for PTMs, are freely available for non-commercial use under licence from Hewlett-Packard (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Hewlett-Packard (2009) Polynomial texture mapping—interactive relighting software licence. &#xA;                    http://www.hpl.hp.com/research/ptm/downloads/agreement.html&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR84" id="ref-link-section-d40580e1351">2009</a>). The per-pixel information is able to record approximations of material properties, including surface inter-reflection, subsurface scattering and self-shadowing.</p><h3 class="c-article__sub-heading" id="Sec12">Recent RTI advances</h3><p>Significant improvements in RTI technology have been achieved by an international research team funded by CHI (Cultural heritage imaging website. <a href="http://www.chi.org/">http://www.chi.org/</a>) contributors and the US Institute for Museum and Library Services. The team (The reasearch team included Tom Malzbender from HPLabs <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="The reasearch team included Tom Malzbender from HPLabs (1998) James Davis, Oliver Wang and Prabath Gunawardane from the University of California Santa Cruz, Martin Doerr and Steve Stead from The International Council of Museum’s (ICOM) Documentation Committee’s (CIDOC) Conceptual Reference Model (CRM) Special Interest Group, Roberto Scopigno, Paolo Cignoni, Massimiliano Corsini and Gianpaolo Palma from the Institute of Information Science and Technology (ISTI), Alberto Proenca and Joao Barbosa from the High Peformance Computing Center at the University of Minho, Alan Chalmers from the University of Warwick, and Holly Rushmeier from Yale" href="/article/10.1007/s10055-010-0154-x#ref-CR163" id="ref-link-section-d40580e1368">1998</a>) produced a new RTI file format for both single and multiple viewpoint RTIs, single-view and multi-view RTI viewing tools, the capacity for management of process history metadata, as well as new RTI single-view and multi-view acquisition tools and methods.</p><p>The new RTI file format, .rti, provides the ability to select from a menu of polynomial basis functions, ways to mathematically synthesise the input set of digital photographs into the optimal type of RTI image. The menu of polynomial basis functions, which includes Polynomial Texture Mapping (PTM), Spherical Harmonics (SH) (Sloan et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Sloan P-P, Kautz J, Snyder J (2002) Precomputed radiance transfer for real-time rendering in dynamic, low-frequency lighting environments. In: SIGGRAPH ’02: proceedings of the 29th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR158" id="ref-link-section-d40580e1374">2002</a>) and Hemispherical Harmonics (HSH) (Gautron et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Gautron P, Krivanek  J, Pattanaik S, Bouatouch K (2004) A novel hemispherical basis for accurate and efficient rendering. In: Rendering techniques 2004, Eurographics symposium on rendering" href="/article/10.1007/s10055-010-0154-x#ref-CR131" id="ref-link-section-d40580e1377">2004</a>), offers greater user control of information richness versus storage/processing cost determinations.</p><p>PTMs offer excellent representations with a compact file size. The SH and HSH alternative offer more accurate representations of a variety of materials, particularly specular and translucent materials, but produce larger files. SH estimates coefficients over an entire sphere, whether there is information from all directions or not, while HSH, a special case of SH, estimates coefficients over half a sphere. As each input image for an RTI represents the reflectance of a light located within a hemispheric sample range, when these images are fitted to the HSH polynomial reflectance function, the resulting coefficients are more accurate. This is helpful, especially in combination with RTIs of the same material captured from different viewpoints, in estimating a material’s BRDF. HSH coefficients have also been demonstrated to enable more accurate classification of different materials, such as shiny or matte versions of the same colour, than SH (Wang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Wang O, Gunawardane P, Scher S, Davis J (2009) Material classification using BRDF slices. IEEE conference on computer vision and pattern recognition" href="/article/10.1007/s10055-010-0154-x#ref-CR176" id="ref-link-section-d40580e1383">2009</a>).</p><p>All methods of building .rti files use the same input photographs. Legacy image sequences used to build PTMs in the past can be reused to generate new .rtis using a different basis function. Selecting the HSH basis function when building an .rti image, permits the use of 4, 9, 16 or 25 coefficients per pixel. The more coefficients, the more closely the resulting RTI resembles the initial photorealistic ground truth, at the cost of larger RTI file size and more input images.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig3">3</a> shows a seventh century Merovingian Triens, the only known example of its type. The Triens is rendered in alternating stripes. The stripes with the black bars on the left show a 9 coefficient HSH rendering, the stripes with the bars on the right show the PTM rendering. The same 24 input photos were used for each rendering.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig3_HTML.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig3_HTML.jpg" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Merovingian Treins rendered in alternating stripes</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The HSH method displays higher contrast, sharpness and specular fidelity to the ground truth. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig4">4</a> shows the disparity maps between a PTM and an HSH rendered in the RTI viewer from the same angle as one of the input images, which served as the ground truth.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig4_HTML.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig4_HTML.jpg" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p><i>Left</i> HSH method. <i>Right</i> PTM method</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The .rti format also contains structures for the management of process history and object metadata. New tools to automate metadata management, consistent with international standard ISO21127, are under development. The tools for generating and viewing .rti files are freely available under GPL licence.</p><p>Single-view RTIs can be captured using two methods. All forms of RTIs require knowledge of the angle of incidence of each light relative to the object. Originally, RTIs were captured with the position of the lights illuminating the object known before the capture session.</p><p>In Highlight RTI, the position of the lights could be calculated after a capture session rather than relying on knowledge of predetermined light positions obtained before the session (Mudge et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Mudge M, Malzbender T, Schroer C, Lum M (2006) New reflection transformation imaging methods for rock art and multiple viewpoint display. VAST ’06: Proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR120" id="ref-link-section-d40580e1450">2006</a>). Highlight RTI calculates the incident light angle using the position of the specular highlight, generated by the incident light, on the surface of a black, reflective sphere introduced into the scene. Previously, RTI capture methods relied on a prior knowledge of the light positions that are used to illuminate the imaging object. This knowledge is encapsulated either in a physical equipment structure such as shown in (Malzbender et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Malzbender T, Gelb D, Wolters H (2001) Polynomial texture maps. In: SIGGRAPH ’01: proceedings of the 28th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR117" id="ref-link-section-d40580e1453">2001</a>; Mudge et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Mudge M, Malzbender T, Schroer C, Lum M (2006) New reflection transformation imaging methods for rock art and multiple viewpoint display. VAST ’06: Proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR120" id="ref-link-section-d40580e1456">2006</a>) or an instructional template that gives directions for the placement of free-standing lights in predetermined locations (Dellepiane et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Dellepiane M, Corsini M, Callieri M, Scopigno R (2006) High quality PTM acquisition: reflection transformation imaging for large objects. In: VAST ’06: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR35" id="ref-link-section-d40580e1459">2006</a>).</p><p>The use of fixed-light position equipment has several advantages. Automatic control of lights and camera can acquire an RTI with great speed, frequently between 2 and 5 min. These efficiencies are valuable when large numbers of objects must be captured. This equipment also can support the optics for controlled wavelength imaging of photonically fragile cultural artefacts (Mudge et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Mudge M, Malzbender T, Schroer C, Lum M (2006) New reflection transformation imaging methods for rock art and multiple viewpoint display. VAST ’06: Proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR120" id="ref-link-section-d40580e1465">2006</a>) and multi-spectral imaging.</p><p>CHI developed a fiber-optic light delivery system to image photonically sensitive document seals on ancient documents with bandpass filters at the light source to remove damaging wavelengths such as UV and IR. The same fiber optic system employing matched sets of band pass filters has been used in multi-spectral imaging.</p><p>There are also limitations associated with fixed-light position equipment. The light distance from the object limits the object’s maximum size. Bigger objects require proportionately larger light distances. As equipment size increases, light power needs, structural requirements, transport difficulties, and costs increase. The Highlight RTI method differs from traditional RTI approaches in that the 3D locations of the lights used to construct the RTI need not be known or determined at the time the photographic images are recorded. Software can automatically find the black spheres in the RTI input photographs, locate the highlights and centres, and determine the incident direction of the light (Barbosa et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Barbosa J, Sobral JL, Proena AJ (2007) Imaging techniques to simplify the ptm generation of a bas-relief. In: VAST ’07: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR17" id="ref-link-section-d40580e1474">2007</a>).</p><p>Highlight RTI has several advantages: it is relatively inexpensive as much of the required photo equipment may already be owned by the user. The staff of the Tauric Preserve of Chersoneses was outfitted with full RTI equipment for ongoing documentation of their collection for $3,000 (excluding the computer). Most of the equipment necessary is already in widespread use. It is easy to learn and is compatible with existing working culture. Highlight RTI can capture a wide range of object sizes from 1 cm to several square meters.</p><p>In multi-view RTI, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig5">5</a>, the .rti format organises a set of RTIs captured from multiple viewing angles of the object, together with associated metadata, into a form that permits a unified, interactive viewing experience. The user captures single-view RTIs at known, equal-angle increments around part or all of the object. The set of single-view RTIs is bundled with a file indicating their order and relationship, and optical flow files (if they were created), into a single package that is accessible by the RTIViewer.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig5_HTML.jpg?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig5_HTML.jpg" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p><i>Left</i> Highlight RTI setup for small objects. <i>Right</i> Multi-view Capture Device</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Multi-view RTI acquisition hardware and software exists to speed the multi-view RTI acquisition process. The software permits user configuration of the number and position of illumination samples captured at each viewpoint. Prototype hardware, called the Multi-view Photography Apparatus (MPA), provides a platform for 2 cameras to capture RTI input images anywhere along a 150 degree inclination arc. An integrated, computer-controlled object rotation turntable permits 360 degrees of object motion relative to the cameras. The camera–object distance is also configurable, permitting the camera to move closer to or farther away from the object to allow optimum camera-lens optics for a variety of object sizes. To illuminate the object, there are 36 lights set in a 42-inch-diameter hemispheric array, which moves along the inclination arc in tandem with the cameras. For each viewpoint, the control software turns on a light, trips the camera shutter, turns off the light, downloads the photograph to the control computer and turns on the next light in the sequence.</p><p>The multi-view RTI processing software collects the input images from each viewpoint, generates .rti files for each viewpoint in the sequence, prepares the file describing their order, generates a log file for each action and bundles the files for the RTIViewer, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig6">6</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig6_HTML.jpg?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig6_HTML.jpg" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>A screen capture of RTIViewer software</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>When in single-view mode, the RTIViewer can read a high-resolution .rti or .ptm file locally or remotely over the Internet and then permit the user to zoom in dynamically, receiving portions of higher and higher resolution images. A software module preprocesses RTI content on the repository side, so that it can be accessed by remote users using the RTIViewer.</p><h3 class="c-article__sub-heading" id="Sec13">Other image-based lighting approaches</h3><p>Debevec (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Debevec P (2003) Image-based techniques for digitizing environments and artifacts. 3DIM: invited paper for the 4th international conference on 3-D digital imaging and modeling" href="/article/10.1007/s10055-010-0154-x#ref-CR42" id="ref-link-section-d40580e1546">2003</a>) presents an overview of various image-based techniques for reconstruction purposes. Some of which for modelling purposes, others for relighting. These examples include not only the previously discussed photometric approach to digitising cultural artefacts (Hawkins et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Hawkins T, Cohen J, Debevec P (2001) A photometric approach to digitizing cultural artifacts. In: VAST ’01: proceedings of the symposium on virtual reality, archeology, and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR78" id="ref-link-section-d40580e1549">2001</a>), but also Linear Light Source Reflectometry (Gardner et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Gardner A, Tchou C, Hawkins T, Debevec P (2003) Linear light source reflectometry. SIGGRAPH ’03: Proceedings of the 30th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR75" id="ref-link-section-d40580e1552">2003</a>), which presents a technique for estimating the spatially varying reflectance properties of a surface based on its appearance during a single pass of a linear light source. By using a linear light source (rather than a point light), it is possible to estimate the diffuse colour and specular colour and roughness of each point of the surface.</p></div></div></section><section aria-labelledby="Sec14"><div class="c-article-section" id="Sec14-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec14">Flame illumination</h2><div class="c-article-section__content" id="Sec14-content"><p>Up until the nineteenth century, the only light that can be considered artificial came from flames. Flame light was a requirement for visibility in dark and enclosed environments, including caves, grottos and interior of houses at night or where there was limited windows. It is clearly documented, mainly by archaeological findings, that candles and oil lamps were commonly used by past societies (Chalmers <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Chalmers A (2002) Very realistic graphics for visualising archaeological site reconstructions. In: Proceedings of 18th spring conference on computer graphics" href="/article/10.1007/s10055-010-0154-x#ref-CR25" id="ref-link-section-d40580e1564">2002</a>; Forbes <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1966" title="Forbes JR (1966) Studies in ancient technology. Leiden &amp; Brill, Netherlands" href="/article/10.1007/s10055-010-0154-x#ref-CR62" id="ref-link-section-d40580e1567">1966</a>; Egan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Egan F (1999) Fine bronze oil lamps. &#xA;                    http://www.eganbronze.com/Pages/lamps.html&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR56" id="ref-link-section-d40580e1570">1999</a>; Gonçalves et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Gonçalves A, Magalhes L, Moura J, Chalmers A (2008) Accurate modelling of roman lamps in conimbriga using high dynamic range. In: VAST ’08: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR69" id="ref-link-section-d40580e1573">2008</a>; Roussos and Chalmers <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Roussos I, Chalmers A (2003) High fidelity lighting of knossos. In: VAST ’03: proceedings of the symposium on virtual reality, archaeology and intelligent cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR142" id="ref-link-section-d40580e1576">2003</a>; Sundstedt et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Sundstedt V, Chalmers A, Martinez P (2004) High fidelity reconstruction of the ancient egyptian temple of kalabsha. In: AFRIGRAPH ’04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR151" id="ref-link-section-d40580e1580">2004</a>). This is probably because they were more stable, movable and easy to manipulate. Hearths, lamps, candles and torches were among the common placeholders for flames (Bridault-Louchez et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Bridault-Louchez F, Leblond M, Rousselle F (2006) Enhanced illumination of reconstructed dynamic environments using a real-time flame model. In: AFRIGRAPH ’06: proceedings of the 4th international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR10" id="ref-link-section-d40580e1583">2006</a>; Devlin et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Devlin K, Chalmers A, Brown D (2002a) Predictive lighting and perception in archaeological representations. In: UNESCO “World Heritage in the Digital Age” 30th Anniversary Digital Congress, UNESCO World Heritage Centre" href="/article/10.1007/s10055-010-0154-x#ref-CR34" id="ref-link-section-d40580e1586">2002</a>a; Forbes <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1966" title="Forbes JR (1966) Studies in ancient technology. Leiden &amp; Brill, Netherlands" href="/article/10.1007/s10055-010-0154-x#ref-CR62" id="ref-link-section-d40580e1589">1966</a>). Flame illumination is, therefore, a crucial part of authentic cultural heritage visualisation.</p><h3 class="c-article__sub-heading" id="Sec15">Flame data collection</h3><p>The visual appearance of past environments mostly depend on the physical properties of the flames that lit the scene. These properties depended on the components the flame was created from. Careful attention must be made to how the flames were created, as well as how they were maintained, including the flame’s colour, luminance and shape. It is also necessary to replicate all data related to the geometry, materials and illumination from and surrounding the flame such as luminaires. Some of these elements of the flame were arguably selected to create a specific visual perception for the environment, while others may have been chosen for practical reasons.</p><p>Experimental archaeology techniques may be used to build a variety of reconstruction candles and oils for lamps using appropriate materials, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig7">7</a>. Data should be based on historical records and gathered methodically, as incorrect data collection can produce erroneous spectral results, see examples in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig9">9</a>. At this stage, the aid of historian experts is crucial to the reliability of the reconstructed luminaire.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig7_HTML.jpg?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig7_HTML.jpg" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p><i>Left</i> Beeswax and tallow candles (Chalmers <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Chalmers A (2002) Very realistic graphics for visualising archaeological site reconstructions. In: Proceedings of 18th spring conference on computer graphics" href="/article/10.1007/s10055-010-0154-x#ref-CR25" id="ref-link-section-d40580e1619">2002</a>). <i>Right</i> Materials for Roman illumination: Roman lucerna, olive oil and salt (Gonçalves et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Gonçalves A, Magalhes L, Moura J, Chalmers A (2007) Metodologia para gerao de imagens high dynamic range em iluminao romana. In: Proceedings of international association for the scientific knowledge InterTIC’07" href="/article/10.1007/s10055-010-0154-x#ref-CR68" id="ref-link-section-d40580e1625">2007</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec16">Luminaires</h4><p>Ideally, historical luminaires of a period should be used to maintain the highest level of authenticity. If there are no authentic luminaires available, these can be made using methods and material available from that period and location in time. This is important as the physical shape and the manufacture material of the luminaire has an impact on the properties of the flame. For example in oil lamps the nozzle temperature causes a preheating of the fuel, then its atomisation and thus ensuring a more complete combustion (Egan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Egan F (1999) Fine bronze oil lamps. &#xA;                    http://www.eganbronze.com/Pages/lamps.html&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR56" id="ref-link-section-d40580e1644">1999</a>). Archaeological evidence indicates that lamps with wicks and fuel became more common at the close of the Bronze Age and passed between civilisations through time. Egyptians, Greeks, Romans, Byzantine among others used them for specific purposes, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig8">8</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig8_HTML.jpg?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig8_HTML.jpg" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p><i>Left</i> A Roman oil lamp (lucerna) manufactured in clay (Gonçalves et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Gonçalves A, Magalhes L, Moura J, Chalmers A (2008) Accurate modelling of roman lamps in conimbriga using high dynamic range. In: VAST ’08: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR69" id="ref-link-section-d40580e1662">2008</a>). <i>Right</i> A North African Bronze oil lamp from the seventh century A.D. (Photo by George Post © 2009) (Egan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Egan F (1999) Fine bronze oil lamps. &#xA;                    http://www.eganbronze.com/Pages/lamps.html&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR56" id="ref-link-section-d40580e1668">1999</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec17">Fuel materials</h4><p>Another important element in the spectral properties of the burning flame is the fuel used to light the luminaire. Solid fuel types can be utilised for firewood, torches and candles. Examples of materials for candles include beeswax and animal fat/tallow, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig7">7</a>. Liquid fuels for lamps include olive oil, sesame oil, fish oil and castor oil. Vegetable oils were the most common fuels used by civilisations established around the Mediterranean Sea due to the abundance of fuel supplies such as olives, sesame seeds in that region (Kimpe et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Kimpe K, Jacobs PA, Waelkens M (2001) Analysis of oil used in late roman oil lamps with different mass spectrometric techniques revealed the presence of predominantly olive oil together with traces of animal fat. J Chromatogr A 937(1–2):87–95" href="/article/10.1007/s10055-010-0154-x#ref-CR100" id="ref-link-section-d40580e1691">2001</a>). Oils produce flames with better quality compared to others from animal sources (Forbes <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1966" title="Forbes JR (1966) Studies in ancient technology. Leiden &amp; Brill, Netherlands" href="/article/10.1007/s10055-010-0154-x#ref-CR62" id="ref-link-section-d40580e1694">1966</a>). The reconstructed fuel materials should consist of the same chemical compounds and be prepared as the past fuel, or else the experimental data obtained could be inaccurate, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig9">9</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig9_HTML.gif?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig9_HTML.gif" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>S1, S2 and S3 show measurements of three samples of olive oil from different origins and manufacture procedures. S1 and S1-S are the measurements of the same olive oil; with no salt (S1) and with salt (S1-S) (Gonçalves et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Gonçalves A, Magalhes L, Moura J, Chalmers A (2008) Accurate modelling of roman lamps in conimbriga using high dynamic range. In: VAST ’08: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR69" id="ref-link-section-d40580e1710">2008</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Gonçalves A, Magalhes L, Moura J, Chalmers A (2009) High dynamic range—a gateway for predictive ancient lighting. ACM J Comput Cult Herit" href="/article/10.1007/s10055-010-0154-x#ref-CR70" id="ref-link-section-d40580e1713">2009</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>S1, S2 and S3 in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig9">9</a> present the spectral radiance of an oil lamp lighting measurements using three distinct samples of pure olive oil as fuel, without of any kind of additives during the manufacture procedure. The green and blue curves (S1 and S2) illustrate the results obtained from two samples manufactured using old traditional methods. The third sample shown by the red curve, S3, is of an olive oil closer to a common commercial olive oil, which can be purchased at an ordinary modern grocery store. In certain regions of the visible electromagnetic spectrum, this sample has an increase of approximately 50% in light intensity. This happens because the viscosity and chemical components of the olive oil differ in the manufacture process. The fuel manufacture procedure (olive oil, in this example) has major implications to the light intensities produced. Ancient manufacturing methods tend to produce inferior values of light intensity: therefore, this should be taken into account whenever these kind simulations are made.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec18">Additives in fuel materials</h4><p>All chemical components change the attributes of the flame. Salt, for instance, is a component used in Roman times because it produces a more stable and brighter flame and reduce the amount of smoke generated by a flame (Devlin and Chalmers <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Devlin K, Chalmers A (2001) Realistic visualisation of the pompeii frescoes. In: AFRIGRAPH ’01: proceedings of the 1st international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR33" id="ref-link-section-d40580e1740">2001</a>; Forbes <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1966" title="Forbes JR (1966) Studies in ancient technology. Leiden &amp; Brill, Netherlands" href="/article/10.1007/s10055-010-0154-x#ref-CR62" id="ref-link-section-d40580e1743">1966</a>; Gonçalves et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Gonçalves A, Magalhes L, Moura J, Chalmers A (2008) Accurate modelling of roman lamps in conimbriga using high dynamic range. In: VAST ’08: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR69" id="ref-link-section-d40580e1746">2008</a>). The bottom plot in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig9">9</a> compares the spectral values of two different configurations of the same olive oil sample. The mixture of salt in the olive oil has a significant impact in light intensity (brown curve) with an increase of more than 60%, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig21">21</a>. This illustrates the importance of studying all additives in fuel materials.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec19">Wicks</h4><p>Wicks also have a large influence on the quality and attributes of the flame. Woven or braided wicks were generally made from fibrous materials such as flax, linen, papyrus, tow, dry reeds, hemp or ordinary rushes (Egan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Egan F (1999) Fine bronze oil lamps. &#xA;                    http://www.eganbronze.com/Pages/lamps.html&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR56" id="ref-link-section-d40580e1763">1999</a>; Forbes <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1966" title="Forbes JR (1966) Studies in ancient technology. Leiden &amp; Brill, Netherlands" href="/article/10.1007/s10055-010-0154-x#ref-CR62" id="ref-link-section-d40580e1766">1966</a>; Gonçalves et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Gonçalves A, Magalhes L, Moura J, Chalmers A (2007) Metodologia para gerao de imagens high dynamic range em iluminao romana. In: Proceedings of international association for the scientific knowledge InterTIC’07" href="/article/10.1007/s10055-010-0154-x#ref-CR68" id="ref-link-section-d40580e1769">2007</a>). Other issues which must be considered include the length and thickness of the wick from the nozzle. This thickness is of importance as thin wicks burn fuel more slowly than thick ones without having a significant influence on the size of the flame. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig10">10</a> shows a variety of examples of wicks that can be used in such experiments.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig10_HTML.jpg?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig10_HTML.jpg" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Examples of several wicks with different diameters for use in experiments. The <i>bottom</i> right three consist of linen, while the others are made up of cotton</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec20">Measuring lighting</h4><p>To acquire the experimental data, it is necessary to measure the absolute values of the spectral properties from the light radiated on the flame under combustion. Spectroradiometers and spectrophotometers are able to measure the emission range of a light source in the visible gamut of the electromagnetic spectrum from 380 to 760 nm. The captured wavelength data can subsequently be rendered as spectral radiance or converted to RGB. Below is a compiled list of suggestions for an experiment setup to measure candle light:
</p><ul class="u-list-style-bullet">
                      <li>
                        <p>A fully dark and sealed room, with no winds to disturb the flame.</p>
                      </li>
                      <li>
                        <p>Avoid single readings, it may lead to misleading values. Multiple readings can be averaged.</p>
                      </li>
                      <li>
                        <p>The burning luminaire should be placed against a board perfectly diffuse and with a reflectance factor closer to 100%.</p>
                      </li>
                      <li>
                        <p>A calibrated spectroradiometer placed perpendicularly to the board, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig11">11</a>.</p>
                      </li>
                      <li>
                        <p>The reading must be made solely from the reflected light on the board, and not of the flame.</p>
                      </li>
                      <li>
                        <p>Measurements should be made in small wavelength intervals, typically; 4–5 nm.</p>
                      </li>
                      <li>
                        <p>Avoid specular surfaces near the experiment.</p>
                      </li>
                    </ul>
                              <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig11_HTML.jpg?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig11_HTML.jpg" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Spectral readings of an oil lamp. The light emitted by the lamp is almost entirely reflected on the white board which is then captured by the spectroradiometer (Gonçalves et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Gonçalves A, Magalhes L, Moura J, Chalmers A (2008) Accurate modelling of roman lamps in conimbriga using high dynamic range. In: VAST ’08: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR69" id="ref-link-section-d40580e1858">2008</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Spectroradiometers needs to be connected to a computer that collect the spectral readings. A full reading can take several minutes, depending on the interval established. Possible results of this kind of experiments can be perceived in the graphs in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig9">9</a>. It is vital, when converting the detailed spectrum data from the spectroradiometer into values representing the red, green and blue portions of the spectrum, that this conversion is calculated in a perceptually valid way, as defined by the CIE (Commission International de l’Eclairage) 1931 2° or 10° standard observer (Devlin and Chalmers <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Devlin K, Chalmers A (2001) Realistic visualisation of the pompeii frescoes. In: AFRIGRAPH ’01: proceedings of the 1st international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR33" id="ref-link-section-d40580e1876">2001</a>).</p><h3 class="c-article__sub-heading" id="Sec21">Flame simulation</h3><p>There are several approaches to simulating flames. One of the earliest examples is the use of particle systems (Perry and Picard <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Perry CH, Picard RW (1994) Synthesizing flames and their spreading. In: Proceedings of the 5th Eurographics workshop on animation and simulation" href="/article/10.1007/s10055-010-0154-x#ref-CR134" id="ref-link-section-d40580e1888">1994</a>; Reeves <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1983" title="Reeves WT (1983) Particle systems—a technique for modeling a class of fuzzy objects. ACM Trans Graph 2(2):91–108" href="/article/10.1007/s10055-010-0154-x#ref-CR143" id="ref-link-section-d40580e1891">1983</a>; Stam and Fiume <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Stam J, Fiume E (1995) Depicting fire and other gaseous phenomena using diffusion processes. In: SIGGRAPH ’95: proceedings of the 22nd annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR152" id="ref-link-section-d40580e1894">1995</a>; Takahashi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Takahashi J-y, Takahashi H, Chiba N (1997) Image synthesis of flickering scenes including simulated flames. IEICE Trans Inf Syst" href="/article/10.1007/s10055-010-0154-x#ref-CR167" id="ref-link-section-d40580e1897">1997</a>). Particle systems refers to common techniques in computer graphics in which it is possible to simulate certain phenomena that are otherwise difficult to replicate through conventional rendering approaches. A particle system typically has an emitter, which acts as the source of the particles. Sets of parameters define the behaviour of the emitted particles, these can include initial velocity vectors, particle lifetime and colour.</p><p>Inakage (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1990" title="Inakage M (1990) A simple model of flames. In: CG international ’90: proceedings of the eighth international conference of the computer graphics society on CG international ’90: computer graphics around the world" href="/article/10.1007/s10055-010-0154-x#ref-CR89" id="ref-link-section-d40580e1903">1990</a>) proposed one of the first still candle flame models. It was based on the physical scattering of light emission and transmission in the regions of combustion. Rendering is achieved by applying a texture map to a geometrical primitive similar to a flame which is then volume rendered. Raczkowski (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Raczkowski J (1996) Visual simulation and animation of a laminar candle flame. In: International conference on image processing and computer graphics" href="/article/10.1007/s10055-010-0154-x#ref-CR139" id="ref-link-section-d40580e1906">1996</a>) extended this work to incorporate the dynamic nature of the flame.</p><p>An alternative approach is to incorporate video footage of a real flames into a virtual environment as suggested by Devlin and Chalmers (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Devlin K, Chalmers A (2001) Realistic visualisation of the pompeii frescoes. In: AFRIGRAPH ’01: proceedings of the 1st international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR33" id="ref-link-section-d40580e1912">2001</a>), see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig12">12</a>. The illumination of the flame is computed from the size and position of the flame, and not recorded in the video. Filming the flame against an evenly green coloured, matt background enables a threshold for each frame, which can be used to identify and dismiss the background colour. This effectively separates the flame from any unwanted parts of the scene. In Radiance, the illumination of the flame can consist of a series of <i>illum</i> spheres, as detailed in by Devlin and Chalmers <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference (2001" title="Devlin K, Chalmers A (2001) Realistic visualisation of the pompeii frescoes. In: AFRIGRAPH ’01: proceedings of the 1st international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR33" id="ref-link-section-d40580e1921">(2001</a>), Chalmers et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference (2002" title="Chalmers A, Devlin K, Brown D, Debevec P, Martinez P, Ward G (2002) Recreating the Past. SIGGRAPH Course" href="/article/10.1007/s10055-010-0154-x#ref-CR20" id="ref-link-section-d40580e1924">(2002</a>) see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig12">12</a>. When viewed directly, the spheres are invisible but emit light in the area they occupy. The number and size of the spheres can vary to achieve a better fit to the shape of the flame for each frame in the video sequence.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig12_HTML.jpg?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig12_HTML.jpg" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p><i>Left</i> Simple luminaire model. <i>Right</i> Real flame in virtual environment (Devlin and Chalmers <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Devlin K, Chalmers A (2001) Realistic visualisation of the pompeii frescoes. In: AFRIGRAPH ’01: proceedings of the 1st international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR33" id="ref-link-section-d40580e1946">2001</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Beaudoin et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Beaudoin P, Paquet S, Poulin P (2001) Realistic and controllable fire simulation. In: GRIN’01: no description on graphics interface 2001" href="/article/10.1007/s10055-010-0154-x#ref-CR16" id="ref-link-section-d40580e1961">2001</a>) illustrate how to represent fire as a collection of individual flames that are deformed according to a space and a time-dependent vector field to simulate the visual dynamics of fire. However, their model lacks accurate smoke and air motion inside the simulation volume.</p><p>Lamorlette and Foster (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Lamorlette A, Foster N (2002) Structural modeling of flames for a production environment. In: SIGGRAPH ’02: proceedings of the 29th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR108" id="ref-link-section-d40580e1968">2002</a>) modelled flame elements as parametric curves with several interpolation points. The curves react according to statistical measurements of natural diffusion flames. Procedural noise is applied to the particles where each particle is coloured based on the colour properties of its neighbours.</p><p>Melek and Keyser <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference (2002" title="Melek Z, Keyser J (2002) Interactive simulation of fire. Technical Report 2002-7-1, Texas A&amp;M University, Department of Computer Science" href="/article/10.1007/s10055-010-0154-x#ref-CR118" id="ref-link-section-d40580e1974">(2002</a>) developed a method to simulate flames combusted by fuel gases. A modified interactive grid fluid dynamics equation solver was used to describe the motion of a 3-gas system (fuel, air and exhaust gasses). The burning process is simulated by the amounts of fuel and air consumption in each grid cell which allow them to gain interactivity in the process while maintaining realistic modelling and visualisation of fire flames.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-13"><figure><figcaption><b id="Fig13" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 13</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/13" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig13_HTML.jpg?as=webp"></source><img aria-describedby="figure-13-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig13_HTML.jpg" alt="figure13" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-13-desc"><p><i>Left</i> Comparison of flame shapes for differing degrees of gaseous expansion. <i>Right</i> Two burning logs are placed on the ground and used to emit fuel. The top, unlit crossways log forces the flame to flow around it (Nguyen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Nguyen DQ, Fedkiw R, Jensen HW (2002) Physically based modeling and animation of fire. SIGGRAPH ’02: Proceedings of the 29th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR129" id="ref-link-section-d40580e1992">2002</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/13" data-track-dest="link:Figure13 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Nguyen et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Nguyen DQ, Fedkiw R, Jensen HW (2002) Physically based modeling and animation of fire. SIGGRAPH ’02: Proceedings of the 29th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR129" id="ref-link-section-d40580e2007">2002</a>) present a physically based model to reproduce realistic both smooth and turbulent flames from solid and gaseous fuels, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig13">13</a>. The method innovates in the reproduction of the interaction of fire with flammable and non-flammable objects and in the expansion of the fuel as it reacts to form hot gaseous products. This was achieved by using implicit surfaces to represent the reaction zone where the gaseous fuel is combusted. For a blackbody, the emitted spectral radiance is computed using Planck’s formula.</p><p>Hasinoff and Kutulakos <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference (2003" title="Hasinoff SW, Kutulakos KN (2003) Photo-consistent 3d fire by flame-sheet decomposition. In: ICCV ’03: proceedings of the ninth IEEE international conference on computer vision" href="/article/10.1007/s10055-010-0154-x#ref-CR82" id="ref-link-section-d40580e2016">(2003</a>) and  Ihrke and Magnor (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Ihrke I, Magnor M (2004) Image-based tomographic reconstruction of flames. In: SCA ’04: proceedings of the ACM SIGGRAPH/Eurographics symposium on computer animation" href="/article/10.1007/s10055-010-0154-x#ref-CR88" id="ref-link-section-d40580e2019">2004</a>) proposed to employ a tomographic methodology for reconstructing volumetric flames from several pictures of a fire. Pegoraro and Parker <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference (2006" title="Pegoraro V, Parker SG (2006) Pshysically based realistic fire rendering. In: Proceedings of the 2nd Eurographics workshop on natural phenomena" href="/article/10.1007/s10055-010-0154-x#ref-CR135" id="ref-link-section-d40580e2022">(2006</a>) use molecular physics properties of the various chemical compounds of fire to compute realistic fire flames. Their rendering algorithm employs detailed simulation of radiative emission and refractive transfer that occurs in real flames.</p><p>Bridault-Louchez et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Bridault-Louchez F, Leblond M, Rousselle F (2006) Enhanced illumination of reconstructed dynamic environments using a real-time flame model. In: AFRIGRAPH ’06: proceedings of the 4th international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR10" id="ref-link-section-d40580e2028">2006</a>) and Bridault et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference (2007" title="Bridault F, Lebond M, Rousselle F, Renaud C (2007) Real-time rendering and animation of plentiful flames. In: Proceedings of the 3rd Eurographics workshop on natural phenomena" href="/article/10.1007/s10055-010-0154-x#ref-CR11" id="ref-link-section-d40580e2031">(2007</a>) generate particles that can be used to control the Non-uniform rational B-splines (NURBS) surfaces that models the flame on which a transparent 2D texture is mapped. This is done to compute the flame flickering in real time. The authors compute the illumination by coding the photometric distribution of a real flame directly into a pixel shader on the GPU.</p><p>
                  <b>Part 2:</b>
                  <b>Illuminating the past</b>
                </p></div></div></section><section aria-labelledby="Sec22"><div class="c-article-section" id="Sec22-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec22">Cultural heritage reconstructions</h2><div class="c-article-section__content" id="Sec22-content"><p>Forte et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Forte M, Siliotti A, Renfrew C (1997) Virtual archaeology: re-creating ancient worlds. Harry N Abrams, New York" href="/article/10.1007/s10055-010-0154-x#ref-CR64" id="ref-link-section-d40580e2052">1997</a>) present an extensive overview of the earliest cultural heritage reconstructions. Despite attempting accurate rendering, few of the reconstructions stand out as close to accurate models compared to today’s standards. However, this is primarily due to the vast advancements in hardware and software solutions that have emerged in the past 12 years. Some well-known historical examples from the book include Stonehenge, the Parthenon, the Sphinx and the Pyramids at Giza.</p><h3 class="c-article__sub-heading" id="Sec23">Reconstruction with sky illumination models</h3><p>Foni et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Foni A, Papagiannakis G, Magnenat-Thalmann N (2002) Virtual hagia sophia: restitution, visualization and virtual life simulation. Presented at the UNESCO World Heritage Congress" href="/article/10.1007/s10055-010-0154-x#ref-CR63" id="ref-link-section-d40580e2062">2002</a>) detail a virtual reconstruction of the Hagia Sofia in Istanbul. Virtual texture restoration is a key topic in this paper due to the severely damaged decorative walls and ceilings. This was done using commercial photo editing software. While this may not be a physically correct approach to restore texture detail, there still remains research to reverse engineer details as texture maps and BRDFs. A render plug-in for 3DS Max (Autodesk <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009a" title="Autodesk (2009a) 3DS Max website. &#xA;                    http://www.autodesk.com/3dsmax&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR7" id="ref-link-section-d40580e2065">2009a</a>) was used in the reconstruction to create realistic interior lighting. Another topic prevalent in the paper is the importance of global illumination for cultural heritage reconstructions. This is unlike several reconstructions that consist of largely same colour diffuse materials.</p><p>Kalabsha is a temple in Egypt that was dismantled and moved in the 1960s to save it from the rising water of Lake Nasser. The purpose of the reconstruction (Sundstedt et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Sundstedt V, Chalmers A, Martinez P (2004) High fidelity reconstruction of the ancient egyptian temple of kalabsha. In: AFRIGRAPH ’04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR151" id="ref-link-section-d40580e2071">2004</a>) was to relight the temple in its previous position as it stood when it was first built 2000 years ago. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig14">14</a> shows two images of the temple of Kalabsha in Egypt employing <i>gensky</i> in Radiance compared with a photograph of the temple today.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-14"><figure><figcaption><b id="Fig14" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 14</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/14" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig14_HTML.jpg?as=webp"></source><img aria-describedby="figure-14-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig14_HTML.jpg" alt="figure14" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-14-desc"><p><i>Top</i> Photograph and Render comparison. <i>Bottom Left</i> Daylight at the Temple of Kalabsha at 9 am on 21 January photograph 2003. <i>Bottom Right</i> Daylight simulation 30BC (Sundstedt et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Sundstedt V, Chalmers A, Martinez P (2004) High fidelity reconstruction of the ancient egyptian temple of kalabsha. In: AFRIGRAPH ’04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR151" id="ref-link-section-d40580e2098">2004</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/14" data-track-dest="link:Figure14 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Debevec (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Debevec P (2005) Making ‘The Parthenon’. Invited paper: VAST ’05: International symposium on virtual reality, archaeology, and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR43" id="ref-link-section-d40580e2113">2005</a>), Debevec et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Debevec P, Tchou C, Gardner A, Hawkins T, Poullis C, Stumpfel J, Jones A, Yun N, Einarsson P, Lundgren T, Fajardo M, Martinez P (2004) Estimating surface reflectance properties of a complex scene under captured natural illumination. In USC ICT technical report ICT-TR-06.2004" href="/article/10.1007/s10055-010-0154-x#ref-CR50" id="ref-link-section-d40580e2116">2004</a>) detail a reconstruction of The Parthenon in Greece as it stands today and its ancient form, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig15">15</a>. In the former paper, the authors estimated diffuse surface colours of the scene lit by sunlight illumination. The paper describes the approach to calculate the spatially varying diffuse surface reflectance given the scene’s geometry, a set of photographs taken under natural illumination, and corresponding measurements of the illumination. Debevec (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Debevec P (2005) Making ‘The Parthenon’. Invited paper: VAST ’05: International symposium on virtual reality, archaeology, and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR43" id="ref-link-section-d40580e2122">2005</a>) then overviews the technology and production processes used to create the model. Einarsson et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Einarsson P, Hawkins T, Debevec P (2004) Photometric stereo for archeological inscriptions. In: SIGGRAPH ’04: ACM SIGGRAPH 2004 Sketches" href="/article/10.1007/s10055-010-0154-x#ref-CR57" id="ref-link-section-d40580e2125">2004</a>) described a low-cost system for acquiring high-resolution geometry and reflectance properties using photometric stereo and was used to model ancient inscriptions on the Parthenon. The reconstruction is expanded upon to cover real-time realistic rendering through precomputed lighting on the GPU by Callieri et al (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Callieri M, Debevec P, Pair J, Scopigno R (2006) A realtime immersive application with realistic lighting: the Parthenon. Comput Graph 30(3):368–376" href="/article/10.1007/s10055-010-0154-x#ref-CR21" id="ref-link-section-d40580e2129">2006</a>) and relit using the approach to capture an HDR environment map by Stumpfel et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Stumpfel J, Jones A, Wenger A, Tchou C, Hawkins T, Debevec P (2004) Direct HDR capture of the sun and sky. In: AFRIGRAPH ’04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR157" id="ref-link-section-d40580e2132">2004</a>). Sander (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Sander P (2006) The Parthenon demo preprocessing and real-time rendering techniques for large datasets. SIGGRAPH" href="/article/10.1007/s10055-010-0154-x#ref-CR150" id="ref-link-section-d40580e2135">2006</a>) uses level of detail approaches to render the scene for real-time purposes.</p><p>CAVE-like systems surround the user with large displays. Gutierrez et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Gutierrez D, Seron F, Magallon J, Sobreviela E, Latorre P (2004) Archaeological and cultural heritage: bringing life to an unearthed muslim suburb in an immersive environment. J Cult Herit" href="/article/10.1007/s10055-010-0154-x#ref-CR73" id="ref-link-section-d40580e2141">2004</a>) present use of realistic lighting in a CAVE-like system for their virtual tenth to twelfth century Muslim suburb Sinhaya. The lighting was calculated using the authors’ in-house Monte Carlo global illumination software. The user could specify a time and a day, atmospheric conditions, and obtain a complete sun and sky model to light the scene. However, only natural light could be used in the application. The authors also discuss the inherent difficulty of adding presence in virtual environments.</p><p>A domestic building from Roman Italica in Andalucia, Spain is presented in by Earl (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Earl GP (2005) Wandering the house of the birds: reconstruction and perception at roman italica. In: VAST ’05: Symposium on virtual reality, archaeology and cultural heritage, short papers" href="/article/10.1007/s10055-010-0154-x#ref-CR52" id="ref-link-section-d40580e2148">2005</a>). Earl uses standard textures to provide an initial impression of the scene. In addition, however, illumination is captured through automatic unwrapping of many thousands of textures produced under varying lighting conditions. These lighting conditions in turn simulate visual prominence of different parts of the site.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-15"><figure><figcaption><b id="Fig15" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 15</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/15" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig15_HTML.jpg?as=webp"></source><img aria-describedby="figure-15-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig15_HTML.jpg" alt="figure15" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-15-desc"><p>Various images of the Parthenon. <i>Top Left</i> Evening render. <i>Top Right</i> The restored version on the ancient Acropolis. <i>Bottom Left</i> Modern day photograph. <i>Bottom Right</i> Daylight modern render (Debevec <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Debevec P (2005) Making ‘The Parthenon’. Invited paper: VAST ’05: International symposium on virtual reality, archaeology, and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR43" id="ref-link-section-d40580e2173">2005</a>; Debevec et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Debevec P, Tchou C, Gardner A, Hawkins T, Poullis C, Stumpfel J, Jones A, Yun N, Einarsson P, Lundgren T, Fajardo M, Martinez P (2004) Estimating surface reflectance properties of a complex scene under captured natural illumination. In USC ICT technical report ICT-TR-06.2004" href="/article/10.1007/s10055-010-0154-x#ref-CR50" id="ref-link-section-d40580e2177">2004</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/15" data-track-dest="link:Figure15 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Rome Reborn is a project that aims to reconstruct ancient Rome. While the initial reconstruction was based on laser-scanned models, version 2.0 was a procedurally generated city and uses an HDR Environment map of the sky captured in Rome to illuminate the city in a realistic fashion (Frischer et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Frischer B, Abernathy D, Guidi G, Myers J, Thibodeau C, Salvemini A, Müller P, Hofstee P, Minor B (2008) Rome reborn. In: SIGGRAPH ’08: ACM SIGGRAPH new tech demos" href="/article/10.1007/s10055-010-0154-x#ref-CR60" id="ref-link-section-d40580e2192">2008</a>).</p><p>Earl et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Earl GP, Keay SJ, Beale G (2008) Computer graphic modelling at portus: analysis, reconstruction and representation of the claudian and trajanic harbours. In: Proceedings of EARSEL SIG remote sensing for archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR58" id="ref-link-section-d40580e2198">2008</a>) discuss the uses of computer graphics, including illumination for now-demolished spaces in and around the proposed Imperial Palace at Portus, Italy. The authors illustrate their approach with three alternative architectural scenarios.</p><p>Corsini et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Corsini M, Callieri M, Cignoni P (2008) Stereo light probe. Comput Graph Forum 27(2):291–300" href="/article/10.1007/s10055-010-0154-x#ref-CR19" id="ref-link-section-d40580e2204">2008</a>) introduce <i>Stereo Light Probes</i> to relight a scanned model of Michelangelo’s David, presented by Koller et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Koller D, Turitzin M, Levoy M, Tarini M, Croccia G, Cignoni P, Scopigno R (2004) Protected interactive 3d graphics via remote rendering. In: SIGGRAPH ’04: proceedings of the 31st annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR106" id="ref-link-section-d40580e2210">2004</a>). This is done to illustrate the significant visual difference of using two light probes compared to a single one, and shows how multiple copies of David appear significantly different with statues casting shadows on one another to a much greater extent with the use of two light probes.</p><p>Happa et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009a" title="Happa J, Artusi A, Dubla P, Bashford-Rogers T, Debattista K, Hulusić V, Chalmers A (2009) The virtual reconstruction and daylight illumination of the panagia angeloktisti. In: VAST ’09: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR77" id="ref-link-section-d40580e2216">2009a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Happa J, Williams M, Turley G, Earl GP, Dubla P, Beale G, Gibbons G, Debattista K, Chalmers A (2009) Virtual relighting of a roman statue head from herculaneum: a case study. In: AFRIGRAPH ’09: proceedings of the 6th international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR85" id="ref-link-section-d40580e2219">b</a>) illustrate two case studies of the pipeline for the data acquisition, post-processing and rendering of cultural heritage objects and environments. The first, a Roman statue head of an Amazon [further discussed by (Earl <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009b" title="Earl GP (2009b) In press physical and photo-realism: the herculaneum amazon. In: Plenary session: fundamentos tericos de la Arqueologa virtual. Proceedings of Arqueologica 2.0 Seville" href="/article/10.1007/s10055-010-0154-x#ref-CR54" id="ref-link-section-d40580e2222">2009b</a>, Earl et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Earl GP, Beale G, Happa J, Williams M, Turley G, Martinez K, Chalmers A (2009) A repainted amazon. In: Proceedings of the EVA London conference" href="/article/10.1007/s10055-010-0154-x#ref-CR55" id="ref-link-section-d40580e2225">2009</a>)], the second, a reconstruction of the Panagia Angeloktisti; a Byzantine church in Cyprus, lit at various times in the day, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig16">16</a>. Both papers emphasise how unbiased rendering for cultural heritage reconstructions can be useful for interpreting the past, making use of Path Tracing and MLT.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-16"><figure><figcaption><b id="Fig16" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 16</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/16" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig16_HTML.jpg?as=webp"></source><img aria-describedby="figure-16-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig16_HTML.jpg" alt="figure16" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-16-desc"><p><i>Top Left</i> A Roman statue head of an Amazon lit under light captured on top of Mount Vesuvius. <i>Top Right</i> The head, added interior environment and a directional light source. Full Environment Map seen in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig2">2</a> (Happa et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Happa J, Williams M, Turley G, Earl GP, Dubla P, Beale G, Gibbons G, Debattista K, Chalmers A (2009) Virtual relighting of a roman statue head from herculaneum: a case study. In: AFRIGRAPH ’09: proceedings of the 6th international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR85" id="ref-link-section-d40580e2250">2009</a>). <i>Bottom Left</i> Interior render of the Panagia Angeloktisti at mid-day. <i>Bottom Right</i> Exterior render of the Panagia Angeloktisti at mid-day (Happa et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Happa J, Artusi A, Dubla P, Bashford-Rogers T, Debattista K, Hulusić V, Chalmers A (2009) The virtual reconstruction and daylight illumination of the panagia angeloktisti. In: VAST ’09: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR77" id="ref-link-section-d40580e2260">2009</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/16" data-track-dest="link:Figure16 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>A reconstruction of the Minoan Cemetery at Phourni in Crete is presented by Papadopoulos and Earl (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009a" title="Earl CPGP (2009a) Structural and lighting models for the minoan cemetery at Phourni, crete. In: VAST ’09: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR53" id="ref-link-section-d40580e2275">2009a</a>). The authors use a physical sky generated in Mental Ray to evaluate the tombs’ architecture, use, visual impact, their capacity as well as the contribution of illumination to their interior.</p><h3 class="c-article__sub-heading" id="Sec24">Image-based techniques and examples</h3><p>The application of Reflectance Fields is described by Hawkins et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Hawkins T, Cohen J, Debevec P (2001) A photometric approach to digitizing cultural artifacts. In: VAST ’01: proceedings of the symposium on virtual reality, archeology, and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR78" id="ref-link-section-d40580e2286">2001</a>) and employed to a number of Native American cultural artefacts including an otter fur headband, a feathered headdress, an animal-skin drum, and several pieces of neckwear and clothing. Gardner et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Gardner A, Tchou C, Hawkins T, Debevec P (2003) Linear light source reflectometry. SIGGRAPH ’03: Proceedings of the 30th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR75" id="ref-link-section-d40580e2289">2003</a>) illustrate recovering reflectance parameters using Linear Light Source Reflectometry for an mediaeval illuminated manuscript and relights it with IBL.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec25">Reflectance transformation imaging examples</h4><p>RTI’s documentary usefulness has been demonstrated in several natural science and cultural heritage object areas and offers significant advantages; (Cultural Heritage <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Cultural Heritage Imaging (2009) CHI Webpage. &#xA;                    http://www.c-h-i.org/featured_projects/featured_projects.html&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR31" id="ref-link-section-d40580e2299">2009</a>; Freeth et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Freeth T, Bitsakis Y, Moussas X, Seiradakis J, Tselikas A, Mangou H, Zafeiropoulou M, Hadland R, Bate D, Ramsey A, Allen M, Crawley A, Hockley P, Malzbender T, Gelb D, Ambrisco W, Edmunds M (2006) Decoding the ancient greek astronomical calculator known as the antikythera mechanism. Nature 444:587–591" href="/article/10.1007/s10055-010-0154-x#ref-CR61" id="ref-link-section-d40580e2302">2006</a>; Malzbender <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Malzbender T (2006) Tom malzbender publication list. &#xA;                    http://www.hpl.hp.com/personal/Tom_Malzbender/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR114" id="ref-link-section-d40580e2305">2006</a>; Malzbender et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Malzbender T, Gelb D, Wolters H (2001) Polynomial texture maps. In: SIGGRAPH ’01: proceedings of the 28th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR117" id="ref-link-section-d40580e2308">2001</a>; Mudge et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Mudge M, Voutaz J-P, Schroer C, Lum M (2005) Reflection transformation imaging and virtual representations of coins from the hospice of the grand St. Bernard. In: VAST ’05: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR125" id="ref-link-section-d40580e2311">2005</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Mudge M, Malzbender T, Schroer C, Lum M (2006) New reflection transformation imaging methods for rock art and multiple viewpoint display. VAST ’06: Proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR120" id="ref-link-section-d40580e2315">2006</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Mudge M, Malzbender T, Chalmers A, Scopigno R, Davis J, Wang O, Gunawardane P, Ashley M, Doerr M, Proenca A, Barbosa J (2008) Image-based empirical acquisition, scientific reliability, and long-term digital preservation for the natural sciences and cultural heritage. Eurographics Tutorial Notes" href="/article/10.1007/s10055-010-0154-x#ref-CR119" id="ref-link-section-d40580e2318">2008</a>; Malzbender and Ordentlict <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Malzbender T, Ordentlict E (2005) Maximum entropy lighting for physical objects. Hewlett-Packard Technical Report HPL-2005-68" href="/article/10.1007/s10055-010-0154-x#ref-CR122" id="ref-link-section-d40580e2321">2005</a>; Mudge <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Mudge M (2004) Implementing digital technology adoption by cultural heritage professionalsl. SIGGRAPH ’04: Conference presentations for cultural heritage and computer graphics panel" href="/article/10.1007/s10055-010-0154-x#ref-CR124" id="ref-link-section-d40580e2324">2004</a>; ; Zányi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007b" title="Zányi E, Schroer C, Mudge MAC (2007b) Lighting and byzantine glass tesserae. In: Proceedings of the 2009 EVA London conference" href="/article/10.1007/s10055-010-0154-x#ref-CR184" id="ref-link-section-d40580e2327">2007b</a>). The use of RTI with PTMs in cultural heritage documentation projects, the natural sciences and law enforcement, as well as other Image-Based Re-lighting (IBRL) applications has been detailed extensively elsewhere, including:
</p><ul class="u-list-style-bullet">
                      <li>
                        <p>Non-contact acquisition of data.</p>
                      </li>
                      <li>
                        <p>Clear representation of 3D shape characteristics through interactive viewing tools.</p>
                      </li>
                      <li>
                        <p>Data discernment improvements over direct physical examination through RTI enhancement functions.</p>
                      </li>
                      <li>
                        <p>No data loss due to shadows and specular highlights.</p>
                      </li>
                      <li>
                        <p>High-resolution sample densities (Malzbender and Ordentlict <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Malzbender T, Ordentlict E (2005) Maximum entropy lighting for physical objects. Hewlett-Packard Technical Report HPL-2005-68" href="/article/10.1007/s10055-010-0154-x#ref-CR122" id="ref-link-section-d40580e2356">2005</a>).</p>
                      </li>
                      <li>
                        <p>Automatic determination of the most information-rich illumination directions (Malzbender and Ordentlict <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Malzbender T, Ordentlict E (2005) Maximum entropy lighting for physical objects. Hewlett-Packard Technical Report HPL-2005-68" href="/article/10.1007/s10055-010-0154-x#ref-CR122" id="ref-link-section-d40580e2366">2005</a>).</p>
                      </li>
                      <li>
                        <p>Simple and achievable image processing pipeline.</p>
                      </li>
                      <li>
                        <p>Easy online communication (Archaeological Computing Research and University of <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Archaeological Computing Research Group, University of Southampton (2009) A polynomial texture map of an amazon statue, interactive demo. &#xA;                    http://www.soton.ac.uk/archaeology/acrg/acrg_research_amazon.html&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR6" id="ref-link-section-d40580e2380">2009</a>).</p>
                      </li>
                    </ul>
                           <p>The top two images in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig17">17</a> show two images of the coin commemorating Julius Caesar’s Funeral Games. The Comet appearing during these games is circled in its full context and then magnified. Due to heavy wear, there is significant abrasion of the coin’s surface features. On the right of the figure, the coin is seen in its Specular Enhancement mode. The specular enhancement mode shows, with superior clarity, the four rays of light surrounding the comet, along with the triangular comets tail extending behind it at the ‘five o’clock’ position.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-17"><figure><figcaption><b id="Fig17" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 17</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/17" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig17_HTML.jpg?as=webp"></source><img aria-describedby="figure-17-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig17_HTML.jpg" alt="figure17" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-17-desc"><p><i>Top Left</i> Unenhanced ‘Julian Star’, the coin is seen in its natural, primarily diffuse mode. <i>Top Right</i> ‘Julian Star’ with Specular Enhancement. <i>Bottom Left</i> Highlighted surface areas are hidden. <i>Bottom Right</i> Surfaces visible</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/17" data-track-dest="link:Figure17 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Mudge et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Mudge M, Voutaz J-P, Schroer C, Lum M (2005) Reflection transformation imaging and virtual representations of coins from the hospice of the grand St. Bernard. In: VAST ’05: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR125" id="ref-link-section-d40580e2425">2005</a>) confirmed previous observations that RTIs were able to robustly document the surfaces of highly specular materials, particularly gold. The bottom images in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig17">17</a> show two images of the obverse of the Merovingian Triens. The bottom left image of the same figure is one of the twenty four input images for the PTM and shows where specular reflections have caused data loss.</p><p>The Antikythera Mechanism was an ancient Greek geared device, constructed at the end of the second century BC. It was used to calculate and displayed celestial information. Freeth et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Freeth T, Bitsakis Y, Moussas X, Seiradakis J, Tselikas A, Mangou H, Zafeiropoulou M, Hadland R, Bate D, Ramsey A, Allen M, Crawley A, Hockley P, Malzbender T, Gelb D, Ambrisco W, Edmunds M (2006) Decoding the ancient greek astronomical calculator known as the antikythera mechanism. Nature 444:587–591" href="/article/10.1007/s10055-010-0154-x#ref-CR61" id="ref-link-section-d40580e2434">2006</a>) describes how surface imaging and high-resolution X-ray tomography of the surviving fragments, enabling the reconstruction the gear function and double the number of deciphered inscriptions.</p><h3 class="c-article__sub-heading" id="Sec26">Reconstruction of ancient flames</h3><p>While several societies in the past may have created fire from arbitrary items in their surroundings, others carefully selected the content of their fuel to ignite the flames in their environments (Devlin and Chalmers <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Devlin K, Chalmers A (2001) Realistic visualisation of the pompeii frescoes. In: AFRIGRAPH ’01: proceedings of the 1st international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR33" id="ref-link-section-d40580e2446">2001</a>; Devlin et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Devlin K, Chalmers A, Brown D (2002a) Predictive lighting and perception in archaeological representations. In: UNESCO “World Heritage in the Digital Age” 30th Anniversary Digital Congress, UNESCO World Heritage Centre" href="/article/10.1007/s10055-010-0154-x#ref-CR34" id="ref-link-section-d40580e2449">2002</a>a; Gonçalves et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Gonçalves A, Magalhes L, Moura J, Chalmers A (2008) Accurate modelling of roman lamps in conimbriga using high dynamic range. In: VAST ’08: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR69" id="ref-link-section-d40580e2452">2008</a>; Sundstedt et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Sundstedt V, Chalmers A, Martinez P (2004) High fidelity reconstruction of the ancient egyptian temple of kalabsha. In: AFRIGRAPH ’04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR151" id="ref-link-section-d40580e2455">2004</a>; Zányi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007a" title="Zányi E, Chrysanthou Y, Bashford-Rogers T, Chalmers A (2007a) High dynamic range display of authentically illuminated byzantine art from Cyprus. In: VAST ’07: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR183" id="ref-link-section-d40580e2458">2007a</a>). The resources were needed for other purposes, in domestic uses for example, or because the lighting properties of some specific fuels can affect the perception of the artefacts that they illuminate.</p><p>Devlin and Chalmers (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Devlin K, Chalmers A (2001) Realistic visualisation of the pompeii frescoes. In: AFRIGRAPH ’01: proceedings of the 1st international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR33" id="ref-link-section-d40580e2464">2001</a>) investigate Pompeii frescoes viewed under olive oil lamp. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig18">18</a> illustrates how virtual scenarios appear significantly different when viewed with modern lighting, revealing details and perception not possible by other means (Chalmers et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Chalmers A, Devlin K, Brown D, Debevec P, Martinez P, Ward G (2002) Recreating the Past. SIGGRAPH Course" href="/article/10.1007/s10055-010-0154-x#ref-CR20" id="ref-link-section-d40580e2470">2002</a>). Topics archaeologists can explore from these examples are related to discussing whether the inclusion of flames made ancient artists deliberately choose colours dependent what they saw, or what they wanted other viewers to see.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-18"><figure><figcaption><b id="Fig18" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 18</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/18" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig18_HTML.jpg?as=webp"></source><img aria-describedby="figure-18-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig18_HTML.jpg" alt="figure18" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-18-desc"><p><i>Top left</i> Mediaeval painting lit by modern lighting. <i>Top right</i> The same painting lit by simulated mediaeval candles (Chalmers et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Chalmers A, Devlin K, Brown D, Debevec P, Martinez P, Ward G (2002) Recreating the Past. SIGGRAPH Course" href="/article/10.1007/s10055-010-0154-x#ref-CR20" id="ref-link-section-d40580e2488">2002</a>).<i> Bottom left</i>: Frescoes in Pompeii lit by modern lighting. <i>Bottom right</i> Same room with authentic candles and olive oil lamp (Devlin and Chalmers <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Devlin K, Chalmers A (2001) Realistic visualisation of the pompeii frescoes. In: AFRIGRAPH ’01: proceedings of the 1st international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR33" id="ref-link-section-d40580e2497">2001</a>; Devlin et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Devlin K, Chalmers A, Brown D (2002a) Predictive lighting and perception in archaeological representations. In: UNESCO “World Heritage in the Digital Age” 30th Anniversary Digital Congress, UNESCO World Heritage Centre" href="/article/10.1007/s10055-010-0154-x#ref-CR34" id="ref-link-section-d40580e2501">2002</a>a)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/18" data-track-dest="link:Figure18 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Chalmers et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Chalmers A, Green C, Hall M (2000) Firelight: graphics and archaeology. SIGGRAPH Electronic Theatre" href="/article/10.1007/s10055-010-0154-x#ref-CR22" id="ref-link-section-d40580e2516">2000</a>) and Chalmers (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Chalmers A (2002) Very realistic graphics for visualising archaeological site reconstructions. In: Proceedings of 18th spring conference on computer graphics" href="/article/10.1007/s10055-010-0154-x#ref-CR25" id="ref-link-section-d40580e2519">2002</a>) present a reconstruction of a prehistoric rock shelter site of Cap Blanc, France where animal sculptures are engraved in the cave walls. Viewing these sculptures illuminated by an animal fat tallow candle creates a warmer ambiance and increases the amount of shadows to the whole scene. The perception of the dynamic flame coupled with the 3D structure of the carving suggest how people may have used this combination of the flickering flame and 3D structure to create animations 15,000 years ago, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig19">19</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-19"><figure><figcaption><b id="Fig19" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 19</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/19" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig19_HTML.jpg?as=webp"></source><img aria-describedby="figure-19-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig19_HTML.jpg" alt="figure19" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-19-desc"><p><i>Top left</i> The simulation under 55w incandescent bulb. <i>Top right and bottom</i> The simulation under animal fat lamplight (Chalmers et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Chalmers A, Green C, Hall M (2000) Firelight: graphics and archaeology. SIGGRAPH Electronic Theatre" href="/article/10.1007/s10055-010-0154-x#ref-CR22" id="ref-link-section-d40580e2540">2000</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/19" data-track-dest="link:Figure19 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>A computer-generated model based on a half-timbered structure in Southampton was generated by Devlin et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Devlin K, Chalmers A, Brown D (2002a) Predictive lighting and perception in archaeological representations. In: UNESCO “World Heritage in the Digital Age” 30th Anniversary Digital Congress, UNESCO World Heritage Centre" href="/article/10.1007/s10055-010-0154-x#ref-CR34" id="ref-link-section-d40580e2555">2002</a>a). The paper investigates the bright colour of pottery in mediaeval times; how the top half of some jugs appear both glazed and decorated. This is probably due to deliberate use of light, suggesting several pots would have looked brightest when lit from above, and done so for practical reasons. This work also showed that mediaeval pottery needed to be brightly coloured in order to be seen in the interior lighting conditions of the period.</p><p>Roussos and Chalmers (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Roussos I, Chalmers A (2003) High fidelity lighting of knossos. In: VAST ’03: proceedings of the symposium on virtual reality, archaeology and intelligent cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR142" id="ref-link-section-d40580e2562">2003</a>) present a reconstruction of a section of the Knossos palace, a Bronze Age archaeological site on Crete. The paper included accurate modelling of a flame that may have been used to light the past environment. A realistic and efficient flickering of flames was created. However, the method is limited to small flames from candles.</p><p>Colourful Egyptian hieroglyphs viewed under sesame oil candle is presented by Sundstedt et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Sundstedt V, Chalmers A, Martinez P (2004) High fidelity reconstruction of the ancient egyptian temple of kalabsha. In: AFRIGRAPH ’04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR151" id="ref-link-section-d40580e2568">2004</a>). In this case, the blue paint appears as almost green, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig20">20</a>. The interior was also modelled to allow exploration and reconstruction of hieroglyphics under contemporary lighting. Properties of real sesame oil lamps were measured in the reconstruction.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-20"><figure><figcaption><b id="Fig20" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 20</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/20" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig20_HTML.jpg?as=webp"></source><img aria-describedby="figure-20-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig20_HTML.jpg" alt="figure20" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-20-desc"><p>Egyptian hieroglyphics from the Temple of Kalabsha illuminated under various conditions. <i>Left</i> Modern light (painted) <i>Middle</i> Sesame oil lamp light (unpainted) and <i>Right</i> Sesame oil lamp light (painted) (Sundstedt et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Sundstedt V, Chalmers A, Martinez P (2004) High fidelity reconstruction of the ancient egyptian temple of kalabsha. In: AFRIGRAPH ’04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR151" id="ref-link-section-d40580e2593">2004</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/20" data-track-dest="link:Figure20 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>A reconstruction of Roman frescoes and mosaics from Conimbriga in Portugal is presented by Gonçalves et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Gonçalves A, Magalhes L, Moura J, Chalmers A (2008) Accurate modelling of roman lamps in conimbriga using high dynamic range. In: VAST ’08: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR69" id="ref-link-section-d40580e2608">2008</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Gonçalves A, Magalhes L, Moura J, Chalmers A (2009) High dynamic range—a gateway for predictive ancient lighting. ACM J Comput Cult Herit" href="/article/10.1007/s10055-010-0154-x#ref-CR70" id="ref-link-section-d40580e2611">2009</a>). The visual perception of Roman oil lamp illumination through HDRI rendering is also explored. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig21">21</a> shows Roman oil lamps using the same sample of olive oil as fuel mixture, but with different fuel additives.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-21"><figure><figcaption><b id="Fig21" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 21</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/21" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig21_HTML.jpg?as=webp"></source><img aria-describedby="figure-21-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig21_HTML.jpg" alt="figure21" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-21-desc"><p>Illuminated frescoes and mosaics by Roman lamps and candlesticks holders. The same sample of olive oil is the fuel source in both images. <i>Left</i> Mixed with salt. <i>Right</i> No salt (Gonçalves et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Gonçalves A, Magalhes L, Moura J, Chalmers A (2008) Accurate modelling of roman lamps in conimbriga using high dynamic range. In: VAST ’08: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR69" id="ref-link-section-d40580e2633">2008</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Gonçalves A, Magalhes L, Moura J, Chalmers A (2009) High dynamic range—a gateway for predictive ancient lighting. ACM J Comput Cult Herit" href="/article/10.1007/s10055-010-0154-x#ref-CR70" id="ref-link-section-d40580e2636">2009</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/21" data-track-dest="link:Figure21 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Kider et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Kider JT, Fletcher RL, Yu N, Holod R, Chalmers A, Badler NI (2009) Recreating early islamic glass lamp lighting. In: VAST ’09: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR97" id="ref-link-section-d40580e2651">2009</a>) investigated the use of experimental data to recreate early Islamic glass lamp lighting and validated how various water levels and glass fixture shapes used during early Islamic times changed the overall light patterns and downward caustics, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig22">22</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-22"><figure><figcaption><b id="Fig22" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 22</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/22" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig22_HTML.jpg?as=webp"></source><img aria-describedby="figure-22-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig22_HTML.jpg" alt="figure22" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-22-desc"><p><i>Top left to right</i> (1) Ground truth photograph, (2) Result from Radiance, (3) Composite Illuminate Texture Result, (4) Result from Caustic Cones. <i>Bottom</i> The Mosque of Córdoba rendered under: <i>Left</i> Simple Ambient Light. <i>Right</i> Caustic Cone method (Kider et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Kider JT, Fletcher RL, Yu N, Holod R, Chalmers A, Badler NI (2009) Recreating early islamic glass lamp lighting. In: VAST ’09: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR97" id="ref-link-section-d40580e2678">2009</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/22" data-track-dest="link:Figure22 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec27">Participating media</h3><p>Less dense participating mediums such as dust particles present in an environment can greatly alter the visual perception in an environment. Sundstedt et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Sundstedt V, Gutierrez D, Gomez F, Chalmers A (2005) Participating media for high-fidelity cultural heritage. In: VAST ’05: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR153" id="ref-link-section-d40580e2699">2005</a>) discuss sunlight in the Temple of Kalabsha and show the visual impact difference in simulations with and without dust, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig23">23</a>. Gutierrez et al. extend this work for use of participating media for cultural heritage reconstructions (Gutierrez et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Gutierrez D, Sundstedt V, Gomez F, Chalmers A (2006) Dust and light: predictive virtual archaeology. J Cult Herit" href="/article/10.1007/s10055-010-0154-x#ref-CR71" id="ref-link-section-d40580e2705">2006</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Gutierrez D, Sundstedt V, Gomez F, Chalmers A (2008) Modeling light scattering for virtual heritage. J Comput Cult Herit" href="/article/10.1007/s10055-010-0154-x#ref-CR72" id="ref-link-section-d40580e2708">2008</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-23"><figure><figcaption><b id="Fig23" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 23</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/23" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig23_HTML.jpg?as=webp"></source><img aria-describedby="figure-23-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig23_HTML.jpg" alt="figure23" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-23-desc"><p><i>Top Left</i> Real picture of a slit. <i>Top Middle</i> Simulation without participating media. <i>Top Right</i> Simulation with participating media. <i>Bottom Left</i> Chamber without participating media, <i>Bottom Right</i> Chamber including participating media (Gutierrez et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Gutierrez D, Sundstedt V, Gomez F, Chalmers A (2008) Modeling light scattering for virtual heritage. J Comput Cult Herit" href="/article/10.1007/s10055-010-0154-x#ref-CR72" id="ref-link-section-d40580e2735">2008</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/23" data-track-dest="link:Figure23 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec28">Visual perception</h3><p>The accurate simulation of the distribution of light energy in scenes does not guarantee that images generated from this simulation will have a correct visual appearance. This is due to two main reasons. First, it may be a limitation of the display technology used. Secondly, it is also necessary to model the behaviour of the HVS to capture and then visualise the correct appearance of the original scene virtually.</p><p>The eye adjusts to the ambient illumination in the environment. The time course of light and dark adaptation is well known and it is different for the cones and rods (Hood and Finkelstein <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1986" title="Hood D, Finkelstein M (1986) Sensitivity to light. Handbook of perception and human performance. Wiley, New York" href="/article/10.1007/s10055-010-0154-x#ref-CR81" id="ref-link-section-d40580e2757">1986</a>). During the eye adaptation process, it is important to simulate effects including colour sensitivity and visual acuity variation. The eye is not capable of seeing colours in darkness. A local model of eye adaptation for HDR images is presented by Ledda et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Ledda P, Santos LP, Chalmers A (2004) A local model of eye adaptation for high dynamic range images. In: AFRIGRAPH ’04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR112" id="ref-link-section-d40580e2760">2004</a>), see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig24">24</a>. The HVS will dynamically adapt to an environment as our eyes are only capable of dealing with the full range of luminance through eye adaptation.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-24"><figure><figcaption><b id="Fig24" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 24</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/24" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig24_HTML.jpg?as=webp"></source><img aria-describedby="figure-24-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig24_HTML.jpg" alt="figure24" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-24-desc"><p><i>Top four images</i> Simulating dark adaptation. After some time, sensitivity increases, allowing the HVS to recover some visibility. <i>Bottom left</i> Kalabsha tone-mapped with a local model of eye adaptation (Ledda et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Ledda P, Santos LP, Chalmers A (2004) A local model of eye adaptation for high dynamic range images. In: AFRIGRAPH ’04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa" href="/article/10.1007/s10055-010-0154-x#ref-CR112" id="ref-link-section-d40580e2781">2004</a>). <i>Bottom right</i> linear mappings at different exposure times</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/24" data-track-dest="link:Figure24 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Beraldin et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Beraldin J-A, Picard M, El-Hakim SF, Godin G, Latouche C, Valzano V, Bandiera A (2002) Exploring a byzantine crypt through a high-resolution texture mapped 3d model: combining range data and photogrammetry. In: Proceedings of ISPRS/CIPA international workshop scanning for cultural heritage recording" href="/article/10.1007/s10055-010-0154-x#ref-CR15" id="ref-link-section-d40580e2799">2002</a>) discuss problems encountered in visualising weathered materials in a Byzantine crypt. Enhancing texture maps over realistic lighting can be useful for virtual tourism applications, however, it also assumes wall writings have already been examined and interpreted by archaeologists.</p><p>Zányi et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007a" title="Zányi E, Chrysanthou Y, Bashford-Rogers T, Chalmers A (2007a) High dynamic range display of authentically illuminated byzantine art from Cyprus. In: VAST ’07: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR183" id="ref-link-section-d40580e2805">2007a</a>) compare images of the Icon of Christ Arakiotis from Cyprus illuminated with simulated modern lighting and candle light that was present in Byzantine times on both a traditional LCD and a novel High Dynamic Range display, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig25">25</a>. The authors argue that in the Byzantine period, the layout and lighting of the icons, frescoes and mosaics were carefully regulated to achieve a spiritual response from the viewer and illustrate how such ideas can be investigated through HDR display technologies.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-25"><figure><figcaption><b id="Fig25" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 25</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/25" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig25_HTML.jpg?as=webp"></source><img aria-describedby="figure-25-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig25_HTML.jpg" alt="figure25" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-25-desc"><p><i>Left</i> Modern Lighting. <i>Middle</i> Approximated Candle Lighting on an HD LCD screen. <i>Right</i> Approximated Candle Lighting on an HDR display (Zányi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007a" title="Zányi E, Chrysanthou Y, Bashford-Rogers T, Chalmers A (2007a) High dynamic range display of authentically illuminated byzantine art from Cyprus. In: VAST ’07: proceedings of the symposium on virtual reality, archaeology and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR183" id="ref-link-section-d40580e2829">2007a</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/25" data-track-dest="link:Figure25 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p><i>Surface Depth Hallucination</i> is a method developed by Glencross et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Glencross M, Ward G, Melendez F, Jay C, Liu J, Hubbold R (2008) A perceptually validated model for surface depth hallucination. In: SIGGRAPH ’08: proceedings of the 35th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR76" id="ref-link-section-d40580e2847">2008</a>) to recover models of predominantly diffuse textured surfaces that can be relit and viewed from any angle under various illumination models. Using standard digital cameras from a single view, the technique takes a diffuse-lit (cloudy day) image and a flashlit image to produce an albedo map and textured height field. The paper uses experimental validation to compare Mayan Glyphs at Chichén Itzá relit using this method to rendering of laser-scanned depth map in Radiance.</p><p>The use of physical light to reconstruct physical artefacts in situ is an emerging application as shown by Aliaga et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Aliaga DG, Law AJ, Yeung YH (2008) A virtual restoration stage for real-world objects. In: SIGGRAPH Asia '08: ACM SIGGRAPH Asia 2008 papers. ACM, Newyork, pp 1–10" href="/article/10.1007/s10055-010-0154-x#ref-CR3" id="ref-link-section-d40580e2853">2008</a>). The authors present a system to restore and alter the appearance of old and deteriorated objects. The system allows altering the appearances of objects to that of a synthetic restoration. This in turn allows the virtual re-illuminations of the objects. The authors use an ancient Chinese vase as an example.</p><p>Ritschel et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Ritschel T, Ihrke M, Frisvad JR, Coppens J, Myszkowski K, Seidel H-P (2009) Temporal glare: real-time dynamic simulation of the scattering in the human eye. Eurographics" href="/article/10.1007/s10055-010-0154-x#ref-CR146" id="ref-link-section-d40580e2859">2009</a>) argue that the temporal properties of glare are a strong means to increase perceived brightness and, therefore, increase realism of bright light sources. The paper proposes a model based on the anatomy of the human eye, enabling the simulation of dynamic glare on a GPU. It does not react to the user’s eye, but rather a human eye model. The glare is dependent on type of illumination and can be seen pulsating realistically in video. This can be used to increase realism of light sources for cultural heritage items such as lit candles.</p></div></div></section><section aria-labelledby="Sec29"><div class="c-article-section" id="Sec29-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec29">Discussion</h2><div class="c-article-section__content" id="Sec29-content"><p>We will, of course, never know precisely how any ancient environment was lit. In addition, our modern preconceptions and cultural backgrounds preclude a complete understanding of the experience of an ancient viewer. However, authentic illumination of reconstructions offers a chance to get closer to a perception of the past thereby facilitating new modes of engagement and interpretation (Goodrick and Gillings <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Goodrick G, Gillings M (2000) Constructs, simulations and hyperreal worlds: the role of virtual reality (vr) in archaeological research. On the theory and practice of archaeological computing" href="/article/10.1007/s10055-010-0154-x#ref-CR66" id="ref-link-section-d40580e2871">2000</a>).</p><h3 class="c-article__sub-heading" id="Sec30">Illumination for virtual archaeology</h3><p>The importance of illumination is of significant importance often overshadowed by the far more noticeable visual impacts of modelling geometry and materials. Authentic illumination is an element of a reconstruction that, unless present will make the viewer unaware of what information may be present in the scene. The question of realism in virtual archaeology remains the object of much discussion (Chalmers et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Chalmers A, Devlin K, Brown D, Debevec P, Martinez P, Ward G (2002) Recreating the Past. SIGGRAPH Course" href="/article/10.1007/s10055-010-0154-x#ref-CR20" id="ref-link-section-d40580e2881">2002</a>; Forte et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Forte M, Siliotti A, Renfrew C (1997) Virtual archaeology: re-creating ancient worlds. Harry N Abrams, New York" href="/article/10.1007/s10055-010-0154-x#ref-CR64" id="ref-link-section-d40580e2884">1997</a>; Martinez <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Martinez P (2001) Digital realities and archaeology: a difficult relationship or a fruitful marriage? In: VAST ’01: proceedings of the symposium on virtual reality, archeology, and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR115" id="ref-link-section-d40580e2887">2001</a>; Reilly <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Reilly P (1991) Towards a virtual archaeology. Comput Appl Quant Methods Archaeol" href="/article/10.1007/s10055-010-0154-x#ref-CR144" id="ref-link-section-d40580e2890">1991</a>; Roberts and Ryan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Roberts J, Ryan N (1997) Alternative archaeological representations within virtual worlds. In: Proceedings of the 4th UK virtual reality specialist interest group conference—Brunel University" href="/article/10.1007/s10055-010-0154-x#ref-CR147" id="ref-link-section-d40580e2893">1997</a>). With this topic comes also the concern regarding the authenticity of the illumination. While there are no differences in light transport from ancient to modern times, there are many changes in the manner people use light in the past thousands of years. Additionally, changes in the environment that may affect the perception of light at the remnants of these sites. Changes in pollution, climate, materials and physical environment (neighbouring buildings) all need to be addressed in the authentic reconstruction of the site.</p><h3 class="c-article__sub-heading" id="Sec31">Rendering</h3><p>It is surprising that when rendering methods that require authentic lighting, unbiased methods have not been fully explored in the cultural heritage domain. The reasons for this may vary. Possibly such methods are still too computationally expensive or possibly the quality difference offered by such methods is not substantially significant to warrant the increased cost. Yet, newer methods such as ERPT (Cline et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Cline D, Talbot J, Egbert P (2005) Energy redistribution path tracing. In: SIGGRAPH ’05: proceedings of the 32nd annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR30" id="ref-link-section-d40580e2904">2005</a>) and PMC (Lai et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Lai Y-C, Fan SH, Chenney S, Dyer C (2007) Rendering techniques. In: Kautz J, Pattanaik S (eds) Photorealistic image rendering with population Monte Carlo energy redistribution" href="/article/10.1007/s10055-010-0154-x#ref-CR109" id="ref-link-section-d40580e2907">2007</a>) may offer possibly distinct advantages at reduced costs. Other, more deterministic methods such as radiance caching (Křivánek et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Křivánek J, Gautron P, Pattanaik S, Bouatouch K (2005) Radiance caching for efficient global illumination computation. IEEE Trans Vis and Comput Graph" href="/article/10.1007/s10055-010-0154-x#ref-CR98" id="ref-link-section-d40580e2910">2005</a>), light cuts (Walter et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Walter B, Fernandez S, Arbree A, Bala K, Donikian M, Greenberg DP (2005) Lightcuts: a scalable approach to illumination. ACM Trans Graph 24(3):1098–1107" href="/article/10.1007/s10055-010-0154-x#ref-CR175" id="ref-link-section-d40580e2913">2005</a>) and its extensions such as bi-directional importance sampling (Wang and Akerlund <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Wang R, Akerlund O (2009) Bidirectional importance sampling for unstructured illuminationn. Eurographics" href="/article/10.1007/s10055-010-0154-x#ref-CR170" id="ref-link-section-d40580e2916">2009</a>) could well provide suitable alternatives to the more traditional photon mapping and irradiance caching methods.</p><p>In terms of interactive global illumination, it is now clear that it is becoming achievable with the development of interactive ray tracing methods (Wald et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Wald I, Mark WR, Günther J, Boulos S, Ize T, Hunt W, Parker SG, Shirley P (2007) State of the art in ray tracing animated scenes. Eurographics" href="/article/10.1007/s10055-010-0154-x#ref-CR178" id="ref-link-section-d40580e2922">2007</a>), the extension of interactive ray tracers to interactive global illumination (Debattista et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Debattista K, Dubla P, Banterle F, Santos LP, Chalmers A (2009) Instant caching for interactive global illumination. Comput Graph Forum 28(8):2216–2228" href="/article/10.1007/s10055-010-0154-x#ref-CR37" id="ref-link-section-d40580e2925">2009</a>; Dubla et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Dubla P, Debattista K, Chalmers A (2009) Adaptive interleaved sampling for interactive high fidelity rendering. Comput Graph Forum 28(8):2117–2130" href="/article/10.1007/s10055-010-0154-x#ref-CR38" id="ref-link-section-d40580e2928">2009</a>), and new GPU techniques such as Imperfect Shadow Maps (Ritschel et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Ritschel T, Grosch T, Kim MH, Seidel H-P, Dachsbacher C, Kautz J (2008) Imperfect shadow maps for efficient computation of indirect illumination. SIGGRAPH Asia ’08: ACM SIGGRAPH Asia papers" href="/article/10.1007/s10055-010-0154-x#ref-CR145" id="ref-link-section-d40580e2931">2008</a>) and the method presented by Wang et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Wang R, Wang R, Zhou K, Pan M, Bao H (2009) An efficient gpu-based approach for interactive global illumination. In: SIGGRAPH ’09: proceedings of the 36th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR181" id="ref-link-section-d40580e2934">2009</a>).</p><p>An aspect that remains largely unexplored in cultural heritage reconstruction includes rendering of dark or predominantly indirectly lit environments. Low lit environments are significantly difficult to render accurately for several reasons; not only the lack of HDR display systems, but also the absence of computational power necessary to render such environments.</p><p>Spectral rendering refers to rendering of light with wavelength data. Traditionally, the spectral nature of light is ignored in favour of a simpler RGB model. Spectral rendering, and its subtle but important visual impact and implications is another unexplored topic in cultural heritage settings.</p><p>There also exists models for night time rendering; however, to our knowledge, there are no papers that explore physically based rendering of cultural heritage objects at night. With the recent advancements in HDRI capturing methods and display technologies, there will be the possibility of rendering night light, and explore the importance of moon and star light in the past.</p><h3 class="c-article__sub-heading" id="Sec32">Documentation and validation</h3><p>Once a reconstruction is considered complete, it may be re-examined in the future. Without comprehensive documentation of the data capture and reconstruction process, vital information about the reconstruction might be lost in the future. This includes topics such as approximations made by the modellers, laser-scanning technicians, difficulties encountered during data collection and in post-processing. While research papers give a general idea of the process they rarely detail problems with the final reconstructions. This is important if the reconstruction should be of any scientific and historic merit for future generations. While there are no standardised approaches of documenting progress of reconstruction, this is likely to become a topic in the future.</p><p>There is increasing research interest in modelling uncertainty in cultural heritage site reconstructions and defining standards for metadata (Arnold and Geser <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Arnold D, Geser G (2007) Research agenda for the applications of ict to cultural heritage. EPOCH publications" href="/article/10.1007/s10055-010-0154-x#ref-CR2" id="ref-link-section-d40580e2954">2007</a>). This is likely to continue to be an active area of research in the coming years. A major problem with illumination models is determining the historical correctness to the approach. For instance, a model may be correct for a given state in time, but not for any other periods in time, or vice versa.</p><p>The Cedarberg, for instance, is an area in South Africa with a large number of prehistoric cave art. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig26">26</a> shows an example of the impact of direct sunlight on a site at different times of the year. The image on the left shows a photograph of painting of a woman in purple taken in November. It looks nothing special; however, on the right is the same painting taken in March. The shadow from the natural overhang of the rock shelter almost perfectly frames the painting on three sides. This shows how much of an impact correct illumination can have on a site and how it can easily be overlooked depending on what time the site is examined.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-26"><figure><figcaption><b id="Fig26" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 26</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/26" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig26_HTML.jpg?as=webp"></source><img aria-describedby="figure-26-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-010-0154-x/MediaObjects/10055_2010_154_Fig26_HTML.jpg" alt="figure26" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-26-desc"><p>Cedarberg cave art. <i>Left</i> November. <i>Right</i> March</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-010-0154-x/figures/26" data-track-dest="link:Figure26 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Not all new information is obtainable through methodical scientific approaches. The validation of authentic illumination is difficult for objects we have no prior knowledge of, except its current location. Occasionally, hypotheses can spring up by chance or coincidentally by combining existing information. An authentic reconstruction should always critically examine existing scientific and historical evidence, otherwise remain an interpretation of the past.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="T. Akenine-Moller, E. Haines, N. Hoffman, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Akenine-Moller T, Haines E, Hoffman N (2008) Real-time rendering. A. K. Peters, Wellesley" /><p class="c-article-references__text" id="ref-CR4">Akenine-Moller T, Haines E, Hoffman N (2008) Real-time rendering. A. K. Peters, Wellesley</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Real-time%20rendering&amp;publication_year=2008&amp;author=Akenine-Moller%2CT&amp;author=Haines%2CE&amp;author=Hoffman%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Aliaga DG, Law AJ, Yeung YH (2008) A virtual restoration stage for real-world objects. In: SIGGRAPH Asia '08: " /><p class="c-article-references__text" id="ref-CR3">Aliaga DG, Law AJ, Yeung YH (2008) A virtual restoration stage for real-world objects. In: SIGGRAPH Asia '08: ACM SIGGRAPH Asia 2008 papers. ACM, Newyork, pp 1–10</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Appel A (1968) Some techniques for shading machine renderings of solids. In: Proceedings of the spring joint c" /><p class="c-article-references__text" id="ref-CR5">Appel A (1968) Some techniques for shading machine renderings of solids. In: Proceedings of the spring joint computer conference</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Archaeological Computing Research Group, University of Southampton (2009) A polynomial texture map of an amazo" /><p class="c-article-references__text" id="ref-CR6">Archaeological Computing Research Group, University of Southampton (2009) A polynomial texture map of an amazon statue, interactive demo. <a href="http://www.soton.ac.uk/archaeology/acrg/acrg_research_amazon.html">http://www.soton.ac.uk/archaeology/acrg/acrg_research_amazon.html</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Arnold D, Geser G (2007) Research agenda for the applications of ict to cultural heritage. EPOCH publications" /><p class="c-article-references__text" id="ref-CR2">Arnold D, Geser G (2007) Research agenda for the applications of ict to cultural heritage. EPOCH publications</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Artusi A, Chetverikov D (2007) A survey of specularity removal methods. Technical Report" /><p class="c-article-references__text" id="ref-CR1">Artusi A, Chetverikov D (2007) A survey of specularity removal methods. Technical Report</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Autodesk (2009a) 3DS Max website. http://www.autodesk.com/3dsmax&#xA;                        " /><p class="c-article-references__text" id="ref-CR7">Autodesk (2009a) 3DS Max website. <a href="http://www.autodesk.com/3dsmax">http://www.autodesk.com/3dsmax</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Autodesk (2009b) Maya website. http://www.autodesk.com/maya&#xA;                        " /><p class="c-article-references__text" id="ref-CR8">Autodesk (2009b) Maya website. <a href="http://www.autodesk.com/maya">http://www.autodesk.com/maya</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Baba M, Asada N (2003) Shadow removal from a real picture. In: SIGGRAPH ’03: ACM SIGGRAPH sketches &amp; applicati" /><p class="c-article-references__text" id="ref-CR9">Baba M, Asada N (2003) Shadow removal from a real picture. In: SIGGRAPH ’03: ACM SIGGRAPH sketches &amp; applications</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Baba M, Mukunoki M, Asada N (2004) Shadow removal from a real image based on shadow density. In: SIGGRAPH ’04:" /><p class="c-article-references__text" id="ref-CR13">Baba M, Mukunoki M, Asada N (2004) Shadow removal from a real image based on shadow density. In: SIGGRAPH ’04: ACM SIGGRAPH posters</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Barbosa J, Sobral JL, Proena AJ (2007) Imaging techniques to simplify the ptm generation of a bas-relief. In: " /><p class="c-article-references__text" id="ref-CR17">Barbosa J, Sobral JL, Proena AJ (2007) Imaging techniques to simplify the ptm generation of a bas-relief. In: VAST ’07: proceedings of the symposium on virtual reality, archaeology and cultural heritage</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Barrow H, Tanenbaum J (1978) Recovering intrinsic scene characteristic from images. Comput Vis Syst" /><p class="c-article-references__text" id="ref-CR18">Barrow H, Tanenbaum J (1978) Recovering intrinsic scene characteristic from images. Comput Vis Syst</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Beaudoin P, Paquet S, Poulin P (2001) Realistic and controllable fire simulation. In: GRIN’01: no description " /><p class="c-article-references__text" id="ref-CR16">Beaudoin P, Paquet S, Poulin P (2001) Realistic and controllable fire simulation. In: GRIN’01: no description on graphics interface 2001</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Beraldin J-A, Picard M, El-Hakim SF, Godin G, Latouche C, Valzano V, Bandiera A (2002) Exploring a byzantine c" /><p class="c-article-references__text" id="ref-CR15">Beraldin J-A, Picard M, El-Hakim SF, Godin G, Latouche C, Valzano V, Bandiera A (2002) Exploring a byzantine crypt through a high-resolution texture mapped 3d model: combining range data and photogrammetry. In: Proceedings of ISPRS/CIPA international workshop scanning for cultural heritage recording</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Blinn JF, Newell ME (1976) Texture and reflection in computer generated images. Commun ACM" /><p class="c-article-references__text" id="ref-CR14">Blinn JF, Newell ME (1976) Texture and reflection in computer generated images. Commun ACM</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Blythe, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Blythe D (2006) The Direct3D 10 system. ACM Trans Graph 25(3):724–734" /><p class="c-article-references__text" id="ref-CR12">Blythe D (2006) The Direct3D 10 system. ACM Trans Graph 25(3):724–734</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Direct3D%2010%20system&amp;journal=ACM%20Trans%20Graph&amp;volume=25&amp;issue=3&amp;pages=724-734&amp;publication_year=2006&amp;author=Blythe%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bridault-Louchez F, Leblond M, Rousselle F (2006) Enhanced illumination of reconstructed dynamic environments " /><p class="c-article-references__text" id="ref-CR10">Bridault-Louchez F, Leblond M, Rousselle F (2006) Enhanced illumination of reconstructed dynamic environments using a real-time flame model. In: AFRIGRAPH ’06: proceedings of the 4th international conference on computer graphics, virtual reality, visualisation and interaction in Africa</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bridault F, Lebond M, Rousselle F, Renaud C (2007) Real-time rendering and animation of plentiful flames. In: " /><p class="c-article-references__text" id="ref-CR11">Bridault F, Lebond M, Rousselle F, Renaud C (2007) Real-time rendering and animation of plentiful flames. In: Proceedings of the 3rd Eurographics workshop on natural phenomena</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Callieri, P. Debevec, J. Pair, R. Scopigno, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Callieri M, Debevec P, Pair J, Scopigno R (2006) A realtime immersive application with realistic lighting: the" /><p class="c-article-references__text" id="ref-CR21">Callieri M, Debevec P, Pair J, Scopigno R (2006) A realtime immersive application with realistic lighting: the Parthenon. Comput Graph 30(3):368–376</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20realtime%20immersive%20application%20with%20realistic%20lighting%3A%20the%20Parthenon&amp;journal=Comput%20Graph&amp;volume=30&amp;issue=3&amp;pages=368-376&amp;publication_year=2006&amp;author=Callieri%2CM&amp;author=Debevec%2CP&amp;author=Pair%2CJ&amp;author=Scopigno%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chalmers A (2002) Very realistic graphics for visualising archaeological site reconstructions. In: Proceedings" /><p class="c-article-references__text" id="ref-CR25">Chalmers A (2002) Very realistic graphics for visualising archaeological site reconstructions. In: Proceedings of 18th spring conference on computer graphics</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chalmers A, Green C, Hall M (2000) Firelight: graphics and archaeology. SIGGRAPH Electronic Theatre" /><p class="c-article-references__text" id="ref-CR22">Chalmers A, Green C, Hall M (2000) Firelight: graphics and archaeology. SIGGRAPH Electronic Theatre</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chalmers A, Devlin K, Brown D, Debevec P, Martinez P, Ward G (2002) Recreating the Past. SIGGRAPH Course" /><p class="c-article-references__text" id="ref-CR20">Chalmers A, Devlin K, Brown D, Debevec P, Martinez P, Ward G (2002) Recreating the Past. SIGGRAPH Course</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chalmers A, Roussos I, Ledda P (2006) Authentic illumination of archaeological site reconstructions. In: CGIV’" /><p class="c-article-references__text" id="ref-CR28">Chalmers A, Roussos I, Ledda P (2006) Authentic illumination of archaeological site reconstructions. In: CGIV’2006: IS&amp;T’s third European conference on color in graphics, imaging and vision</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chandrasekhar S (1960) Radiative transfer. Dover Publications, New York" /><p class="c-article-references__text" id="ref-CR24">Chandrasekhar S (1960) Radiative transfer. Dover Publications, New York</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cline D, Talbot J, Egbert P (2005) Energy redistribution path tracing. In: SIGGRAPH ’05: proceedings of the 32" /><p class="c-article-references__text" id="ref-CR30">Cline D, Talbot J, Egbert P (2005) Energy redistribution path tracing. In: SIGGRAPH ’05: proceedings of the 32nd annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cohen MF, Wallace J, Hanrahan P (1993) Radiosity and realistic image synthesis. Academic Press Professional, S" /><p class="c-article-references__text" id="ref-CR32">Cohen MF, Wallace J, Hanrahan P (1993) Radiosity and realistic image synthesis. Academic Press Professional, San Diego</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cook RL, Torrance KE (1982) A reflectance model for computer graphics. ACM Trans Graph" /><p class="c-article-references__text" id="ref-CR29">Cook RL, Torrance KE (1982) A reflectance model for computer graphics. ACM Trans Graph</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cook RL, Porter T, Carpenter L (1984) Distributed ray tracing. In: SIGGRAPH ’84: proceedings of the 11th annua" /><p class="c-article-references__text" id="ref-CR27">Cook RL, Porter T, Carpenter L (1984) Distributed ray tracing. In: SIGGRAPH ’84: proceedings of the 11th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Corsini, M. Callieri, P. Cignoni, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Corsini M, Callieri M, Cignoni P (2008) Stereo light probe. Comput Graph Forum 27(2):291–300" /><p class="c-article-references__text" id="ref-CR19">Corsini M, Callieri M, Cignoni P (2008) Stereo light probe. Comput Graph Forum 27(2):291–300</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Stereo%20light%20probe&amp;journal=Comput%20Graph%20Forum&amp;volume=27&amp;issue=2&amp;pages=291-300&amp;publication_year=2008&amp;author=Corsini%2CM&amp;author=Callieri%2CM&amp;author=Cignoni%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cucchiara R, Grana C, Piccardi M, Prati A, Sirotti S (2001) Improving shadow suppression in moving object dete" /><p class="c-article-references__text" id="ref-CR23">Cucchiara R, Grana C, Piccardi M, Prati A, Sirotti S (2001) Improving shadow suppression in moving object detection with HSV color information. In: Proceedings of intelligent transportation systems</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cultural Heritage Imaging (2009) CHI Webpage. http://www.c-h-i.org/featured_projects/featured_projects.html&#xA;  " /><p class="c-article-references__text" id="ref-CR31">Cultural Heritage Imaging (2009) CHI Webpage. <a href="http://www.c-h-i.org/featured_projects/featured_projects.html">http://www.c-h-i.org/featured_projects/featured_projects.html</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dachsbacher C, Stamminger M, Drettakis G, Durand F (2007) Implicit visibility and antiradiance for interactive" /><p class="c-article-references__text" id="ref-CR48">Dachsbacher C, Stamminger M, Drettakis G, Durand F (2007) Implicit visibility and antiradiance for interactive global illumination. In: SIGGRAPH ’07: proceedings of the 34th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Daubert K, Schirmacher H, Sillion F, Drettakis G (1997) Hierarchical lighting simulation for outdoor scenes. I" /><p class="c-article-references__text" id="ref-CR49">Daubert K, Schirmacher H, Sillion F, Drettakis G (1997) Hierarchical lighting simulation for outdoor scenes. In: Proceedings of the Eurographics workshop on rendering</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Debattista, P. Dubla, F. Banterle, LP. Santos, A. Chalmers, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Debattista K, Dubla P, Banterle F, Santos LP, Chalmers A (2009) Instant caching for interactive global illumin" /><p class="c-article-references__text" id="ref-CR37">Debattista K, Dubla P, Banterle F, Santos LP, Chalmers A (2009) Instant caching for interactive global illumination. Comput Graph Forum 28(8):2216–2228</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Instant%20caching%20for%20interactive%20global%20illumination&amp;journal=Comput%20Graph%20Forum&amp;volume=28&amp;issue=8&amp;pages=2216-2228&amp;publication_year=2009&amp;author=Debattista%2CK&amp;author=Dubla%2CP&amp;author=Banterle%2CF&amp;author=Santos%2CLP&amp;author=Chalmers%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Debevec P (1998) Rendering synthetic objects into real scenes: bridging traditional and image-based graphics w" /><p class="c-article-references__text" id="ref-CR39">Debevec P (1998) Rendering synthetic objects into real scenes: bridging traditional and image-based graphics with global illumination and high dynamic range photography. In: SIGGRAPH ’98: proceedings of the 25th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Debevec P (2001) Light probe image gallery. http://www.debevec.org/probes/&#xA;                        " /><p class="c-article-references__text" id="ref-CR40">Debevec P (2001) Light probe image gallery. <a href="http://www.debevec.org/probes/">http://www.debevec.org/probes/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Debevec, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Debevec P (2002) Image-based lighting. Comput Graph Appl IEEE 22(2):26–34" /><p class="c-article-references__text" id="ref-CR41">Debevec P (2002) Image-based lighting. Comput Graph Appl IEEE 22(2):26–34</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Image-based%20lighting&amp;journal=Comput%20Graph%20Appl%20IEEE&amp;volume=22&amp;issue=2&amp;pages=26-34&amp;publication_year=2002&amp;author=Debevec%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Debevec P (2003) Image-based techniques for digitizing environments and artifacts. 3DIM: invited paper for the" /><p class="c-article-references__text" id="ref-CR42">Debevec P (2003) Image-based techniques for digitizing environments and artifacts. 3DIM: invited paper for the 4th international conference on 3-D digital imaging and modeling</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Debevec P (2005) Making ‘The Parthenon’. Invited paper: VAST ’05: International symposium on virtual reality, " /><p class="c-article-references__text" id="ref-CR43">Debevec P (2005) Making ‘The Parthenon’. Invited paper: VAST ’05: International symposium on virtual reality, archaeology, and cultural heritage</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Debevec P (2006) High resolution light probe gallery. http://www.gl.ict.usc.edu/Data/HighResProbes/&#xA;          " /><p class="c-article-references__text" id="ref-CR44">Debevec P (2006) High resolution light probe gallery. <a href="http://www.gl.ict.usc.edu/Data/HighResProbes/">http://www.gl.ict.usc.edu/Data/HighResProbes/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Debevec P, Malik J (1997) Recovering high dynamic range radiance maps from photographs. In: SIGGRAPH ’97: proc" /><p class="c-article-references__text" id="ref-CR46">Debevec P, Malik J (1997) Recovering high dynamic range radiance maps from photographs. In: SIGGRAPH ’97: proceedings of the 24th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Debevec P, Hawkins T, Tchou C, Duiker H-P, Sarokin W, Sagar M (2000) Acquiring the reflectance field of a huma" /><p class="c-article-references__text" id="ref-CR45">Debevec P, Hawkins T, Tchou C, Duiker H-P, Sarokin W, Sagar M (2000) Acquiring the reflectance field of a human face. In: SIGGRAPH ’00: proceedings of the 27th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Debevec P, Tchou C, Gardner A, Hawkins T, Poullis C, Stumpfel J, Jones A, Yun N, Einarsson P, Lundgren T, Faja" /><p class="c-article-references__text" id="ref-CR50">Debevec P, Tchou C, Gardner A, Hawkins T, Poullis C, Stumpfel J, Jones A, Yun N, Einarsson P, Lundgren T, Fajardo M, Martinez P (2004) Estimating surface reflectance properties of a complex scene under captured natural illumination. In USC ICT technical report ICT-TR-06.2004</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dellepiane M, Corsini M, Callieri M, Scopigno R (2006) High quality PTM acquisition: reflection transformation" /><p class="c-article-references__text" id="ref-CR35">Dellepiane M, Corsini M, Callieri M, Scopigno R (2006) High quality PTM acquisition: reflection transformation imaging for large objects. In: VAST ’06: proceedings of the symposium on virtual reality, archaeology and cultural heritage</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Devlin K, Chalmers A (2001) Realistic visualisation of the pompeii frescoes. In: AFRIGRAPH ’01: proceedings of" /><p class="c-article-references__text" id="ref-CR33">Devlin K, Chalmers A (2001) Realistic visualisation of the pompeii frescoes. In: AFRIGRAPH ’01: proceedings of the 1st international conference on computer graphics, virtual reality, visualisation and interaction in Africa</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Devlin K, Chalmers A, Brown D (2002a) Predictive lighting and perception in archaeological representations. In" /><p class="c-article-references__text" id="ref-CR34">Devlin K, Chalmers A, Brown D (2002a) Predictive lighting and perception in archaeological representations. In: UNESCO “World Heritage in the Digital Age” 30th Anniversary Digital Congress, UNESCO World Heritage Centre</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Devlin K, Chalmers A, Wilkie A, Purgathofer W (2002b) STAR report on tone reproduction and physically based sp" /><p class="c-article-references__text" id="ref-CR36">Devlin K, Chalmers A, Wilkie A, Purgathofer W (2002b) STAR report on tone reproduction and physically based spectral rendering. Eurographics</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="DiCarlo JC, Wandell BA (2000) Rendering high dynamic range images. SPIE conferences" /><p class="c-article-references__text" id="ref-CR51">DiCarlo JC, Wandell BA (2000) Rendering high dynamic range images. SPIE conferences</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dorsey J, Rushmeier H, Sillion F (2008) Digital modeling of the appearance of materials. Morgan Kaufmann, San " /><p class="c-article-references__text" id="ref-CR47">Dorsey J, Rushmeier H, Sillion F (2008) Digital modeling of the appearance of materials. Morgan Kaufmann, San Francisco</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Dubla, K. Debattista, A. Chalmers, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Dubla P, Debattista K, Chalmers A (2009) Adaptive interleaved sampling for interactive high fidelity rendering" /><p class="c-article-references__text" id="ref-CR38">Dubla P, Debattista K, Chalmers A (2009) Adaptive interleaved sampling for interactive high fidelity rendering. Comput Graph Forum 28(8):2117–2130</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 50 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Adaptive%20interleaved%20sampling%20for%20interactive%20high%20fidelity%20rendering&amp;journal=Comput%20Graph%20Forum&amp;volume=28&amp;issue=8&amp;pages=2117-2130&amp;publication_year=2009&amp;author=Dubla%2CP&amp;author=Debattista%2CK&amp;author=Chalmers%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Earl GP (2005) Wandering the house of the birds: reconstruction and perception at roman italica. In: VAST ’05:" /><p class="c-article-references__text" id="ref-CR52">Earl GP (2005) Wandering the house of the birds: reconstruction and perception at roman italica. In: VAST ’05: Symposium on virtual reality, archaeology and cultural heritage, short papers</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Earl CPGP (2009a) Structural and lighting models for the minoan cemetery at Phourni, crete. In: VAST ’09: proc" /><p class="c-article-references__text" id="ref-CR53">Earl CPGP (2009a) Structural and lighting models for the minoan cemetery at Phourni, crete. In: VAST ’09: proceedings of the symposium on virtual reality, archaeology and cultural heritage</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Earl GP (2009b) In press physical and photo-realism: the herculaneum amazon. In: Plenary session: fundamentos " /><p class="c-article-references__text" id="ref-CR54">Earl GP (2009b) In press physical and photo-realism: the herculaneum amazon. In: Plenary session: fundamentos tericos de la Arqueologa virtual. Proceedings of Arqueologica 2.0 Seville</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Earl GP, Keay SJ, Beale G (2008) Computer graphic modelling at portus: analysis, reconstruction and representa" /><p class="c-article-references__text" id="ref-CR58">Earl GP, Keay SJ, Beale G (2008) Computer graphic modelling at portus: analysis, reconstruction and representation of the claudian and trajanic harbours. In: Proceedings of EARSEL SIG remote sensing for archaeology and cultural heritage</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Earl GP, Beale G, Happa J, Williams M, Turley G, Martinez K, Chalmers A (2009) A repainted amazon. In: Proceed" /><p class="c-article-references__text" id="ref-CR55">Earl GP, Beale G, Happa J, Williams M, Turley G, Martinez K, Chalmers A (2009) A repainted amazon. In: Proceedings of the EVA London conference</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Egan F (1999) Fine bronze oil lamps. http://www.eganbronze.com/Pages/lamps.html&#xA;                        " /><p class="c-article-references__text" id="ref-CR56">Egan F (1999) Fine bronze oil lamps. <a href="http://www.eganbronze.com/Pages/lamps.html">http://www.eganbronze.com/Pages/lamps.html</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Einarsson P, Hawkins T, Debevec P (2004) Photometric stereo for archeological inscriptions. In: SIGGRAPH ’04: " /><p class="c-article-references__text" id="ref-CR57">Einarsson P, Hawkins T, Debevec P (2004) Photometric stereo for archeological inscriptions. In: SIGGRAPH ’04: ACM SIGGRAPH 2004 Sketches</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Freeth, Y. Bitsakis, X. Moussas, J. Seiradakis, A. Tselikas, H. Mangou, M. Zafeiropoulou, R. Hadland, D. Bate, A. Ramsey, M. Allen, A. Crawley, P. Hockley, T. Malzbender, D. Gelb, W. Ambrisco, M. Edmunds, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Freeth T, Bitsakis Y, Moussas X, Seiradakis J, Tselikas A, Mangou H, Zafeiropoulou M, Hadland R, Bate D, Ramse" /><p class="c-article-references__text" id="ref-CR61">Freeth T, Bitsakis Y, Moussas X, Seiradakis J, Tselikas A, Mangou H, Zafeiropoulou M, Hadland R, Bate D, Ramsey A, Allen M, Crawley A, Hockley P, Malzbender T, Gelb D, Ambrisco W, Edmunds M (2006) Decoding the ancient greek astronomical calculator known as the antikythera mechanism. Nature 444:587–591</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 58 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Decoding%20the%20ancient%20greek%20astronomical%20calculator%20known%20as%20the%20antikythera%20mechanism&amp;journal=Nature&amp;volume=444&amp;pages=587-591&amp;publication_year=2006&amp;author=Freeth%2CT&amp;author=Bitsakis%2CY&amp;author=Moussas%2CX&amp;author=Seiradakis%2CJ&amp;author=Tselikas%2CA&amp;author=Mangou%2CH&amp;author=Zafeiropoulou%2CM&amp;author=Hadland%2CR&amp;author=Bate%2CD&amp;author=Ramsey%2CA&amp;author=Allen%2CM&amp;author=Crawley%2CA&amp;author=Hockley%2CP&amp;author=Malzbender%2CT&amp;author=Gelb%2CD&amp;author=Ambrisco%2CW&amp;author=Edmunds%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Frischer B, Abernathy D, Guidi G, Myers J, Thibodeau C, Salvemini A, Müller P, Hofstee P, Minor B (2008) Rome " /><p class="c-article-references__text" id="ref-CR60">Frischer B, Abernathy D, Guidi G, Myers J, Thibodeau C, Salvemini A, Müller P, Hofstee P, Minor B (2008) Rome reborn. In: SIGGRAPH ’08: ACM SIGGRAPH new tech demos</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="JR. Forbes, " /><meta itemprop="datePublished" content="1966" /><meta itemprop="headline" content="Forbes JR (1966) Studies in ancient technology. Leiden &amp; Brill, Netherlands" /><p class="c-article-references__text" id="ref-CR62">Forbes JR (1966) Studies in ancient technology. Leiden &amp; Brill, Netherlands</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 60 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Studies%20in%20ancient%20technology&amp;publication_year=1966&amp;author=Forbes%2CJR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Foni A, Papagiannakis G, Magnenat-Thalmann N (2002) Virtual hagia sophia: restitution, visualization and virtu" /><p class="c-article-references__text" id="ref-CR63">Foni A, Papagiannakis G, Magnenat-Thalmann N (2002) Virtual hagia sophia: restitution, visualization and virtual life simulation. Presented at the UNESCO World Heritage Congress</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="M. Forte, A. Siliotti, C. Renfrew, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Forte M, Siliotti A, Renfrew C (1997) Virtual archaeology: re-creating ancient worlds. Harry N Abrams, New Yor" /><p class="c-article-references__text" id="ref-CR64">Forte M, Siliotti A, Renfrew C (1997) Virtual archaeology: re-creating ancient worlds. Harry N Abrams, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 62 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20archaeology%3A%20re-creating%20ancient%20worlds&amp;publication_year=1997&amp;author=Forte%2CM&amp;author=Siliotti%2CA&amp;author=Renfrew%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gardner A, Tchou C, Hawkins T, Debevec P (2003) Linear light source reflectometry. SIGGRAPH ’03: Proceedings o" /><p class="c-article-references__text" id="ref-CR75">Gardner A, Tchou C, Hawkins T, Debevec P (2003) Linear light source reflectometry. SIGGRAPH ’03: Proceedings of the 30th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gautron P, Krivanek  J, Pattanaik S, Bouatouch K (2004) A novel hemispherical basis for accurate and efficient" /><p class="c-article-references__text" id="ref-CR131">Gautron P, Krivanek  J, Pattanaik S, Bouatouch K (2004) A novel hemispherical basis for accurate and efficient rendering. In: Rendering techniques 2004, Eurographics symposium on rendering</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gautron P, Bouatouch K, Pattanaik S (2007) Temporal radiance caching. IEEE Trans Vis Comput Graph" /><p class="c-article-references__text" id="ref-CR65">Gautron P, Bouatouch K, Pattanaik S (2007) Temporal radiance caching. IEEE Trans Vis Comput Graph</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Glassner A (1994) Principles of digital image synthesis. Morgan Kaufmann, San Francisco" /><p class="c-article-references__text" id="ref-CR67">Glassner A (1994) Principles of digital image synthesis. Morgan Kaufmann, San Francisco</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Goodrick G, Gillings M (2000) Constructs, simulations and hyperreal worlds: the role of virtual reality (vr) i" /><p class="c-article-references__text" id="ref-CR66">Goodrick G, Gillings M (2000) Constructs, simulations and hyperreal worlds: the role of virtual reality (vr) in archaeological research. On the theory and practice of archaeological computing</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gonçalves A, Magalhes L, Moura J, Chalmers A (2007) Metodologia para gerao de imagens high dynamic range em il" /><p class="c-article-references__text" id="ref-CR68">Gonçalves A, Magalhes L, Moura J, Chalmers A (2007) Metodologia para gerao de imagens high dynamic range em iluminao romana. In: Proceedings of international association for the scientific knowledge InterTIC’07</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gonçalves A, Magalhes L, Moura J, Chalmers A (2008) Accurate modelling of roman lamps in conimbriga using high" /><p class="c-article-references__text" id="ref-CR69">Gonçalves A, Magalhes L, Moura J, Chalmers A (2008) Accurate modelling of roman lamps in conimbriga using high dynamic range. In: VAST ’08: proceedings of the symposium on virtual reality, archaeology and cultural heritage</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gonçalves A, Magalhes L, Moura J, Chalmers A (2009) High dynamic range—a gateway for predictive ancient lighti" /><p class="c-article-references__text" id="ref-CR70">Gonçalves A, Magalhes L, Moura J, Chalmers A (2009) High dynamic range—a gateway for predictive ancient lighting. ACM J Comput Cult Herit</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gutierrez D, Sundstedt V, Gomez F, Chalmers A (2006) Dust and light: predictive virtual archaeology. J Cult He" /><p class="c-article-references__text" id="ref-CR71">Gutierrez D, Sundstedt V, Gomez F, Chalmers A (2006) Dust and light: predictive virtual archaeology. J Cult Herit</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gutierrez D, Sundstedt V, Gomez F, Chalmers A (2008) Modeling light scattering for virtual heritage. J Comput " /><p class="c-article-references__text" id="ref-CR72">Gutierrez D, Sundstedt V, Gomez F, Chalmers A (2008) Modeling light scattering for virtual heritage. J Comput Cult Herit</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Glencross M, Ward G, Melendez F, Jay C, Liu J, Hubbold R (2008) A perceptually validated model for surface dep" /><p class="c-article-references__text" id="ref-CR76">Glencross M, Ward G, Melendez F, Jay C, Liu J, Hubbold R (2008) A perceptually validated model for surface depth hallucination. In: SIGGRAPH ’08: proceedings of the 35th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Goral CM, Torrance KE, Greenberg DP, Battaile B (1984) Modeling the interaction of light between diffuse surfa" /><p class="c-article-references__text" id="ref-CR74">Goral CM, Torrance KE, Greenberg DP, Battaile B (1984) Modeling the interaction of light between diffuse surfaces. In: SIGGRAPH ’84: proceedings of the 11th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gutierrez D, Seron F, Magallon J, Sobreviela E, Latorre P (2004) Archaeological and cultural heritage: bringin" /><p class="c-article-references__text" id="ref-CR73">Gutierrez D, Seron F, Magallon J, Sobreviela E, Latorre P (2004) Archaeological and cultural heritage: bringing life to an unearthed muslim suburb in an immersive environment. J Cult Herit</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Happa J, Artusi A, Dubla P, Bashford-Rogers T, Debattista K, Hulusić V, Chalmers A (2009) The virtual reconstr" /><p class="c-article-references__text" id="ref-CR77">Happa J, Artusi A, Dubla P, Bashford-Rogers T, Debattista K, Hulusić V, Chalmers A (2009) The virtual reconstruction and daylight illumination of the panagia angeloktisti. In: VAST ’09: proceedings of the symposium on virtual reality, archaeology and cultural heritage</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hawkins T, Cohen J, Debevec P (2001) A photometric approach to digitizing cultural artifacts. In: VAST ’01: pr" /><p class="c-article-references__text" id="ref-CR78">Hawkins T, Cohen J, Debevec P (2001) A photometric approach to digitizing cultural artifacts. In: VAST ’01: proceedings of the symposium on virtual reality, archeology, and cultural heritage</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hawkins T, Einarsson P, Debevec P (2005) Acquisition of time-varying participating media. In: SIGGRAPH ’05: pr" /><p class="c-article-references__text" id="ref-CR80">Hawkins T, Einarsson P, Debevec P (2005) Acquisition of time-varying participating media. In: SIGGRAPH ’05: proceedings of the 32nd annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hachisuka T, Ogaki S, Jensen HW (2008) Progressive photon mapping. In: SIGGRAPH Asia ’08: ACM SIGGRAPH Asia pa" /><p class="c-article-references__text" id="ref-CR83">Hachisuka T, Ogaki S, Jensen HW (2008) Progressive photon mapping. In: SIGGRAPH Asia ’08: ACM SIGGRAPH Asia papers</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="HDRShop (2001) Example software to research hdri. http://www.gl.ict.usc.edu/HDRShop/&#xA;                        " /><p class="c-article-references__text" id="ref-CR79">HDRShop (2001) Example software to research hdri. <a href="http://www.gl.ict.usc.edu/HDRShop/">http://www.gl.ict.usc.edu/HDRShop/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Happa J, Williams M, Turley G, Earl GP, Dubla P, Beale G, Gibbons G, Debattista K, Chalmers A (2009) Virtual r" /><p class="c-article-references__text" id="ref-CR85">Happa J, Williams M, Turley G, Earl GP, Dubla P, Beale G, Gibbons G, Debattista K, Chalmers A (2009) Virtual relighting of a roman statue head from herculaneum: a case study. In: AFRIGRAPH ’09: proceedings of the 6th international conference on computer graphics, virtual reality, visualisation and interaction in Africa</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hasinoff SW, Kutulakos KN (2003) Photo-consistent 3d fire by flame-sheet decomposition. In: ICCV ’03: proceedi" /><p class="c-article-references__text" id="ref-CR82">Hasinoff SW, Kutulakos KN (2003) Photo-consistent 3d fire by flame-sheet decomposition. In: ICCV ’03: proceedings of the ninth IEEE international conference on computer vision</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hewlett-Packard (2009) Polynomial texture mapping—interactive relighting software licence. http://www.hpl.hp.c" /><p class="c-article-references__text" id="ref-CR84">Hewlett-Packard (2009) Polynomial texture mapping—interactive relighting software licence. <a href="http://www.hpl.hp.com/research/ptm/downloads/agreement.html">http://www.hpl.hp.com/research/ptm/downloads/agreement.html</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="D. Hood, M. Finkelstein, " /><meta itemprop="datePublished" content="1986" /><meta itemprop="headline" content="Hood D, Finkelstein M (1986) Sensitivity to light. Handbook of perception and human performance. Wiley, New Yo" /><p class="c-article-references__text" id="ref-CR81">Hood D, Finkelstein M (1986) Sensitivity to light. Handbook of perception and human performance. Wiley, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 84 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Sensitivity%20to%20light.%20Handbook%20of%20perception%20and%20human%20performance&amp;publication_year=1986&amp;author=Hood%2CD&amp;author=Finkelstein%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Igawa N, Koga Y, Matsuzawa T, Nakamura H (2004) Models of sky radiance distribution and sky luminance distribu" /><p class="c-article-references__text" id="ref-CR87">Igawa N, Koga Y, Matsuzawa T, Nakamura H (2004) Models of sky radiance distribution and sky luminance distribution. Solar Energy</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ihrke I, Magnor M (2004) Image-based tomographic reconstruction of flames. In: SCA ’04: proceedings of the ACM" /><p class="c-article-references__text" id="ref-CR88">Ihrke I, Magnor M (2004) Image-based tomographic reconstruction of flames. In: SCA ’04: proceedings of the ACM SIGGRAPH/Eurographics symposium on computer animation</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Inakage M (1990) A simple model of flames. In: CG international ’90: proceedings of the eighth international c" /><p class="c-article-references__text" id="ref-CR89">Inakage M (1990) A simple model of flames. In: CG international ’90: proceedings of the eighth international conference of the computer graphics society on CG international ’90: computer graphics around the world</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Iwasaki K, Dobashi Y, Yoshimoto F, Nishita T (2007) Precomputed radiance transfer for dynamics scene taking in" /><p class="c-article-references__text" id="ref-CR86">Iwasaki K, Dobashi Y, Yoshimoto F, Nishita T (2007) Precomputed radiance transfer for dynamics scene taking into account light inter-reflection. In: Eurographics symposium on rendering</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="W. Jarosz, C. Donner, M. Zwicker, HW. Jensen, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Jarosz W, Donner C, Zwicker M, Jensen HW (2008) Radiance caching for participating media. ACM Trans Graph 27(1" /><p class="c-article-references__text" id="ref-CR92">Jarosz W, Donner C, Zwicker M, Jensen HW (2008) Radiance caching for participating media. ACM Trans Graph 27(1):1–11</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 89 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Radiance%20caching%20for%20participating%20media&amp;journal=ACM%20Trans%20Graph&amp;volume=27&amp;issue=1&amp;pages=1-11&amp;publication_year=2008&amp;author=Jarosz%2CW&amp;author=Donner%2CC&amp;author=Zwicker%2CM&amp;author=Jensen%2CHW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Jensen HW (2001) Realistic image synthesis using photon mapping. A.K. Peters, Natick" /><p class="c-article-references__text" id="ref-CR93">Jensen HW (2001) Realistic image synthesis using photon mapping. A.K. Peters, Natick</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Jensen HW, Christensen PH (1998) Efficient simulation of light transport in scences with participating media u" /><p class="c-article-references__text" id="ref-CR90">Jensen HW, Christensen PH (1998) Efficient simulation of light transport in scences with participating media using photon maps. In: SIGGRAPH ’98: proceedings of the 25th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Jensen HW, Durand F, Stark M, Premoze S, Dorsey J, Shirley P (2001a) A physically based nightsky model. In: SI" /><p class="c-article-references__text" id="ref-CR91">Jensen HW, Durand F, Stark M, Premoze S, Dorsey J, Shirley P (2001a) A physically based nightsky model. In: SIGGRAPH ’01: proceedings of the 28th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Jensen HW, Marschner SR, Levoy M, Hanrahan P (2001b) A practical model for subsurface light transport. In: SIG" /><p class="c-article-references__text" id="ref-CR94">Jensen HW, Marschner SR, Levoy M, Hanrahan P (2001b) A practical model for subsurface light transport. In: SIGGRAPH ’01: proceedings of the 28th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kang SB, Uyttendaele M, Winder S, Szeliski R (2003) High dynamic range video. ACM Trans Graph" /><p class="c-article-references__text" id="ref-CR107">Kang SB, Uyttendaele M, Winder S, Szeliski R (2003) High dynamic range video. ACM Trans Graph</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kajiya J (1986) The rendering equation. In: SIGGRAPH ’86: proceedings of the 13th annual conference on compute" /><p class="c-article-references__text" id="ref-CR95">Kajiya J (1986) The rendering equation. In: SIGGRAPH ’86: proceedings of the 13th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Keller A (1997) Instant radiosity. In: SIGGRAPH ’97: proceedings of the 24th annual conference on computer gra" /><p class="c-article-references__text" id="ref-CR96">Keller A (1997) Instant radiosity. In: SIGGRAPH ’97: proceedings of the 24th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Keng S-L, Lee W-Y, Chuang J-H (2006) An efficient caching-based rendering of translucent materials. Vis Comput" /><p class="c-article-references__text" id="ref-CR101">Keng S-L, Lee W-Y, Chuang J-H (2006) An efficient caching-based rendering of translucent materials. Vis Comput: Int J Comput Graph</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kider JT, Fletcher RL, Yu N, Holod R, Chalmers A, Badler NI (2009) Recreating early islamic glass lamp lightin" /><p class="c-article-references__text" id="ref-CR97">Kider JT, Fletcher RL, Yu N, Holod R, Chalmers A, Badler NI (2009) Recreating early islamic glass lamp lighting. In: VAST ’09: proceedings of the symposium on virtual reality, archaeology and cultural heritage</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Klinker GJ, Shafer SA, Kannade T (1987) Using a color reflection model to separate highlights from object colo" /><p class="c-article-references__text" id="ref-CR103">Klinker GJ, Shafer SA, Kannade T (1987) Using a color reflection model to separate highlights from object color. In: Proceedings 1st international conference on computer vision, IEEE London</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Klinker GJ, Shafer SA, Kannade T (1990a) The measurement of highlights in color images. Int J Comput Vis" /><p class="c-article-references__text" id="ref-CR104">Klinker GJ, Shafer SA, Kannade T (1990a) The measurement of highlights in color images. Int J Comput Vis</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Klinker GJ, Shafer SA, Kannade T (1990b) A physical approach to color image understanding. Int J Comput Vis" /><p class="c-article-references__text" id="ref-CR105">Klinker GJ, Shafer SA, Kannade T (1990b) A physical approach to color image understanding. Int J Comput Vis</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kim D, Lin S, Hong K, Shum H (2002) Variational specular separation using color and polarization. In: IAPR wor" /><p class="c-article-references__text" id="ref-CR102">Kim D, Lin S, Hong K, Shum H (2002) Variational specular separation using color and polarization. In: IAPR workshop on machine vision applications</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Kimpe, PA. Jacobs, M. Waelkens, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Kimpe K, Jacobs PA, Waelkens M (2001) Analysis of oil used in late roman oil lamps with different mass spectro" /><p class="c-article-references__text" id="ref-CR100">Kimpe K, Jacobs PA, Waelkens M (2001) Analysis of oil used in late roman oil lamps with different mass spectrometric techniques revealed the presence of predominantly olive oil together with traces of animal fat. J Chromatogr A 937(1–2):87–95</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 103 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Analysis%20of%20oil%20used%20in%20late%20roman%20oil%20lamps%20with%20different%20mass%20spectrometric%20techniques%20revealed%20the%20presence%20of%20predominantly%20olive%20oil%20together%20with%20traces%20of%20animal%20fat&amp;journal=J%20Chromatogr%20A&amp;volume=937&amp;issue=1%E2%80%932&amp;pages=87-95&amp;publication_year=2001&amp;author=Kimpe%2CK&amp;author=Jacobs%2CPA&amp;author=Waelkens%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Koller D, Turitzin M, Levoy M, Tarini M, Croccia G, Cignoni P, Scopigno R (2004) Protected interactive 3d grap" /><p class="c-article-references__text" id="ref-CR106">Koller D, Turitzin M, Levoy M, Tarini M, Croccia G, Cignoni P, Scopigno R (2004) Protected interactive 3d graphics via remote rendering. In: SIGGRAPH ’04: proceedings of the 31st annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Křivánek J, Gautron P, Pattanaik S, Bouatouch K (2005) Radiance caching for efficient global illumination comp" /><p class="c-article-references__text" id="ref-CR98">Křivánek J, Gautron P, Pattanaik S, Bouatouch K (2005) Radiance caching for efficient global illumination computation. IEEE Trans Vis and Comput Graph</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Kuang, GM. Johnson, MD. Fairchild, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Kuang J, Johnson GM, Fairchild MD (2007) iCAM06: a refined image appearance model for HDR image rendering. J V" /><p class="c-article-references__text" id="ref-CR99">Kuang J, Johnson GM, Fairchild MD (2007) iCAM06: a refined image appearance model for HDR image rendering. J Vis Commun Image Represent 18(5):406–414</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 106 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=iCAM06%3A%20a%20refined%20image%20appearance%20model%20for%20HDR%20image%20rendering&amp;journal=J%20Vis%20Commun%20Image%20Represent&amp;volume=18&amp;issue=5&amp;pages=406-414&amp;publication_year=2007&amp;author=Kuang%2CJ&amp;author=Johnson%2CGM&amp;author=Fairchild%2CMD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lafortune E, Foo S-C, Torrance K, Greenberg D (1997) Non-linear approximation of reflectance functions. In: SI" /><p class="c-article-references__text" id="ref-CR110">Lafortune E, Foo S-C, Torrance K, Greenberg D (1997) Non-linear approximation of reflectance functions. In: SIGGRAPH ’97: proceedings of the 24th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lai Y-C, Fan SH, Chenney S, Dyer C (2007) Rendering techniques. In: Kautz J, Pattanaik S (eds) Photorealistic " /><p class="c-article-references__text" id="ref-CR109">Lai Y-C, Fan SH, Chenney S, Dyer C (2007) Rendering techniques. In: Kautz J, Pattanaik S (eds) Photorealistic image rendering with population Monte Carlo energy redistribution</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lamorlette A, Foster N (2002) Structural modeling of flames for a production environment. In: SIGGRAPH ’02: pr" /><p class="c-article-references__text" id="ref-CR108">Lamorlette A, Foster N (2002) Structural modeling of flames for a production environment. In: SIGGRAPH ’02: proceedings of the 29th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ledda P, Santos LP, Chalmers A (2004) A local model of eye adaptation for high dynamic range images. In: AFRIG" /><p class="c-article-references__text" id="ref-CR112">Ledda P, Santos LP, Chalmers A (2004) A local model of eye adaptation for high dynamic range images. In: AFRIGRAPH ’04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lin S, Li Y, Kang SB, Tong X, Shum HY (2002) Diffuse-specular separation and depth recovery from image sequenc" /><p class="c-article-references__text" id="ref-CR111">Lin S, Li Y, Kang SB, Tong X, Shum HY (2002) Diffuse-specular separation and depth recovery from image sequences. In: European conference on computer vision</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lin S, Tan P, Quan L (2006) Separation of highlight reflections on texture surfaces. In: IEEE conference on co" /><p class="c-article-references__text" id="ref-CR113">Lin S, Tan P, Quan L (2006) Separation of highlight reflections on texture surfaces. In: IEEE conference on computer vision and pattern recognition 2006</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mallick SP, Zickler T, Kriegman DJ, Belhumeur PN (2006) Specularity removal in images and videos: a pde approa" /><p class="c-article-references__text" id="ref-CR126">Mallick SP, Zickler T, Kriegman DJ, Belhumeur PN (2006) Specularity removal in images and videos: a pde approach. In: Proceedings European conference computer vision</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mann S, Picard RW (1995) Being “undigital” with digital cameras: extending dynamic range by combining differen" /><p class="c-article-references__text" id="ref-CR123">Mann S, Picard RW (1995) Being “undigital” with digital cameras: extending dynamic range by combining differently exposed pictures. In: Proceedings of IS&amp;T 46th annual conference</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Malzbender T (2006) Tom malzbender publication list. http://www.hpl.hp.com/personal/Tom_Malzbender/&#xA;          " /><p class="c-article-references__text" id="ref-CR114">Malzbender T (2006) Tom malzbender publication list. <a href="http://www.hpl.hp.com/personal/Tom_Malzbender/">http://www.hpl.hp.com/personal/Tom_Malzbender/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Malzbender T, Ordentlict E (2005) Maximum entropy lighting for physical objects. Hewlett-Packard Technical Rep" /><p class="c-article-references__text" id="ref-CR122">Malzbender T, Ordentlict E (2005) Maximum entropy lighting for physical objects. Hewlett-Packard Technical Report HPL-2005-68</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Malzbender T, Gelb D, Wolters H (2001) Polynomial texture maps. In: SIGGRAPH ’01: proceedings of the 28th annu" /><p class="c-article-references__text" id="ref-CR117">Malzbender T, Gelb D, Wolters H (2001) Polynomial texture maps. In: SIGGRAPH ’01: proceedings of the 28th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Martinez P (2001) Digital realities and archaeology: a difficult relationship or a fruitful marriage? In: VAST" /><p class="c-article-references__text" id="ref-CR115">Martinez P (2001) Digital realities and archaeology: a difficult relationship or a fruitful marriage? In: VAST ’01: proceedings of the symposium on virtual reality, archeology, and cultural heritage</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Melek Z, Keyser J (2002) Interactive simulation of fire. Technical Report 2002-7-1, Texas A&amp;M University, Depa" /><p class="c-article-references__text" id="ref-CR118">Melek Z, Keyser J (2002) Interactive simulation of fire. Technical Report 2002-7-1, Texas A&amp;M University, Department of Computer Science</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mental Images (2009) Mental ray company website. http://www.mentalimages.com/&#xA;                        " /><p class="c-article-references__text" id="ref-CR116">Mental Images (2009) Mental ray company website. <a href="http://www.mentalimages.com/">http://www.mentalimages.com/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mitsunaga T, Nayar S (1999) Radiometric self calibration. In: IEEE conference on computer vision and pattern r" /><p class="c-article-references__text" id="ref-CR121">Mitsunaga T, Nayar S (1999) Radiometric self calibration. In: IEEE conference on computer vision and pattern recognition (CVPR)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mudge M (2004) Implementing digital technology adoption by cultural heritage professionalsl. SIGGRAPH ’04: Con" /><p class="c-article-references__text" id="ref-CR124">Mudge M (2004) Implementing digital technology adoption by cultural heritage professionalsl. SIGGRAPH ’04: Conference presentations for cultural heritage and computer graphics panel</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mudge M, Voutaz J-P, Schroer C, Lum M (2005) Reflection transformation imaging and virtual representations of " /><p class="c-article-references__text" id="ref-CR125">Mudge M, Voutaz J-P, Schroer C, Lum M (2005) Reflection transformation imaging and virtual representations of coins from the hospice of the grand St. Bernard. In: VAST ’05: proceedings of the symposium on virtual reality, archaeology and cultural heritage</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mudge M, Malzbender T, Schroer C, Lum M (2006) New reflection transformation imaging methods for rock art and " /><p class="c-article-references__text" id="ref-CR120">Mudge M, Malzbender T, Schroer C, Lum M (2006) New reflection transformation imaging methods for rock art and multiple viewpoint display. VAST ’06: Proceedings of the symposium on virtual reality, archaeology and cultural heritage</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mudge M, Malzbender T, Chalmers A, Scopigno R, Davis J, Wang O, Gunawardane P, Ashley M, Doerr M, Proenca A, B" /><p class="c-article-references__text" id="ref-CR119">Mudge M, Malzbender T, Chalmers A, Scopigno R, Davis J, Wang O, Gunawardane P, Ashley M, Doerr M, Proenca A, Barbosa J (2008) Image-based empirical acquisition, scientific reliability, and long-term digital preservation for the natural sciences and cultural heritage. Eurographics Tutorial Notes</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Nayar S, Branzoi V (2003) Adaptive dynamic range imaging: optical control of pixel exposures over space and ti" /><p class="c-article-references__text" id="ref-CR127">Nayar S, Branzoi V (2003) Adaptive dynamic range imaging: optical control of pixel exposures over space and time. In: IEEE international conference on computer vision (ICCV)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Nayar SK, Fang X, Boult T (1997) Separation of reflection components using color and polarization. Int J Compu" /><p class="c-article-references__text" id="ref-CR128">Nayar SK, Fang X, Boult T (1997) Separation of reflection components using color and polarization. Int J Comput Vis</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Nguyen DQ, Fedkiw R, Jensen HW (2002) Physically based modeling and animation of fire. SIGGRAPH ’02: Proceedin" /><p class="c-article-references__text" id="ref-CR129">Nguyen DQ, Fedkiw R, Jensen HW (2002) Physically based modeling and animation of fire. SIGGRAPH ’02: Proceedings of the 29th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Panoscan (2002) Panoscan MK-3, Company website. http://www.panoscan.com/&#xA;                        " /><p class="c-article-references__text" id="ref-CR130">Panoscan (2002) Panoscan MK-3, Company website. <a href="http://www.panoscan.com/">http://www.panoscan.com/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Pan, R. Wang, X. Liu, Q. Peng, H. Bao, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Pan M, Wang R, Liu X, Peng Q, Bao H (2007) Precomputed radiance transfer field for rendering inter-reflections" /><p class="c-article-references__text" id="ref-CR138">Pan M, Wang R, Liu X, Peng Q, Bao H (2007) Precomputed radiance transfer field for rendering inter-reflections in dynamic scenes. Comput Graph Forum 26(3):485–493</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 130 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Precomputed%20radiance%20transfer%20field%20for%20rendering%20inter-reflections%20in%20dynamic%20scenes&amp;journal=Comput%20Graph%20Forum&amp;volume=26&amp;issue=3&amp;pages=485-493&amp;publication_year=2007&amp;author=Pan%2CM&amp;author=Wang%2CR&amp;author=Liu%2CX&amp;author=Peng%2CQ&amp;author=Bao%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Perry CH, Picard RW (1994) Synthesizing flames and their spreading. In: Proceedings of the 5th Eurographics wo" /><p class="c-article-references__text" id="ref-CR134">Perry CH, Picard RW (1994) Synthesizing flames and their spreading. In: Proceedings of the 5th Eurographics workshop on animation and simulation</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pegoraro V, Parker SG (2006) Pshysically based realistic fire rendering. In: Proceedings of the 2nd Eurographi" /><p class="c-article-references__text" id="ref-CR135">Pegoraro V, Parker SG (2006) Pshysically based realistic fire rendering. In: Proceedings of the 2nd Eurographics workshop on natural phenomena</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Perez R, Seals R, Ineichen P (1993) An allweather model for skyluminance distribution. Solar Energy" /><p class="c-article-references__text" id="ref-CR136">Perez R, Seals R, Ineichen P (1993) An allweather model for skyluminance distribution. Solar Energy</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="M. Pharr, G. Humphreys, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Pharr M, Humphreys G (2004) Physically based rendering: from theory to implementation. Morgan Kaufmann, San Fr" /><p class="c-article-references__text" id="ref-CR132">Pharr M, Humphreys G (2004) Physically based rendering: from theory to implementation. Morgan Kaufmann, San Francisco</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 134 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Physically%20based%20rendering%3A%20from%20theory%20to%20implementation&amp;publication_year=2004&amp;author=Pharr%2CM&amp;author=Humphreys%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Preetham A, Shirley P, Smits B (1999) A practical analytic model for daylight. In: SIGGRAPH ’99: proceedings o" /><p class="c-article-references__text" id="ref-CR137">Preetham A, Shirley P, Smits B (1999) A practical analytic model for daylight. In: SIGGRAPH ’99: proceedings of the 26th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Raczkowski J (1996) Visual simulation and animation of a laminar candle flame. In: International conference on" /><p class="c-article-references__text" id="ref-CR139">Raczkowski J (1996) Visual simulation and animation of a laminar candle flame. In: International conference on image processing and computer graphics</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="WT. Reeves, " /><meta itemprop="datePublished" content="1983" /><meta itemprop="headline" content="Reeves WT (1983) Particle systems—a technique for modeling a class of fuzzy objects. ACM Trans Graph 2(2):91–1" /><p class="c-article-references__text" id="ref-CR143">Reeves WT (1983) Particle systems—a technique for modeling a class of fuzzy objects. ACM Trans Graph 2(2):91–108</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 137 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Particle%20systems%E2%80%94a%20technique%20for%20modeling%20a%20class%20of%20fuzzy%20objects&amp;journal=ACM%20Trans%20Graph&amp;volume=2&amp;issue=2&amp;pages=91-108&amp;publication_year=1983&amp;author=Reeves%2CWT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Reilly P (1991) Towards a virtual archaeology. Comput Appl Quant Methods Archaeol" /><p class="c-article-references__text" id="ref-CR144">Reilly P (1991) Towards a virtual archaeology. Comput Appl Quant Methods Archaeol</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="E. Reinhard, G. Ward, S. Pattanaik, P. Debevec, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Reinhard E, Ward G, Pattanaik S, Debevec P (2005) High dynamic range imaging: acquisition, display, and image-" /><p class="c-article-references__text" id="ref-CR149">Reinhard E, Ward G, Pattanaik S, Debevec P (2005) High dynamic range imaging: acquisition, display, and image-based lighting. Morgan Kaufmann, San Francisco</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 139 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=High%20dynamic%20range%20imaging%3A%20acquisition%2C%20display%2C%20and%20image-based%20lighting&amp;publication_year=2005&amp;author=Reinhard%2CE&amp;author=Ward%2CG&amp;author=Pattanaik%2CS&amp;author=Debevec%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ritschel T, Grosch T, Kim MH, Seidel H-P, Dachsbacher C, Kautz J (2008) Imperfect shadow maps for efficient co" /><p class="c-article-references__text" id="ref-CR145">Ritschel T, Grosch T, Kim MH, Seidel H-P, Dachsbacher C, Kautz J (2008) Imperfect shadow maps for efficient computation of indirect illumination. SIGGRAPH Asia ’08: ACM SIGGRAPH Asia papers</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ritschel T, Ihrke M, Frisvad JR, Coppens J, Myszkowski K, Seidel H-P (2009) Temporal glare: real-time dynamic " /><p class="c-article-references__text" id="ref-CR146">Ritschel T, Ihrke M, Frisvad JR, Coppens J, Myszkowski K, Seidel H-P (2009) Temporal glare: real-time dynamic simulation of the scattering in the human eye. Eurographics</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Robertson MA, Borman S, Stevenson RL (1999) Dynamic range improvement through multiple exposures. In: Proceedi" /><p class="c-article-references__text" id="ref-CR140">Robertson MA, Borman S, Stevenson RL (1999) Dynamic range improvement through multiple exposures. In: Proceedings of the 1999 international conference on image processing (ICIP-99)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MA. Robertson, S. Borman, RL. Stevenson, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Robertson MA, Borman S, Stevenson RL (2003) Estimation-theoretic approach to dynamic range enhancement using m" /><p class="c-article-references__text" id="ref-CR141">Robertson MA, Borman S, Stevenson RL (2003) Estimation-theoretic approach to dynamic range enhancement using multiple exposures. J Electron Imaging 12(2):219–228</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 143 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Estimation-theoretic%20approach%20to%20dynamic%20range%20enhancement%20using%20multiple%20exposures&amp;journal=J%20Electron%20Imaging&amp;volume=12&amp;issue=2&amp;pages=219-228&amp;publication_year=2003&amp;author=Robertson%2CMA&amp;author=Borman%2CS&amp;author=Stevenson%2CRL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Roberts J, Ryan N (1997) Alternative archaeological representations within virtual worlds. In: Proceedings of " /><p class="c-article-references__text" id="ref-CR147">Roberts J, Ryan N (1997) Alternative archaeological representations within virtual worlds. In: Proceedings of the 4th UK virtual reality specialist interest group conference—Brunel University</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Roussos I, Chalmers A (2003) High fidelity lighting of knossos. In: VAST ’03: proceedings of the symposium on " /><p class="c-article-references__text" id="ref-CR142">Roussos I, Chalmers A (2003) High fidelity lighting of knossos. In: VAST ’03: proceedings of the symposium on virtual reality, archaeology and intelligent cultural heritage</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rushmeier H (1995) Rendering participating media: problems and solutions from application areas. In: Proceedin" /><p class="c-article-references__text" id="ref-CR148">Rushmeier H (1995) Rendering participating media: problems and solutions from application areas. In: Proceedings of the 5th Eurographics workshop on rendering, Springer</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Salvador E, Ebrahimi T (2001) Shadow identification and classification using invariant color models" /><p class="c-article-references__text" id="ref-CR59">Salvador E, Ebrahimi T (2001) Shadow identification and classification using invariant color models</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sander P (2006) The Parthenon demo preprocessing and real-time rendering techniques for large datasets. SIGGRA" /><p class="c-article-references__text" id="ref-CR150">Sander P (2006) The Parthenon demo preprocessing and real-time rendering techniques for large datasets. SIGGRAPH</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Schlns K, Teschner M (1995a) Analysis of 2d color spaces for highlight elimination in 3d shape reconstruction." /><p class="c-article-references__text" id="ref-CR160">Schlns K, Teschner M (1995a) Analysis of 2d color spaces for highlight elimination in 3d shape reconstruction. In: Proceedings ACCV</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Schlns K, Teschner M (1995b) Fast separation of reflection components and its application in 3d shape recovery" /><p class="c-article-references__text" id="ref-CR161">Schlns K, Teschner M (1995b) Fast separation of reflection components and its application in 3d shape recovery. In: Proceedings 3rd color imaging conference</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Seetzen H, Heidrich W, Stuerzlinger W, Ward G, Whitehead L, Trentacoste M, Ghosh A, Vorozcovs A (2004) High dy" /><p class="c-article-references__text" id="ref-CR155">Seetzen H, Heidrich W, Stuerzlinger W, Ward G, Whitehead L, Trentacoste M, Ghosh A, Vorozcovs A (2004) High dynamic range display systems. In: SIGGRAPH '04: ACM SIGGRAPH 2004 Emerging technologies. ACM, New York, p 8</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Shafer S (1984) Using color to separate reflection components. Technical Report" /><p class="c-article-references__text" id="ref-CR154">Shafer S (1984) Using color to separate reflection components. Technical Report</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Shreiner D, Woo M, Neider J, Davis T (2004) OpenGL(R) 1.4 Reference manual, 4th edn. Addison Wesley Longman Pu" /><p class="c-article-references__text" id="ref-CR162">Shreiner D, Woo M, Neider J, Davis T (2004) OpenGL(R) 1.4 Reference manual, 4th edn. Addison Wesley Longman Publishing Co., Inc</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sloan P-P, Kautz J, Snyder J (2002) Precomputed radiance transfer for real-time rendering in dynamic, low-freq" /><p class="c-article-references__text" id="ref-CR158">Sloan P-P, Kautz J, Snyder J (2002) Precomputed radiance transfer for real-time rendering in dynamic, low-frequency lighting environments. In: SIGGRAPH ’02: proceedings of the 29th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="B. Spencer, MW. Jones, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Spencer B, Jones MW (2009) Into the blue: better caustics through photon relaxation. Comput Graph Forum 28(2):" /><p class="c-article-references__text" id="ref-CR156">Spencer B, Jones MW (2009) Into the blue: better caustics through photon relaxation. Comput Graph Forum 28(2):319–328</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 155 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Into%20the%20blue%3A%20better%20caustics%20through%20photon%20relaxation&amp;journal=Comput%20Graph%20Forum&amp;volume=28&amp;issue=2&amp;pages=319-328&amp;publication_year=2009&amp;author=Spencer%2CB&amp;author=Jones%2CMW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Spheron (2002) SpherOn HDR, Company website. http://www.spheron.com/&#xA;                        " /><p class="c-article-references__text" id="ref-CR159">Spheron (2002) SpherOn HDR, Company website. <a href="http://www.spheron.com/">http://www.spheron.com/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Stam J, Fiume E (1995) Depicting fire and other gaseous phenomena using diffusion processes. In: SIGGRAPH ’95:" /><p class="c-article-references__text" id="ref-CR152">Stam J, Fiume E (1995) Depicting fire and other gaseous phenomena using diffusion processes. In: SIGGRAPH ’95: proceedings of the 22nd annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Stumpfel J, Jones A, Wenger A, Tchou C, Hawkins T, Debevec P (2004) Direct HDR capture of the sun and sky. In:" /><p class="c-article-references__text" id="ref-CR157">Stumpfel J, Jones A, Wenger A, Tchou C, Hawkins T, Debevec P (2004) Direct HDR capture of the sun and sky. In: AFRIGRAPH ’04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sundstedt V, Chalmers A, Martinez P (2004) High fidelity reconstruction of the ancient egyptian temple of kala" /><p class="c-article-references__text" id="ref-CR151">Sundstedt V, Chalmers A, Martinez P (2004) High fidelity reconstruction of the ancient egyptian temple of kalabsha. In: AFRIGRAPH ’04: proceedings of the 3rd international conference on computer graphics, virtual reality, visualisation and interaction in Africa</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sundstedt V, Gutierrez D, Gomez F, Chalmers A (2005) Participating media for high-fidelity cultural heritage. " /><p class="c-article-references__text" id="ref-CR153">Sundstedt V, Gutierrez D, Gomez F, Chalmers A (2005) Participating media for high-fidelity cultural heritage. In: VAST ’05: proceedings of the symposium on virtual reality, archaeology and cultural heritage</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Takahashi J-y, Takahashi H, Chiba N (1997) Image synthesis of flickering scenes including simulated flames. IE" /><p class="c-article-references__text" id="ref-CR167">Takahashi J-y, Takahashi H, Chiba N (1997) Image synthesis of flickering scenes including simulated flames. IEICE Trans Inf Syst</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Tan R, Ikeuchi K (2003) Separating reflection components of terxtured surfaces using a single image. In: Proce" /><p class="c-article-references__text" id="ref-CR165">Tan R, Ikeuchi K (2003) Separating reflection components of terxtured surfaces using a single image. In: Proceeding IEEE international conference on computer vision ICCV</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Tan R, Ikeuchi K (2004) Intrinsic properties of an image with highlights. Meeting on image recognition and und" /><p class="c-article-references__text" id="ref-CR166">Tan R, Ikeuchi K (2004) Intrinsic properties of an image with highlights. Meeting on image recognition and understanding MIRU 2004</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Tan P, Lin S, Quan L (2006) Separation of highlight reflections on texture surfaces. In: IEEE conference on co" /><p class="c-article-references__text" id="ref-CR133">Tan P, Lin S, Quan L (2006) Separation of highlight reflections on texture surfaces. In: IEEE conference on computer vision and pattern recognition</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Tappen MF, Freeman WT, Adelson EH (2005) Recovering intrinsic images from a single image. IEEE Trans Pattern A" /><p class="c-article-references__text" id="ref-CR164">Tappen MF, Freeman WT, Adelson EH (2005) Recovering intrinsic images from a single image. IEEE Trans Pattern Anal Mach Intell</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="The reasearch team included Tom Malzbender from HPLabs (1998) James Davis, Oliver Wang and Prabath Gunawardane" /><p class="c-article-references__text" id="ref-CR163">The reasearch team included Tom Malzbender from HPLabs (1998) James Davis, Oliver Wang and Prabath Gunawardane from the University of California Santa Cruz, Martin Doerr and Steve Stead from The International Council of Museum’s (ICOM) Documentation Committee’s (CIDOC) Conceptual Reference Model (CRM) Special Interest Group, Roberto Scopigno, Paolo Cignoni, Massimiliano Corsini and Gianpaolo Palma from the Institute of Information Science and Technology (ISTI), Alberto Proenca and Joao Barbosa from the High Peformance Computing Center at the University of Minho, Alan Chalmers from the University of Warwick, and Holly Rushmeier from Yale</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Unger J (2009) Incident light fields. PhD thesis, Linkping University" /><p class="c-article-references__text" id="ref-CR168">Unger J (2009) Incident light fields. PhD thesis, Linkping University</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Veach E, Guibas LJ (1997) Metropolis light transport. In: SIGGRAPH ’97: proceedings of the 24th annual confere" /><p class="c-article-references__text" id="ref-CR169">Veach E, Guibas LJ (1997) Metropolis light transport. In: SIGGRAPH ’97: proceedings of the 24th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Wang R, Akerlund O (2009) Bidirectional importance sampling for unstructured illuminationn. Eurographics" /><p class="c-article-references__text" id="ref-CR170">Wang R, Akerlund O (2009) Bidirectional importance sampling for unstructured illuminationn. Eurographics</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ward GJ (1992) Measuring and modeling anisotropic reflection. SIGGRAPH ’92: Proceedings of the 19th annual con" /><p class="c-article-references__text" id="ref-CR172">Ward GJ (1992) Measuring and modeling anisotropic reflection. SIGGRAPH ’92: Proceedings of the 19th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ward G (1994) The radiance lighting simulation and rendering system. In: SIGGRAPH ’94: proceedings of the 21st" /><p class="c-article-references__text" id="ref-CR173">Ward G (1994) The radiance lighting simulation and rendering system. In: SIGGRAPH ’94: proceedings of the 21st annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="B. Walter, S. Fernandez, A. Arbree, K. Bala, M. Donikian, DP. Greenberg, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Walter B, Fernandez S, Arbree A, Bala K, Donikian M, Greenberg DP (2005) Lightcuts: a scalable approach to ill" /><p class="c-article-references__text" id="ref-CR175">Walter B, Fernandez S, Arbree A, Bala K, Donikian M, Greenberg DP (2005) Lightcuts: a scalable approach to illumination. ACM Trans Graph 24(3):1098–1107</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 172 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Lightcuts%3A%20a%20scalable%20approach%20to%20illumination&amp;journal=ACM%20Trans%20Graph&amp;volume=24&amp;issue=3&amp;pages=1098-1107&amp;publication_year=2005&amp;author=Walter%2CB&amp;author=Fernandez%2CS&amp;author=Arbree%2CA&amp;author=Bala%2CK&amp;author=Donikian%2CM&amp;author=Greenberg%2CDP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Walter B, Arbree A, Bala K, Greenberg DP (2006) Multidimensional lightcuts. ACM Trans Graph" /><p class="c-article-references__text" id="ref-CR171">Walter B, Arbree A, Bala K, Greenberg DP (2006) Multidimensional lightcuts. ACM Trans Graph</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Wang O, Gunawardane P, Scher S, Davis J (2009) Material classification using BRDF slices. IEEE conference on c" /><p class="c-article-references__text" id="ref-CR176">Wang O, Gunawardane P, Scher S, Davis J (2009) Material classification using BRDF slices. IEEE conference on computer vision and pattern recognition</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Wald I, Mark WR, Günther J, Boulos S, Ize T, Hunt W, Parker SG, Shirley P (2007) State of the art in ray traci" /><p class="c-article-references__text" id="ref-CR178">Wald I, Mark WR, Günther J, Boulos S, Ize T, Hunt W, Parker SG, Shirley P (2007) State of the art in ray tracing animated scenes. Eurographics</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ward G, Shakespeare R (2003) Rendering with radiance: the art and science of lighting visualisation (Revised e" /><p class="c-article-references__text" id="ref-CR180">Ward G, Shakespeare R (2003) Rendering with radiance: the art and science of lighting visualisation (Revised edition). Morgan Kaufmann, San Francisco</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ward G, Rubinstein FM, Clear RD (1988) A ray tracing solution for diffuse inter-reflection. In: SIGGRAPH ’88: " /><p class="c-article-references__text" id="ref-CR179">Ward G, Rubinstein FM, Clear RD (1988) A ray tracing solution for diffuse inter-reflection. In: SIGGRAPH ’88: proceedings of the 15th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Wang R, Wang R, Zhou K, Pan M, Bao H (2009) An efficient gpu-based approach for interactive global illuminatio" /><p class="c-article-references__text" id="ref-CR181">Wang R, Wang R, Zhou K, Pan M, Bao H (2009) An efficient gpu-based approach for interactive global illumination. In: SIGGRAPH ’09: proceedings of the 36th annual conference on computer graphics and interactive techniques</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Weiss Y (2001) Deriving intrinsic images from image sequences. In: Proceeding IEEE international conference on" /><p class="c-article-references__text" id="ref-CR174">Weiss Y (2001) Deriving intrinsic images from image sequences. In: Proceeding IEEE international conference on computer vision ICCV</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Whitted, " /><meta itemprop="datePublished" content="1980" /><meta itemprop="headline" content="Whitted T (1980) An improved illumination model for shaded display. Commun ACM 23(6):343–349" /><p class="c-article-references__text" id="ref-CR177">Whitted T (1980) An improved illumination model for shaded display. Commun ACM 23(6):343–349</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 180 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20improved%20illumination%20model%20for%20shaded%20display&amp;journal=Commun%20ACM&amp;volume=23&amp;issue=6&amp;pages=343-349&amp;publication_year=1980&amp;author=Whitted%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Yoon KJ, Choi Y, Kweon IS (2006) Fast separation of reflection components using a specularity-invariant image " /><p class="c-article-references__text" id="ref-CR182">Yoon KJ, Choi Y, Kweon IS (2006) Fast separation of reflection components using a specularity-invariant image representation. In: IEEE international conference on image processing ICIP</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zányi E, Chrysanthou Y, Bashford-Rogers T, Chalmers A (2007a) High dynamic range display of authentically illu" /><p class="c-article-references__text" id="ref-CR183">Zányi E, Chrysanthou Y, Bashford-Rogers T, Chalmers A (2007a) High dynamic range display of authentically illuminated byzantine art from Cyprus. In: VAST ’07: proceedings of the symposium on virtual reality, archaeology and cultural heritage</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zányi E, Schroer C, Mudge MAC (2007b) Lighting and byzantine glass tesserae. In: Proceedings of the 2009 EVA L" /><p class="c-article-references__text" id="ref-CR184">Zányi E, Schroer C, Mudge MAC (2007b) Lighting and byzantine glass tesserae. In: Proceedings of the 2009 EVA London conference</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-010-0154-x-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgments</h2><div class="c-article-section__content" id="Ack1-content"><p>Images in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig1">1</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig15">15</a> courtesy of Paul Debevec (Debevec <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Debevec P (2001) Light probe image gallery. &#xA;                    http://www.debevec.org/probes/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR40" id="ref-link-section-d40580e3010">2001</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Debevec P (2005) Making ‘The Parthenon’. Invited paper: VAST ’05: International symposium on virtual reality, archaeology, and cultural heritage" href="/article/10.1007/s10055-010-0154-x#ref-CR43" id="ref-link-section-d40580e3013">2005</a>; Debevec et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Debevec P, Tchou C, Gardner A, Hawkins T, Poullis C, Stumpfel J, Jones A, Yun N, Einarsson P, Lundgren T, Fajardo M, Martinez P (2004) Estimating surface reflectance properties of a complex scene under captured natural illumination. In USC ICT technical report ICT-TR-06.2004" href="/article/10.1007/s10055-010-0154-x#ref-CR50" id="ref-link-section-d40580e3016">2004</a>). Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig3">3</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig4">4</a> courtesy of Oliver Wang, Prabath Gunawardane, and James Davis. Left image in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig8">8</a> courtesy of George Post (Egan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Egan F (1999) Fine bronze oil lamps. &#xA;                    http://www.eganbronze.com/Pages/lamps.html&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-010-0154-x#ref-CR56" id="ref-link-section-d40580e3029">1999</a>). Images in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig13">13</a> courtesy of Henrik Wann Jensen (Nguyen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Nguyen DQ, Fedkiw R, Jensen HW (2002) Physically based modeling and animation of fire. SIGGRAPH ’02: Proceedings of the 29th annual conference on computer graphics and interactive techniques" href="/article/10.1007/s10055-010-0154-x#ref-CR129" id="ref-link-section-d40580e3035">2002</a>). Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig12">12</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig14">14</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig20">20</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-010-0154-x#Fig24">24</a> courtesy of University of Bristol. Many thanks to Carla Schroer for her efforts and help in preperation for, and during our presentation of this survey at VAST 2009. We thank the anonymous reviewers of this survey for their comments, and to Graeme Earl for additional comments.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">International Digital Laboratory, University of Warwick, Coventry, UK</p><p class="c-article-author-affiliation__authors-list">Jassim Happa, Kurt Debattista &amp; Alan Chalmers</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Cultural Heritage Imaging, San Francisco, USA</p><p class="c-article-author-affiliation__authors-list">Mark Mudge</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">CASToRC Cyprus Institute, Nicosia, Cyprus</p><p class="c-article-author-affiliation__authors-list">Alessandro Artusi</p></li><li id="Aff4"><p class="c-article-author-affiliation__address">Research Center for Informatics and Communications, Polytechnic Institute of Leiria, Leiria, Portugal</p><p class="c-article-author-affiliation__authors-list">Alexandrino Gonçalves</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Jassim-Happa"><span class="c-article-authors-search__title u-h3 js-search-name">Jassim Happa</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Jassim+Happa&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jassim+Happa" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jassim+Happa%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Mark-Mudge"><span class="c-article-authors-search__title u-h3 js-search-name">Mark Mudge</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Mark+Mudge&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Mark+Mudge" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Mark+Mudge%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Kurt-Debattista"><span class="c-article-authors-search__title u-h3 js-search-name">Kurt Debattista</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Kurt+Debattista&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Kurt+Debattista" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Kurt+Debattista%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Alessandro-Artusi"><span class="c-article-authors-search__title u-h3 js-search-name">Alessandro Artusi</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Alessandro+Artusi&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Alessandro+Artusi" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Alessandro+Artusi%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Alexandrino-Gon_alves"><span class="c-article-authors-search__title u-h3 js-search-name">Alexandrino Gonçalves</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Alexandrino+Gon%C3%A7alves&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Alexandrino+Gon%C3%A7alves" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Alexandrino+Gon%C3%A7alves%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Alan-Chalmers"><span class="c-article-authors-search__title u-h3 js-search-name">Alan Chalmers</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Alan+Chalmers&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Alan+Chalmers" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Alan+Chalmers%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-010-0154-x/email/correspondent/c1/new">Jassim Happa</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Illuminating%20the%20past%3A%20state%20of%20the%20art&amp;author=Jassim%20Happa%20et%20al&amp;contentID=10.1007%2Fs10055-010-0154-x&amp;publication=1359-4338&amp;publicationDate=2010-02-20&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Happa, J., Mudge, M., Debattista, K. <i>et al.</i> Illuminating the past: state of the art.
                    <i>Virtual Reality</i> <b>14, </b>155–182 (2010). https://doi.org/10.1007/s10055-010-0154-x</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-010-0154-x.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2009-08-11">11 August 2009</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2010-01-21">21 January 2010</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2010-02-20">20 February 2010</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2010-09">September 2010</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-010-0154-x" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-010-0154-x</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Cultural heritage</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Computer graphics</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Image-processing</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Rendering</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Global illumination</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Reflectance transformation imaging</span></li><li class="c-article-subject-list__subject"><span itemprop="about">High dynamic range imaging</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Sky modelling</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Flame modelling</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Colour science</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Visual perception</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-010-0154-x.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=154;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

