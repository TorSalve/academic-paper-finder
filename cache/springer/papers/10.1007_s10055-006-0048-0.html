<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="The design and realization of CoViD: a system for collaborative virtua"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Many important decisions in the design process are made during fairly early on, after designers have presented initial concepts. In many domains, these concepts are already realized as 3D digital..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/10/2.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="The design and realization of CoViD: a system for collaborative virtual 3D design"/>

    <meta name="dc.source" content="Virtual Reality 2006 10:2"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2006-09-19"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2006 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Many important decisions in the design process are made during fairly early on, after designers have presented initial concepts. In many domains, these concepts are already realized as 3D digital models. Then, in a meeting, the stakeholders for the project get together and evaluate these potential solutions. Frequently, the participants in this meeting want to interactively modify the proposed 3D designs to explore the design space better. Today&#8217;s systems and tools do not support this, as computer systems typically support only a single user and computer-aided design tools require significant training. This paper presents the design of a new system to facilitate a collaborative 3D design process. First, we discuss a set of guidelines which have been introduced by others and that are relevant to collaborative 3D design systems. Then, we introduce the new system, which consists of two main parts. The first part is an easy-to-use conceptual 3D design tool that can be used productively even by naive users. The tool provides novel interaction techniques that support important properties of conceptual design. The user interface is non-obtrusive, easy-to-learn, and supports rapid creation and modification of 3D models. The second part is a novel infrastructure for collaborative work, which offers an interactive table and several large interactive displays in a semi-immersive setup. It is designed to support multiple users working together. This infrastructure also includes novel pointing devices that work both as a stylus and a remote pointing device. The combination of the (modified) design tool with the collaborative infrastructure forms a new platform for collaborative virtual 3D design. Then, we present an evaluation of the system against the guidelines for collaborative 3D design. Finally, we present results of a preliminary user study, which asked naive users to collaborate in a 3D design task on the new system."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2006-09-19"/>

    <meta name="prism.volume" content="10"/>

    <meta name="prism.number" content="2"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="135"/>

    <meta name="prism.endingPage" content="147"/>

    <meta name="prism.copyright" content="2006 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-006-0048-0"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-006-0048-0"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-006-0048-0.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-006-0048-0"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="The design and realization of CoViD: a system for collaborative virtual 3D design"/>

    <meta name="citation_volume" content="10"/>

    <meta name="citation_issue" content="2"/>

    <meta name="citation_publication_date" content="2006/10"/>

    <meta name="citation_online_date" content="2006/09/19"/>

    <meta name="citation_firstpage" content="135"/>

    <meta name="citation_lastpage" content="147"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-006-0048-0"/>

    <meta name="DOI" content="10.1007/s10055-006-0048-0"/>

    <meta name="citation_doi" content="10.1007/s10055-006-0048-0"/>

    <meta name="description" content="Many important decisions in the design process are made during fairly early on, after designers have presented initial concepts. In many domains, these con"/>

    <meta name="dc.creator" content="Wolfgang Stuerzlinger"/>

    <meta name="dc.creator" content="Loutfouz Zaman"/>

    <meta name="dc.creator" content="Andriy Pavlovych"/>

    <meta name="dc.creator" content="Ji-Young Oh"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Deisinger J, Blach R, Wesche G, Breining R, Simon A (2000) Towards immersive modeling - challenges and recommendations: a workshop analyzing the needs of designers, Virtual environments, Springer, Berlin Heidelberg New York, pp 145&#8211;156"/>

    <meta name="citation_reference" content="citation_journal_title=Conf ACM CHI; citation_title=KidPad: a design collaboration between children, technologists, and educators; citation_author=A Druin, J Stewart, D Proft, B Bederson, J Hollan; citation_volume=97; citation_publication_date=1997; citation_pages=463-470; citation_id=CR2"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph; citation_title=Drawing on the back of envelope: a framework for interacting with application programs by freehand drawing; citation_author=M Gross, E Do; citation_volume=24; citation_publication_date=2000; citation_pages=835-849; citation_doi=10.1016/S0097-8493(00)00087-X; citation_id=CR3"/>

    <meta name="citation_reference" content="Gross M (2001) Emergence in a recognition based drawing interface. Conf Vis Spatial Reason, 51&#8211;65"/>

    <meta name="citation_reference" content="Igarashi T, Matsuoka S, Tanaka H (1999) Teddy: a sketching interface for 3D freeform design. Conf ACM SIGGRAPH&#8217;99, 409&#8211;416"/>

    <meta name="citation_reference" content="Oh J-Y (2005) Desktop 3D conceptual design systems. PhD Thesis, York University"/>

    <meta name="citation_reference" content="Oh J-Y, Stuerzlinger W (2005) Moving objects with 2D input devices in CAD systems and desktop virtual environments. Conf Graphics Interface, 141&#8211;149"/>

    <meta name="citation_reference" content="Oh J-Y, Stuerzlinger W, Danahy J (2005) Comparing SESAME and sketching for conceptual 3D design. Workshop EG Sketch Based Interfaces Modeling, 81&#8211;88"/>

    <meta name="citation_reference" content="Oh J-Y, Stuerzlinger W, Dadgari D (2006a) Group selection techniques for efficient 3D modeling. IEEE Symp 3D User Interfaces, 95&#8211;102 "/>

    <meta name="citation_reference" content="Oh J-Y, Stuerzlinger W, Danahy J (2006b) SESAME: towards better 3D conceptual design systems. Conf ACM Dis, 80&#8211;89"/>

    <meta name="citation_reference" content="Pavlovych A, Stuerzlinger W (2004) Laser pointers as interaction devices for collaborative pervasive computing. Adv Pervasive Comput, 315&#8211;320. ISBN 385403176-9"/>

    <meta name="citation_reference" content="Ryall K, Forlines C, Shen C, Morris M (2004) Exploring the effects of group size and table size on interactions with tabletop shared-display groupware. Conf ACM CSCW, 284&#8211;293"/>

    <meta name="citation_reference" content="Scott S, Grant K, Mandryk R (2003) System guidelines for co-located, collaborative work on a tabletop display. Conf ECSCW, Springer, Berlin Heidelberg New York, pp 159&#8211;178.
                    http://www.springer.com/east/home/generic/search/results?SGWID=5-40109-22-33658793-0
                    
                  
                "/>

    <meta name="citation_reference" content="Shu L, Flowers W (1992) Groupware experiences in three-dimensional computer-aided design. CSCW, 179&#8211;186"/>

    <meta name="citation_reference" content="Stewart J, Bederson B, Druin A (1999) A model for co-present collaboration. Conf ACM CHI, 286&#8211;293"/>

    <meta name="citation_reference" content="Tano S, Kodera T, Nakashima T, Kawano I, Nakanishi K, Hamagishi G, Inoue M, Watanabe A, Okamoto T, Kawagoe K, Kaneko K, Hotta T, Tatsuoka M (2003) Godzilla: seamless 2D and 3D sketch environment for reflective and creative design work. IFIP INTERACT&#8217;03, 311&#8211;318"/>

    <meta name="citation_reference" content="Tse E, Greenberg S (2004) Rapidly prototyping single display groupware through the SDGToolkit. Australasian User Interface Conf, 101&#8211;110"/>

    <meta name="citation_reference" content="Zeleznik R, Herndon K, Hughes J (1996) SKETCH: an interface for sketching 3D scenes. Conf ACM SIGGRAPH&#8217;96, 163&#8211;170"/>

    <meta name="citation_author" content="Wolfgang Stuerzlinger"/>

    <meta name="citation_author_institution" content="York University, Toronto, Canada"/>

    <meta name="citation_author" content="Loutfouz Zaman"/>

    <meta name="citation_author_institution" content="York University, Toronto, Canada"/>

    <meta name="citation_author" content="Andriy Pavlovych"/>

    <meta name="citation_author_institution" content="York University, Toronto, Canada"/>

    <meta name="citation_author" content="Ji-Young Oh"/>

    <meta name="citation_author_email" content="jyoh@optics.arizona.edu"/>

    <meta name="citation_author_institution" content="University of Arizona, Tucson, USA"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-006-0048-0&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2006/10/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-006-0048-0"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="The design and realization of CoViD: a system for collaborative virtual 3D design"/>
        <meta property="og:description" content="Many important decisions in the design process are made during fairly early on, after designers have presented initial concepts. In many domains, these concepts are already realized as 3D digital models. Then, in a meeting, the stakeholders for the project get together and evaluate these potential solutions. Frequently, the participants in this meeting want to interactively modify the proposed 3D designs to explore the design space better. Today’s systems and tools do not support this, as computer systems typically support only a single user and computer-aided design tools require significant training. This paper presents the design of a new system to facilitate a collaborative 3D design process. First, we discuss a set of guidelines which have been introduced by others and that are relevant to collaborative 3D design systems. Then, we introduce the new system, which consists of two main parts. The first part is an easy-to-use conceptual 3D design tool that can be used productively even by naive users. The tool provides novel interaction techniques that support important properties of conceptual design. The user interface is non-obtrusive, easy-to-learn, and supports rapid creation and modification of 3D models. The second part is a novel infrastructure for collaborative work, which offers an interactive table and several large interactive displays in a semi-immersive setup. It is designed to support multiple users working together. This infrastructure also includes novel pointing devices that work both as a stylus and a remote pointing device. The combination of the (modified) design tool with the collaborative infrastructure forms a new platform for collaborative virtual 3D design. Then, we present an evaluation of the system against the guidelines for collaborative 3D design. Finally, we present results of a preliminary user study, which asked naive users to collaborate in a 3D design task on the new system."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>The design and realization of CoViD: a system for collaborative virtual 3D design | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-006-0048-0","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Collaborative design, 3D design, Collaborative virtual reality","kwrd":["Collaborative_design","3D_design","Collaborative_virtual_reality"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-006-0048-0","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-006-0048-0","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=48;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-006-0048-0">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            The design and realization of CoViD: a system for collaborative virtual 3D design
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-006-0048-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-006-0048-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2006-09-19" itemprop="datePublished">19 September 2006</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">The design and realization of CoViD: a system for collaborative virtual 3D design</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Wolfgang-Stuerzlinger" data-author-popup="auth-Wolfgang-Stuerzlinger" data-corresp-id="c1">Wolfgang Stuerzlinger<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="York University" /><meta itemprop="address" content="grid.21100.32, 0000000419369430, York University, Toronto, Canada" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Loutfouz-Zaman" data-author-popup="auth-Loutfouz-Zaman">Loutfouz Zaman</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="York University" /><meta itemprop="address" content="grid.21100.32, 0000000419369430, York University, Toronto, Canada" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Andriy-Pavlovych" data-author-popup="auth-Andriy-Pavlovych">Andriy Pavlovych</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="York University" /><meta itemprop="address" content="grid.21100.32, 0000000419369430, York University, Toronto, Canada" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Ji_Young-Oh" data-author-popup="auth-Ji_Young-Oh">Ji-Young Oh</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Arizona" /><meta itemprop="address" content="grid.134563.6, 000000012168186X, University of Arizona, Tucson, AZ, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 10</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">135</span>–<span itemprop="pageEnd">147</span>(<span data-test="article-publication-year">2006</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">533 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">5 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-006-0048-0/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Many important decisions in the design process are made during fairly early on, after designers have presented initial concepts. In many domains, these concepts are already realized as 3D digital models. Then, in a meeting, the stakeholders for the project get together and evaluate these potential solutions. Frequently, the participants in this meeting want to interactively modify the proposed 3D designs to explore the design space better. Today’s systems and tools do not support this, as computer systems typically support only a single user and computer-aided design tools require significant training. This paper presents the design of a new system to facilitate a collaborative 3D design process. First, we discuss a set of guidelines which have been introduced by others and that are relevant to collaborative 3D design systems. Then, we introduce the new system, which consists of two main parts. The first part is an easy-to-use conceptual 3D design tool that can be used productively even by naive users. The tool provides novel interaction techniques that support important properties of conceptual design. The user interface is non-obtrusive, easy-to-learn, and supports rapid creation and modification of 3D models. The second part is a novel infrastructure for collaborative work, which offers an interactive table and several large interactive displays in a semi-immersive setup. It is designed to support multiple users working together. This infrastructure also includes novel pointing devices that work both as a stylus and a remote pointing device. The combination of the (modified) design tool with the collaborative infrastructure forms a new platform for collaborative virtual 3D design. Then, we present an evaluation of the system against the guidelines for collaborative 3D design. Finally, we present results of a preliminary user study, which asked naive users to collaborate in a 3D design task on the new system.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Today, digital 3D models are critical in many domains, such as architecture and urban planning, all kinds of industrial design, the entertainment industry, and many engineering applications. Many of the important decisions surrounding a design are made in the initial phases, after the designer(s) have proposed a first version of the design. There, typically in a meeting, the stakeholders in the project get together and evaluate these potential solutions. Frequently, the participants in this meeting want to interactively modify the proposed designs to explore the design space better. Today’s design tools and computer infrastructure do not support such activities well, as computer systems typically support only a single user and computer-aided design tools require significant training.</p><p>Traditional tools for 3D design require a large amount of training. Part of this is based on the fact that they offer a large number of functions to support every possible 3D design activity. Another issue is that traditional 3D design tools expose the technical foundations of computer graphics directly to the user. The problem is that, without training, most people cannot easily understand the visualization of 3D objects in multiple orthogonal views or do not understand the intricacies of hierarchical 3D transformations.</p><p>One common solution to offer multiple users access to a computer system is to use one (or more) large display, typically via projection. However, most large display systems allow for only one <i>active</i> user at any given time, even if multiple physical screens are available! The reason behind this is that most software packages and graphical user interface toolkits can only handle input from a single user. This leads to the “driver” problem, i.e. that one person controls the content and collaboration of the meeting—usually the person who is most adept in controlling the system, which may not be the person best suited to edit a design.</p><p>This paper introduces a new system that aims to make the collaborative 3D design process more productive. The factors mentioned above currently render 3D design a sub-optimal and time-consuming process. To illustrate the potential gains, we present the following scenario: imagine a family who wishes to redesign their living room with the help of a professional interior designer. Traditionally, and after an initial consultation, this designer came up with several concept designs and presented them to the family. The family picks one (or two) designs and proposes some modifications to adapt the design to their needs. Several days later, they meet again over a more refined version of the designs, which addresses the needs of the family better. As the designer may have not have addressed all concerns fully, this process is usually iterated a few times. Also, in this process, auxiliary information, such as furniture catalogues and images of other living rooms are consulted. At last, a final design is chosen and the designer elaborates it further so that other people can build the desired living room configuration.</p><p>With a collaborative 3D design system, this process could work as follows: after the initial consultation, the designer brings digital versions of several concept designs to the meeting with the family. All participants sit around a fully interactive system, which allows each of them to directly modify the digital model of the initial concepts. While the technical system may support fully simultaneous operations, the normal social protocols encourage the members of the family to take turns and to work constructively with the designer. Auxiliary information is displayed on a secondary screen, typically by browsing an on-line catalogue or digital images. Based on the direct visualization of the 3D design, the family and the designer quickly agree on one alternative. Then the designer again elaborates on the final 3D design and passes it on to others.</p><p>As this example highlights, the possibility to quickly manipulate a 3D digital model in a collaborative setting enables a much more rapid design process. This paper presents a system that targets this scenario.</p><h3 class="c-article__sub-heading" id="Sec2">Related work</h3><p>Due to space restrictions we cannot give here a complete overview of all work in all relevant areas. Hence, we point to publications that provide good overviews of related work and discuss only the most relevant pieces of work.</p><p>There are many approaches to 3D design. Most of them can be categorized into traditional 3D computer-aided design systems, sketch reconstruction systems, gesture-based systems, voxel-based systems, virtual reality systems, and systems that are targeted at naïve users. A recent overview of most of these areas can be found in Oh (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Oh J-Y (2005) Desktop 3D conceptual design systems. PhD Thesis, York University" href="/article/10.1007/s10055-006-0048-0#ref-CR6" id="ref-link-section-d78109e361">2005</a>).</p><p>As the computer skills of participants in collaborative work often varies substantially, most systems that require that the user has a good understanding of 3D geometry cannot be used. Similarly, systems that suffer from various limitations of today’s recognition, 3D display, or 3D tracking technologies are also a bad choice as user frustration is quickly fatal for collaboration. This leaves only easy-to-use 3D design systems as a viable choice for collaborative design.</p><p>SKETCH (Zeleznik et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Zeleznik R, Herndon K, Hughes J (1996) SKETCH: an interface for sketching 3D scenes. Conf ACM SIGGRAPH’96, 163–170" href="/article/10.1007/s10055-006-0048-0#ref-CR18" id="ref-link-section-d78109e369">1996</a>) is one of the most prominent examples, but it still necessitates the user to learn a predefined set of gestures. Teddy (Igarashi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Igarashi T, Matsuoka S, Tanaka H (1999) Teddy: a sketching interface for 3D freeform design. Conf ACM SIGGRAPH’99, 409–416" href="/article/10.1007/s10055-006-0048-0#ref-CR5" id="ref-link-section-d78109e372">1999</a>) is a system limited to the design of free-form humanoid and animalistic shapes, but it has been shown to be usable even by children. Sketchup by @Last Software (<a href="http://www.sketchup.com">http://www.sketchup.com</a>) is an effective commercial tool for 3D design, which uses extrusion as the main way to create 3D objects. Another system that was developed at the same times and shares some of it’s features is SESAME (sketch, extrude, sculpt, and manipulate easily) (Oh et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Oh J-Y, Stuerzlinger W, Danahy J (2005) Comparing SESAME and sketching for conceptual 3D design. Workshop EG Sketch Based Interfaces Modeling, 81–88" href="/article/10.1007/s10055-006-0048-0#ref-CR8" id="ref-link-section-d78109e382">2005</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006a" title="Oh J-Y, Stuerzlinger W, Dadgari D (2006a) Group selection techniques for efficient 3D modeling. IEEE Symp 3D User Interfaces, 95–102 " href="/article/10.1007/s10055-006-0048-0#ref-CR9" id="ref-link-section-d78109e385">2006a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Oh J-Y, Stuerzlinger W, Danahy J (2006b) SESAME: towards better 3D conceptual design systems. Conf ACM Dis, 80–89" href="/article/10.1007/s10055-006-0048-0#ref-CR10" id="ref-link-section-d78109e389">b</a>; Oh <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Oh J-Y (2005) Desktop 3D conceptual design systems. PhD Thesis, York University" href="/article/10.1007/s10055-006-0048-0#ref-CR6" id="ref-link-section-d78109e392">2005</a>), a solid-modeling conceptual design tool that allows even naïve users to quickly create 3D designs. SESAME is one of the main components of collaborative virtual 3D design CoViD (a system for collaborative virtual three-dimensional design) and will be discussed in detail later.</p><p>Collaborative systems have been studied in the computer supported collaborative work (CSCW) and groupware literature for many years. While distributed collaborative systems are available, we point out that face-to-face interaction is very valuable for collaboration. This is especially true for the decision making-process as people are usually reluctant to negotiate important issues over the distance. Hence, this system focuses on collaboration between people in a single location in a form of meeting. As such meetings typically take place around a table, we focus on systems that include some form of interactive tabletop system.</p><p>Standard computer systems are designed to support interaction with only one user at a time. If more users want to use the system, they must take turns. This limitation motivated researchers to come up with various kinds of groupware systems allowing multiple users to perform tasks simultaneously on one (or more) display. This is commonly referred to as Single Display Groupware (Stewart et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Stewart J, Bederson B, Druin A (1999) A model for co-present collaboration. Conf ACM CHI, 286–293" href="/article/10.1007/s10055-006-0048-0#ref-CR15" id="ref-link-section-d78109e401">1999</a>) or Shared Display Groupware (SDG). The main issues here are that SDG hardware needs to support multiple input devices and that the software running on the SDG hardware needs to support (potentially simultaneous) input from multiple users correctly. An overview over recent work in tabletop SDG systems can be found in Scott et al<i>.</i>’s review of the area (Scott et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Scott S, Grant K, Mandryk R (2003) System guidelines for co-located, collaborative work on a tabletop display. Conf ECSCW, Springer, Berlin Heidelberg New York, pp 159–178.&#xA;                    http://www.springer.com/east/home/generic/search/results?SGWID=5-40109-22-33658793-0&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-006-0048-0#ref-CR13" id="ref-link-section-d78109e407">2003</a>).</p><p>Finally, there has been some previous work in collaborative 3D design. One of the earliest was the Teledesign system (Shu and Flowers <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Shu L, Flowers W (1992) Groupware experiences in three-dimensional computer-aided design. CSCW, 179–186" href="/article/10.1007/s10055-006-0048-0#ref-CR14" id="ref-link-section-d78109e413">1992</a>), but there each user sat in front of their own display. A collaborative SDG 2D design system had been previously been explored by Tse and Greenberg (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Tse E, Greenberg S (2004) Rapidly prototyping single display groupware through the SDGToolkit. Australasian User Interface Conf, 101–110" href="/article/10.1007/s10055-006-0048-0#ref-CR17" id="ref-link-section-d78109e416">2004</a>) and Kidpad explored a collaborative environment for kids, where multiple children could simultaneously draw on one display (Druin et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Druin A, Stewart J, Proft D, Bederson B, Hollan J (1997) KidPad: a design collaboration between children, technologists, and educators. Conf ACM CHI 97:463–470" href="/article/10.1007/s10055-006-0048-0#ref-CR2" id="ref-link-section-d78109e419">1997</a>).</p><h3 class="c-article__sub-heading" id="Sec3">Guidelines for collaborative design systems</h3><p>Previous work in 3D design as well as collaborative systems has resulted in a set of guidelines that enumerate desirable criteria for such systems. The first part of this section lists a set of guidelines for the design process, which are based on a review of the design research literature (Oh et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Oh J-Y, Stuerzlinger W, Danahy J (2005) Comparing SESAME and sketching for conceptual 3D design. Workshop EG Sketch Based Interfaces Modeling, 81–88" href="/article/10.1007/s10055-006-0048-0#ref-CR8" id="ref-link-section-d78109e430">2005</a>), which also contains more details.</p><ul class="u-list-style-bullet">
                    <li>
                      <p>
                        <i>Non</i>
                        <i>-intrusive interface: </i>One of the reasons that designers sketch is due to the complexity of design problems and the fact that mental resources are limited. Therefore, designers sketch to externalize their vague ideas in their mental imagery and to visually evaluate them. Hence, the cognitive demand for using computer tools should be minimal so that the designers can fully commit themselves to solve the design problem rather than worrying about the tool interface.</p>
                    </li>
                    <li>
                      <p>
                        <i>Easy creation: </i>The design process is dialectic and cyclic. Solutions are repetitively created or refined while (mentally) testing them against the desired criteria. This means that the cost to visualize a solution should be minimal. Therefore, any computer tool has to provide efficient ways to create design solutions quickly.</p>
                    </li>
                    <li>
                      <p>
                        <i>Easy combination and restructuring: </i>The recognition of individual parts and their relationships aid a human in the interpretation of a whole object. In the context of design, researchers observed that the combination and restructuring of parts are the main activities in creative invention. Furthermore, combination is a simple mental activity, while restructuring requires the aid of externalizations. Therefore, the user must be able to combine components of objects easily as well as to be able to restructure the result of a combination.</p>
                    </li>
                    <li>
                      <p>
                        <i>Tolerance to ambiguity and incompleteness: </i>Although design decisions are not well formed in the conceptual design phase, designers can still express their ideas via sketching, and the visuals naturally exhibit the ambiguity and incompleteness of these ideas. Hence, computer tools should not always expect precise input from users, and provide a way to externalize ambiguous forms. In addition, the visual output has to reflect the tentativeness of a solution, so that the designers can easily identify newly created problems or defects from intermediate forms.</p>
                    </li>
                    <li>
                      <p>
                        <i>Range of levels of abstraction: </i>There is a range of levels of abstraction that designers commonly move within, since they can only deal with a limited set of problems at any instant. Experienced designers tend to shift more fluently between overall and detailed aspects of design. This range may vary between different design disciplines (architect vs. door designer) and any computer tool has to match to the range of detail that a designer works with.</p>
                    </li>
                    <li>
                      <p>
                        <i>Ability to edit various forms of information: </i>The representations used in the design process are not only geometric shapes, but also different free-form strokes that stand for size, ratio, or trajectory. By putting figural and conceptual information together, a designer can reflect on different dimensions of a design problem at once. Therefore, the goal of sketching is to organize the problem/solution via different kinds of symbolic representations in the course of producing a final geometric shape. Many tools overlook this factor by focusing overly on various geometric representations.</p>
                    </li>
                    <li>
                      <p>
                        <i>Supporting evaluation (simulation): </i>Designers explore a solution/problem space by generating many solutions and testing them, asking ‘what if’. Sketching visualizes a situation on paper, and designers perform simulation of the situation in their mind. On the other hand, computer tools can conduct the simulation directly, instead of the designers. This should be beneficial, if the system can support spontaneous creation, modification, and re-simulation. However, simulation is closely task-specific, so one cannot count this as a criterion to judge computer tools for the design process.</p>
                    </li>
                  </ul><p>In the second part of this section we list a set of guidelines for collaborative work. Scott et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Scott S, Grant K, Mandryk R (2003) System guidelines for co-located, collaborative work on a tabletop display. Conf ECSCW, Springer, Berlin Heidelberg New York, pp 159–178.&#xA;                    http://www.springer.com/east/home/generic/search/results?SGWID=5-40109-22-33658793-0&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-006-0048-0#ref-CR13" id="ref-link-section-d78109e503">2003</a>) created a list of guidelines for tabletop displays, which is summarized here. For details and references please consult the original article:</p><ul class="u-list-style-bullet">
                    <li>
                      <p>
                        <i>Natural </i>
                        <i>interpersonal interaction: </i>Collaboration works only when people can communicate effectively. Any breakdown in communication (be it due to technical problems, technical limitations, etc.) has strong adverse effects on the ability of people to achieve work together.</p>
                    </li>
                    <li>
                      <p>
                        <i>Transitions between activities: </i>Many tasks require that users can seamlessly and quickly switch between various activities. For example, it may be necessary to switch between various drawing modes, keyboard entry, different software tools (e.g. design tool, WWW browser, spreadsheet), and different forms of collaboration (presentation, collaborative work, decision making, etc.).</p>
                    </li>
                    <li>
                      <p>
                        <i>Transitions between personal and group work: </i>In collaborative work, people transition fluently between individual and group work. The support of a “personal space” for every participant is important to facilitate experimentation. This can be accomplished via external devices (i.e. a portable computer for each person) or by “partitioning” a large display surface appropriately.</p>
                    </li>
                    <li>
                      <p>
                        <i>Transition between tabletop collaboration and external work: </i>Collaborative work often involves the integration of independently developed pieces into the larger work as well as the reverse. Furthermore, it needs to be simple to transfer content that was externally developed or modified into a system and out of it.</p>
                    </li>
                    <li>
                      <p>
                        <i>The use of physical objects: </i>Table surfaces provide a convenient location to place objects such as laptops, notebooks, printouts, and even non-task-related objects (cell phones, etc.). Any good tabletop infrastructure should not block this kind of usage. Furthermore, the idea of tangible user interfaces has been introduced. Here special objects tracked by the infrastructure are used as input devices (e.g. the use of a model house to specify the location of a building in the design).</p>
                    </li>
                    <li>
                      <p>
                        <i>Accessing shared physical and digital objects: </i>As participants are typically placed around a table in a meeting, shared access to the artifacts becomes a necessity. For physical objects, this is less of a problem as people are used to sharing objects on a table surface and can easily decode pointing gestures toward them. For shared digital objects this can be more of a problem, when objects are duplicated for each user, and it is usually simpler to have a single visualization accessible to everyone. Furthermore, the orientation of each object may pose problems on a tabletop surface—e.g. it is hard to read and interact with upside down text. Finally, a user of the infrastructure should not be able to block the display for another user (e.g. with the shadow of their hand).</p>
                    </li>
                    <li>
                      <p>
                        <i>Flexible user arrangements: </i>Users may want to sit or stand in many configurations around a table, depending on the type of collaboration (decision making, presentation, collaborative work, ...), the interpersonal relations between participants, and the properties of the task at hand. A tabletop infrastructure should support all these and allow for fluent transitions between various forms of arrangements.</p>
                    </li>
                    <li>
                      <p>
                        <i>Simultaneous user interactions: </i>When multiple people engage in tabletop activities, they often and naturally interact with artifacts on the table surface simultaneously. Many traditional computing platforms support only one input device and hence force users to take turns. This leads to a style of interaction where a single person “drives” at a time, which is hinders fluid collaboration. Supporting multiple users simultaneously is both a hardware and a software issue. For the hardware side, the infrastructure needs to be able to reliably track and distinguish between individual interaction devices with imperceptible latency. For the software side, the infrastructure needs to support multiple concurrent actions (potentially even with different applications simultaneously).</p>
                    </li>
                  </ul>
                </div></div></section><section aria-labelledby="Sec4"><div class="c-article-section" id="Sec4-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec4">CoViD—a system for collaborative virtual 3D design</h2><div class="c-article-section__content" id="Sec4-content"><p>The CoViD system consists of two main parts—the SESAME conceptual design tool and the MULTI collaborative setup. To simplify the discussion, we first discuss the single-user version of SESAME, then the MULTI platform, and finally how both components work together in CoViD.</p><h3 class="c-article__sub-heading" id="Sec5">Sketch, extrude, sculpt, and manipulate easily (SESAME)</h3><p>SESAME was designed to be a simple-to-use 3D design tool for 3D design. It is an ideal tool in the context of CoViD, as in any collaborative setting the computer skills of the participants will vary wildly.</p><p>The user interface of (the single-user version of) SESAME consists of a main 3D scene view and a menu panel on the right side. The menu offers a color/texture palette (top right), a 2D and 3D primitive shape selection palette (left part of menu panel), an undo button (at the bottom of the 3D palette), a navigation mode switch button, and a recycle bin (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0048-0#Fig1">1</a>). The 2D palette consists of common 2D tools such as lines and arcs, and a freeform drawing tool. The 3D palette provides a tool to move objects in 3D and the instantiation of primitive 3D shapes, such as boxes, triangular prisms, spheres, and cylinders.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0048-0/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0048-0/MediaObjects/10055_2006_48_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0048-0/MediaObjects/10055_2006_48_Fig1_HTML.jpg" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>SESAME user interface</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0048-0/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>The user interface utilizes only a three-button mouse and a few modifier keys. All actions such as sketching a contour or moving objects can be accomplished with them. From a high level, the tool has two main modes: 2D and 3D, each of which is activated once any tool from the corresponding palette is selected. However, there are several operations that are available in both modes. An overview of the mouse function assignments is shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-006-0048-0#Tab1">1</a>.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Mouse and keyboard commands</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-006-0048-0/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Cloning provides a powerful way to create repetitive patterns in combination with the grouping technique explained below. It is implemented as a (continuous) dragging action. That is, once a user drags the selected source object more than certain distance, a cloned object is instantiated. The cloned object will continue to move in the scene, until the user places it on the target position by releasing the mouse.</p><p>Additionally, SESAME provides a simple navigation interface so that users can assess the 3D structure of the scene rapidly. Camera rotation, pan, and zoom are accessible through middle mouse button dragging, shift-dragging, and scrolling, respectively.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec6">Improved tools for 3D design</h4><p>Beyond the basic actions listed above, SESAME provides also several advanced facilities for the rapid creation of 3D content.</p><p>With the 2D drawing tools the user can draw lines, arcs, or free-form curves onto any planar surface. As the user draws these in a 3D perspective view, SESAME displays a perspectively distorted circle during 2D drawing operations to help the user perceive the orientation of the current drawing plane. That is, in addition to visualizing the current line with the well-known rubber band technique, a circle is displayed with the origin at the start of the line and a radius proportional to the current length of the line (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0048-0#Fig2">2</a>).
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0048-0/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0048-0/MediaObjects/10055_2006_48_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0048-0/MediaObjects/10055_2006_48_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>A <i>circle</i> is used to visualize the orientation of the current plane in SESAME. The user is currently drawing line <i>a</i>. Additionally, multiple colored guides are displayed based on other connected lines (<i>b</i> and <i>c</i>). The <i>yellow line</i> is perpendicular to <i>b</i>, the <i>purple line</i> is parallel to <i>c</i>, and the <i>straight white lines</i> are parallel to the coordinate axes</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0048-0/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <p>Furthermore, multiple guides are displayed as well. These include guides parallel to the coordinate axes, as well as suggestions for lines that are perpendicular and parallel to other parts of the 2D drawing. The cursor snaps to these suggestions to aid the construction of common configurations. To avoid overloading the user, the SESAME displays only suggested completions that are close to the cursor.</p><p>Whenever the user adds any 2D shape, SESAME analyzes the current drawing and detects all closed contours created by the added shape. This also allows the user to subdivide existing closed contours by drawing other shapes over it. This effectively accommodates the creation of emergent shapes as these have been shown to facilitate creative thinking during the design process (Gross and Do <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Gross M, Do E (2000) Drawing on the back of envelope: a framework for interacting with application programs by freehand drawing. Comput Graph 24:835–849" href="/article/10.1007/s10055-006-0048-0#ref-CR3" id="ref-link-section-d78109e978">2000</a>; Gross <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Gross M (2001) Emergence in a recognition based drawing interface. Conf Vis Spatial Reason, 51–65" href="/article/10.1007/s10055-006-0048-0#ref-CR4" id="ref-link-section-d78109e981">2001</a>). The user can then extrude any closed contour by clicking with the right mouse button inside the contour and dragging. For this, the height of the extrusion is proportional to the length of the drag, i.e. the top surface of the extrusion follows the cursor. A drag operation outward relative to existing 3D geometry will extrude a new volume (or resize an existing volume), while a drag inward will sculpt the volume, i.e. can be used to create holes. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0048-0#Fig3">3</a> illustrates the technique.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0048-0/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0048-0/MediaObjects/10055_2006_48_Fig3_HTML.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0048-0/MediaObjects/10055_2006_48_Fig3_HTML.jpg" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Sketching interface. <b>a</b>, <b>b</b> Dragging outward from a closed contour creates a volume. <b>c</b>, <b>d</b> Drawing a contour on a face and dragging inward sculpts the volume. <b>d</b>, <b>e</b> The user creates a new shape by dragging outward. <b>e</b>, <b>f</b> The user can also “stretch” an object by dragging the face directly. (<i>Red lines</i> added to visualize drag operations)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0048-0/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <p>SESAME also provides a technique to let the user grab any object and slide it across the scene to the desired position to visually assess the impact of a change. One of the main motivations behind this is that this will greatly facilitate exploration. As almost all objects in the real world are attached to other objects, we based the design of our interaction technique on the idea that, unless special actions are taken, objects should <i>always</i> stay connected with another part of the scene and should not interpenetrate other objects. This conforms better to the way most people think about the real world. In contrast to other techniques, SESAME includes a novel technique that uses the entire area of the visual overlap of a foreground object with the (potentially complex) background, as this has been shown to work very well for 3D object manipulation (Oh and Stuerzlinger <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Oh J-Y, Stuerzlinger W (2005) Moving objects with 2D input devices in CAD systems and desktop virtual environments. Conf Graphics Interface, 141–149" href="/article/10.1007/s10055-006-0048-0#ref-CR7" id="ref-link-section-d78109e1041">2005</a>). An evaluation showed that this new technique is significantly more efficient for novice users and showed that our technique conforms very well to users’ expectation about the position of objects relative to a scene.</p><p>Finally, SESAME also provides support for the selection of groups of objects. For this, the tool analyzes the scene and detects which objects are placed on top of another, as such objects will move with the base object in the real world. The implementation then simply selects objects on top of a base object whenever the base is selected (e.g. with clicking or rectangle selection). This turns out to greatly facilitate the manipulation of common scene configurations (Oh et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006a" title="Oh J-Y, Stuerzlinger W, Dadgari D (2006a) Group selection techniques for efficient 3D modeling. IEEE Symp 3D User Interfaces, 95–102 " href="/article/10.1007/s10055-006-0048-0#ref-CR9" id="ref-link-section-d78109e1047">2006a</a>). Lastly, a multi-click scheme, similar to character, word and paragraph selection in MS Word, cycles through an object with all objects it supports, the group consisting of all touching objects, and the object itself. Together, these selection techniques make restructuring and combinations of many 3D scenes easier.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec7">Evaluation of SESAME</h4><p>Traditional computer design tools are targeted toward the final stages of design. Senior designers have commented, “recent designs are very beautiful due to the (use of a computer) design tool, but they are very poor, far from the design ideal” (Tano et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Tano S, Kodera T, Nakashima T, Kawano I, Nakanishi K, Hamagishi G, Inoue M, Watanabe A, Okamoto T, Kawagoe K, Kaneko K, Hotta T, Tatsuoka M (2003) Godzilla: seamless 2D and 3D sketch environment for reflective and creative design work. IFIP INTERACT’03, 311–318" href="/article/10.1007/s10055-006-0048-0#ref-CR16" id="ref-link-section-d78109e1058">2003</a>). This means that while all details are perfect, the users of current design tools often do not adequately explore the space of all possible design solutions.</p><p>SESAME was previously evaluated to analyze its suitability as a design tool. A comparison with sketching with pen and paper revealed that SESAME yields the same level of design quality as judged by an expert designer (Oh et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Oh J-Y, Stuerzlinger W, Danahy J (2005) Comparing SESAME and sketching for conceptual 3D design. Workshop EG Sketch Based Interfaces Modeling, 81–88" href="/article/10.1007/s10055-006-0048-0#ref-CR8" id="ref-link-section-d78109e1064">2005</a>). Another comparison with users of 3D Studio Max demonstrated that even first-time users of SESAME could generate meaningful designs faster with this tool than traditional CAD systems (Oh et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006b" title="Oh J-Y, Stuerzlinger W, Danahy J (2006b) SESAME: towards better 3D conceptual design systems. Conf ACM Dis, 80–89" href="/article/10.1007/s10055-006-0048-0#ref-CR10" id="ref-link-section-d78109e1067">2006b</a>). Also, studies with naïve users (i.e. people who had never used 3D design systems before) showed that most people quickly understand how SESAME works and are rapidly able to use it to create 3D designs.</p><p>SESAME, as described, is capable of creating mainly prismatic objects, i.e. everything that can be modeled by extrusions. This limits the application domain to engineering domains, interior design, as well as architecture. Current work on SESAME aims to add support for rotationally symmetric objects as well as freeform modeling tools.</p><h3 class="c-article__sub-heading" id="Sec8">Multi-user laser table interface (MULTI)</h3><p>In general, the stakeholders in a design project make important high-level decisions in a meeting. However, for effective collaboration, the participants in such a meeting need to be able to see a visualization of the current design proposal(s). If this visualization is interactive, the participants will in general be able to reach better decisions, as they can explore the design space more completely.</p><p>However, 3D design activities frequently require large displays, as they make it simpler to assess the impact of a proposed design. Another factor is that screen space is often limited in many situations, especially when multiple proposals are evaluated simultaneously. Furthermore, in collaborative meetings, there is always secondary information that is critical to the task, but not represented on the main visual display. Often this information is available in printouts, but this is clearly not a very interactive medium. Another alternative is various kinds other mobile devices, but all of these are essentially single-user devices and are often poor platforms for collaborative activities. As discussed above, most meetings take place around tables. However, Ryall et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Ryall K, Forlines C, Shen C, Morris M (2004) Exploring the effects of group size and table size on interactions with tabletop shared-display groupware. Conf ACM CSCW, 284–293" href="/article/10.1007/s10055-006-0048-0#ref-CR12" id="ref-link-section-d78109e1083">2004</a> stated that for groups with more than three persons a single tabletop is not sufficient and that larger groups may well need vertical displays for shared information. Hence, it is desirable to have an infrastructure that supports both an interactive tabletop as well a several additional large interactive display surfaces.</p><p>The MULTI infrastructure was designed for collaborative 3D design. It consists of an interactive table and three interactive walls that are positioned in a semi-circular arrangement around one of the short sides of the table. A single 3 GHz Windows XP computer, with three graphics cards with two outputs each, drives all five projectors. The infrastructure includes also a standard 802.11 wireless network and several Tablet PC’s (not shown). An image of MULTI is shown if Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0048-0#Fig4">4</a>.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0048-0/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0048-0/MediaObjects/10055_2006_48_Fig4_HTML.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0048-0/MediaObjects/10055_2006_48_Fig4_HTML.jpg" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>An overview of the screen configuration of MULTI. All projectors and cameras are located behind the screens. The image on the table is created by two projectors (partially located underneath the middle wall screen)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0048-0/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>MULTI is designed for groups of five to seven active participants and the size of the table was chosen so that five people can comfortably sit around it. To give users full access to both long sides and one of the short sides of the table, we had to use two projectors for the table, each of which covers approximately half of the table. The decision to add several walls was motivated by several factors: the desire to be able to work on large-scale designs, the desire to support even more users as a “passive” audience, and the ability to use e.g. only the walls alone for large-scale visualization. Furthermore, the table has a stable ledge around the interactive surface in the middle, which provides space for laptops, paper, and other work artifacts (and is even stable enough to sit on).</p><p>To avoid issues with shadows cast by user’s hands etc., all surfaces are back-projection screens and the projectors and cameras are placed behind the screens (both for the table and the walls).</p><p>Each of the three back-projection screens has a 60′′ diagonal and is illuminated by a NEC WT600 projector, which have an extremely short throw distance. This helps to reduce the space usage of the configuration. The tabletop has also a 60′′ diagonal and two WT600 projectors illuminate it from underneath (the front and back half of the table, respectively). This “split-screen” design gives users free access to the two long sides and one short side of the table. Careful positioning of the projectors guarantees an almost seamless image. All projection screens are acrylic with a 0.7 gain. A pane of tempered glass thick enough to carry the weight of an adult supports the tabletop screen and a thin protective layer on top prevents scratches. Finally, there is a 15 cm wide metal ledge around the three accessible edges of the tabletop.</p><p>The main interaction devices of MULTI are several computer-controlled laser styli. The laser spots observable at any intersection of the laser beam with the projection surfaces are detected by a set of cameras. Each stylus works both as a pen (as in pen-based computing) as well as a remote pointing device. The button on a stylus is configured to work as the left mouse button, which makes it very natural to interact with standard GUI applications. Each laser stylus is wired to a control box that allows the computer to control their laser diode and the status of the button on the stylus. The laser diodes are driven with a time-multiplexing scheme that allows the infrastructure to identify each laser stylus (Pavlovych and Stuerzlinger <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Pavlovych A, Stuerzlinger W (2004) Laser pointers as interaction devices for collaborative pervasive computing. Adv Pervasive Comput, 315–320. ISBN 385403176-9" href="/article/10.1007/s10055-006-0048-0#ref-CR11" id="ref-link-section-d78109e1120">2004</a>). In the MULTI system, we use a “scaled version” of this time-multiplexing scheme that allows simultaneous tracking of seven laser styli on all four surfaces. All laser spots are tracked with Naturalpoint cameras, which feature partial hardware support for the detection of bright spots. We removed the IR filter from each camera to enable tracking of the laser spots via the standard CMOS camera chip. Each camera has a 57° lens, but due to sightline restrictions MULTI uses six cameras underneath the table, four behind the middle wall, and one behind each sidewall. As the time multiplexing of the laser diodes is synchronized with the refresh rate of the cameras (120 Hz), the blinking is (usually) not visible to the human eye.</p><p>The software tracking the laser styli can either send all stylus events to multi-user aware applications over a socket interface or alternatively simulate standard mouse events for the operating system. This second alternative is somewhat limited as the operating system silently assumes a single input device and displays only one cursor. This facility is very useful, however, as it enables the users to interact with the standard GUI environment of the operating system and all installed applications. Further details about the construction, the hardware, and software for MULTI will appear in a forthcoming publication.</p><h3 class="c-article__sub-heading" id="Sec9">CoViD: merging SESAME and MULTI</h3><p>The three main modifications necessary to enable the functionalities of SESAME to run on MULTI were the support for multiple display windows, adaptations to support laser styli as input devices, and the support for multiple simultaneous users. Together, this forms the CoViD system.</p><p>First, the displays of MULTI were associated with various views of the 3D design. The tabletop surface is best used for a view of the design from the top, akin to e.g. the view afforded by a map of a city. The vertical surfaces are better suited for a “side” view of the 3D model and we typically use two or all three wall displays together to provide a large-scale perspective view of the design (see e.g. Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0048-0#Fig5">5</a>). As additional information is critical in many design meetings, we allow the users to display and interact with additional information (e.g. a browser window or a spreadsheet) on one (or more) of the wall screens a browser window. These windows are typically placed on one of the two “side” walls. Furthermore, several tablet PC’s are available in the system as another means to access auxiliary information or to allow people to transition between group and individual work. Connectivity is provided via a wireless network and two USB hubs, which are mounted in convenient locations under the table.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0048-0/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0048-0/MediaObjects/10055_2006_48_Fig5_HTML.jpg?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0048-0/MediaObjects/10055_2006_48_Fig5_HTML.jpg" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>The CoViD system in action</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0048-0/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Technically speaking, it was fairly easy to adapt SESAME to support multiple views. We only had to change the rendering loop to support multiple open windows. However, there were subtle issues related to limitations of graphics card drivers, which prevented us from creating a single window across that spans all three wall displays. We currently handle this case simply by opening one window on two displays and another on the third.</p><p>The second issue, supporting a laser stylus as input device, was done by modifying the central event loop of SESAME to check for updates from the laser stylus tracking software of MULTI, which sends all information about stylus movements and button presses over a socket. Then, each stylus event is handled by the standard event handling code in SESAME, similar to how mouse events are handled.</p><p>However, a limitation of the current MULTI laser styli is that they have only a single button, while SESAME assumes a three-button input device. The middle mouse button is used for navigation, while the right mouse button is used for extrusion, sculpting, and resizing. On the other hand, it doesn’t make much sense to allow all users to change the camera for the shared tabletop display as this would allow one user to change the view while another is manipulating content. Hence, we decide to support navigation only via a single wireless mouse attached to MULTI, which naturally enforces a turn-taking protocol. The functionality of the right mouse button in SESAME is important for the design process. Hence, we added a special icon to the tool palette of SESAME, which allows users to toggle “right-button” mode for their stylus (and also added appropriate visual feedback close to the cursor position).</p><p>To support multiple operations by multiple users at the same time, we enhanced SESAME to keep track of separate states for each user. Also, the software needs to simulate a separate cursor for each participant. Whenever a user selects on of the tool palette entries, his/her cursor is changed to reflect their current mode. Furthermore, the undo functionality of SESAME was adapted by allowing people to activate undo in any display.</p><p>Finally, we had to perform more extensive modifications to SESAME to enable the creation of new content in parallel by multiple users. This involved keeping track of the currently active “drawing plane” on a per user basis and modifying that information with every 2D interaction of a user. We also adapted the 2D drawing facilities of SESAME so that all guides are only visible in the current window—i.e. do not show up in other windows. This avoids obscuring other views of the 3D model with these temporary visualizations.</p></div></div></section><section aria-labelledby="Sec10"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Evaluation of CoViD against guidelines</h2><div class="c-article-section__content" id="Sec10-content"><p>This section presents an evaluation of the CoViD system relative to the guidelines presented in the first part of the paper. This evaluation was performed by one of the authors, a human–computer interaction expert. As most points focus on one of the two main parts of CoViD (SESAME and MULTI), we refer these parts whenever appropriate.</p><ul class="u-list-style-bullet">
                  <li>
                    <p>
                      <i>Non</i>
                      <i>-intrusive interface: </i>To minimize the cognitive load of the user SESAME relies only a minimum set of modes: a 2D mode for drawing contours and a 3D mode for manipulating solids and the various tools associated with each mode. For 2D drawing activities, the system provides a rich set of support techniques—e.g. suggestions, automatic segmentation of freehand drawings, and recognition of closed structures. In 3D manipulation mode, the system provides a natural and efficient manipulation techniques based on physical properties, such as gravity and collisions. To avoid the cognitive overhead associated with wire-frame visualization and/or orthogonal perspective, SESAME allows the user to perform all manipulations in a perspective view.</p>
                  </li>
                  <li>
                    <p>
                      <i>Easy creation: </i>As solid modeling is more appropriate for early design phases compared to other approaches such as polygonal modeling (Deisinger et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Deisinger J, Blach R, Wesche G, Breining R, Simon A (2000) Towards immersive modeling - challenges and recommendations: a workshop analyzing the needs of designers, Virtual environments, Springer, Berlin Heidelberg New York, pp 145–156" href="/article/10.1007/s10055-006-0048-0#ref-CR1" id="ref-link-section-d78109e1197">2000</a>), SESAME supports solid modeling directly, via the metaphor of the extrusion of 2D contours, as well as sculpting and direct manipulation of 3D objects.</p>
                  </li>
                  <li>
                    <p>
                      <i>Easy combination and restructuring: </i>SESAME provides object manipulation schemes that use a single viewpoint and match the users’ expectations about the most probable 3D object motion. Similarly, group manipulation techniques behave in a way that is consistent with the real world. Both of these techniques facilitate experimentation with the structure of the scene, as objects behave like most <i>naïve</i> users expect them to do.</p>
                  </li>
                  <li>
                    <p>
                      <i>Tolerance to ambiguity and incompleteness: </i>Sketching naturally supports ambiguity and incompleteness, which makes it a great tool for the initial phases of design. SESAME includes support for three of the most important features of sketching. First, any freehand sketch is automatically beautified by segmenting it into primitive 2D shapes. As user input usually contains some amount of jitter, often also caused by digitization, a certain degree of beautification is usually a positive thing. In SESAME, the level of detail for the segmentation varies depending on the view distance to preserve important details while removing unwanted noise. We found that this addresses the trade-off between ease-of-use and precision fairly well. Also, the parts of segmented stroke can be manipulated later, i.e. if the user wants to refine a design, which facilitates the transition to more precise designs. Second, SESAME supports the coexistence of 2D drawings and 3D shapes, as it facilitates the “exchange” of ideas across dimensionalities. Finally, SESAME renders the scene as flat-shaded objects with thick outlines overlaid on top of them. This is a compromise between the “perfect” look of standard computer graphics and the “imprecise” look of a pen-and-paper sketch. While it would be desirable to provide a more “sketchy” look, the problem is that there are no <i>efficient</i> and <i>general</i> interaction techniques that work with imprecise 3D information.</p>
                  </li>
                  <li>
                    <p>
                      <i>Range of levels of abstraction: </i>Snapping provides a convenient bridge between the inaccuracy of a users’ input and the accuracy required by computer system. With snapping, designers can quickly generate a rough scene configuration and the system can display it accurately (enough). In SESAME, the level of detail is proportional to the viewing distance in many interaction techniques. This is based on the observation that designers generally work on an overall idea by viewing the scene from a farther distance and work on detail by zooming into the part of interest. Furthermore, the group manipulation techniques of SESAME facilitate fluid transitions between work at a large scale and detail modification.</p>
                  </li>
                  <li>
                    <p>
                      <i>Ability to edit various forms of information: </i>Currently, SESAME does not address this in a significant way.</p>
                  </li>
                  <li>
                    <p>
                      <i>Supporting evaluation (simulation): </i>We support this is via the export of scene geometry to any simulation package (e.g. photorealistic rendering software or stress analysis) and then running that simulation. In the future, we may integrate this functionality better.</p>
                  </li>
                  <li>
                    <p>
                      <i>Natural interpersonal interaction: </i>As all participants are sitting (or standing) around the MULTI table, this is similar to standard meetings around a conference table. Hence, participants can naturally interact face-to-face with other participants in the system.</p>
                  </li>
                  <li>
                    <p>
                      <i>Transitions between activities: </i>MULTI allows its users to interact with the standard GUI desktop, which enables them to use many different applications and hence transition seamlessly between activities such as design, performing a WWW search, interacting with spread-sheets or other documents, etc. As the wall surfaces are interactive as well, it is easy to transition to sessions, where one person interacts with the system as if it were a large blackboard. Furthermore, people can (and usually do) place paper documents and other work artifacts on the rim of the table, which provides even more possibilities for transitions between various activities.</p>
                  </li>
                  <li>
                    <p>
                      <i>Transitions between personal and group work: </i>The table surface of MULTI is large enough that a person cannot simply reach completely across it (without standing up and leaning across). This effectively gives each user their own personal space in an unambiguous manner. Furthermore, all work files are placed in subfolders of the GUI desktop. As this desktop folder of the system is shared via the wireless network, this makes it easy for participants to transfer (part of) the data to an external portable device (e.g. a Tablet PC) for individual work and back to the desktop to share it again.</p>
                  </li>
                  <li>
                    <p>
                      <i>Transition between tabletop collaboration and external work: </i>Two USB hubs have been mounted in easy to access locations under the table. This facilitates transfer of data from USB drives to and from MULTI. Furthermore, the wireless network as well as the standard network connection of the system provide for even more opportunities to transfer data to and from MULTI.</p>
                  </li>
                  <li>
                    <p>
                      <i>The use of physical objects: </i>The wide metal ledge around the table is stable enough for a user to sit on and users can place laptops, various printouts, notebooks, and other personal items on it. While people may be tempted to put a lot of stuff around the ledge, this may also block their access to the table, which balances things nicely. The interactive tabletop itself is stable enough to support considerable weight (due to the pane of tempered glass behind it). This allows people to place objects onto the interactive part, but such objects block the projection. Currently, MULTI does not support a tangible user interface, but we are working on adding this functionality.</p>
                  </li>
                  <li>
                    <p>
                      <i>Accessing shared physical and digital objects: </i>To access a shared digital object the user just needs to point at it with his/her laser stylus. In computer-based design applications, the orientation of artifacts on the table surface is less of a concern, as the natural perspective for content on the table surface is a top down view onto the content. This makes it relatively easy to access objects from any direction. The wall surfaces of the system provide a side view of the 3D environment, but these surfaces have anyways a natural “up” orientation. All physical/tangible objects on the table surface can easily be manipulated by reaching for them. Finally, all interactive surfaces are back-projected in MULTI, which makes it impossible for a user to cast shadows onto content (beyond normal blocking of shared content with a hand).</p>
                  </li>
                  <li>
                    <p>
                      <i>Flexible user arrangements: </i>Due to the size and the physical configuration of the table (only one short side is blocked), users can sit in many configurations around it. As the table is on heavy-duty rollers, it can even be rolled away completely if the users only want to only use the wall surfaces. As discussed in the previous point, in the context of design applications, the natural view for the table is top–down, which leaves a lot of flexibility for the users to arrange themselves around the table.</p>
                  </li>
                  <li>
                    <p>
                      <i>Simultaneous user interactions: </i>Due to the time multiplexing scheme, several people can simultaneously interact with MULTI. Due to the restrictions of the Windows operating system (it only supports one cursor), standard GUI applications do not support multiple users seamlessly. However, applications that include support for multiple input devices can use the full functionality of MULTI.</p>
                  </li>
                </ul>
              </div></div></section><section aria-labelledby="Sec11"><div class="c-article-section" id="Sec11-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec11">Pilot user study of CoViD</h2><div class="c-article-section__content" id="Sec11-content"><p>We conducted two pilot experiments to test the basic features of CoViD in single user mode in comparison with collaborative mode. Nine participants were recruited from the pool of computer science undergraduate and graduate students (two female, seven male) at the local university. They were organized in three groups of 3. Each participant was asked to perform two tasks individually as well as collaboratively in the group. Before the experiment, we explained how the system worked and demonstrated the use of the laser styli as well as the relevant operations of SESAME to each participant for about 10 min. At the end the experiment, users were given a questionnaire to rate preferences between working in groups versus working individually and which task they enjoyed the most. Statistics was analyzed via ANOVA.</p><h3 class="c-article__sub-heading" id="Sec12">Scene assembly task</h3><p>We first evaluated the effectiveness of the system to assemble a simple object with the 3D movement technique of SESAME. The participants were asked to assemble a chair from parts first individually, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0048-0#Fig6">6</a>.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0048-0/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0048-0/MediaObjects/10055_2006_48_Fig6_HTML.jpg?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0048-0/MediaObjects/10055_2006_48_Fig6_HTML.jpg" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Scene assembly task. <b>a</b> Initial state. <b>b</b> Target scene</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0048-0/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec13">Results</h4><p>When working individually, average completion time for the task was 4 min and 23 s. When working collaboratively the average completion time was 5 min 40 s. Detailed timings are shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-006-0048-0#Tab2">2</a>.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Scene assembly times by user (in seconds)</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-006-0048-0/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <p>None of the differences between the individual and group performances are statistically significant.</p><h3 class="c-article__sub-heading" id="Sec14">Design task</h3><p>In the second task we asked users to create a simple 3D design. The task was to create three different 2D shapes using the rectangle, freeform and circle tools, to turn them into 3D structures via extrusion and then create “chimneys” on top of them. The condition was that the chimneys had to be created using tools different from the ones that were used to create their corresponding structures, as illustrated by Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0048-0#Fig7">7</a>.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0048-0/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0048-0/MediaObjects/10055_2006_48_Fig7_HTML.jpg?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0048-0/MediaObjects/10055_2006_48_Fig7_HTML.jpg" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Sample configuration for the design task</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0048-0/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec15">Results</h4><p>When working individually, average completion time for the task was 4 min and 5 s. When working collaboratively, average time was 4 min and 54 s. Detailed timings are shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-006-0048-0#Tab3">3</a>.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Design task times by user (in seconds)</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-006-0048-0/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <p>Again, none of the differences between the individual and group performances were statistically significant.</p><h3 class="c-article__sub-heading" id="Sec16">Discussion</h3><p>Due to the small sample size (only three groups) none of the results of the statistical analysis were significant, which limits our ability to draw conclusions from the data. One factor that may have contributed to this is that the tasks were relatively simple and the potential benefits of collaboration hence negligible. However, we can still state that participants were able to complete the tasks reasonably quickly.</p><p>One interesting behavior we observed was that two groups worked mainly in the perspective view and used the tabletop only when users wanted to work in parallel. This may have been based on the relatively larger size of the scene on the wall screens. The lack of a second button on the laser styli was also an issue that led to unnecessary errors.</p><p>The analysis of the questionnaires revealed that on average participants rated the four different conditions (individual scene assembly, individual design, collaborative scene assembly, and collaborative design) about equally in terms of how much they enjoyed the different conditions.</p><p>As for the collaborative assembly task, users commented that assembling parts with others made it more confusing because complained that other users would often interfere and “ruin” their work. For collaborative design, users commented that working with other people made the task more entertaining and that it was more fun to create new designs together rather than assembling parts. This hints at the potential of CoViD to support creativity in design sessions. Some users reported problems with the laser styli in the palette area on the table. This seems to have been caused by calibration problems in that region of the tabletop. The small seam (less than one pixel) caused by the overlap between the images of the two table projectors was not recognized as a noteworthy issue.</p><p>The evaluation of CoViD revealed several issues that need to be addressed, before a more comprehensive user study can be performed. Most importantly, we need to redesign the laser styli to be wireless and to include a second button. Furthermore, there were calibration problems in certain areas of the screens and some synchronization problems between the laser diode circuit and the camera systems, mainly due to some bugs in the camera driver. We are currently working on fixing these issues.</p></div></div></section><section aria-labelledby="Sec17"><div class="c-article-section" id="Sec17-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec17">Conclusions and future work</h2><div class="c-article-section__content" id="Sec17-content"><p>This paper presented CoViD, a novel system for collaborative 3D design. We first introduced a set of guidelines for collaborative design systems. Then we introduced the new system and presented details about its components and how they were adapted to form a collaborative 3D design system. Subsequently, we evaluated the design of the system against the guidelines and reported results of a pilot study, in which users generally liked the ability to collaboratively design in 3D.</p><p>We are currently working on addressing the issues that were identified during the pilot study. Once that is done, we intend to perform a more comprehensive evaluation by having a group of architectural students design building(s) for a free lot in a collaborative setting in collaboration with a professor in architecture. Furthermore, we also intend to analyze how the collaborative aspect of the CoViD system affects creativity. Another area of future work is the extension of SESAME to support additional modeling primitives (such as rotationally symmetric and freeform objects). Finally, we are working on a tangible user interface for MULTI and plan to extend SESAME to allow for tangible interaction.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Deisinger J, Blach R, Wesche G, Breining R, Simon A (2000) Towards immersive modeling - challenges and recomme" /><p class="c-article-references__text" id="ref-CR1">Deisinger J, Blach R, Wesche G, Breining R, Simon A (2000) Towards immersive modeling - challenges and recommendations: a workshop analyzing the needs of designers, Virtual environments, Springer, Berlin Heidelberg New York, pp 145–156</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Druin, J. Stewart, D. Proft, B. Bederson, J. Hollan, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Druin A, Stewart J, Proft D, Bederson B, Hollan J (1997) KidPad: a design collaboration between children, tech" /><p class="c-article-references__text" id="ref-CR2">Druin A, Stewart J, Proft D, Bederson B, Hollan J (1997) KidPad: a design collaboration between children, technologists, and educators. Conf ACM CHI 97:463–470</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=KidPad%3A%20a%20design%20collaboration%20between%20children%2C%20technologists%2C%20and%20educators&amp;journal=Conf%20ACM%20CHI&amp;volume=97&amp;pages=463-470&amp;publication_year=1997&amp;author=Druin%2CA&amp;author=Stewart%2CJ&amp;author=Proft%2CD&amp;author=Bederson%2CB&amp;author=Hollan%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Gross, E. Do, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Gross M, Do E (2000) Drawing on the back of envelope: a framework for interacting with application programs by" /><p class="c-article-references__text" id="ref-CR3">Gross M, Do E (2000) Drawing on the back of envelope: a framework for interacting with application programs by freehand drawing. Comput Graph 24:835–849</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0097-8493%2800%2900087-X" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Drawing%20on%20the%20back%20of%20envelope%3A%20a%20framework%20for%20interacting%20with%20application%20programs%20by%20freehand%20drawing&amp;journal=Comput%20Graph&amp;volume=24&amp;pages=835-849&amp;publication_year=2000&amp;author=Gross%2CM&amp;author=Do%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gross M (2001) Emergence in a recognition based drawing interface. Conf Vis Spatial Reason, 51–65" /><p class="c-article-references__text" id="ref-CR4">Gross M (2001) Emergence in a recognition based drawing interface. Conf Vis Spatial Reason, 51–65</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Igarashi T, Matsuoka S, Tanaka H (1999) Teddy: a sketching interface for 3D freeform design. Conf ACM SIGGRAPH" /><p class="c-article-references__text" id="ref-CR5">Igarashi T, Matsuoka S, Tanaka H (1999) Teddy: a sketching interface for 3D freeform design. Conf ACM SIGGRAPH’99, 409–416</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Oh J-Y (2005) Desktop 3D conceptual design systems. PhD Thesis, York University" /><p class="c-article-references__text" id="ref-CR6">Oh J-Y (2005) Desktop 3D conceptual design systems. PhD Thesis, York University</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Oh J-Y, Stuerzlinger W (2005) Moving objects with 2D input devices in CAD systems and desktop virtual environm" /><p class="c-article-references__text" id="ref-CR7">Oh J-Y, Stuerzlinger W (2005) Moving objects with 2D input devices in CAD systems and desktop virtual environments. Conf Graphics Interface, 141–149</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Oh J-Y, Stuerzlinger W, Danahy J (2005) Comparing SESAME and sketching for conceptual 3D design. Workshop EG S" /><p class="c-article-references__text" id="ref-CR8">Oh J-Y, Stuerzlinger W, Danahy J (2005) Comparing SESAME and sketching for conceptual 3D design. Workshop EG Sketch Based Interfaces Modeling, 81–88</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Oh J-Y, Stuerzlinger W, Dadgari D (2006a) Group selection techniques for efficient 3D modeling. IEEE Symp 3D U" /><p class="c-article-references__text" id="ref-CR9">Oh J-Y, Stuerzlinger W, Dadgari D (2006a) Group selection techniques for efficient 3D modeling. IEEE Symp 3D User Interfaces, 95–102 </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Oh J-Y, Stuerzlinger W, Danahy J (2006b) SESAME: towards better 3D conceptual design systems. Conf ACM Dis, 80" /><p class="c-article-references__text" id="ref-CR10">Oh J-Y, Stuerzlinger W, Danahy J (2006b) SESAME: towards better 3D conceptual design systems. Conf ACM Dis, 80–89</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pavlovych A, Stuerzlinger W (2004) Laser pointers as interaction devices for collaborative pervasive computing" /><p class="c-article-references__text" id="ref-CR11">Pavlovych A, Stuerzlinger W (2004) Laser pointers as interaction devices for collaborative pervasive computing. Adv Pervasive Comput, 315–320. ISBN 385403176-9</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ryall K, Forlines C, Shen C, Morris M (2004) Exploring the effects of group size and table size on interaction" /><p class="c-article-references__text" id="ref-CR12">Ryall K, Forlines C, Shen C, Morris M (2004) Exploring the effects of group size and table size on interactions with tabletop shared-display groupware. Conf ACM CSCW, 284–293</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Scott S, Grant K, Mandryk R (2003) System guidelines for co-located, collaborative work on a tabletop display." /><p class="c-article-references__text" id="ref-CR13">Scott S, Grant K, Mandryk R (2003) System guidelines for co-located, collaborative work on a tabletop display. Conf ECSCW, Springer, Berlin Heidelberg New York, pp 159–178.<a href="http://www.springer.com/east/home/generic/search/results?SGWID=5-40109-22-33658793-0">http://www.springer.com/east/home/generic/search/results?SGWID=5-40109-22-33658793-0</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Shu L, Flowers W (1992) Groupware experiences in three-dimensional computer-aided design. CSCW, 179–186" /><p class="c-article-references__text" id="ref-CR14">Shu L, Flowers W (1992) Groupware experiences in three-dimensional computer-aided design. CSCW, 179–186</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Stewart J, Bederson B, Druin A (1999) A model for co-present collaboration. Conf ACM CHI, 286–293" /><p class="c-article-references__text" id="ref-CR15">Stewart J, Bederson B, Druin A (1999) A model for co-present collaboration. Conf ACM CHI, 286–293</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Tano S, Kodera T, Nakashima T, Kawano I, Nakanishi K, Hamagishi G, Inoue M, Watanabe A, Okamoto T, Kawagoe K, " /><p class="c-article-references__text" id="ref-CR16">Tano S, Kodera T, Nakashima T, Kawano I, Nakanishi K, Hamagishi G, Inoue M, Watanabe A, Okamoto T, Kawagoe K, Kaneko K, Hotta T, Tatsuoka M (2003) Godzilla: seamless 2D and 3D sketch environment for reflective and creative design work. IFIP INTERACT’03, 311–318</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Tse E, Greenberg S (2004) Rapidly prototyping single display groupware through the SDGToolkit. Australasian Us" /><p class="c-article-references__text" id="ref-CR17">Tse E, Greenberg S (2004) Rapidly prototyping single display groupware through the SDGToolkit. Australasian User Interface Conf, 101–110</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zeleznik R, Herndon K, Hughes J (1996) SKETCH: an interface for sketching 3D scenes. Conf ACM SIGGRAPH’96, 163" /><p class="c-article-references__text" id="ref-CR18">Zeleznik R, Herndon K, Hughes J (1996) SKETCH: an interface for sketching 3D scenes. Conf ACM SIGGRAPH’96, 163–170</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-006-0048-0-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>Thanks to D. Phillips, D. Dadgari, and A. Vorozcovs for help with camera calibration and programming the laser spot detector software, to the York Centre of Vision Research, and to NSERC for funding.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">York University, Toronto, Canada</p><p class="c-article-author-affiliation__authors-list">Wolfgang Stuerzlinger, Loutfouz Zaman &amp; Andriy Pavlovych</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">University of Arizona, Tucson, AZ, USA</p><p class="c-article-author-affiliation__authors-list">Ji-Young Oh</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Wolfgang-Stuerzlinger"><span class="c-article-authors-search__title u-h3 js-search-name">Wolfgang Stuerzlinger</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Wolfgang+Stuerzlinger&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Wolfgang+Stuerzlinger" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Wolfgang+Stuerzlinger%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Loutfouz-Zaman"><span class="c-article-authors-search__title u-h3 js-search-name">Loutfouz Zaman</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Loutfouz+Zaman&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Loutfouz+Zaman" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Loutfouz+Zaman%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Andriy-Pavlovych"><span class="c-article-authors-search__title u-h3 js-search-name">Andriy Pavlovych</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Andriy+Pavlovych&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Andriy+Pavlovych" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Andriy+Pavlovych%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Ji_Young-Oh"><span class="c-article-authors-search__title u-h3 js-search-name">Ji-Young Oh</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Ji-Young+Oh&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Ji-Young+Oh" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ji-Young+Oh%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                Wolfgang Stuerzlinger.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=The%20design%20and%20realization%20of%20CoViD%3A%20a%20system%20for%20collaborative%20virtual%203D%20design&amp;author=Wolfgang%20Stuerzlinger%20et%20al&amp;contentID=10.1007%2Fs10055-006-0048-0&amp;publication=1359-4338&amp;publicationDate=2006-09-19&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Stuerzlinger, W., Zaman, L., Pavlovych, A. <i>et al.</i> The design and realization of CoViD: a system for collaborative virtual 3D design.
                    <i>Virtual Reality</i> <b>10, </b>135–147 (2006). https://doi.org/10.1007/s10055-006-0048-0</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-006-0048-0.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-03-14">14 March 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-05-12">12 May 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-09-19">19 September 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-10">October 2006</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-006-0048-0" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-006-0048-0</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Collaborative design</span></li><li class="c-article-subject-list__subject"><span itemprop="about">3D design</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Collaborative virtual reality</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-006-0048-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=48;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

