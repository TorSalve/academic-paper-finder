<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Toward the development of interactive virtual dissection with haptic f"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Traditional, hands-on dissection of an animal is common practice in many classrooms to aid in the study of anatomy and biology. More specifically, virtual dissection environments have been..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/14/2.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Toward the development of interactive virtual dissection with haptic feedback"/>

    <meta name="dc.source" content="Virtual Reality 2009 14:2"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2009-09-03"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2009 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Traditional, hands-on dissection of an animal is common practice in many classrooms to aid in the study of anatomy and biology. More specifically, virtual dissection environments have been developed making it possible to study the inner workings of animals without cutting them up. In this paper, we present a novel virtual reality dissection simulator, where a user can dissect an animal (i.e. frog) and its organs using a 3D force feedback haptic device. The simulator uses force feedback as part of a multimodal cue to provide guidance and performance feedback to the user. This paper highlights methodologies which are used for addressing some of the key challenges involved in designing and developing simulators, such as: modelling and mechanics of deformation, collision detection between multiple deformable bodies, and haptic feedback."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2009-09-03"/>

    <meta name="prism.volume" content="14"/>

    <meta name="prism.number" content="2"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="85"/>

    <meta name="prism.endingPage" content="103"/>

    <meta name="prism.copyright" content="2009 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-009-0132-3"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-009-0132-3"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-009-0132-3.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-009-0132-3"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Toward the development of interactive virtual dissection with haptic feedback"/>

    <meta name="citation_volume" content="14"/>

    <meta name="citation_issue" content="2"/>

    <meta name="citation_publication_date" content="2010/06"/>

    <meta name="citation_online_date" content="2009/09/03"/>

    <meta name="citation_firstpage" content="85"/>

    <meta name="citation_lastpage" content="103"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-009-0132-3"/>

    <meta name="DOI" content="10.1007/s10055-009-0132-3"/>

    <meta name="citation_doi" content="10.1007/s10055-009-0132-3"/>

    <meta name="description" content="Traditional, hands-on dissection of an animal is common practice in many classrooms to aid in the study of anatomy and biology. More specifically, virtual "/>

    <meta name="dc.creator" content="Nasim Melony Vafai"/>

    <meta name="dc.creator" content="Shahram Payandeh"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Basdogan C, Srinivasan M (2001) Haptic rendering in virtual environments. In: Stanney K (ed) Virtual environments handbook, Erlbaum, Mahwah, NJ, pp 117&#8211;134"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Comput Graph Appl; citation_title=Haptics in minimally invasive surgical simulation and training; citation_author=C Basdogan, S De, J Kim, M Manivannan, H Kim, MA Srinivasan; citation_volume=24; citation_issue=2; citation_publication_date=2004; citation_pages=56-64; citation_doi=10.1109/MCG.2004.1274062; citation_id=CR2"/>

    <meta name="citation_reference" content="Brown J, Sorkin S, Bruyns C, Latombe JC, Montgomery K, Stephanides M (2001) Real-time simulation of deformable objects: tools and application. Computer animation 2001, Seoul, Korea, November 7&#8211;8"/>

    <meta name="citation_reference" content="Burden RL, Faires JD (2000) Numerical analysis. Brooks-Cole"/>

    <meta name="citation_reference" content="Cover S, Norberto FE, Obrien JF, Rowe R, Gadau T, Palm E (1993) Interactively deformable models for surgery simulation. In: Proceedings of ICRA, pp 68&#8211;75"/>

    <meta name="citation_reference" content="Crossan A, Brewster S, Reid S et&#160;al (2001) A horse ovary palpation simulator for veterinary training. In: Haptic human-computer interaction, pp 157&#8211;164"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Aided Des; citation_title=Behaviour of recursive division surfaces near extraordinary points; citation_author=D Doo, M Sabin; citation_volume=10; citation_publication_date=1978; citation_pages=356-360; citation_doi=10.1016/0010-4485(78)90111-2; citation_id=CR7"/>

    <meta name="citation_reference" content="citation_journal_title=Med Image Anal; citation_title=A layered model of a virtual human intestine for surgery simulation; citation_author=L France, J Lenoir, A Angelidis, P Meseure, MP Cani, F Faure, C Chaillou; citation_volume=9; citation_publication_date=2005; citation_pages=123-132; citation_doi=10.1016/j.media.2004.11.006; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph; citation_title=A multigrid framework for real-time simulation of deformable bodies; citation_author=J Georgii, R Westermann; citation_volume=30; citation_issue=3; citation_publication_date=2006; citation_pages=409-416; citation_doi=10.1016/j.cag.2006.02.016; citation_id=CR9"/>

    <meta name="citation_reference" content="Gibson S (1997) A survey of deformable modeling in computer graphics. Technical report no. TR-97-19, Mitsubishi Electric Research Laboratory, Cambridge MA"/>

    <meta name="citation_reference" content="Laugier C, Mendoza C, Sundaraj K (2003) Towards a realistic medical simulator using virtual environments and haptic interaction. Robotics Research, volume 6 of Springer Tracts in Advanced Robotics (STAR)"/>

    <meta name="citation_reference" content="Lawlor OS, Kale LV (2002) A voxel-based parallel collision detection algorithm. In: Proceedings of the 16th international conference on Supercomputing, 22&#8211;26 June, pp 285&#8211;293"/>

    <meta name="citation_reference" content="Lin M, Gottschalk S (1999) Collision detection between geometric models: a survey. In: Proceedings of IMA conference on mathematics of surfaces, pp 37&#8211;56"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real J; citation_title=Enabling design and interactive selection of haptic modes; citation_author=K Lundin, M Cooper, A Ynnerman; citation_volume=11; citation_issue=1; citation_publication_date=2007; citation_pages=1-13; citation_doi=10.1007/s10055-006-0033-7; citation_id=CR14"/>

    <meta name="citation_reference" content="Mendoza C, Sundaraj K, Laugier C (2003) Faithfull haptic feedback in medical simulators. Robotics Research, volume 5 of Springer Tracts in Advanced Robotics (STAR)"/>

    <meta name="citation_reference" content="Montgomery K, Bruyns C, Wildermuth S (2001) A virtual environment for simulated rat dissection: a case study of visualization for astronaut training. Vis 2001, San Diego, California"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions; citation_title=Haptic rendering of dynamic volumetric data, visualization and computer graphics; citation_author=KL Palmerius, M Cooper, A Ynnerman; citation_volume=14; citation_issue=2; citation_publication_date=2008; citation_pages=263-276; citation_id=CR17"/>

    <meta name="citation_reference" content="Pauly M, Pai D, Guibas L (2004) Quasi-rigid objects in contact, Eurographics/ACM SIGGRAPH symposium on computer animation"/>

    <meta name="citation_reference" content="Payandeh S, Azouz N (2001) Finite elements, mass-spring-damper systems and haptic rendering. In: Proceedings of IEEE international symposium on computational intelligence in robotics and automation, pp 224&#8211;230"/>

    <meta name="citation_reference" content="Picinbono G, Lombardo J (1999) Extrapolation: a solution to force feedback. In: International scientific workshop on virtual reality and prototyping, Laval, France, pp 117&#8211;125"/>

    <meta name="citation_reference" content="citation_title=Applied finite element analysis; citation_publication_date=1976; citation_id=CR21; citation_author=L Segerlind; citation_publisher=Wiley"/>

    <meta name="citation_reference" content="Sundaraj K (2004) Real-time dynamic simulation and 3D interaction of biological tissue: application to medical simulators. PhD. Thesis, Institut National Polytechnique de Grenoble"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions Med Imaging; citation_title=Sphere-filled organ model for virtual surgery system; citation_author=S Suzuki, N Suzuki, A Hattori, A Uchiyama, S Kobayashi; citation_volume=23; citation_issue=6; citation_publication_date=2004; citation_pages=714; citation_doi=10.1109/TMI.2004.826947; citation_id=CR23"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graphics Forum; citation_title=Collision detection for deformable objects; citation_author=M Teschner, S Kimmerle, B Heidelberger; citation_volume=24; citation_issue=1; citation_publication_date=2005; citation_pages=61-81; citation_doi=10.1111/j.1467-8659.2005.00829.x; citation_id=CR24"/>

    <meta name="citation_reference" content="Tong C, Song A, Juan W (2007) A mass-spring model for haptic display of flexible object global deformation. In: Proceedings of ICMA 2007"/>

    <meta name="citation_reference" content="citation_journal_title=J Graphics Tools; citation_title=Efficient collision detection of complex deformable models using AABB trees; citation_author=G Van Den Bergen; citation_volume=2; citation_issue=4; citation_publication_date=1997; citation_pages=1-14; citation_id=CR26"/>

    <meta name="citation_reference" content="Zhang H, Payandeh S, Dill J (2004) On cutting and dissection of virtual deformable objects. In: Proceedings of IEEE international conference on robotics and automation, pp 3908&#8211;3913"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Appl Percept; citation_title=A study of level-of-detail in haptic rendering; citation_author=J Zhang, S Payandeh, J Dill; citation_volume=2; citation_issue=1; citation_publication_date=2005; citation_pages=15-34; citation_doi=10.1145/1048687.1048689; citation_id=CR28"/>

    <meta name="citation_reference" content="Zhennan Y, Lixu G, Huang P (2007) Soft tissue deformation simulation in virtual surgery using nonlinear finite element method. In: Proceedings of the 29th annual international conference of the IEEE EMBS"/>

    <meta name="citation_reference" content="Zhou M, Claffee K, Lee K, McMurray G (2006a) Cutting, &#8216;by pressing and slicing&#8217;, applied to the robotic cut of bio-materials, Part I: modeling of stress distribution. In: Proceedings ICRA06, pp 2896&#8211;2901"/>

    <meta name="citation_reference" content="Zhou M, Claffee K, Lee K, McMurray G (2006b) Cutting, &#8216;by pressing and slicing&#8217;, applied to the robotic cut of bio-materials, Part II: force during slicing and pressing cuts. In: Proceedings of ICRA06, pp 2256&#8211;2261"/>

    <meta name="citation_author" content="Nasim Melony Vafai"/>

    <meta name="citation_author_email" content="nmvafai@alumni.sfu.ca"/>

    <meta name="citation_author_institution" content="Experimental Robotics and Graphics Laboratory, Simon Fraser University, Burnaby, Canada"/>

    <meta name="citation_author" content="Shahram Payandeh"/>

    <meta name="citation_author_email" content="shahram@cs.sfu.ca"/>

    <meta name="citation_author_institution" content="Experimental Robotics and Graphics Laboratory, Simon Fraser University, Burnaby, Canada"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-009-0132-3&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2010/06/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-009-0132-3"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Toward the development of interactive virtual dissection with haptic feedback"/>
        <meta property="og:description" content="Traditional, hands-on dissection of an animal is common practice in many classrooms to aid in the study of anatomy and biology. More specifically, virtual dissection environments have been developed making it possible to study the inner workings of animals without cutting them up. In this paper, we present a novel virtual reality dissection simulator, where a user can dissect an animal (i.e. frog) and its organs using a 3D force feedback haptic device. The simulator uses force feedback as part of a multimodal cue to provide guidance and performance feedback to the user. This paper highlights methodologies which are used for addressing some of the key challenges involved in designing and developing simulators, such as: modelling and mechanics of deformation, collision detection between multiple deformable bodies, and haptic feedback."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Toward the development of interactive virtual dissection with haptic feedback | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-009-0132-3","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Virtual reality, Object deformation, Cutting, Dissection, Collision detection, Haptics, Force feedback","kwrd":["Virtual_reality","Object_deformation","Cutting","Dissection","Collision_detection","Haptics","Force_feedback"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-009-0132-3","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-009-0132-3","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=132;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-009-0132-3">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Toward the development of interactive virtual dissection with haptic feedback
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-009-0132-3.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-009-0132-3.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2009-09-03" itemprop="datePublished">03 September 2009</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Toward the development of interactive virtual dissection with haptic feedback</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Nasim_Melony-Vafai" data-author-popup="auth-Nasim_Melony-Vafai" data-corresp-id="c1">Nasim Melony Vafai<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Simon Fraser University" /><meta itemprop="address" content="grid.61971.38, 0000000419367494, Experimental Robotics and Graphics Laboratory, Simon Fraser University, Burnaby, BC, Canada" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Shahram-Payandeh" data-author-popup="auth-Shahram-Payandeh">Shahram Payandeh</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Simon Fraser University" /><meta itemprop="address" content="grid.61971.38, 0000000419367494, Experimental Robotics and Graphics Laboratory, Simon Fraser University, Burnaby, BC, Canada" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 14</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">85</span>–<span itemprop="pageEnd">103</span>(<span data-test="article-publication-year">2010</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">269 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">4 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">0 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-009-0132-3/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Traditional, hands-on dissection of an animal is common practice in many classrooms to aid in the study of anatomy and biology. More specifically, virtual dissection environments have been developed making it possible to study the inner workings of animals without cutting them up. In this paper, we present a novel virtual reality dissection simulator, where a user can dissect an animal (i.e. frog) and its organs using a 3D force feedback haptic device. The simulator uses force feedback as part of a multimodal cue to provide guidance and performance feedback to the user. This paper highlights methodologies which are used for addressing some of the key challenges involved in designing and developing simulators, such as: modelling and mechanics of deformation, collision detection between multiple deformable bodies, and haptic feedback.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Realistic simulation of deformable bodies together with haptic feedback remains a fundamental challenge in the field of virtual reality (VR). Recently, there has been much research dedicated to simulating deformable bodies in real-time virtual environments. However, a number of major challenges remain to be explored arising from a number of issues including: modelling and computational mechanics of deformation, solution to systems of differential equations, collision (i.e. contact) detection between bodies (solid and deformable), and modelling contact response as a result of topological changes (Brown et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Brown J, Sorkin S, Bruyns C, Latombe JC, Montgomery K, Stephanides M (2001) Real-time simulation of deformable objects: tools and application. Computer animation 2001, Seoul, Korea, November 7–8" href="/article/10.1007/s10055-009-0132-3#ref-CR3" id="ref-link-section-d77471e303">2001</a>). Therefore, the complex nature of deformable bodies still lacks acceptable solutions particularly where real-time performance is concerned.</p><p>The refresh or update rate for graphics (i.e. to display and animate the deformable objects) should be at least 30 frames per second (fps) for smooth and continuous visual feedback, and for motion to appear fluid and lifelike. However, the desired refresh rate for haptics (i.e. creating the sense of touch at the hand of the user) is an order of magnitude higher (~1,000 fps for fast haptic rendering) than the graphic refresh rate. This high performance requirement is quite challenging with an application that requires complex and lengthy computations. We have chosen to work with the PHANToM for our dissection simulation because it allows sufficient degrees of freedom, provides us with enough realism for our virtual scene and provides better cost performance than most of the other commercially available haptic devices.</p><p>In this paper we describe the results of some of our methods that help simplify calculations for various situations (i.e. contact deformation and collision detection between deformable objects). Our particular focus is the computation of a special class of object deformations which involves contact detection between deformable bodies. There is a strong need to address palpation (i.e. deformation) training, for example, the specific need of detecting subsurface tumors or similar abnormalities. Our objective is to combine the deformation and contact detection algorithms to deliver a more realistic model for interaction forces through haptic devices.</p><p>This paper is an early investigation into interactive virtual dissection with haptic feedback. This can be part of an ultimate objective to provide an alternative environment to study the inner workings of animals without physically dissecting them. By providing force feedback, the user can directly interact with the dissection environment (i.e. they can “feel” the animal through the sense of touch) engaging more of their senses. We will be discussing some of the issues and challenges associated with it.</p><p>The remainder of this paper is organized as follows: Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0132-3#Sec2">2</a> reviews related work. In Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0132-3#Sec3">3</a> a contact detection model for soft objects is examined and Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0132-3#Sec8">4</a> discusses computation of object deformations and simulation of a “sliding” effect on the surface of a deformable body is simulated as being part of the palpation model. We discuss our novel data structure (manifold proximity class) that is used for solving deformation between multiple deformable bodies. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0132-3#Sec11">5</a> covers our novel “skin peeling” algorithm, while Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0132-3#Sec12">6</a> describes multimodal cues of haptic feedback calculations and extrapolation techniques used to stabilize and smooth the force feedback. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0132-3#Sec15">7</a> briefly discusses our user study results and analysis and we finally conclude in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0132-3#Sec24">8</a> and discuss possible future work.</p><p>Our example application, demonstrates all the methods discussed in this paper. The user begins by cutting along the abdomen area of the surface skin using a force feedback haptic device (i.e. PHANToM) represented graphically by a scalpel. Once the abdomen area has been cut through, the skin is peeled using a grasper to expose the organs. Furthermore, various organs can be cut out allowing them to be easily removed.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Background</h2><div class="c-article-section__content" id="Sec2-content"><p>We present an approach for a real-time virtual dissection simulation. The main components of our dissection simulation are the physical modelling, collision detection between deformable objects, and soft-tissue deformation which will be covered in subsequent sections.</p><p>To our knowledge, most previous dissection work focused on surgical simulation (Cover et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Cover S, Norberto FE, Obrien JF, Rowe R, Gadau T, Palm E (1993) Interactively deformable models for surgery simulation. In: Proceedings of ICRA, pp 68–75" href="/article/10.1007/s10055-009-0132-3#ref-CR5" id="ref-link-section-d77471e350">1993</a>; Georgii and Westermann <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Georgii J, Westermann R (2006) A multigrid framework for real-time simulation of deformable bodies. Comput Graph 30(3):409–416" href="/article/10.1007/s10055-009-0132-3#ref-CR9" id="ref-link-section-d77471e353">2006</a>; Mendoza et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Mendoza C, Sundaraj K, Laugier C (2003) Faithfull haptic feedback in medical simulators. Robotics Research, volume 5 of Springer Tracts in Advanced Robotics (STAR)" href="/article/10.1007/s10055-009-0132-3#ref-CR15" id="ref-link-section-d77471e356">2003</a>), concentrating on cutting (Doo and Sabin <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1978" title="Doo D, Sabin M (1978) Behaviour of recursive division surfaces near extraordinary points. Comput Aided Des 10:356–360" href="/article/10.1007/s10055-009-0132-3#ref-CR7" id="ref-link-section-d77471e359">1978</a>; Laugier et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Laugier C, Mendoza C, Sundaraj K (2003) Towards a realistic medical simulator using virtual environments and haptic interaction. Robotics Research, volume 6 of Springer Tracts in Advanced Robotics (STAR)" href="/article/10.1007/s10055-009-0132-3#ref-CR11" id="ref-link-section-d77471e362">2003</a>; Zhang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Zhang H, Payandeh S, Dill J (2004) On cutting and dissection of virtual deformable objects. In: Proceedings of IEEE international conference on robotics and automation, pp 3908–3913" href="/article/10.1007/s10055-009-0132-3#ref-CR27" id="ref-link-section-d77471e366">2004</a>) and suturing (Suzuki et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Suzuki S, Suzuki N, Hattori A, Uchiyama A, Kobayashi S (2004) Sphere-filled organ model for virtual surgery system. IEEE Transactions Med Imaging 23(6):714" href="/article/10.1007/s10055-009-0132-3#ref-CR23" id="ref-link-section-d77471e369">2004</a>; Zhang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Zhang H, Payandeh S, Dill J (2004) On cutting and dissection of virtual deformable objects. In: Proceedings of IEEE international conference on robotics and automation, pp 3908–3913" href="/article/10.1007/s10055-009-0132-3#ref-CR27" id="ref-link-section-d77471e372">2004</a>). Montgomery and Bruyns at Stanford University have also implemented a rat dissection simulator for astronaut training (Montgomery et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Montgomery K, Bruyns C, Wildermuth S (2001) A virtual environment for simulated rat dissection: a case study of visualization for astronaut training. Vis 2001, San Diego, California" href="/article/10.1007/s10055-009-0132-3#ref-CR16" id="ref-link-section-d77471e375">2001</a>) and Crossan has also used haptics for veterinary training (Crossan et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Crossan A, Brewster S, Reid S et al (2001) A horse ovary palpation simulator for veterinary training. In: Haptic human-computer interaction, pp 157–164" href="/article/10.1007/s10055-009-0132-3#ref-CR6" id="ref-link-section-d77471e378">2001</a>). Surgical simulators and dissection simulators are very similar in most aspects; the main differences are in the simulation models used and in the tasks performed. For example, surgical simulators focus on cutting, suturing, and other similar surgical tasks. Dissection simulators focus mainly on cutting, peeling, and grasping and do not normally require suturing tasks.</p><p>The modelling of deformable bodies has been extensively studied over the last few years in order to find appropriate models to describe their particular physical properties. Deformable models can be modelled with a geometric or physical method.</p><p>Geometric or non-mechanics based modelling approaches are not based on the object’s physical properties, such as the object’s mass or viscoelastic properties. They have fast computation times and are relatively easy to implement, but they do not take into consideration the physical (i.e. mechanical) properties of the object. Spline-based approaches (Basdogan et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Basdogan C, De S, Kim J, Manivannan M, Kim H, Srinivasan MA (2004) Haptics in minimally invasive surgical simulation and training. IEEE Comput Graph Appl 24(2):56–64" href="/article/10.1007/s10055-009-0132-3#ref-CR2" id="ref-link-section-d77471e386">2004</a>) have been studied extensively, along with using spheres to model the objects and compute deformations by means of reactive movements of small rigid interior spheres that make up the model (Suzuki et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Suzuki S, Suzuki N, Hattori A, Uchiyama A, Kobayashi S (2004) Sphere-filled organ model for virtual surgery system. IEEE Transactions Med Imaging 23(6):714" href="/article/10.1007/s10055-009-0132-3#ref-CR23" id="ref-link-section-d77471e389">2004</a>).</p><p>Mechanics-based modelling, on the other hand, satisfies the requirement that objects must look and behave realistically and the models should be based on physical laws governing the dynamic behaviour of deformable objects. The two commonly used mechanics-based approaches are mass-spring models and the finite element method (FEM) (Payandeh and Azouz <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Payandeh S, Azouz N (2001) Finite elements, mass-spring-damper systems and haptic rendering. In: Proceedings of IEEE international symposium on computational intelligence in robotics and automation, pp 224–230" href="/article/10.1007/s10055-009-0132-3#ref-CR19" id="ref-link-section-d77471e396">2001</a>; Segerlind <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1976" title="Segerlind L (1976) Applied finite element analysis. Wiley, New Jersey" href="/article/10.1007/s10055-009-0132-3#ref-CR21" id="ref-link-section-d77471e399">1976</a>). Though the finite element method offers more accurate modelling than mass-spring models, it is computationally more demanding and requires careful pre-processing and object meshing for accurate modelling. Mass-spring systems are a simple physical model with well understood dynamics (Cover et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Cover S, Norberto FE, Obrien JF, Rowe R, Gadau T, Palm E (1993) Interactively deformable models for surgery simulation. In: Proceedings of ICRA, pp 68–75" href="/article/10.1007/s10055-009-0132-3#ref-CR5" id="ref-link-section-d77471e402">1993</a>; Payandeh and Azouz <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Payandeh S, Azouz N (2001) Finite elements, mass-spring-damper systems and haptic rendering. In: Proceedings of IEEE international symposium on computational intelligence in robotics and automation, pp 224–230" href="/article/10.1007/s10055-009-0132-3#ref-CR19" id="ref-link-section-d77471e405">2001</a>; Zhang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Zhang H, Payandeh S, Dill J (2004) On cutting and dissection of virtual deformable objects. In: Proceedings of IEEE international conference on robotics and automation, pp 3908–3913" href="/article/10.1007/s10055-009-0132-3#ref-CR27" id="ref-link-section-d77471e408">2004</a>). The main advantage is their ease of interpretation and implementation since they do not require continuous parameterizations. They have been used for static as well as dynamic computation. Mass-spring models are widely used for interactive applications because they focus more on visual realism than exact physically-based deformation and require simulations to be performed in real-time (Zhang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Zhang H, Payandeh S, Dill J (2004) On cutting and dissection of virtual deformable objects. In: Proceedings of IEEE international conference on robotics and automation, pp 3908–3913" href="/article/10.1007/s10055-009-0132-3#ref-CR27" id="ref-link-section-d77471e412">2004</a>; Brown et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Brown J, Sorkin S, Bruyns C, Latombe JC, Montgomery K, Stephanides M (2001) Real-time simulation of deformable objects: tools and application. Computer animation 2001, Seoul, Korea, November 7–8" href="/article/10.1007/s10055-009-0132-3#ref-CR3" id="ref-link-section-d77471e415">2001</a>). In (Zhennan et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Zhennan Y, Lixu G, Huang P (2007) Soft tissue deformation simulation in virtual surgery using nonlinear finite element method. In: Proceedings of the 29th annual international conference of the IEEE EMBS" href="/article/10.1007/s10055-009-0132-3#ref-CR29" id="ref-link-section-d77471e418">2007</a>), finite element method (FEM) was used for surgical simulation. As well, Georgii and Westermann present a multigrid framework in (Georgii and Westermann <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Georgii J, Westermann R (2006) A multigrid framework for real-time simulation of deformable bodies. Comput Graph 30(3):409–416" href="/article/10.1007/s10055-009-0132-3#ref-CR9" id="ref-link-section-d77471e421">2006</a>) for the motion of deformable volumetric models. Brown et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Brown J, Sorkin S, Bruyns C, Latombe JC, Montgomery K, Stephanides M (2001) Real-time simulation of deformable objects: tools and application. Computer animation 2001, Seoul, Korea, November 7–8" href="/article/10.1007/s10055-009-0132-3#ref-CR3" id="ref-link-section-d77471e424">2001</a>) and Gibson (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Gibson S (1997) A survey of deformable modeling in computer graphics. Technical report no. TR-97-19, Mitsubishi Electric Research Laboratory, Cambridge MA" href="/article/10.1007/s10055-009-0132-3#ref-CR10" id="ref-link-section-d77471e427">1997</a>) are good surveys comparing the various methods of the modelling of deformable models. A newer physical model, the long element method (LEM) is based on Pascal’s Principle which can be an alternative to the finite element method (Laugier et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Laugier C, Mendoza C, Sundaraj K (2003) Towards a realistic medical simulator using virtual environments and haptic interaction. Robotics Research, volume 6 of Springer Tracts in Advanced Robotics (STAR)" href="/article/10.1007/s10055-009-0132-3#ref-CR11" id="ref-link-section-d77471e431">2003</a>; Mendoza et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Mendoza C, Sundaraj K, Laugier C (2003) Faithfull haptic feedback in medical simulators. Robotics Research, volume 5 of Springer Tracts in Advanced Robotics (STAR)" href="/article/10.1007/s10055-009-0132-3#ref-CR15" id="ref-link-section-d77471e434">2003</a>; Sundaraj <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Sundaraj K (2004) Real-time dynamic simulation and 3D interaction of biological tissue: application to medical simulators. PhD. Thesis, Institut National Polytechnique de Grenoble" href="/article/10.1007/s10055-009-0132-3#ref-CR22" id="ref-link-section-d77471e437">2004</a>).</p><p>To simulate interactions between deformable objects, all contact points need to be considered (i.e. we need to find the occurrence and location of all intersection points between instruments, deformable bodies, and other objects). Bounding-volume hierarchies (BVHs) have proven to be among the most efficient data structures for collision detection. Mostly, they have been applied to rigid body collision detection. The idea of BVHs is to partition the set of object primitives recursively until some leaf (i.e. trees) criterion is met. In (Van Den Bergen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Van Den Bergen G (1997) Efficient collision detection of complex deformable models using AABB trees. J Graphics Tools 2(4):1–14" href="/article/10.1007/s10055-009-0132-3#ref-CR26" id="ref-link-section-d77471e443">1997</a>), an approach using bounding volumes with Axis Aligned Bounding Box (AABB) Trees for deformable bodies is discussed. In (Lin and Gottschalk <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Lin M, Gottschalk S (1999) Collision detection between geometric models: a survey. In: Proceedings of IMA conference on mathematics of surfaces, pp 37–56" href="/article/10.1007/s10055-009-0132-3#ref-CR13" id="ref-link-section-d77471e446">1999</a>; Teschner et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Teschner M, Kimmerle S, Heidelberger B (2005) Collision detection for deformable objects. Comput Graphics Forum 24(1):61–81" href="/article/10.1007/s10055-009-0132-3#ref-CR24" id="ref-link-section-d77471e449">2005</a>), a comparison survey of different collision detection techniques for deformable bodies is described.</p><p>Although BVHs can be made to be computationally faster than using a distance-based method, they require time-consuming pre-processing and it was found to be unsuitable for the proposed application of this paper. In our virtual dissection application, the location of the multiple deformable bodies can easily be related to each other which can be used to avoid reducing high computational overhead. In (Pauly et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Pauly M, Pai D, Guibas L (2004) Quasi-rigid objects in contact, Eurographics/ACM SIGGRAPH symposium on computer animation" href="/article/10.1007/s10055-009-0132-3#ref-CR18" id="ref-link-section-d77471e455">2004</a>), an efficient method to handle contact between quasi-rigid objects (i.e. solids that undergo reasonable deformations, but still preserve their basic shape) is presented. Hierarchical representations and multi-level computations are used where the computation begins at the coarsest level and propagates to the next finer level using interpolation. In this paper we partition the object space to provide an efficient method for collision detection between deformable bodies. We utilize the data structure of our discrete dynamic model and the adjacency relationship between the deformable bodies (i.e. skin and organs) to detect contact.</p></div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Contact detection</h2><div class="c-article-section__content" id="Sec3-content"><p>Contact/proximity detection between multiple deformable bodies is a complex and costly process because the topology of the objects constantly change and any precomputations may become invalid when the objects deform. Due to this, detecting contact of deformable bodies remains a challenging and intricate problem.</p><p>There are a number of contact detection cases that need to be addressed for a dissection application. First, the case when the instrument (i.e. probe) collides with a deformable body (i.e. skin). Second, the case where the virtual instrument collides together with the skin and any deformable organs located underneath.</p><p>To help decrease computation time for contact detection between the instrument and the deformable body, broad phase and narrow phase methods are used to determine the exact contact/intersection points among the potential candidate vertices (Basdogan and Srinivasan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Basdogan C, Srinivasan M (2001) Haptic rendering in virtual environments. In: Stanney K (ed) Virtual environments handbook, Erlbaum, Mahwah, NJ, pp 117–134" href="/article/10.1007/s10055-009-0132-3#ref-CR1" id="ref-link-section-d77471e470">2001</a>; Mendoza et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Mendoza C, Sundaraj K, Laugier C (2003) Faithfull haptic feedback in medical simulators. Robotics Research, volume 5 of Springer Tracts in Advanced Robotics (STAR)" href="/article/10.1007/s10055-009-0132-3#ref-CR15" id="ref-link-section-d77471e473">2003</a>). Our contact detection method can be extended to add a beating heart to our virtual dissection application, where the user is able to feel the pulse. The modelling approach and analysis for defining the deformation of the skin and the organs (located under the skin) are based on mass-spring methods which will be discussed in the following section.</p><h3 class="c-article__sub-heading" id="Sec4">Physical modelling</h3><p>A dissection environment requires models for tools along with multiple deformable models (i.e. surface skin and organs). The tool models are simplified version of the tools which are used in actual dissection for a faster computational environment and to increase the haptic feedback rate in a dissection training environment. High-speed simulation of simple mechanics offers a more stable interaction in a discrete dynamic environment than more complex models.</p><p>For a dissection, three general instruments are required; a grasper (also referred to as tweezers), scalpel, and a regular probe (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig1">1</a>). The deformable model will be updated differently depending on which of the three instruments it is interacting with. All three instruments can cause the tissue to deform. The scalpel model can cut the deformable model, whereas the grasper model can grab and displace the tissue. The grasper is always in one of either two states, open or closed which can be triggered by the haptic device (e.g. to toggle between these two states, the button on the PHANToM stylus is used). The cutting of tissue will modify the underlying structure of the deformable model, whereas deforming and displacing do not change the topological structure.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Virtual instrument depiction</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Visualization is accomplished through surface polygons with an underlying triangular mesh and proper texturing for realistic appearances. For efficient collision detection, the instrument representations are also simplified to a small set of lines. For example, the grasper model for collision detection is represented by three line segments: one for the shaft and one for each jaw of the grasper. The scalpel model is represented as a line segment for the shaft and a triangle for the end.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec5">Organ modelling</h4><p>Most real-time applications use one of the two main physics-based modelling approaches, the mass-spring model and the finite element method (Gibson <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Gibson S (1997) A survey of deformable modeling in computer graphics. Technical report no. TR-97-19, Mitsubishi Electric Research Laboratory, Cambridge MA" href="/article/10.1007/s10055-009-0132-3#ref-CR10" id="ref-link-section-d77471e515">1997</a>; Sundaraj <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Sundaraj K (2004) Real-time dynamic simulation and 3D interaction of biological tissue: application to medical simulators. PhD. Thesis, Institut National Polytechnique de Grenoble" href="/article/10.1007/s10055-009-0132-3#ref-CR22" id="ref-link-section-d77471e518">2004</a>; Payandeh and Azouz <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Payandeh S, Azouz N (2001) Finite elements, mass-spring-damper systems and haptic rendering. In: Proceedings of IEEE international symposium on computational intelligence in robotics and automation, pp 224–230" href="/article/10.1007/s10055-009-0132-3#ref-CR19" id="ref-link-section-d77471e521">2001</a>). The finite element method offers more realistic modelling than the mass-spring model, but it is also computationally more demanding and requires unrealistic simplifications for real-time applications. Mass-spring models rely more on visual realism and are therefore widely used for real-time interactive application (Doo and Sabin <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1978" title="Doo D, Sabin M (1978) Behaviour of recursive division surfaces near extraordinary points. Comput Aided Des 10:356–360" href="/article/10.1007/s10055-009-0132-3#ref-CR7" id="ref-link-section-d77471e524">1978</a>). For this reason, we use a surface mass-spring system with added home springs for our dissection simulator (Payandeh and Azouz <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Payandeh S, Azouz N (2001) Finite elements, mass-spring-damper systems and haptic rendering. In: Proceedings of IEEE international symposium on computational intelligence in robotics and automation, pp 224–230" href="/article/10.1007/s10055-009-0132-3#ref-CR19" id="ref-link-section-d77471e527">2001</a>). The outer surface mesh of the models are used for graphical visualization. At each of the surface vertices of surface mesh, a spring is added which contributes to the numerical stabilization of the augmented surface mesh with the mass-spring model.</p><p>The discrete dynamic model (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig2">2</a>) is composed of vertices as a mass point (<i>m</i>) and edges as a simple linear spring (<i>k</i>
                              <sub>m</sub>) modelling the surface of the object (Tong et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Tong C, Song A, Juan W (2007) A mass-spring model for haptic display of flexible object global deformation. In: Proceedings of ICMA 2007" href="/article/10.1007/s10055-009-0132-3#ref-CR25" id="ref-link-section-d77471e544">2007</a>). A triangular mesh is used for this application where each individual triangle is composed of three vertices and three edges. When a soft elastic object deforms, the interior of the object also contributes to the shape of deformation. As mentioned above, to reflect this, a stabilizer has been added known as a “home spring” (<i>k</i>
                              <sub>h</sub>) where each node is also connected by a home spring to its initial or rest position. When instruments deform the tissue model by intersecting a triangle, feedback is calculated by summing the forces on all of the nodes of the triangle and applying the total force to the instrument.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>A portion of the mass-spring model</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>To generate the organ models, organ data were imported into the 3D Studio Max software to graphically create all the internal organs (e.g. the frog model). The export model from 3D Studio Max is a VRML file and will be input in our virtual dissection training environment. The imported data (i.e. VRML file) are then augmented with the mass-spring model combined with OpenGL rendering code in a pipeline. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig3">3</a> shows the basic flow of this process.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Process of surface extraction in our dissection simulator</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Our application requires the display of several different models: the skin model without organs underneath, the skin model (both when it is and is not in contact with an organ), models of neighbouring organs, and a model of the skin when it is peeled away to expose the organs.</p><h3 class="c-article__sub-heading" id="Sec6">Contact detection between multiple deformable bodies</h3><p>Contact detection between multiple deformable bodies can be a challenging task, even more so to make sure that the application performs in computationally efficient time (Lawlor and Kale <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Lawlor OS, Kale LV (2002) A voxel-based parallel collision detection algorithm. In: Proceedings of the 16th international conference on Supercomputing, 22–26 June, pp 285–293" href="/article/10.1007/s10055-009-0132-3#ref-CR12" id="ref-link-section-d77471e607">2002</a>). Several cases must be considered for a general dissection application. The first case is contact detection between skin and organs while the skin is being pushed by the probe. Organ–organ contact which can be further divided into two cases: first when the skin is being peeled to expose the organs and second when the probe pushes on an organ possibly causing the organ to push on other internal organs. The organ will deform at the local contact point and may also cause adjacent organs to deform. In order to model and implement these cases, we have proposed a unique data structure that utilizes the manifold proximity class adjacency relationships between the various deformable organs.</p><p>The manifold proximity class is a neighbourhood data structure that uses the location of the organs in relation to the skin to initially define a relationship between them to help speed up our contact detection. With each skin vertex located directly above an organ (e.g. along the <i>z</i> coordinate), we associate a variable that stores the organ ID. For example, <i>directly above</i> means the frontal view of the frog, where at these locations only the <i>z</i> (depth) coordinate is different between the skin vertices and the organ. Some skin vertices may have multiple organs associated with them, which are sorted according to depth from the associated skin vertex. This is used to help predict which deformable objects will collide with one another. For our scene, this division of the volume is given since the skin and the organs have a defined proximal relationship with respect to each other.</p><p>Assume the probe contacts a skin vertex. If the contacted vertex has an organ ID associated with it, then appropriate reaction forces are computed that result from the surrounding skin vertices and from the associated organ vertices. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig4">4</a> shows (frontal view of the frog) a visual example of the relationship between the skin vertices and the associated organ with 4 sample vertices (<i>v</i>
                           <sub>1</sub>, <i>v</i>
                           <sub>2</sub>, <i>v</i>
                           <sub>3</sub>, and <i>v</i>
                           <sub>4</sub>) chosen to help illustrate this concept. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig4">4</a>a also defines the directional quadrants of the frog. The top quadrant that includes vertex <i>v</i>
                           <sub>1</sub> is defined as the left and up quadrant and the quadrant that includes vertex <i>v</i>
                           <sub>2</sub> is defined as the right and up quadrant, both with respect to the centre point of the frog. The bottom quadrant with vertex <i>v</i>
                           <sub>3</sub> is classified as left and down quadrant and the quadrant with vertex <i>v</i>
                           <sub>4</sub> is the right and down quadrant again with respect to the centre of the frog. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig5">5</a> represents a conceptual model of the contact detection. The probe is contacting the skin and is colliding with organ 2 as well. The dotted lines represent the previous location of the skin. This data structure will help eliminate unnecessary costly collision checks thereby helping accelerate the simulation.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Frontal view of the virtual dissection environment showing the relationship between four skin vertices and their corresponding organs. <b>a</b> Textured model of frog, <b>b</b> Mesh model showing internal organs of frog</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Probe palpating over the skin with directional velocity <i>V</i>
                                    </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec7">Organ–organ contact detection</h3><p>We have proposed and implemented a neighbourhood data structure (i.e. similar to the manifold proximity class) for developing an efficient contact detection between the current organ in contact with the instrument and the other organs. We use the location of the organs in relation to each other to help eliminate computationally demanding collision checking. The difference between this neighbourhood data structure and that of the manifold proximity class is that the former includes relationships at the organ to organ level, whereas the latter includes relationships at the vertex to organ level. There are three main structural relationships that make up the neighbourhood data structure. These relationships are used for contact detection between the current organ in contact and other neighbouring organs.</p><p>The first structural relationship of the neighbourhood data structure is at the organ level. Each vertex of each organ will have three Boolean attributes that specify its location with respect to the entire organ, using the geometric centre (defined below) of the organ as a reference point. The three Boolean attributes within each vertex data structure are <i>left</i>, <i>up</i>, and <i>front</i>. Thus, if a vertex is on the left side of the organ in relation to its geometric centre, then <i>left</i> is set to 1. But if a vertex is on the right side, then <i>left</i> is set to 0. Hence, for each vertex the Boolean attributes are set to either left or right, up or down, or front or back of the organ with respect to its geometric centre. These location attributes are calculated at the initialization phase of the program for all organs. However, only the location attributes for the current organ in contact need to be recalculated at each time step since the current organ is the only one that will possibly change location or shape by contact.</p><p>The next relationship is at the organ vertex to organ level and calculations are only required for the vertices of the current organ in contact (i.e. current organ being displaced). This is because in our virtual dissection application, the organs are displaced one at a time and in a pre-defined order (i.e. following that of traditional dissection) allowing only the current organ to be displaced at a given time.</p><p>This relationship is between the vertices of the current organ in contact with the instrument and all the other organs. For each vertex of the current organ <i>j</i>, we compare the location of each vertex of organ <i>j</i> to the geometric centre of each of the neighbouring organs to determine the directional relationship between them. Hence, each vertex of organ <i>j</i> will contain an array of vectors, where <i>n</i> is defined as the total number of organs (currently 9) and the vector specifies the relative location of the geometric centre of organ (<i>j</i>), with respect to the current vertex (i.e. left, right, above, below, and front or back).</p><p>The third relationship determines the relationship at the organ to organ level. The organ in contact with the instrument will have a relationship defined with respect to all other organs, using their geometric centres. This organ to organ relationship is computed for the first time once the current organ in contact (say <i>j</i>) is determined. Then at each time step, it needs to be recalculated when the organ starts to move or for any organ collision due to deformation. The above relationship needs to be re-calculated only for the organs that are located in the direction of the movement of <i>j</i>. This further reduces unnecessary calculations.</p></div></div></section><section aria-labelledby="Sec8"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Contact deformation</h2><div class="c-article-section__content" id="Sec8-content"><p>Once contact has been detected between deformable objects, they will deform at the corresponding location of contact. The relative position of the each vertex will be computed with respect to one another using the underlaying mass-spring system.</p><p>We have incorporated several penalty-based contact responses, depending on the type of physical model used. Penalty-based methods use integration techniques to calculate displacement based on the applied force at the region of contact. The penalty-based method is primarily used for its simplicity and requires a penetration measurement (e.g. depth, volume, etc.) which is given by the contact detection algorithm. We will first review the virtual instrument in contact with a deformable body (e.g. skin or organ). The next case is the virtual instrument being in contact with a deformable body where there is another deformable body directly underneath (e.g. instrument in contact with skin on top of an organ). The scenarios and models will now be compared and discussed.</p><h3 class="c-article__sub-heading" id="Sec9">Deformation on contact of rigid instrument with deformable body</h3><p>The deformation on contact of the instrument with a deformable body begins by first detecting a collision point, i.e. vertex <i>i</i>, on the deformable body (e.g. skin). Based on Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig6">6</a>, <i>i</i> would be the point of exact contact of the skin and the probe. The force vector, <i>F</i>
                           <sub>
                    <i>i</i>
                  </sub> for <i>i</i> is computed by using the following equation:</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Calculating force on vertex <i>i</i> (with displacement ∆<i>p</i> to <i>i</i>’)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div id="Equa" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ F_{i} = - K_{\text{d}} V_{i} + K_{\text{h}} l_{h} + K_{\text{m}} \sum \left( {L_{ji} /L_{ji'} } \right)\left( {L_{ji'} - r_{ji} } \right) + f_{i}^{{e}} $$</span></div></div><p>where <i>K</i>
                           <sub>m</sub> is a mesh spring constant, <i>K</i>
                           <sub>h</sub> is a home spring constant, <i>K</i>
                           <sub>d</sub> is the damping constant, <i>L</i>
                           <sub>
                    <i>ji</i>
                  </sub> is the length between adjacent vertices <i>j</i> and <i>i</i>, <i>L</i>
                           <sub>
                    <i>ji′</i>
                  </sub> is the magnitude of the vector between vertices <i>j</i> and <i>i</i>, <i>l</i>
                           <sub>
                    <i>h</i>
                  </sub> is a displacement vector from the vertices position, <i>f</i>
                           <span class="c-stack">
                    <sup><i>e</i></sup><sub>
                      <i>i</i>
                    </sub>
                    
                  </span> is the external force applied on <i>K</i>
                           <sub>m</sub>, <i>r</i>
                           <sub>
                    <i>ji</i>
                  </sub> is the rest length of <i>K</i>
                           <sub>m</sub> and V<sub>
                    <i>i</i>
                  </sub> is the velocity when the instrument intersects vertex <i>i</i>.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig6">6</a> displays a representation of the force calculation for a given vertex. Vertex <i>i</i> in the diagram has three adjacent edges and vertices and is displaced by <i>∆p</i>. Explicit Euler’s method is used to obtain the acceleration, velocity, and position based on the computed force. Refer to (Burden and Faires <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Burden RL, Faires JD (2000) Numerical analysis. Brooks-Cole" href="/article/10.1007/s10055-009-0132-3#ref-CR4" id="ref-link-section-d77471e971">2000</a>) for details of the explicit Euler’s method.</p><p>If we apply Euler’s method to all vertices of our mass-spring model it is easy to see that for one computational cycle, we will require considerable resources. As a result, to improve efficiency, we were led to search for a technique that would reduce computation. We use the technique known as local deformation, in which the deformation calculation is localized to a limited area surrounding the region in contact.</p><p>Essentially, with local deformation, force <i>F</i>
                           <sub>
                    <i>i</i>
                  </sub> propagates to its neighbouring vertices causing the neighbouring vertices to displace until the calculated force is smaller than a threshold (in our case 0.05 N) [32] (Zhang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Zhang J, Payandeh S, Dill J (2005) A study of level-of-detail in haptic rendering. ACM Trans Appl Percept 2(1):15–34" href="/article/10.1007/s10055-009-0132-3#ref-CR28" id="ref-link-section-d77471e988">2005</a>). To implement such a method, calculation begins with the intersected vertices. Deformation of each displaced vertex is calculated and if the total force is bigger than the threshold, we then traverse to their neighbouring vertices.</p><p>Local deformation also provides a continuous sequence of deformation (i.e. “sliding” effect), with force <i>F</i>
                           <sub>
                    <i>i</i>
                  </sub> propagating to its neighbouring vertices causing them to also displace. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig7">7</a> demonstrates this by showing a sample of our virtual frog dissection application. The “sliding” effect occurs as a combination of both force propagation and the continuous calculations of the two deformation phases for each new collision point. The following pseudocode illustrates the complete deformation algorithm and “sliding” effect:</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig7_HTML.gif?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig7_HTML.gif" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Demonstration of “Sliding” in a virtual dissection application. All screen shots together demonstrate the probe palpating over the skin. <b>a</b> Sliding of probe begins, <b>b</b> probe slides along skin, <b>c</b> Probe continues sliding, and <b>d</b> Sliding of probe ends</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>NEIGHBOUR_DEFORMATION (vertex <i>i</i>)</p><ol class="u-list-style-none">
                    <li>
                      <span class="u-custom-list-number">1.</span>
                      
                        <p><b>for</b> (all neighbours <i>n</i> of <i>i</i>)</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">2.</span>
                      
                        <p>
                          <b>do</b>
                          <span class="mathjax-tex">\( F_{n} = k_{h} l_{h} + k\sum {{\frac{{L_{jn} }}{{L_{jn'} }}}(L_{jn'} - r_{jn} ) + f_{n}^{e} } \)</span>
                        </p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">3.</span>
                      
                        <p><span class="mathjax-tex">\( \Updelta p = \iint {{\frac{f}{m}}}{\text{d}}t{\text{d}}t \)</span> //position based on Euler’s method</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">4.</span>
                      
                        <p><span class="mathjax-tex">\( F = - k\Updelta p \)</span> //force based on displacement</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">5.</span>
                      
                        <p>map <i>F</i> and send to haptic device</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">6.</span>
                      
                        <p><b>if</b> (<i>F</i> &lt; 0.05)</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">7.</span>
                      
                        <p>
                          <b>return</b>
                        </p>
                      
                    </li>
                  </ol>
                        <p>The pseudocode above calculates the following: an initial net force is calculated for contact vertex <i>i</i> (line 2 of pseudocode), followed by the new position of <i>i</i> (using Euler’s method, line 3), then the applied Force <i>F</i> based on Hooke’s Law is calculated (line 4) and <i>F</i> is mapped and sent to haptic device (line 5 of pseudocode). The “sliding” effect continues until the force <i>F</i> is below our set threshold of 0.05.</p><h3 class="c-article__sub-heading" id="Sec10">Deformation of multiple deformable bodies</h3><p>In this section, we propose and study an interaction model for the case when the instrument interacts with multiple deformable bodies. This includes the skin (in our case) that has other bodies (organs) located underneath. We extend our manifold proximity class data structure briefly mentioned in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0132-3#Sec9">4.1</a> by adding a relationship between the skin and the organs.</p><p>The main idea of the manifold proximity class is to take advantage of the neighbourhood data structure (described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0132-3#Sec6">3.2</a>). Since the geometric relationship between the organs and the skin is initially known, certain vertices of the skin and organs are connected with additional springs. This connecting spring is distinct from and is in addition to the home springs and mesh springs of the skin and organs. The vertices of the skin are connected to organs that are located directly below it (i.e. have a defined proximal relationship with respect to each other).</p><p>When the probe is in contact with a skin vertex which is connected to a vertex on an organ, the deformation of the skin vertex in contact is determined as a function of probe motion with the inclusion of two additional steps. The first step is the addition of the force from the spring connecting the skin vertex to the organ vertex. The second step is the calculation of the displacement vector (deformation) based on the force generated by the spring that connects the skin vertex to the organ vertex (based on the force from step 1).</p><p>Thus, for the first step when vertex <i>i</i> moves with respect to vertex <i>j</i>, the force in the spring <i>k</i>
                           <sub>
                    <i>ij</i>
                  </sub> can be computed such that it can exert force on both the skin vertex and the connecting organ vertex, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig8">8</a> for vertex <i>i</i> connected to vertex <i>j</i> by spring <i>k</i>
                           <sub>
                    <i>ij</i>
                  </sub>. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig9">9</a> depicts the conceptual representation of the relationship between the skin and 2 organs. In this figure vertices i <i>−</i> 1, <i>i</i>, and <i>i</i> <i>+</i> 1 represent three vertices of the skin mesh. Vertices <i>j</i> <i>−</i> 1, <i>j</i>, and <i>j</i> <i>+</i> <i>1</i> represent three vertices of organ mesh 1 and vertices <i>k</i> <i>−</i> 1, <i>k</i>, and <i>k</i> <i>+</i> <i>1</i> represent three vertices of organ mesh 2. Spring <i>k</i>
                           <sub>
                    <i>ij</i>
                  </sub> connects the skin to organ 1 and spring <i>k</i>
                           <sub>
                    <i>ik</i>
                  </sub> connects the skin to organ 2, respectively.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig8_HTML.gif?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig8_HTML.gif" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Illustration of connecting spring (<i>K</i>
                                       <sub>
                            <i>ij</i>
                          </sub>) between deformable body <i>i</i> and deformable body <i>j</i>
                                    </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig9_HTML.gif?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig9_HTML.gif" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Illustration of connecting spring (<i>K</i>
                                       <sub>
                            <i>ij</i>
                          </sub>) between deformable skin and <i>2</i> organs</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>A computational approach similar to that described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0132-3#Sec9">4.1</a> can now be followed. The force <i>F</i>
                           <sub>
                    <i>i</i>
                  </sub> on vertex <i>i</i> is computed with the addition of the force from the spring <i>k</i>
                           <sub>
                    <i>ij</i>
                  </sub> (and damper) which connects the skin vertex to the organ vertex. The spring constant of the connecting spring is defined as a function of the distance of the organ from the skin. The closer the organ is to the skin, the higher the spring constant and vice versa. Although the force calculation of an organ depends on its stiffness parameters, generally speaking, the closer an organ is to the skin, the more haptic force the user feels (lump or hardening of deformation under the skin) while gliding over such an area with the probe. Refer to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig10">10</a>a and b for before and after screen shots of our simulation that demonstrate the deformation method. The coloured meshes in the figures represent organs under the skin. Organ deformation is shown clearly in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig10">10</a>b illustrating the manifold proximity class algorithm.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig10_HTML.gif?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig10_HTML.gif" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Contact deformation. <b>a</b> Before contact, <b>b</b> after contact while deforming the skin along with the organ in contact</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        </div></div></section><section aria-labelledby="Sec11"><div class="c-article-section" id="Sec11-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec11">Virtual peeling</h2><div class="c-article-section__content" id="Sec11-content"><p>Tissue grasping (i.e. pinching) involves grasping a fragment of tissue between the jaws of the grasper and possibly moving the tissue fragment away if the applied force exceeds some set threshold. In our simulation model, the peeling process involves peeling away each side of the stomach region of skin (left and right) to expose the organs underneath after this region has been separated by cutting (Lawlor and Kale <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Lawlor OS, Kale LV (2002) A voxel-based parallel collision detection algorithm. In: Proceedings of the 16th international conference on Supercomputing, 22–26 June, pp 285–293" href="/article/10.1007/s10055-009-0132-3#ref-CR12" id="ref-link-section-d77471e1459">2002</a>). Using a grasper (or tweezers), the user pinches the skin and begins to pull it away to expose the organs. This is performed for both sides of the stomach region.</p><p>To initiate vertex movements of the deformable body (to simulate peeling), an additional home-spring base layer is added to the surface mesh. The additional home-springs are connected to the surface mesh at a distance between the skin and organ mesh. The forces generated along these home-springs are monitored to determine the initiation of the peeling process. In terms of the mass-spring model, the additional vertex (i.e. mass <i>m</i>
                        <sub>
                  <i>j</i>
                </sub>) connects to the surface vertex (mass <i>m</i>
                        <sub>
                  <i>i</i>
                </sub>) by the home spring <i>k</i>
                        <sub>h</sub> (which can have zero initial length). Then <i>m</i>
                        <sub>
                  <i>j</i>
                </sub> is connected to <i>K</i>
                        <sub>h0</sub> (additional home-spring) that acts as a base anchor. This second surface is actually a “virtual” segment in that it is not involved in any physical model computations and is not visible to the user. The entire second surface along with the base <i>K</i>
                        <sub>h0</sub> can be considered as an anchor for the skin. See Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig11">11</a> for such a conceptual representation.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig11_HTML.gif?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig11_HTML.gif" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Contact schematic of underlying peeling model with <i>K</i>
                                    <sub>h</sub> as a home spring connected to the base quasi home-spring <i>K</i>
                                    <sub>h0</sub> by mass <i>m</i>
                                 </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>As the user pulls the skin to expose the organs, the forces on the home springs and quasi home-springs are monitored for exceeding a threshold. If the current force doubles from the force at the initial point of contact, the stiffness value (i.e. <i>k</i>
                        <sub>h</sub>) of that home spring is set to zero. As a result, the surface mesh moves away from its initial configuration (i.e. deformable body will start to move in the direction of the force). For our virtual dissection application, once the peeling of abdominal region has exposed the internal organs, the peeling method stops. The condition used to determine this is scene dependent and is determined on the first location of where the abdomen region has exposed the internal organs.</p><p>Once the force threshold has been exceeded, the peeling begins. The home positions (i.e. initial position of each vertex at the start of the application) of each vertex are recomputed (relocated) using the calculated deformation force, <i>F</i>
                        <sub>
                  <i>i</i>
                </sub>, generated by the springs connected to the intersected triangle’s vertices (as explained in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0132-3#Sec8">4</a>). This force, <i>F</i>
                        <sub>
                  <i>i</i>
                </sub>, when applied to the model’s vertices will move their home positions. This is computed using Euler’s method.</p><p>An inverse kinematics procedure has been applied to ensure that the peeling can simulate the expected properties of the deformable body. We have selected a maximum deformation rate of 15–20% for skin (Doo and Sabin <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1978" title="Doo D, Sabin M (1978) Behaviour of recursive division surfaces near extraordinary points. Comput Aided Des 10:356–360" href="/article/10.1007/s10055-009-0132-3#ref-CR7" id="ref-link-section-d77471e1580">1978</a>), so that the deformable body cannot “stretch” beyond a certain limit. This is the case before and during peeling; all the vertices cannot move past a pre-defined set critical threshold. To ensure the spring lengths do not exceed their natural stretch lengths, a critical arbitrary stretch threshold (<i>T</i>
                        <sub>c</sub>) of 20% is set. If this condition is met, then an inverse kinematics procedure is applied to each spring so that its deformation rate equals <i>T</i>
                        <sub>c</sub>.</p><p>There are three different cases to consider for the inverse kinematics procedure as well as two types of vertices (“unbound” vertex and “anchor” vertex) used for the peeling model. The “unbound” type vertex allows displacement and the “anchor” type vertex remains fixed in position. The anchor vertices will be located along the intersecting region of the abdomen region to keep the peeled skin connected to the rest of the skin model (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig12">12</a>). The anchor vertices are represented as small white spheres in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig12">12</a> and the unbound vertices are all the rest of the vertices in the abdomen region. There are three cases we need to consider during peeling with “anchored” and “unbound” vertices as illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig13">13</a>. The first case is both vertices of the spring being “unbound”; then both will be evenly brought closer to their middle so that the spring reaches its <i>T</i>
                        <sub>c</sub>. The next case considers one vertex as “unbound”, and the “unbound” vertex is brought closer to the fixed end so as to reach the critical threshold, <i>T</i>
                        <sub>c</sub>. If both vertices are “anchored”, then they are left unchanged. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig13">13</a> represents the above three cases pictorially. The vertices are anchored in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig13">13</a>a and neither can therefore be displaced. One vertex in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig13">13</a>b is unbound and its displacement is adjusted to remain with the critical threshold, <i>T</i>
                        <sub>c</sub> and the unbound vertex is moved to its adjusted location as in the diagram to the right. Finally, in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig13">13</a>c both vertices are unbound and both of their displacement amounts are adjusted within the critical threshold, <i>T</i>
                        <sub>c</sub> and both vertices are moved to their adjusted locations.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig12_HTML.jpg?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig12_HTML.jpg" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Virtual peeling. Sample screen shot with “anchor” type vertices (defined above) shown as small spheres</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-13"><figure><figcaption><b id="Fig13" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 13</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/13" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig13_HTML.gif?as=webp"></source><img aria-describedby="figure-13-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig13_HTML.gif" alt="figure13" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-13-desc"><p>Principle method of the three (<b>a</b>, <b>b</b>, <b>c</b>) adjustment procedures to ensure critical threshold holds</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/13" data-track-dest="link:Figure13 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Once the skin has been peeled away, fully exposing the internal organs, then the peeling stops and a graphical pin is placed to keep the peeled skin in place. For now, since the location of the frog with respect to the scene is known, we use a simple location method to determine when to end the peeling. While peeling, the current vertex locations are compared against a threshold location (i.e. the minimum location outside the internal abdomen region). Once they are past this threshold then the peeling process is finished and a pin is inserted in place (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig14">14</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-14"><figure><figcaption><b id="Fig14" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 14</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/14" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig14_HTML.jpg?as=webp"></source><img aria-describedby="figure-14-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig14_HTML.jpg" alt="figure14" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-14-desc"><p>Virtual peeling. Sample screen shots (<b>a</b>, <b>b</b>, <b>c</b>) of peeling process separated into three sequential sections. <b>a</b> Peeling on left begins, <b>b</b> peeling on left continues, <b>c</b> peeling on left side ends</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/14" data-track-dest="link:Figure14 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig15">15</a> shows a plot of forces (force values are in Newton) generated at the tip of the tweezer during the peeling of one side of the skin (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig14">14</a>). Essentially, the more the skin is stretched during peeling, the more reaction force is felt by the user. Once the peeling begins, the force plot (segment 1, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig15">15</a>a) slowly increases and then there are some rapid jumps in the force values (segment 2, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig15">15</a>b). These jumps will occur and magnify if the user does not stretch the skin at a constant velocity (since force is proportional to velocity). That is why segment 2 of the plot is so jerky and not smooth. Once the peeling is done (segment 3, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig15">15</a>c), there is a noticeable rapid decrease in the force.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-15"><figure><figcaption><b id="Fig15" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 15</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/15" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig15_HTML.gif?as=webp"></source><img aria-describedby="figure-15-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig15_HTML.gif" alt="figure15" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-15-desc"><p>Force plot of peeling motion from Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig14">14</a> separated into 3 numbered segments corresponding to (<b>a</b>), (<b>b</b>), and (<b>c</b>), respectively</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/15" data-track-dest="link:Figure15 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Effectively, when contact is made with the skin and while it is being peeled and stretched in the direction along the skin surface, it is possible to map the reaction force of the skin being pulled; this reaction force is relative to the amount of stretch in the skin.</p></div></div></section><section aria-labelledby="Sec12"><div class="c-article-section" id="Sec12-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec12">Haptic feedback</h2><div class="c-article-section__content" id="Sec12-content"><p>Haptic feedback can help increase the realism of the virtual system when the user anticipates natural behaviour of the interacting objects. In other words, the user is able to “feel” virtual objects in a simulated environment. Our current system uses a PHANToM Haptic Device which provides haptic feedback to the user as they interact with virtual objects. Reaction forces generated during interaction with the deformable objects (i.e. deformation) are computed and sent to the haptic device. This section first discusses our technique used to help increase our haptic feedback refresh rate. We then review some of our force plots for different dissection scenarios.</p><h3 class="c-article__sub-heading" id="Sec13">Stable control of haptic feedback</h3><p>A common problem in haptics is that the user may perceive unrealistic behaviour, for example, high frequency buzzing or vibrations (Basdogan and Srinivasan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Basdogan C, Srinivasan M (2001) Haptic rendering in virtual environments. In: Stanney K (ed) Virtual environments handbook, Erlbaum, Mahwah, NJ, pp 117–134" href="/article/10.1007/s10055-009-0132-3#ref-CR1" id="ref-link-section-d77471e1796">2001</a>). There are a few reasons that this behaviour may occur, like perception of force magnitude and direction. The direction of force changing between time steps may cause unstable vibration (i.e. <i>buzzing effect</i>) to occur. Too large a change in force between time steps may cause <i>buzzing</i> to occur as well. The fact that the refresh rate for the haptic feedback needs to be an order of magnitude higher than that of the graphic refresh rate creates difficulties to provide realistic deformable models with continuous force-feedback.</p><p>An extrapolation method using the instrument’s previous positions is used to help increase the haptic feedback refresh rate and help stabilize the behaviour of haptic feedback (Palmerius et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Palmerius KL, Cooper M, Ynnerman A (2008) Haptic rendering of dynamic volumetric data, visualization and computer graphics. IEEE Transactions 14(2):263–276" href="/article/10.1007/s10055-009-0132-3#ref-CR17" id="ref-link-section-d77471e1808">2008</a>; Lundin et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Lundin K, Cooper M, Ynnerman A (2007) Enabling design and interactive selection of haptic modes. Virtual Real J 11(1):1–13" href="/article/10.1007/s10055-009-0132-3#ref-CR14" id="ref-link-section-d77471e1811">2007</a>).</p><p>To calculate the extrapolated force, tool positions and computed forces from the previous two time steps are used. The equation is as follows (Picinbono and Lombardo <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Picinbono G, Lombardo J (1999) Extrapolation: a solution to force feedback. In: International scientific workshop on virtual reality and prototyping, Laval, France, pp 117–125" href="/article/10.1007/s10055-009-0132-3#ref-CR20" id="ref-link-section-d77471e1817">1999</a>):</p><div id="Equb" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ F^{p} \left( t \right) = F_{n} + {\frac{{\left\| {P' - P_{n} } \right\|}}{{P_{n} - P_{n - 1} }}}\left( {F_{n} - F_{n - 1} } \right)\quad t_{n} \le t &lt; t_{n + 1} $$</span></div></div>
                        <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig16">16</a> is a conceptual representation of the above equation, where <i>P</i>
                           <sub><i>n</i>−1</sub> and <i>P</i>
                           <sub>
                    <i>n</i>
                  </sub>, are the tool positions from the previous two time steps, respectively. <i>F</i>
                           <sub><i>n</i>−1</sub> and <i>F</i>
                           <sub>
                    <i>n</i>
                  </sub>, are the calculated forces from the previous two time steps, respectively, and <i>P</i> is the current position of the instrument.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-16"><figure><figcaption><b id="Fig16" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 16</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/16" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig16_HTML.gif?as=webp"></source><img aria-describedby="figure-16-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig16_HTML.gif" alt="figure16" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-16-desc"><p>Graphical representation for linear extrapolation over position of instrument motion</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/16" data-track-dest="link:Figure16 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The extrapolation method described for our virtual dissection simulator gives the user good haptic sensation, so that vibrations are not felt by the user. Without this extrapolation method, the haptic refresh rate was about 200 Hz for the dissection application. This is an acceptable rate, but not ideal. The method has raised the haptic rate to about 700 Hz, much closer to the ideal 1,000 Hz.</p><p>An image of the dissection setup can be seen in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig17">17</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-17"><figure><figcaption><b id="Fig17" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 17</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/17" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig17_HTML.jpg?as=webp"></source><img aria-describedby="figure-17-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig17_HTML.jpg" alt="figure17" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-17-desc"><p>Dissection setup using a PHANToM Omni device</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/17" data-track-dest="link:Figure17 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec14">Contact forces</h3><p>After having implemented the manifold proximity class algorithm with the virtual dissection application, a few scenarios were tested and analyzed. Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig18">18</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig20">20</a> show an example of probe trajectories while sliding over the skin with organ 1 and organ 2 beneath.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-18"><figure><figcaption><b id="Fig18" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 18</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/18" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig18_HTML.gif?as=webp"></source><img aria-describedby="figure-18-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig18_HTML.gif" alt="figure18" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-18-desc"><p>Trajectory of the probe over two organs separated into 5 numbered segments</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/18" data-track-dest="link:Figure18 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The dotted red line in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig18">18</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig20">20</a> represents the path of the probe as controlled by the user. Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig19">19</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig21">21</a> show plots of reaction forces as a function of the position of the probe sliding on the skin and gliding over top of the organs in relation to Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig18">18</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig20">20</a>, respectively. Once the probe glides over an organ, the computed force can be mapped to allow the user to experience a haptic sensation of a “lump” or hardening of deformation under the skin.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-19"><figure><figcaption><b id="Fig19" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 19</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/19" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig19_HTML.gif?as=webp"></source><img aria-describedby="figure-19-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig19_HTML.gif" alt="figure19" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-19-desc"><p>Force plot of probe motion corresponding to the numbered segments in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig18">18</a>
                                    </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/19" data-track-dest="link:Figure19 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-20"><figure><figcaption><b id="Fig20" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 20</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/20" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig20_HTML.gif?as=webp"></source><img aria-describedby="figure-20-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig20_HTML.gif" alt="figure20" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-20-desc"><p>Trajectory of the probe over two organs separated into 5 numbered segments</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/20" data-track-dest="link:Figure20 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-21"><figure><figcaption><b id="Fig21" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 21</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/21" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig21_HTML.gif?as=webp"></source><img aria-describedby="figure-21-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig21_HTML.gif" alt="figure21" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-21-desc"><p>Force Plot of probe motion corresponding to the numbered segments in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig20">20</a>
                                    </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/21" data-track-dest="link:Figure21 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>In this study, the probe’s path is separated into 5 sections. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig19">19</a> begins with a relatively low and steady force (segment 1); once the probe glides over top of organ 1 (segment 2 of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig18">18</a>), the force rapidly increases. Once contact with organ 1 ends (segment 3), the force value drops to its initial, low value. When the probe subsequently reaches contact with organ 2 (segment 4), a second significant rise in the force value is seen; finally, once the probe leaves contact with organ 2, the force value again drops (segment 5).</p><p>Heuristically, the force values for probe contact over organ 2 is slightly higher than that of organ 1. This is because the spring parameters are a function of organ location with respect to the skin. Since organ 2 is closer to the surface of the skin, it is assigned a higher spring parameter resulting in higher force values and deformation.</p><p>There is less fluctuation in the force values of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig21">21</a> than in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig19">19</a>. This is because organs 1 and 2 in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig21">21</a> are closer to each other and to the skin than in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig18">18</a>. As a result, when the probe reaches contact with organ 1 (segment 2) and then moves between the two organs (segment 3), the force value will not drop as much as it does in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig19">19</a>. This happens for two reasons: the probe coming in contact with organ 2 (segment 4) immediately after it leaves organ 1, and the higher spring parameters assigned to the organs.</p><p>In the previous study, the probe deforms along a path with only the surface mesh (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig22">22</a>). As anticipated, the reaction forces shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig23">23</a> are lower than those in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig19">19</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig21">21</a>. In the computation of force response, the organ is also contributing a reaction force due to our manifold proximity class where the organ is connected by a spring to the surface skin mesh.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-22"><figure><figcaption><b id="Fig22" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 22</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/22" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig22_HTML.gif?as=webp"></source><img aria-describedby="figure-22-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig22_HTML.gif" alt="figure22" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-22-desc"><p>Trajectory of the probe over skin without any organs underneath</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/22" data-track-dest="link:Figure22 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-23"><figure><figcaption><b id="Fig23" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 23</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/23" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig23_HTML.gif?as=webp"></source><img aria-describedby="figure-23-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig23_HTML.gif" alt="figure23" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-23-desc"><p>Force plot of probe motion from path of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig22">22</a>
                                    </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/23" data-track-dest="link:Figure23 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        </div></div></section><section aria-labelledby="Sec15"><div class="c-article-section" id="Sec15-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec15">User study and results</h2><div class="c-article-section__content" id="Sec15-content"><p>A user study was conducted that was designed to identify the effects of haptic feedback in usage of the virtual dissection training environment (which is also the main hypothesis of our study). The entire dissection process was broken down into three individual tasks that each user participated in, such as cutting, peeling, and placing organs in a tray. Each task was performed using a PHANToM device with two different conditions. The first condition used haptic feedback as a multimodal cue to help provide guidance in response to the user’s action. The second condition provided no haptic feedback to the user as they performed the assigned task. Participants were asked to perform the tasks as fast and as accurately as possible. The subjective open-ended questionnaire (refer to Appendix A for questionnaire) was completed after the completion of all the tasks. Ten high school students (7 females and 3 males, between the ages of 14 and 18) participated in this study, with a median age of 17.</p><h3 class="c-article__sub-heading" id="Sec16">Experimental set-up overview</h3><p>The experiment was conducted on a workstation with dual Intel Pentium 4 3.2 GHz processors and 512 MB of RAM, running Microsoft Windows XP 2002. The haptic device used is a PHANToM with six degrees of freedom of positional sensing and three degrees of freedom in force feedback.</p><p>The virtual dissection training environment was developed using Microsoft Visual C++ 6.0, using OpenHaptics (API for the PHANToM device) for haptic rendering and OpenGL 2.0 and GLUT 3.7 for graphical rendering. Refer back to Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig24">24</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig25">25</a> showing the interface used in the experiment for the first and second tasks. In each task, a different state of the frog will appear along with a different virtual instrument.</p><h3 class="c-article__sub-heading" id="Sec17">Experiment design</h3><p>This experiment used a single-factor within-subjects design. The first cutting task specifically asked the participant to cut along three dotted lines along the abdomen region using a PHANToM. Once the participant finished cutting, the cut area would be separated and the task was complete. The second task required the participants to peel each side of the abdomen skin to expose the internal organs. The third task required the participants to detach an organ (i.e. liver) and place it into a labelled tray. Each of the three tasks was performed under both conditions of haptic feedback and no force feedback.</p><p>Each participant performed 10 trials per condition (i.e. force feedback and no feedback), 60 trials in total. The order in which the conditions within each task were presented to the participant was random (i.e. in some cases the haptic feedback condition, followed by no feedback presented or vice versa) to limit any external factors that could affect the validity of the results. However, the order in which the tasks were presented to each participant was always the same for consistency of results. Trial times were recorded, as were certain performance metrics (described in the Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0132-3#Sec15">7</a>) for each task. Participants also completed background questionnaires and open-ended subject questionnaires.</p><p>Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig24">24</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig25">25</a>, and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig26">26</a> show images of our virtual dissection setup for each of the three tasks, cutting, peeling, and displacing organs, respectively.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-24"><figure><figcaption><b id="Fig24" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 24</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/24" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig24_HTML.jpg?as=webp"></source><img aria-describedby="figure-24-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig24_HTML.jpg" alt="figure24" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-24-desc"><p>Dissection setup while user is cutting</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/24" data-track-dest="link:Figure24 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-25"><figure><figcaption><b id="Fig25" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 25</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/25" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig25_HTML.jpg?as=webp"></source><img aria-describedby="figure-25-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig25_HTML.jpg" alt="figure25" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-25-desc"><p>Dissection setup while user is peeling</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/25" data-track-dest="link:Figure25 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-26"><figure><figcaption><b id="Fig26" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 26</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/26" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig26_HTML.jpg?as=webp"></source><img aria-describedby="figure-26-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig26_HTML.jpg" alt="figure26" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-26-desc"><p>Dissection setup while user is displacing organs</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/26" data-track-dest="link:Figure26 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec18">Hypotheses</h3><p>We expected the participants to prefer haptic feedback while using our virtual dissection environment rather than no haptic feedback. As a result of the added haptic cue, we predicted better (lower) performance times for the tasks using haptic feedback than for no feedback. Implicitly we also expected performance times to improve for each task with each added trial, with participants having little difficulty after 20 total trials per task. This also implies that we also expect the participant to have a slower trial time if they performed the task with greater accuracy.</p><h3 class="c-article__sub-heading" id="Sec19">User study results</h3><p>Participant performance metrics and trial times were recorded for each of the three tasks. The performance metric for the cutting task is the deviation of the actual cut from the predetermined path for each trial (Zhou et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006a" title="Zhou M, Claffee K, Lee K, McMurray G (2006a) Cutting, ‘by pressing and slicing’, applied to the robotic cut of bio-materials, Part I: modeling of stress distribution. In: Proceedings ICRA06, pp 2896–2901" href="/article/10.1007/s10055-009-0132-3#ref-CR30" id="ref-link-section-d77471e2241">2006a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Zhou M, Claffee K, Lee K, McMurray G (2006b) Cutting, ‘by pressing and slicing’, applied to the robotic cut of bio-materials, Part II: force during slicing and pressing cuts. In: Proceedings of ICRA06, pp 2256–2261" href="/article/10.1007/s10055-009-0132-3#ref-CR31" id="ref-link-section-d77471e2244">b</a>) For the peeling task, the number of times the tissue is “re-grasped” during the trial is recorded as a performance metric. Finally, for the displacing organ task, the number of collisions with other organs of the frog is recorded for each trial as a performance metric. For the trial times, the worst time (longest time) was eliminated for each participant to provide a more accurate average trial time. This method is used to deal with the case, where a user had one trial much greater than the rest of the trial times. If this trial time was included in the calculation of the average time, the average would be much greater than if it had not been included.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec20">Task 1: cutting</h4><p>For the cutting task, trial times were recorded, with both force and no force conditions in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig27">27</a>. The trial times for the force condition were lower than those of the no force condition. The average time improvement for all participants between force and no force condition was approximately 20%. Most participants performed the task within approximately similar blocks of time. The mean of the trial time for the force condition over all participants was 28.76 s, with a standard deviation of 10.24. The mean of the trial time for the no force condition over all participants was 42.18 s, with a standard deviation of 17.78.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-27"><figure><figcaption><b id="Fig27" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 27</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/27" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig27_HTML.gif?as=webp"></source><img aria-describedby="figure-27-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig27_HTML.gif" alt="figure27" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-27-desc"><p>Comparing average time of both force and no force modules of cutting task for all 10 participants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/27" data-track-dest="link:Figure27 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig28">28</a> compares the calculated deviation between the actual cut path and the predefined path for both force and no force conditions for each participant. The deviation is computed by calculating the area between the two paths. As each path is represented by a set of straight line segments and defined by the intersection points of the instrument and tissue model, triangles are formed between the predefined path and actual path. The mean of the cut path deviation for the force condition over all participants was 1.87, with a standard deviation of 1.09. The mean of the cut path deviation for the no force condition over all participants was 2.08, with a standard deviation of 1.33.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-28"><figure><figcaption><b id="Fig28" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 28</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/28" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig28_HTML.gif?as=webp"></source><img aria-describedby="figure-28-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig28_HTML.gif" alt="figure28" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-28-desc"><p>Comparing deviation of cut path of both force and no force modules of cutting task for all 10 participants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/28" data-track-dest="link:Figure28 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig29">29</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig30">30</a> plot the deviation of the cut path for all 10 users versus time for both force and no force conditions, respectively. These plots are combinations of the two metrics (i.e. trial time, deviation) from Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig27">27</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig28">28</a>. We notice a general trend of greater deviation for shorter trial times and less deviation for longer trial times, complying with our hypothesis. A possible explanation for such a trend could apply to the fact that all the participants had little exposure using a haptic device, so they would require greater time to perform the task with greater accuracy. Perhaps with an expert user of the simulation task, this would not be the case since they could perform the task with greater accuracy and less time. Although we have shown that this preliminary user study does indeed support the claims of our hypothesis, we cannot yet statistically prove any general claims or conclusions.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-29"><figure><figcaption><b id="Fig29" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 29</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/29" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig29_HTML.gif?as=webp"></source><img aria-describedby="figure-29-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig29_HTML.gif" alt="figure29" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-29-desc"><p>Plot comparing deviation of cut path vs. time for force condition of cutting task for all 10 participants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/29" data-track-dest="link:Figure29 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                              <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-30"><figure><figcaption><b id="Fig30" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 30</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/30" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig30_HTML.gif?as=webp"></source><img aria-describedby="figure-30-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig30_HTML.gif" alt="figure30" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-30-desc"><p>Plot comparing deviation of cut path vs. time for no force condition of cutting task for all 10 participants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/30" data-track-dest="link:Figure30 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec21">Task 2: peeling</h4><p>Trial times have been recorded in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig31">31</a> comparing both force and no force conditions for the peeling task. All the metrics recorded for the peeling task involves the peeling of both sides of the abdomen. We notice that trial times are greater for the no force condition as compared to the force condition, complying with our hypothesis. The mean of the trial time for the force condition over all participants was 39.38 s, with a standard deviation of 12.48. The mean of the trial time for the no force condition over all participants was 47.91 s, with a standard deviation of 16.62.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-31"><figure><figcaption><b id="Fig31" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 31</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/31" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig31_HTML.gif?as=webp"></source><img aria-describedby="figure-31-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig31_HTML.gif" alt="figure31" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-31-desc"><p>Comparing average time of both force and no force modules of peeling task for all 10 participants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/31" data-track-dest="link:Figure31 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>The novice user may have difficulty in determining depth while using a 2D monitor screen. For that reason, we chose to record the number of times the participant “re-grasps” the skin they are peeling as a performance metric for this task (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig29">29</a>). We notice in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig29">29</a> that the number of “re-grasps” is higher for the no force condition. The occurrence of both of these trends could be because the force condition helps the participant recognize contact with the skin more quickly and easily. The mean of the number of re-grasps for the force condition over all participants was 4.65, with a standard deviation of 1.84. The mean of the number of re-grasps for the no force condition over all participants was 5.59, with a standard deviation of 1.91.</p><p>Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig33">33</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig34">34</a> compare the results of the number of times skin is “re-grasped” versus times for both force and no force conditions, respectively. These plots are a combination of Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig31">31</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig32">32</a>. For both these plots there is a general trend of the number of “re-grasps” increasing with time.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-32"><figure><figcaption><b id="Fig32" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 32</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/32" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig32_HTML.gif?as=webp"></source><img aria-describedby="figure-32-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig32_HTML.gif" alt="figure32" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-32-desc"><p>Comparing average time of both force and no force modules of peeling task for all 10 participants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/32" data-track-dest="link:Figure32 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                              <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-33"><figure><figcaption><b id="Fig33" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 33</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/33" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig33_HTML.gif?as=webp"></source><img aria-describedby="figure-33-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig33_HTML.gif" alt="figure33" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-33-desc"><p>Comparing number of times of tissue is re-grasped vs. time for force condition of peeling task for all 10 participants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/33" data-track-dest="link:Figure33 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                              <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-34"><figure><figcaption><b id="Fig34" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 34</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/34" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig34_HTML.gif?as=webp"></source><img aria-describedby="figure-34-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig34_HTML.gif" alt="figure34" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-34-desc"><p>Plot comparing number of times of tissue is re-grasped vs. time for no force condition of peeling task for all 10 participants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/34" data-track-dest="link:Figure34 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec22">Task 3: displacing organs</h4><p>A graph comparing the trial times of both force and no force conditions is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig35">35</a> for the displacing organ task. The trial times are again greater for the no force condition as compared to the force condition, complying with our hypothesis. The mean of the trial time for the force condition over all participants was 33.71 s, with a standard deviation of 12.22. The mean of the trial time for the no force condition over all participants was 45.58 s, with a standard deviation of 16.87.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-35"><figure><figcaption><b id="Fig35" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 35</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/35" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig35_HTML.gif?as=webp"></source><img aria-describedby="figure-35-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig35_HTML.gif" alt="figure35" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-35-desc"><p>Comparing average time of both force and no force modules of displacing organ task for all 10 participants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/35" data-track-dest="link:Figure35 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>We chose to record the number of collisions as a performance metric for this task, since a novice user would tend to generate more collisions than an expert user (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig36">36</a>). We can easily notice that there are fewer collisions for the force condition as compared to the no force condition. A likely reason for this trend could be because the user is more aware of collisions while there is force feedback and allows them to help limit the number of collisions during the trial.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-36"><figure><figcaption><b id="Fig36" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 36</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/36" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig36_HTML.gif?as=webp"></source><img aria-describedby="figure-36-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig36_HTML.gif" alt="figure36" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-36-desc"><p>Comparing average number of collisions of both force and no force conditions of displacing organ task for all 10 participants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/36" data-track-dest="link:Figure36 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig37">37</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0132-3#Fig38">38</a> contain plots comparing the number of collisions versus time for both force and no force conditions. A similar trend is observed in both plots; the number of collisions increase with time. Since all participants had little previous exposure with a PHANToM device, this general trend is appropriate. In general, the participants who took more time with a task had lower dexterity level with the PHANToM than those who took less time causing more collisions during the task. There are also a few cases (participants) in these plots that show fewer collisions with increasing time. This could deal with participants who were trying to ensure few collisions, but again since they were a novice PHANToM user they needed to perform the task slowly for a higher level of accuracy. The mean of the number of collisions for the force condition over all participants was 4.23, with a standard deviation of 1.81. The mean of the number of collisions for the no force condition over all participants was 5.53, with a standard deviation of 1.83.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-37"><figure><figcaption><b id="Fig37" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 37</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/37" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig37_HTML.gif?as=webp"></source><img aria-describedby="figure-37-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig37_HTML.gif" alt="figure37" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-37-desc"><p>Plot comparing number of collisions vs. time for the force condition of displacing organ task for all 10 participants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/37" data-track-dest="link:Figure37 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                              <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-38"><figure><figcaption><b id="Fig38" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 38</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/38" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig38_HTML.gif?as=webp"></source><img aria-describedby="figure-38-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Fig38_HTML.gif" alt="figure38" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-38-desc"><p>Plot comparing number of collisions vs. time for the no force condition of displacing organ task for all 10 participants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0132-3/figures/38" data-track-dest="link:Figure38 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-009-0132-3#Tab1">1</a> and <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-009-0132-3#Tab2">2</a> summarize the mean time and standard deviations for each of the three tasks averaged over all 10 participants. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-009-0132-3#Tab1">1</a> is for the force feedback condition and Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-009-0132-3#Tab2">2</a> is for the no force condition. Comparing the two tables, we can see that participants performed about 30% faster for each of the three tasks when they were given force feedback cues.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Table comparing the mean time and standard deviation values from all three dissection tasks averaged over all 10 participants for the force feedback condition</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-009-0132-3/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                              <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Table comparing the mean time and standard deviation values from all three dissection tasks averaged over all 10 participants for the no force feedback condition</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-009-0132-3/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec23">Responses to the questionnaire</h4><p>Each of the 10 participants filled out the questionnaire (refer to Appendix A) after they completed their three tasks. We will now discuss some of the details of their responses.</p><p>For question 1 of the questionnaire, all 10 participants preferred the force feedback condition to the no force condition. Where 9 out of 10 preferred force feedback for all three tasks and one participant only preferred the force feedback condition for the peeling and displacing organ tasks. This participant did not feel that the force feedback condition helped their performance for the cutting task. Most participants had the most difficulty with the peeling task and preferred the force feedback condition for this task.</p><p>For question 2 of the questionnaire, the average of the rankings provided from our 10 participants was 4.5 (where 5 is rated as excellent) meaning that the participants felt the instructions of the virtual dissection environment to be clear. For question 3, the average ranking was 4 meaning that the participants felt the force feedback cues in response to their actions were clear. For question 4, the average ranking was 4.5 meaning that the participants felt the force feedback cues helped them in performing their tasks. For question 5, the ranking was 2 meaning that they felt uncomfortable performing the task when force feedback cues were removed. These questions reinforced part of our hypotheses that all users felt the haptic cues to be helpful while performing dissection tasks.</p><p>Some general comments of the participants was that for those who performed the force condition before the no force condition (since the order was selected at random) mentioned that they had an easier time with the no force condition task, since the force cues helped them know what to expect.</p></div></div></section><section aria-labelledby="Sec24"><div class="c-article-section" id="Sec24-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec24">Discussion and future work</h2><div class="c-article-section__content" id="Sec24-content"><p>We have presented a framework for haptic rendering incorporating novel methods to improve the realism of virtual dissection. The prime contributions of this paper were the manifold proximity class algorithm to model contact detection and soft-object deformation, along with a novel “peeling” method in conjunction with extrapolation techniques to provide more realistic contact forces. We take advantage of several characteristics of virtual dissection: (1) determining an appropriate trade-off between visual realism and realistic simulation; (2) most deformations are local; (3) virtual instruments for dissection have relatively slow motions. Our contact deformation algorithm exploits proximity relationships between the deformable bodies and deformation locality to minimize simulation time and help increase realism. Within our proposed and implemented virtual dissection environment, several areas remain to be further explored.</p><p>Providing users with multimodal cues has the potential to both guide them and offer them performance feedback during the simulation. Currently, our dissection simulation provides users with haptic cues (i.e. force-feedback). We plan to add both graphical and audio cues to future versions of the dissection simulator. A graphical cue can draw the user’s attention to a particular area by highlighting that specific part of the model. An audio cue provides immediate feedback to the user warning them about an incorrect action, allowing them to correct their actions themselves.</p><p>To realistically simulate interactions between deformable objects, the collision detection cases discussed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0132-3#Sec3">3</a> can be extended to include self-collisions. With the virtual peeling method, it is possible for the skin to “go through” itself. A possible solution to detect self-collisions would be to use some kind of layered sphere-based model as proposed by (France et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="France L, Lenoir J, Angelidis A, Meseure P, Cani MP, Faure F, Chaillou C (2005) A layered model of a virtual human intestine for surgery simulation. Med Image Anal 9:123–132" href="/article/10.1007/s10055-009-0132-3#ref-CR8" id="ref-link-section-d77471e2804">2005</a>).</p><p>The heuristics from our manifold proximity class method can be formalized in a future iteration of our virtual dissection environment. Our current goal was to test whether haptic feedback provides any benefits in a virtual dissection. Future work includes the development of a formal framework for our proposed manifold proximity class.</p><p>Although we have shown that this preliminary user study does support the claims of our hypothesis, we cannot yet statistically prove any general claims or conclusions for our hypothesis. As well, further study and analysis are needed to formally prove the statements of our hypothesis. A future direction can be to extend our user study in the comparison of virtual dissection to that of traditional dissection and determine the effectiveness of a virtual dissection as a dissection alternative. Perhaps, the user study could involve a student performing both a traditional dissection and a virtual dissection and comparing the results and obtaining feedback based on the participant’s opinion of the two experiences. As well, the usage of less expensive haptic devices can increase the popularity and acceptance of such training environments. The Novint Falcon (with cost of about $150 USD) has also been considered and can be used with our software, but this would be a part of future work.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Basdogan C, Srinivasan M (2001) Haptic rendering in virtual environments. In: Stanney K (ed) Virtual environme" /><p class="c-article-references__text" id="ref-CR1">Basdogan C, Srinivasan M (2001) Haptic rendering in virtual environments. In: Stanney K (ed) Virtual environments handbook, Erlbaum, Mahwah, NJ, pp 117–134</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Basdogan, S. De, J. Kim, M. Manivannan, H. Kim, MA. Srinivasan, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Basdogan C, De S, Kim J, Manivannan M, Kim H, Srinivasan MA (2004) Haptics in minimally invasive surgical simu" /><p class="c-article-references__text" id="ref-CR2">Basdogan C, De S, Kim J, Manivannan M, Kim H, Srinivasan MA (2004) Haptics in minimally invasive surgical simulation and training. IEEE Comput Graph Appl 24(2):56–64</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FMCG.2004.1274062" aria-label="View reference 2">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Haptics%20in%20minimally%20invasive%20surgical%20simulation%20and%20training&amp;journal=IEEE%20Comput%20Graph%20Appl&amp;volume=24&amp;issue=2&amp;pages=56-64&amp;publication_year=2004&amp;author=Basdogan%2CC&amp;author=De%2CS&amp;author=Kim%2CJ&amp;author=Manivannan%2CM&amp;author=Kim%2CH&amp;author=Srinivasan%2CMA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Brown J, Sorkin S, Bruyns C, Latombe JC, Montgomery K, Stephanides M (2001) Real-time simulation of deformable" /><p class="c-article-references__text" id="ref-CR3">Brown J, Sorkin S, Bruyns C, Latombe JC, Montgomery K, Stephanides M (2001) Real-time simulation of deformable objects: tools and application. Computer animation 2001, Seoul, Korea, November 7–8</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Burden RL, Faires JD (2000) Numerical analysis. Brooks-Cole" /><p class="c-article-references__text" id="ref-CR4">Burden RL, Faires JD (2000) Numerical analysis. Brooks-Cole</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cover S, Norberto FE, Obrien JF, Rowe R, Gadau T, Palm E (1993) Interactively deformable models for surgery si" /><p class="c-article-references__text" id="ref-CR5">Cover S, Norberto FE, Obrien JF, Rowe R, Gadau T, Palm E (1993) Interactively deformable models for surgery simulation. In: Proceedings of ICRA, pp 68–75</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Crossan A, Brewster S, Reid S et al (2001) A horse ovary palpation simulator for veterinary training. In: Hapt" /><p class="c-article-references__text" id="ref-CR6">Crossan A, Brewster S, Reid S et al (2001) A horse ovary palpation simulator for veterinary training. In: Haptic human-computer interaction, pp 157–164</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Doo, M. Sabin, " /><meta itemprop="datePublished" content="1978" /><meta itemprop="headline" content="Doo D, Sabin M (1978) Behaviour of recursive division surfaces near extraordinary points. Comput Aided Des 10:" /><p class="c-article-references__text" id="ref-CR7">Doo D, Sabin M (1978) Behaviour of recursive division surfaces near extraordinary points. Comput Aided Des 10:356–360</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2F0010-4485%2878%2990111-2" aria-label="View reference 7">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Behaviour%20of%20recursive%20division%20surfaces%20near%20extraordinary%20points&amp;journal=Comput%20Aided%20Des&amp;volume=10&amp;pages=356-360&amp;publication_year=1978&amp;author=Doo%2CD&amp;author=Sabin%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. France, J. Lenoir, A. Angelidis, P. Meseure, MP. Cani, F. Faure, C. Chaillou, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="France L, Lenoir J, Angelidis A, Meseure P, Cani MP, Faure F, Chaillou C (2005) A layered model of a virtual h" /><p class="c-article-references__text" id="ref-CR8">France L, Lenoir J, Angelidis A, Meseure P, Cani MP, Faure F, Chaillou C (2005) A layered model of a virtual human intestine for surgery simulation. Med Image Anal 9:123–132</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.media.2004.11.006" aria-label="View reference 8">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20layered%20model%20of%20a%20virtual%20human%20intestine%20for%20surgery%20simulation&amp;journal=Med%20Image%20Anal&amp;volume=9&amp;pages=123-132&amp;publication_year=2005&amp;author=France%2CL&amp;author=Lenoir%2CJ&amp;author=Angelidis%2CA&amp;author=Meseure%2CP&amp;author=Cani%2CMP&amp;author=Faure%2CF&amp;author=Chaillou%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Georgii, R. Westermann, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Georgii J, Westermann R (2006) A multigrid framework for real-time simulation of deformable bodies. Comput Gra" /><p class="c-article-references__text" id="ref-CR9">Georgii J, Westermann R (2006) A multigrid framework for real-time simulation of deformable bodies. Comput Graph 30(3):409–416</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.cag.2006.02.016" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20multigrid%20framework%20for%20real-time%20simulation%20of%20deformable%20bodies&amp;journal=Comput%20Graph&amp;volume=30&amp;issue=3&amp;pages=409-416&amp;publication_year=2006&amp;author=Georgii%2CJ&amp;author=Westermann%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gibson S (1997) A survey of deformable modeling in computer graphics. Technical report no. TR-97-19, Mitsubish" /><p class="c-article-references__text" id="ref-CR10">Gibson S (1997) A survey of deformable modeling in computer graphics. Technical report no. TR-97-19, Mitsubishi Electric Research Laboratory, Cambridge MA</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Laugier C, Mendoza C, Sundaraj K (2003) Towards a realistic medical simulator using virtual environments and h" /><p class="c-article-references__text" id="ref-CR11">Laugier C, Mendoza C, Sundaraj K (2003) Towards a realistic medical simulator using virtual environments and haptic interaction. Robotics Research, volume 6 of Springer Tracts in Advanced Robotics (STAR)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lawlor OS, Kale LV (2002) A voxel-based parallel collision detection algorithm. In: Proceedings of the 16th in" /><p class="c-article-references__text" id="ref-CR12">Lawlor OS, Kale LV (2002) A voxel-based parallel collision detection algorithm. In: Proceedings of the 16th international conference on Supercomputing, 22–26 June, pp 285–293</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lin M, Gottschalk S (1999) Collision detection between geometric models: a survey. In: Proceedings of IMA conf" /><p class="c-article-references__text" id="ref-CR13">Lin M, Gottschalk S (1999) Collision detection between geometric models: a survey. In: Proceedings of IMA conference on mathematics of surfaces, pp 37–56</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Lundin, M. Cooper, A. Ynnerman, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Lundin K, Cooper M, Ynnerman A (2007) Enabling design and interactive selection of haptic modes. Virtual Real " /><p class="c-article-references__text" id="ref-CR14">Lundin K, Cooper M, Ynnerman A (2007) Enabling design and interactive selection of haptic modes. Virtual Real J 11(1):1–13</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10055-006-0033-7" aria-label="View reference 14">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Enabling%20design%20and%20interactive%20selection%20of%20haptic%20modes&amp;journal=Virtual%20Real%20J&amp;volume=11&amp;issue=1&amp;pages=1-13&amp;publication_year=2007&amp;author=Lundin%2CK&amp;author=Cooper%2CM&amp;author=Ynnerman%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mendoza C, Sundaraj K, Laugier C (2003) Faithfull haptic feedback in medical simulators. Robotics Research, vo" /><p class="c-article-references__text" id="ref-CR15">Mendoza C, Sundaraj K, Laugier C (2003) Faithfull haptic feedback in medical simulators. Robotics Research, volume 5 of Springer Tracts in Advanced Robotics (STAR)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Montgomery K, Bruyns C, Wildermuth S (2001) A virtual environment for simulated rat dissection: a case study o" /><p class="c-article-references__text" id="ref-CR16">Montgomery K, Bruyns C, Wildermuth S (2001) A virtual environment for simulated rat dissection: a case study of visualization for astronaut training. Vis 2001, San Diego, California</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="KL. Palmerius, M. Cooper, A. Ynnerman, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Palmerius KL, Cooper M, Ynnerman A (2008) Haptic rendering of dynamic volumetric data, visualization and compu" /><p class="c-article-references__text" id="ref-CR17">Palmerius KL, Cooper M, Ynnerman A (2008) Haptic rendering of dynamic volumetric data, visualization and computer graphics. IEEE Transactions 14(2):263–276</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Haptic%20rendering%20of%20dynamic%20volumetric%20data%2C%20visualization%20and%20computer%20graphics&amp;journal=IEEE%20Transactions&amp;volume=14&amp;issue=2&amp;pages=263-276&amp;publication_year=2008&amp;author=Palmerius%2CKL&amp;author=Cooper%2CM&amp;author=Ynnerman%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pauly M, Pai D, Guibas L (2004) Quasi-rigid objects in contact, Eurographics/ACM SIGGRAPH symposium on compute" /><p class="c-article-references__text" id="ref-CR18">Pauly M, Pai D, Guibas L (2004) Quasi-rigid objects in contact, Eurographics/ACM SIGGRAPH symposium on computer animation</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Payandeh S, Azouz N (2001) Finite elements, mass-spring-damper systems and haptic rendering. In: Proceedings o" /><p class="c-article-references__text" id="ref-CR19">Payandeh S, Azouz N (2001) Finite elements, mass-spring-damper systems and haptic rendering. In: Proceedings of IEEE international symposium on computational intelligence in robotics and automation, pp 224–230</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Picinbono G, Lombardo J (1999) Extrapolation: a solution to force feedback. In: International scientific works" /><p class="c-article-references__text" id="ref-CR20">Picinbono G, Lombardo J (1999) Extrapolation: a solution to force feedback. In: International scientific workshop on virtual reality and prototyping, Laval, France, pp 117–125</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="L. Segerlind, " /><meta itemprop="datePublished" content="1976" /><meta itemprop="headline" content="Segerlind L (1976) Applied finite element analysis. Wiley, New Jersey" /><p class="c-article-references__text" id="ref-CR21">Segerlind L (1976) Applied finite element analysis. Wiley, New Jersey</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Applied%20finite%20element%20analysis&amp;publication_year=1976&amp;author=Segerlind%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sundaraj K (2004) Real-time dynamic simulation and 3D interaction of biological tissue: application to medical" /><p class="c-article-references__text" id="ref-CR22">Sundaraj K (2004) Real-time dynamic simulation and 3D interaction of biological tissue: application to medical simulators. PhD. Thesis, Institut National Polytechnique de Grenoble</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Suzuki, N. Suzuki, A. Hattori, A. Uchiyama, S. Kobayashi, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Suzuki S, Suzuki N, Hattori A, Uchiyama A, Kobayashi S (2004) Sphere-filled organ model for virtual surgery sy" /><p class="c-article-references__text" id="ref-CR23">Suzuki S, Suzuki N, Hattori A, Uchiyama A, Kobayashi S (2004) Sphere-filled organ model for virtual surgery system. IEEE Transactions Med Imaging 23(6):714</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTMI.2004.826947" aria-label="View reference 23">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Sphere-filled%20organ%20model%20for%20virtual%20surgery%20system&amp;journal=IEEE%20Transactions%20Med%20Imaging&amp;volume=23&amp;issue=6&amp;publication_year=2004&amp;author=Suzuki%2CS&amp;author=Suzuki%2CN&amp;author=Hattori%2CA&amp;author=Uchiyama%2CA&amp;author=Kobayashi%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Teschner, S. Kimmerle, B. Heidelberger, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Teschner M, Kimmerle S, Heidelberger B (2005) Collision detection for deformable objects. Comput Graphics Foru" /><p class="c-article-references__text" id="ref-CR24">Teschner M, Kimmerle S, Heidelberger B (2005) Collision detection for deformable objects. Comput Graphics Forum 24(1):61–81</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fj.1467-8659.2005.00829.x" aria-label="View reference 24">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Collision%20detection%20for%20deformable%20objects&amp;journal=Comput%20Graphics%20Forum&amp;volume=24&amp;issue=1&amp;pages=61-81&amp;publication_year=2005&amp;author=Teschner%2CM&amp;author=Kimmerle%2CS&amp;author=Heidelberger%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Tong C, Song A, Juan W (2007) A mass-spring model for haptic display of flexible object global deformation. In" /><p class="c-article-references__text" id="ref-CR25">Tong C, Song A, Juan W (2007) A mass-spring model for haptic display of flexible object global deformation. In: Proceedings of ICMA 2007</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Van Den Bergen, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Van Den Bergen G (1997) Efficient collision detection of complex deformable models using AABB trees. J Graphic" /><p class="c-article-references__text" id="ref-CR26">Van Den Bergen G (1997) Efficient collision detection of complex deformable models using AABB trees. J Graphics Tools 2(4):1–14</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0927.68100" aria-label="View reference 26 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Efficient%20collision%20detection%20of%20complex%20deformable%20models%20using%20AABB%20trees&amp;journal=J%20Graphics%20Tools&amp;volume=2&amp;issue=4&amp;pages=1-14&amp;publication_year=1997&amp;author=Van%20Den%20Bergen%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zhang H, Payandeh S, Dill J (2004) On cutting and dissection of virtual deformable objects. In: Proceedings of" /><p class="c-article-references__text" id="ref-CR27">Zhang H, Payandeh S, Dill J (2004) On cutting and dissection of virtual deformable objects. In: Proceedings of IEEE international conference on robotics and automation, pp 3908–3913</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Zhang, S. Payandeh, J. Dill, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Zhang J, Payandeh S, Dill J (2005) A study of level-of-detail in haptic rendering. ACM Trans Appl Percept 2(1)" /><p class="c-article-references__text" id="ref-CR28">Zhang J, Payandeh S, Dill J (2005) A study of level-of-detail in haptic rendering. ACM Trans Appl Percept 2(1):15–34</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F1048687.1048689" aria-label="View reference 28">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20study%20of%20level-of-detail%20in%20haptic%20rendering&amp;journal=ACM%20Trans%20Appl%20Percept&amp;volume=2&amp;issue=1&amp;pages=15-34&amp;publication_year=2005&amp;author=Zhang%2CJ&amp;author=Payandeh%2CS&amp;author=Dill%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zhennan Y, Lixu G, Huang P (2007) Soft tissue deformation simulation in virtual surgery using nonlinear finite" /><p class="c-article-references__text" id="ref-CR29">Zhennan Y, Lixu G, Huang P (2007) Soft tissue deformation simulation in virtual surgery using nonlinear finite element method. In: Proceedings of the 29th annual international conference of the IEEE EMBS</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zhou M, Claffee K, Lee K, McMurray G (2006a) Cutting, ‘by pressing and slicing’, applied to the robotic cut of" /><p class="c-article-references__text" id="ref-CR30">Zhou M, Claffee K, Lee K, McMurray G (2006a) Cutting, ‘by pressing and slicing’, applied to the robotic cut of bio-materials, Part I: modeling of stress distribution. In: Proceedings ICRA06, pp 2896–2901</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zhou M, Claffee K, Lee K, McMurray G (2006b) Cutting, ‘by pressing and slicing’, applied to the robotic cut of" /><p class="c-article-references__text" id="ref-CR31">Zhou M, Claffee K, Lee K, McMurray G (2006b) Cutting, ‘by pressing and slicing’, applied to the robotic cut of bio-materials, Part II: force during slicing and pressing cuts. In: Proceedings of ICRA06, pp 2256–2261</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-009-0132-3-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Experimental Robotics and Graphics Laboratory, Simon Fraser University, Burnaby, BC, Canada</p><p class="c-article-author-affiliation__authors-list">Nasim Melony Vafai &amp; Shahram Payandeh</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Nasim_Melony-Vafai"><span class="c-article-authors-search__title u-h3 js-search-name">Nasim Melony Vafai</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Nasim Melony+Vafai&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Nasim Melony+Vafai" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Nasim Melony+Vafai%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Shahram-Payandeh"><span class="c-article-authors-search__title u-h3 js-search-name">Shahram Payandeh</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Shahram+Payandeh&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Shahram+Payandeh" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Shahram+Payandeh%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-009-0132-3/email/correspondent/c1/new">Nasim Melony Vafai</a>.</p></div></div></section><section aria-labelledby="appendices"><div class="c-article-section" id="appendices-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="appendices">Appendix A: Questionnaire from user study</h2><div class="c-article-section__content" id="appendices-content"><h3 class="c-article__sub-heading u-visually-hidden" id="App1">Appendix A: Questionnaire from user study</h3><h3 class="c-article__sub-heading" id="Sec26">Opinion questionnaire</h3><p>Now that you have completed the experiment, we would like to ask you a few questions about what you experienced. In the questions below asking for a selection on a range of 1 to 5, circle one number where 1 is poor and 5 is excellent.</p>
                    <div class="c-article-section__figure c-article-section__figure--no-border" data-test="figure" data-container-section="figure" id="figure-a"><figure><div class="c-article-section__figure-content" id="Figa"><div class="c-article-section__figure-item"><div class="c-article-section__figure-content"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Figa_HTML.gif?as=webp"></source><img aria-describedby="figure-a-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0132-3/MediaObjects/10055_2009_132_Figa_HTML.gif" alt="figurea" loading="lazy" /></picture></div></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-a-desc"></div></div></figure></div>
                  </div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Toward%20the%20development%20of%20interactive%20virtual%20dissection%20with%20haptic%20feedback&amp;author=Nasim%20Melony%20Vafai%20et%20al&amp;contentID=10.1007%2Fs10055-009-0132-3&amp;publication=1359-4338&amp;publicationDate=2009-09-03&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Vafai, N.M., Payandeh, S. Toward the development of interactive virtual dissection with haptic feedback.
                    <i>Virtual Reality</i> <b>14, </b>85–103 (2010). https://doi.org/10.1007/s10055-009-0132-3</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-009-0132-3.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2009-02-24">24 February 2009</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2009-08-19">19 August 2009</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2009-09-03">03 September 2009</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2010-06">June 2010</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-009-0132-3" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-009-0132-3</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Virtual reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Object deformation</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Cutting</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Dissection</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Collision detection</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Haptics</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Force feedback</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-009-0132-3.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=132;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

