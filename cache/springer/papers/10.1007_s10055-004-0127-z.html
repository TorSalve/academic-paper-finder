<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="A desktop VR prototype for industrial training applications"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="The recent advances in computer graphics has spurred interest from both academics and industries in virtual reality (VR) enabled training applications. This paper presents a desktop VR prototype..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/7/3.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="A desktop VR prototype for industrial training applications"/>

    <meta name="dc.source" content="Virtual Reality 2004 7:3"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2004-05-20"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2004 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="The recent advances in computer graphics has spurred interest from both academics and industries in virtual reality (VR) enabled training applications. This paper presents a desktop VR prototype for industrial training applications. It is designed and implemented as a general shell by providing the data interface to import both the virtual environment models and specific domain knowledge. The geometric models of the virtual environment are constructed using feature-based modelling and assembly function by external CAD tools, and then transferred into the prototype through a conversion module. A hierarchical structure is proposed to partition and organise these imported virtual environment models. Based on this structure, a visibility culling approach is developed for fast rendering and user interaction. The case study has demonstrated the functionality of the proposed prototype system by applying it to a maintenance training application for a refinery bump system, which, in general, has a large number of polygons and a certain depth complexity. Significant speedup in both context rendering and response to user manipulations has been achieved to provide the user with a fast system response within the desktop virtual environment. Compared with the immersive VR system, the proposed system has offered an affordable and portable training media for industrial applications."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2004-05-20"/>

    <meta name="prism.volume" content="7"/>

    <meta name="prism.number" content="3"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="187"/>

    <meta name="prism.endingPage" content="197"/>

    <meta name="prism.copyright" content="2004 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-004-0127-z"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-004-0127-z"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-004-0127-z.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-004-0127-z"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="A desktop VR prototype for industrial training applications"/>

    <meta name="citation_volume" content="7"/>

    <meta name="citation_issue" content="3"/>

    <meta name="citation_publication_date" content="2004/06"/>

    <meta name="citation_online_date" content="2004/05/20"/>

    <meta name="citation_firstpage" content="187"/>

    <meta name="citation_lastpage" content="197"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-004-0127-z"/>

    <meta name="DOI" content="10.1007/s10055-004-0127-z"/>

    <meta name="citation_doi" content="10.1007/s10055-004-0127-z"/>

    <meta name="description" content="The recent advances in computer graphics has spurred interest from both academics and industries in virtual reality (VR) enabled training applications. Thi"/>

    <meta name="dc.creator" content="Q. H. Wang"/>

    <meta name="dc.creator" content="J. R. Li"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph; citation_author=null Bartz; citation_volume=23; citation_publication_date=1999; citation_pages=667; citation_id=CR1"/>

    <meta name="citation_reference" content="Burdea GC, Coiffet P (2003) Virtual reality technology. Wiley, New Jersey"/>

    <meta name="citation_reference" content="citation_journal_title=Commun ACM; citation_author=null Cruz-Neira; citation_volume=35; citation_publication_date=1992; citation_pages=65; citation_doi=10.1145/129888.129892; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph; citation_author=null Gomes; citation_volume=23; citation_publication_date=1999; citation_pages=389; citation_doi=10.1016/S0097-8493(99)00047-3; citation_id=CR4"/>

    <meta name="citation_reference" content="Greene N (1996) Hierarchical polygon tiling with coverage masks. In: Proceedings of the ACM SIGGRAPH&#8217;96 conference, New Orleans, Louisiana, August 1996, pp 65&#8211;74"/>

    <meta name="citation_reference" content="Greene N, Kass M, Miller G (1993) Hierarchical Z-buffer visibility. In: Proceedings of the ACM SIGGRAPH&#8217;93 conference, Anaheim, California, August 1993, pp 231&#8211;238"/>

    <meta name="citation_reference" content="Johnson A, Roussos M, Leigh J, Barnes C, Vasilakis C, Moher T (1998) The NICE project: learning together in a virtual world. In: Proceedings of the VRAIS &#8216;98 conference, Atlanta, Georgia, March 1998, pp 176&#8211;183"/>

    <meta name="citation_reference" content="Kashiwa K, Mitani T, Tezura T, Yoshikawa TH (1995) Development of machine-maintenance training system in virtual environment. In: Proceedings of the 4th IEEE international workshop on robot and human communication (RO-MAN&#8217;95), Tokyo, Japan, July 1995, pp 295&#8211;300"/>

    <meta name="citation_reference" content="citation_journal_title=J Comput Inform Sci; citation_author=null Li; citation_volume=Eng; citation_publication_date=2002; citation_pages=28; citation_id=CR9"/>

    <meta name="citation_reference" content="Naylor BF (1992) Partitioning tree image representation and generation from 3D geometric models. In: Proceedings of Graphics Interface&#8217;92, Vancouver, Canada, May 1992, pp 201&#8211;212"/>

    <meta name="citation_reference" content="citation_journal_title=Assembly Autom; citation_author=null Rooks; citation_volume=19; citation_publication_date=1999; citation_pages=203; citation_doi=10.1108/01445159910280065; citation_id=CR11"/>

    <meta name="citation_reference" content="Sleeman D, Brown JS (1982) Intelligent tutoring systems. Academic Press, London"/>

    <meta name="citation_reference" content="Wenger E (1987) Artificial intelligence and tutoring systems. Morgan Kaufmann, California"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Ind; citation_author=null Weyrich; citation_volume=38; citation_publication_date=1999; citation_pages=5; citation_id=CR14"/>

    <meta name="citation_reference" content="Zhang HS, Manocha D, Hudson T, Hoff K (1997) Visibility culling using hierarchical occlusion map. In: Proceedings of the ACM SIGGRAPH&#8217;97 conference, Los Angeles, California, August 1997, pp 77&#8211;88"/>

    <meta name="citation_author" content="Q. H. Wang"/>

    <meta name="citation_author_email" content="qinghui.wang@autodesk.com"/>

    <meta name="citation_author_institution" content="Manufacturing Solutions Division,  Autodesk Inc. 391B, Singapore"/>

    <meta name="citation_author" content="J. R. Li"/>

    <meta name="citation_author_institution" content="Robotics Research Centre, School of Mechanical and Production Engineering, Nanyang Technological University, Singapore"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-004-0127-z&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2004/06/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-004-0127-z"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="A desktop VR prototype for industrial training applications"/>
        <meta property="og:description" content="The recent advances in computer graphics has spurred interest from both academics and industries in virtual reality (VR) enabled training applications. This paper presents a desktop VR prototype for industrial training applications. It is designed and implemented as a general shell by providing the data interface to import both the virtual environment models and specific domain knowledge. The geometric models of the virtual environment are constructed using feature-based modelling and assembly function by external CAD tools, and then transferred into the prototype through a conversion module. A hierarchical structure is proposed to partition and organise these imported virtual environment models. Based on this structure, a visibility culling approach is developed for fast rendering and user interaction. The case study has demonstrated the functionality of the proposed prototype system by applying it to a maintenance training application for a refinery bump system, which, in general, has a large number of polygons and a certain depth complexity. Significant speedup in both context rendering and response to user manipulations has been achieved to provide the user with a fast system response within the desktop virtual environment. Compared with the immersive VR system, the proposed system has offered an affordable and portable training media for industrial applications."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>A desktop VR prototype for industrial training applications | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-004-0127-z","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Virtual reality, Desktop virtual environment, Computer-based training, Visibility culling","kwrd":["Virtual_reality","Desktop_virtual_environment","Computer-based_training","Visibility_culling"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-004-0127-z","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-004-0127-z","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-b0018c9f69.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-c02f1b37f0.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=127;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-004-0127-z">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            A desktop VR prototype for industrial training applications
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-004-0127-z.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-004-0127-z.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2004-05-20" itemprop="datePublished">20 May 2004</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">A desktop VR prototype for industrial training applications</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Q__H_-Wang" data-author-popup="auth-Q__H_-Wang" data-corresp-id="c1">Q. H. Wang<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content=" Autodesk Inc. 391B" /><meta itemprop="address" content="Manufacturing Solutions Division,  Autodesk Inc. 391B, Orchard Road, #12-06 Ngee Ann City Tower B,  238874, Singapore" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-J__R_-Li" data-author-popup="auth-J__R_-Li">J. R. Li</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Nanyang Technological University" /><meta itemprop="address" content="grid.59025.3b, 0000000122240361, Robotics Research Centre, School of Mechanical and Production Engineering, Nanyang Technological University, 50 Nanyang Avenue, 639798, Singapore" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 7</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">187</span>–<span itemprop="pageEnd">197</span>(<span data-test="article-publication-year">2004</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">447 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">19 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-004-0127-z/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>The recent advances in computer graphics has spurred interest from both academics and industries in virtual reality (VR) enabled training applications. This paper presents a desktop VR prototype for industrial training applications. It is designed and implemented as a general shell by providing the data interface to import both the virtual environment models and specific domain knowledge. The geometric models of the virtual environment are constructed using feature-based modelling and assembly function by external CAD tools, and then transferred into the prototype through a conversion module. A hierarchical structure is proposed to partition and organise these imported virtual environment models. Based on this structure, a visibility culling approach is developed for fast rendering and user interaction. The case study has demonstrated the functionality of the proposed prototype system by applying it to a maintenance training application for a refinery bump system, which, in general, has a large number of polygons and a certain depth complexity. Significant speedup in both context rendering and response to user manipulations has been achieved to provide the user with a fast system response within the desktop virtual environment. Compared with the immersive VR system, the proposed system has offered an affordable and portable training media for industrial applications.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Introduction</h2><div class="c-article-section__content" id="Sec2-content"><p>The recent advances in computer graphics has spurred interest from both academics and industries in virtual reality (VR) enabled training applications. As a synthetic, 3-D, interactive environment typically generated by a computer, VR has been recognised as a very powerful human–computer interface for decades [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Burdea GC, Coiffet P (2003) Virtual reality technology. Wiley, New Jersey" href="/article/10.1007/s10055-004-0127-z#ref-CR2" id="ref-link-section-d75187e313">2</a>]. The classification of the VR system is not unique. Based on its realism intended and the hardware required, VR applications can be grouped into two categories, namely, immersive VR and desktop-oriented VR. In the public education domain, Johnson et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Johnson A, Roussos M, Leigh J, Barnes C, Vasilakis C, Moher T (1998) The NICE project: learning together in a virtual world. In: Proceedings of the VRAIS ‘98 conference, Atlanta, Georgia, March 1998, pp 176–183" href="/article/10.1007/s10055-004-0127-z#ref-CR7" id="ref-link-section-d75187e316">7</a>] have developed an exploratory learning environment that will engage children in authentic activities, such as planting in the garden. The implementation of the immersive virtual environment is through the famous CAVE virtual theatre [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Cruz-Neira C, Sandin DJ, DeFanti TA, Kenyon RV, Hart JC (1992) The CAVE: audio visual experience automatic virtual environment. Commun ACM 35(6):65–72" href="/article/10.1007/s10055-004-0127-z#ref-CR3" id="ref-link-section-d75187e319">3</a>]. On the other hand, VR also enables various new applications in manufacturing industries. An interactive environment for virtual manufacturing has been proposed for planning and testing products and manufacturing facilities [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Weyrich M, Drews P (1999) An interactive environment for virtual manufacturing: the virtual workbench. Comput Ind 38:5–15" href="/article/10.1007/s10055-004-0127-z#ref-CR14" id="ref-link-section-d75187e322">14</a>]. Users watch the projection screen of the workbench through the special LCD shutter glasses and interact with the virtual workbench via a space joystick and data glove. Kashiwa et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Kashiwa K, Mitani T, Tezura T, Yoshikawa TH (1995) Development of machine-maintenance training system in virtual environment. In: Proceedings of the 4th IEEE international workshop on robot and human communication (RO-MAN’95), Tokyo, Japan, July 1995, pp 295–300" href="/article/10.1007/s10055-004-0127-z#ref-CR8" id="ref-link-section-d75187e325">8</a>] presented an immersive VR system for maintenance training. In their work, different assembly or disassembly procedures were modelled using Petri nets and were coupled to the VR environment. The interaction between the trainee and the VR system is by means of wearing a head-mounted display (HMD) and data glove. For immersive VR system, the cost of hardware, as well as software, limits the applications and their popularity. And the ergonomics of most VR devices is still a major problem for making VR a popular and widely accepted tool in engineering verifications [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Gomes de Sa A, Zachmann G (1999) Virtual reality as a tool for verification of assembly and maintenance processes. Comput Graph 23:389–403" href="/article/10.1007/s10055-004-0127-z#ref-CR4" id="ref-link-section-d75187e329">4</a>]. Furthermore, users are limited to laboratories and having to wear the equipment, which do not allow collective visualisation and observation.</p><p>At the other end of the spectrum, desktop VR system offers an affordable solution that displays a virtual environment on a conventional desktop PC in a non-immersive manner [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Rooks B (1999) The reality of virtual reality. Assembly Autom 19(3):203–208" href="/article/10.1007/s10055-004-0127-z#ref-CR11" id="ref-link-section-d75187e335">11</a>]. Comparing with donning a helmet and data glove, the input devices and the usage of a desktop PC provide a more convenient and easy-to-follow interface for the engineers indeed. Thus, alternatively, in many VR applications, users prefer a desktop virtual environment due to its low cost and portability. More importantly, the desktop VR system enables knowledge or information sharing during the training process. For different industrial applications, the corresponding domain knowledge is essential information for the trainees to appreciate. Compared with traditional computer assisted instructions (CAI) [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Wenger E (1987) Artificial intelligence and tutoring systems. Morgan Kaufmann, California" href="/article/10.1007/s10055-004-0127-z#ref-CR13" id="ref-link-section-d75187e338">13</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Sleeman D, Brown JS (1982) Intelligent tutoring systems. Academic Press, London" href="/article/10.1007/s10055-004-0127-z#ref-CR12" id="ref-link-section-d75187e341">12</a>], coupling the related knowledge and experience display dynamically onto the interactive 3D display will provide benefits for the user, with a better learning experience and training result in the desktop VR system as well. However, without the sensory tracking of the user position to enable the immersive feeling, one of the major technical challenges for desktop VR is its ability to provide realistic and interactive performance. This places greater demand on both the software and hardware required.</p><p>In this paper, a prototype desktop VR system for industrial training application is presented. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-004-0127-z#Sec3">2</a> describes its general system architecture. The virtual environment construction method and scene organisation are presented in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-004-0127-z#Sec4">3</a>. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-004-0127-z#Sec7">4</a> presents an on-line visibility culling approach, which is designed to improve the performance of the visual effect and user interaction for the desktop VR prototype. A knowledge model for training programmes is illustrated and explained in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-004-0127-z#Sec12">5</a>. The maintenance training application for a refinery system is engaged as the case study. Description of system functionalities and a performance comparison on the visibility culling approach implemented are detailed through the case study, in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-004-0127-z#Sec13">6</a>. The last section, Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-004-0127-z#Sec18">7</a>, concludes this work.</p></div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">A desktop VR prototype system</h2><div class="c-article-section__content" id="Sec3-content"><p>The design of the desktop VR prototype aims at providing a general shell for different industrial training applications. The main functional requirements of the system are identified as following: </p><ul class="u-list-style-dash">
                  <li>
                    <p>Modelling and construction of a virtual environment for a specific application, from which users could have an authentic feeling of the actual scene.</p>
                  </li>
                  <li>
                    <p>User interaction with virtual environment in real-time. Users are allowed to explore the environment and manipulate the virtual objects to involve themselves in the training programme, and are enlightened with related knowledge by interacting with virtual objects.</p>
                  </li>
                  <li>
                    <p>Domain knowledge representation and acquisition for training purposes.</p>
                  </li>
                  <li>
                    <p>Training programme for a specific application. Training processes are controlled by the programme, which responds to user interaction and coordinates the related VR display and knowledge output (i.e. text output or acoustic rendering). During the training process, users experience the individual training tasks defined by the training programme, which are accessible from the database.</p>
                  </li>
                  <li>
                    <p>A user-friendly interface to integrate the system functions, such as user interaction, VR rendering, information sharing and acoustic rendering.</p>
                  </li>
                </ul>
<p>Based on the requirements analysis, the architecture of the prototype system is designed and is illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig1">1</a>. The system is implemented with a component-based structure, in which the separate functions are encapsulated and implemented within a set of dynamic link libraries (DLLs). The GUI component provides the user with a friendly interface. During a training process, all the user interactions with the system are received and processed by the GUI, and dispatched to related functional components. The<i>
training programme manager</i> is designed to control the trigger of the system functions, such as knowledge output and interactive VR display at the system level. The<i> VE exploration manager</i> is designed for the interactive display of the virtual environment and operation process, based on the messages received from user input or from the training programme manger. To improve the rendering rates,<i>
visibility culling</i> is implemented to cull away large portions of invisible primitives before screen rendering. The<i> VE objects manipulator</i> is responsible for the VR object manipulation. As an industrial application, the system will not provide the user with the function of 3D environment modelling; all the virtual environment models could be constructed in external modelling tools and then imported into the VR system through some kind of data converter. The related domain knowledge for the user to learn will be retrieved from a knowledge base and managed for the display via the<i> training programme manager</i>. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb1.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb1.jpg" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p> Schematic overview of the desktop VR prototype system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
</div></div></section><section aria-labelledby="Sec4"><div class="c-article-section" id="Sec4-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec4">VE construction</h2><div class="c-article-section__content" id="Sec4-content"><h3 class="c-article__sub-heading" id="Sec5">Modelling of objects</h3><p>Modelling is the most time-consuming task in the construction of a VR system. The combination of feature-based geometry modelling and parametric-driven technology is the mainstream in current industry design. Starting from simple conceptual sketches, complex 3D solid models are easily created through adding various features, and modified through the editing of sketches and features. Based on feature-based modelling, individual geometrical parts are assembled into complicated industrial systems through the defining of assembly constraints among them. Today, commercially available CAD modelling tools have been becoming more powerful in their functions, and are more affordable as well. Most current VR systems are designed to use these powerful CAD modelling tools by importing external geometrical models, and data translators are required to convert CAD data from one system to another.</p><p>An STL (stereo lithography format) file represents solid objects as a polygonal mesh consisting of a set of triangles with their normal vectors. As the STL file has been becoming the de facto geometrical format for rapid prototyping manufacturing (RPM), most current solid modelling tools offer the STL interface to export solid models. It is known that the solid models in other CAD formats need a process of tessellating geometries into a polygonal mesh, which is required for OpenGL rendering. For VR systems, one of the advantages is that the polygon data in the STL file can be directly used in virtual environment rendering by OpenGL without any conversion. However, the STL file is a kind of pure geometrical format for solid shape representation, which means that the attributes associated with a solid object, such as colour, name, ID and material, are not available. Not obtaining any topological information with the STL file is another critical barrier to keep it from being directly used in VR applications. In the case of an STL file containing mesh data of more than one solid object, the object information is also lost among these tessellated mesh. For this VR application, the object information is critical, since most training interactions are based on manipulating individual objects (mechanical part) and their assembly. Thus, the ideal solution is a file format that contains an assembly of objects with topological information, in which each object is the combination of other objects’ polygonal mesh data (same as the STL file format), together with its auxiliary attributes.</p><p>Most current CAD systems provide the user with advanced programming interfaces (APIs), such as Mechanical Desktop (MDT) APIs, Solidworks APIs, etc. These development toolkits offer the user a set of advanced functions to deal with their models, such as access to an assembly model to generate the polygonal mesh for solid objects. It gives the user the convenience to customise the CAD system for some special applications. In this work, a customised module, named<i> virtual reality model</i> (<i>VLM) file converter,</i> has been developed for converting assembly models to VR models based on Mechanical Desktop APIs. In this, the assembly module in MDT can be converted into a customised VLM format file, which not only keeps the assembly relations between objects, but also represents individual objects based on a polygonal mesh together with auxiliary attributes (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig2">2</a>). The generated VLM file can then be directly imported to the VR system to create the virtual environment. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb2.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb2.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p> Converting CAD assembly model to VR model</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<h3 class="c-article__sub-heading" id="Sec6">Scene organisation</h3><p>For industrial VR training applications, the simulated virtual environment requires precise geometric representation of the mechanical system that is the concern for the training purpose. It is common that the corresponding virtual environment may contain millions of geometric polygon primitives. Over the past years, a number of model sub-division schemes, such as BSP-tree [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Naylor BF (1992) Partitioning tree image representation and generation from 3D geometric models. In: Proceedings of Graphics Interface’92, Vancouver, Canada, May 1992, pp 201–212" href="/article/10.1007/s10055-004-0127-z#ref-CR10" id="ref-link-section-d75187e493">10</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Greene N (1996) Hierarchical polygon tiling with coverage masks. In: Proceedings of the ACM SIGGRAPH’96 conference, New Orleans, Louisiana, August 1996, pp 65–74" href="/article/10.1007/s10055-004-0127-z#ref-CR5" id="ref-link-section-d75187e496">5</a>] and Octrees [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Greene N, Kass M, Miller G (1993) Hierarchical Z-buffer visibility. In: Proceedings of the ACM SIGGRAPH’93 conference, Anaheim, California, August 1993, pp 231–238" href="/article/10.1007/s10055-004-0127-z#ref-CR6" id="ref-link-section-d75187e499">6</a>], have been proposed to organise large polygonal models. Among them, BSP-tree representation is the most standard scheme, and is particularly suitable for applications with a frequently moving camera in a static scene. However, for industrial training applications, the scene is also dynamically changing, due to different training processes and user interactions. For example, in maintenance training process, the part object may change its spatial position, orientation and assembly relations. This indicates that a static representation, such as BSP-tree, is not sufficient. However, to every minimum unit of the scene, which refers to the single part of the system that is concerned, its composition is static. Thus, in this work, a modified hierarchical data structure based on BSP-tree is proposed to organise the models for the dynamic training environment.</p><p>In general, a training environment can be composed of a training room, furniture such as a workbench and a desk, and the mechanical systems that needs attention. The training room and furniture are usually geometrically constructed by planar faces; therefore, they result in a small number of polygons after triangulation. The mechanical systems are assemblies of a large number of mechanical/electrical parts with precision requirements in their spatial relations. In the proposed data structure, the mechanical system is divided by its mechanical assembly relationships until the individual mechanical part level (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig3">3</a>). One sub-assembly node, also named component, may consist of a set of sub-components and single parts. Those single parts with a large polygon number will then be further partitioned and represented using BSP-tree. Only the leaf nodes (node of a “polygon set”) contain the polygon data for rendering. Nodes in other levels in the tree structure contain the bounding volume information of their child nodes. More importantly, to enhance the model sub-division in dealing with dynamic display, for each removable node (node “single part” and above), a transformation matrix (a 4×3 homogenous matrix) is attached to describe its real-time change in position and orientation. In this manner, the movement of the parts or components can be easily tracked and operated. The transformation matrix of each node is effective to all of the nodes in sub-tree. The final bounding volume of a node is a spatial box resulted by multiplying the transformation matrixes of the node and those of its parent nodes. Thus, the bounding volume is oriented. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb3.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb3.jpg" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p> Hierarchical scene organisation based on BSP-tree partitioning</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
</div></div></section><section aria-labelledby="Sec7"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7">User interaction with virtual environment and on-line visibility culling</h2><div class="c-article-section__content" id="Sec7-content"><h3 class="c-article__sub-heading" id="Sec8">User interaction with virtual environment</h3><p>User interaction with the virtual environment is one of the most important issues to facilitate the user with the immersive feeling in the computer-generated world. By involving users in the virtual environment, the functionality of the VR system can then be imposed. As a virtual environment, the system level exploration and navigation within the overall environment is essential to the desktop VR training prototype proposed here. This is also the common feature of VR systems. At the component level, in order to train the users with specific operations, the manipulating of individual objects in the environment is required. The system will allow the user to interactively pick and move the related geometric models in the virtual environment by means of input devices, such as a mouse, keyboard, etc. As a virtual environment for industrial training usually contains millions of polygons, the system response rate for the interactive display is crucial, in particular to a desktop VR system, to ensure the user with a real feeling of being in the virtual world. In order to render the virtual environment at acceptably interactive rates, the rendering algorithm needs to use techniques based on on-line visibility culling to limit the number of primitives rendered in each frame.</p><h3 class="c-article__sub-heading" id="Sec9">On-line visibility culling</h3><p>The aim of visibility culling is to cull those geometries that are not visible from current viewpoint, from OpenGL rendering. In this work, the on-line visibility culling consists of two steps: view-frustum culling first, and then followed by occlusion culling.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec10">View-frustum culling</h4><p>In OpenGL,<i>
view-frustum</i> is a viewing volume which has a geometric shape as a section of a pyramid viewed from narrow end to the broad end. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig4">4</a>a shows a view-frustum, with the observer (eye) in place. For a node in the hierarchical structure, if its bounding box has no intersection with the view-frustum, the node will be removed from further scan-converting its polygons. To save the time of soft computing for the intersection relationship, the OpenGL<i>
selection mode</i> has been used to determine the intersection between a view-frustum with a batch of bounding boxes [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Bartz D, Meissner M, Huettner T (1999) OpenGL-assisted occlusion culling for large polygonal models. Comput Graph 23:667–679" href="/article/10.1007/s10055-004-0127-z#ref-CR1" id="ref-link-section-d75187e561">1</a>], where the whole screen is specified as the hit region. Results have demonstrated its good performance, especially for the scenes with a big number of sub-divided spaces, since the intersection relationships can be determined in batch. In this work, the OpenGL-assisted view-frustum culling is also adopted; the six quad faces of an oriented bounding volume are used to calculate whether the node has any contribution to the hit region. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4a, b</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb4.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb4.jpg" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p> Illustrations of frame representation of bounding volumes. Note: A and B are selected as occluders, and C, D, and E are occludees. The object E, which is visible, is a real view, and is occluded by the bounding volumes of C and D. (<b>a</b>) Illustration of wrong occlusion culling by polygonal bounding volumes. (<b>b</b>) Frame representation of bounding volumes</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec11">Occlusion-culling</h4><p>As discussed, the virtual environments for industrial training have high-depth complexity due to the complicated and compact system assembly. After performing the view-frustum culling, in many cases, a large portion of the primitives, which are actually invisible due to occlusion by objects in front, still remain in the view-frustum. Thus, occlusion culling is effective for these high-depth complexity models.</p><p>A novel occlusion culling algorithm is presented here. It is able to fast-detect the occlusion of a set of objects in a batch-process manner. At each frame, the algorithm initially selects a set of ideal objects as occluders. Zhang et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Zhang HS, Manocha D, Hudson T, Hoff K (1997) Visibility culling using hierarchical occlusion map. In: Proceedings of the ACM SIGGRAPH’97 conference, Los Angeles, California, August 1997, pp 77–88" href="/article/10.1007/s10055-004-0127-z#ref-CR15" id="ref-link-section-d75187e599">15</a>] proposed a criterion to select occluders, in which the size, redundancy and rendering complexity of an object are evaluated. One of the problems of detecting the occlusion of the rest of the objects using their bounding volumes in a batch process is: an object, which is visible in the real view, may be possibly occluded by the solid bounding volumes of the objects in front of it (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig4">4</a>a). To avoid this possible wrong culling, a ‘transparent’ frame model composed of 18 solid lines to represent a bounding volume is designed instead of the commonly used solid face model (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig4">4</a>b). To test occlusion of the bounding volumes, each of the bounding frame models is labelled with a unique RGB colour using a lookup table, which identified the individual objects. Then, the polygonal model of the selected occluders and the frame models of the bounding volumes of the rest of the objects are sent to the OpenGL pipeline, using Z-buffer test, while converting the polygons and lines into the frame buffer. The output in the frame buffer is then read back as a colour image, named as<i> colour-indexed occlusion map</i>. Occluded bounding volumes will not contribute to the occlusion map. Hence, all the non-occluded bounding volumes could be found out by scanning the occlusion map.</p></div></div></section><section aria-labelledby="Sec12"><div class="c-article-section" id="Sec12-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec12">Domain knowledge representation and training programme</h2><div class="c-article-section__content" id="Sec12-content"><p>For a specific VR-enabled training application, a training programme, which contains training sequences and links to specific domain knowledge, is required to be integrated with the VR interaction. The domain knowledge here indicates the information other than the geometric representation of the mechanical system and its auxiliary attributes. To take an example, for a maintenance training application for mechanical systems, the assembly instructions and requirements, the assembly and disassembly sequences, are the possible knowledge involved. The format of knowledge representation could be text illustration, links to HTML files, media clips, etc. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig5">5</a> gives an example for a mechanical training application. The<i> pure text</i> illustration contains the brief description of the node and related operation, which could be displayed in a text window during the course of training. The<i> link to HTML</i> file provides a method when the user requests a related illustration. The<i> link to media clip</i> offers another alternative to output training information. The<i> operation instructions</i> advises the user on how to operate this part or component. The node is also linked to the optimised assembly/disassembly sequences for user reference. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zflb5.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zflb5.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p> An example of domain knowledge model</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
</div></div></section><section aria-labelledby="Sec13"><div class="c-article-section" id="Sec13-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec13">Case study</h2><div class="c-article-section__content" id="Sec13-content"><p>Maintenance represents the largest single variable operating cost in most enterprises when considering physical plant value, maintenance labour, materials and overhead. High productivity maintenance contributes to better customer service, high quality, on-time delivery and, ultimately, satisfied customers. In a narrow sense, maintenance comprises two integral tasks, namely, disassembly sequence planning for the removal of faulty system components and sequential disassembly operations for the replacement or repair of these components. The planning of the disassembly sequences, which involves the generation of a near-optimal feasible disassembly sequence, demands both experience and knowledge. On the other hand, the efforts used to carry out disassembly operations also require a high degree of technical skills and knowledge of the system that is under maintenance. The right skilful maintenance staff equipped with an optimised maintenance plan for the task can save a sizable maintenance cost and also improves maintenance productivity as well. Hence, training of maintenance engineers has been identified as the primary intervention to improve the quality and reliability of the maintenance work.</p><p>To demonstrate one of the applications of the prototype VR system developed in this work, a training environment for maintenance is adopted. The machinery that is under maintenance is a centrifugal pump system widely used in refinery.</p><h3 class="c-article__sub-heading" id="Sec14">Customisation of the desktop VR system for maintenance training</h3><p>Applying the proposed general shell to a maintenance application indicates that the constructed virtual environment should simulate the real maintenance environment of the pump system. Therefore, the geometric models for the representation of the maintenance environment need to be constructed in external CAD software and then converted into the acceptable VLM format for the system using the VLM file converter. The system will then organise the imported models into the hierarchical structure described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-004-0127-z#Sec6">3.2</a>. Another customisation is to incorporate related domain knowledge and information for the user to appreciate the maintenance work. For the maintenance case study here, the maintenance knowledge embodies the proper disassembly plan to different faulty components. A near-optimal disassembly plan may take into consideration various disassembly factors, such as tools needed and orientation change required for specific disassembly operations. The results from previous research work in disassembly sequence planning [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Li JR, Tor SB, Khoo LP (2002) A hybrid disassembly sequence planning approach for maintenance. J Comput Inform Sci Eng (JCISE) 2:28–37" href="/article/10.1007/s10055-004-0127-z#ref-CR9" id="ref-link-section-d75187e675">9</a>] is adopted to generate the maintenance knowledge base, i.e. once the user has selected certain components for maintenance, its corresponding near-optimal disassembly sequence can then be retrieved from the knowledge base to guide the user in the disassembly process in the virtual environment.</p><h3 class="c-article__sub-heading" id="Sec15">Desktop VR system interface</h3><p>The case study is performed with a desktop PC (Dell Precision 650MT with Intel Xeon 2.8 GHz processor, 1 GB SDRAM memory and 256 MB 3DLabs graphic card). The implemented application is named as virtual reality enabled system for maintenance training (V-REALISM).</p><p>The GUI is designed with the reference to the interface layouts of popular CAD software that are widely used by the industry, such as SolidWorks and AutoCAD. The concern is to provide the end user, the trainee engineer, with a familiar user interface for more efficient training purposes. The GUI (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig6">6</a>) has four sub-windows, namely, a main menu window, a VR display window, a left-hand information window and a bottom output window. The interaction between V-REALISM and the users is implemented through the main menu and the left-hand information windows via mouse and keyboard input. The main menu window provides the overall functions of V-REALISM. It allows the users to trigger a system message map to activate a maintenance process, such as disassembly sequence planning, VR display or disassembly process. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb6.jpg?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb6.jpg" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p> The GUI of the desktop VR maintenance application</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>To enable information sharing of the maintenance process for learning effect, the left-hand information window is split into two tab dialogs: ‘V_REALISM’ for the display of the hierarchical structure of the geometric models and ‘Disassembly Info’ for the interaction of virtual disassembly processes. The tab dialog of ‘V_REALISM’ allows the user to appreciate the composition of the virtual environment and the machinery so as to prepare themselves for the similar real work site. The ‘Disassembly Info’ tab provides the users with an overview of the maintenance process and a fixed information window to track the information of different maintenance phases. This is used to facilitate the learning process. The bottom output window allows V-REALISM to output text instructions to the users. The virtual environment for pump system maintenance is shown in the VR display window. Users are able to navigate and visualise the environment in this window. Moreover, to enhance interactivity, toolbars such as the navigation toolbar and standard system toolbar have also been incorporated (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig6">6</a>).</p><h3 class="c-article__sub-heading" id="Sec16">Walkthrough of the maintenance training process</h3><p>The selection of the faulty component(s) that need to be disassembled is provided through user interaction. Assuming that the user chooses to replace the two bearings on the pump shaft, the system will retrieve the near-optimal disassembly sequence from the knowledge base accordingly. The optimisation of the sequence is based on disassembly time minimisation. The result is then output in the bottom output window (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig7">7</a>) to acknowledge the users. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb7.jpg?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb7.jpg" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p> Disassembly process in the prototype</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>Subsequently, disassembly operations are carried out according to the sequence. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig7">7</a>
shows that the first operation is to dismantle a sub-assembly from the pump. The sub-assembly comprises the components, ‘Casing’ and ‘Casing Wearing Ring’ (inside the component, ‘Casing’). The left-hand disassembly information tab dialog also shows the information on the current disassembly process, for example, ‘Current target’ for the target component of the current disassembly process. Thus, the users can visualise the disassembly process, get the knowledge of the 3D geometric relationship among the components with VR display and also obtain real-time disassembly information.</p><p>During the disassembly process, the components are removed one at a time from the pump assembly by following the training programme either automatically or manually, whichever is preferred by the user. The disassembly trajectory is used to illustrate the different orientation of the disassembly operations. In this manner, the user can have a clear idea of the orientation of the disassembly operations. This would enhance their understanding of the disassembly process too. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig8">8</a> shows the virtual disassembly process after seven operations. Here, the component being disassembled is the ‘Impeller Locknut’. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig8">8</a> also shows that users can navigate in the virtual environment and change the direction of view at the same time during the disassembly process. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb8.jpg?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb8.jpg" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p> Virtual disassembly process after seven operations</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>With the disassembly process proceeding, both of the bearings, the target components for maintenance, become exposed and removable (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig9">9</a>). The system highlighted the target components for identification. Users are able to practise the disassembly process and also the overall maintenance process as many times as they wish for training purposes by using V-REALISM. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb9.jpg?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb9.jpg" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p> Removal of target components for maintenance</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<h3 class="c-article__sub-heading" id="Sec17">Discussions</h3><p>By importing the geometric models of the maintenance environment and integrating with the maintenance knowledge base, the general desktop VR prototype has been customised into a training application for maintenance of a refinery pump system. The trainee is able to navigate inside the virtual worksite and disassemble or assemble the pumping system for maintenance training purpose (Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig7">7</a>
and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig8">8</a>). The overall environment includes 451 single parts and 860,865 polygons after triangulation. More importantly, it has high-depth complexity due to the highly constrained pump assembly, since most of the parts in this rotary system are assembled along the direction of its shaft. During the maintenance training process, users will practise the assembly or disassembly on the workbench with the right orientation. This further adds up the depth complexity of the dynamic display (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig7">7</a>). Therefore, proper visibility culling to offer a virtual display with an interactive rendering rate is crucial to give the user an immersive feeling in the virtual environment. The comparison result with proposed visibility culling approach is illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig10">10</a>. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10a, b</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb10.jpg?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zfhb10.jpg" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p> Illustration of the depth complexity of the virtual maintenance environment. (<b>a</b>) An overview of the virtual environment for maintenance training of a refinery pump system. (<b>b</b>) A close-up view during the virtual disassembly process. Note: In (a), a total of 82.7% of the model is culled, in which 0.5% is by view-frustum and the rest by occlusion culling. In (b), a total of 83.8% of the model is culled, in which 14.1% is culled by view-frustum culling and 69.7% is culled by occlusion culling</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>Although for every frame rendering, the visibility culling approach consumes computing time in the steps of view-frustum culling using the OpenGL<i> selection mode</i>, occlusion map rendering, frame buffer reading and occlusion map processing. Compared with a direct display without visibility culling, the frame rate with the visibility culling approach has been greatly improved. In terms of culling efficiency, the proposed approach also significantly reduced the number of polygons needed to be rendered in each individual frame, compared with that of with view-frustum culling. By comparing the frame rates achieved by the proposed visibility culling approach (view-frustum culling and occlusion culling) and the view-frustum culling only (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-004-0127-z#Fig11">11</a>), the result has demonstrated the greatly improved efficiency of the proposed novel occlusion culling algorithm in dealing with the highly depth-complex virtual environment. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zflb11.gif?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-004-0127-z/MediaObjects/s10055-004-0127-zflb11.gif" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p> Frame rate and visibility culling rate illustration</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-004-0127-z/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>So, the implemented prototype has shown its advantage in fast rendering of both quantity and depth of training environment for industrial applications. With the case study conducted on the desktop PC, the rendering rate for this virtual training environment can speed up by four times at most (from around 4 frames/s to 16 frames/s), therefore, the visualisation effect of the virtual training process is smoother and more friendly to the end user.</p></div></div></section><section aria-labelledby="Sec18"><div class="c-article-section" id="Sec18-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec18">Conclusion</h2><div class="c-article-section__content" id="Sec18-content"><p>The goal of bringing virtual reality technology to industrial applications has challenged the researchers from both academia and industries. In this paper, a prototype desktop VR system is proposed for industrial training applications. It provides a hierarchical data structure, which is a modified BSP tree, to organise the training environment. To ensure the immersive feeling of the user in the virtual training environment, a visibility culling approach is proposed to enhance the desktop VR system with an interactive display. It is well suited to the dynamically changing environment caused by interactive operations during the training process. To customise the VR system to a specific domain application, the prototype provides a data interface to import the geometric models for the construction of the virtual environment and the link to the domain knowledge base. In this manner, the general system architecture can be adapted to different domains for training purposes. The case study with the refinery pump system has demonstrated the virtual maintenance training using this prototype. It appears that the system is able to offer intelligent assistance in generating a reasonable disassembly sequence and guiding the users through the disassembly process for maintenance accordingly. Furthermore, the visibility culling approach implemented has shown its significance in improving the real-time rendering rates. This is crucial for the interactive display of a desktop virtual environment with both depth and quantity complexity that is common in industrial applications. Compared with reported immersive VR systems, this desktop prototype VR system does not relegate a training task to a training room or a particular audience. With the hardware and software required, the proposed system offers a portable and affordable VR solution to industrial training applications.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content=". Bartz, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Bartz D, Meissner M, Huettner T (1999) OpenGL-assisted occlusion culling for large polygonal models. Comput Gr" /><span class="c-article-references__counter">1.</span><p class="c-article-references__text" id="ref-CR1">Bartz D, Meissner M, Huettner T (1999) OpenGL-assisted occlusion culling for large polygonal models. Comput Graph 23:667–679</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=Comput%20Graph&amp;volume=23&amp;publication_year=1999&amp;author=Bartz%2C">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Burdea GC, Coiffet P (2003) Virtual reality technology. Wiley, New Jersey" /><span class="c-article-references__counter">2.</span><p class="c-article-references__text" id="ref-CR2">Burdea GC, Coiffet P (2003) Virtual reality technology. Wiley, New Jersey</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content=". Cruz-Neira, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Cruz-Neira C, Sandin DJ, DeFanti TA, Kenyon RV, Hart JC (1992) The CAVE: audio visual experience automatic vir" /><span class="c-article-references__counter">3.</span><p class="c-article-references__text" id="ref-CR3">Cruz-Neira C, Sandin DJ, DeFanti TA, Kenyon RV, Hart JC (1992) The CAVE: audio visual experience automatic virtual environment. Commun ACM 35(6):65–72</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F129888.129892" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=Commun%20ACM&amp;volume=35&amp;publication_year=1992&amp;author=Cruz-Neira%2C">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content=". Gomes, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Gomes de Sa A, Zachmann G (1999) Virtual reality as a tool for verification of assembly and maintenance proces" /><span class="c-article-references__counter">4.</span><p class="c-article-references__text" id="ref-CR4">Gomes de Sa A, Zachmann G (1999) Virtual reality as a tool for verification of assembly and maintenance processes. Comput Graph 23:389–403</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0097-8493%2899%2900047-3" aria-label="View reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=Comput%20Graph&amp;volume=23&amp;publication_year=1999&amp;author=Gomes%2C">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Greene N (1996) Hierarchical polygon tiling with coverage masks. In: Proceedings of the ACM SIGGRAPH’96 confer" /><span class="c-article-references__counter">5.</span><p class="c-article-references__text" id="ref-CR5">Greene N (1996) Hierarchical polygon tiling with coverage masks. In: Proceedings of the ACM SIGGRAPH’96 conference, New Orleans, Louisiana, August 1996, pp 65–74</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Greene N, Kass M, Miller G (1993) Hierarchical Z-buffer visibility. In: Proceedings of the ACM SIGGRAPH’93 con" /><span class="c-article-references__counter">6.</span><p class="c-article-references__text" id="ref-CR6">Greene N, Kass M, Miller G (1993) Hierarchical Z-buffer visibility. In: Proceedings of the ACM SIGGRAPH’93 conference, Anaheim, California, August 1993, pp 231–238</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Johnson A, Roussos M, Leigh J, Barnes C, Vasilakis C, Moher T (1998) The NICE project: learning together in a " /><span class="c-article-references__counter">7.</span><p class="c-article-references__text" id="ref-CR7">Johnson A, Roussos M, Leigh J, Barnes C, Vasilakis C, Moher T (1998) The NICE project: learning together in a virtual world. In: Proceedings of the VRAIS ‘98 conference, Atlanta, Georgia, March 1998, pp 176–183</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kashiwa K, Mitani T, Tezura T, Yoshikawa TH (1995) Development of machine-maintenance training system in virtu" /><span class="c-article-references__counter">8.</span><p class="c-article-references__text" id="ref-CR8">Kashiwa K, Mitani T, Tezura T, Yoshikawa TH (1995) Development of machine-maintenance training system in virtual environment. In: Proceedings of the 4th IEEE international workshop on robot and human communication (RO-MAN’95), Tokyo, Japan, July 1995, pp 295–300</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content=". Li, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Li JR, Tor SB, Khoo LP (2002) A hybrid disassembly sequence planning approach for maintenance. J Comput Inform" /><span class="c-article-references__counter">9.</span><p class="c-article-references__text" id="ref-CR9">Li JR, Tor SB, Khoo LP (2002) A hybrid disassembly sequence planning approach for maintenance. J Comput Inform Sci Eng (JCISE) 2:28–37</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=J%20Comput%20Inform%20Sci&amp;volume=Eng&amp;publication_year=2002&amp;author=Li%2C">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Naylor BF (1992) Partitioning tree image representation and generation from 3D geometric models. In: Proceedin" /><span class="c-article-references__counter">10.</span><p class="c-article-references__text" id="ref-CR10">Naylor BF (1992) Partitioning tree image representation and generation from 3D geometric models. In: Proceedings of Graphics Interface’92, Vancouver, Canada, May 1992, pp 201–212</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content=". Rooks, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Rooks B (1999) The reality of virtual reality. Assembly Autom 19(3):203–208" /><span class="c-article-references__counter">11.</span><p class="c-article-references__text" id="ref-CR11">Rooks B (1999) The reality of virtual reality. Assembly Autom 19(3):203–208</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1108%2F01445159910280065" aria-label="View reference 11">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=Assembly%20Autom&amp;volume=19&amp;publication_year=1999&amp;author=Rooks%2C">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sleeman D, Brown JS (1982) Intelligent tutoring systems. Academic Press, London" /><span class="c-article-references__counter">12.</span><p class="c-article-references__text" id="ref-CR12">Sleeman D, Brown JS (1982) Intelligent tutoring systems. Academic Press, London</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Wenger E (1987) Artificial intelligence and tutoring systems. Morgan Kaufmann, California" /><span class="c-article-references__counter">13.</span><p class="c-article-references__text" id="ref-CR13">Wenger E (1987) Artificial intelligence and tutoring systems. Morgan Kaufmann, California</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content=". Weyrich, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Weyrich M, Drews P (1999) An interactive environment for virtual manufacturing: the virtual workbench. Comput " /><span class="c-article-references__counter">14.</span><p class="c-article-references__text" id="ref-CR14">Weyrich M, Drews P (1999) An interactive environment for virtual manufacturing: the virtual workbench. Comput Ind 38:5–15</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=Comput%20Ind&amp;volume=38&amp;publication_year=1999&amp;author=Weyrich%2C">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zhang HS, Manocha D, Hudson T, Hoff K (1997) Visibility culling using hierarchical occlusion map. In: Proceedi" /><span class="c-article-references__counter">15.</span><p class="c-article-references__text" id="ref-CR15">Zhang HS, Manocha D, Hudson T, Hoff K (1997) Visibility culling using hierarchical occlusion map. In: Proceedings of the ACM SIGGRAPH’97 conference, Los Angeles, California, August 1997, pp 77–88</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-004-0127-z-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Manufacturing Solutions Division,  Autodesk Inc. 391B, Orchard Road, #12-06 Ngee Ann City Tower B,  238874, Singapore</p><p class="c-article-author-affiliation__authors-list">Q. H. Wang</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Robotics Research Centre, School of Mechanical and Production Engineering, Nanyang Technological University, 50 Nanyang Avenue, 639798, Singapore</p><p class="c-article-author-affiliation__authors-list">J. R. Li</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Q__H_-Wang"><span class="c-article-authors-search__title u-h3 js-search-name">Q. H. Wang</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Q. H.+Wang&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Q. H.+Wang" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Q. H.+Wang%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-J__R_-Li"><span class="c-article-authors-search__title u-h3 js-search-name">J. R. Li</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;J. R.+Li&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=J. R.+Li" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22J. R.+Li%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-004-0127-z/email/correspondent/c1/new">Q. H. Wang</a>.</p></div></div></section><section aria-labelledby="additional-information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><p>The work was done in Nanyang Technological University.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=A%20desktop%20VR%20prototype%20for%20industrial%20training%20applications&amp;author=Q.%20H.%20Wang%20et%20al&amp;contentID=10.1007%2Fs10055-004-0127-z&amp;publication=1359-4338&amp;publicationDate=2004-05-20&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Wang, Q.H., Li, J.R. A desktop VR prototype for industrial training applications.
                    <i>Virtual Reality</i> <b>7, </b>187–197 (2004). https://doi.org/10.1007/s10055-004-0127-z</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-004-0127-z.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2003-12-12">12 December 2003</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2004-03-29">29 March 2004</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2004-05-20">20 May 2004</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2004-06">June 2004</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-004-0127-z" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-004-0127-z</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Virtual reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Desktop virtual environment</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Computer-based training</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Visibility culling</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-004-0127-z.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=127;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

