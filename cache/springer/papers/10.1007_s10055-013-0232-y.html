<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="The design space of dynamic interactive virtual environments"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Virtual environments have become a key component of many fields and the critical component of virtual reality applications. Due to their virtual nature, they can accommodate an infinite number of..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/18/2.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="The design space of dynamic interactive virtual environments"/>

    <meta name="dc.source" content="Virtual Reality 2013 18:2"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2013-09-28"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2013 Springer-Verlag London"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Virtual environments have become a key component of many fields and the critical component of virtual reality applications. Due to their virtual nature, they can accommodate an infinite number of possibilities. A theoretical work is presented, which decomposes those innumerous possibilities into concepts to help clarify the vast design space and provide insights into future applied research. We propose that what makes environments interesting and engaging is having worlds that are both active and reactive. This article explores the manifestations of those actions and reactions in what we term: dynamic components and interactions. We term worlds containing these dynamic interactive virtual environments (DIVE). An analysis of each component time was performed, with the purpose of providing a theoretical understanding of the respective design spaces. Initially, we collected the myriad possibilities of each component, e.g., the possible kinds of interactions. We point to examples throughout the field to ground and explain concepts presented. We then categorized of each area into taxonomies. The result of the analyses provides insights into the design space of virtual environments, exposes several avenues of research that are yet underexplored, and provides better understandings of ways in which DIVE creation can be supported."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2013-09-28"/>

    <meta name="prism.volume" content="18"/>

    <meta name="prism.number" content="2"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="101"/>

    <meta name="prism.endingPage" content="116"/>

    <meta name="prism.copyright" content="2013 Springer-Verlag London"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-013-0232-y"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-013-0232-y"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-013-0232-y.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-013-0232-y"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="The design space of dynamic interactive virtual environments"/>

    <meta name="citation_volume" content="18"/>

    <meta name="citation_issue" content="2"/>

    <meta name="citation_publication_date" content="2014/06"/>

    <meta name="citation_online_date" content="2013/09/28"/>

    <meta name="citation_firstpage" content="101"/>

    <meta name="citation_lastpage" content="116"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-013-0232-y"/>

    <meta name="DOI" content="10.1007/s10055-013-0232-y"/>

    <meta name="citation_doi" content="10.1007/s10055-013-0232-y"/>

    <meta name="description" content="Virtual environments have become a key component of many fields and the critical component of virtual reality applications. Due to their virtual nature, th"/>

    <meta name="dc.creator" content="Kristopher J. Blom"/>

    <meta name="dc.creator" content="Steffi Beckhaus"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Beckhaus S (2003) Dynamic potential fields for guided exploration in virtual environments. 6. Fraunhofer Series in Information and Communication Technology, vol 6. Shaker Verlag, Aachen"/>

    <meta name="citation_reference" content="Beckhaus S, Blom KJ, Haringer M (2007) ChairIO&#8212;the chair-based interface. In: Magerkurth C, R&#246;cker C (eds) Concepts and technologies for pervasive games: a reader for pervasive gaming research, vol 1. Shaker Verlag, Aachen, pp 231&#8211;264"/>

    <meta name="citation_reference" content="Bernier E, Chellali R, Mouttapa Thouvenin I, Blom KJ (2012) The ICED plug-in for virtual reality, immersive creation and edition of animation. In: Workshop on software engineering and architectures for real time interactive systems (SEARIS). Costa Mesa, CA, USA,  pp 36&#8211;42. doi:
                    10.1109/SEARIS.2012.6231167
                    
                  
                "/>

    <meta name="citation_reference" content="Bierbaum A, Cruz-Neira C (2000) Run-time reconfiguration in VR Juggler. In: 4th immersive projection technology workshop"/>

    <meta name="citation_reference" content="citation_journal_title=Commun ACM; citation_title=Collaborative augmented reality; citation_author=M Billinghurst, H Kato; citation_volume=45; citation_issue=7; citation_publication_date=2002; citation_pages=64-70; citation_doi=10.1145/514236.514265; citation_id=CR5"/>

    <meta name="citation_reference" content="Blom KJ (2009) Dynamic, interactive virtual environments. Sierke Verlag, G&#246;ttingen"/>

    <meta name="citation_reference" content="Blom KJ, Beckhaus S (2005) Emotional storytelling. In: IEEE virtual reality 2005 conference workshop &#8220;Virtuality structure&#8221;, Bonn, Germany, pp 23&#8211;27"/>

    <meta name="citation_reference" content="Blom KJ, Beckhaus S (2007a) Functional reactive virtual reality. In: IPT/EGVE &#8217;07: short paper proceedings of the IPT/EuroGraphics workshop on virtual environments, EuroGraphics Association, pp 295&#8211;302"/>

    <meta name="citation_reference" content="Blom KJ, Beckhaus S (2007b) Supporting the creation of dynamic, interactive virtual environments. In: VRST &#8217;07: proceedings of the 2007 ACM symposium on virtual reality software and technology, ACM Press, pp 51&#8211;54. doi:
                    10.1145/1315184.1315191
                    
                  
                "/>

    <meta name="citation_reference" content="Boussinot F, Susini JF, Tran FD, Hazard L (2001) A reactive behavior framework for dynamic virtual worlds. In: Web3D &#8217;01: proceedings of the sixth international conference on 3D Web technology, ACM Press, New York, NY, USA, pp 69&#8211;75"/>

    <meta name="citation_reference" content="citation_journal_title=J Vis Lang Comput; citation_title=Formalizing the design, evaluation, and application of interaction techniques for immersive virtual environments; citation_author=DA Bowman, L Hodges; citation_volume=10; citation_issue=1; citation_publication_date=1999; citation_pages=37-53; citation_id=CR11"/>

    <meta name="citation_reference" content="Brooks H, DeKeyser T, Jaskot D, Sibert D, Sledd R, Stilwell W, Scherer W (2004) Using agent-based simulation to reduce collateral damage during military operations. In: Systems and information engineering design symposium, 2004. Proceedings of the 2004 IEEE, IEEE, pp 71&#8211;77"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Phys Commun; citation_title=Time, data-time, and real-time interactive visualization; citation_author=S Bryson; citation_volume=11; citation_issue=3; citation_publication_date=1997; citation_pages=270-274; citation_doi=10.1063/1.4822556; citation_id=CR13"/>

    <meta name="citation_reference" content="Cavazza M, Hartley S, Lugrin JL, Bras ML (2003) Alternative reality: a new platform for virtual reality art. In: Proceedings of virtual reality software and technology (VRST), ACM Press, pp 100&#8211;107. doi:
                    10.1145/1008653.1008672
                    
                  
                "/>

    <meta name="citation_reference" content="Courtney A, Nilsson H, Peterson J (2003) The Yampa Arcade. In: ACM SIGPLAN Haskell workshop, ACM SIGPLAN, pp 7&#8211;18"/>

    <meta name="citation_reference" content="Dachselt R, Rukzio E (2003) Behavior3D: an XML-based framework for 3D graphics behavior. In: Proceedings of the ACM Web3D 2003 conference, ACM Press, pp 101&#8211;112"/>

    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Immersive interfaces for engagement and learning; citation_author=C. Dede; citation_volume=323; citation_issue=5910; citation_publication_date=2009; citation_pages=66-69; citation_doi=10.1126/science.1167311; citation_id=CR17"/>

    <meta name="citation_reference" content="de Haan G, Koutek M, Post FH (2005) IntenSelect: using dynamic object rating for assisting 3D object selection. In: Proceedings of the 9th IPT and 11th Eurographics VE workshop (EGVE), pp 201&#8211;209"/>

    <meta name="citation_reference" content="citation_journal_title=J Clin Psychiatry; citation_title=Virtual reality exposure therapy for the treatment of posttraumatic stress disorder following September 11, 2001; citation_author=J Difede, J Cukor, N Jayasinghe, I Patt, S Jedel, L Spielman, C Giosan, H Hoffman; citation_volume=68; citation_issue=11; citation_publication_date=2007; citation_pages=1639-1647; citation_id=CR19"/>

    <meta name="citation_reference" content="Elliott C, Hudak P (1997) Functional reactive animation. In: International conference on functional programming, pp 196&#8211;203"/>

    <meta name="citation_reference" content="Emond B, Fournier H, Lapointe J et&#160;al (2010) Applying advanced user models and input technologies to augment military simulation-based training. In: Proceedings of the 2010 spring military modeling and simulation symposium, pp 1&#8211;7"/>

    <meta name="citation_reference" content="citation_journal_title=Br J Psychiatry; citation_title=Virtual reality study of paranoid thinking in the general population; citation_author=D Freeman, K Pugh, A Antley, M Slater, P Bebbington, M Gittins, G Dunn, E Kuipers, D Fowler, P Garety; citation_volume=192; citation_issue=4; citation_publication_date=2008; citation_pages=258-263; citation_doi=10.1192/bjp.bp.107.044677; citation_id=CR22"/>

    <meta name="citation_reference" content="citation_journal_title=CyberPsychol Behav; citation_title=Emotional response to virtual reality exposure across different cultures: the role of the attribution process; citation_author=A Gorini, J Mosso, D Mosso, E Pineda, N Ru&#237;z, M Ram&#237;ez, J Morales, G Riva; citation_volume=12; citation_issue=6; citation_publication_date=2009; citation_pages=699-705; citation_doi=10.1089/cpb.2009.0192; citation_id=CR23"/>

    <meta name="citation_reference" content="citation_journal_title=Cyberpsychol Behav; citation_title=Brain&#8211;computer interface for virtual reality control; citation_author=C Guger, C Groenegress, C Holzner, G Edlinger, M Slater; citation_volume=12; citation_issue=1; citation_publication_date=2009; citation_pages=84; citation_id=CR24"/>

    <meta name="citation_reference" content="Haringer M, Beckhaus S (2010) Effect based scene manipulation for multimodal VR systems. In: IEEE VR 2010: proceedings of the IEEE virtual reality conference"/>

    <meta name="citation_reference" content="citation_journal_title=Presence; citation_title=Adaptive generation of emotional impact using enhanced virtual environments; citation_author=M Haringer, S Beckhaus; citation_volume=21; citation_issue=1; citation_publication_date=2012; citation_pages=96-116; citation_doi=10.1162/PRES_a_00092; citation_id=CR26"/>

    <meta name="citation_reference" content="Hassanpour R, Wong S, Shahbahrami A (2008) Vision based hand gesture recognition for human computer interaction: a review. In: IADIS international conference interfaces and human computer interaction, p 125"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoper Virtual Environ; citation_title=Telepresence; citation_author=RM Held, NI Durlach; citation_volume=1; citation_publication_date=1992; citation_pages=109-112; citation_id=CR28"/>

    <meta name="citation_reference" content="Hernando J, Martinez J, Martin V, L&#243;pez M, Martin-Gago J (2009) Svis: a computational steering visualization environment for surface structure determination. In: Visualisation, 2009. VIZ&#8217;09. Second international conference in, IEEE, pp 36&#8211;39"/>

    <meta name="citation_reference" content="Herrlich M, Walther-Franks B, Schr&#246;der-Kroll R, Holthusen J, Malaka R (2011) Proxy-based selection for occluded and dynamic objects. In: Smart graphics, Springer, pp 142&#8211;145"/>

    <meta name="citation_reference" content="citation_journal_title=Cyberpsychol Behav; citation_title=A virtual environment for the treatment of chronic combat-related post-traumatic stress disorder; citation_author=L Hodges, B Rothbaum, R Alarcon, D Ready, F Shahar, K Graap, J Pair, P Hebert, D Gotz, B Wills; citation_volume=2; citation_issue=1; citation_publication_date=1999; citation_pages=7-14; citation_doi=10.1089/cpb.1999.2.7; citation_id=CR31"/>

    <meta name="citation_reference" content="citation_journal_title=Cyberpsychol Behav; citation_title=The effectiveness of virtual reality for dental pain control: a case study; citation_author=H Hoffman, A Garcia-Palacios, D Patterson, M Jensen, T Furness, W Ammons; citation_volume=4; citation_issue=4; citation_publication_date=2001; citation_pages=527-535; citation_doi=10.1089/109493101750527088; citation_id=CR32"/>

    <meta name="citation_reference" content="Kallmann M, Thalmann D (1999) Direct 3D interaction with smart objects. In: VRST &#8217;99: proceedings of the ACM symposium on virtual reality software and technology, ACM Press, New York, NY, USA, pp 124&#8211;130. doi:
                    10.1145/323663.323683
                    
                  
                "/>

    <meta name="citation_reference" content="Konieczny J, Heckman J, Meyer G, Manyen M, Rabens M, Shimizu C (2008) Automotive spray paint simulation. Lecture Notes in Comput Sci 5358:998&#8211;1007"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Comput Graph Appl; citation_title=Building on realism and magic for designing 3D interaction techniques; citation_author=A Kulik; citation_volume=29; citation_issue=6; citation_publication_date=2009; citation_pages=22-33; citation_doi=10.1109/MCG.2009.115; citation_id=CR35"/>

    <meta name="citation_reference" content="Mateas M, Stern A (2003) Facade: an experiment in building a fully-realized interactive drama. In: Proceedings of the game developer&#8217;s conference: Game Design Track"/>

    <meta name="citation_reference" content="citation_journal_title=Cyberpsychol Behav Soc Netw; citation_title=A randomized, controlled trial of virtual reality-graded exposure therapy for post-traumatic stress disorder in active duty service members with combat-related post-traumatic stress disorder; citation_author=RN McLay, DP Wood, JA Webb-Murphy, JL Spira, MD Wiederhold, JM Pyne, BK Wiederhold; citation_volume=13; citation_issue=1; citation_publication_date=2010; citation_pages=3-11; citation_doi=10.1089/cyber.2009.0346; citation_id=CR37"/>

    <meta name="citation_reference" content="Mesing B, Hellmich C (2006) Using aspect oriented methods to add behaviour to X3D documents. In: Proceedings of the ACM Web3D 2006 conference, ACM"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoper Virtual Environ; citation_title=Modeling of tool&#8211;tissue interactions for computer-based surgical simulation: a literature review; citation_author=S Misra, K Ramesh, A Okamura; citation_volume=17; citation_issue=5; citation_publication_date=2008; citation_pages=463-491; citation_doi=10.1162/pres.17.5.463; citation_id=CR40"/>

    <meta name="citation_reference" content="Pape D (1998) Crayoland. In: SIGGRAPH &#8217;98: ACM SIGGRAPH 98 electronic art and animation catalog, ACM Press, New York, NY, USA, p 116"/>

    <meta name="citation_reference" content="Rehn GD, Lemessi M, Vance JM, Dorozhkin DV (2004) Integrating operations simulation results with an immersive virtual reality environment. In: WSC &#8217;04: Proceedings of the 36th winter simulation conference, pp 1713&#8211;1719"/>

    <meta name="citation_reference" content="citation_journal_title=Surg Endosc; citation_title=Review of methods for objective surgical skill evaluation; citation_author=C Reiley, H Lin, D Yuh, G Hager; citation_volume=25; citation_issue=2; citation_publication_date=2011; citation_pages=356-366; citation_doi=10.1007/s00464-010-1190-z; citation_id=CR43"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoper Virtual Environ; citation_title=Modeling dynamic interaction in virtual environments and the evaluation of dynamic virtual fixtures; citation_author=P Richard, M Naud, FX Inglese, E Richard; citation_volume=21; citation_issue=3; citation_publication_date=2012; citation_pages=321-337; citation_doi=10.1162/PRES_a_00116; citation_id=CR44"/>

    <meta name="citation_reference" content="Rizzo A, Rothbaum BO, Graap K (2007) Virtual reality applications for the treatment of combat-related PTSD. In: Figley CR, Nash WP (eds) Combat stress injury: theory, research, and management. Routledge, New York, pp 183&#8211;204"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph; citation_title=NICE: combining constructionism, narrative and collaboration in a virtual learning environment; citation_author=M Roussos, AE Johnson, J Leigh, CA Vasilakis, CR Barnes, TG Moher; citation_volume=31; citation_issue=3; citation_publication_date=1997; citation_pages=62-63; citation_doi=10.1145/262171.262264; citation_id=CR46"/>

    <meta name="citation_reference" content="Salzmann H, Moehring M, Froehlich B (2009) Virtual vs. real-world pointing in two-user scenarios. In: VR &#8217;09: Proceedings of the 2009 IEEE virtual reality conference, IEEE Computer Society, Washington, DC, USA, pp 127&#8211;130. doi:
                    10.1109/VR.2009.4811011
                    
                  
                "/>

    <meta name="citation_reference" content="citation_journal_title=Nat Rev Neurosci; citation_title=From presence to consciousness through virtual reality; citation_author=MV Sanchez-Vives, M Slater; citation_volume=6; citation_issue=4; citation_publication_date=2005; citation_pages=332-339; citation_doi=10.1038/nrn1651; citation_id=CR48"/>

    <meta name="citation_reference" content="Schr&#246;der-Kroll R, Blom KJ, Beckhaus S (2008) Interaction techniques for dynamic virtual environments. In: Proceedings of &#8220;Virtuelle und Erweiterte Realit&#228;t&#8221; workshop of the Gesellschaft f&#252;r Informatik e.V. (GI), Shaker Verlag, pp 57&#8211;68"/>

    <meta name="citation_reference" content="citation_journal_title=Expert Rev Neurother; citation_title=Applications of virtual reality for pain management in burn-injured patients; citation_author=S Sharar, W Miller, A Teeley, M Soltani, H Hoffman, M Jensen, D Patterson; citation_volume=8; citation_issue=11; citation_publication_date=2008; citation_pages=1667; citation_doi=10.1586/14737175.8.11.1667; citation_id=CR50"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoper Virtual Environ; citation_title=Musings on telepresence and virtual presence; citation_author=T Sheridan; citation_volume=1; citation_issue=1; citation_publication_date=1992; citation_pages=120-126; citation_id=CR51"/>

    <meta name="citation_reference" content="citation_title=Networked virtual environments. Design and implementation; citation_publication_date=1999; citation_id=CR52; citation_author=S Singhal; citation_author=M Zyda; citation_publisher=Addison Wesley"/>

    <meta name="citation_reference" content="citation_journal_title=Philos Trans R Soc Lond B Biol Sci; citation_title=Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments; citation_author=M Slater; citation_volume=364; citation_issue=1535; citation_publication_date=2009; citation_pages=3549-3557; citation_doi=10.1098/rstb.2009.0138; citation_id=CR53"/>

    <meta name="citation_reference" content="citation_journal_title=Anu Psicol; citation_title=How we experience immersive virtual environments: the concept of presence and its measurement; citation_author=M Slater, B Lotto, MM Arnold, MV Sanchez-Vives; citation_volume=40; citation_issue=2; citation_publication_date=2009; citation_pages=193-210; citation_id=CR54"/>

    <meta name="citation_reference" content="Steed A. (2006) Towards a general model for selection in virtual environments. In: Proceedings of the IEEE symposium on 3D user interfaces (3DUI), IEEE, pp 103&#8211;110"/>

    <meta name="citation_reference" content="citation_journal_title=J Commun; citation_title=Defining virtual reality: dimensions determining telepresence; citation_author=J Steuer; citation_volume=42; citation_issue=4; citation_publication_date=1992; citation_pages=73-93; citation_doi=10.1111/j.1460-2466.1992.tb00812.x; citation_id=CR56"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Hum Behav; citation_title=Components of human experience in virtual environments; citation_author=J Takatalo, G Nyman, L Laaksonen; citation_volume=24; citation_issue=1; citation_publication_date=2008; citation_pages=1-15; citation_doi=10.1016/j.chb.2006.11.003; citation_id=CR57"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph; citation_title=3D collision detection: a survey; citation_author=F Thomas, C Torras; citation_volume=25; citation_publication_date=2001; citation_pages=269-285; citation_doi=10.1016/S0097-8493(00)00130-8; citation_id=CR58"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph Appl IEEE; citation_title=Immersive VR for scientific visualization: a progress report; citation_author=A Van Dam, A Forsberg, D Laidlaw, J LaViola, R Simpson; citation_volume=20; citation_issue=6; citation_publication_date=2000; citation_pages=26-52; citation_doi=10.1109/38.888006; citation_id=CR59"/>

    <meta name="citation_reference" content="citation_journal_title=Surg Endosc; citation_title=The value of haptic feedback in conventional and robot-assisted minimal invasive surgery and virtual reality training: a current review; citation_author=O Meijden, M Schijven; citation_volume=23; citation_issue=6; citation_publication_date=2009; citation_pages=1180-1190; citation_doi=10.1007/s00464-008-0298-x; citation_id=CR38"/>

    <meta name="citation_reference" content="Wan Z, Hudak P (2000) Functional reactive programming from first principles. In: Conference on programming language design and implementation (PLDI&#8217;00), ACM SIGPLAN, ACM Press, pp 242&#8211;252"/>

    <meta name="citation_reference" content="Wu W, Arefin A, Rivas R, Nahrstedt K, Sheppard R, Yang Z (2009) Quality of experience in distributed interactive multimedia environments: toward a theoretical framework. In: Proceedings of the seventeen ACM international conference on multimedia, ACM, pp 481&#8211;490"/>

    <meta name="citation_reference" content="citation_title=Review of modern speech synthesis; citation_inbook_title=Electronics and signal processing, lecture notes in electrical engineering, vol 97; citation_publication_date=2011; citation_pages=517-524; citation_id=CR62; citation_author=C Xian-Yi; citation_author=P Yan; citation_publisher=Springer"/>

    <meta name="citation_reference" content="Yang U, Lee G, Kim Y, Jo D, Choi J, Kim K (2010) Virtual reality based welding training simulator with 3D multimodal interaction. In: Cyberworlds (CW), 2010 international conference on, IEEE, pp 150&#8211;154"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Comput Intell AI Games; citation_title=Real-time game adaptation for optimizing player satisfaction; citation_author=GN Yannakakis, J Hallam; citation_volume=1; citation_issue=2; citation_publication_date=2009; citation_pages=121-133; citation_doi=10.1109/TCIAIG.2009.2024533; citation_id=CR64"/>

    <meta name="citation_reference" content="citation_journal_title=Presence; citation_title=Presence as being-in-the-world; citation_author=P Zahorik, R Jenison; citation_volume=7; citation_issue=1; citation_publication_date=1998; citation_pages=78-89; citation_doi=10.1162/105474698565541; citation_id=CR65"/>

    <meta name="citation_reference" content="citation_journal_title=J Neural Eng; citation_title=Towards passive brain&#8211;computer interfaces: applying brain&#8211;computer interface technology to human-machine systems in general; citation_author=TO Zander, C Kothe; citation_volume=8; citation_issue=2; citation_publication_date=2011; citation_pages=025005; citation_doi=10.1088/1741-2560/8/2/025005; citation_id=CR66"/>

    <meta name="citation_author" content="Kristopher J. Blom"/>

    <meta name="citation_author_email" content="blomk@acm.org"/>

    <meta name="citation_author_institution" content="Department Informatik, interactive media.virtual environments, Universit&#228;t Hamburg, Hamburg, Germany"/>

    <meta name="citation_author" content="Steffi Beckhaus"/>

    <meta name="citation_author_email" content="sb@steffi.beckhaus.de"/>

    <meta name="citation_author_institution" content="Department Informatik, interactive media.virtual environments, Universit&#228;t Hamburg, Hamburg, Germany"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-013-0232-y&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2014/06/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-013-0232-y"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="The design space of dynamic interactive virtual environments"/>
        <meta property="og:description" content="Virtual environments have become a key component of many fields and the critical component of virtual reality applications. Due to their virtual nature, they can accommodate an infinite number of possibilities. A theoretical work is presented, which decomposes those innumerous possibilities into concepts to help clarify the vast design space and provide insights into future applied research. We propose that what makes environments interesting and engaging is having worlds that are both active and reactive. This article explores the manifestations of those actions and reactions in what we term: dynamic components and interactions. We term worlds containing these dynamic interactive virtual environments (DIVE). An analysis of each component time was performed, with the purpose of providing a theoretical understanding of the respective design spaces. Initially, we collected the myriad possibilities of each component, e.g., the possible kinds of interactions. We point to examples throughout the field to ground and explain concepts presented. We then categorized of each area into taxonomies. The result of the analyses provides insights into the design space of virtual environments, exposes several avenues of research that are yet underexplored, and provides better understandings of ways in which DIVE creation can be supported."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>The design space of dynamic interactive virtual environments | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-013-0232-y","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Virtual environments, Dynamic interactive VEs, 3D user interaction, VR systems","kwrd":["Virtual_environments","Dynamic_interactive_VEs","3D_user_interaction","VR_systems"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-013-0232-y","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-013-0232-y","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=232;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-013-0232-y">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            The design space of dynamic interactive virtual environments
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-013-0232-y.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-013-0232-y.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2013-09-28" itemprop="datePublished">28 September 2013</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">The design space of dynamic interactive virtual environments</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Kristopher_J_-Blom" data-author-popup="auth-Kristopher_J_-Blom" data-corresp-id="c1">Kristopher J. Blom<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Universität Hamburg" /><meta itemprop="address" content="grid.9026.d, 0000000122872617, Department Informatik, interactive media.virtual environments, Universität Hamburg, Vogt-Kölln-Straße 30, 22527, Hamburg, Germany" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Steffi-Beckhaus" data-author-popup="auth-Steffi-Beckhaus">Steffi Beckhaus</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Universität Hamburg" /><meta itemprop="address" content="grid.9026.d, 0000000122872617, Department Informatik, interactive media.virtual environments, Universität Hamburg, Vogt-Kölln-Straße 30, 22527, Hamburg, Germany" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 18</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">101</span>–<span itemprop="pageEnd">116</span>(<span data-test="article-publication-year">2014</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">665 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">5 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">2 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-013-0232-y/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Virtual environments have become a key component of many fields and the critical component of virtual reality applications. Due to their virtual nature, they can accommodate an infinite number of possibilities. A theoretical work is presented, which decomposes those innumerous possibilities into concepts to help clarify the vast design space and provide insights into future applied research. We propose that what makes environments <i>interesting</i> and <i>engaging</i> is having worlds that are both active and reactive. This article explores the manifestations of those actions and reactions in what we term: dynamic components and interactions. We term worlds containing these dynamic interactive virtual environments (DIVE). An analysis of each component time was performed, with the purpose of providing a theoretical understanding of the respective design spaces. Initially, we collected the myriad possibilities of each component, e.g., the possible kinds of interactions. We point to examples throughout the field to ground and explain concepts presented. We then categorized of each area into taxonomies. The result of the analyses provides insights into the design space of virtual environments, exposes several avenues of research that are yet underexplored, and provides better understandings of ways in which DIVE creation can be supported.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Statements like “in virtual reality anything is possible” and “the possibilities are only constrained by the imagination of the designer” have been heard for decades. In many senses, these statements are true, as it is all just virtual. However, this promise of everything and anything in virtual reality (VR) has never really come to fruition. The realizable possibilities are much more constrained than the imagination of almost any of us. Part of this is that we do not yet have an understanding of what the virtual environment, the center point of VR, is and can be. Tools have been developed to solve technical problems; yet, rarely, has there been consideration of what is needed to create the virtual environments that fulfill the endless possibilities of VR. The tools for creating “anything is possible” simply do not yet exist. We feel the largest hindrance is currently that we do not have an understanding of what the possibilities are, and, therefore, do not have appropriate system support to enable its creation.</p><p>The work presented here strives to advance our understanding, through an investigation of the design space of the possibilities of virtual environments. We focus in this paper on those virtual environments (VEs) that are <i>engaging</i> and <i>experiential</i>. Naturally, the creativity of the designer is an important factor, and what makes an environment interesting or engaging is difficult to precisely define and somewhat personal. However, as with other media, like film or books, it is possible to identify components that are likely to assist in creating engaging or meaningful experience. In this work, we focus on the aspects that can be supported from a computer science standpoint.</p><p>In this article, we put forth a series of taxonomies designed to make those interesting and engaging components explicitly visible and tangible. These taxonomies were created through a process of collecting potential components and categorization. By identifying the basic components that are able to create such engaging, experiential environments, we can gain valuable insight into what is possible. The taxonomies serve as a reference for getting ideas of what can be done to make environments more interesting. They also outline the design space, providing a new, more formal basis and understanding of what VEs can be. Moreover, this work exposes the time-based nature of many of these different components; based on that knowledge, new approaches to their application and implementation may be fruitful to explore. Components found near each other in the taxonomies are likely to share many design and implementation details. This can assist with finding methods for the development of as well as insight into future design patterns.</p><p>The following section will propose that the two basic components necessary for such environments are <i>dynamic components</i>, changes happening over time, and <i>interaction</i>, in general and with dynamic components. Both of these function to liven the environment and to make it more interesting, particularly over longer periods of time. While individually they are interesting, environments that combine interaction and dynamic components in differing ways are likely to be more interesting. After introducing the style of environment we refer to as <i>dynamic interactive virtual environments</i> (DIVEs), we explore the design spaces of the main identified components individually in Sects. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-013-0232-y#Sec6">3</a> to <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-013-0232-y#Sec10">7</a>. A short discussion of work on DIVEs follows in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-013-0232-y#Sec11">8</a>.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Engaging environments</h2><div class="c-article-section__content" id="Sec2-content"><p>Our goal in this section is to come to a basic understanding of the components that make up environments characterized as follows: engaging, exciting, affective, interesting, and experiential. We take inspiration from an arbitrary selection of a few simple, yet illustrative, examples of well-known environments that achieve such experiences. Considering those examples, we identify and define what we believe are the critical components that require system support to enable designers to create engaging experiences.</p><h3 class="c-article__sub-heading" id="Sec3">Example environments</h3><p>Virtual reality distraction therapies are an example of the class of engaging environments. The goal of these environments is to capture the attention of the user so completely that they are able to remain detached from the physical realities surrounding them and even partially ignore painful procedures. The “Snow World” application is one example of this (Hoffman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Hoffman H, Garcia-Palacios A, Patterson D, Jensen M, Furness T III, Ammons W Jr (2001) The effectiveness of virtual reality for dental pain control: a case study. Cyberpsychol Behav 4(4):527–535" href="/article/10.1007/s10055-013-0232-y#ref-CR32" id="ref-link-section-d69465e370">2001</a>; Sharar et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Sharar S, Miller W, Teeley A, Soltani M, Hoffman H, Jensen M, Patterson D (2008) Applications of virtual reality for pain management in burn-injured patients. Expert Rev Neurother 8(11):1667" href="/article/10.1007/s10055-013-0232-y#ref-CR50" id="ref-link-section-d69465e373">2008</a>). Snow World has been used in various applications, but originally was for burn treatment. The environment is just a simple game, presented immersively, where the user shoots snowballs at snowmen, while moving through a snowy environment. The original version is of quite low fidelity, though newer versions have more up to date graphics. What is interesting in Snow World is that such a simple game, with limited interaction possibilities, can reduce the perception of pain by successfully engaging the user.</p><p>Another highly successful application has been a virtual reality exposure therapy (VRET) design for treatment of post-traumatic stress disorder (PTSD) (Rizzo et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Rizzo A, Rothbaum BO, Graap K (2007) Virtual reality applications for the treatment of combat-related PTSD. In: Figley CR, Nash WP (eds) Combat stress injury: theory, research, and management. Routledge, New York, pp 183–204" href="/article/10.1007/s10055-013-0232-y#ref-CR45" id="ref-link-section-d69465e379">2007</a>). In therapy sessions, the patient is exposed to scenarios from the traumatizing events. Early applications were for therapy of Vietnam veterans (Hodges et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Hodges L, Rothbaum B, Alarcon R, Ready D, Shahar F, Graap K, Pair J, Hebert P, Gotz D, Wills B et al (1999) A virtual environment for the treatment of chronic combat-related post-traumatic stress disorder. Cyberpsychol Behav 2(1):7–14" href="/article/10.1007/s10055-013-0232-y#ref-CR31" id="ref-link-section-d69465e382">1999</a>). For this therapy to work, the patient has to feel that they are in the situation(s) that caused the trauma. In early works, a Vietnam scenario was used. Of particular importance were the actions in the environment, e.g., helicopters. VRETs are now used for war veterans and active duty personnel (McLay et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="McLay RN, Wood DP, Webb-Murphy JA, Spira JL, Wiederhold MD, Pyne JM, Wiederhold BK (2010) A randomized, controlled trial of virtual reality-graded exposure therapy for post-traumatic stress disorder in active duty service members with combat-related post-traumatic stress disorder. Cyberpsychol Behav Soc Netw 13(1):3–11" href="/article/10.1007/s10055-013-0232-y#ref-CR37" id="ref-link-section-d69465e385">2010</a>) as well as being used in setting such as the September 11 attacks (Difede et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Difede J, Cukor J, Jayasinghe N, Patt I, Jedel S, Spielman L, Giosan C, Hoffman H (2007) Virtual reality exposure therapy for the treatment of posttraumatic stress disorder following September 11, 2001. J Clin Psychiatry 68(11):1639–1647" href="/article/10.1007/s10055-013-0232-y#ref-CR19" id="ref-link-section-d69465e388">2007</a>). VRET applications are different than distraction therapy, because at its core it is about transporting the patient to another place and having them experience some particular time and events. It is necessary that the scenario “comes to life.” Although the scenarios are filled with action, interaction is typical minimal. They are also multi-sensory, moving beyond visual and audio to include haptic and olfactory (smell) cues, both as transient and static parts of the environments.</p><p>Finally, one of the classic virtual environments, “Crayoland,” is a worthwhile example (Pape <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Pape D (1998) Crayoland. In: SIGGRAPH ’98: ACM SIGGRAPH 98 electronic art and animation catalog, ACM Press, New York, NY, USA, p 116" href="/article/10.1007/s10055-013-0232-y#ref-CR41" id="ref-link-section-d69465e394">1998</a>). Crayoland is very polygonal, with textures that were made with crayons. The grass plane of the scene is contained by cutout mountains. A small shack with windows and a door is present as well as a tree and a pond. On the tree is a bee hive that, when swatted, releases bees that swarm around the user for a while. In a field of flowers is a butterfly, which patient users can get to land on their virtual hand. When Crayoland becomes reality is while batting of the beehive and the ensuing pursuit of angry bees—are they really angry? In our experience, the visitor to Crayoland tends to say they were angry, anthropomorphizing them similarly to what has been shown to happen with virtual characters (Freeman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Freeman D, Pugh K, Antley A, Slater M, Bebbington P, Gittins M, Dunn G, Kuipers E, Fowler D, Garety P (2008) Virtual reality study of paranoid thinking in the general population. Br J Psychiatry 192(4):258–263. doi:&#xA;                    10.1192/bjp.bp.107.044677&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-013-0232-y#ref-CR22" id="ref-link-section-d69465e397">2008</a>). Another case is getting the butterfly to land on your hand; it actually lands on a virtual hand representation that is in front of the control device, However, people recall the event as if it landed on their hand. Without those parts of the world that are active and reactive to the user, Crayoland would likely be long forgotten. Crayoland only functions because it reacts to the user and is alive itself.</p><h3 class="c-article__sub-heading" id="Sec4">Deriving components</h3><p>The examples above are only singular examples of the many possible environments. However, they demonstrate that environments can produce powerful experiences, even when extremely simple. In the distraction therapy example, a clever context and a simple set of interactions is enough to engage the user to an extent that it can reduce pain perception. The VRET example shows that extensive interaction is not necessary; instead, it creates a meaningful and intense experience through action in the environment. Finally, Crayoland demonstrates the power of the combination of interactions and action and provides important examples of those combinations. Certainly in these examples, content that interests the users and that affects the user’s emotional state is important. Content designers and storytellers can create these human connections, but require a well-defined framework of their design space in which they should work and mechanisms to support content creation within that design space. We believe two critical components that are fruitful to support from the CS perspective are reactivity, i.e., interaction, and activity, i.e., changes over time.</p><p>In the literature, we find support for interaction’s importance. Interaction is usually included as part of the definition of virtual reality and is a definite requirement for games. Central to attempts to understand the experience of immersive virtual environments has been presence (Sanchez-Vives and Slater <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Sanchez-Vives MV, Slater M (2005) From presence to consciousness through virtual reality. Nat Rev Neurosci 6(4):332–339" href="/article/10.1007/s10055-013-0232-y#ref-CR48" id="ref-link-section-d69465e410">2005</a>). In presence research, interaction was consistently seen as a factor (Held and Durlach <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Held RM, Durlach NI (1992) Telepresence. Presence Teleoper Virtual Environ 1:109–112" href="/article/10.1007/s10055-013-0232-y#ref-CR28" id="ref-link-section-d69465e413">1992</a>; Sheridan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Sheridan T (1992) Musings on telepresence and virtual presence. Presence Teleoper Virtual Environ 1(1):120–126" href="/article/10.1007/s10055-013-0232-y#ref-CR51" id="ref-link-section-d69465e416">1992</a>; Steuer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Steuer J (1992) Defining virtual reality: dimensions determining telepresence. J Commun 42(4):73–93" href="/article/10.1007/s10055-013-0232-y#ref-CR56" id="ref-link-section-d69465e419">1992</a>). Other recent work has used interaction as a foundational component of experience (Dede <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Dede C (2009) Immersive interfaces for engagement and learning. Science 323(5910):66–69. doi:&#xA;                    10.1126/science.1167311&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-013-0232-y#ref-CR17" id="ref-link-section-d69465e422">2009</a>; Gorini et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Gorini A, Mosso J, Mosso D, Pineda E, Ruíz N, Ramíez M, Morales J, Riva G (2009) Emotional response to virtual reality exposure across different cultures: the role of the attribution process. CyberPsychol Behav 12(6):699–705" href="/article/10.1007/s10055-013-0232-y#ref-CR23" id="ref-link-section-d69465e426">2009</a>; Takatalo et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Takatalo J, Nyman G, Laaksonen L (2008) Components of human experience in virtual environments. Comput Hum Behav 24(1):1–15" href="/article/10.1007/s10055-013-0232-y#ref-CR57" id="ref-link-section-d69465e429">2008</a>; Wu et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Wu W, Arefin A, Rivas R, Nahrstedt K, Sheppard R, Yang Z (2009) Quality of experience in distributed interactive multimedia environments: toward a theoretical framework. In: Proceedings of the seventeen ACM international conference on multimedia, ACM, pp 481–490" href="/article/10.1007/s10055-013-0232-y#ref-CR61" id="ref-link-section-d69465e432">2009</a>). The distraction therapy example demonstrates this markedly, as the interaction helps place the user in a different environment than the therapy room.</p><p>There is some support in the literature for activity being an important component of experience in VEs. It has even been argued that action is what defines the reality of the environment (Zahorik and Jenison <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Zahorik P, Jenison R (1998) Presence as being-in-the-world. Presence 7(1):78–89" href="/article/10.1007/s10055-013-0232-y#ref-CR65" id="ref-link-section-d69465e438">1998</a>). Recent theories put forth by Slater et al. have held that the plausibility of the actions in an environment (Slater <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Slater M (2009) Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments. Philos Trans R Soc Lond B Biol Sci 364(1535):3549–3557. doi:&#xA;                    10.1098/rstb.2009.0138&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-013-0232-y#ref-CR53" id="ref-link-section-d69465e441">2009</a>) and the “behavior–response” of the environment on user interactions are necessary components of presence (Slater et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Slater M, Lotto B, Arnold MM, Sanchez-Vives MV (2009) How we experience immersive virtual environments: the concept of presence and its measurement. Anu Psicol 40(2):193–210" href="/article/10.1007/s10055-013-0232-y#ref-CR54" id="ref-link-section-d69465e444">2009</a>). Both of these imply further that the environment has to be believable. We contest that part of believability is that the world is not static. Slater’s behavior–response concept requires this, and his examples are based on this. However, Slater’s arguments seem to implicitly assume avatars as the actors and interactors, where we see this more broadly. These non-static environments are instead dynamic, such as the activities in the virtual Vietnam VRET or the bees and butterfly in Crayoland. These dynamic and interactive components often lead to more believable environments.</p><p>Our investigation into the design space followed a multi-step process. The first step was to formally define the components of interest outlined above. The second step was to identify manifestations of each different class of elements. This was done by posing questions like: What interactions can you imagine being possible in a virtual environment? We produced these lists over a number of weeks, holding small workshops with various participants with backgrounds ranging from VR to computer gaming. An immense number of examples were produced. To reduce that data into a manageable quantity, we categorized the data into taxonomies. The leaves of the taxonomies are examples, and the branches capture the common natures of those examples.</p><h3 class="c-article__sub-heading" id="Sec5">Defining the components</h3><p>Two key components of the type of environments we are interested in were identified in the previous discussion. In this section, we formally define the components and further derive three additional components.</p><p>We define interaction as follows:
</p><blockquote class="c-blockquote"><div class="c-blockquote__body">
                    <p>
                      <i>Interaction</i> is the user taking influence on the environment or its controlling structure.</p>
                  </div></blockquote><p>This definition takes a different approach to interaction than has previously used in the VR community. The VR view of interaction has largely identified with Bowman’s interaction taxonomy (Bowman and Hodges <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Bowman DA, Hodges L (1999) Formalizing the design, evaluation, and application of interaction techniques for immersive virtual environments. J Vis Lang Comput 10(1):37–53" href="/article/10.1007/s10055-013-0232-y#ref-CR11" id="ref-link-section-d69465e468">1999</a>) and is still the prevalent view, cf. (Kulik <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Kulik A (2009) Building on realism and magic for designing 3D interaction techniques. IEEE Comput Graph Appl 29(6):22–33. doi:&#xA;                    10.1109/MCG.2009.115&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-013-0232-y#ref-CR35" id="ref-link-section-d69465e471">2009</a>). Bowman did not define interaction, but his focus was clearly on interaction techniques and was closely tied to implementation. This viewpoint holds that four interaction types (tasks) exist: selection, manipulation, navigation, and system. The community has largely focused on these interactions and techniques, devoting limited effort on other possible interactions.</p><p>The second component identified was action. These actions can be better understood as aspects that change over time. We refer to the portions of the VE that change over time as “dynamic components,”
<sup><a href="#Fn1"><span class="u-visually-hidden">Footnote </span>1</a></sup> as they create the opposite of a static environment, and define them as follows:
</p><blockquote class="c-blockquote"><div class="c-blockquote__body">
                    <p>
                      <i>Dynamic component</i> is anything that changes over time that effects perceivable changes to the VE either directly or indirectly.</p>
                  </div></blockquote><p> Our definition is purposefully general, covering an immense spectrum. We feel anything that changes over time potentially makes the environment more lively and interesting. However, we constrain the meaning slightly to anything that has a <i>perceivable</i> effect on the VE. Anything that is never perceived does not really make the environment more interesting. Perception in our understanding includes unconscious perception, allowing ideas like masking, but excluding phenomena like “change blindness.” This perception clause does not, however, imply that an immediate or direct visibility of the changes is required. A <i>dynamic component</i> can also be an indirect and even invisible change to the actual user of the system, for instance a branch in a story due to the user “choosing door number two.” This visibility issue is also a motivation for using the term <i>dynamic component</i>, as it does not imply a visible object change.</p><p>We are interested in VEs that contain both <i>dynamic components</i> and <i>interaction</i>, such as those in the Crayoland example. An important question that needs to be addressed is what happens when components are both interactive and dynamic? We feel this question is crucial to the development of better support of new types of interesting environments. Unfortunately, the areas at the conjunction of dynamic components and interaction are underdeveloped.</p><p>There are two ways in which such actions and reactions can be combined. Examples of these combinations are found in the Crayoland example. The butterfly is a <i>dynamic component</i>, and furthermore one with which the user can interact, when getting it to land on your hand. We refer the resultant combination as an <i>interactive dynamic component</i>. When the butterfly is on the hand, a new dynamic component is introduced through the interaction, i.e., slow movement of the butterfly induced by the user’s hand. These we refer to this as a <i>dynamic interaction</i>.</p><p>We define dynamic interactions as follows:
</p><blockquote class="c-blockquote"><div class="c-blockquote__body">
                    <p>
                      <i>Dynamic interaction</i> is any interaction that either induces a dynamic in the environment or the interaction takes place over a period of time.</p>
                  </div></blockquote><p>
                  <i>Dynamic interactions</i> are quite commonplace in classical VR. Most of Bowman’s manipulation category of interaction techniques falls into this category. Manipulations cause an object to move, rotate, or scale over time. Although one does not often think of those manipulations as causing a dynamic, without seeing the physical manipulation—for instance in a distributed VE without an avatar—the changes would just be a dynamic component. An even more commonplace <i>dynamic interaction</i> is travel. <i>Dynamic interactions</i> exist beyond those that are part of Bowman’s taxonomy and will be discussed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-013-0232-y#Sec8">5</a>.</p><p>The other combination of dynamic components and interaction is a class of interaction involving dynamic components:
</p><blockquote class="c-blockquote"><div class="c-blockquote__body">
                    <p>
                      <i>Interactive dynamic components</i> are any interaction, where the “object” of interaction is a dynamic component.</p>
                  </div></blockquote><p> This subset is those interactions that are with dynamic components that are changing at the moment of interaction. For instance, if we are to strike a virtual football that is traveling toward us, the ball would be an interactive dynamic component. Even the selection of the object would be an <i>interactive dynamic component</i>. In our definition, object is offset in quotes to indicate that the “object” of an interaction may not be a traditional, concrete thing that is “manipulated.” Having a conversation with an embodied agent would be a case of an <i>interactive dynamic component</i>. The “object” might not even be visible; for instance, interactions with the storyline, via the user’s actions, would also be an <i>interactive dynamic component</i>.</p><p>There remains one additional step along this path that we can take. When investigating interactive dynamic components, it becomes apparent that their combination with dynamic interactions is inevitable. These are dynamic interactions, where the target of the interaction is a dynamic component. We refer to these as <i>dynamic interactions with dynamic components</i>.
</p><blockquote class="c-blockquote"><div class="c-blockquote__body">
                    <p>
                      <i>Dynamic interaction with a dynamic component</i> is a special subset of interactive dynamic components that is concerned with cases when the interaction performed is itself occurs over time. Hence, the object of interaction is changing over time as well as the interaction with that object.</p>
                  </div></blockquote>
                <p>Five types of components we believe contribute to creating interesting, engaging types of environments have been identified: <i>dynamic components, interaction, interactive dynamic components, dynamic interactions</i>, and <i>dynamic interactions with dynamic components</i>. In the coming sections, we investigate each of these component types in turn. For each, we develop categorizations. The <i>interaction</i> design space is presented in the next section, followed by the <i>dynamic components</i> design space. Sections <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-013-0232-y#Sec8">5</a> and <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-013-0232-y#Sec9">6</a> explore the design spaces of <i>dynamic interactions</i> and <i>interactive dynamic components</i>, respectively. Finally, the special case of <i>dynamic interaction with dynamic components</i> will be discussed, before moving onto a general discussion in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-013-0232-y#Sec11">8</a>.</p></div></div></section><section aria-labelledby="Sec6"><div class="c-article-section" id="Sec6-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec6">Interaction</h2><div class="c-article-section__content" id="Sec6-content"><p>Interactions are a fairly obvious component for creating environments that can be interesting for longer periods of time. Although there are infinitely many conceivable interactions, they reduce nicely into a relatively small hierarchy of interaction types. The developed taxonomy of interactions can be found in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-013-0232-y#Fig1">1</a>. Prominent among them are the classical VE interactions of object manipulation; however, there are other interactions not often considered in immersive VEs. These actions are somewhat more common in games, though still in limited capacities. Many of these interactions are complex. For instance, conversations with a virtual character are definitely interactions, but are hard to implement unless trivialized. An example is the classic “click on the response” method for avatar interactions seen in many computer games.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-013-0232-y/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-013-0232-y/MediaObjects/10055_2013_232_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-013-0232-y/MediaObjects/10055_2013_232_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Design space of interactions with a VE. <i>Bold font</i> indicates a category or sub-category, and <i>standard font</i> listings are concrete interaction examples</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-013-0232-y/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>Portions of the categorization merit additional explanation. Speech and gesture interactions are not further discussed here, as they are classes of interactions of their own right (Hassanpour et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Hassanpour R, Wong S, Shahbahrami A (2008) Vision based hand gesture recognition for human computer interaction: a review. In: IADIS international conference interfaces and human computer interaction, p 125" href="/article/10.1007/s10055-013-0232-y#ref-CR27" id="ref-link-section-d69465e656">2008</a>; Xian-Yi and Yan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Xian-Yi C, Yan P (2011) Review of modern speech synthesis. In: Hu W (eds) Electronics and signal processing, lecture notes in electrical engineering, vol 97, Springer, Berlin, pp 517–524" href="/article/10.1007/s10055-013-0232-y#ref-CR62" id="ref-link-section-d69465e659">2011</a>). Interactions that occur in real space, though involving the virtual space, form a perceptually different class. For instance, two people pointing to virtual objects and talking about them. Though not purely VR interaction, they are important and have been researched by a number of groups, cf. (Billinghurst and Kato <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Billinghurst M, Kato H (2002) Collaborative augmented reality. Commun ACM 45(7):64–70" href="/article/10.1007/s10055-013-0232-y#ref-CR5" id="ref-link-section-d69465e662">2002</a>; Salzmann et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Salzmann H, Moehring M, Froehlich B (2009) Virtual vs. real-world pointing in two-user scenarios. In: VR ’09: Proceedings of the 2009 IEEE virtual reality conference, IEEE Computer Society, Washington, DC, USA, pp 127–130. doi:&#xA;                    10.1109/VR.2009.4811011&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-013-0232-y#ref-CR47" id="ref-link-section-d69465e665">2009</a>). When considering the possibility of distributed virtual environments, these person-to-person interactions take on a slightly different meaning, but are essentially the same.</p><p>An emerging type of interaction is non-intentionally controlled interactions. Bodily interactions of emerging types, like those using physiological signals, are an example of this type of interaction. For instance, various researchers are working on emotional coupled steering of games and VEs (Blom and Beckhaus <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Blom KJ, Beckhaus S (2005) Emotional storytelling. In: IEEE virtual reality 2005 conference workshop “Virtuality structure”, Bonn, Germany, pp 23–27" href="/article/10.1007/s10055-013-0232-y#ref-CR7" id="ref-link-section-d69465e671">2005</a>; Haringer and Beckhaus <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Haringer M, Beckhaus S (2012) Adaptive generation of emotional impact using enhanced virtual environments. Presence 21(1):96–116" href="/article/10.1007/s10055-013-0232-y#ref-CR26" id="ref-link-section-d69465e674">2012</a>; Yannakakis and Hallam <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Yannakakis GN, Hallam J (2009) Real-time game adaptation for optimizing player satisfaction. IEEE Trans Comput Intell AI Games 1(2):121–133" href="/article/10.1007/s10055-013-0232-y#ref-CR64" id="ref-link-section-d69465e677">2009</a>). It is important to note, that many of the same signals may also be used for intentional steering. For example, the emerging area of passive BCI (Zander and Kothe <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Zander TO, Kothe C (2011) Towards passive brain–computer interfaces: applying brain–computer interface technology to human-machine systems in general. J Neural Eng 8(2):025005" href="/article/10.1007/s10055-013-0232-y#ref-CR66" id="ref-link-section-d69465e680">2011</a>) uses brain activity to determine cognitive or emotional state, and intentional BCI, such as motor imagery (Guger et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Guger C, Groenegress C, Holzner C, Edlinger G, Slater M (2009) Brain–computer interface for virtual reality control. Cyberpsychol Behav 12(1):84" href="/article/10.1007/s10055-013-0232-y#ref-CR24" id="ref-link-section-d69465e683">2009</a>), has been shown capable of controlling a VE.</p><p>The final two interaction categories on the right-hand side have been only narrowly considered to date in the VR community. Meta-level interactions provide deeper meaning to the environment; this is vital for creating experiential environments. Creating such interactions is challenging, from conception to design and implementation.</p><p>The area of object–object interactions has had some attention in VE-related communities, but has been limited in scope. The simplest example is shooting a gun, where the bullet then interacts with objects in the scene. This is common in many games, but also in immersive VR in the military, e.g. (Brooks et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Brooks H, DeKeyser T, Jaskot D, Sibert D, Sledd R, Stilwell W, Scherer W (2004) Using agent-based simulation to reduce collateral damage during military operations. In: Systems and information engineering design symposium, 2004. Proceedings of the 2004 IEEE, IEEE, pp 71–77" href="/article/10.1007/s10055-013-0232-y#ref-CR12" id="ref-link-section-d69465e692">2004</a>; Emond et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Emond B, Fournier H, Lapointe J et al (2010) Applying advanced user models and input technologies to augment military simulation-based training. In: Proceedings of the 2010 spring military modeling and simulation symposium, pp 1–7" href="/article/10.1007/s10055-013-0232-y#ref-CR21" id="ref-link-section-d69465e695">2010</a>). The area of training applications, where interactions are based on some tool, has done some work in this direction. Conceivably any (virtual) tool could act upon another. Examples in VR include surgical simulators (van der Meijden and Schijven <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="van der Meijden O, Schijven M (2009) The value of haptic feedback in conventional and robot-assisted minimal invasive surgery and virtual reality training: a current review. Surg Endosc 23(6):1180–1190" href="/article/10.1007/s10055-013-0232-y#ref-CR38" id="ref-link-section-d69465e698">2009</a>; Reiley et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Reiley C, Lin H, Yuh D, Hager G (2011) Review of methods for objective surgical skill evaluation. Surg Endosc 25(2):356–366" href="/article/10.1007/s10055-013-0232-y#ref-CR43" id="ref-link-section-d69465e701">2011</a>), welding trainers (Yang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Yang U, Lee G, Kim Y, Jo D, Choi J, Kim K (2010) Virtual reality based welding training simulator with 3D multimodal interaction. In: Cyberworlds (CW), 2010 international conference on, IEEE, pp 150–154" href="/article/10.1007/s10055-013-0232-y#ref-CR63" id="ref-link-section-d69465e704">2010</a>), and automotive painting simulators (Konieczny et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Konieczny J, Heckman J, Meyer G, Manyen M, Rabens M, Shimizu C (2008) Automotive spray paint simulation. Lecture Notes in Comput Sci 5358:998–1007" href="/article/10.1007/s10055-013-0232-y#ref-CR34" id="ref-link-section-d69465e708">2008</a>). Extensive research has been done in the computer graphics community on implementing complex object–object interactions, such as collisions (Thomas and Torras <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Thomas F, Torras C (2001) 3D collision detection: a survey. Comput Graph 25:269–285" href="/article/10.1007/s10055-013-0232-y#ref-CR58" id="ref-link-section-d69465e711">2001</a>) and soft body deformations (Misra et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Misra S, Ramesh K, Okamura A (2008) Modeling of tool–tissue interactions for computer-based surgical simulation: a literature review. Presence Teleoper Virtual Environ 17(5):463–491" href="/article/10.1007/s10055-013-0232-y#ref-CR40" id="ref-link-section-d69465e714">2008</a>). Object–object interactions might not even be initiated by user, but interactions between virtual objects independent of the user. For instance, virtual characters may interact with the simulated environment (Kallmann and Thalmann <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Kallmann M, Thalmann D (1999) Direct 3D interaction with smart objects. In: VRST ’99: proceedings of the ACM symposium on virtual reality software and technology, ACM Press, New York, NY, USA, pp 124–130. doi:&#xA;                    10.1145/323663.323683&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-013-0232-y#ref-CR33" id="ref-link-section-d69465e717">1999</a>).</p></div></div></section><section aria-labelledby="Sec7"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7">Dynamic components</h2><div class="c-article-section__content" id="Sec7-content"><p>When considering the possible dynamic components that could be found in a VE, the number is overwhelming. As with interaction, when we collected ideas, we strove to: not constrain ourselves by prior ideas, not get lost in the myriad of endless variations (e.g., by different objects being put together), and not to miss things by generalizing prematurely. The most important criteria we used when generalizing and grouping was that of observer perception. This is in contrast to a typical view of how they are implemented. We felt this was important, as thinking about the implementation at this stage tended to constrain one’s view greatly. After collecting the potential dynamic components, we categorized them according to observer perception. A complete look at all levels of the categorization is not possible in this article. Instead, we present the highest levels and most important discoveries; a more complete view of the whole classification can be found in (Blom <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Blom KJ (2009) Dynamic, interactive virtual environments. Sierke Verlag, Göttingen" href="/article/10.1007/s10055-013-0232-y#ref-CR6" id="ref-link-section-d69465e728">2009</a>).</p><p>The dynamic components design space consists of six top-level categories. Moving from the most overarching to specific, then to the most abstract, the categories are as follows:
</p><ul class="u-list-style-none">
                  <li>
                    <p>
                      <i>Overall Presentation</i> artifacts of the presentation method</p>
                  </li>
                  <li>
                    <p>
                      <i>Scene Attributes</i> artifacts of the scene presented as a whole</p>
                  </li>
                  <li>
                    <p>
                      <i>Singular Objects</i> changes affecting a single item in the scene</p>
                  </li>
                  <li>
                    <p>
                      <i>Propagating Quantities</i> time change effects that are not directly associated with the medium (object) in which they are present</p>
                  </li>
                  <li>
                    <p>
                      <i>System State</i> artifacts of changes in the technology, either hardware or software, that is used in presenting the VE</p>
                  </li>
                  <li>
                    <p>
                      <i>Abstract Components</i> intangible and conceptual changes that can only be indirectly experienced.</p>
                  </li>
                </ul><p>In the following text, each category is presented separately and more clearly delineated. Important sub-categories are mentioned. A mindmap of the highest levels of the taxonomy built on the perception direction is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-013-0232-y#Fig2">2</a>. The full taxonomy in (Blom <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Blom KJ (2009) Dynamic, interactive virtual environments. Sierke Verlag, Göttingen" href="/article/10.1007/s10055-013-0232-y#ref-CR6" id="ref-link-section-d69465e795">2009</a>) develops the areas of <i>Scene Attributes</i> and <i>Singular Objects</i> to deeper levels.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-013-0232-y/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-013-0232-y/MediaObjects/10055_2013_232_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-013-0232-y/MediaObjects/10055_2013_232_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>A mindmap categorization of the highest level of the dynamic components taxonomy is shown. <i>Bold font</i> indicates a category or sub-category, and <i>standard font</i> listings are concrete examples of dynamic components. The <i>Screen Attributes</i> and <i>Singular Object</i> hierarchies contain a lengthy sub-tree broken out in (Blom <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Blom KJ (2009) Dynamic, interactive virtual environments. Sierke Verlag, Göttingen" href="/article/10.1007/s10055-013-0232-y#ref-CR6" id="ref-link-section-d69465e827">2009</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-013-0232-y/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>The <i>Overall Presentation</i> category deals with artifacts that are attributable to the presentation method. These components affect the entire VE, but are differentiated from the Scene Attributes category in that they are not strictly part of the scene. Examples include filters that change how the scene is presented. For instance, visual effects, e.g., cartoon shading, could be added to change the appearance completely (Haringer and Beckhaus <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Haringer M, Beckhaus S (2010) Effect based scene manipulation for multimodal VR systems. In: IEEE VR 2010: proceedings of the IEEE virtual reality conference" href="/article/10.1007/s10055-013-0232-y#ref-CR25" id="ref-link-section-d69465e845">2010</a>). Similarly, something as simple as the audio level fits in this category. A physical example of this is the warming of the projectors over time. This changes the color of the complete system.</p><p>
                <i>Scene Attributes</i> are dynamic components present at the level of the whole world. These dynamic components are part of the scene, but are not just singular objects within the scene. Ambient effects across the different modalities fall into this classification. The addition of ambient sounds, such as a “soundtrack,” to make the VE more interesting is one example. A common dynamic component implemented in VR classes is changes to the number of objects in the environment. This can either be the introduction of new objects or the deletion of objects. We categorize them as scene attributes changes, because it is not a change of the object itself, but rather a change of the scene’s composure. Similarly, the breaking of an object into multiple objects, a conceptually simple, physically based phenomenon fits into this category. The final dynamic component category is changes of the scene in its entirety. This typically reduces to a sub-worlds concept, as it is at some level still the same VE or at least the same program. The most common manifestation of this is the level paradigm common to computer games. Similarly, interactive storytelling environments may have different scenes as the story progresses.</p><p>The largest subset is dynamic <i>Singular Objects</i> and likely the most commonly thought of dynamic component. The two classical dynamic components of virtual worlds are in the sub-categories of <i>Spatial Behavior</i> and <i>Autonomous Entities</i>. The <i>Spatial Behavior</i> of an object is its movement through space. For instance, the classical manipulation of VEs is a spatial behavior (Bowman and Hodges <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Bowman DA, Hodges L (1999) Formalizing the design, evaluation, and application of interaction techniques for immersive virtual environments. J Vis Lang Comput 10(1):37–53" href="/article/10.1007/s10055-013-0232-y#ref-CR11" id="ref-link-section-d69465e870">1999</a>). <i>Autonomous entities</i> include the classical virtual humans, which for many people is the quintessential dynamic component.</p><p>On account of their unique nature, <i>Propagating Quantities</i> are in their own category. These propagating quantities are manifest only through another medium. Examples include waves in an ocean, waves in a pool of water, sound waves, and smells. We chose to categorize these differently, because there is a perceptual difference for the observer. One does not think of the ocean moving, but instead of waves. One does not think of particles moving in the air, but instead of smells moving through the world. Here, the motion has its own importance that is largely independent of the transport medium, making the distinction important.</p><p>A number of potential changes are not so much a part of the VE, but rather of the <i>system state</i>. However, these impact the experience of the environment. Only one of these is a typical dynamic component of existing applications, modal interaction. Interaction with VEs is often performed with only a single device, which is overloaded in functionality. The changing between modes is an important dynamic component of the system. Related to this is the possibility of changing the display configuration or system configuration at run-time (Bierbaum and Cruz-Neira <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Bierbaum A, Cruz-Neira C (2000) Run-time reconfiguration in VR Juggler. In: 4th immersive projection technology workshop" href="/article/10.1007/s10055-013-0232-y#ref-CR4" id="ref-link-section-d69465e889">2000</a>). For instance, in certain Scientific Visualization contexts, this may mean changing the number of processors or even computers involved in the computation (Hernando et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Hernando J, Martinez J, Martin V, López M, Martin-Gago J (2009) Svis: a computational steering visualization environment for surface structure determination. In: Visualisation, 2009. VIZ’09. Second international conference in, IEEE, pp 36–39" href="/article/10.1007/s10055-013-0232-y#ref-CR29" id="ref-link-section-d69465e892">2009</a>; Van Dam et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Van Dam A, Forsberg A, Laidlaw D, LaViola J Jr, Simpson R (2000) Immersive VR for scientific visualization: a progress report. Comput Graph Appl IEEE 20(6):26–52" href="/article/10.1007/s10055-013-0232-y#ref-CR59" id="ref-link-section-d69465e895">2000</a>). Similarly, in distributed applications, this can be changes the connections or changes to the aspects of the VE that are distributed (Singhal and Zyda <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Singhal S, Zyda M (1999) Networked virtual environments. Design and implementation. Addison Wesley, Reading" href="/article/10.1007/s10055-013-0232-y#ref-CR52" id="ref-link-section-d69465e898">1999</a>). However, recall for these to fit our definition of a dynamic component, they have to have perceivable consequences, e.g., the speed of the simulation increases or new virtual characters appear.</p><p>
                <i>Abstract Components</i> of dynamic change are less tangible, but aspects that are implicit and potentially powerful components to making a VE into an experience. Story and game components of VEs are two of the major components at this level. Both of these necessarily unfold over time. In early games, this was created primarily through levels, However, today’s attempts try to handle this solely through a changing environment, without the explicit changes. Interactive storytelling environments are also implicitly dynamic VEs, particularly in that the stories are influenced by the user.</p><p>The final major potential abstract dynamic component of VE is time itself. As dynamic components are defined as being aspects that change over time, this may seem intrinsically wrong. However, in a synthetic world, time is not limited to moving in one direction or at a specific rate. More formally expressed, time does not have to be a homogeneous time arrow. Time in VR is flexible. This is a possibility that is often recognized and is often considered desirable (Bryson <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Bryson S (1997) Time, data-time, and real-time interactive visualization. Comput Phys Commun 11(3):270–274" href="/article/10.1007/s10055-013-0232-y#ref-CR13" id="ref-link-section-d69465e910">1997</a>; Cavazza et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Cavazza M, Hartley S, Lugrin JL, Bras ML (2003) Alternative reality: a new platform for virtual reality art. In: Proceedings of virtual reality software and technology (VRST), ACM Press, pp 100–107. doi:&#xA;                    10.1145/1008653.1008672&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-013-0232-y#ref-CR14" id="ref-link-section-d69465e913">2003</a>; Rehn et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Rehn GD, Lemessi M, Vance JM, Dorozhkin DV (2004) Integrating operations simulation results with an immersive virtual reality environment. In: WSC ’04: Proceedings of the 36th winter simulation conference, pp 1713–1719" href="/article/10.1007/s10055-013-0232-y#ref-CR42" id="ref-link-section-d69465e916">2004</a>; Roussos et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Roussos M, Johnson AE, Leigh J, Vasilakis CA, Barnes CR, Moher TG (1997) NICE: combining constructionism, narrative and collaboration in a virtual learning environment. Comput Graph 31(3):62–63. doi:&#xA;                    10.1145/262171.262264&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-013-0232-y#ref-CR46" id="ref-link-section-d69465e919">1997</a>). An example use of this is for learning environments. In such cases, the learner can experience the proper process at different speeds and review them freely (Bernier et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Bernier E, Chellali R, Mouttapa Thouvenin I, Blom KJ (2012) The ICED plug-in for virtual reality, immersive creation and edition of animation. In: Workshop on software engineering and architectures for real time interactive systems (SEARIS). Costa Mesa, CA, USA,  pp 36–42. doi:&#xA;                    10.1109/SEARIS.2012.6231167&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-013-0232-y#ref-CR3" id="ref-link-section-d69465e922">2011</a>). Conceivable and even often suggested methods include reversing time’s flow, freezing time, changing time’s “speed,” heterogeneous time skewing, and an “undo” for time. However, these possibilities are rarely realized and, even then, usually in very limited ways.</p><p>The discussion of dynamic components up to now has been on classifying the potentials of the design space in terms of perceptual groupings. This is useful when thinking of the possibilities. We believe this will become a useful tool when considering how to make more interesting worlds, by providing a structured way to investigate possible dynamic components to add. It is also useful when evaluating systems for VE creation. Systems can be checked for support of each different class of dynamic component. Implementations within hierarchical categories can be expected to contain similarities or even exact methods. However, for implementing insights, there is another way to classify the collected potentials, based on the decisive factor, time.</p><p>Classifying the dynamic component design space by how time is perceptually understood provides interesting insights into how to create the individual effects and how to support them. We have created a time-based classification of dynamic components. The resulting taxonomy is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-013-0232-y#Fig3">3</a>. It is important to note that three of the four categories involve continuous or piecewise continuous time changes. This insight will be taken back up in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-013-0232-y#Sec12">8.1</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-013-0232-y/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-013-0232-y/MediaObjects/10055_2013_232_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-013-0232-y/MediaObjects/10055_2013_232_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>A categorization of dynamic components based on a time representation criteria is shown. The boundedness of the representation is given below the descriptor. <i>Bold font</i> indicates a category or sub-category, and <i>standard font</i> listings are concrete examples</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-013-0232-y/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              </div></div></section><section aria-labelledby="Sec8"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Dynamic interactions</h2><div class="c-article-section__content" id="Sec8-content"><p>Having looked at the design spaces of dynamic components and interactions, we can now move to the areas that combine them. The first we investigate is <i>dynamic interactions</i>. Recall that they are dynamic components induced through interactions. The design space of dynamic interactions provides interesting insight not only into what is possible, but uncovers a large research field that is largely unexplored and provides new insight into the necessary support mechanisms for such interactions.</p><p>The design space of <i>dynamic interaction</i> consists of various standard interactions and less conventional interactions. We present the design space in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-013-0232-y#Fig4">4</a> only in the form of a time-based categorization, as the equivalent categorization based on perception contributes little additional information.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-013-0232-y/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-013-0232-y/MediaObjects/10055_2013_232_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-013-0232-y/MediaObjects/10055_2013_232_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>The design space of dynamic interactions is shown in taxonomy form. <i>Bold font</i> indicates a category or sub-category, and <i>standard font</i> listings are concrete examples</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-013-0232-y/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>Considering first the different possibilities themselves, we see that a good number of the possible dynamic components are induced by interactions. This is interesting, as it supports the prevalent thought that interaction is of importance for making things interesting, as they also produce actions. We will introduce the different dynamic interactions in three groups: classical VR interactions, meta-level interactions, and those from “advanced” or “immersive” interfaces.</p><p>When we consider the interaction techniques that are typically used in VR environments, it turns out that most of them fall into the category of dynamic interactions. The ubiquitous interactions of object manipulation are a prime example as well as most of the travel methods that are crucial to VR. These classic VR interaction types are rarely considered with regard to their dynamic nature, exceptions include (Herrlich et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Herrlich M, Walther-Franks B, Schröder-Kroll R, Holthusen J, Malaka R (2011) Proxy-based selection for occluded and dynamic objects. In: Smart graphics, Springer, pp 142–145" href="/article/10.1007/s10055-013-0232-y#ref-CR30" id="ref-link-section-d69465e1012">2011</a>; Schröder-Kroll et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Schröder-Kroll R, Blom KJ, Beckhaus S (2008) Interaction techniques for dynamic virtual environments. In: Proceedings of “Virtuelle und Erweiterte Realität” workshop of the Gesellschaft für Informatik e.V. (GI), Shaker Verlag, pp 57–68" href="/article/10.1007/s10055-013-0232-y#ref-CR49" id="ref-link-section-d69465e1015">2008</a>; Steed <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Steed A. (2006) Towards a general model for selection in virtual environments. In: Proceedings of the IEEE symposium on 3D user interfaces (3DUI), IEEE, pp 103–110" href="/article/10.1007/s10055-013-0232-y#ref-CR55" id="ref-link-section-d69465e1018">2006</a>).</p><p>Meta-level interactions include a number of things like games and storytelling. However, other potential dynamic interactions can be included here. Conversations, gestures, and speech all can be include. Each is dependent on something occurring over time, which is part of what makes them challenging.</p><p>Finally, certain devices enforce a dynamic interaction. Basically, these are “continuous” sensors. Standard spatial tracking devices are this way, if values are continuously used. Haptics devices are also continuous in nature, because of the fidelity required. However, newer devices like brain computer interfaces (BCI), eye tracking, and physiological sensors are potentially dynamic interactions, even if they are rarely used as such.</p><p>When categorizing based on time representation, the dynamic interaction design space is divided into four categories. Two categories are continuous in nature, differing only by their boundedness in time, <i>continuous infinite</i> and <i>continuous over an interval</i>. The second set of interactions involves ordered sets of interactions that occur over time. We further differentiate between ordered sets that are composed of either continuous over intervals segments or discrete events.</p><p>The boundedness difference for the continuous time categories may seem trivial and irrelevant. However, this may prove to have an impact on the implementation, making it more than a conceptual difference. In the continuous infinite case, we expect the interaction to be active over the entire course of the application’s life. A classic example of this is head tracking. Another example is the ChairIO travel interface (Beckhaus et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Beckhaus S, Blom KJ, Haringer M (2007) ChairIO—the chair-based interface. In: Magerkurth C, Röcker C (eds) Concepts and technologies for pervasive games: a reader for pervasive gaming research, vol 1. Shaker Verlag, Aachen, pp 231–264" href="/article/10.1007/s10055-013-0232-y#ref-CR2" id="ref-link-section-d69465e1038">2007</a>), which is continuous for the length of program. On the other hand, tracking of an input device used for travel or manipulation typically is handled as a continuous interval, as they are almost exclusively performed as modal interactions.</p><p>The second set of categories is based on the premise that the interaction is composed of an ordered set of interactions that are distributed in time. The individual interactions take meaning through their association together. In this sense, these are interactions that occur over time. For example, a conversation is a collection of speech components that occur in a specific order. Games and stories can be found as both sets of intervals and of discrete events. Although this deals primarily with implementation details, there is a conceptual impact on how the interaction is viewed. Classically, implementations view the interactions as a collection of discrete occurrences. This is partially because interactions in storytelling and games have been implemented as discrete interactions, but mostly because implementations are typically based on state machines. While the story of the experience is retold in this discrete way, the experiences are almost always continuous over some period of time, i.e., a continuous time interval.</p></div></div></section><section aria-labelledby="Sec9"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">Interactive dynamic components</h2><div class="c-article-section__content" id="Sec9-content"><p>The alternative combination of interaction and a dynamic component is an <i>interactive dynamic component</i>. They are simply interactions that occur with a dynamic component. Conceptually, this is quite straightforward; however, they are not as well understood and explored as prior ideas. Known examples of interactive dynamic components are yet limited in scope; however, we feel the larger area of interactive dynamic components will become important in the near future.</p><p>The design space of interactive dynamic components can be seen in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-013-0232-y#Fig5">5</a>. The design space is seemingly small in size, though many of the categories encapsulate countless potentials. This small number may be more a result of the little exploration that has been performed in this direction than truly an indication of a small design space.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-013-0232-y/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-013-0232-y/MediaObjects/10055_2013_232_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-013-0232-y/MediaObjects/10055_2013_232_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>The taxonomy of the interactive dynamic components’ design space categorization. <i>Bold font</i> indicates a category or sub-category, and <i>standard font</i> listings are concrete examples</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-013-0232-y/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>Examples of interactive dynamic components can be found in real life. Interactions with dynamic objects are performed in real life, though few cases are frequent for the average person. Many sports involve such interactions at their core, for instance kicking a moving ball. This often forms much of the challenge of the sport, particularly for youth and amateurs. While not everyone actively plays sports, another category is very commonplace. The “simple” act of having a conversation is built upon interactions that fall into this category.</p><p>One class of interactive dynamic components is simply taking dynamic components and interacting with them. While it is easy to say, we will interact with a dynamic component, actually doing it or even considering and planning to do it more difficult. Computer games do this often as a way to increase the challenge. Because of implementation challenges, interaction with dynamic objects is typically instantaneous. However, as we saw in dynamic interactions, there are a whole class of interactions that are continuous and, potentially, more interesting than just “instantaneous” shooting and stomping interactions that are classic in computer games. These overlapping areas are what we have termed <i>dynamic interactions with dynamic components</i> and will be introduced in the next section.</p><p>A few of the categories shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-013-0232-y#Fig5">5</a> merit explanation. Parameter steering is a category, where the interactions are not directly with the dynamic component in question, but rather manipulation of some controlling mechanism in the simulation. Direct value changes are similar to what Bowman called “system” interactions. An example of this would be controlling the passage of time, e.g., stop, play, slow play, fast forward, and reverse buttons. Another could be controlling gravity’s defined value. Indirect parameter steering is likely to be found in interactive storytelling. Here, the user’s actions cause parameters in the story manager to be modified, e.g., the user ignores a character in the interactive drama Façade (Mateas and Stern <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Mateas M, Stern A (2003) Facade: an experiment in building a fully-realized interactive drama. In: Proceedings of the game developer’s conference: Game Design Track" href="/article/10.1007/s10055-013-0232-y#ref-CR36" id="ref-link-section-d69465e1101">2003</a>). This in turn modifies the next act or task that the story manager picks out, which in turn modifies the behavior of the actors, e.g., the ignored character accosts the user. Such effects could be more subtle and long term, as seen in various current role playing games.</p><p>Most other interactions highlighted happen more at a meta-level. The object of interaction is not so concrete here. For instance, most meaningful interactions with an “entity” (avatar, person, animal/thing) involve some abstraction. A conversation implies that there is a change happening in the internal state of the conversant. Similarly, interactions in an interactive storytelling application imply that the interactions of the user influence in some way the flow of the story. Although this may not actually be the case in the programming, perceptually successful applications provide the illusion of such deeper interactions.</p></div></div></section><section aria-labelledby="Sec10"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Dynamic interactions with dynamic components</h2><div class="c-article-section__content" id="Sec10-content"><p>
                <i>Dynamic interactions with dynamic components</i> are a challenging area first formalized here. They are interesting both for the application user and as a research area. It turns out that a large portion of the identified interactive dynamic components in the previous section fit into this category. For the user of an application, the meta-level dynamic interactions with dynamic components (e.g., conversation, interactive storytelling, entity relations) provide depth to a world and make them seem more realistic. Haptics have been extensively explored; however, the area, as a whole, is largely underexplored. We believe a large portion of this is simply that they are very challenging.</p><p>What exactly does a <i>dynamic interaction with a dynamic component</i> (DID) entail? The examples given in the prior section focused on interactions well known from our everyday life. Conversations involve “give and take” methods, such that one actor talks and the other(s) listen, in “turn taking.” Here, rules have emerged in culture to make the DID possible. However, body language may play a role in conversations even between those discrete intervals of speech. Similarly, haptics research largely implements well-know sets of rules based on physical properties, i.e., we push on something and the force (an abstraction over time) is feed into the system.</p><p>
                <i>Dynamic interactions with dynamic components</i> that are not based on existing physical and/or cultural rules are not as clear. An abstract example that functions well is Beckhaus’ Guided Exploration system (Beckhaus <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Beckhaus S (2003) Dynamic potential fields for guided exploration in virtual environments. 6. Fraunhofer Series in Information and Communication Technology, vol 6. Shaker Verlag, Aachen" href="/article/10.1007/s10055-013-0232-y#ref-CR1" id="ref-link-section-d69465e1129">2003</a>). Her system created a hybrid interactive and guided system for exploration of a virtual environment. A passive user would be guided through an environment, from one point of interest to the next. However, the user had the possibility of interrupting the guidance system to navigate on their own. When returning to a passive mode, the guidance system reengaged. The system was designed to be emergent, such that it “created” a different tour through the environment after the interaction intervention. The user’s new position started the system anew, and it took into account the points of interests visited by the user while they were in control.</p><p>The guided exploration example presents one possible method of DIDs: an informed takeover of control. Conversation involves exclusion in the verbal modality in the turn taking convention. However, when trying to extrapolate from those examples to come to an “essence” of DIDs, one quickly runs into difficulties.</p><p>To illustrate this, an example will be made of classical direct manipulation in VR. This interaction is a good example, because it is both easy to visualize and also commonly thought of when first approaching this kind of interaction (though according to the authors’ experience, always quickly disregarded when attempting to implement it). Assuming the manipulation being performed is translation, looking at the possible ways in which the dynamic component and the manipulation dynamic component can be combined is informative. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-013-0232-y#Fig6">6</a> visualizes the possibilities listed here:
</p><ul class="u-list-style-bullet">
                  <li>
                    <p>add the manipulation to the continuing object movement—changing the position directly</p>
                  </li>
                  <li>
                    <p>add the manipulation to the continuing object movement—changing the dynamic at a higher-order level (e.g., velocity)</p>
                  </li>
                  <li>
                    <p>add the manipulation to the continuing object movement—snap back to dynamics afterward</p>
                  </li>
                  <li>
                    <p>stop the movement and manipulate—continue as before (i.e., the manipulation has no effect after manipulation ends)</p>
                  </li>
                  <li>
                    <p>stop the movement and manipulate—continue dynamics from the manipulated position</p>
                  </li>
                </ul><p> Implementations of each are possible; the larger question is, what manipulations make sense? We feel that the answer to that lies in the application for which it is needed, making it a difficult to answer question.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-013-0232-y/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-013-0232-y/MediaObjects/10055_2013_232_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-013-0232-y/MediaObjects/10055_2013_232_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>This diagram shows the identified methods in which direct manipulation and existing dynamic component can be combined. For simplicity, the interaction is reduced to a 2D space. The timings of the interaction and the dynamic component are seen on the <i>left-hand side</i>
                      </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-013-0232-y/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              </div></div></section><section aria-labelledby="Sec11"><div class="c-article-section" id="Sec11-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec11">Discussion</h2><div class="c-article-section__content" id="Sec11-content"><p>As we performed this research, we were often reminded of the immense possibilities for what could be and, yet, so rarely is. This was true even for the areas of interaction and dynamic components. In this section, we discuss briefly some of the insights won during the process of this research. We also discuss briefly two topics of importance related to this work. The first is supporting the creation of DIVEs, a central motivation of this research. The second is some of the ongoing research into the newly identified research areas, in particular <i>interactive dynamic components</i> and <i>dynamic interactions</i>.</p><p>Interaction is the one area that has been extensively researched in the VR community, and yet this is the first work we know of that has asked what is possible. Here, we have shown that many potential avenues of interaction have not yet been deeply explored. Many of these interactions are related to dynamic components, another area that has had limited attention. The Web3D community has been the primary area of research on dynamic components in the recent years (Boussinot et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Boussinot F, Susini JF, Tran FD, Hazard L (2001) A reactive behavior framework for dynamic virtual worlds. In: Web3D ’01: proceedings of the sixth international conference on 3D Web technology, ACM Press, New York, NY, USA, pp 69–75" href="/article/10.1007/s10055-013-0232-y#ref-CR10" id="ref-link-section-d69465e1208">2001</a>; Dachselt and Rukzio <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Dachselt R, Rukzio E (2003) Behavior3D: an XML-based framework for 3D graphics behavior. In: Proceedings of the ACM Web3D 2003 conference, ACM Press, pp 101–112" href="/article/10.1007/s10055-013-0232-y#ref-CR16" id="ref-link-section-d69465e1211">2003</a>; Mesing and Hellmich <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Mesing B, Hellmich C (2006) Using aspect oriented methods to add behaviour to X3D documents. In: Proceedings of the ACM Web3D 2006 conference, ACM" href="/article/10.1007/s10055-013-0232-y#ref-CR39" id="ref-link-section-d69465e1214">2006</a>).</p><p>We believe, however, that the most interesting part of this work is the revelation of the very underexplored areas at the intersection of dynamic components and interaction; we have termed the different ways in which they can combine as <i>dynamic interaction</i>, <i>interactive dynamic components</i>, and <i>dynamic interaction with dynamic components</i>. These different combinations of interaction and action are likely to be compelling and interesting components of VEs. From a research viewpoint, each combination is interesting. A primary reason is the challenge. The combination of components that change over time and interaction with that same object is difficult. It is often difficult to conceive interactions that are functional and user friendly. In turn, these kinds of interactions are usually difficult to implement.</p><p>Given the challenges and the huge potential of these areas, it is surprising how little research exists on these topics. Most of the relevant prior research has been mentioned in sections introducing each concept. In the following subsection, we briefly present the system we have developed specifically to support the creation of <i>Dynamic interactive VEs</i>. After that, we introduce some of the research we have been performing on such combinations of dynamic components and interaction.</p><h3 class="c-article__sub-heading" id="Sec12">Supporting DIVE creation</h3><p>The number of existing and previous VE systems is expansive, so it is surprising that only a single system has been designed with DIVE creation in mind. Reviews of the various systems can be found in (Blom <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Blom KJ (2009) Dynamic, interactive virtual environments. Sierke Verlag, Göttingen" href="/article/10.1007/s10055-013-0232-y#ref-CR6" id="ref-link-section-d69465e1243">2009</a>; Blom and Beckhaus <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Blom KJ, Beckhaus S (2007b) Supporting the creation of dynamic, interactive virtual environments. In: VRST ’07: proceedings of the 2007 ACM symposium on virtual reality software and technology, ACM Press, pp 51–54. doi:&#xA;                    10.1145/1315184.1315191&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-013-0232-y#ref-CR9" id="ref-link-section-d69465e1246">2007</a>). We briefly introduce the issues surrounding supporting DIVE creation and introduce our system that was designed to fully support DIVE creation.</p><p>Systems that support interaction can be readily found, including various systems specifically for interactions. However, support for creating dynamic components is generally lacking in most systems. Most systems that support time-based changes do so by providing the programming language itself and a “timer.” In all but a few exceptions, the support systems consider time to be instantaneous and occurring only at the frame update. If “continuous” dynamic components are supported, they are typically enabled only through pre-planned—typically keyframe—animations. Unfortunately, pre-planned animations exclude most interactions. <i>Interactive dynamic components</i> and <i>dynamic interactions</i> are rarely, if ever, supported in current systems at any level.</p><p>Based on the research presented here, we developed a system specifically to support the creation of DIVEs, called functional reactive virtual reality (FRVR) (Blom <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Blom KJ (2009) Dynamic, interactive virtual environments. Sierke Verlag, Göttingen" href="/article/10.1007/s10055-013-0232-y#ref-CR6" id="ref-link-section-d69465e1261">2009</a>; Blom and Beckhaus <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007a" title="Blom KJ, Beckhaus S (2007a) Functional reactive virtual reality. In: IPT/EGVE ’07: short paper proceedings of the IPT/EuroGraphics workshop on virtual environments, EuroGraphics Association, pp 295–302" href="/article/10.1007/s10055-013-0232-y#ref-CR8" id="ref-link-section-d69465e1264">2007a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Blom KJ, Beckhaus S (2007b) Supporting the creation of dynamic, interactive virtual environments. In: VRST ’07: proceedings of the 2007 ACM symposium on virtual reality software and technology, ACM Press, pp 51–54. doi:&#xA;                    10.1145/1315184.1315191&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-013-0232-y#ref-CR9" id="ref-link-section-d69465e1267">b</a>). It directly and natively supports time-based creation of dynamics of every class identified in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-013-0232-y#Sec7">4</a>. It also provides provisions for reactive interaction with those dynamics, thereby supporting every category of DIVE described previously.</p><p>FRVR is built upon the functional reactive programming (FRP) paradigm. In FRP, time is a first class part of the system and is considered continuous (Elliott and Hudak <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Elliott C, Hudak P (1997) Functional reactive animation. In: International conference on functional programming, pp 196–203" href="/article/10.1007/s10055-013-0232-y#ref-CR20" id="ref-link-section-d69465e1276">1997</a>; Wan and Hudak <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Wan Z, Hudak P (2000) Functional reactive programming from first principles. In: Conference on programming language design and implementation (PLDI’00), ACM SIGPLAN, ACM Press, pp 242–252" href="/article/10.1007/s10055-013-0232-y#ref-CR60" id="ref-link-section-d69465e1279">2000</a>). What differentiates FRVR from other systems that can handle continuous time is that it: still handles instantaneous time changes well, supports interaction, and is VR system independent. This support of interaction can be for all classes of interaction: instantaneous, interactive dynamic components, dynamic interactions, and even dynamic interactions with dynamic components.</p><p>The FRP paradigm focuses on two things, expressing (time-based) behaviors as mathematical functions and being reactive to input. Although FRP is not exclusively for time-based usages, its strength lies therein. Time is explicit to the system, but hidden from the developer. Instead, typical dynamic components are programmed using integrals. FRVR uses the Yampa FRP implementation, which is written in Haskell using Arrows (Courtney et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Courtney A, Nilsson H, Peterson J (2003) The Yampa Arcade. In: ACM SIGPLAN Haskell workshop, ACM SIGPLAN, pp 7–18" href="/article/10.1007/s10055-013-0232-y#ref-CR15" id="ref-link-section-d69465e1286">2003</a>).</p><p>FRVR expands on the original FRP paradigm for the needs of virtual reality. FRVR adds diverse abilities for traditional usages, like keyframed animation. FRP’s reactive system enables switching between “behaviors,” and also for emergent and nonlinear behavior of the system. FRVR adds support for exploration of the dynamic interaction through various functionalities. Even time is flexible in the FRVR system, manipulatable for all behaviors, independently per behavior, or as groups of behaviors. Time can even be frozen, while still allowing interactions. An undo functionality that is unique to FRVR can even step back through time. As with many of these abilities, undo requires only the addition of a single function.</p><p>FRFR is open source and freely available
<sup><a href="#Fn2"><span class="u-visually-hidden">Footnote </span>2</a></sup>. It is cross-platform and can be integrated into any VR system, using any graphics libraries. Currently, implementations of FRVR exist for two VR systems and have been demonstrated with five different graphics engines. FRVR is additionally designed to be multiply connected to various input and output generation systems, e.g., sound, that are running at different update rates. To achieve this, FRVR has only a loose coupling to each system, including the VR system, via a blackboard implementation. Additionally, FRVR has a variable simulation rate that can be determined as required by the application.</p><h3 class="c-article__sub-heading" id="Sec13">Active DIVE research</h3><p>A limited amount of research into the newer areas of the DIVE spectrum has been undertaken. We have started research into interactive dynamic components at various levels and introduce those directions here.</p><p>As this area is yet underdeveloped, we have started with the simplest of interactions, selection. In our initial work, we tested various methods of selection of dynamic objects (Schröder-Kroll et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Schröder-Kroll R, Blom KJ, Beckhaus S (2008) Interaction techniques for dynamic virtual environments. In: Proceedings of “Virtuelle und Erweiterte Realität” workshop of the Gesellschaft für Informatik e.V. (GI), Shaker Verlag, pp 57–68" href="/article/10.1007/s10055-013-0232-y#ref-CR49" id="ref-link-section-d69465e1317">2008</a>). We attempted various methods of selection based on expectations gleaned from the developed taxonomies. We performed user tests with four different methods: standard ray picking, the snapping pointer, the time cone, and the trajectory-based selections. The last three methods use a cone selection with specialized functions for determining the selected object, based loosely on the research of de Haan et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="de Haan G, Koutek M, Post FH (2005) IntenSelect: using dynamic object rating for assisting 3D object selection. In: Proceedings of the 9th IPT and 11th Eurographics VE workshop (EGVE), pp 201–209" href="/article/10.1007/s10055-013-0232-y#ref-CR18" id="ref-link-section-d69465e1320">2005</a>). In a small study, we found that the snapping pointer—closest object in cone—and time cone methods—selection based on length of time the object is present in the cone—worked best for single object selection and selection in a occluding group. This work on selection of dynamic objects has continued outside our group in (Herrlich et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Herrlich M, Walther-Franks B, Schröder-Kroll R, Holthusen J, Malaka R (2011) Proxy-based selection for occluded and dynamic objects. In: Smart graphics, Springer, pp 142–145" href="/article/10.1007/s10055-013-0232-y#ref-CR30" id="ref-link-section-d69465e1323">2011</a>) and by others (Richard et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Richard P, Naud M, Inglese FX, Richard E (2012) Modeling dynamic interaction in virtual environments and the evaluation of dynamic virtual fixtures. Presence Teleoper Virtual Environ 21(3):321–337" href="/article/10.1007/s10055-013-0232-y#ref-CR44" id="ref-link-section-d69465e1326">2012</a>).</p><p>We have also performed research exploring <i>dynamic interactions with dynamic components</i>. Our initial work was with defining and refining of paths through an environment. Here, we have been dealing with the classic issue of defining a “fly through” of an environment. The path is recorded in FRVR and then can be played back. The simplest interaction that can be implemented with FRVR is allowing dynamic changing of the flow of time for the playback (requiring the addition of only a single function). Developing interactions beyond the time manipulation requires some thought.</p><p>In order to edit the spatial changes, we experimented with the replacement of sections of the path (Bernier et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Bernier E, Chellali R, Mouttapa Thouvenin I, Blom KJ (2012) The ICED plug-in for virtual reality, immersive creation and edition of animation. In: Workshop on software engineering and architectures for real time interactive systems (SEARIS). Costa Mesa, CA, USA,  pp 36–42. doi:&#xA;                    10.1109/SEARIS.2012.6231167&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-013-0232-y#ref-CR3" id="ref-link-section-d69465e1338">2011</a>). This is probably the easiest DID method, at least with the FRVR implementation. We just select a starting time and ending time, replacing it with a newly recorded segment that roughly “matches up.” Currently one watches/experiences the path and triggers the start and end times during the playback (time manipulation can occur during this to increase accuracy if desired). Then, the start position and end position are visualized. The user starts from the start position, recording a new path, ending at the end position. Classically such a method would cause discontinuities that are not acceptable, particularly for viewpoint paths. However, using FRVR’s different transitions functions, we can smooth the transitions from one to the other, without having to intervene. Usage of transition functionalities requires only the replacement of the switching functionality with a special function that implements the desired transition method.</p></div></div></section><section aria-labelledby="Sec14"><div class="c-article-section" id="Sec14-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec14">Conclusion</h2><div class="c-article-section__content" id="Sec14-content"><p>We have introduced and investigated the area of dynamic interactive virtual environments (DIVEs). These are a class of engaging VEs based on the idea that what makes them interesting are their dynamic and interactive components. This paper defines and explores the design space of this class of environments, providing insights into what is possible, identifying new areas for research, and providing insights into how to support their creation.</p><p>We identify five types of components to the environment that have to be regarded: <i>interaction, dynamic components, dynamic interactions, interactive dynamic components</i>, and <i>dynamic interactions with dynamic components</i>. For each area, we have explored and categorized the design spaces of what is possible. This has made explicit the design space of possibilities for each and shed light onto a myriad of exciting areas of research. We have additionally provided an analysis of the dynamic component design space based on how the passage of the time based is perceived, providing insight into implementation of requirements for these components. Among the more interesting areas for research formalized through this work are <i>dynamic interactions</i> and <i>interactive dynamic components</i>, two areas that have large potentials and are widely open for future research.</p></div></div></section>
                        
                    

                    <section aria-labelledby="notes"><div class="c-article-section" id="notes-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="notes">Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1"><span class="c-article-footnote--listed__index">1.</span><div class="c-article-footnote--listed__content"><p>In prior publications, we had referred to these as “dynamics.” A discussion of the choice of nomenclature can be found in Online Resource 1.</p></div></li><li class="c-article-footnote--listed__item" id="Fn2"><span class="c-article-footnote--listed__index">2.</span><div class="c-article-footnote--listed__content"><p>
                      <a href="http://imve.informatik.uni-hamburg.de/projects/FRVR.">http://imve.informatik.uni-hamburg.de/projects/FRVR.</a>
                    </p></div></li></ol></div></div></section><section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Beckhaus S (2003) Dynamic potential fields for guided exploration in virtual environments. 6. Fraunhofer Serie" /><p class="c-article-references__text" id="ref-CR1">Beckhaus S (2003) Dynamic potential fields for guided exploration in virtual environments. 6. Fraunhofer Series in Information and Communication Technology, vol 6. Shaker Verlag, Aachen</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Beckhaus S, Blom KJ, Haringer M (2007) ChairIO—the chair-based interface. In: Magerkurth C, Röcker C (eds) Con" /><p class="c-article-references__text" id="ref-CR2">Beckhaus S, Blom KJ, Haringer M (2007) ChairIO—the chair-based interface. In: Magerkurth C, Röcker C (eds) Concepts and technologies for pervasive games: a reader for pervasive gaming research, vol 1. Shaker Verlag, Aachen, pp 231–264</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bernier E, Chellali R, Mouttapa Thouvenin I, Blom KJ (2012) The ICED plug-in for virtual reality, immersive cr" /><p class="c-article-references__text" id="ref-CR3">Bernier E, Chellali R, Mouttapa Thouvenin I, Blom KJ (2012) The ICED plug-in for virtual reality, immersive creation and edition of animation. In: Workshop on software engineering and architectures for real time interactive systems (SEARIS). Costa Mesa, CA, USA,  pp 36–42. doi:<a href="https://doi.org/10.1109/SEARIS.2012.6231167">10.1109/SEARIS.2012.6231167</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bierbaum A, Cruz-Neira C (2000) Run-time reconfiguration in VR Juggler. In: 4th immersive projection technolog" /><p class="c-article-references__text" id="ref-CR4">Bierbaum A, Cruz-Neira C (2000) Run-time reconfiguration in VR Juggler. In: 4th immersive projection technology workshop</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Billinghurst, H. Kato, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Billinghurst M, Kato H (2002) Collaborative augmented reality. Commun ACM 45(7):64–70" /><p class="c-article-references__text" id="ref-CR5">Billinghurst M, Kato H (2002) Collaborative augmented reality. Commun ACM 45(7):64–70</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F514236.514265" aria-label="View reference 5">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Collaborative%20augmented%20reality&amp;journal=Commun%20ACM&amp;volume=45&amp;issue=7&amp;pages=64-70&amp;publication_year=2002&amp;author=Billinghurst%2CM&amp;author=Kato%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Blom KJ (2009) Dynamic, interactive virtual environments. Sierke Verlag, Göttingen" /><p class="c-article-references__text" id="ref-CR6">Blom KJ (2009) Dynamic, interactive virtual environments. Sierke Verlag, Göttingen</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Blom KJ, Beckhaus S (2005) Emotional storytelling. In: IEEE virtual reality 2005 conference workshop “Virtuali" /><p class="c-article-references__text" id="ref-CR7">Blom KJ, Beckhaus S (2005) Emotional storytelling. In: IEEE virtual reality 2005 conference workshop “Virtuality structure”, Bonn, Germany, pp 23–27</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Blom KJ, Beckhaus S (2007a) Functional reactive virtual reality. In: IPT/EGVE ’07: short paper proceedings of " /><p class="c-article-references__text" id="ref-CR8">Blom KJ, Beckhaus S (2007a) Functional reactive virtual reality. In: IPT/EGVE ’07: short paper proceedings of the IPT/EuroGraphics workshop on virtual environments, EuroGraphics Association, pp 295–302</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Blom KJ, Beckhaus S (2007b) Supporting the creation of dynamic, interactive virtual environments. In: VRST ’07" /><p class="c-article-references__text" id="ref-CR9">Blom KJ, Beckhaus S (2007b) Supporting the creation of dynamic, interactive virtual environments. In: VRST ’07: proceedings of the 2007 ACM symposium on virtual reality software and technology, ACM Press, pp 51–54. doi:<a href="https://doi.org/10.1145/1315184.1315191">10.1145/1315184.1315191</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Boussinot F, Susini JF, Tran FD, Hazard L (2001) A reactive behavior framework for dynamic virtual worlds. In:" /><p class="c-article-references__text" id="ref-CR10">Boussinot F, Susini JF, Tran FD, Hazard L (2001) A reactive behavior framework for dynamic virtual worlds. In: Web3D ’01: proceedings of the sixth international conference on 3D Web technology, ACM Press, New York, NY, USA, pp 69–75</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DA. Bowman, L. Hodges, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Bowman DA, Hodges L (1999) Formalizing the design, evaluation, and application of interaction techniques for i" /><p class="c-article-references__text" id="ref-CR11">Bowman DA, Hodges L (1999) Formalizing the design, evaluation, and application of interaction techniques for immersive virtual environments. J Vis Lang Comput 10(1):37–53</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Formalizing%20the%20design%2C%20evaluation%2C%20and%20application%20of%20interaction%20techniques%20for%20immersive%20virtual%20environments&amp;journal=J%20Vis%20Lang%20Comput&amp;volume=10&amp;issue=1&amp;pages=37-53&amp;publication_year=1999&amp;author=Bowman%2CDA&amp;author=Hodges%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Brooks H, DeKeyser T, Jaskot D, Sibert D, Sledd R, Stilwell W, Scherer W (2004) Using agent-based simulation t" /><p class="c-article-references__text" id="ref-CR12">Brooks H, DeKeyser T, Jaskot D, Sibert D, Sledd R, Stilwell W, Scherer W (2004) Using agent-based simulation to reduce collateral damage during military operations. In: Systems and information engineering design symposium, 2004. Proceedings of the 2004 IEEE, IEEE, pp 71–77</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Bryson, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Bryson S (1997) Time, data-time, and real-time interactive visualization. Comput Phys Commun 11(3):270–274" /><p class="c-article-references__text" id="ref-CR13">Bryson S (1997) Time, data-time, and real-time interactive visualization. Comput Phys Commun 11(3):270–274</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1063%2F1.4822556" aria-label="View reference 13">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Time%2C%20data-time%2C%20and%20real-time%20interactive%20visualization&amp;journal=Comput%20Phys%20Commun&amp;volume=11&amp;issue=3&amp;pages=270-274&amp;publication_year=1997&amp;author=Bryson%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cavazza M, Hartley S, Lugrin JL, Bras ML (2003) Alternative reality: a new platform for virtual reality art. I" /><p class="c-article-references__text" id="ref-CR14">Cavazza M, Hartley S, Lugrin JL, Bras ML (2003) Alternative reality: a new platform for virtual reality art. In: Proceedings of virtual reality software and technology (VRST), ACM Press, pp 100–107. doi:<a href="https://doi.org/10.1145/1008653.1008672">10.1145/1008653.1008672</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Courtney A, Nilsson H, Peterson J (2003) The Yampa Arcade. In: ACM SIGPLAN Haskell workshop, ACM SIGPLAN, pp 7" /><p class="c-article-references__text" id="ref-CR15">Courtney A, Nilsson H, Peterson J (2003) The Yampa Arcade. In: ACM SIGPLAN Haskell workshop, ACM SIGPLAN, pp 7–18</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dachselt R, Rukzio E (2003) Behavior3D: an XML-based framework for 3D graphics behavior. In: Proceedings of th" /><p class="c-article-references__text" id="ref-CR16">Dachselt R, Rukzio E (2003) Behavior3D: an XML-based framework for 3D graphics behavior. In: Proceedings of the ACM Web3D 2003 conference, ACM Press, pp 101–112</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C.. Dede, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Dede C (2009) Immersive interfaces for engagement and learning. Science 323(5910):66–69. doi:10.1126/science.1" /><p class="c-article-references__text" id="ref-CR17">Dede C (2009) Immersive interfaces for engagement and learning. Science 323(5910):66–69. doi:<a href="https://doi.org/10.1126/science.1167311">10.1126/science.1167311</a>
                </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1126%2Fscience.1167311" aria-label="View reference 17">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Immersive%20interfaces%20for%20engagement%20and%20learning&amp;journal=Science&amp;doi=10.1126%2Fscience.1167311&amp;volume=323&amp;issue=5910&amp;pages=66-69&amp;publication_year=2009&amp;author=Dede%2CC.">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="de Haan G, Koutek M, Post FH (2005) IntenSelect: using dynamic object rating for assisting 3D object selection" /><p class="c-article-references__text" id="ref-CR18">de Haan G, Koutek M, Post FH (2005) IntenSelect: using dynamic object rating for assisting 3D object selection. In: Proceedings of the 9th IPT and 11th Eurographics VE workshop (EGVE), pp 201–209</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Difede, J. Cukor, N. Jayasinghe, I. Patt, S. Jedel, L. Spielman, C. Giosan, H. Hoffman, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Difede J, Cukor J, Jayasinghe N, Patt I, Jedel S, Spielman L, Giosan C, Hoffman H (2007) Virtual reality expos" /><p class="c-article-references__text" id="ref-CR19">Difede J, Cukor J, Jayasinghe N, Patt I, Jedel S, Spielman L, Giosan C, Hoffman H (2007) Virtual reality exposure therapy for the treatment of posttraumatic stress disorder following September 11, 2001. J Clin Psychiatry 68(11):1639–1647</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20exposure%20therapy%20for%20the%20treatment%20of%20posttraumatic%20stress%20disorder%20following%20September%2011%2C%202001&amp;journal=J%20Clin%20Psychiatry&amp;volume=68&amp;issue=11&amp;pages=1639-1647&amp;publication_year=2007&amp;author=Difede%2CJ&amp;author=Cukor%2CJ&amp;author=Jayasinghe%2CN&amp;author=Patt%2CI&amp;author=Jedel%2CS&amp;author=Spielman%2CL&amp;author=Giosan%2CC&amp;author=Hoffman%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Elliott C, Hudak P (1997) Functional reactive animation. In: International conference on functional programmin" /><p class="c-article-references__text" id="ref-CR20">Elliott C, Hudak P (1997) Functional reactive animation. In: International conference on functional programming, pp 196–203</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Emond B, Fournier H, Lapointe J et al (2010) Applying advanced user models and input technologies to augment m" /><p class="c-article-references__text" id="ref-CR21">Emond B, Fournier H, Lapointe J et al (2010) Applying advanced user models and input technologies to augment military simulation-based training. In: Proceedings of the 2010 spring military modeling and simulation symposium, pp 1–7</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Freeman, K. Pugh, A. Antley, M. Slater, P. Bebbington, M. Gittins, G. Dunn, E. Kuipers, D. Fowler, P. Garety, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Freeman D, Pugh K, Antley A, Slater M, Bebbington P, Gittins M, Dunn G, Kuipers E, Fowler D, Garety P (2008) V" /><p class="c-article-references__text" id="ref-CR22">Freeman D, Pugh K, Antley A, Slater M, Bebbington P, Gittins M, Dunn G, Kuipers E, Fowler D, Garety P (2008) Virtual reality study of paranoid thinking in the general population. Br J Psychiatry 192(4):258–263. doi:<a href="https://doi.org/10.1192/bjp.bp.107.044677">10.1192/bjp.bp.107.044677</a>
                </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1192%2Fbjp.bp.107.044677" aria-label="View reference 22">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20study%20of%20paranoid%20thinking%20in%20the%20general%20population&amp;journal=Br%20J%20Psychiatry&amp;doi=10.1192%2Fbjp.bp.107.044677&amp;volume=192&amp;issue=4&amp;pages=258-263&amp;publication_year=2008&amp;author=Freeman%2CD&amp;author=Pugh%2CK&amp;author=Antley%2CA&amp;author=Slater%2CM&amp;author=Bebbington%2CP&amp;author=Gittins%2CM&amp;author=Dunn%2CG&amp;author=Kuipers%2CE&amp;author=Fowler%2CD&amp;author=Garety%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Gorini, J. Mosso, D. Mosso, E. Pineda, N. Ruíz, M. Ramíez, J. Morales, G. Riva, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Gorini A, Mosso J, Mosso D, Pineda E, Ruíz N, Ramíez M, Morales J, Riva G (2009) Emotional response to virtual" /><p class="c-article-references__text" id="ref-CR23">Gorini A, Mosso J, Mosso D, Pineda E, Ruíz N, Ramíez M, Morales J, Riva G (2009) Emotional response to virtual reality exposure across different cultures: the role of the attribution process. CyberPsychol Behav 12(6):699–705</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1089%2Fcpb.2009.0192" aria-label="View reference 23">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Emotional%20response%20to%20virtual%20reality%20exposure%20across%20different%20cultures%3A%20the%20role%20of%20the%20attribution%20process&amp;journal=CyberPsychol%20Behav&amp;volume=12&amp;issue=6&amp;pages=699-705&amp;publication_year=2009&amp;author=Gorini%2CA&amp;author=Mosso%2CJ&amp;author=Mosso%2CD&amp;author=Pineda%2CE&amp;author=Ru%C3%ADz%2CN&amp;author=Ram%C3%ADez%2CM&amp;author=Morales%2CJ&amp;author=Riva%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Guger, C. Groenegress, C. Holzner, G. Edlinger, M. Slater, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Guger C, Groenegress C, Holzner C, Edlinger G, Slater M (2009) Brain–computer interface for virtual reality co" /><p class="c-article-references__text" id="ref-CR24">Guger C, Groenegress C, Holzner C, Edlinger G, Slater M (2009) Brain–computer interface for virtual reality control. Cyberpsychol Behav 12(1):84</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Brain%E2%80%93computer%20interface%20for%20virtual%20reality%20control&amp;journal=Cyberpsychol%20Behav&amp;volume=12&amp;issue=1&amp;publication_year=2009&amp;author=Guger%2CC&amp;author=Groenegress%2CC&amp;author=Holzner%2CC&amp;author=Edlinger%2CG&amp;author=Slater%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Haringer M, Beckhaus S (2010) Effect based scene manipulation for multimodal VR systems. In: IEEE VR 2010: pro" /><p class="c-article-references__text" id="ref-CR25">Haringer M, Beckhaus S (2010) Effect based scene manipulation for multimodal VR systems. In: IEEE VR 2010: proceedings of the IEEE virtual reality conference</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Haringer, S. Beckhaus, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Haringer M, Beckhaus S (2012) Adaptive generation of emotional impact using enhanced virtual environments. Pre" /><p class="c-article-references__text" id="ref-CR26">Haringer M, Beckhaus S (2012) Adaptive generation of emotional impact using enhanced virtual environments. Presence 21(1):96–116</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2FPRES_a_00092" aria-label="View reference 26">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Adaptive%20generation%20of%20emotional%20impact%20using%20enhanced%20virtual%20environments&amp;journal=Presence&amp;volume=21&amp;issue=1&amp;pages=96-116&amp;publication_year=2012&amp;author=Haringer%2CM&amp;author=Beckhaus%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hassanpour R, Wong S, Shahbahrami A (2008) Vision based hand gesture recognition for human computer interactio" /><p class="c-article-references__text" id="ref-CR27">Hassanpour R, Wong S, Shahbahrami A (2008) Vision based hand gesture recognition for human computer interaction: a review. In: IADIS international conference interfaces and human computer interaction, p 125</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RM. Held, NI. Durlach, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Held RM, Durlach NI (1992) Telepresence. Presence Teleoper Virtual Environ 1:109–112" /><p class="c-article-references__text" id="ref-CR28">Held RM, Durlach NI (1992) Telepresence. Presence Teleoper Virtual Environ 1:109–112</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Telepresence&amp;journal=Presence%20Teleoper%20Virtual%20Environ&amp;volume=1&amp;pages=109-112&amp;publication_year=1992&amp;author=Held%2CRM&amp;author=Durlach%2CNI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hernando J, Martinez J, Martin V, López M, Martin-Gago J (2009) Svis: a computational steering visualization e" /><p class="c-article-references__text" id="ref-CR29">Hernando J, Martinez J, Martin V, López M, Martin-Gago J (2009) Svis: a computational steering visualization environment for surface structure determination. In: Visualisation, 2009. VIZ’09. Second international conference in, IEEE, pp 36–39</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Herrlich M, Walther-Franks B, Schröder-Kroll R, Holthusen J, Malaka R (2011) Proxy-based selection for occlude" /><p class="c-article-references__text" id="ref-CR30">Herrlich M, Walther-Franks B, Schröder-Kroll R, Holthusen J, Malaka R (2011) Proxy-based selection for occluded and dynamic objects. In: Smart graphics, Springer, pp 142–145</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Hodges, B. Rothbaum, R. Alarcon, D. Ready, F. Shahar, K. Graap, J. Pair, P. Hebert, D. Gotz, B. Wills, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Hodges L, Rothbaum B, Alarcon R, Ready D, Shahar F, Graap K, Pair J, Hebert P, Gotz D, Wills B et al (1999) A " /><p class="c-article-references__text" id="ref-CR31">Hodges L, Rothbaum B, Alarcon R, Ready D, Shahar F, Graap K, Pair J, Hebert P, Gotz D, Wills B et al (1999) A virtual environment for the treatment of chronic combat-related post-traumatic stress disorder. Cyberpsychol Behav 2(1):7–14</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1089%2Fcpb.1999.2.7" aria-label="View reference 31">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20virtual%20environment%20for%20the%20treatment%20of%20chronic%20combat-related%20post-traumatic%20stress%20disorder&amp;journal=Cyberpsychol%20Behav&amp;volume=2&amp;issue=1&amp;pages=7-14&amp;publication_year=1999&amp;author=Hodges%2CL&amp;author=Rothbaum%2CB&amp;author=Alarcon%2CR&amp;author=Ready%2CD&amp;author=Shahar%2CF&amp;author=Graap%2CK&amp;author=Pair%2CJ&amp;author=Hebert%2CP&amp;author=Gotz%2CD&amp;author=Wills%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Hoffman, A. Garcia-Palacios, D. Patterson, M. Jensen, T. Furness, W. Ammons, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Hoffman H, Garcia-Palacios A, Patterson D, Jensen M, Furness T III, Ammons W Jr (2001) The effectiveness of vi" /><p class="c-article-references__text" id="ref-CR32">Hoffman H, Garcia-Palacios A, Patterson D, Jensen M, Furness T III, Ammons W Jr (2001) The effectiveness of virtual reality for dental pain control: a case study. Cyberpsychol Behav 4(4):527–535</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1089%2F109493101750527088" aria-label="View reference 32">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effectiveness%20of%20virtual%20reality%20for%20dental%20pain%20control%3A%20a%20case%20study&amp;journal=Cyberpsychol%20Behav&amp;volume=4&amp;issue=4&amp;pages=527-535&amp;publication_year=2001&amp;author=Hoffman%2CH&amp;author=Garcia-Palacios%2CA&amp;author=Patterson%2CD&amp;author=Jensen%2CM&amp;author=Furness%2CT&amp;author=Ammons%2CW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kallmann M, Thalmann D (1999) Direct 3D interaction with smart objects. In: VRST ’99: proceedings of the ACM s" /><p class="c-article-references__text" id="ref-CR33">Kallmann M, Thalmann D (1999) Direct 3D interaction with smart objects. In: VRST ’99: proceedings of the ACM symposium on virtual reality software and technology, ACM Press, New York, NY, USA, pp 124–130. doi:<a href="https://doi.org/10.1145/323663.323683">10.1145/323663.323683</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Konieczny J, Heckman J, Meyer G, Manyen M, Rabens M, Shimizu C (2008) Automotive spray paint simulation. Lectu" /><p class="c-article-references__text" id="ref-CR34">Konieczny J, Heckman J, Meyer G, Manyen M, Rabens M, Shimizu C (2008) Automotive spray paint simulation. Lecture Notes in Comput Sci 5358:998–1007</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Kulik, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Kulik A (2009) Building on realism and magic for designing 3D interaction techniques. IEEE Comput Graph Appl 2" /><p class="c-article-references__text" id="ref-CR35">Kulik A (2009) Building on realism and magic for designing 3D interaction techniques. IEEE Comput Graph Appl 29(6):22–33. doi:<a href="https://doi.org/10.1109/MCG.2009.115">10.1109/MCG.2009.115</a>
                </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FMCG.2009.115" aria-label="View reference 35">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2549564" aria-label="View reference 35 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Building%20on%20realism%20and%20magic%20for%20designing%203D%20interaction%20techniques&amp;journal=IEEE%20Comput%20Graph%20Appl&amp;doi=10.1109%2FMCG.2009.115&amp;volume=29&amp;issue=6&amp;pages=22-33&amp;publication_year=2009&amp;author=Kulik%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mateas M, Stern A (2003) Facade: an experiment in building a fully-realized interactive drama. In: Proceedings" /><p class="c-article-references__text" id="ref-CR36">Mateas M, Stern A (2003) Facade: an experiment in building a fully-realized interactive drama. In: Proceedings of the game developer’s conference: Game Design Track</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RN. McLay, DP. Wood, JA. Webb-Murphy, JL. Spira, MD. Wiederhold, JM. Pyne, BK. Wiederhold, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="McLay RN, Wood DP, Webb-Murphy JA, Spira JL, Wiederhold MD, Pyne JM, Wiederhold BK (2010) A randomized, contro" /><p class="c-article-references__text" id="ref-CR37">McLay RN, Wood DP, Webb-Murphy JA, Spira JL, Wiederhold MD, Pyne JM, Wiederhold BK (2010) A randomized, controlled trial of virtual reality-graded exposure therapy for post-traumatic stress disorder in active duty service members with combat-related post-traumatic stress disorder. Cyberpsychol Behav Soc Netw 13(1):3–11</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1089%2Fcyber.2009.0346" aria-label="View reference 37">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20randomized%2C%20controlled%20trial%20of%20virtual%20reality-graded%20exposure%20therapy%20for%20post-traumatic%20stress%20disorder%20in%20active%20duty%20service%20members%20with%20combat-related%20post-traumatic%20stress%20disorder&amp;journal=Cyberpsychol%20Behav%20Soc%20Netw&amp;volume=13&amp;issue=1&amp;pages=3-11&amp;publication_year=2010&amp;author=McLay%2CRN&amp;author=Wood%2CDP&amp;author=Webb-Murphy%2CJA&amp;author=Spira%2CJL&amp;author=Wiederhold%2CMD&amp;author=Pyne%2CJM&amp;author=Wiederhold%2CBK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mesing B, Hellmich C (2006) Using aspect oriented methods to add behaviour to X3D documents. In: Proceedings o" /><p class="c-article-references__text" id="ref-CR39">Mesing B, Hellmich C (2006) Using aspect oriented methods to add behaviour to X3D documents. In: Proceedings of the ACM Web3D 2006 conference, ACM</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Misra, K. Ramesh, A. Okamura, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Misra S, Ramesh K, Okamura A (2008) Modeling of tool–tissue interactions for computer-based surgical simulatio" /><p class="c-article-references__text" id="ref-CR40">Misra S, Ramesh K, Okamura A (2008) Modeling of tool–tissue interactions for computer-based surgical simulation: a literature review. Presence Teleoper Virtual Environ 17(5):463–491</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2Fpres.17.5.463" aria-label="View reference 39">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Modeling%20of%20tool%E2%80%93tissue%20interactions%20for%20computer-based%20surgical%20simulation%3A%20a%20literature%20review&amp;journal=Presence%20Teleoper%20Virtual%20Environ&amp;volume=17&amp;issue=5&amp;pages=463-491&amp;publication_year=2008&amp;author=Misra%2CS&amp;author=Ramesh%2CK&amp;author=Okamura%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pape D (1998) Crayoland. In: SIGGRAPH ’98: ACM SIGGRAPH 98 electronic art and animation catalog, ACM Press, Ne" /><p class="c-article-references__text" id="ref-CR41">Pape D (1998) Crayoland. In: SIGGRAPH ’98: ACM SIGGRAPH 98 electronic art and animation catalog, ACM Press, New York, NY, USA, p 116</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rehn GD, Lemessi M, Vance JM, Dorozhkin DV (2004) Integrating operations simulation results with an immersive " /><p class="c-article-references__text" id="ref-CR42">Rehn GD, Lemessi M, Vance JM, Dorozhkin DV (2004) Integrating operations simulation results with an immersive virtual reality environment. In: WSC ’04: Proceedings of the 36th winter simulation conference, pp 1713–1719</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Reiley, H. Lin, D. Yuh, G. Hager, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Reiley C, Lin H, Yuh D, Hager G (2011) Review of methods for objective surgical skill evaluation. Surg Endosc " /><p class="c-article-references__text" id="ref-CR43">Reiley C, Lin H, Yuh D, Hager G (2011) Review of methods for objective surgical skill evaluation. Surg Endosc 25(2):356–366</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs00464-010-1190-z" aria-label="View reference 42">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 42 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Review%20of%20methods%20for%20objective%20surgical%20skill%20evaluation&amp;journal=Surg%20Endosc&amp;volume=25&amp;issue=2&amp;pages=356-366&amp;publication_year=2011&amp;author=Reiley%2CC&amp;author=Lin%2CH&amp;author=Yuh%2CD&amp;author=Hager%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Richard, M. Naud, FX. Inglese, E. Richard, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Richard P, Naud M, Inglese FX, Richard E (2012) Modeling dynamic interaction in virtual environments and the e" /><p class="c-article-references__text" id="ref-CR44">Richard P, Naud M, Inglese FX, Richard E (2012) Modeling dynamic interaction in virtual environments and the evaluation of dynamic virtual fixtures. Presence Teleoper Virtual Environ 21(3):321–337</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2FPRES_a_00116" aria-label="View reference 43">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 43 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Modeling%20dynamic%20interaction%20in%20virtual%20environments%20and%20the%20evaluation%20of%20dynamic%20virtual%20fixtures&amp;journal=Presence%20Teleoper%20Virtual%20Environ&amp;volume=21&amp;issue=3&amp;pages=321-337&amp;publication_year=2012&amp;author=Richard%2CP&amp;author=Naud%2CM&amp;author=Inglese%2CFX&amp;author=Richard%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rizzo A, Rothbaum BO, Graap K (2007) Virtual reality applications for the treatment of combat-related PTSD. In" /><p class="c-article-references__text" id="ref-CR45">Rizzo A, Rothbaum BO, Graap K (2007) Virtual reality applications for the treatment of combat-related PTSD. In: Figley CR, Nash WP (eds) Combat stress injury: theory, research, and management. Routledge, New York, pp 183–204</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Roussos, AE. Johnson, J. Leigh, CA. Vasilakis, CR. Barnes, TG. Moher, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Roussos M, Johnson AE, Leigh J, Vasilakis CA, Barnes CR, Moher TG (1997) NICE: combining constructionism, narr" /><p class="c-article-references__text" id="ref-CR46">Roussos M, Johnson AE, Leigh J, Vasilakis CA, Barnes CR, Moher TG (1997) NICE: combining constructionism, narrative and collaboration in a virtual learning environment. Comput Graph 31(3):62–63. doi:<a href="https://doi.org/10.1145/262171.262264">10.1145/262171.262264</a>
                </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F262171.262264" aria-label="View reference 45">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 45 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=NICE%3A%20combining%20constructionism%2C%20narrative%20and%20collaboration%20in%20a%20virtual%20learning%20environment&amp;journal=Comput%20Graph&amp;doi=10.1145%2F262171.262264&amp;volume=31&amp;issue=3&amp;pages=62-63&amp;publication_year=1997&amp;author=Roussos%2CM&amp;author=Johnson%2CAE&amp;author=Leigh%2CJ&amp;author=Vasilakis%2CCA&amp;author=Barnes%2CCR&amp;author=Moher%2CTG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Salzmann H, Moehring M, Froehlich B (2009) Virtual vs. real-world pointing in two-user scenarios. In: VR ’09: " /><p class="c-article-references__text" id="ref-CR47">Salzmann H, Moehring M, Froehlich B (2009) Virtual vs. real-world pointing in two-user scenarios. In: VR ’09: Proceedings of the 2009 IEEE virtual reality conference, IEEE Computer Society, Washington, DC, USA, pp 127–130. doi:<a href="https://doi.org/10.1109/VR.2009.4811011">10.1109/VR.2009.4811011</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MV. Sanchez-Vives, M. Slater, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Sanchez-Vives MV, Slater M (2005) From presence to consciousness through virtual reality. Nat Rev Neurosci 6(4" /><p class="c-article-references__text" id="ref-CR48">Sanchez-Vives MV, Slater M (2005) From presence to consciousness through virtual reality. Nat Rev Neurosci 6(4):332–339</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1038%2Fnrn1651" aria-label="View reference 47">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 47 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=From%20presence%20to%20consciousness%20through%20virtual%20reality&amp;journal=Nat%20Rev%20Neurosci&amp;volume=6&amp;issue=4&amp;pages=332-339&amp;publication_year=2005&amp;author=Sanchez-Vives%2CMV&amp;author=Slater%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Schröder-Kroll R, Blom KJ, Beckhaus S (2008) Interaction techniques for dynamic virtual environments. In: Proc" /><p class="c-article-references__text" id="ref-CR49">Schröder-Kroll R, Blom KJ, Beckhaus S (2008) Interaction techniques for dynamic virtual environments. In: Proceedings of “Virtuelle und Erweiterte Realität” workshop of the Gesellschaft für Informatik e.V. (GI), Shaker Verlag, pp 57–68</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Sharar, W. Miller, A. Teeley, M. Soltani, H. Hoffman, M. Jensen, D. Patterson, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Sharar S, Miller W, Teeley A, Soltani M, Hoffman H, Jensen M, Patterson D (2008) Applications of virtual reali" /><p class="c-article-references__text" id="ref-CR50">Sharar S, Miller W, Teeley A, Soltani M, Hoffman H, Jensen M, Patterson D (2008) Applications of virtual reality for pain management in burn-injured patients. Expert Rev Neurother 8(11):1667</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1586%2F14737175.8.11.1667" aria-label="View reference 49">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 49 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Applications%20of%20virtual%20reality%20for%20pain%20management%20in%20burn-injured%20patients&amp;journal=Expert%20Rev%20Neurother&amp;volume=8&amp;issue=11&amp;publication_year=2008&amp;author=Sharar%2CS&amp;author=Miller%2CW&amp;author=Teeley%2CA&amp;author=Soltani%2CM&amp;author=Hoffman%2CH&amp;author=Jensen%2CM&amp;author=Patterson%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Sheridan, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Sheridan T (1992) Musings on telepresence and virtual presence. Presence Teleoper Virtual Environ 1(1):120–126" /><p class="c-article-references__text" id="ref-CR51">Sheridan T (1992) Musings on telepresence and virtual presence. Presence Teleoper Virtual Environ 1(1):120–126</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 50 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Musings%20on%20telepresence%20and%20virtual%20presence&amp;journal=Presence%20Teleoper%20Virtual%20Environ&amp;volume=1&amp;issue=1&amp;pages=120-126&amp;publication_year=1992&amp;author=Sheridan%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="S. Singhal, M. Zyda, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Singhal S, Zyda M (1999) Networked virtual environments. Design and implementation. Addison Wesley, Reading" /><p class="c-article-references__text" id="ref-CR52">Singhal S, Zyda M (1999) Networked virtual environments. Design and implementation. Addison Wesley, Reading</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 51 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Networked%20virtual%20environments.%20Design%20and%20implementation&amp;publication_year=1999&amp;author=Singhal%2CS&amp;author=Zyda%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Slater, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Slater M (2009) Place illusion and plausibility can lead to realistic behaviour in immersive virtual environme" /><p class="c-article-references__text" id="ref-CR53">Slater M (2009) Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments. Philos Trans R Soc Lond B Biol Sci 364(1535):3549–3557. doi:<a href="https://doi.org/10.1098/rstb.2009.0138">10.1098/rstb.2009.0138</a>
                </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1098%2Frstb.2009.0138" aria-label="View reference 52">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 52 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Place%20illusion%20and%20plausibility%20can%20lead%20to%20realistic%20behaviour%20in%20immersive%20virtual%20environments&amp;journal=Philos%20Trans%20R%20Soc%20Lond%20B%20Biol%20Sci&amp;doi=10.1098%2Frstb.2009.0138&amp;volume=364&amp;issue=1535&amp;pages=3549-3557&amp;publication_year=2009&amp;author=Slater%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Slater, B. Lotto, MM. Arnold, MV. Sanchez-Vives, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Slater M, Lotto B, Arnold MM, Sanchez-Vives MV (2009) How we experience immersive virtual environments: the co" /><p class="c-article-references__text" id="ref-CR54">Slater M, Lotto B, Arnold MM, Sanchez-Vives MV (2009) How we experience immersive virtual environments: the concept of presence and its measurement. Anu Psicol 40(2):193–210</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 53 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=How%20we%20experience%20immersive%20virtual%20environments%3A%20the%20concept%20of%20presence%20and%20its%20measurement&amp;journal=Anu%20Psicol&amp;volume=40&amp;issue=2&amp;pages=193-210&amp;publication_year=2009&amp;author=Slater%2CM&amp;author=Lotto%2CB&amp;author=Arnold%2CMM&amp;author=Sanchez-Vives%2CMV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Steed A. (2006) Towards a general model for selection in virtual environments. In: Proceedings of the IEEE sym" /><p class="c-article-references__text" id="ref-CR55">Steed A. (2006) Towards a general model for selection in virtual environments. In: Proceedings of the IEEE symposium on 3D user interfaces (3DUI), IEEE, pp 103–110</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Steuer, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Steuer J (1992) Defining virtual reality: dimensions determining telepresence. J Commun 42(4):73–93" /><p class="c-article-references__text" id="ref-CR56">Steuer J (1992) Defining virtual reality: dimensions determining telepresence. J Commun 42(4):73–93</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fj.1460-2466.1992.tb00812.x" aria-label="View reference 55">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 55 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Defining%20virtual%20reality%3A%20dimensions%20determining%20telepresence&amp;journal=J%20Commun&amp;volume=42&amp;issue=4&amp;pages=73-93&amp;publication_year=1992&amp;author=Steuer%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Takatalo, G. Nyman, L. Laaksonen, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Takatalo J, Nyman G, Laaksonen L (2008) Components of human experience in virtual environments. Comput Hum Beh" /><p class="c-article-references__text" id="ref-CR57">Takatalo J, Nyman G, Laaksonen L (2008) Components of human experience in virtual environments. Comput Hum Behav 24(1):1–15</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.chb.2006.11.003" aria-label="View reference 56">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 56 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Components%20of%20human%20experience%20in%20virtual%20environments&amp;journal=Comput%20Hum%20Behav&amp;volume=24&amp;issue=1&amp;pages=1-15&amp;publication_year=2008&amp;author=Takatalo%2CJ&amp;author=Nyman%2CG&amp;author=Laaksonen%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="F. Thomas, C. Torras, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Thomas F, Torras C (2001) 3D collision detection: a survey. Comput Graph 25:269–285" /><p class="c-article-references__text" id="ref-CR58">Thomas F, Torras C (2001) 3D collision detection: a survey. Comput Graph 25:269–285</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0097-8493%2800%2900130-8" aria-label="View reference 57">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 57 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=3D%20collision%20detection%3A%20a%20survey&amp;journal=Comput%20Graph&amp;volume=25&amp;pages=269-285&amp;publication_year=2001&amp;author=Thomas%2CF&amp;author=Torras%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Van Dam, A. Forsberg, D. Laidlaw, J. LaViola, R. Simpson, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Van Dam A, Forsberg A, Laidlaw D, LaViola J Jr, Simpson R (2000) Immersive VR for scientific visualization: a " /><p class="c-article-references__text" id="ref-CR59">Van Dam A, Forsberg A, Laidlaw D, LaViola J Jr, Simpson R (2000) Immersive VR for scientific visualization: a progress report. Comput Graph Appl IEEE 20(6):26–52</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F38.888006" aria-label="View reference 58">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 58 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Immersive%20VR%20for%20scientific%20visualization%3A%20a%20progress%20report&amp;journal=Comput%20Graph%20Appl%20IEEE&amp;volume=20&amp;issue=6&amp;pages=26-52&amp;publication_year=2000&amp;author=Van%20Dam%2CA&amp;author=Forsberg%2CA&amp;author=Laidlaw%2CD&amp;author=LaViola%2CJ&amp;author=Simpson%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="O. Meijden, M. Schijven, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="van der Meijden O, Schijven M (2009) The value of haptic feedback in conventional and robot-assisted minimal i" /><p class="c-article-references__text" id="ref-CR38">van der Meijden O, Schijven M (2009) The value of haptic feedback in conventional and robot-assisted minimal invasive surgery and virtual reality training: a current review. Surg Endosc 23(6):1180–1190</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs00464-008-0298-x" aria-label="View reference 59">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 59 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20value%20of%20haptic%20feedback%20in%20conventional%20and%20robot-assisted%20minimal%20invasive%20surgery%20and%20virtual%20reality%20training%3A%20a%20current%20review&amp;journal=Surg%20Endosc&amp;volume=23&amp;issue=6&amp;pages=1180-1190&amp;publication_year=2009&amp;author=Meijden%2CO&amp;author=Schijven%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Wan Z, Hudak P (2000) Functional reactive programming from first principles. In: Conference on programming lan" /><p class="c-article-references__text" id="ref-CR60">Wan Z, Hudak P (2000) Functional reactive programming from first principles. In: Conference on programming language design and implementation (PLDI’00), ACM SIGPLAN, ACM Press, pp 242–252</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Wu W, Arefin A, Rivas R, Nahrstedt K, Sheppard R, Yang Z (2009) Quality of experience in distributed interacti" /><p class="c-article-references__text" id="ref-CR61">Wu W, Arefin A, Rivas R, Nahrstedt K, Sheppard R, Yang Z (2009) Quality of experience in distributed interactive multimedia environments: toward a theoretical framework. In: Proceedings of the seventeen ACM international conference on multimedia, ACM, pp 481–490</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="C. Xian-Yi, P. Yan, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Xian-Yi C, Yan P (2011) Review of modern speech synthesis. In: Hu W (eds) Electronics and signal processing, l" /><p class="c-article-references__text" id="ref-CR62">Xian-Yi C, Yan P (2011) Review of modern speech synthesis. In: Hu W (eds) Electronics and signal processing, lecture notes in electrical engineering, vol 97, Springer, Berlin, pp 517–524</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 62 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Electronics%20and%20signal%20processing%2C%20lecture%20notes%20in%20electrical%20engineering%2C%20vol%2097&amp;pages=517-524&amp;publication_year=2011&amp;author=Xian-Yi%2CC&amp;author=Yan%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Yang U, Lee G, Kim Y, Jo D, Choi J, Kim K (2010) Virtual reality based welding training simulator with 3D mult" /><p class="c-article-references__text" id="ref-CR63">Yang U, Lee G, Kim Y, Jo D, Choi J, Kim K (2010) Virtual reality based welding training simulator with 3D multimodal interaction. In: Cyberworlds (CW), 2010 international conference on, IEEE, pp 150–154</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="GN. Yannakakis, J. Hallam, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Yannakakis GN, Hallam J (2009) Real-time game adaptation for optimizing player satisfaction. IEEE Trans Comput" /><p class="c-article-references__text" id="ref-CR64">Yannakakis GN, Hallam J (2009) Real-time game adaptation for optimizing player satisfaction. IEEE Trans Comput Intell AI Games 1(2):121–133</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTCIAIG.2009.2024533" aria-label="View reference 64">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 64 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Real-time%20game%20adaptation%20for%20optimizing%20player%20satisfaction&amp;journal=IEEE%20Trans%20Comput%20Intell%20AI%20Games&amp;volume=1&amp;issue=2&amp;pages=121-133&amp;publication_year=2009&amp;author=Yannakakis%2CGN&amp;author=Hallam%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Zahorik, R. Jenison, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Zahorik P, Jenison R (1998) Presence as being-in-the-world. Presence 7(1):78–89" /><p class="c-article-references__text" id="ref-CR65">Zahorik P, Jenison R (1998) Presence as being-in-the-world. Presence 7(1):78–89</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474698565541" aria-label="View reference 65">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 65 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Presence%20as%20being-in-the-world&amp;journal=Presence&amp;volume=7&amp;issue=1&amp;pages=78-89&amp;publication_year=1998&amp;author=Zahorik%2CP&amp;author=Jenison%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="TO. Zander, C. Kothe, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Zander TO, Kothe C (2011) Towards passive brain–computer interfaces: applying brain–computer interface technol" /><p class="c-article-references__text" id="ref-CR66">Zander TO, Kothe C (2011) Towards passive brain–computer interfaces: applying brain–computer interface technology to human-machine systems in general. J Neural Eng 8(2):025005</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1088%2F1741-2560%2F8%2F2%2F025005" aria-label="View reference 66">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 66 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Towards%20passive%20brain%E2%80%93computer%20interfaces%3A%20applying%20brain%E2%80%93computer%20interface%20technology%20to%20human-machine%20systems%20in%20general&amp;journal=J%20Neural%20Eng&amp;volume=8&amp;issue=2&amp;publication_year=2011&amp;author=Zander%2CTO&amp;author=Kothe%2CC">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-013-0232-y-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Department Informatik, interactive media.virtual environments, Universität Hamburg, Vogt-Kölln-Straße 30, 22527, Hamburg, Germany</p><p class="c-article-author-affiliation__authors-list">Kristopher J. Blom &amp; Steffi Beckhaus</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Kristopher_J_-Blom"><span class="c-article-authors-search__title u-h3 js-search-name">Kristopher J. Blom</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Kristopher J.+Blom&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Kristopher J.+Blom" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Kristopher J.+Blom%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Steffi-Beckhaus"><span class="c-article-authors-search__title u-h3 js-search-name">Steffi Beckhaus</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Steffi+Beckhaus&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Steffi+Beckhaus" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Steffi+Beckhaus%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-013-0232-y/email/correspondent/c1/new">Kristopher J. Blom</a>.</p></div></div></section><section aria-labelledby="Sec15"><div class="c-article-section" id="Sec15-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec15">Electronic supplementary material</h2><div class="c-article-section__content" id="Sec15-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><p>Below is the link to the electronic supplementary material.

</p>
                <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM1"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1007%2Fs10055-013-0232-y/MediaObjects/10055_2013_232_MOESM1_ESM.pdf" data-supp-info-image="">PDF (164 KB)</a></h3></div></div></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=The%20design%20space%20of%20dynamic%20interactive%20virtual%20environments&amp;author=Kristopher%20J.%20Blom%20et%20al&amp;contentID=10.1007%2Fs10055-013-0232-y&amp;publication=1359-4338&amp;publicationDate=2013-09-28&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Blom, K.J., Beckhaus, S. The design space of dynamic interactive virtual environments.
                    <i>Virtual Reality</i> <b>18, </b>101–116 (2014). https://doi.org/10.1007/s10055-013-0232-y</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-013-0232-y.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2011-02-07">07 February 2011</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2013-09-12">12 September 2013</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2013-09-28">28 September 2013</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2014-06">June 2014</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-013-0232-y" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-013-0232-y</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Virtual environments</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Dynamic interactive VEs</span></li><li class="c-article-subject-list__subject"><span itemprop="about">3D user interaction</span></li><li class="c-article-subject-list__subject"><span itemprop="about">VR systems</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-013-0232-y.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=232;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

