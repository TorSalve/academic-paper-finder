<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="A hybrid optical&#8211;mechanical calibration procedure for the Scalab"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="In this research, a simple, yet, efficient calibration procedure is presented in order to improve the accuracy of the Scalable-SPIDAR haptic device. The two-stage procedure aims to reduce..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/21/3.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="A hybrid optical&#8211;mechanical calibration procedure for the Scalable-SPIDAR haptic device"/>

    <meta name="dc.source" content="Virtual Reality 2016 21:3"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2016-12-10"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2016 Springer-Verlag London"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="In this research, a simple, yet, efficient calibration procedure is presented in order to improve the accuracy of the Scalable-SPIDAR haptic device. The two-stage procedure aims to reduce discrepancies between measured and actual values. First, we propose a new semi-automatic procedure for the initialization of the haptic device. To perform this initialization with a high level of accuracy, an infrared optical tracking device was used. Furthermore, audio and haptic cues were used to guide the user during the initialization process. Second, we developed two calibration methods based on regression techniques that effectively compensate for the errors in tracked position. Both neural networks and support vector regression methods were applied to calibrate the position errors present in the haptic device readings. A comparison between these two regression methods was carried out to show the underlying algorithm and to indicate the inherent advantages and limitations for each method. Initial evaluation of the proposed procedure indicated that it is possible to improve accuracy by reducing the Scalable-SPIDAR&#8217;s average absolute position error to about 6&#160;mm within a 1&#160;m&#160;&#215;&#160;1&#160;m&#160;&#215;&#160;1&#160;m workspace."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2016-12-10"/>

    <meta name="prism.volume" content="21"/>

    <meta name="prism.number" content="3"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="109"/>

    <meta name="prism.endingPage" content="125"/>

    <meta name="prism.copyright" content="2016 Springer-Verlag London"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-016-0303-y"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-016-0303-y"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-016-0303-y.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-016-0303-y"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="A hybrid optical&#8211;mechanical calibration procedure for the Scalable-SPIDAR haptic device"/>

    <meta name="citation_volume" content="21"/>

    <meta name="citation_issue" content="3"/>

    <meta name="citation_publication_date" content="2017/09"/>

    <meta name="citation_online_date" content="2016/12/10"/>

    <meta name="citation_firstpage" content="109"/>

    <meta name="citation_lastpage" content="125"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-016-0303-y"/>

    <meta name="DOI" content="10.1007/s10055-016-0303-y"/>

    <meta name="citation_doi" content="10.1007/s10055-016-0303-y"/>

    <meta name="description" content="In this research, a simple, yet, efficient calibration procedure is presented in order to improve the accuracy of the Scalable-SPIDAR haptic device. The tw"/>

    <meta name="dc.creator" content="M&#8217;hamed Frad"/>

    <meta name="dc.creator" content="Hichem Maaref"/>

    <meta name="dc.creator" content="Samir Otmane"/>

    <meta name="dc.creator" content="Abdellatif Mtibaa"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Advanced Realtime Tracking GmbH (2003) ARTtrack1 &amp; DTrack&#8212;Manual Version 1.18"/>

    <meta name="citation_reference" content="citation_title=Neural networks for pattern recognition; citation_publication_date=1995; citation_id=CR2; citation_author=CM Bishop; citation_publisher=Oxford University Press Inc"/>

    <meta name="citation_reference" content="citation_journal_title=Inf Sci; citation_title=Support vector regression from simulation data and few experimental samples; citation_author=G Bloch; citation_volume=178; citation_issue=20; citation_publication_date=2008; citation_pages=3813-3827; citation_doi=10.1016/j.ins.2008.05.016; citation_id=CR3"/>

    <meta name="citation_reference" content="Boudoin P et al (2010) SPIDAR calibration based on neural networks versus optical tracking. BT&#8212;artificial neural networks and intelligent information processing. In: Proceedings of the 6th international workshop on artificial neural networks and intelligent information processing, pp 87&#8211;98"/>

    <meta name="citation_reference" content="Bouguila L, Ishii M, Sato M (2000) Effect of coupling haptics and stereopsis on depth perception in virtual environment. In: Proceedings of the 1st workshop on haptic human computer interaction, 31st August&#8211;1st Sept 2000. pp 54&#8211;62"/>

    <meta name="citation_reference" content="Briggs W (1999) Magnetic calibration by tetrahedral interpolation. In: Proceedings of NIST-ASME industrial virtual reality symposium, Chicago, pp 27&#8211;32"/>

    <meta name="citation_reference" content="Bryson S (1992) Measurement and calibration of static distortion of position data from 3D trackers. In: Proceedings of SPIE conference. Stereoscopic displays and applications III, pp 244&#8211;255"/>

    <meta name="citation_reference" content="Buoguila L, Ishii M, Sato M (2000) Multi-modal haptic device for large-scale virtual environments. In: Proceedings of the eighth ACM international conference on multimedia. MULTIMEDIA &#8217;00. ACM, New York, pp 277&#8211;283"/>

    <meta name="citation_reference" content="citation_title=Force and touch feedback for virtual reality; citation_publication_date=1996; citation_id=CR9; citation_author=GC Burdea; citation_publisher=Wiley"/>

    <meta name="citation_reference" content="Ellis SR et al (1999) Sensor spatial distortion, visual latency, and update rate effects\non 3D tracking in virtual environments. In: Proceedings IEEE virtual reality (Cat no 99CB36316), pp 218&#8211;221"/>

    <meta name="citation_reference" content="citation_title=Haptic virtual reality training environment for micro-robotic cell injection; citation_inbook_title=Haptic interaction: perception, devices and applications; citation_publication_date=2015; citation_pages=245-249; citation_id=CR11; citation_author=S Faroque; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Ind; citation_title=The development of an integrated haptic VR machining environment for the automatic generation of process plans; citation_author=C Fletcher; citation_volume=64; citation_issue=8; citation_publication_date=2013; citation_pages=1045-1060; citation_doi=10.1016/j.compind.2013.07.005; citation_id=CR12"/>

    <meta name="citation_reference" content="citation_title=Virtual reality: concepts and technologies; citation_publication_date=2011; citation_id=CR13; citation_author=P Fuchs; citation_author=G Moreau; citation_author=P Guitton; citation_publisher=CRC Press Inc"/>

    <meta name="citation_reference" content="Ghazisaedy M et al (1995) Ultrasonic calibration of a magnetic tracker in a virtual reality space. In: Proceedings virtual reality annual international symposium &#8217;95, pp 179&#8211;188"/>

    <meta name="citation_reference" content="Group S (2005) SPIDAR-G/AHS1.0A user&#8217;s manual Ver. 2.0., pp 1&#8211;44"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Neural Netw; citation_title=Training feedforward networks with the Marquardt algorithm; citation_author=MT Hagan, MB Menhaj; citation_volume=5; citation_issue=6; citation_publication_date=1994; citation_pages=989-993; citation_doi=10.1109/72.329697; citation_id=CR16"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Vis Comput Graph; citation_title=Calibration, registration, and synchronization for high precision augmented reality haptics; citation_author=M Harders; citation_volume=15; citation_issue=1; citation_publication_date=2009; citation_pages=138-149; citation_doi=10.1109/TVCG.2008.63; citation_id=CR17"/>

    <meta name="citation_reference" content="citation_title=The elements of statistical learning: data mining, inference, and prediction; citation_publication_date=2009; citation_id=CR18; citation_author=TJ Hastie; citation_author=RJ Tibshirani; citation_author=JH Friedman; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Sensor Rev; citation_title=Haptic interfaces and devices; citation_author=V Hayward; citation_volume=24; citation_issue=1; citation_publication_date=2004; citation_pages=16-29; citation_doi=10.1108/02602280410515770; citation_id=CR19"/>

    <meta name="citation_reference" content="Hirata Y, Sato M (1992) 3-dimensional interface device for virtual work space. In: Proceedings of the 1992 lEEE/RSJ international conference on intelligent robots and systems, vol 2, pp 889&#8211;896"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Netw; citation_title=Multilayer feedforward networks are universal approximators; citation_author=K Hornik, M Stinchcombe, H White; citation_volume=2; citation_issue=5; citation_publication_date=1989; citation_pages=359-366; citation_doi=10.1016/0893-6080(89)90020-8; citation_id=CR21"/>

    <meta name="citation_reference" content="citation_journal_title=Adv Neural Inf Process Syst; citation_title=A comparison of projection pursuit and neural network regression modeling; citation_author=J-N Huang; citation_volume=4; citation_publication_date=1992; citation_pages=1159-1166; citation_id=CR22"/>

    <meta name="citation_reference" content="ISO 5725-1 (1994) Accuracy (trueness and precision) of measurement methods and results&#8212;part 1: general principles and definitions. International Organization for Standardization, Geneva"/>

    <meta name="citation_reference" content="citation_journal_title=Proc IEEE Virtual Real; citation_title=An improved calibration framework for electromagnetic tracking devices; citation_author=M Ikits; citation_volume=2001; citation_publication_date=2001; citation_pages=63-70; citation_id=CR24"/>

    <meta name="citation_reference" content="Ikits M, Hansen CD, Johnson CR (2003) A comprehensive calibration and registration procedure for the visual haptic workbench. In: Proceedings of the workshop on virtual environments 2003. EGVE&#8217;03. ACM, New York, pp 247&#8211;254"/>

    <meta name="citation_reference" content="Ikits M et al (2000) The visual haptic workbench. In: Proceedings of PHANToM users group workshop. pp 46&#8211;49"/>

    <meta name="citation_reference" content="citation_journal_title=J Mech Des; citation_title=Integrated real-time calibration of electromagnetic tracking of user motions for engineering applications in virtual environments; citation_author=U Jayaram, R Repp; citation_volume=124; citation_publication_date=2002; citation_pages=623; citation_doi=10.1115/1.1517562; citation_id=CR27"/>

    <meta name="citation_reference" content="citation_title=Learning and soft computing: support vector machines, neural networks, and fuzzy logic models; citation_publication_date=2001; citation_id=CR28; citation_author=V Kecman; citation_publisher=MIT Press"/>

    <meta name="citation_reference" content="citation_title=Support vector machines&#8212;an introduction; citation_inbook_title=Support vector machines: theory and applications; citation_publication_date=2005; citation_pages=1-47; citation_id=CR29; citation_author=V Kecman; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Vis Comput Graph; citation_title=Interactive time-dependent particle tracing using tetrahedral decomposition; citation_author=DN Kenwright, DA Lane; citation_volume=2; citation_issue=2; citation_publication_date=1996; citation_pages=120-129; citation_doi=10.1109/2945.506224; citation_id=CR30"/>

    <meta name="citation_reference" content="Kim S et al (2002) Tension based 7-DOF force feedback device: SPIDAR-G. In: Proceedings, IEEE virtual reality. pp 283&#8211;284"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=Calibration of electromagnetic tracking devices; citation_author=V Kindratenko; citation_volume=4; citation_publication_date=1999; citation_pages=139-150; citation_doi=10.1007/BF01408592; citation_id=CR32"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=A survey of electromagnetic position tracker calibration techniques; citation_author=V Kindratenko; citation_volume=5; citation_issue=3; citation_publication_date=2000; citation_pages=169-182; citation_doi=10.1007/BF01409422; citation_id=CR33"/>

    <meta name="citation_reference" content="citation_title=Evaluation of rotation correction techniques for electromagnetic position tracking systems; citation_inbook_title=Virtual environments 2000 SE&#8212;3. Eurographics; citation_publication_date=2000; citation_pages=13-22; citation_id=CR34; citation_author=V Kindratenko; citation_author=A Bennett; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real.; citation_title=Neural network-based calibration of electromagnetic tracking systems; citation_author=VV Kindratenko, WR Sherman; citation_volume=9; citation_issue=1; citation_publication_date=2005; citation_pages=70-78; citation_doi=10.1007/s10055-005-0005-3; citation_id=CR35"/>

    <meta name="citation_reference" content="Knoerlein B, Harders M (2011) Comparison of tracker-based to tracker-less haptic device calibration. In: World haptics conference (WHC), 2011 IEEE, pp 119&#8211;124"/>

    <meta name="citation_reference" content="Kunzler U, Runde C (2005) Kinesthetic haptics integration into large-scale virtual environments. In: Eurohaptics conference, 2005 and symposium on haptic interfaces for virtual environment and teleoperator systems, 2005. World haptics 2005. First Joint, pp 551&#8211;556"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Geosci Remote Sens; citation_title=Application of machine-learning techniques toward the creation of a consistent and calibrated global chlorophyll concentration baseline dataset using remotely sensed ocean color data; citation_author=EJ Kwiatkowska, GS Fargion; citation_volume=41; citation_issue=12; citation_publication_date=2003; citation_pages=2844-2860; citation_doi=10.1109/TGRS.2003.818016; citation_id=CR38"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Magnetic tracker calibration for improved augmented reality registration; citation_author=MA Livingston, A State; citation_volume=6; citation_issue=5; citation_publication_date=1997; citation_pages=532-546; citation_doi=10.1162/pres.1997.6.5.532; citation_id=CR39"/>

    <meta name="citation_reference" content="citation_journal_title=Soft Comput; citation_title=Studies in fuzziness and soft computing, volume 172; citation_author=P Melin, O Castillo; citation_volume=18; citation_issue=3&#8211;4; citation_publication_date=2005; citation_pages=318; citation_id=CR40"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoper Virtual Environ; citation_title=A survey of position trackers; citation_author=K Meyer, HL Applewhite, FA Biocca; citation_volume=1; citation_issue=2; citation_publication_date=1992; citation_pages=173-200; citation_doi=10.1162/pres.1992.1.2.173; citation_id=CR41"/>

    <meta name="citation_reference" content="Moreira AHJ et al (2014) Electromagnetic tracker feasibility in the design of a dental superstructure for edentulous patients. In: IEEE MeMeA 2014&#8212;IEEE international symposium on medical measurements and applications, Proceedings, pp 1&#8211;6"/>

    <meta name="citation_reference" content="citation_title=Adaptive pattern recognition and neural networks; citation_publication_date=1989; citation_id=CR43; citation_author=Y-H Pao; citation_publisher=Addison-Wesley Longman Publishing Co., Inc"/>

    <meta name="citation_reference" content="Ramsamy P et al (2006) Using haptics to improve immersion in virtual environments. In: Alexandrov V et al (eds) Computational science&#8212;ICCS 2006 SE&#8212;81, Lecture Notes in Computer Science. Springer, Berlin, pp 603&#8211;609"/>

    <meta name="citation_reference" content="Reinig K, Tracy R, Gilmore H, Mahalik T (1997) Some calibration information for a Phantom 1.5 a. In: Proceedings of the second PHANToM user&#8217;s group workshop. Dedham, Massachusetts, pp 70&#8211;73"/>

    <meta name="citation_reference" content="citation_journal_title=Stat Comput; citation_title=A tutorial on support vector regression; citation_author=AJ Smola, B Sch&#246;lkopf; citation_volume=14; citation_issue=3; citation_publication_date=2004; citation_pages=199-222; citation_doi=10.1023/B:STCO.0000035301.49549.88; citation_id=CR46"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph; citation_title=Haptics in virtual environments: taxonomy, research status, and challenges; citation_author=MA Srinivasan, C Basdogan; citation_volume=21; citation_issue=4; citation_publication_date=1997; citation_pages=393-404; citation_doi=10.1016/S0097-8493(97)00030-7; citation_id=CR47"/>

    <meta name="citation_reference" content="citation_title=Virtual reality: scientific and technical challenges; citation_inbook_title=Report of the committee on virtual reality research and development, National Research Council; citation_publication_date=1995; citation_pages=161-187; citation_id=CR48; citation_author=MA Srinivasan; citation_publisher=National Academy Press"/>

    <meta name="citation_reference" content="citation_journal_title=Neurocomputing; citation_title=Weighted least squares support vector machines: robustness and sparse approximation; citation_author=JAK Suykens; citation_volume=48; citation_issue=1&#8211;4; citation_publication_date=2002; citation_pages=85-105; citation_doi=10.1016/S0925-2312(01)00644-0; citation_id=CR49"/>

    <meta name="citation_reference" content="Tukey JW (1977) Schematic and summaries (pictures and numbers). In: Tukey JW (ed) Exploratory data analysis. Addison-Wesley Inc., pp 27&#8211;55"/>

    <meta name="citation_reference" content="Vapnik V, Golowich SE, Smola AJ (1997) Support vector method for function approximation, regression estimation and signal processing. In: Mozer M, Jordan MI, Petsche T (eds) Advances in neural information processing systems 9&#8212;proceedings of the 1996 neural information processing systems conference (NIPS 1996). MIT Press, Cambridge, Dever, pp 281&#8211;287"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph Appl IEEE; citation_title=Motion tracking: no silver bullet, but a respectable arsenal; citation_author=G Welch, E Foxlin; citation_volume=22; citation_issue=6; citation_publication_date=2002; citation_pages=24-38; citation_doi=10.1109/MCG.2002.1046626; citation_id=CR52"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Adv Manuf Technol; citation_title=A new type haptics-based virtual environment system for assembly training of complex products; citation_author=P Xia; citation_volume=58; citation_issue=1; citation_publication_date=2012; citation_pages=379-396; citation_doi=10.1007/s00170-011-3381-8; citation_id=CR53"/>

    <meta name="citation_reference" content="Yu H, Wilamowski BM (2011) Levenberg&#8211;Marquardt training. In: Industrial electronics handbook&#8212;intelligent systems, vol 5. CRC Press, Inc., pp 12&#8211;1&#8211;12&#8211;15"/>

    <meta name="citation_reference" content="Zachmann G (1997) Distortion correction of magnetic fields for position tracking. In: Proceedings computer graphics international, pp 213&#8211;220, 251"/>

    <meta name="citation_author" content="M&#8217;hamed Frad"/>

    <meta name="citation_author_email" content="mhamed.frad@gmail.com"/>

    <meta name="citation_author_institution" content="IBISC Laboratory, University of Evry Val-d&#8217;Essonne, &#201;vry, France"/>

    <meta name="citation_author_institution" content="E&#181;E Laboratory, University of Monastir, Monastir, Tunisia"/>

    <meta name="citation_author" content="Hichem Maaref"/>

    <meta name="citation_author_institution" content="IBISC Laboratory, University of Evry Val-d&#8217;Essonne, &#201;vry, France"/>

    <meta name="citation_author" content="Samir Otmane"/>

    <meta name="citation_author_institution" content="IBISC Laboratory, University of Evry Val-d&#8217;Essonne, &#201;vry, France"/>

    <meta name="citation_author" content="Abdellatif Mtibaa"/>

    <meta name="citation_author_institution" content="E&#181;E Laboratory, University of Monastir, Monastir, Tunisia"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-016-0303-y&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2017/09/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-016-0303-y"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="A hybrid optical–mechanical calibration procedure for the Scalable-SPIDAR haptic device"/>
        <meta property="og:description" content="In this research, a simple, yet, efficient calibration procedure is presented in order to improve the accuracy of the Scalable-SPIDAR haptic device. The two-stage procedure aims to reduce discrepancies between measured and actual values. First, we propose a new semi-automatic procedure for the initialization of the haptic device. To perform this initialization with a high level of accuracy, an infrared optical tracking device was used. Furthermore, audio and haptic cues were used to guide the user during the initialization process. Second, we developed two calibration methods based on regression techniques that effectively compensate for the errors in tracked position. Both neural networks and support vector regression methods were applied to calibrate the position errors present in the haptic device readings. A comparison between these two regression methods was carried out to show the underlying algorithm and to indicate the inherent advantages and limitations for each method. Initial evaluation of the proposed procedure indicated that it is possible to improve accuracy by reducing the Scalable-SPIDAR’s average absolute position error to about 6&amp;nbsp;mm within a 1&amp;nbsp;m&amp;nbsp;×&amp;nbsp;1&amp;nbsp;m&amp;nbsp;×&amp;nbsp;1&amp;nbsp;m workspace."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>A hybrid optical–mechanical calibration procedure for the Scalable-SPIDAR haptic device | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-016-0303-y","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Scalable-SPIDAR, Virtual reality, Tracking, Calibration, Neural networks, Support vector regression","kwrd":["Scalable-SPIDAR","Virtual_reality","Tracking","Calibration","Neural_networks","Support_vector_regression"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-016-0303-y","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-016-0303-y","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=303;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-016-0303-y">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            A hybrid optical–mechanical calibration procedure for the Scalable-SPIDAR haptic device
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-016-0303-y.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-016-0303-y.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2016-12-10" itemprop="datePublished">10 December 2016</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">A hybrid optical–mechanical calibration procedure for the Scalable-SPIDAR haptic device</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-M_hamed-Frad" data-author-popup="auth-M_hamed-Frad" data-corresp-id="c1">M’hamed Frad<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><span class="u-js-hide"> 
            <a class="js-orcid" itemprop="url" href="http://orcid.org/0000-0003-2517-7040"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-2517-7040</a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Evry Val-d’Essonne" /><meta itemprop="address" content="0000 0001 2180 5818, grid.8390.2, IBISC Laboratory, University of Evry Val-d’Essonne, Évry, France" /></span><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Monastir" /><meta itemprop="address" content="0000 0004 0593 5040, grid.411838.7, EµE Laboratory, University of Monastir, Monastir, Tunisia" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Hichem-Maaref" data-author-popup="auth-Hichem-Maaref">Hichem Maaref</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Evry Val-d’Essonne" /><meta itemprop="address" content="0000 0001 2180 5818, grid.8390.2, IBISC Laboratory, University of Evry Val-d’Essonne, Évry, France" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Samir-Otmane" data-author-popup="auth-Samir-Otmane">Samir Otmane</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Evry Val-d’Essonne" /><meta itemprop="address" content="0000 0001 2180 5818, grid.8390.2, IBISC Laboratory, University of Evry Val-d’Essonne, Évry, France" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Abdellatif-Mtibaa" data-author-popup="auth-Abdellatif-Mtibaa">Abdellatif Mtibaa</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Monastir" /><meta itemprop="address" content="0000 0004 0593 5040, grid.411838.7, EµE Laboratory, University of Monastir, Monastir, Tunisia" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 21</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">109</span>–<span itemprop="pageEnd">125</span>(<span data-test="article-publication-year">2017</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">300 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-016-0303-y/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>In this research, a simple, yet, efficient calibration procedure is presented in order to improve the accuracy of the Scalable-SPIDAR haptic device. The two-stage procedure aims to reduce discrepancies between measured and actual values. First, we propose a new semi-automatic procedure for the initialization of the haptic device. To perform this initialization with a high level of accuracy, an infrared optical tracking device was used. Furthermore, audio and haptic cues were used to guide the user during the initialization process. Second, we developed two calibration methods based on regression techniques that effectively compensate for the errors in tracked position. Both neural networks and support vector regression methods were applied to calibrate the position errors present in the haptic device readings. A comparison between these two regression methods was carried out to show the underlying algorithm and to indicate the inherent advantages and limitations for each method. Initial evaluation of the proposed procedure indicated that it is possible to improve accuracy by reducing the Scalable-SPIDAR’s average absolute position error to about 6 mm within a 1 m × 1 m × 1 m workspace.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Haptic feedback is a natural part of our daily experience when we manipulate objects in our surroundings. With advances in haptic technology, virtual reality (VR) systems with integrated haptic devices are becoming increasingly popular in assembly training (Xia et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Xia P et al (2012) A new type haptics-based virtual environment system for assembly training of complex products. Int J Adv Manuf Technol 58(1):379–396" href="/article/10.1007/s10055-016-0303-y#ref-CR53" id="ref-link-section-d17e341">2012</a>), virtual machining (Fletcher et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Fletcher C et al (2013) The development of an integrated haptic VR machining environment for the automatic generation of process plans. Comput Ind 64(8):1045–1060" href="/article/10.1007/s10055-016-0303-y#ref-CR12" id="ref-link-section-d17e344">2013</a>) and virtual biology training (Faroque et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Faroque S et al (2015) Haptic virtual reality training environment for micro-robotic cell injection. In: Kajimoto H, Ando H, Kyung K-U (eds) Haptic interaction: perception, devices and applications. Springer, Tokyo, pp 245–249" href="/article/10.1007/s10055-016-0303-y#ref-CR11" id="ref-link-section-d17e347">2015</a>). Being able to touch, feel and manipulate virtual objects improves the realism of virtual environments and, therefore, intensifies the user’s feeling of immersion and presence (Srinivasan and Basdogan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Srinivasan MA, Basdogan C (1997) Haptics in virtual environments: taxonomy, research status, and challenges. Comput Graph 21(4):393–404" href="/article/10.1007/s10055-016-0303-y#ref-CR47" id="ref-link-section-d17e350">1997</a>; Ramsamy et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Ramsamy P et al (2006) Using haptics to improve immersion in virtual environments. In: Alexandrov V et al (eds) Computational science—ICCS 2006 SE—81, Lecture Notes in Computer Science. Springer, Berlin, pp 603–609" href="/article/10.1007/s10055-016-0303-y#ref-CR44" id="ref-link-section-d17e353">2006</a>). Various studies have addressed the development of haptic devices in virtual reality, for instance Burdea (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Burdea GC (1996) Force and touch feedback for virtual reality. Wiley, New York" href="/article/10.1007/s10055-016-0303-y#ref-CR9" id="ref-link-section-d17e357">1996</a>), Hayward et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Hayward V et al (2004) Haptic interfaces and devices. Sensor Rev 24(1):16–29" href="/article/10.1007/s10055-016-0303-y#ref-CR19" id="ref-link-section-d17e360">2004</a>) and Fuchs et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Fuchs P, Moreau G, Guitton P (2011) Virtual reality: concepts and technologies, 1st edn. CRC Press Inc, Boca Raton" href="/article/10.1007/s10055-016-0303-y#ref-CR13" id="ref-link-section-d17e363">2011</a>). Unfortunately, most of the current devices are either bulky, intrusive, expensive or only work within a limited space (Srinivasan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Srinivasan MA (1995) Virtual reality: scientific and technical challenges. In: Durlach NI, Mavor AS (eds) Report of the committee on virtual reality research and development, National Research Council. National Academy Press, Washington, pp 161–187" href="/article/10.1007/s10055-016-0303-y#ref-CR48" id="ref-link-section-d17e366">1995</a>; Ikits et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Ikits M et al (2000) The visual haptic workbench. In: Proceedings of PHANToM users group workshop. pp 46–49" href="/article/10.1007/s10055-016-0303-y#ref-CR26" id="ref-link-section-d17e369">2000</a>).</p><p>To overcome these problems, Buoguila et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Buoguila L, Ishii M, Sato M (2000) Multi-modal haptic device for large-scale virtual environments. In: Proceedings of the eighth ACM international conference on multimedia. MULTIMEDIA ’00. ACM, New York, pp 277–283" href="/article/10.1007/s10055-016-0303-y#ref-CR8" id="ref-link-section-d17e375">2000</a>) proposed a human-scale haptic device named Scalable-SPIDAR for SPace Interface Device for Artificial Reality. The device is derived from the original desktop SPIDAR device which was developed by Hirata and Sato (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Hirata Y, Sato M (1992) 3-dimensional interface device for virtual work space. In: Proceedings of the 1992 lEEE/RSJ international conference on intelligent robots and systems, vol 2, pp 889–896" href="/article/10.1007/s10055-016-0303-y#ref-CR20" id="ref-link-section-d17e378">1992</a>). According to the state-of-the-art haptic interface technology given by Kunzler and Runde (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Kunzler U, Runde C (2005) Kinesthetic haptics integration into large-scale virtual environments. In: Eurohaptics conference, 2005 and symposium on haptic interfaces for virtual environment and teleoperator systems, 2005. World haptics 2005. First Joint, pp 551–556" href="/article/10.1007/s10055-016-0303-y#ref-CR37" id="ref-link-section-d17e381">2005</a>), Scalable-SPIDAR is transparent, unbulky and suitable for large-scale haptic immersion. However, it has certain limitations in interacting with virtual environments, especially manipulation difficulties. In fact, the Scalable-SPIDAR is a single-point interface and, thus, is not well suited to perform specific two-handed tasks such as the bimanual exploration of large virtual environments and grasping of virtual objects. The device uses tensioned string techniques to track and measure the motion of the user’s hands as well as to display force feedback sensations. Nevertheless, due to various limitations, Scalable-SPIDAR is subject to tracking inaccuracies and, thus, cannot always provide faithful data rendering. The question, then, is whether any discrepancy caused by tracking inaccuracies matters to the user’s experience or performance in virtual environments. Several studies have shown that large tracking inaccuracies lead to inconsistency between physical and virtual working environments which may contribute to detracting from the sense of presence, causing sickness or degrading the task performance (Meyer et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Meyer K, Applewhite HL, Biocca FA (1992) A survey of position trackers. Presence Teleoper Virtual Environ 1(2):173–200" href="/article/10.1007/s10055-016-0303-y#ref-CR41" id="ref-link-section-d17e384">1992</a>; Welch and Foxlin <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Welch G, Foxlin E (2002) Motion tracking: no silver bullet, but a respectable arsenal. Comput Graph Appl IEEE 22(6):24–38" href="/article/10.1007/s10055-016-0303-y#ref-CR52" id="ref-link-section-d17e387">2002</a>; Jayaram and Repp <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Jayaram U, Repp R (2002) Integrated real-time calibration of electromagnetic tracking of user motions for engineering applications in virtual environments. J Mech Des 124:623" href="/article/10.1007/s10055-016-0303-y#ref-CR27" id="ref-link-section-d17e391">2002</a>). Therefore, it is important to improve the tracking accuracy of the Scalable-SPIDAR haptic device. To this end, accurate calibration is indispensable. In this work, we focus on the development of a comprehensive calibration procedure for improving the accuracy of the Scalable-SPIDAR haptic device. As a design goal, the procedure needs to be robust and flexible enough to be applied to other similar systems.</p><p>In the next section, we provide an overview of related works regarding methods used to improve tracking accuracy in virtual and augmented reality environments. Thereafter, we introduce our visual-haptic VR setup, followed by a brief description of its main components. In Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0303-y#Sec4">4</a>, we detail the developed calibration procedure. We present some of the key aspects concerning the characterization and calibration of the Scalable-SPIDAR haptic device. Finally, we conclude by evaluating the performance of the proposed calibration techniques.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Related work</h2><div class="c-article-section__content" id="Sec2-content"><p>Before launching in a further discussion, it is important to grasp what is meant by the term “accuracy.” In fact, the accuracy of a measurement system refers to the degree of closeness of measurements of a quantity to its actual value (ISO 5725-1 <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="ISO 5725-1 (1994) Accuracy (trueness and precision) of measurement methods and results—part 1: general principles and definitions. International Organization for Standardization, Geneva" href="/article/10.1007/s10055-016-0303-y#ref-CR23" id="ref-link-section-d17e408">1994</a>). Similarly, tracking accuracy refers to the closeness of position tracker measurements to the actual position value. Unfortunately, tracking devices are often inaccurate and imperfect. Distortions are introduced into the tracking data so that the data reported by the tracker only loosely correspond to the actual data. If this distortion is repeatable, it can be mathematically characterized and then the actual data can be inferred from the distorted data. This will be called calibrating the tracking device.</p><p>In the following section, we provide an overview of related activities regarding methods used to calibrate tracking devices in virtual and augmented reality environments. The majority of previous works have focused on calibration issues for electromagnetic trackers. It has been reported that these trackers have an inherent accuracy problem due to the dependence of their reports on the local electromagnetic field that can be easily distorted by conductive or ferrous materials. To overcome this issue, various calibration methods have been proposed. Kindratenko (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Kindratenko V (2000) A survey of electromagnetic position tracker calibration techniques. Virtual Real 5(3):169–182" href="/article/10.1007/s10055-016-0303-y#ref-CR33" id="ref-link-section-d17e414">2000</a>) conducted a detailed survey of these methods. In each of the reviewed methods, measurement data were collected to determine the relationship between actual and distorted data. Several error correction methods were, then, applied so that distorted measurement data can be effectively compensated.</p><p>Ghazisaedy et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Ghazisaedy M et al (1995) Ultrasonic calibration of a magnetic tracker in a virtual reality space. In: Proceedings virtual reality annual international symposium ’95, pp 179–188" href="/article/10.1007/s10055-016-0303-y#ref-CR14" id="ref-link-section-d17e420">1995</a>) used a local correction technique based on trilinear interpolation to correct errors in the position reported by the tracker. Calibration data were collected using an ultrasonic tracking system on a regular grid, and a lookup table of corrections was built. The technique compensated large errors in position readings but did not significantly improve on small errors. Similarly, Livingston and State (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Livingston MA, State A (1997) Magnetic tracker calibration for improved augmented reality registration. Presence Teleoperators Virtual Environ 6(5):532–546" href="/article/10.1007/s10055-016-0303-y#ref-CR39" id="ref-link-section-d17e423">1997</a>) applied trilinear interpolation to compensate for errors in the reported position and a sequence of spherical linear interpolations between quaternions representing the reported orientation to correct errors in orientation. A lookup table was built by collecting a very large irregular distributed set of samples and re-sampling it into a rectilinear grid to form calibration cells. The authors determined that position accuracy could be improved by roughly 80% although they had difficulty with orientation correction. They corrected errors in the orientation using averaging over the error quaternions of lookup table points surrounding the point to be calibrated.</p><p>Bryson (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Bryson S (1992) Measurement and calibration of static distortion of position data from 3D trackers. In: Proceedings of SPIE conference. Stereoscopic displays and applications III, pp 244–255" href="/article/10.1007/s10055-016-0303-y#ref-CR7" id="ref-link-section-d17e429">1992</a>) developed a weighted lookup table technique with two different weight functions (one with linear interpolation and one with a Gaussian-weighted lookup table). He measured errors in the tracked position on a rectilinear grid defined by a pegboard and found that the Gaussian-weighted lookup table performed best. Kindratenko and Bennett (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Kindratenko V, Bennett A (2000) Evaluation of rotation correction techniques for electromagnetic position tracking systems. In: Mulder J, van Liere R (eds) Virtual environments 2000 SE—3. Eurographics. Springer, Vienna, pp 13–22" href="/article/10.1007/s10055-016-0303-y#ref-CR34" id="ref-link-section-d17e432">2000</a>) extended this technique to calibrate both the position and orientation reports. The authors built a lookup table by placing the tracker at regularly spaced locations and with a known constant orientation and then recording both the true position/orientation and that reported by the tracker. They conclude that weighted lookup table technique could also significantly reduce the errors in the reported orientation. Ellis et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Ellis SR et al (1999) Sensor spatial distortion, visual latency, and update rate effects\non 3D tracking in virtual environments. In: Proceedings IEEE virtual reality (Cat no 99CB36316), pp 218–221" href="/article/10.1007/s10055-016-0303-y#ref-CR10" id="ref-link-section-d17e435">1999</a>) proposed to correct errors in the reported position by using an adaptation of an algorithm developed by Kenwright and Lane (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Kenwright DN, Lane DA (1996) Interactive time-dependent particle tracing using tetrahedral decomposition. IEEE Trans Vis Comput Graph 2(2):120–129" href="/article/10.1007/s10055-016-0303-y#ref-CR30" id="ref-link-section-d17e438">1996</a>). The proposed technique used a local interpolation based on a simple form of shape function derived for tetrahedrons. Similarly, Briggs (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Briggs W (1999) Magnetic calibration by tetrahedral interpolation. In: Proceedings of NIST-ASME industrial virtual reality symposium, Chicago, pp 27–32" href="/article/10.1007/s10055-016-0303-y#ref-CR6" id="ref-link-section-d17e441">1999</a>) used a weighted lookup table technique to correct position errors. This technique is similar to the one presented by Livingston and State (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Livingston MA, State A (1997) Magnetic tracker calibration for improved augmented reality registration. Presence Teleoperators Virtual Environ 6(5):532–546" href="/article/10.1007/s10055-016-0303-y#ref-CR39" id="ref-link-section-d17e445">1997</a>); however, it differs in the way the lookup tables are re-sampled from data taken on an irregular grid. In addition, Jayaram and Repp (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Jayaram U, Repp R (2002) Integrated real-time calibration of electromagnetic tracking of user motions for engineering applications in virtual environments. J Mech Des 124:623" href="/article/10.1007/s10055-016-0303-y#ref-CR27" id="ref-link-section-d17e448">2002</a>) used various inverse weighting interpolation methods to obtain correct values from the distorted electromagnetic tracker readings. The authors mentioned that the lookup table-based correction method dramatically improves tracking system accuracy but that the improvement varied based on the applied interpolation method.</p><p>Another way of calibrating errors for electromagnetic tracking systems is to use the high-order polynomial fit method. In fact, Bryson (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Bryson S (1992) Measurement and calibration of static distortion of position data from 3D trackers. In: Proceedings of SPIE conference. Stereoscopic displays and applications III, pp 244–255" href="/article/10.1007/s10055-016-0303-y#ref-CR7" id="ref-link-section-d17e455">1992</a>) computed polynomials of the order 1 through 8 for each reported position from the calibration table via the least-square fit method. He found via the correlation analysis that the fourth-order polynomials were the most suited. Kindratenko (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Kindratenko V (1999) Calibration of electromagnetic tracking devices. Virtual Real 4:139–150" href="/article/10.1007/s10055-016-0303-y#ref-CR32" id="ref-link-section-d17e458">1999</a>) and Ikits et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Ikits M et al (2001) An improved calibration framework for electromagnetic tracking devices. Proc IEEE Virtual Real 2001:63–70" href="/article/10.1007/s10055-016-0303-y#ref-CR24" id="ref-link-section-d17e461">2001</a>) extended this technique to compensate the errors in the reported orientation. Kindratenko (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Kindratenko V (1999) Calibration of electromagnetic tracking devices. Virtual Real 4:139–150" href="/article/10.1007/s10055-016-0303-y#ref-CR32" id="ref-link-section-d17e464">1999</a>) used Euler angles, while Ikits et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Ikits M et al (2001) An improved calibration framework for electromagnetic tracking devices. Proc IEEE Virtual Real 2001:63–70" href="/article/10.1007/s10055-016-0303-y#ref-CR24" id="ref-link-section-d17e467">2001</a>) used quaternionial representation to compute corrected orientations. Furthermore, Zachmann (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Zachmann G (1997) Distortion correction of magnetic fields for position tracking. In: Proceedings computer graphics international, pp 213–220, 251" href="/article/10.1007/s10055-016-0303-y#ref-CR55" id="ref-link-section-d17e471">1997</a>) introduced a scattered data interpolation using Hardy’s Multi-Quadric method with LU matrix decomposition to solve the interpolation equation. The motivation for using this method is that Hardy’s Multi-Quadric polynomials tend not to oscillate as polynomial interpolations like Newton or Lagrange interpolation, since the degree of interpolating function does not depend of the number of samples. So far, the majority of reported calibration methods are based on either local interpolation or polynomial function methods. Local interpolation method requires a lookup table of the closest points or the enclosing cell, which needs some additional data, structures if the lookup is to be faithful and fast. Polynomial calibration works very well when distortion is smoothly spread through the tracking workspace but is not that effective when an abrupt, localized nonlinearity occurs in the mapped space. Hence, an alternative error correction approach with a multilayer feed-forward neural network was proposed by Kindratenko and Sherman (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Kindratenko VV, Sherman WR (2005) Neural network-based calibration of electromagnetic tracking systems. Virtual Real. 9(1):70–78" href="/article/10.1007/s10055-016-0303-y#ref-CR35" id="ref-link-section-d17e474">2005</a>). The calibration procedure in this method is both to obtain a calibration table and to train the network until a certain accuracy level is reached. Recently, Moreira et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Moreira AHJ et al (2014) Electromagnetic tracker feasibility in the design of a dental superstructure for edentulous patients. In: IEEE MeMeA 2014—IEEE international symposium on medical measurements and applications, Proceedings, pp 1–6" href="/article/10.1007/s10055-016-0303-y#ref-CR42" id="ref-link-section-d17e477">2014</a>) tested three calibration methods (linear interpolation, higher-order polynomial and Hardy’s Multi-Quadric) in order to implement a suitable strategy for the evaluation of new dental impression techniques.</p><p>With regard to mechanical tracking system, only some attempts have been made to increase the accuracy of tracking. Most of these attempts examined the positioning accuracy and the calibration of the Phantom haptic device. A planar grid calibration was suggested by Reinig et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Reinig K, Tracy R, Gilmore H, Mahalik T (1997) Some calibration information for a Phantom 1.5 a. In: Proceedings of the second PHANToM user’s group workshop. Dedham, Massachusetts, pp 70–73" href="/article/10.1007/s10055-016-0303-y#ref-CR45" id="ref-link-section-d17e483">1997</a>) to correct the haptic position and then extend this correction to the entire haptic workspace by extrapolation. Unfortunately, the results show that the position errors increase as the tip moves away from the grid. Ikits et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Ikits M, Hansen CD, Johnson CR (2003) A comprehensive calibration and registration procedure for the visual haptic workbench. In: Proceedings of the workshop on virtual environments 2003. EGVE’03. ACM, New York, pp 247–254" href="/article/10.1007/s10055-016-0303-y#ref-CR25" id="ref-link-section-d17e486">2003</a>) proposed an enhancement of the grid approach by placing two perpendicular planar grids in the haptic volume. More recently, Knoerlein and Harders (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Knoerlein B, Harders M (2011) Comparison of tracker-based to tracker-less haptic device calibration. In: World haptics conference (WHC), 2011 IEEE, pp 119–124" href="/article/10.1007/s10055-016-0303-y#ref-CR36" id="ref-link-section-d17e489">2011</a>) presented a comparison of tracker based on tracker-less haptic device calibration. They compare previously developed technique by Harders et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Harders M et al (2009) Calibration, registration, and synchronization for high precision augmented reality haptics. IEEE Trans Vis Comput Graph 15(1):138–149" href="/article/10.1007/s10055-016-0303-y#ref-CR17" id="ref-link-section-d17e492">2009</a>) using external optical tracking system to a new approach not relying on external metrology. Prior approaches focusing on the Phantom haptic device calibration are based on model methods. However, important to these methods is the development of an accurate kinematic model. On the other hand, only few attempts have been made to explore the potential of model-less calibration method in haptic devices. Model-less method does not need any kinematic model. Boudoin et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Boudoin P et al (2010) SPIDAR calibration based on neural networks versus optical tracking. BT—artificial neural networks and intelligent information processing. In: Proceedings of the 6th international workshop on artificial neural networks and intelligent information processing, pp 87–98" href="/article/10.1007/s10055-016-0303-y#ref-CR4" id="ref-link-section-d17e495">2010</a>) developed a neural network-based method to improve the position accuracy of the Scalable-SPIDAR haptic device. They used a two-layered feed-forward neural network to correct nonlinear position errors.</p></div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">System overview</h2><div class="c-article-section__content" id="Sec3-content"><p>In order to immerse the user into the virtual environment, changes in the user’s location have to be incorporated into the system. We used the infrared (IR) optical 6-DoF tracking system “ARTrack1/Dtrack” from Advanced Realtime Tracking GmbH to get marker pose estimates. In fact, the “ARTrack1/Dtrack” system is based on two IR intelligent cameras that are able to recognize retro-reflective markers and compute the marker pose in image coordinates (2D) with high precision. These data are transferred via Ethernet to the central Dtrack PC. The PC with the “Dtrack” software samples the 2D data coming from the two IR cameras and computes the 6-DoF pose targets, which are located in the measurement volume. Unfortunately, IR optical trackers are prone to occlusions (Welch and Foxlin <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Welch G, Foxlin E (2002) Motion tracking: no silver bullet, but a respectable arsenal. Comput Graph Appl IEEE 22(6):24–38" href="/article/10.1007/s10055-016-0303-y#ref-CR52" id="ref-link-section-d17e506">2002</a>), which leads to significant loss of tracking.</p><p>To overcome the problem of tracking loss, we combine the IR optical tracker with a haptic-based tracking approach. In fact, a string-based haptic system called Scalable-SPIDAR has been integrated into our setup in order to provide stable tracking and to enable haptic interaction with virtual objects in the virtual environment. As well, haptic sensations are known to impart users with realistic feeling about physical interactions. Scalable-SPIDAR is composed of a cubic frame, which encloses a cave-like space, where the user can move around to perform large-scale movements. Within this space, various aspects of haptic feedback sensations associated mainly with weight, contact and inertia can be displayed to the user’s hands by means of tensioned strings. The front side of the device holds a large screen where a computer-generated virtual world is displayed. Providing such combination of haptic and visual feedback cues may strongly improve interaction with virtual objects in manner similar to those in real world. This combination is essential to let the user’s eyes and hands work in concert to discover and manipulate objects populating the virtual environment (Bouguila et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Bouguila L, Ishii M, Sato M (2000) Effect of coupling haptics and stereopsis on depth perception in virtual environment. In: Proceedings of the 1st workshop on haptic human computer interaction, 31st August–1st Sept 2000. pp 54–62" href="/article/10.1007/s10055-016-0303-y#ref-CR5" id="ref-link-section-d17e512">2000</a>). The device uses tensioned string techniques to track hands position as well as to provide force feedback sensation. The technique consists in applying appropriate tensions to the eight strings supporting each the end-effector worn by the user Kim et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Kim S et al (2002) Tension based 7-DOF force feedback device: SPIDAR-G. In: Proceedings, IEEE virtual reality. pp 283–284" href="/article/10.1007/s10055-016-0303-y#ref-CR31" id="ref-link-section-d17e515">2002</a>). In order to control the tension and the length of each string, one extremity is attached to the end-effector and the other extremity wound around a pulley, which is driven by a DC motor. An encoder is fixed to the DC motor to detect the string length variation. The set of DC motor, pulley and encoder controlling each string are mounted in the corners of the frame. A general overview of the system’s components is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig1">1</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig1_HTML.jpg" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Components of the visual-haptic VR setup</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     </div></div></section><section aria-labelledby="Sec4"><div class="c-article-section" id="Sec4-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec4">Calibration procedure</h2><div class="c-article-section__content" id="Sec4-content"><p>The purpose of our current research is the development of a simple, yet, efficient calibration procedure for improving the accuracy of the Scalable-SPIDAR haptic device. This procedure is necessary to maintain consistency between physical and virtual working environments that is crucial to fine-motor tasks in areas including assembly-planning tools or rapid prototyping applications. Therefore, we developed a hybrid tracking approach using the IR optical tracker available within our setup. Accuracy and robustness of the calibration procedure are greatly influenced by the quality of the optical tracker’s calibration. To this end, two types of calibration have to be performed with the software Dtrack before tracking is started: room calibration and body calibration. During room calibration, the axes and the origin of camera coordinate system are defined. For this procedure, a “wand kit” is put into the field of the IR cameras. Following the process described in the ARTrack1/Dtrack manual (Advanced Realtime Tracking GmbH <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Advanced Realtime Tracking GmbH (2003) ARTtrack1 &amp; DTrack—Manual Version 1.18" href="/article/10.1007/s10055-016-0303-y#ref-CR1" id="ref-link-section-d17e547">2003</a>), a valid room calibration can be performed. As shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig2">2</a>, the calibration angle is an L-shaped tool with four markers that defines the origin and the axes of the coordinate system:</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Optical tracking system calibration (room calibration)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div> 
                        <ul class="u-list-style-bullet">
                  <li>
                    <p>The center of the marker lying in the crossing point of the two sides of the angle defines the origin of the coordinate system.</p>
                  </li>
                  <li>
                    <p>The long side of the calibration angle defines the +<i>X</i> direction</p>
                  </li>
                  <li>
                    <p>The short side of the calibration angle defines the +<i>Y</i> direction.</p>
                  </li>
                  <li>
                    <p>The <i>Z</i>-axis corresponds to the right-handed coordinate system.</p>
                  </li>
                </ul>
                     <p>During body calibration, Dtrack fixes a local coordinate system (body coordinate system) for each rigid body. Therefore, the position and orientation of a target are expressed by a transformation <span class="mathjax-tex">\((\vec{x},R)\)</span> that transforms a vector <span class="mathjax-tex">\(\vec{x}\)</span> from body coordinate system to room coordinate system</p><div id="Equ1" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\vec{x}_{\text{room}} = R \times \vec{x}_{\text{body}} + \vec{s}$$</span></div><div class="c-article-equation__number">
                    (1)
                </div></div><p>where the coordinate <span class="mathjax-tex">\(\vec{x}\)</span> gives the position of the origin of the body coordinate system, measured in room coordinate, and R is the 3 × 3-rotation matrix describing the rotational part of the transformation. The next step focuses on the calibration of the haptic interface. Scalable-SPIDAR is a human-scale haptic device, based on tensioned string techniques, to display force feedback sensation in a large space, while allowing smooth movement and keeping the space transparent. However, it provides only a low tracking accuracy. This problem is mainly caused by two reasons. First, Scalable-SPIDAR has a built-in initialization procedure that is based on manually moving the end-effector to home position, then calling some particular API functions (Group <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Group S (2005) SPIDAR-G/AHS1.0A user’s manual Ver. 2.0., pp 1–44" href="/article/10.1007/s10055-016-0303-y#ref-CR15" id="ref-link-section-d17e763">2005</a>). Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig3">3</a> shows the discrepancy between the position provided by the built-in initialization procedure and the true initialization position that has to be reached. As revealed by picture 3, the built-in procedure is unable to accomplish and repeat the initialization of the Scalable-SPIDAR in a precise manner. Therefore, a custom initialization procedure that allows the user to accurately place the end-effector to a fixed known location within the workspace of the haptic device is needed.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig3_HTML.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig3_HTML.jpg" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Built-in initialization procedure of Scalable-SPIDAR</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The position and force computations within the High Definition Haptic Controller (HDHC) firmware (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig4">4</a>) are based on the nominal kinematic model of the Scalable-SPIDAR haptic device, which is different from its actual model. In fact, the actual geometry of the Scalable-SPIDAR does not quite meet the design specifications required to accurately track the user’s hands within the workspace. This deviation between the nominal and real geometry of the haptic device causes errors in the string lengths, which in turn leads to positional errors of the end-effector and therefore affects its accuracy.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Illustration of Scalable-SPIDAR (motors and stings, HDHC and computer)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The calibration process can now be carried out in two stages. We first determine a solution for the initialization problem. To this end, we propose a new procedure for initializing the haptic device, which will be outlined in the next section. Thereafter, we apply a calibration method to calibrate position readings from the haptic device within a defined working volume.</p><h3 class="c-article__sub-heading" id="Sec5">Multimodal initialization procedure</h3><p>The built-in procedure conflicts with our need to a highly accurate initialization. The more accurate this initialization is, the higher tracking accuracy becomes. Therefore, we propose a new semi-automatic procedure for the haptic device initialization. To accomplish this initialization with a high level of accuracy, we use the IR optical tracking system. The underlying idea is to measure the actual initialization position (colored in green in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig3">3</a>) with respect to the room coordinate system. To this end, an IR marker is rigidly attached to the end of the end-effector. Here, the center of the cubic frame is taken to be the true initialization point. The vector <span class="mathjax-tex">\(\vec{v}\)</span>, shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig5">5</a>, gives the distance of the IR marker attached to the end-effector relative to actual initialization point as well as the required direction to converge to it. In order to help the user to accomplish and repeat initialization in a precise manner, multimodal cues are needed. This can be derived by first converting spatial information into multimodal parameters. Let h be a function that takes distance from the origin as input and returns an index expressing the closeness of the end-effector to the origin:</p><div id="Equ2" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} h(d) &amp; = \left\{ {\begin{array}{*{20}l} {\frac{{d_{\hbox{min} } - d}}{{d_{\hbox{min} } }}} \hfill &amp; {{\text{if}}\quad d \le d_{\hbox{min} } } \hfill \\ 0 \hfill &amp; {{\text{if}}\quad d &gt; d_{\hbox{min} } } \hfill \\ \end{array} } \right. \\ d &amp; = \left\| {\vec{v}} \right\|\quad {\text{with}}\quad \vec{v} = \left[ {v_{x} ,v_{y} ,v_{z} } \right] \\ \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (2)
                </div></div><p>where <i>d</i> is the distance between the end-effector and the origin with respect to the room coordinate system and <i>d</i>
                           <sub>min</sub> is the minimal distance from which h starts fluctuating. In our case, <i>d</i> and <i>d</i>
                           <sub>min</sub> are expressed in millimeter.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Proposed initialization procedure</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>In the following subsection, multimodal cues used during the initialization process are presented.</p><p>Audio cue: A discrete audio cue that increases in frequency when approaching the initialization point is used. Therefore, as the end-effector approaches the initialization point, the frequency of the beeping sound increases. In our case, beep frequency is linked to the distance d according to:</p><div id="Equ3" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$f(d) = 1000 \times h(d)\quad {\text{if}}\quad \, d \le d_{\hbox{min} }$$</span></div><div class="c-article-equation__number">
                    (3)
                </div></div>
                        <p>Haptic cue: First, the direction vector <span class="mathjax-tex">\(\vec{v}\)</span> is transformed into a force vector <span class="mathjax-tex">\(\overrightarrow {\text{F}}\)</span> according to:</p><div id="Equ4" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\overrightarrow {F} = \overrightarrow {\Delta } \times s(d) \times F_{\text{Max}}$$</span></div><div class="c-article-equation__number">
                    (4)
                </div></div><p>where <span class="mathjax-tex">\(s(x)\)</span> is a sigmoid function that allows applying a progressive force to the end-effector given by:</p><div id="Equ5" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$s(x) = e^{{ - 10((1 - h(d)) - 0.5)^{2} }} {\text{ if }}x \in [ - 0.5,0.5]$$</span></div><div class="c-article-equation__number">
                    (5)
                </div></div>
                        <p>
                           <span class="mathjax-tex">\(\Delta\)</span> is the unit vector given that points in the direction of the origin <span class="mathjax-tex">\(\overrightarrow {\Delta } = \frac{ 1}{{\| {\overrightarrow {V} } \|}} \cdot \overrightarrow {V}\)</span> and <span class="mathjax-tex">\(F_{\text{Max}}\)</span> is the maximum force that can be exerted on the end-effector. This force vector is then exerted on the end-effector as a way to provide haptic guidance cue to the user to reach the origin.</p><p>The initialization process can now be carried out in two steps. First, the built-in procedure places the end-effector in a limited region of the workspace close to the origin. However, as depicted in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig3">3</a>, this procedure results in a discrepancy of about a few centimeters. Therefore, it is called “unrefined initialization region.” Due to the low sensitivity of the haptic device in small distance, the end-effector cannot be moved using force feedback capabilities. In order to improve initialization accuracy, one more step is needed. To this end, we perform the multimodal approach described above. Based on the high accuracy of the external tracker and multimodal cues, the user’s hand, holding the end-effector, is guided in a precise and repeated way to the origin. Consequently, a new initialization area that we name “precise initialization region” is obtained.</p><p>With the proposed initialization procedure described in the previous section, we are able to estimate the relationship between the haptic and the room coordinate system. Let <span class="mathjax-tex">\(p_{i}^{H}\)</span> and <span class="mathjax-tex">\(p_{i}^{R}\)</span> represent the position of the end-effector, respectively, in the haptic and room coordinate systems. The transformation between these points is then given by: <span class="mathjax-tex">\(p_{i}^{R} = \, p_{i}^{H} + \, t\)</span> where t denotes the translation vector from origin of the room coordinate system to the haptic workspace origin:</p><div id="Equ6" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$t = \left( \begin{array}{c} 0 \\ 0 \\ 1500 \\ \end{array} \right)$$</span></div><div class="c-article-equation__number">
                    (6)
                </div></div>
                        <h3 class="c-article__sub-heading" id="Sec6">Shortcomings of the mechanical design</h3><p>Unfortunately, additional errors in the reported end-effector position remain. The major problem is the difference between the nominal and real geometry of the Scalable-SPIDAR. This difference arises mainly from shortcomings in the mechanical structure design (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig6">6</a>). In what follows, we investigate some of these shortcomings.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig6_HTML.jpg?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig6_HTML.jpg" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Basic structure of Scalable-SPIDAR’s motor block</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec7">Encoders are secured to the motor shaft</h4><p>Scalable-SPIDAR is a haptic device supported by strings in parallel that are actuated by tensioning motors. Each string is reeled on a pulley attached to a rotary encoder that is secured to the motor shaft. This configuration is identified as a source of problem. In fact, before running Scalable-SPIDAR, the user must specify the pulley radius in order to calculate changes in the length of strings. However, this radius is no longer constant, depending on the amount of string wound. Hence, this radius would change, causing errors in length measurement—lengths are measured from the angular position of the pulley and its radius, which leads to errors in the reported end-effector position.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec8">Pulley size is very small</h4><p>The small radius of the used pulley further exacerbates errors in length measurement. It turned out that winding radius is not negligible if compared to the pulley radius especially when large amounts of string are reeled on pulley. As a consequence, the pulley radius will vary widely as the string is being wound resulting in a total discrepancy between the measured and the true length of string.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec9">Badly designed string guide</h4><p>In the actual realization, string passes through a hole located in a plate and wraps around a pulley. This method conflicts with our need to a reliable winding control method. First, it increases system friction, damages the string and impedes it to wind around pulley on an ideal way. Second, it does not prevent string from sliding out of the grooves on the pulley. Indeed, if the pulley fails to wind the string fast enough, excessive string waiting to enter to the pulley will bend and forms a curve with a curvature large enough to slide out of the grooves on the pulley. Hence, the reeled string does not reflect the exact distance between the attaching point and the end-effector. Thus, the position measurement is no longer precise.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec10">Large SPIDAR’s dimensions</h4><p>The length of string that can be wound greatly affects the workspace volume. The longer the wound length is, the larger the workspace volume is. However, due to design issues described above, length measurement errors will increase as the workspace volume increases. Thereby, the large dimensions of the haptic device exacerbate length errors.</p><p>It can easily be seen from the investigation above that shortcomings in the mechanical structure design lead to a significant loss in tracking. To address this problem, calibration method is used instead of changing the mechanical structure. The calibration problem can be tackled using model-based or model-less method. Since the HDHC software of the Scalable-SPIDAR haptic device comes as a black box, it conceals the inner kinematic model used to compute end-effector pose and does not allow full functionality or control of the device. Moreover, some of the inaccuracy sources are difficult to model explicitly. Therefore, we have to carry out a model-less haptic device calibration. In fact, the model-less method does not need any kinematic model or identification steps. Furthermore, the correction of the tracking position errors is performed using a black box approach without the need for modeling the different errors sources affecting the Scalable-SPIDAR accuracy.</p><p>We claim that it is possible to extend the model-less approach to other tracking systems and especially to haptic systems like cable-driven systems. In fact, multi-DOF haptic systems have often complex-to-model geometries. The use of model-based approach presents two major drawbacks. First, a large number of parameters are needed to cover all the possible sources of inaccuracy. This implies that a dense system has to be solved during the identification phase. Second, some of the errors sources may be very difficult to model explicitly which results in a lack of model completeness.</p><h3 class="c-article__sub-heading" id="Sec11">Calibration method</h3><p>The calibration framework, which is essential for haptic devices to avoid motion sickness and intersensory conflicts, involves several steps: characterizing the Scalable-SPIDAR and providing methods for estimating the true end-effector position. This requires a reliable protocol for gathering large quantities of data in the working volume.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec12">Data collection protocol</h4><p>In order to characterize the Scalable-SPIDAR haptic device, one must collect tuples that consist of the measured data and the “truth values”—what a secondary accurate tracker should report. The accuracy of these actual values is crucial for the calibration method, since the goal of the calibration method is to map measured data into actual data. Therefore, we use the IR optical tracking device as a reference for the Scalable-SPIDAR. This is a legitimate choice because of its high accuracy. An overall view of the new procedure’s components is depicted in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig7">7</a>. It can be seen that the custom initialization procedure is efficient and able to place the end-effector in the center of the cubic frame. Moreover, to provide for well-distributed data that can be collected, a volumetric calibration protocol is developed. The underlying idea is to develop a quasi-static data acquisition method where acquisition is guided by a calibration fixture. To this end, the screen of our visual-haptic setup is first filled by a virtual cubic lattice divided into a sequence of small cubic cells. Each cell corresponds to a subspace of the Scalable-SPIDAR workspace.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig7_HTML.jpg?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig7_HTML.jpg" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>New procedure calibration</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>The set of small cubic cells covers the entire Scalable-SPIDAR workspace. On the other hand, a virtual end-effector (the red sphere in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig8">8</a>) shows the position of the marker attached to the end-effector with respect to the room coordinate system. The target cubic cell is highlighted by changing its color to pink. A user holds the end-effector straight and moves it until the displayed end-effector ranges inside the colored cubic cell. Then, the program records the position given by the IR optical tracking system and the haptic device. Once these positions are recorded, the cubic cell vanishes ensuring that only one measurement was associated with this subspace. This procedure continues until all the small cubic cells inside the virtual cubic lattice are sampled. The sample points were collected starting at the front of the volume, processing through the same <i>x</i>–<i>z</i> plane and then moving forward to the next plane. In practice, a sub-volume of 1 m<sup>3</sup> is considered. This sub-volume is divided into 2197 small cubic cells. Hence, 2197-point measurements inside the cubic lattice are sampled.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig8_HTML.jpg?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig8_HTML.jpg" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Display in the Scalable-SPIDAR of boxes to collect. The virtual end-effector (the <i>red sphere</i>) is moved inside colored box (<i>colored pink</i>) to collect point (color figure online)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>The developed protocol seems suitable for collecting a large number of data points with a predetermined data distribution using a quasi-static collection mode. Besides, it requires minimal user interaction. Indeed, to simplify human performance requirements in the data collection phase, we record data as soon the virtual end-effector collides with the cubic cell. Another important advantage of this protocol is that it allows the collection of data over a flexible volume that can be changed by an expert. However, this protocol is time consuming, especially when the number of samples increases significantly. In fact, the data collection takes about 80 min.</p><p>Seeing the characterization data obtained using the previous collection protocol, the absolute position errors for each of the 2197 points were calculated. The absolute position error is measured as the distance between the tracked position by the Scalable-SPIDAR haptic device and the corresponding reference position as reported by the IR optical tracking system.</p><div id="Equ7" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$${\text{err}}_{\text{pos}} = \sqrt {(x_{\text{SPIDAR}} - x_{\text{OTS}} )^{ 2} + (y_{\text{SPIDAR}} - y_{\text{OTS}} )^{ 2} + (z_{\text{SPIDAR}} - z_{\text{OTS}} )^{ 2} }$$</span></div><div class="c-article-equation__number">
                    (7)
                </div></div><p>where the <span class="mathjax-tex">\((x_{\text{SPIDAR}} ,\,\,y_{\text{SPIDAR}} ,\,\,z_{\text{SPIDAR}} )\)</span> position is reported by the Scalable-SPIDAR and <span class="mathjax-tex">\((x_{\text{OTS}} ,\,\,y_{\text{OTS}} ,\,\,z_{\text{OTS}} )\)</span> is the reference position.</p><p>Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig9">9</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig10">10</a> illustrate position errors in two formats of varying details. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig9">9</a> shows the absolute position errors spatially at each reference position <span class="mathjax-tex">\((x_{\text{OTS}} ,\;y_{\text{OTS}} ,\;z_{\text{OTS}} )\)</span>, with the error magnitude proportional to the corresponding colors. The plot clearly shows that errors are more pronounced when the end-effector is manipulated away from the center of the workspace toward the edge of the cubic frame.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig9_HTML.gif?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig9_HTML.gif" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Spatially represented absolute position errors</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                              <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig10_HTML.gif?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig10_HTML.gif" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Absolute position errors represented in sequence</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig10">10</a>, absolute position errors are plotted as a function of the sequence in which they were collected from the front of the volume to the back. Plotting position errors as a 1D plot results in the loss of a substantial amount of spatial information, but still shows the same trend, and from the plot’s periodicity we can infer that errors increase at the volume edges.</p><p>The clusters of large errors at the upper left and right corner of the plot, also called outliers, will be investigated in the next section.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec13">Machine learning techniques for calibration</h4><p>The Scalable-SPIDAR haptic device is a multi-DOF device with complex-to-model geometries. Moreover, some of the inaccuracy sources are difficult to model explicitly, which results in lack of model completeness and therefore in a loss of accuracy. Regression techniques provide attractive solutions for improving the tracking accuracy of the Scalable-SPIDAR. Indeed, the input–output relationship is approximated using a black box approach without the need for modeling explicitly the different errors sources affecting the device accuracy. To this end, we look for a regression function f that provides mapping from measured to actual data. The measured data are directly read from the haptic device being calibrated. The actual values are reported by the IR optical tracking system. Although the mapping can be performed using conventional nonlinear regression, the use of machine learning techniques such as neural networks (NN) and support vector regression (SVR) is preferred because they can approximate any complex regression (Pao <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1989" title="Pao Y-H (1989) Adaptive pattern recognition and neural networks. Addison-Wesley Longman Publishing Co., Inc, Boston" href="/article/10.1007/s10055-016-0303-y#ref-CR43" id="ref-link-section-d17e2310">1989</a>).</p><p>The function-fitting paradigm from a machine learning point of view supposes that errors are additive and that the model <span class="mathjax-tex">\(Y = f(X) + \varepsilon\)</span> is a reasonable assumption (Hastie et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Hastie TJ, Tibshirani RJ, Friedman JH (2009) The elements of statistical learning: data mining, inference, and prediction. Springer, New York" href="/article/10.1007/s10055-016-0303-y#ref-CR18" id="ref-link-section-d17e2356">2009</a>). Supervised learning attempts to learn f based on training set of <i>N</i> input–output pairs <span class="mathjax-tex">\((x_{i} ,y_{i} ),\quad i = 1, \ldots N\)</span>. Here, the symbol <i>X</i> denotes an input variable and <i>Y</i> denotes a quantitative output. Observed values are written in lowercase; hence, the <i>i</i>th observed value of <i>X</i> is written as <span class="mathjax-tex">\(x_{i}\)</span> (where <span class="mathjax-tex">\(x_{i}\)</span> is a scalar or vector). The input value <span class="mathjax-tex">\(x_{i}\)</span> is fed into an artificial system, known as a learning algorithm which also produces outputs <span class="mathjax-tex">\(\widehat{f}(x_{i} )\)</span> in response to the inputs. The learning algorithm has the property to modify its input–output relationship <span class="mathjax-tex">\(\widehat{f}\)</span> in response to the difference between the original and generated output <span class="mathjax-tex">\(y_{i} - \widehat{f}(x_{i} )\)</span>. This process is known as learning by examples. Here, the data pairs <span class="mathjax-tex">\((x_{i} ,y_{i} ),\quad i = 1, \ldots N\)</span> correspond, respectively, to tracked position and true position reported by the IR optical tracking system.</p><h5 class="c-article__sub-heading" id="Sec14">Neural networks</h5><p>Our goal is to design a neural network capable of estimating the actual end-effector position based on its tracked position. It has been shown that a feed-forward network with hidden layers is a universal approximator. This means that a multilayer feed-forward network can approximate any continuous nonlinear function over a compact subset of <span class="mathjax-tex">\({\mathbb{R}}^{n}\)</span> to an arbitrary degree of accuracy (Hornik et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1989" title="Hornik K, Stinchcombe M, White H (1989) Multilayer feedforward networks are universal approximators. Neural Netw 2(5):359–366" href="/article/10.1007/s10055-016-0303-y#ref-CR21" id="ref-link-section-d17e2725">1989</a>). This is achieved by training the neural network with an error back-propagation algorithm by presenting points’ pairs of tracked position by Scalable-SPIDAR and actual position reported by the IR optical tracking system. Therefore, the neural network devised for position error correction should accept three input coordinates of the measured position and should produce three outputs <i>x</i>, <i>y</i> and <i>z</i> coordinates of the corrected position. We need to decide on the network architecture (number of hidden layers, number of neurons in each layer, type of transfer function, etc.) and on the type of the error back-propagation training algorithm. There is no recipe for selecting the right network complexity for a given problem, and the optimal solution is often found by experimentation. One of the first decisions to be made is how many layers are needed in order to obtain a good model. It is hard to say which topology is better. A reasonable answer would specify the cost function for neural network’s performance, including the size of the neural network, accuracy and the like. According to Kecman (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Kecman V (2001) Learning and soft computing: support vector machines, neural networks, and fuzzy logic models. MIT Press, Cambridge" href="/article/10.1007/s10055-016-0303-y#ref-CR28" id="ref-link-section-d17e2738">2001</a>), it might be useful to try solving the problem at hand using a neural network with one hidden layer. In this work, we use a single-layer perceptron also called the hidden layer back-propagation network with a tangent sigmoid transfer function for the neurons in the hidden layer and linear transfer function for the neurons in the output layer (Bishop <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Bishop CM (1995) Neural networks for pattern recognition. Oxford University Press Inc, New York" href="/article/10.1007/s10055-016-0303-y#ref-CR2" id="ref-link-section-d17e2741">1995</a>). The right number of neurons in hidden layer required for an optimal solution is estimated experimentally by training networks of different sizes and determining the one with the best overall performances.</p><p>Different error back-propagation training algorithms can be used to train feed-forward neural network. In order to obtain a fast training procedure in the sense that the network converges in a small number of iterations, we select Levenberg–Marquardt algorithm (Hagan and Menhaj <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Hagan MT, Menhaj MB (1994) Training feedforward networks with the Marquardt algorithm. IEEE Trans Neural Netw 5(6):989–993" href="/article/10.1007/s10055-016-0303-y#ref-CR16" id="ref-link-section-d17e2747">1994</a>; Yu and Wilamowski <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Yu H, Wilamowski BM (2011) Levenberg–Marquardt training. In: Industrial electronics handbook—intelligent systems, vol 5. CRC Press, Inc., pp 12–1–12–15" href="/article/10.1007/s10055-016-0303-y#ref-CR54" id="ref-link-section-d17e2750">2011</a>). Although neural networks have good nonlinear regression abilities, they also have some drawbacks. During the neural network optimization process, we need to move on to a surface having multiple local minima. In fact, neural network’s learning/optimizing algorithms cannot avoid being stuck in local minima, which can lead to a sub-optimal solution (Suykens et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Suykens JAK et al (2002) Weighted least squares support vector machines: robustness and sparse approximation. Neurocomputing 48(1–4):85–105" href="/article/10.1007/s10055-016-0303-y#ref-CR49" id="ref-link-section-d17e2753">2002</a>).</p><p>Consequently, we use a single-layer perceptron to approximate the regression function that determines the relationship between the tracked position by the Scalable-SPIDAR and the actual position reported by the IR optical tracking system. However, we still need to check whether the training algorithm is trapped in a local minimum and thus avoid sub-optimal solutions. Therefore, we employ the support vector regression. In fact, SVR is not plagued with the problem of local minima and the solution is always unique, optimal and global (Smola and Schölkopf <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Smola AJ, Schölkopf B (2004) A tutorial on support vector regression. Stat Comput 14(3):199–222" href="/article/10.1007/s10055-016-0303-y#ref-CR46" id="ref-link-section-d17e2759">2004</a>).</p><h5 class="c-article__sub-heading" id="Sec15">Support vector machine for regression</h5><p>Initially developed for solving pattern recognition problems, support vector machine techniques can be successfully applied in regression for a functional approximation problem (Kwiatkowska and Fargion <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Kwiatkowska EJ, Fargion GS (2003) Application of machine-learning techniques toward the creation of a consistent and calibrated global chlorophyll concentration baseline dataset using remotely sensed ocean color data. IEEE Trans Geosci Remote Sens 41(12):2844–2860" href="/article/10.1007/s10055-016-0303-y#ref-CR38" id="ref-link-section-d17e2770">2003</a>; Kecman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Kecman V (2005) Support vector machines—an introduction. In: Wang L (ed) Support vector machines: theory and applications. Springer, Berlin, pp 1–47" href="/article/10.1007/s10055-016-0303-y#ref-CR29" id="ref-link-section-d17e2773">2005</a>). Given a training dataset <span class="mathjax-tex">\(D = \left\{ {\left[ {{\mathbf{x}}_{i} ,y} \right]} \right. \in {\mathbb{R}}^{n} \times {\mathbb{R}},\quad i = \left. {1, \ldots ,l} \right\}\)</span> where the input <b>x</b> denotes <i>n</i>-dimensional vectors <span class="mathjax-tex">\({\mathbf{x}} \in {\mathbb{R}}^{n}\)</span> and output <span class="mathjax-tex">\(y \in {\mathbb{R}}\)</span>, support vector regression attempts to learn the input–output relationship in a black box modeling approach. It originally consists in finding a function <span class="mathjax-tex">\(f(x)\)</span> that has at most an epsilon deviation from the actually obtained targets for all the training data with the smallest complexity. Hence, support vector regression (SVR) amounts to solve a constrained optimization problem, in which the complexity, measured by the norm of the weight parameters, is minimized. Allowing for the cases where the constraints cannot all be satisfied leads to minimizing the Vapnik linear loss function with <span class="mathjax-tex">\(\varepsilon\)</span>-insensitivity zone described by Melin and Castillo (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Melin P, Castillo O (2005) Studies in fuzziness and soft computing, volume 172. Soft Comput 18(3–4):318" href="/article/10.1007/s10055-016-0303-y#ref-CR40" id="ref-link-section-d17e2985">2005</a>) as:</p><div id="Equ8" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$E({\mathbf{x}},y,f) = \left| {y - f({\mathbf{x}},{\mathbf{w}})} \right|_{\varepsilon } = \left\{ {\begin{array}{ll} 0 \hfill &amp;{{\text{ if }}\quad \left| {y - f({\mathbf{x}},{\mathbf{w}})} \right| \le \varepsilon } \hfill \\ {\left| {y - f({\mathbf{x}},{\mathbf{w}})} \right| - \varepsilon } \hfill &amp;{\text{otherwise}} \hfill \\ \end{array} } \right.$$</span></div><div class="c-article-equation__number">
                    (8)
                </div></div><p>where <b>w</b> denotes the weight vector.</p><p>The support vector regression algorithm can therefore be written as a quadratic programming problem where both the <i>L</i>
                                 <sub>1</sub>-norm of the errors larger than epsilon and the <i>L</i>
                                 <sub>2</sub>-norm of the weight parameters are minimized.</p><div id="Equ9" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\frac{1}{2}\left\| {\mathbf{w}} \right\|^{2}\,+\,C\sum\limits_{i = 1}^{l} {\left| {y_{i} - f({\mathbf{x}}_{i} ,{\mathbf{w}})} \right|_{\varepsilon } }$$</span></div><div class="c-article-equation__number">
                    (9)
                </div></div><p>where <i>C</i> is a constant providing the trade-off between minimizing training errors and minimizing the model complexity term <span class="mathjax-tex">\(\left\| {\mathbf{w}} \right\|^{2}\)</span>. To deal with nonlinear regression tasks, SVR uses various kernel functions such as polynomial, sigmoidal and radial basis function RBF kernel that allow to extend linear methods to nonlinear problems through an implicit mapping to higher-dimensional feature space. Compared to neural network, SVR has many advantages: intrinsic regularization, no local minima (convex problem with a unique solution) and good generalization ability from a limited amount of samples (Bloch et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Bloch G et al (2008) Support vector regression from simulation data and few experimental samples. Inf Sci 178(20):3813–3827" href="/article/10.1007/s10055-016-0303-y#ref-CR3" id="ref-link-section-d17e3348">2008</a>).</p><p>We conclude that neural networks and support vector regression are both universal approximators, which could be used to calibrate the Scalable-SPIDAR haptic device in a black box modeling approach without the need for modeling explicitly the main error sources affecting its accuracy. Nevertheless, neural networks’ learning algorithm may get stuck in the local minima that the error surface may include and thus the global solution is not guaranteed. To overcome this issue, we use support vector regression to avoid such unfavorable local minima and to find out whether the designed network is converging to the global solution for the given dataset.</p></div></div></section><section aria-labelledby="Sec16"><div class="c-article-section" id="Sec16-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec16">Experimental results and discussion</h2><div class="c-article-section__content" id="Sec16-content"><p>In this section, a series of experiments were conducted to evaluate the performances of both neural networks and support vector regression. Each experiment used gathered data to approximate regression function that provides mapping between the tracked position by the Scalable-SPIDAR haptic device and the reference position reported by the optical tracking system.</p><h3 class="c-article__sub-heading" id="Sec17">Data preprocessing</h3><p>Before appl<b>y</b>ing the regression technique, input data need to be transformed to simplify either the neural network or support vector training. One important task is elimination of outliers. Training with outliers without awareness may lead to fitting unwanted data and may jeopardize function approximation (Huang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Huang J-N et al (1992) A comparison of projection pursuit and neural network regression modeling. Adv Neural Inf Process Syst 4:1159–1166" href="/article/10.1007/s10055-016-0303-y#ref-CR22" id="ref-link-section-d17e3375">1992</a>; Vapnik et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Vapnik V, Golowich SE, Smola AJ (1997) Support vector method for function approximation, regression estimation and signal processing. In: Mozer M, Jordan MI, Petsche T (eds) Advances in neural information processing systems 9—proceedings of the 1996 neural information processing systems conference (NIPS 1996). MIT Press, Cambridge, Dever, pp 281–287" href="/article/10.1007/s10055-016-0303-y#ref-CR51" id="ref-link-section-d17e3378">1997</a>). A close examination of the 1D box plot reveals that the points with large errors are isolated and inconsistent with the majority of data. This can be explained by the abnormal behavior of the motor placed at the upper left corner of the cubic frame. Therefore, we need a way to detect these data points and deflate their influence. We use informal box plots (Tukey <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1977" title="Tukey JW (1977) Schematic and summaries (pictures and numbers). In: Tukey JW (ed) Exploratory data analysis. Addison-Wesley Inc., pp 27–55" href="/article/10.1007/s10055-016-0303-y#ref-CR50" id="ref-link-section-d17e3381">1977</a>) to pinpoint the outlying points in the current dataset. Taking advantage of this method, we eliminate nearly 300 points of the 2197 points. The absolute position errors distribution without outliers is plotted as a frequency histogram (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig11">11</a>). Some of the representative statistics that describe much of this error distribution are given in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0303-y#Tab1">1</a>. As can be seen from this table, the mean absolute error value is rather large. This means an important discrepancy of about 270 mm between the tracked position and the true position that ideally has to be reached. This poor spatial tracking accuracy may cause inconsistency between the physical and virtual environments, which in turn can render training in a virtual environment ineffective, or, more seriously, result in negative skill transfer.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig11_HTML.gif?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig11_HTML.gif" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Absolute position errors represented as a frequency histogram</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Error statistics for non-calibrated Scalable-SPIDAR</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0303-y/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Before applying regression techniques, we still need to scale data. In fact, the task of training regression algorithm is significantly simplified if data lie within a small range. We scale all inputs to have mean zero and standard deviation one.</p><div id="Equ10" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\left\{ {\begin{array}{*{20}l} {N_{\text{SPIDAR}} = \left( {{{\left( {P_{\text{SPIDAR}} - \varGamma_{\text{SPIDAR}} } \right)} \mathord{\left/ {\vphantom {{\left( {P_{\text{SPIDAR}} - \varGamma_{\text{SPIDAR}} } \right)} {\varSigma_{\text{SPIDAR}} }}} \right. \kern-0pt} {\varSigma_{\text{SPIDAR}} }}} \right)} \hfill \\ {N_{\text{OTS}} = \left( {{{\left( {P_{\text{OTS}} - \varGamma_{\text{OTS}} } \right)} \mathord{\left/ {\vphantom {{\left( {P_{\text{OTS}} - \varGamma_{\text{OTS}} } \right)} {\varSigma_{\text{OTS}} }}} \right. \kern-0pt} {\varSigma_{\text{OTS}} }}} \right)} \hfill \\ \end{array} } \right.$$</span></div><div class="c-article-equation__number">
                    (10)
                </div></div><p>where <span class="mathjax-tex">\(\varGamma_{\text{SPIDAR}} = \gamma_{\text{SPIDAR}} \cdot J \quad {\text{and}}\quad \varSigma_{\text{SPIDAR}} = \sigma_{\text{SPIDAR}} \cdot J\)</span>, <span class="mathjax-tex">\(\varGamma_{\text{OTS}} = \gamma_{\text{OTS}} \cdot J\quad {\text{and}}\quad \varSigma_{\text{OTS}} = \sigma_{\text{OTS}} \cdot J\)</span>. <span class="mathjax-tex">\(\gamma_{\text{SPIDAR}}\)</span> matrix of mean components of the matrix of positions given by the Scalable-SPIDAR. <span class="mathjax-tex">\(\gamma_{\text{OTS}}\)</span> matrix of mean components of the matrix of positions given by the optical tracking system. <span class="mathjax-tex">\(P_{\text{SPIDAR}}\)</span> positions reported by the Scalable-SPIDAR. <span class="mathjax-tex">\(P_{\text{OTS}}\)</span> positions reported by the IR optical tracking system. <i>J</i> identity matrix. <span class="mathjax-tex">\(N_{\text{SPIDAR}}\)</span> standardized positions of the Scalable-SPIDAR. <span class="mathjax-tex">\(N_{\text{OTS}}\)</span> standardized positions of the optical tracking system.</p><h3 class="c-article__sub-heading" id="Sec18">Calibration using neural networks</h3><p>In the present study, we use a single-hidden layer feed-forward network which accepts three inputs x, y and z coordinates of the tracked position by the Scalable-SPIDAR and produces three outputs x, y and z of the calibrated position. The selected network model had two layers, with a tangent sigmoid transfer function <span class="mathjax-tex">\(\Phi (u) = \tanh u = \frac{2}{{1 + e^{ - 2u} }} - 1\)</span> for the neurons in the hidden layer and linear transfer function <span class="mathjax-tex">\(\Phi (u) = u\)</span> for the neurons in the output layer (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig12">12</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig12_HTML.gif?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig12_HTML.gif" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Single-hidden layer network used for the Scalable-SPIDAR calibration</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>This network was then trained to provide the corrected outputs by modifying weights according to “training algorithm.” The Levenberg–Marquardt algorithm was preferred as it is saving time and well suited to function approximation problems with networks of moderate size and number of parameters.</p><p>Furthermore, deciding on the number of neurons in the hidden layer is essential for deciding the overall neural network architecture and, therefore, must be carefully considered. To determine the right number of neurons, we trained neural networks with 3–24 neurons in the hidden layer and compute the average errors between the expected actual position and the calibrated position. Based on these results, we selected the most effective configuration estimating the values of the given dataset. Thus, in essence, we calibrated the Scalable-SPIDAR with different configurations and selected the one that gives the best results. By plotting the mean absolute error versus the number of neurons in hidden layer (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig13">13</a>), we can see that the optimal solution is 20.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-13"><figure><figcaption><b id="Fig13" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 13</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/13" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig13_HTML.gif?as=webp"></source><img aria-describedby="figure-13-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig13_HTML.gif" alt="figure13" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-13-desc"><p>Mean absolute position error versus number of neurons in hidden layer</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/13" data-track-dest="link:Figure13 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Analyses were conducted to evaluate the performances of neural network-based calibration. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig14">14</a> represents the spatial distribution of absolute position errors after calibration with the error magnitudes proportional to the corresponding color. As revealed by this plot, neural network-based calibration is able to reduce the magnitude of absolute position errors from 267 to &lt;30 mm in almost whole workspace.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-14"><figure><figcaption><b id="Fig14" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 14</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/14" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig14_HTML.gif?as=webp"></source><img aria-describedby="figure-14-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig14_HTML.gif" alt="figure14" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-14-desc"><p>Absolute position errors represented spatially after neural network-based calibration</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/14" data-track-dest="link:Figure14 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>As for Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig15">15</a>, it depicts the distribution of absolute position errors as a function of distance to the Scalable-SPIDAR’s origin before and after calibration. As shown by the plot, neural network-based method is efficient and able to achieve fewer errors in the whole working space. It is apparent that error becomes less sensitive to distance and even the errors at distances greater than 600 mm were successfully corrected by calibration.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-15"><figure><figcaption><b id="Fig15" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 15</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/15" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig15_HTML.gif?as=webp"></source><img aria-describedby="figure-15-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig15_HTML.gif" alt="figure15" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-15-desc"><p>Distribution of absolute position errors as a function of distance to the Scalable-SPIDAR’s origin (before and after neural network-based calibration method)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/15" data-track-dest="link:Figure15 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>To gauge more the importance of the improvements obtained with the neural network-based calibration method, some representative statistics before and after calibration are presented in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0303-y#Tab2">2</a>. The mean tracked position error from the training dataset is 267.83 ± 76.51 mm (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0303-y#Tab2">2</a>), whereas the mean position error after calibration is 6.47 ± 3.43 mm. The statistics proved that the neural network-based method has significantly decreased errors in the tracked position.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Error statistics before and after neural network-based calibration</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0303-y/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>After testing the neural network with training data, we need to measure its ability to handle unseen data. The underlying idea is to construct a testing dataset. To this end, the end-effector of the Scalable-SPIDAR haptic device was moved in random trajectories of sequential points. These paths represent groups of data points within our predetermined working space. Following this, corresponding point measurements of both the Scalable-SPIDAR and the IR optical tracking system can be obtained, thus allowing evaluating the generalization capability of our network.</p><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0303-y#Tab3">3</a> summarizes the results of the calibration based on the data from the testing dataset. A close examination shows that our neural network does not keep the same performances as in training, but it is still ranging within reasonable error band of 14.50 ± 8.39 mm.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Error statistics in generalization</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0303-y/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec19">Calibration using support vector regression</h3><p>In this section, we applied support vector regression (SVR) for calibrating the Scalable-SPIDAR haptic device. In fact, the support vector regression is a promising new universal approximator that has been shown to have remarkable characteristics. One of the key characteristics is that SVR training leads to a convex quadratic programming (QP) problem, rather than a nonconvex, unconstrained minimization problem as in neural network training; hence, it always converges to the global solution for a given dataset. Therefore, SVR is a promising alternative to the conventional multilayer perceptron for the calibration of the Scalable-SPIDAR haptic device.</p><p>The convergence of support vector machine depends on the selection of a kernel function. Kernel functions project the data into high-dimensional feature space. This work uses that radial basis function to perform better than polynomial and linear functions in demining a relationship between Scalable-SPIDAR and optical tracking system data. In the following, trials radial basis kernels were applied:</p><div id="Equ11" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$${\text{radial}}\;{\text{basis}}\;{\text{fucntion}} = \exp ( - {\text{gamma}} \times \left\| {x_{i} - x_{j} } \right\|^{2} )$$</span></div><div class="c-article-equation__number">
                    (11)
                </div></div><p>where gamma is known as the kernel parameter.</p><p>A search was performed for the most effective capacity parameter C to enhance generalization accuracy of the regression method. The capacity measures the flexibility or richness of regression functions and gives the protection against over fitting. In experiments, the capacity was set to values between 30 and 100. Another parameter used in the training of support vector regression is epsilon, which checks the insensitivity of the regression. The algorithm assumes that estimations that lie within epsilon distance of their true values are accurate enough. Epsilon was chosen to be equal to 0.01.</p><p>To analyze the performances of the support vector regression, we plot the spatial distribution of absolute position errors as in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0303-y#Sec18">5.2</a> but after calibration using support vector regression method.</p><p>As we can see, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig16">16</a> shows that SVR is quite effective and greatly improves the Scalable-SPIDAR accuracy in comparison with Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig9">9</a>. Support vector regression performs a good calibration in the whole workspace expect in its corners.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-16"><figure><figcaption><b id="Fig16" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 16</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/16" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig16_HTML.gif?as=webp"></source><img aria-describedby="figure-16-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig16_HTML.gif" alt="figure16" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-16-desc"><p>Absolute position errors represented spatially after SVR calibration</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/16" data-track-dest="link:Figure16 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0303-y#Fig17">17</a> shows that SVR is quite efficient and exhibits fewer errors. The Scalable-SPIDAR accuracy is less sensitive to distance to the Scalable-SPIDAR’s origin and even the errors at distances greater than 600 mm were corrected by calibration. We can see from Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0303-y#Tab4">4</a> that the SVR calibration was successful in reducing the mean absolute position error in tracked position from 267.83 ± 76.51 to 6.27 ± 2.86 mm. The maximum possible error is about 20.3819 mm.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-17"><figure><figcaption><b id="Fig17" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 17</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/17" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig17_HTML.gif?as=webp"></source><img aria-describedby="figure-17-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0303-y/MediaObjects/10055_2016_303_Fig17_HTML.gif" alt="figure17" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-17-desc"><p>Distribution of absolute position errors as a function of distance to the Scalable-SPIDAR’s origin (before and after SVR calibration)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0303-y/figures/17" data-track-dest="link:Figure17 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 Error statistics before and after SVR calibration</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0303-y/tables/4"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>In order to measure the generalization ability of the support vector regression-based method, we use the same testing dataset created previously.</p><p>A close examination of Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0303-y#Tab5">5</a> reveals that SVR keeps convenient performance when handling unseen data. Both the mean and the standard deviation of absolute errors in position at the testing points are less than those by the neural network method. The SVR provided improved results at high error levels with a maximum position error of 22.33 mm.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 Error statistics in generalization</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0303-y/tables/5"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec20">Comparison of the calibration results by support vector regression and neural network-based calibration techniques</h3><p>To stress the performances improvements obtained with machine learning methods, we summarize the calibration results of the two methods discussed in this paper. The first method employs a single-layer feed-forward network model as a calibration model. The second method uses a support vector regression to calibrate the Scalable-SPIDAR position readings. The design parameters were determined based on the guidelines described at the beginning of Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0303-y#Sec19">5.3</a>.</p><p>Based on the error statistics listed in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0303-y#Tab6">6</a> and above (Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0303-y#Tab3">3</a>, <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0303-y#Tab5">5</a>), support vector regression method outperformed the neural network-based method when applied to calibrate the position readings form the Scalable-SPIDAR. The significance of the improvements obtained by SVR was demonstrated more by its ability to generalize when handling unseen data. Actually, SVR shows higher robustness and greater estimation ability for future data points. The obtained results suggest that the proposed SVR is better suited than the neural network-based method for the Scalable-SPIDAR calibration. This is in accordance with our initial hypothesis. In fact, as we have mentioned above, neural network’s learning algorithms may stuck in local minima, thus providing sub-optimal solution and limiting the effectiveness of the neural network-based calibration method.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-6"><figure><figcaption class="c-article-table__figcaption"><b id="Tab6" data-test="table-caption">Table 6 Summary of the calibration results obtained by the two machine learning techniques discussed in this paper</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0303-y/tables/6"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The support vector regression has the advantage of being free from local minima and thus can be used to find whether the selected neural network has reached the global minimum. The major advantage of this approach is that it allows avoiding non-optimal calibration solutions.</p><h3 class="c-article__sub-heading" id="Sec21">Recalibration at runtime</h3><p>The one-time calibration of the Scalable-SPIDAR is a crucial step to provide accurate tracking data. However, issues influencing calibration such as the haptic controller behavior can change while using the Scalable-SPIDAR. Therefore, position estimation might deteriorate if haptic control failures occur. To keep tracking quality high, recalibration at runtime is required at suitable intervals. It seems more convenient to use data provided by the optical tracking system for unobtrusive calibration. In fact, if the Scalable-SPIDAR loses tracking, optical tracking data can then be used and calibration would be improved at runtime without disturbing the user. Combining the Scalable-SPIDAR and the optical tracking system into a hybrid tracking system aims to maintain an uninterrupted tracking data and the required spatial accuracy under varying conditions in the operating workspace.</p></div></div></section><section aria-labelledby="Sec22"><div class="c-article-section" id="Sec22-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec22">Conclusions</h2><div class="c-article-section__content" id="Sec22-content"><p>In this paper, a novel calibration procedure was proposed to improve the tracking accuracy of a human-scale haptic device: the Scalable-SPIDAR. The basic idea of the procedure is to adopt the concepts of virtual reality and machine learning techniques to calibrate the position errors present in the haptic device readings. In this paper, a visual-haptic VR setup was established to maintain an interrupted tracking and to enable haptic interaction with virtual objects in the virtual environment. Based on this setup, a multimodal initialization procedure was developed in order to help the user to accomplish and repeat the initialization of the Scalable-SPIDAR in a precise manner. Nevertheless, additional errors in the reported position remain due to serious problems in the mechanical structure design of the haptic device. To overcome this issue, a collection data protocol was first developed to characterize the Scalable-SPIDAR’s tracking position errors. Then, a model-less approach using regression methods was adopted to correct these errors. Two nonlinear regression techniques, thus, have been used for the calibration of the haptic device. The first one is a neural network-based calibration method, while the second is based on the support vector regression.</p><p>The obtained results above indicate that the proposed calibration techniques work well for position error, reducing the scalable-SPIDAR’s average absolute position error to about 6 mm. These results are an improvement of the average accuracy of 7.8 mm reported in Boudoin et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Boudoin P et al (2010) SPIDAR calibration based on neural networks versus optical tracking. BT—artificial neural networks and intelligent information processing. In: Proceedings of the 6th international workshop on artificial neural networks and intelligent information processing, pp 87–98" href="/article/10.1007/s10055-016-0303-y#ref-CR4" id="ref-link-section-d17e4911">2010</a>) and confirm an earlier investigation, where the model-less calibration approach was found to be a promising opportunity to improve the tracking accuracy of the Scalable-SPIDAR haptic device. The position correction achieved by the calibration procedure thus offers a visible improvement in tracking accuracy in a VR system.</p><p>Compared with other calibration methods, the proposed method employs machine learning techniques such as neural networks and support vector regression to tackle problems of tracking inaccuracy. Based on their universal approximation capability, these methods were able to perform the calibration of the Scalable-SPIDAR without the need for modeling explicitly the main error sources affecting its accuracy. Even though the proposed procedure is limited by the use of the Scalable-SPIDAR system, it is possible to extend it to other tracking systems. The distinguishing features of scalability and convince make from this procedure a flexible method that can accommodate various virtual reality systems ranging from desktop to human-scale and network environments.</p><p>Furthermore, since the Scalable-SPIDAR is intended to serve as a 6-DOF human-scale haptic device, a straightforward extension to this work is to build an orientation calibration method. Therefore, the Scalable-SPIDAR can be used to accomplish several applications ranging from the simple “pick and place” task to more physical-based interactions.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Advanced Realtime Tracking GmbH (2003) ARTtrack1 &amp; DTrack—Manual Version 1.18" /><p class="c-article-references__text" id="ref-CR1">Advanced Realtime Tracking GmbH (2003) ARTtrack1 &amp; DTrack—Manual Version 1.18</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="CM. Bishop, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Bishop CM (1995) Neural networks for pattern recognition. Oxford University Press Inc, New York" /><p class="c-article-references__text" id="ref-CR2">Bishop CM (1995) Neural networks for pattern recognition. Oxford University Press Inc, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20networks%20for%20pattern%20recognition&amp;publication_year=1995&amp;author=Bishop%2CCM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Bloch, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Bloch G et al (2008) Support vector regression from simulation data and few experimental samples. Inf Sci 178(" /><p class="c-article-references__text" id="ref-CR3">Bloch G et al (2008) Support vector regression from simulation data and few experimental samples. Inf Sci 178(20):3813–3827</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.ins.2008.05.016" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Support%20vector%20regression%20from%20simulation%20data%20and%20few%20experimental%20samples&amp;journal=Inf%20Sci&amp;volume=178&amp;issue=20&amp;pages=3813-3827&amp;publication_year=2008&amp;author=Bloch%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Boudoin P et al (2010) SPIDAR calibration based on neural networks versus optical tracking. BT—artificial neur" /><p class="c-article-references__text" id="ref-CR4">Boudoin P et al (2010) SPIDAR calibration based on neural networks versus optical tracking. BT—artificial neural networks and intelligent information processing. In: Proceedings of the 6th international workshop on artificial neural networks and intelligent information processing, pp 87–98</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bouguila L, Ishii M, Sato M (2000) Effect of coupling haptics and stereopsis on depth perception in virtual en" /><p class="c-article-references__text" id="ref-CR5">Bouguila L, Ishii M, Sato M (2000) Effect of coupling haptics and stereopsis on depth perception in virtual environment. In: Proceedings of the 1st workshop on haptic human computer interaction, 31st August–1st Sept 2000. pp 54–62</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Briggs W (1999) Magnetic calibration by tetrahedral interpolation. In: Proceedings of NIST-ASME industrial vir" /><p class="c-article-references__text" id="ref-CR6">Briggs W (1999) Magnetic calibration by tetrahedral interpolation. In: Proceedings of NIST-ASME industrial virtual reality symposium, Chicago, pp 27–32</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bryson S (1992) Measurement and calibration of static distortion of position data from 3D trackers. In: Procee" /><p class="c-article-references__text" id="ref-CR7">Bryson S (1992) Measurement and calibration of static distortion of position data from 3D trackers. In: Proceedings of SPIE conference. Stereoscopic displays and applications III, pp 244–255</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Buoguila L, Ishii M, Sato M (2000) Multi-modal haptic device for large-scale virtual environments. In: Proceed" /><p class="c-article-references__text" id="ref-CR8">Buoguila L, Ishii M, Sato M (2000) Multi-modal haptic device for large-scale virtual environments. In: Proceedings of the eighth ACM international conference on multimedia. MULTIMEDIA ’00. ACM, New York, pp 277–283</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="GC. Burdea, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Burdea GC (1996) Force and touch feedback for virtual reality. Wiley, New York" /><p class="c-article-references__text" id="ref-CR9">Burdea GC (1996) Force and touch feedback for virtual reality. Wiley, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Force%20and%20touch%20feedback%20for%20virtual%20reality&amp;publication_year=1996&amp;author=Burdea%2CGC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ellis SR et al (1999) Sensor spatial distortion, visual latency, and update rate effects\non 3D tracking in vi" /><p class="c-article-references__text" id="ref-CR10">Ellis SR et al (1999) Sensor spatial distortion, visual latency, and update rate effects\non 3D tracking in virtual environments. In: Proceedings IEEE virtual reality (Cat no 99CB36316), pp 218–221</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="S. Faroque, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Faroque S et al (2015) Haptic virtual reality training environment for micro-robotic cell injection. In: Kajim" /><p class="c-article-references__text" id="ref-CR11">Faroque S et al (2015) Haptic virtual reality training environment for micro-robotic cell injection. In: Kajimoto H, Ando H, Kyung K-U (eds) Haptic interaction: perception, devices and applications. Springer, Tokyo, pp 245–249</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Haptic%20interaction%3A%20perception%2C%20devices%20and%20applications&amp;pages=245-249&amp;publication_year=2015&amp;author=Faroque%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Fletcher, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Fletcher C et al (2013) The development of an integrated haptic VR machining environment for the automatic gen" /><p class="c-article-references__text" id="ref-CR12">Fletcher C et al (2013) The development of an integrated haptic VR machining environment for the automatic generation of process plans. Comput Ind 64(8):1045–1060</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.compind.2013.07.005" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20development%20of%20an%20integrated%20haptic%20VR%20machining%20environment%20for%20the%20automatic%20generation%20of%20process%20plans&amp;journal=Comput%20Ind&amp;volume=64&amp;issue=8&amp;pages=1045-1060&amp;publication_year=2013&amp;author=Fletcher%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="P. Fuchs, G. Moreau, P. Guitton, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Fuchs P, Moreau G, Guitton P (2011) Virtual reality: concepts and technologies, 1st edn. CRC Press Inc, Boca R" /><p class="c-article-references__text" id="ref-CR13">Fuchs P, Moreau G, Guitton P (2011) Virtual reality: concepts and technologies, 1st edn. CRC Press Inc, Boca Raton</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%3A%20concepts%20and%20technologies&amp;publication_year=2011&amp;author=Fuchs%2CP&amp;author=Moreau%2CG&amp;author=Guitton%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ghazisaedy M et al (1995) Ultrasonic calibration of a magnetic tracker in a virtual reality space. In: Proceed" /><p class="c-article-references__text" id="ref-CR14">Ghazisaedy M et al (1995) Ultrasonic calibration of a magnetic tracker in a virtual reality space. In: Proceedings virtual reality annual international symposium ’95, pp 179–188</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Group S (2005) SPIDAR-G/AHS1.0A user’s manual Ver. 2.0., pp 1–44" /><p class="c-article-references__text" id="ref-CR15">Group S (2005) SPIDAR-G/AHS1.0A user’s manual Ver. 2.0., pp 1–44</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MT. Hagan, MB. Menhaj, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Hagan MT, Menhaj MB (1994) Training feedforward networks with the Marquardt algorithm. IEEE Trans Neural Netw " /><p class="c-article-references__text" id="ref-CR16">Hagan MT, Menhaj MB (1994) Training feedforward networks with the Marquardt algorithm. IEEE Trans Neural Netw 5(6):989–993</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F72.329697" aria-label="View reference 16">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Training%20feedforward%20networks%20with%20the%20Marquardt%20algorithm&amp;journal=IEEE%20Trans%20Neural%20Netw&amp;volume=5&amp;issue=6&amp;pages=989-993&amp;publication_year=1994&amp;author=Hagan%2CMT&amp;author=Menhaj%2CMB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Harders, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Harders M et al (2009) Calibration, registration, and synchronization for high precision augmented reality hap" /><p class="c-article-references__text" id="ref-CR17">Harders M et al (2009) Calibration, registration, and synchronization for high precision augmented reality haptics. IEEE Trans Vis Comput Graph 15(1):138–149</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTVCG.2008.63" aria-label="View reference 17">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Calibration%2C%20registration%2C%20and%20synchronization%20for%20high%20precision%20augmented%20reality%20haptics&amp;journal=IEEE%20Trans%20Vis%20Comput%20Graph&amp;volume=15&amp;issue=1&amp;pages=138-149&amp;publication_year=2009&amp;author=Harders%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="TJ. Hastie, RJ. Tibshirani, JH. Friedman, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Hastie TJ, Tibshirani RJ, Friedman JH (2009) The elements of statistical learning: data mining, inference, and" /><p class="c-article-references__text" id="ref-CR18">Hastie TJ, Tibshirani RJ, Friedman JH (2009) The elements of statistical learning: data mining, inference, and prediction. Springer, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20elements%20of%20statistical%20learning%3A%20data%20mining%2C%20inference%2C%20and%20prediction&amp;publication_year=2009&amp;author=Hastie%2CTJ&amp;author=Tibshirani%2CRJ&amp;author=Friedman%2CJH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="V. Hayward, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Hayward V et al (2004) Haptic interfaces and devices. Sensor Rev 24(1):16–29" /><p class="c-article-references__text" id="ref-CR19">Hayward V et al (2004) Haptic interfaces and devices. Sensor Rev 24(1):16–29</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1984423" aria-label="View reference 19 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1108%2F02602280410515770" aria-label="View reference 19">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Haptic%20interfaces%20and%20devices&amp;journal=Sensor%20Rev&amp;volume=24&amp;issue=1&amp;pages=16-29&amp;publication_year=2004&amp;author=Hayward%2CV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hirata Y, Sato M (1992) 3-dimensional interface device for virtual work space. In: Proceedings of the 1992 lEE" /><p class="c-article-references__text" id="ref-CR20">Hirata Y, Sato M (1992) 3-dimensional interface device for virtual work space. In: Proceedings of the 1992 lEEE/RSJ international conference on intelligent robots and systems, vol 2, pp 889–896</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Hornik, M. Stinchcombe, H. White, " /><meta itemprop="datePublished" content="1989" /><meta itemprop="headline" content="Hornik K, Stinchcombe M, White H (1989) Multilayer feedforward networks are universal approximators. Neural Ne" /><p class="c-article-references__text" id="ref-CR21">Hornik K, Stinchcombe M, White H (1989) Multilayer feedforward networks are universal approximators. Neural Netw 2(5):359–366</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2F0893-6080%2889%2990020-8" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Multilayer%20feedforward%20networks%20are%20universal%20approximators&amp;journal=Neural%20Netw&amp;volume=2&amp;issue=5&amp;pages=359-366&amp;publication_year=1989&amp;author=Hornik%2CK&amp;author=Stinchcombe%2CM&amp;author=White%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J-N. Huang, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Huang J-N et al (1992) A comparison of projection pursuit and neural network regression modeling. Adv Neural I" /><p class="c-article-references__text" id="ref-CR22">Huang J-N et al (1992) A comparison of projection pursuit and neural network regression modeling. Adv Neural Inf Process Syst 4:1159–1166</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20comparison%20of%20projection%20pursuit%20and%20neural%20network%20regression%20modeling&amp;journal=Adv%20Neural%20Inf%20Process%20Syst&amp;volume=4&amp;pages=1159-1166&amp;publication_year=1992&amp;author=Huang%2CJ-N">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="ISO 5725-1 (1994) Accuracy (trueness and precision) of measurement methods and results—part 1: general princip" /><p class="c-article-references__text" id="ref-CR23">ISO 5725-1 (1994) Accuracy (trueness and precision) of measurement methods and results—part 1: general principles and definitions. International Organization for Standardization, Geneva</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Ikits, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Ikits M et al (2001) An improved calibration framework for electromagnetic tracking devices. Proc IEEE Virtual" /><p class="c-article-references__text" id="ref-CR24">Ikits M et al (2001) An improved calibration framework for electromagnetic tracking devices. Proc IEEE Virtual Real 2001:63–70</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20improved%20calibration%20framework%20for%20electromagnetic%20tracking%20devices&amp;journal=Proc%20IEEE%20Virtual%20Real&amp;volume=2001&amp;pages=63-70&amp;publication_year=2001&amp;author=Ikits%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ikits M, Hansen CD, Johnson CR (2003) A comprehensive calibration and registration procedure for the visual ha" /><p class="c-article-references__text" id="ref-CR25">Ikits M, Hansen CD, Johnson CR (2003) A comprehensive calibration and registration procedure for the visual haptic workbench. In: Proceedings of the workshop on virtual environments 2003. EGVE’03. ACM, New York, pp 247–254</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ikits M et al (2000) The visual haptic workbench. In: Proceedings of PHANToM users group workshop. pp 46–49" /><p class="c-article-references__text" id="ref-CR26">Ikits M et al (2000) The visual haptic workbench. In: Proceedings of PHANToM users group workshop. pp 46–49</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="U. Jayaram, R. Repp, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Jayaram U, Repp R (2002) Integrated real-time calibration of electromagnetic tracking of user motions for engi" /><p class="c-article-references__text" id="ref-CR27">Jayaram U, Repp R (2002) Integrated real-time calibration of electromagnetic tracking of user motions for engineering applications in virtual environments. J Mech Des 124:623</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1115%2F1.1517562" aria-label="View reference 27">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Integrated%20real-time%20calibration%20of%20electromagnetic%20tracking%20of%20user%20motions%20for%20engineering%20applications%20in%20virtual%20environments&amp;journal=J%20Mech%20Des&amp;volume=124&amp;publication_year=2002&amp;author=Jayaram%2CU&amp;author=Repp%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="V. Kecman, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Kecman V (2001) Learning and soft computing: support vector machines, neural networks, and fuzzy logic models." /><p class="c-article-references__text" id="ref-CR28">Kecman V (2001) Learning and soft computing: support vector machines, neural networks, and fuzzy logic models. MIT Press, Cambridge</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20and%20soft%20computing%3A%20support%20vector%20machines%2C%20neural%20networks%2C%20and%20fuzzy%20logic%20models&amp;publication_year=2001&amp;author=Kecman%2CV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="V. Kecman, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Kecman V (2005) Support vector machines—an introduction. In: Wang L (ed) Support vector machines: theory and a" /><p class="c-article-references__text" id="ref-CR29">Kecman V (2005) Support vector machines—an introduction. In: Wang L (ed) Support vector machines: theory and applications. Springer, Berlin, pp 1–47</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Support%20vector%20machines%3A%20theory%20and%20applications&amp;pages=1-47&amp;publication_year=2005&amp;author=Kecman%2CV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DN. Kenwright, DA. Lane, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Kenwright DN, Lane DA (1996) Interactive time-dependent particle tracing using tetrahedral decomposition. IEEE" /><p class="c-article-references__text" id="ref-CR30">Kenwright DN, Lane DA (1996) Interactive time-dependent particle tracing using tetrahedral decomposition. IEEE Trans Vis Comput Graph 2(2):120–129</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F2945.506224" aria-label="View reference 30">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Interactive%20time-dependent%20particle%20tracing%20using%20tetrahedral%20decomposition&amp;journal=IEEE%20Trans%20Vis%20Comput%20Graph&amp;volume=2&amp;issue=2&amp;pages=120-129&amp;publication_year=1996&amp;author=Kenwright%2CDN&amp;author=Lane%2CDA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kim S et al (2002) Tension based 7-DOF force feedback device: SPIDAR-G. In: Proceedings, IEEE virtual reality." /><p class="c-article-references__text" id="ref-CR31">Kim S et al (2002) Tension based 7-DOF force feedback device: SPIDAR-G. In: Proceedings, IEEE virtual reality. pp 283–284</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="V. Kindratenko, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Kindratenko V (1999) Calibration of electromagnetic tracking devices. Virtual Real 4:139–150" /><p class="c-article-references__text" id="ref-CR32">Kindratenko V (1999) Calibration of electromagnetic tracking devices. Virtual Real 4:139–150</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2FBF01408592" aria-label="View reference 32">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Calibration%20of%20electromagnetic%20tracking%20devices&amp;journal=Virtual%20Real&amp;volume=4&amp;pages=139-150&amp;publication_year=1999&amp;author=Kindratenko%2CV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="V. Kindratenko, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Kindratenko V (2000) A survey of electromagnetic position tracker calibration techniques. Virtual Real 5(3):16" /><p class="c-article-references__text" id="ref-CR33">Kindratenko V (2000) A survey of electromagnetic position tracker calibration techniques. Virtual Real 5(3):169–182</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2FBF01409422" aria-label="View reference 33">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20survey%20of%20electromagnetic%20position%20tracker%20calibration%20techniques&amp;journal=Virtual%20Real&amp;volume=5&amp;issue=3&amp;pages=169-182&amp;publication_year=2000&amp;author=Kindratenko%2CV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="V. Kindratenko, A. Bennett, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Kindratenko V, Bennett A (2000) Evaluation of rotation correction techniques for electromagnetic position trac" /><p class="c-article-references__text" id="ref-CR34">Kindratenko V, Bennett A (2000) Evaluation of rotation correction techniques for electromagnetic position tracking systems. In: Mulder J, van Liere R (eds) Virtual environments 2000 SE—3. Eurographics. Springer, Vienna, pp 13–22</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20environments%202000%20SE%E2%80%943.%20Eurographics&amp;pages=13-22&amp;publication_year=2000&amp;author=Kindratenko%2CV&amp;author=Bennett%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="VV. Kindratenko, WR. Sherman, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Kindratenko VV, Sherman WR (2005) Neural network-based calibration of electromagnetic tracking systems. Virtua" /><p class="c-article-references__text" id="ref-CR35">Kindratenko VV, Sherman WR (2005) Neural network-based calibration of electromagnetic tracking systems. Virtual Real. 9(1):70–78</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10055-005-0005-3" aria-label="View reference 35">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20network-based%20calibration%20of%20electromagnetic%20tracking%20systems&amp;journal=Virtual%20Real.&amp;volume=9&amp;issue=1&amp;pages=70-78&amp;publication_year=2005&amp;author=Kindratenko%2CVV&amp;author=Sherman%2CWR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Knoerlein B, Harders M (2011) Comparison of tracker-based to tracker-less haptic device calibration. In: World" /><p class="c-article-references__text" id="ref-CR36">Knoerlein B, Harders M (2011) Comparison of tracker-based to tracker-less haptic device calibration. In: World haptics conference (WHC), 2011 IEEE, pp 119–124</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kunzler U, Runde C (2005) Kinesthetic haptics integration into large-scale virtual environments. In: Eurohapti" /><p class="c-article-references__text" id="ref-CR37">Kunzler U, Runde C (2005) Kinesthetic haptics integration into large-scale virtual environments. In: Eurohaptics conference, 2005 and symposium on haptic interfaces for virtual environment and teleoperator systems, 2005. World haptics 2005. First Joint, pp 551–556</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EJ. Kwiatkowska, GS. Fargion, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Kwiatkowska EJ, Fargion GS (2003) Application of machine-learning techniques toward the creation of a consiste" /><p class="c-article-references__text" id="ref-CR38">Kwiatkowska EJ, Fargion GS (2003) Application of machine-learning techniques toward the creation of a consistent and calibrated global chlorophyll concentration baseline dataset using remotely sensed ocean color data. IEEE Trans Geosci Remote Sens 41(12):2844–2860</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTGRS.2003.818016" aria-label="View reference 38">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 38 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Application%20of%20machine-learning%20techniques%20toward%20the%20creation%20of%20a%20consistent%20and%20calibrated%20global%20chlorophyll%20concentration%20baseline%20dataset%20using%20remotely%20sensed%20ocean%20color%20data&amp;journal=IEEE%20Trans%20Geosci%20Remote%20Sens&amp;volume=41&amp;issue=12&amp;pages=2844-2860&amp;publication_year=2003&amp;author=Kwiatkowska%2CEJ&amp;author=Fargion%2CGS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MA. Livingston, A. State, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Livingston MA, State A (1997) Magnetic tracker calibration for improved augmented reality registration. Presen" /><p class="c-article-references__text" id="ref-CR39">Livingston MA, State A (1997) Magnetic tracker calibration for improved augmented reality registration. Presence Teleoperators Virtual Environ 6(5):532–546</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2Fpres.1997.6.5.532" aria-label="View reference 39">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Magnetic%20tracker%20calibration%20for%20improved%20augmented%20reality%20registration&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=6&amp;issue=5&amp;pages=532-546&amp;publication_year=1997&amp;author=Livingston%2CMA&amp;author=State%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Melin, O. Castillo, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Melin P, Castillo O (2005) Studies in fuzziness and soft computing, volume 172. Soft Comput 18(3–4):318" /><p class="c-article-references__text" id="ref-CR40">Melin P, Castillo O (2005) Studies in fuzziness and soft computing, volume 172. Soft Comput 18(3–4):318</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 40 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Studies%20in%20fuzziness%20and%20soft%20computing%2C%20volume%20172&amp;journal=Soft%20Comput&amp;volume=18&amp;issue=3%E2%80%934&amp;publication_year=2005&amp;author=Melin%2CP&amp;author=Castillo%2CO">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Meyer, HL. Applewhite, FA. Biocca, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Meyer K, Applewhite HL, Biocca FA (1992) A survey of position trackers. Presence Teleoper Virtual Environ 1(2)" /><p class="c-article-references__text" id="ref-CR41">Meyer K, Applewhite HL, Biocca FA (1992) A survey of position trackers. Presence Teleoper Virtual Environ 1(2):173–200</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2Fpres.1992.1.2.173" aria-label="View reference 41">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 41 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20survey%20of%20position%20trackers&amp;journal=Presence%20Teleoper%20Virtual%20Environ&amp;volume=1&amp;issue=2&amp;pages=173-200&amp;publication_year=1992&amp;author=Meyer%2CK&amp;author=Applewhite%2CHL&amp;author=Biocca%2CFA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Moreira AHJ et al (2014) Electromagnetic tracker feasibility in the design of a dental superstructure for eden" /><p class="c-article-references__text" id="ref-CR42">Moreira AHJ et al (2014) Electromagnetic tracker feasibility in the design of a dental superstructure for edentulous patients. In: IEEE MeMeA 2014—IEEE international symposium on medical measurements and applications, Proceedings, pp 1–6</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="Y-H. Pao, " /><meta itemprop="datePublished" content="1989" /><meta itemprop="headline" content="Pao Y-H (1989) Adaptive pattern recognition and neural networks. Addison-Wesley Longman Publishing Co., Inc, B" /><p class="c-article-references__text" id="ref-CR43">Pao Y-H (1989) Adaptive pattern recognition and neural networks. Addison-Wesley Longman Publishing Co., Inc, Boston</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 43 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Adaptive%20pattern%20recognition%20and%20neural%20networks&amp;publication_year=1989&amp;author=Pao%2CY-H">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ramsamy P et al (2006) Using haptics to improve immersion in virtual environments. In: Alexandrov V et al (eds" /><p class="c-article-references__text" id="ref-CR44">Ramsamy P et al (2006) Using haptics to improve immersion in virtual environments. In: Alexandrov V et al (eds) Computational science—ICCS 2006 SE—81, Lecture Notes in Computer Science. Springer, Berlin, pp 603–609</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Reinig K, Tracy R, Gilmore H, Mahalik T (1997) Some calibration information for a Phantom 1.5 a. In: Proceedin" /><p class="c-article-references__text" id="ref-CR45">Reinig K, Tracy R, Gilmore H, Mahalik T (1997) Some calibration information for a Phantom 1.5 a. In: Proceedings of the second PHANToM user’s group workshop. Dedham, Massachusetts, pp 70–73</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AJ. Smola, B. Schölkopf, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Smola AJ, Schölkopf B (2004) A tutorial on support vector regression. Stat Comput 14(3):199–222" /><p class="c-article-references__text" id="ref-CR46">Smola AJ, Schölkopf B (2004) A tutorial on support vector regression. Stat Comput 14(3):199–222</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2086398" aria-label="View reference 46 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1023%2FB%3ASTCO.0000035301.49549.88" aria-label="View reference 46">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 46 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20tutorial%20on%20support%20vector%20regression&amp;journal=Stat%20Comput&amp;volume=14&amp;issue=3&amp;pages=199-222&amp;publication_year=2004&amp;author=Smola%2CAJ&amp;author=Sch%C3%B6lkopf%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MA. Srinivasan, C. Basdogan, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Srinivasan MA, Basdogan C (1997) Haptics in virtual environments: taxonomy, research status, and challenges. C" /><p class="c-article-references__text" id="ref-CR47">Srinivasan MA, Basdogan C (1997) Haptics in virtual environments: taxonomy, research status, and challenges. Comput Graph 21(4):393–404</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0097-8493%2897%2900030-7" aria-label="View reference 47">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 47 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Haptics%20in%20virtual%20environments%3A%20taxonomy%2C%20research%20status%2C%20and%20challenges&amp;journal=Comput%20Graph&amp;volume=21&amp;issue=4&amp;pages=393-404&amp;publication_year=1997&amp;author=Srinivasan%2CMA&amp;author=Basdogan%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="MA. Srinivasan, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Srinivasan MA (1995) Virtual reality: scientific and technical challenges. In: Durlach NI, Mavor AS (eds) Repo" /><p class="c-article-references__text" id="ref-CR48">Srinivasan MA (1995) Virtual reality: scientific and technical challenges. In: Durlach NI, Mavor AS (eds) Report of the committee on virtual reality research and development, National Research Council. National Academy Press, Washington, pp 161–187</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 48 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Report%20of%20the%20committee%20on%20virtual%20reality%20research%20and%20development%2C%20National%20Research%20Council&amp;pages=161-187&amp;publication_year=1995&amp;author=Srinivasan%2CMA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JAK. Suykens, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Suykens JAK et al (2002) Weighted least squares support vector machines: robustness and sparse approximation. " /><p class="c-article-references__text" id="ref-CR49">Suykens JAK et al (2002) Weighted least squares support vector machines: robustness and sparse approximation. Neurocomputing 48(1–4):85–105</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0925-2312%2801%2900644-0" aria-label="View reference 49">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1006.68799" aria-label="View reference 49 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 49 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Weighted%20least%20squares%20support%20vector%20machines%3A%20robustness%20and%20sparse%20approximation&amp;journal=Neurocomputing&amp;volume=48&amp;issue=1%E2%80%934&amp;pages=85-105&amp;publication_year=2002&amp;author=Suykens%2CJAK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Tukey JW (1977) Schematic and summaries (pictures and numbers). In: Tukey JW (ed) Exploratory data analysis. A" /><p class="c-article-references__text" id="ref-CR50">Tukey JW (1977) Schematic and summaries (pictures and numbers). In: Tukey JW (ed) Exploratory data analysis. Addison-Wesley Inc., pp 27–55</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Vapnik V, Golowich SE, Smola AJ (1997) Support vector method for function approximation, regression estimation" /><p class="c-article-references__text" id="ref-CR51">Vapnik V, Golowich SE, Smola AJ (1997) Support vector method for function approximation, regression estimation and signal processing. In: Mozer M, Jordan MI, Petsche T (eds) Advances in neural information processing systems 9—proceedings of the 1996 neural information processing systems conference (NIPS 1996). MIT Press, Cambridge, Dever, pp 281–287</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Welch, E. Foxlin, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Welch G, Foxlin E (2002) Motion tracking: no silver bullet, but a respectable arsenal. Comput Graph Appl IEEE " /><p class="c-article-references__text" id="ref-CR52">Welch G, Foxlin E (2002) Motion tracking: no silver bullet, but a respectable arsenal. Comput Graph Appl IEEE 22(6):24–38</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FMCG.2002.1046626" aria-label="View reference 52">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 52 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Motion%20tracking%3A%20no%20silver%20bullet%2C%20but%20a%20respectable%20arsenal&amp;journal=Comput%20Graph%20Appl%20IEEE&amp;volume=22&amp;issue=6&amp;pages=24-38&amp;publication_year=2002&amp;author=Welch%2CG&amp;author=Foxlin%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Xia, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Xia P et al (2012) A new type haptics-based virtual environment system for assembly training of complex produc" /><p class="c-article-references__text" id="ref-CR53">Xia P et al (2012) A new type haptics-based virtual environment system for assembly training of complex products. Int J Adv Manuf Technol 58(1):379–396</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs00170-011-3381-8" aria-label="View reference 53">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 53 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20new%20type%20haptics-based%20virtual%20environment%20system%20for%20assembly%20training%20of%20complex%20products&amp;journal=Int%20J%20Adv%20Manuf%20Technol&amp;volume=58&amp;issue=1&amp;pages=379-396&amp;publication_year=2012&amp;author=Xia%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Yu H, Wilamowski BM (2011) Levenberg–Marquardt training. In: Industrial electronics handbook—intelligent syste" /><p class="c-article-references__text" id="ref-CR54">Yu H, Wilamowski BM (2011) Levenberg–Marquardt training. In: Industrial electronics handbook—intelligent systems, vol 5. CRC Press, Inc., pp 12–1–12–15</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Zachmann G (1997) Distortion correction of magnetic fields for position tracking. In: Proceedings computer gra" /><p class="c-article-references__text" id="ref-CR55">Zachmann G (1997) Distortion correction of magnetic fields for position tracking. In: Proceedings computer graphics international, pp 213–220, 251</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-016-0303-y-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">IBISC Laboratory, University of Evry Val-d’Essonne, Évry, France</p><p class="c-article-author-affiliation__authors-list">M’hamed Frad, Hichem Maaref &amp; Samir Otmane</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">EµE Laboratory, University of Monastir, Monastir, Tunisia</p><p class="c-article-author-affiliation__authors-list">M’hamed Frad &amp; Abdellatif Mtibaa</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-M_hamed-Frad"><span class="c-article-authors-search__title u-h3 js-search-name">M’hamed Frad</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;M%E2%80%99hamed+Frad&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=M%E2%80%99hamed+Frad" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22M%E2%80%99hamed+Frad%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Hichem-Maaref"><span class="c-article-authors-search__title u-h3 js-search-name">Hichem Maaref</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Hichem+Maaref&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Hichem+Maaref" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Hichem+Maaref%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Samir-Otmane"><span class="c-article-authors-search__title u-h3 js-search-name">Samir Otmane</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Samir+Otmane&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Samir+Otmane" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Samir+Otmane%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Abdellatif-Mtibaa"><span class="c-article-authors-search__title u-h3 js-search-name">Abdellatif Mtibaa</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Abdellatif+Mtibaa&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Abdellatif+Mtibaa" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Abdellatif+Mtibaa%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-016-0303-y/email/correspondent/c1/new">M’hamed Frad</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=A%20hybrid%20optical%E2%80%93mechanical%20calibration%20procedure%20for%20the%20Scalable-SPIDAR%20haptic%20device&amp;author=M%E2%80%99hamed%20Frad%20et%20al&amp;contentID=10.1007%2Fs10055-016-0303-y&amp;publication=1359-4338&amp;publicationDate=2016-12-10&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-016-0303-y" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-016-0303-y" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Frad, M., Maaref, H., Otmane, S. <i>et al.</i> A hybrid optical–mechanical calibration procedure for the Scalable-SPIDAR haptic device.
                    <i>Virtual Reality</i> <b>21, </b>109–125 (2017). https://doi.org/10.1007/s10055-016-0303-y</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-016-0303-y.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-02-05">05 February 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-11-28">28 November 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-12-10">10 December 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2017-09">September 2017</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-016-0303-y" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-016-0303-y</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Scalable-SPIDAR</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Virtual reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Tracking</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Calibration</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Neural networks</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Support vector regression</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-016-0303-y.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=303;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

