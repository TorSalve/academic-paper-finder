<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Carpeno: interfacing remote collaborative virtual environments with ta"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Creativity is enhanced by communication and collaboration. Thus, the increasing number of distributed creative tasks requires better support from computer-mediated communication and collaborative..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/10/2.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Carpeno: interfacing remote collaborative virtual environments with table-top interaction"/>

    <meta name="dc.source" content="Virtual Reality 2006 10:2"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2006-09-07"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2006 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Creativity is enhanced by communication and collaboration. Thus, the increasing number of distributed creative tasks requires better support from computer-mediated communication and collaborative tools. In this paper we introduce &#8220;Carpeno&#8221;, a new system for facilitating intuitive face-to-face and remote collaboration on creative tasks. Normally the most popular and efficient way for people to collaborate is face-to-face, sitting around a table. Computer augmented surface environments, in particular interactive table-top environments, are increasingly used to support face-to-face meetings. They help co-located teams to develop new ideas by facilitating the presentation, manipulation, and exchange of shared digital documents displayed on the table-top surface. Users can see each other at the same time as the information they are talking about. In this way the task space and communication space can be brought together in a more natural and intuitive way. The discussion of digital content is redirected from a computer screen, back to a table where people can gather around. In contrast, collaborative virtual environments (CVE) are used to support remote collaboration. They frequently create familiar discussion scenarios for remote interlocutors by utilizing room metaphors. Here, virtual avatars and table metaphors are used, where the participants can get together and communicate with each other in a way that allows behaviour that is as close to face-to-face collaboration as possible. The Carpeno system described here combines table-top interaction with a CVE to support intuitive face-to-face and remote collaboration. This allows for simultaneous co-located and remote collaboration around a common, interactive table."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2006-09-07"/>

    <meta name="prism.volume" content="10"/>

    <meta name="prism.number" content="2"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="95"/>

    <meta name="prism.endingPage" content="107"/>

    <meta name="prism.copyright" content="2006 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-006-0045-3"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-006-0045-3"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-006-0045-3.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-006-0045-3"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Carpeno: interfacing remote collaborative virtual environments with table-top interaction"/>

    <meta name="citation_volume" content="10"/>

    <meta name="citation_issue" content="2"/>

    <meta name="citation_publication_date" content="2006/10"/>

    <meta name="citation_online_date" content="2006/09/07"/>

    <meta name="citation_firstpage" content="95"/>

    <meta name="citation_lastpage" content="107"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-006-0045-3"/>

    <meta name="DOI" content="10.1007/s10055-006-0045-3"/>

    <meta name="citation_doi" content="10.1007/s10055-006-0045-3"/>

    <meta name="description" content="Creativity is enhanced by communication and collaboration. Thus, the increasing number of distributed creative tasks requires better support from computer-"/>

    <meta name="dc.creator" content="Holger Regenbrecht"/>

    <meta name="dc.creator" content="Michael Haller"/>

    <meta name="dc.creator" content="Joerg Hauber"/>

    <meta name="dc.creator" content="Mark Billinghurst"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=Computer Animat Virtual Worlds; citation_title=Remote collaboration on desk-sized displays; citation_author=M Ashdown, P Robinson; citation_volume=16; citation_issue=1; citation_publication_date=2005; citation_pages=41-51; citation_doi=10.1002/cav.55; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_journal_title=Commun ACM; citation_title=Collaborative augmented reality; citation_author=M Billinghurst, H Kato; citation_volume=45; citation_issue=7; citation_publication_date=2002; citation_pages=64-70; citation_doi=10.1145/514236.514265; citation_id=CR2"/>

    <meta name="citation_reference" content="citation_journal_title=ACM transactions on graphics; citation_title=VisionWand: interaction techniques for large displays using a passive wand tracked in 3D; citation_author=X Cao, R Balakrishnan; citation_volume=23; citation_publication_date=2004; citation_pages=729; citation_id=CR3"/>

    <meta name="citation_reference" content="Collins M (2004) Eccentric contraptions: an amazing gadgets, gizmos and thingamambobs. David &amp; Charles, Newton Abbott"/>

    <meta name="citation_reference" content="Gutwin C, Greenberg S (1996) Workspace awareness for groupware. In: Tauber M. J. (ed) Conference companion on human factors in computing systems: common ground, Vancouver, CHI &#8217;96, April 13&#8211;18, 1996,"/>

    <meta name="citation_reference" content="Haller M, Leithinger D, Leitner J, Seifried T (2005) An augmented surface environment for storyboard presentations. ACM SIGGRAPH 2005, Poster Session, Los Angeles, August 2005 "/>

    <meta name="citation_reference" content="Hauber J, Billinghurst M, Regenbrecht H (2004) Tangible teleconferencing. In: Proceedings of the sixth Asia Pacific conference on human computer interaction (APCHI 2004), Rotorua, 29 June&#8211;2 July, 2004. Lecture notes in computer science 3101, Springer, Berlin Heidelberg New York, pp. 143&#8211;152"/>

    <meta name="citation_reference" content="Hauber J, Regenbrecht H, Hills A, Cockburn A, Billinghurst M (2005) Social Presence in two- and three-dimensional videoconferencing. In: Proceedings of eighth annual international workshop on presence, London/UK, September 21&#8211;23, 2005, pp. 189&#8211;198"/>

    <meta name="citation_reference" content="Hills A, Hauber J, Regenbrecht H (2005) Videos in space: a study on presence in video mediating communication systems. Short paper in proceedings of ICAT University of Canterbury, New Zealand, 5&#8211;8 December, 2005"/>

    <meta name="citation_reference" content="Haller M, Leithinger D, Leitner J, Seifried T (2005) An augmented surface environment for storyboard presentations. ACM SIGGRAPH 2005, Poster Session, Los Angeles, August 2005 "/>

    <meta name="citation_reference" content="Hollan J, Stornetta S (1992) Beyond being there. In: Proceedings of the SIGCHI conference on human factors in computing systems. ACM, Monterey, 1992, pp. 119&#8211;125"/>

    <meta name="citation_reference" content="Inkpen K (1997) Adapting the human computer interface to support collaborative learning environments for children. PhD Dissertation, Department of Computer Science, University of British Columbia, 1997"/>

    <meta name="citation_reference" content="Ishii H, Ullmer B (1997) Tangible bits: towards seamless interfaces between people, bits and atoms. In: Proceedings of conference on human factors in computing systems (CHI &#8216;97). ACM, Atlanta, March 1997, pp. 234&#8211;241"/>

    <meta name="citation_reference" content="Kauff P, Schreer O (2002) An immersive 3D video-conferencing system using shared virtual team user environments. In: Proceedings of the fourth international conference on collaborative virtual environments. ACM, Bonn, 2002, pp. 105&#8211;112"/>

    <meta name="citation_reference" content="citation_title=The art of Innovation; citation_publication_date=2001; citation_id=CR15; citation_author=T Kelly; citation_publisher=Doubleday/Random House"/>

    <meta name="citation_reference" content="Nakanishi H, Yoshida C, Nishimura T, Ishida T (1998) FreeWalk: a three-dimensional meeting-place for communities. In: Ishida T (ed) Community computing: collaboration over global information networks. Wiley, London, pp. 55&#8211;89"/>

    <meta name="citation_reference" content="Regenbrecht H, Wagner M, Baratoff G (2002) MagicMeeting: a collaborative tangible augmented reality system. Virtual reality: systems, development and applications 6(3), Springer, Berlin Heidelberg New York, pp. 151&#8211;166"/>

    <meta name="citation_reference" content="citation_journal_title=Presence: teleoperators and virtual environments; citation_title=Using augmented virtuality for remote collaboration; citation_author=H Regenbrecht, T Lum, P Kohler, C Ott, M Wagner, W Wilke, E Mueller; citation_volume=13; citation_issue=3; citation_publication_date=2004; citation_pages=338-354; citation_id=CR18"/>

    <meta name="citation_reference" content="Rekimoto J, Saitoh M (1999) Augmented surfaces: a spatially continuous workspace for hybrid computing environments. In CHI &#8216;99: Proceedings of the SIGCHI conference on human factors in computing systems, 1999"/>

    <meta name="citation_reference" content="citation_journal_title=Human Comp Interact; citation_title=Remote conversations: The effects of mediating talk with technology; citation_author=A Sellen; citation_volume=10; citation_issue=4; citation_publication_date=1995; citation_pages=401-444; citation_doi=10.1207/s15327051hci1004_2; citation_id=CR20"/>

    <meta name="citation_reference" content="Short J, Williams E, Christie B (1976) The social psychology of telecommunications. Wiley, London"/>

    <meta name="citation_reference" content="citation_journal_title=Commun ACM; citation_title=Beyond the chalkboard: computer support for collaboration and problem solving in meetings; citation_author=M Stefik, G Foster, D Bobrow, K Kahn, S Lanning, L Suchman; citation_volume=30; citation_issue=1; citation_publication_date=1987; citation_pages=32-47; citation_id=CR22"/>

    <meta name="citation_reference" content="Stewart J, Bederson B, Druin A (1999) Single display groupware: a model for co-present collaboration. In: Proceedings of human factors in computing systems (CHI 99). ACM, Pittsburgh, pp. 286&#8211;293"/>

    <meta name="citation_reference" content="Streitz N, Prante P, R&#246;cker C, van Alphen D, Magerkurth C, Stenzel R, Plewe (2003) Ambient displays and mobile devices for the creation of social architectural spaces: supporting informal communication and social awareness in organizations. In: public and situated displays: social and interactional aspects of shared display technologies. Kluwer, Dordrecht 2003, pp. 387&#8211;409"/>

    <meta name="citation_reference" content="Tang A, Boyle M, Greenberg S (2004) Display and presence disparity in mixed presence groupware. In fifth Australasian user interface conference (AUIC2004), Dunedin. In Cockburn A (ed) Conferences in research and practice in information technology, vol 28. "/>

    <meta name="citation_reference" content="Vertegaal R (1999) The GAZE groupware system: mediating joint attention in multiparty communication and collaboration. In: Proceedings of the SIGCHI conference on human factors in computing systems: the CHI is the limit. ACM, Pittsburgh, 1999, pp. 294&#8211;301"/>

    <meta name="citation_author" content="Holger Regenbrecht"/>

    <meta name="citation_author_email" content="holger@infoscience.otago.ac.nz"/>

    <meta name="citation_author_institution" content="Information Science, University of Otago, Dunedin, New Zealand"/>

    <meta name="citation_author" content="Michael Haller"/>

    <meta name="citation_author_institution" content="Upper Austria University of Applied Sciences, Frank-Fritsch-Stra&#223;e, Austria"/>

    <meta name="citation_author" content="Joerg Hauber"/>

    <meta name="citation_author_institution" content="University of Canterbury, Christchurch, New Zealand"/>

    <meta name="citation_author" content="Mark Billinghurst"/>

    <meta name="citation_author_institution" content="University of Canterbury, Christchurch, New Zealand"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-006-0045-3&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2006/10/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-006-0045-3"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Carpeno: interfacing remote collaborative virtual environments with table-top interaction"/>
        <meta property="og:description" content="Creativity is enhanced by communication and collaboration. Thus, the increasing number of distributed creative tasks requires better support from computer-mediated communication and collaborative tools. In this paper we introduce “Carpeno”, a new system for facilitating intuitive face-to-face and remote collaboration on creative tasks. Normally the most popular and efficient way for people to collaborate is face-to-face, sitting around a table. Computer augmented surface environments, in particular interactive table-top environments, are increasingly used to support face-to-face meetings. They help co-located teams to develop new ideas by facilitating the presentation, manipulation, and exchange of shared digital documents displayed on the table-top surface. Users can see each other at the same time as the information they are talking about. In this way the task space and communication space can be brought together in a more natural and intuitive way. The discussion of digital content is redirected from a computer screen, back to a table where people can gather around. In contrast, collaborative virtual environments (CVE) are used to support remote collaboration. They frequently create familiar discussion scenarios for remote interlocutors by utilizing room metaphors. Here, virtual avatars and table metaphors are used, where the participants can get together and communicate with each other in a way that allows behaviour that is as close to face-to-face collaboration as possible. The Carpeno system described here combines table-top interaction with a CVE to support intuitive face-to-face and remote collaboration. This allows for simultaneous co-located and remote collaboration around a common, interactive table."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Carpeno: interfacing remote collaborative virtual environments with table-top interaction | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-006-0045-3","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Collaborative work, CSCW, Virtual environments, Table-top interfaces, Teleconferencing","kwrd":["Collaborative_work","CSCW","Virtual_environments","Table-top_interfaces","Teleconferencing"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-006-0045-3","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-006-0045-3","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=45;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-006-0045-3">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Carpeno: interfacing remote collaborative virtual environments with table-top interaction
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-006-0045-3.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-006-0045-3.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2006-09-07" itemprop="datePublished">07 September 2006</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Carpeno: interfacing remote collaborative virtual environments with table-top interaction</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Holger-Regenbrecht" data-author-popup="auth-Holger-Regenbrecht" data-corresp-id="c1">Holger Regenbrecht<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Otago" /><meta itemprop="address" content="grid.29980.3a, 0000000419367830, Information Science, University of Otago, P.O. Box 56, Dunedin, New Zealand" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Michael-Haller" data-author-popup="auth-Michael-Haller">Michael Haller</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Upper Austria University of Applied Sciences" /><meta itemprop="address" content="grid.425061.4, 0000 0004 0469 7490, Upper Austria University of Applied Sciences, Frank-Fritsch-Straße, Upper Austria, Austria" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Joerg-Hauber" data-author-popup="auth-Joerg-Hauber">Joerg Hauber</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Canterbury" /><meta itemprop="address" content="grid.21006.35, 0000000121791970, University of Canterbury, Christchurch, New Zealand" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Mark-Billinghurst" data-author-popup="auth-Mark-Billinghurst">Mark Billinghurst</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Canterbury" /><meta itemprop="address" content="grid.21006.35, 0000000121791970, University of Canterbury, Christchurch, New Zealand" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 10</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">95</span>–<span itemprop="pageEnd">107</span>(<span data-test="article-publication-year">2006</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">227 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">14 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">6 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-006-0045-3/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Creativity is enhanced by communication and collaboration. Thus, the increasing number of distributed creative tasks requires better support from computer-mediated communication and collaborative tools. In this paper we introduce “Carpeno”, a new system for facilitating intuitive face-to-face and remote collaboration on creative tasks. Normally the most popular and efficient way for people to collaborate is face-to-face, sitting around a table. Computer augmented surface environments, in particular interactive table-top environments, are increasingly used to support face-to-face meetings. They help co-located teams to develop new ideas by facilitating the presentation, manipulation, and exchange of shared digital documents displayed on the table-top surface. Users can see each other at the same time as the information they are talking about. In this way the task space and communication space can be brought together in a more natural and intuitive way. The discussion of digital content is redirected from a computer screen, back to a table where people can gather around. In contrast, collaborative virtual environments (CVE) are used to support remote collaboration. They frequently create familiar discussion scenarios for remote interlocutors by utilizing room metaphors. Here, virtual avatars and table metaphors are used, where the participants can get together and communicate with each other in a way that allows behaviour that is as close to face-to-face collaboration as possible. The Carpeno system described here combines table-top interaction with a CVE to support intuitive face-to-face and remote collaboration. This allows for simultaneous co-located and remote collaboration around a common, interactive table.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>In recent years computing and communication has become tightly connected so it is easier than ever before for remote teams to work together. Despite this, current remote collaborative tools do not support the easy interchange of ideas that occur in a face-to-face brainstorming session. In this case people are able to use speech, gesture, gaze, interaction with real objects and other non-verbal cues to rapidly explore different ideas. In addition, there is a need to provide technology that can capture and enhance face-to-face meetings, such as digital whiteboards and interactive tables.</p><p>The central question that we are interested in exploring is: how can we create a computer supported environment which enhances face-to-face collaboration while at the same time allowing remote team members to work as closely together as if they were all sitting around a single real table.</p><p>A tool dedicated to group processes has to support the inherent requirements of a creative environment (Kelly <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Kelly T (2001) The art of innovation. Doubleday/Random House, New York" href="/article/10.1007/s10055-006-0045-3#ref-CR15" id="ref-link-section-d91864e359">2001</a>):</p><ul class="u-list-style-bullet">
                  <li>
                    <p>The group members have to be able to communicate their ideas verbally and non-verbally, so they can build on top of each other’s ideas.</p>
                  </li>
                  <li>
                    <p>Group members need to be able to visualize ideas through use of sketching, image presentation and document sharing</p>
                  </li>
                  <li>
                    <p>Group members need to be able to work with real world objects, including creating new or modifying objects and showing examples to others.</p>
                  </li>
                </ul><p>The tool to be developed has to deal with three elements: creative people working in a creative space focusing on the creative task. Creative people are the target users, such as designers, and architects, who work in domains requiring original idea generation. The creative space is an environment, which should be as close as possible to a face-to-face situation, which generally proves to be the most creative settings. Creative tasks are those where the goal is divergent rather than convergent thinking and where group result is supposed to be better than any individual outcome.</p><p>These requirements are challenging, however, in this paper we present a prototype system that has many of the elements of an ideal interface for supporting face-to-face and remote collaboration. In the next section we review related work from earlier research in enhancing face-to-face collaboration and enabling remote collaboration. Then we describe two of our earlier prototype systems, cAR/PE! and Coeno, and our current integrated system, Carpeno, which uses elements from both of these prototypes. Finally we present an exploratory usability study, which evaluates the Carpeno prototype and gives some directions for future research.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Related work</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Enhancing face-to-face collaboration</h3><p>Early attempts at computer enhanced face-to-face collaboration involved conference rooms in which each participant had their own networked-desktop computer that allowed them to send text or data to each other. However, these computer conference rooms were largely unsuccessful partly because of the lack of a common workspace (Inkpen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Inkpen K (1997) Adapting the human computer interface to support collaborative learning environments for children. PhD Dissertation, Department of Computer Science, University of British Columbia, 1997" href="/article/10.1007/s10055-006-0045-3#ref-CR12" id="ref-link-section-d91864e394">1997</a>).</p><p>An early improvement was using a video projector to provide a public display space. For example the Colab room at Xerox PARC (Stefik et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Stefik M, Foster G, Bobrow D, Kahn K, Lanning S, Suchman L (1987) Beyond the chalkboard: computer support for collaboration and problem solving in meetings. Commun ACM. 30(1), pp. 32–47" href="/article/10.1007/s10055-006-0045-3#ref-CR22" id="ref-link-section-d91864e400">1987</a>) had an electronic whiteboard that any participant could use to display information to others. The importance of a central display for supporting face-to-face meetings has been recognized by the developers of large interactive commercial displays (such as the SMARTBoard DViT.<sup><a href="#Fn1"><span class="u-visually-hidden">Footnote </span>1</a></sup>)</p><p>In normal face-to-face conversation, people are able to equally contribute and interact with each other and with objects in the real world. However, with large shared displays it is difficult to have equal collaboration when only one of the users has the input device, or the software does not support parallel input. In recent years (Stewart et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Stewart J, Bederson B, Druin A (1999) Single display groupware: a model for co-present collaboration. In: Proceedings of human factors in computing systems (CHI 99). ACM, Pittsburgh, pp. 286–293" href="/article/10.1007/s10055-006-0045-3#ref-CR23" id="ref-link-section-d91864e411">1999</a>) coined the term single display groupware (SDG) to describe groupware systems, which support multiple input channels, coupled to a single display. They have found that SDG systems eliminate conflict among users for input devices, enabling more work to be done in parallel by reducing turn-taking, and strengthening communication and collaboration.</p><p>In general, traditional desktop interface metaphors are less usable on large displays. For example, pull down menus may no longer be accessible, keyboard input may be difficult, and the mouse requires movement over large distances (Cao and Balakrishnan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Cao X, Balakrishnan R (2004) VisionWand: interaction techniques for large displays using a passive wand tracked in 3D. ACM transactions on graphics, 23(3). In: Proceedings of SIGGRAPH 2004, p. 729" href="/article/10.1007/s10055-006-0045-3#ref-CR3" id="ref-link-section-d91864e417">2004</a>). A greater problem is that traditional desktop input devices do not allow people to use free-hand gesture or object-based interaction as they normally would in face-to-face collaboration. Researchers such as Ishii and Ullmer (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Ishii H, Ullmer B (1997) Tangible bits: towards seamless interfaces between people, bits and atoms. In: Proceedings of conference on human factors in computing systems (CHI ‘97). ACM, Atlanta, March 1997, pp. 234–241" href="/article/10.1007/s10055-006-0045-3#ref-CR13" id="ref-link-section-d91864e420">1997</a>) have explored the use of tangible object interfaces for table-top collaboration while Streitz et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Streitz N, Prante P, Röcker C, van Alphen D, Magerkurth C, Stenzel R, Plewe (2003) Ambient displays and mobile devices for the creation of social architectural spaces: supporting informal communication and social awareness in organizations. In: public and situated displays: social and interactional aspects of shared display technologies. Kluwer, Dordrecht 2003, pp. 387–409" href="/article/10.1007/s10055-006-0045-3#ref-CR24" id="ref-link-section-d91864e423">2003</a>) use natural gesture and object based interaction in their i-Land smart space. In both cases people find the interfaces easy to use and a natural extension of how they normally interact with the real world.</p><p>In many interfaces there is a shared projected display visible by all participants; however, collaborative spaces can also support private data viewing. In Rekimoto’s Augmented Surface interface (Rekimoto and Saitoh <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Rekimoto J, Saitoh M (1999) Augmented surfaces: a spatially continuous workspace for hybrid computing environments. In CHI ‘99: Proceedings of the SIGCHI conference on human factors in computing systems, 1999" href="/article/10.1007/s10055-006-0045-3#ref-CR19" id="ref-link-section-d91864e430">1999</a>), users are able to bring their own laptop computers to a face-to-face meeting and drag data from their private desktops onto a table or wall display area. They use an interaction technique called hyper-dragging which allows the projected display to become an extension of their own personal desktop. Hyper-dragging allows users to see the information their partner is manipulating in the shared space, so it becomes an extension of the normal non-verbal gestures used in face-to-face collaboration. In this way the task space becomes a part of the personal space.</p><h3 class="c-article__sub-heading" id="Sec4">Enabling remote collaboration</h3><p>Although being in one place and talking to another person face-to-face can be considered the gold standard for collaboration, it is not always possible, economical, or otherwise desirable for people to come together in the same location. In that case they alternatively rely on teleconferencing systems that support effective collaboration at a distance.</p><p>Many researchers from the fields of CSCW (computer supported cooperative Work), HCI (human computer interaction) (Gutwin and Greenberg <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Gutwin C, Greenberg S (1996) Workspace awareness for groupware. In: Tauber M. J. (ed) Conference companion on human factors in computing systems: common ground, Vancouver, CHI ’96, April 13–18, 1996," href="/article/10.1007/s10055-006-0045-3#ref-CR5" id="ref-link-section-d91864e443">1996</a>; Sellen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Sellen A (1995) Remote conversations: The effects of mediating talk with technology. Human Comp Interact 10(4):401–444" href="/article/10.1007/s10055-006-0045-3#ref-CR20" id="ref-link-section-d91864e446">1995</a>) and social psychology (Short et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1976" title="Short J, Williams E, Christie B (1976) The social psychology of telecommunications. Wiley, London" href="/article/10.1007/s10055-006-0045-3#ref-CR21" id="ref-link-section-d91864e449">1976</a>) have explored the complex issues around distant communication and remote collaboration. They have tried to understand how systems for remote collaboration should be designed to mediate human activities in a way that allows people at a distance to accomplish tasks with the same efficiency and satisfaction as if being co-located, ideally even going beyond that (Hollan and Stornetta <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Hollan J, Stornetta S (1992) Beyond being there. In: Proceedings of the SIGCHI conference on human factors in computing systems. ACM, Monterey, 1992, pp. 119–125" href="/article/10.1007/s10055-006-0045-3#ref-CR11" id="ref-link-section-d91864e452">1992</a>).</p><p>In that context, videoconferencing (VC) technology has always played and still plays an increasingly important role as it provides a rich communication environment that allows the real-time exchange of visual information including facial expression and hand gestures. A growing number of organisations nowadays use advanced video based collaboration-networks like for example the AccessGrid,<sup><a href="#Fn2"><span class="u-visually-hidden">Footnote </span>2</a></sup> or Halo<sup><a href="#Fn3"><span class="u-visually-hidden">Footnote </span>3</a></sup> system developed by HP for group-to-group meetings on a daily basis. Although the installation and operation costs for these systems seem high, they still prove effective at supporting tasks over a distance, thus making travel redundant. However, although systems like these are capable of producing videos with high-grade audio and image quality, a remote encounter for people in front of the cameras often feels rather formal and artificial. The spontaneity and natural interaction that we take for granted in face-to-face meetings is inhibited by the absence of spatial cues (such as eye-contact), by the lack of a shared social and physical context, and by a limited possibility for informal communication. In fact, as various studies have proven, people’s communication behaviour while being connected through a standard audio–video link more closely resembles that of people talking over a phone than of people talking from face-to-face (Inkpen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Inkpen K (1997) Adapting the human computer interface to support collaborative learning environments for children. PhD Dissertation, Department of Computer Science, University of British Columbia, 1997" href="/article/10.1007/s10055-006-0045-3#ref-CR12" id="ref-link-section-d91864e468">1997</a>; Kelly <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Kelly T (2001) The art of innovation. Doubleday/Random House, New York" href="/article/10.1007/s10055-006-0045-3#ref-CR15" id="ref-link-section-d91864e471">2001</a>). While this might not greatly affect tasks that involve the exchange and the presentation of existing information and documents, it does have a negative impact on tasks of a more creative nature.</p><p>In an attempt to simulate traditional face-to-face meetings more closely and eventually overcome the formal and mediated character of standard videoconferencing interfaces, various three-dimensional metaphors have been developed in videoconferencing applications. Early work introduced spatially positioned video and audio streams into the conferencing space [FreeWalk (Nakanishi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Nakanishi H, Yoshida C, Nishimura T, Ishida T (1998) FreeWalk: a three-dimensional meeting-place for communities. In: Ishida T (ed) Community computing: collaboration over global information networks. Wiley, London, pp. 55–89" href="/article/10.1007/s10055-006-0045-3#ref-CR16" id="ref-link-section-d91864e477">1998</a>), Gaze (Vertegaal <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Vertegaal R (1999) The GAZE groupware system: mediating joint attention in multiparty communication and collaboration. In: Proceedings of the SIGCHI conference on human factors in computing systems: the CHI is the limit. ACM, Pittsburgh, 1999, pp. 294–301" href="/article/10.1007/s10055-006-0045-3#ref-CR26" id="ref-link-section-d91864e480">1999</a>), VIRTUE (Kauff and Schreer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Kauff P, Schreer O (2002) An immersive 3D video-conferencing system using shared virtual team user environments. In: Proceedings of the fourth international conference on collaborative virtual environments. ACM, Bonn, 2002, pp. 105–112" href="/article/10.1007/s10055-006-0045-3#ref-CR14" id="ref-link-section-d91864e483">2002</a>)], but without the addition of virtual content to be discussed in such a meeting. In contrast, SmartMeeting<sup><a href="#Fn4"><span class="u-visually-hidden">Footnote </span>4</a></sup> provides a highly realistic conference environment with virtual rooms with chairs, whiteboards, multi-media projectors, and even an interactive chessboard, but without spatially placed video representations of the participants. AliceStreet<sup><a href="#Fn5"><span class="u-visually-hidden">Footnote </span>5</a></sup> makes use of a similar concept, although with a more minimalist virtual room design, but the participants are represented here as rotating video planes sitting around a virtual table at fixed positions and watching each other or a shared presentation screen capable of displaying presentation slides.</p><p>The common goal of all of these approaches is to improve the usability of remote collaboration systems by decreasing the artificial character of a remote encounter.</p><h3 class="c-article__sub-heading" id="Sec5">Mixed presence groupware</h3><p>Systems that support multiple simultaneous users interacting on a single shared display are categorized as single display groupware (SDG) (Stewart et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Stewart J, Bederson B, Druin A (1999) Single display groupware: a model for co-present collaboration. In: Proceedings of human factors in computing systems (CHI 99). ACM, Pittsburgh, pp. 286–293" href="/article/10.1007/s10055-006-0045-3#ref-CR23" id="ref-link-section-d91864e507">1999</a>). If a shared visual workspace also supports distributed participants in real-time, one can label such a system as multiple presence groupware (MPG) (Tang et al <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Tang A, Boyle M, Greenberg S (2004) Display and presence disparity in mixed presence groupware. In fifth Australasian user interface conference (AUIC2004), Dunedin. In Cockburn A (ed) Conferences in research and practice in information technology, vol 28. " href="/article/10.1007/s10055-006-0045-3#ref-CR25" id="ref-link-section-d91864e510">2004</a>; Ashdown and Robinson <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Ashdown M, Robinson P (2005) Remote collaboration on desk-sized displays. Computer Animat Virtual Worlds 16(1): 41–51" href="/article/10.1007/s10055-006-0045-3#ref-CR1" id="ref-link-section-d91864e513">2005</a>). If placed into a place/time groupware matrix (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0045-3#Fig1">1</a>) it spans over the two places segments while still being synchronous.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Mixed presence groupware in place/time matrix</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Tang et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Tang A, Boyle M, Greenberg S (2004) Display and presence disparity in mixed presence groupware. In fifth Australasian user interface conference (AUIC2004), Dunedin. In Cockburn A (ed) Conferences in research and practice in information technology, vol 28. " href="/article/10.1007/s10055-006-0045-3#ref-CR25" id="ref-link-section-d91864e540">2004</a>) identified only few MPG systems to date, a cave-like environment by SICS (Touch Desktop), Microsoft’s Halo, a split screen environment for the Xbox, and two video-overlaying systems without spatial arrangements of the participants. They found two main problems in using MPG systems: (1) display disparity: considering the appropriate arrangement of persons and artefacts when using a mix of horizontal and vertical displays and (2) presence disparity: the perception of the presence of others depending on whether s/he is co-located or remote. In our research presented in this article we will address both problems and try to find (partial) solutions.</p></div></div></section><section aria-labelledby="Sec6"><div class="c-article-section" id="Sec6-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec6">System concepts used</h2><div class="c-article-section__content" id="Sec6-content"><p>Our approach is novel in that it combines and integrates several vital features found in other earlier work:</p><ul class="u-list-style-bullet">
                  <li>
                    <p>We make use of a horizontal, interactive workspace to support creative group processes in a natural way and allow remote group members to be part of that process avoiding presence disparities.</p>
                  </li>
                  <li>
                    <p>We combine interfaces of the remote and co-located worlds in a natural and easy-to-use way.</p>
                  </li>
                  <li>
                    <p>We provide a system seamlessly combining a vertical and horizontal display system in a way that minimizes display disparities.</p>
                  </li>
                  <li>
                    <p>We integrate the task space (data) within the workspace (table environment) providing both with a task to focus on and a creative atmosphere.</p>
                  </li>
                  <li>
                    <p>We offer private and public workspaces at different levels for all group members regardless of their location.</p>
                  </li>
                </ul><p>In the following we present in brief our earlier existing systems and how we combined them to create a novel collaborative environment.</p><h3 class="c-article__sub-heading" id="Sec7">3D teleconferencing system: cAR/PE!</h3><p>cAR/PE! is a teleconferencing system used with commonly available equipment: a PC with a web camera and a headset. It is designed for small group collaboration between Internet networked computers and it integrates data distribution and presentation with communication capabilities. cAR/PE! simulates a face-to-face meeting in a room and therefore uses the metaphor of a three-dimensional conference room (Regenbrecht et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Regenbrecht H, Lum T, Kohler P, Ott C, Wagner M, Wilke W, Mueller E (2004) Using augmented virtuality for remote collaboration. Presence: teleoperators and virtual environments 13(3), MIT Press, Cambridge, pp. 338–354" href="/article/10.1007/s10055-006-0045-3#ref-CR18" id="ref-link-section-d91864e587">2004</a>).</p><p>All participants meet in this room and are represented by video avatars The virtual room is “furnished” with a meeting table and several presentation screens to be used in a way as close as possible to a real world meeting (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0045-3#Fig2">2</a>). The participants can freely move around within this room, can place slides, movies, or pictures on the virtual screens or on the table, can share remote computer screens in an interactive way, and can put three dimensional virtual models onto the table to be discussed with others. The person’s movement within the room is visible to all other participants easing gaze and workspace awareness. This awareness is further supported by the provision of three-dimensional sound (in particular to hear others from the right direction even they are not in the current field of view).
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Views (screenshots) into the cAR/PE! room</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>From a technological point of view, cAR/PE! stations are connected via standard Internet as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0045-3#Fig3">3</a>. Up to six stations can be connected forming one virtual meeting space. The maximal number of stations depends on the bandwidth available and with standard ADSL connections three stations can be used with a good overall quality. All audio and video streams as well as the data distribution are implemented point-to-point, mainly for security reasons. All interactions occurring in a session (e.g. the movement of the participants within the room or changing slides on the virtual projection screen) are sent to a common request broker, which delivers the results to all stations. Supplemental remote computers can be connected to this cAR/PE! network. The content of the displays of these computers is displayed within the virtual cAR/PE! environment and can be operated interactively from within the meeting room.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>cAR/PE! connection scheme</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Given these capabilities, the cAR/PE! system allows for synchronous collaboration over a distance while trying to maintain the metaphor of a traditional face-to-face meeting. Remotely located participants are able to focus on their task and data (shared place) and to communicate in a natural way (shared space), because of the integration of both domains: data and communication.</p><p>The system has been used in pilot installations in industry and academia and usability and social presence successfully evaluated with hundreds of subjects (Regenbrecht et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Regenbrecht H, Lum T, Kohler P, Ott C, Wagner M, Wilke W, Mueller E (2004) Using augmented virtuality for remote collaboration. Presence: teleoperators and virtual environments 13(3), MIT Press, Cambridge, pp. 338–354" href="/article/10.1007/s10055-006-0045-3#ref-CR18" id="ref-link-section-d91864e644">2004</a>; Hauber et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Hauber J, Regenbrecht H, Hills A, Cockburn A, Billinghurst M (2005) Social Presence in two- and three-dimensional videoconferencing. In: Proceedings of eighth annual international workshop on presence, London/UK, September 21–23, 2005, pp. 189–198" href="/article/10.1007/s10055-006-0045-3#ref-CR8" id="ref-link-section-d91864e647">2005</a>; Hills et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Hills A, Hauber J, Regenbrecht H (2005) Videos in space: a study on presence in video mediating communication systems. Short paper in proceedings of ICAT University of Canterbury, New Zealand, 5–8 December, 2005" href="/article/10.1007/s10055-006-0045-3#ref-CR9" id="ref-link-section-d91864e650">2005</a>).</p><p>Some desired interface functionality could not be supported yet, because of the technology used, or the inherent limitations of this dedicated distant communication and collaboration tool. For instance, by its very nature tangibility input is not supported by any means. Users operate the system using a traditional mouse and therefore all interactions are virtual. To visualize ideas in a real world scenario one would probably use paper and pen or a whiteboard, in a mouse operated virtual room this is inconvenient and less natural. In addition, co-located collaboration and the transmission of most non-verbal cues are poorly supported, even when used in combination with a projection system.</p><h3 class="c-article__sub-heading" id="Sec8">Co-located table-top system: Coeno</h3><p>Collaborative table-top setups are becoming increasingly popular for creative tasks. Coeno, is a collaborative table-top environment that is designed for brainstorming and discussion meetings. In Coeno, we particularly focus on a novel ubiquitous environment for creative sketching, drawing, and brainstorming (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0045-3#Fig4">4</a>).
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig4_HTML.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig4_HTML.jpg" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>People can discuss and brainstorm by directly interacting with the table and presenting their results on a rear-projection screen (<b>a</b>). Moreover, we support natural input devices (e.g. digital pens) (<b>b</b>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>The application incorporates multiple devices and novel interaction metaphors supporting content creation in an easy-to-use environment. Our installation offers a cooperative and social experience by allowing multiple face-to-face participants to interact easily around the shared workspace, while also having access to their own private information space and a public presentation space.</p><p>The installation itself consists of two main modules (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0045-3#Fig5">5</a>):</p><ol class="u-list-style-none">
                    <li>
                      <span class="u-custom-list-number">1.</span>
                      
                        <p>An Interactive Table, combining the benefits of a traditional table with all the functionalities of an interactive surface and display. The table allows people to easily access digital data and re-arrange both scribbles and virtual sketches in an intuitive way using different interaction tools.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">2.</span>
                      
                        <p>An Interactive Wall, consisting of an optically tracked rear-projection screen that displays digital content and captures gesture input. Combined with the Interactive Table, data can be seamlessly transformed from all presentation sources to the presentation wall.</p>
                      
                    </li>
                  </ol><p>The interface consists of two ceiling and one wall mounted projectors showing data on a table surface (Interactive Table) and on a rear-projection screen (Interactive Wall). All users can sit at the table and connect their own laptop and/or tablet PC computer to the display server. There is no limit as to how many clients can connect simultaneously to the system and the amount of co-located participants depends on the space around the table. In our case, typically 4–5 participants are involved in a meeting, where one of the participants usually leads the session.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Coeno system configuration</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Participants can interact with the table in several ways. They can either use their personal devices (e.g. tablet PC) wirelessly connected to the server, or a digital pen. Designers can create imagery on their own personal computers and “move” them to the interactive table for further discussion using hyper-dragging as proposed by Rekimoto et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Rekimoto J, Saitoh M (1999) Augmented surfaces: a spatially continuous workspace for hybrid computing environments. In CHI ‘99: Proceedings of the SIGCHI conference on human factors in computing systems, 1999" href="/article/10.1007/s10055-006-0045-3#ref-CR19" id="ref-link-section-d91864e743">1999</a>).</p><p>Unlike Rekimoto’s work, users can also use real paper in the interface. To digitally capture handwritten notes, participants use the Anoto<sup><a href="#Fn6"><span class="u-visually-hidden">Footnote </span>6</a></sup> digital pen system. These are ballpoint pens with an embedded IR camera that tracks the pen movement on an especially printed-paper covered with a pattern of tiny dots. We use the Maxell Pen-It device with Bluetooth wireless connectivity. In our table-top interface, we also augment the real paper with projected virtual graphics. The paper itself is tracked by using ARTag<sup><a href="#Fn7"><span class="u-visually-hidden">Footnote </span>7</a></sup> markers, placed on top of each piece of paper. Thus, participants can make annotations on real content that is combined with digital content projected on top of the paper surface.</p><p>Participants are able to use the Interactive Table as a traditional whiteboard for brainstorming tasks. We integrated a MIMIO device,<sup><a href="#Fn8"><span class="u-visually-hidden">Footnote </span>8</a></sup> with ultrasonic tracking, which enables participants to draw on the interactive table and create annotations in real-time. Finally, the Interactive Wall is a rear-projection system, which allows an intuitive gesture based interaction on a wall screen. We use a transparent rear-projection screen and track the user’s gestures with an infrared (IR) camera setup.</p><p>All of these devices can be used simultaneously and they combine input and output on one surface using several novel interaction metaphors. A closer description of the implemented interaction metaphors including a first pilot study is presented in Haller et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Haller M, Leithinger D, Leitner J, Seifried T (2005) An augmented surface environment for storyboard presentations. ACM SIGGRAPH 2005, Poster Session, Los Angeles, August 2005 " href="/article/10.1007/s10055-006-0045-3#ref-CR10" id="ref-link-section-d91864e771">2005</a>).</p><p>In summary, the Coeno interface combines three different display spaces:</p><ul class="u-list-style-bullet">
                    <li>
                      <p>
                        <i>Private </i>
                        <i>Space:</i> the users’ own hardware device (e.g. laptop/tablet PC screen) and/or the area on the table around each participant. Other users cannot see the private information of the others.</p>
                    </li>
                    <li>
                      <p>
                        <i>Design Space:</i> the shared table surface (the interactive table), only visible to those sitting around the table. This space is mainly used during the brainstorming process.</p>
                    </li>
                    <li>
                      <p>
                        <i>Presentation Space:</i> the digital whiteboard, which is visible to all people in the room and therefore part of the presentation space.</p>
                    </li>
                  </ul><p>However, Coeno does not offer a remote, collaborative functionality. Therefore, we combined the advantages of cAR/PE! and Coeno into a first prototype, Carpeno, which is described in the next section.</p></div></div></section><section aria-labelledby="Sec9"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">A combined approach: Carpeno</h2><div class="c-article-section__content" id="Sec9-content"><p>Carpeno tries to overcome the barrier between co-located and remote collaboration while maintaining the interface advantages of table-top environments for creative group processes. Therefore a combination of the cAR/PE! and Coeno systems seem to be a promising approach. We will briefly introduce our conceptual idea and show a proof of concept with an initial, exploratory user study based on a first implementation of the concept.</p><p>Our general concept is based around the obvious idea of combining the two approaches: (1) the table-top part of the Coeno environment and (2) the teleconferencing elements of cAR/PE! in a wall projection mode. The goal is to link these systems as closely together as possible to allow for a borderless communication and interaction space. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0045-3#Fig6">6</a> shows the setup in a simplified manner.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Carpeno principle</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>Coeno’s private space is preserved and the data and interface components are still used in the same or even enhanced way as the design space introduced earlier. The presentation space is replaced by a screen projection showing the remote cAR/PE! virtual meeting room environment. This should create the impression for the local participants of two tables placed next to each other: the physical local table and the remote virtual table, both interactive and suitable for information display. The remote cAR/PE! participants can still freely move around in the virtual space. With this they are able to form an own-shared space out of reach and sight of the local participants (similar to their local shared space). Both sides of the setup are coupled via (1) the display of the video and audio streams, including their (changing) locations and (2) data transfer and interactions coupled between the systems. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0045-3#Fig7">7</a> illustrates the new communication and interaction spaces with Carpeno.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig7_HTML.gif?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig7_HTML.gif" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Carpeno spaces</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>The central shared element between all participants (local and remote) is the virtual table within the (former) cAR/PE! environment, called the Common Shared Space. Local spaces are provided for each group: the local shared space on top of the physical table and the remote shared space everywhere within the cAR/PE! environment outside the reach of the local group. For example, the remote participants can choose a corner (and virtual table or presentation screen if needed) within the virtual environment and come back to the common shared space (virtual table) for discussions concerning the entire group.</p><p>The private spaces are on each side personal information systems (in most cases laptop computers or tablet PCs) connected to the Carpeno system, but only visible to the individuals. Digital content can be shared via hyper-dragging or screen sharing, visible to a sub-group (e.g. local only) or the whole group (e.g. on the virtual table). Furthermore the virtual presentation screen within the cAR/PE! environment can be made visible to all for group discussions.</p><p>With this concept a new technological infrastructure and features have to be developed. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0045-3#Fig8">8</a> illustrates how Coeno and cAR/PE! are linked together to form the seamless Carpeno system. As shown, the networked part of the cAR/PE! system remains almost entirely unchanged, while the data and interaction components are extended by the Coeno interface. We adopt a loosely coupled approach, where network-messaging techniques are used as the main software technical method. With this we are able to control almost all of the aspects of the cAR/PE! part of the system with the Coeno part and vice versa.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig8_HTML.gif?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig8_HTML.gif" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Carpeno scheme</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>A virtually infinite number of even mixed local and remote stations can be linked together without any system-inherent limitations. The main reasons not to do so are: (1) limited bandwidth and other networking issues, (2) the (virtual) placement of a certain number of persons and parties around one virtual table, and (3) interface issues that have to be solved beforehand (e.g. orientation of documents, pointers indicating interacting persons, etc.). Currently two–six co-operating parties can be brought together in one Carpeno system without serious problems.</p></div></div></section><section aria-labelledby="Sec10"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Prototype implementation</h2><div class="c-article-section__content" id="Sec10-content"><p>The first implementation of our conceptual approach serves as a test bed for evaluating the feasibility of the Carpeno concept. Our focus therefore is set on building a functioning and tangible system to be used for testing rather than on providing the most comprehensive and complex solution first. We decided not to implement and integrate all features available in cAR/PE! and Coeno but rather to develop a system which can be initially tested in exploratory studies.</p><h3 class="c-article__sub-heading" id="Sec11">System</h3><p>The initial version includes the following elements (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0045-3#Fig9">9</a>):
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig9_HTML.jpg?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig9_HTML.jpg" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Carpeno v1.0</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>A vertical Plasma projection screen (WXGA resolution) displaying the remote shared space. The size of this screen was chosen to provide a wide field of view for the local party. The screen is accompanied with speakers to display the (spatially arranged) voices of the remote participants to the local group in a convenient way.</p><p>The local shared space is defined by a touch sensitive surface<sup><a href="#Fn9"><span class="u-visually-hidden">Footnote </span>9</a></sup> on which a projector (XGA resolution) shows the augmented surface content. With this setup one person at a time from the local group can directly interact with the digital content displayed simply by using his or her finger.</p><p>The augmented surface content is provided by the cAR/PE! system: an additional computer is rendering the same environment as shown on the vertical screen, but from a correct perspective from above the physical and virtual table. With this pre-configured setup we can ensure that both sides, local and remote, see the same content on the table.</p><p>To capture the live video stream of the local participant(s), we placed an Apple iSight camera on top of the Plasma display. While the image quality of the camera is superior for teleconferencing purposes, no real eye-to-eye contact can be achieved. In a standard situation, where the remote and local participants are sitting, this is still the best camera position, because it is close to the remote participant’s eyes.</p><p>Within the shared cAR/PE! environment the virtual content on the table is provided via a VNC application-sharing component. The Coeno system connected to the network is providing this screen stream and resides on an additional computer.</p><p>In summary, three components from the cAR/PE! system are involved in the Carpeno setup: (1) the remote participant working at a standard PC screen, (2) the vertical screen (Plasma) of the local setup, and (3) the horizontal screen (touch screen) of the local setup. We have configured and calibrated these three components in a way that they form one, consistent spatial environment.</p><p>A tablet PC standing beside the touch sensitive surface provides the local private space. It is used to prepare content to be discussed in the group and to drag and drop it to and from the local shared space using the hyper-dragging metaphor. While for the users this interaction is a transparent one, the actual technical process is implemented via VNC application sharing feeding the cAR/PE! applications. All three cAR/PE! components receive the same VNC stream and display it on top of the virtual table.</p><p>All computers involved in this initial Carpeno setup are linked via a dedicated network switch, ensuring the highest possible networking performance. While we could have chosen virtually any video and audio codes in this network setup, eventually we opted for high quality videoconferencing standards (G.711 uLaw and H.261 CIF) to emulate an internet connection.</p><p>In this version we have reduced the conceptual number of possible spaces to three to ease our exploratory studies. The virtual table (common shared space) and the projection onto the physical table (local shared space) are exactly overlaid to give the impression of one single table surface. Therefore, what the remote participants see on the virtual table is exactly the same what the local participants see. In addition, we abandoned the use of additional PC’s on the remote side (remote private spaces) to avoid confusion about the interface in the first instance.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0045-3#Fig10">10</a> illustrates our implementation. The Coeno system delivers all content via the application sharing functionality of cAR/PE! (sharing parts of the computer screen) while the interaction with the content of the common shared space is controlled by the touch sensitive surface. This system allows for actual communication and interaction within the Carpeno concept and serves as the basis for our exploratory user study described in the next section.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig10_HTML.gif?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig10_HTML.gif" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Carpeno v1.0 implementation</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <h3 class="c-article__sub-heading" id="Sec12">Exploratory study</h3><p>We conducted an informal exploratory study with our first prototype system. In total forty visitors at the ICAT2005 and Graphite2005 conferences participated in a hands-on evaluation during the exhibition of our system (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0045-3#Fig11">11</a>).
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig11_HTML.jpg?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig11_HTML.jpg" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>User study at conferences</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec13">Task</h4><p>Two persons at a time took a seat at different parts of our booth. One part was configured as a Carpeno station as described in the Implementation section and the other part was set up as a cAR/PE! station using a standard PC and monitor equipped with a headset and a web cam. If only one volunteer was available, one of the exhibitors took on the role of the second person at the cAR/PE! side. Photographs of interesting looking devices that were invented during the last 200 years taken from Collins (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Collins M (2004) Eccentric contraptions: an amazing gadgets, gizmos and thingamambobs. David &amp; Charles, Newton Abbott" href="/article/10.1007/s10055-006-0045-3#ref-CR4" id="ref-link-section-d91864e1018">2004</a>) were then dragged onto the shared table by a moderator. The task for the participants was to collaboratively discuss what exactly the purpose of the displayed objects might be. If a device’s function could be guessed correctly, the moderator removed that picture from the table. All pairs had to discuss five–six different photographs in order to clear the table while playfully exploring the features of the Carpeno setup at the same time. To complete one round typically took between 5 and 8 min.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec14">Questionnaire</h4><p>After a team completed the task, both participants were asked to fill out a short questionnaire. Besides usability issues we were especially interested in finding potential research variables that would arise from the asymmetrical nature of our setup. Most results that are presented in the following section are therefore presented separately for cAR/PE! and Carpeno users.</p></div></div></section><section aria-labelledby="Sec15"><div class="c-article-section" id="Sec15-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec15">Results</h2><div class="c-article-section__content" id="Sec15-content"><p>After each session users were asked to subjectively rate the experience by answering nine seven-point Likert-scale questions. The questions and their normalised scores are summarized in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0045-3#Fig12">12</a>.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig12_HTML.gif?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0045-3/MediaObjects/10055_2006_45_Fig12_HTML.gif" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Questionnaire results by system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0045-3/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>The scores in the satisfaction questions Q1 and Q2 show that both user groups liked the system. With the exception of question Q6, the answers on general usability issues (Q3 to Q7) further show an overall positive response. The lower score of Q6 uncovers that users of both sides could not easily infer where the other person was looking at. This deserves further investigation but could be influenced by the fact that there was a very high task focus. No major differences in the usability scores emerged between the Carpeno and cAR/PE! side. However, cAR/PE! users were more aware of the other person’s presence, as can be seen in the scores of question Q8, probably due to their undisturbed concentration on one screen surface (the monitor). The biggest difference between both user groups emerged in question Q9. Carpeno users felt much more that the meeting with the other person occurred “locally”, i.e. around the physical table in front of them. On the other hand, cAR/PE! users thought the meeting took place more “remotely”, situated somewhere in the middle between their and the other person’s location.</p><p>Although we have not carried out formal statistical tests in this exploratory study, we can derive some initial lessons: </p><ol class="u-list-style-none">
                  <li>
                    <span class="u-custom-list-number">1.</span>
                    
                      <p>The low gaze awareness that appeared in question Q6 suggests that this issue demands some more attention in our setup. Applying head tracking technology that allows users to control their video avatar simply by moving their heads could deliver some improvements and would get rid of the need for mouse-based navigation. In addition, other gaze awareness support could be integrated such as the “miner’s helmet” metaphor (Vertegaal <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Vertegaal R (1999) The GAZE groupware system: mediating joint attention in multiparty communication and collaboration. In: Proceedings of the SIGCHI conference on human factors in computing systems: the CHI is the limit. ACM, Pittsburgh, 1999, pp. 294–301" href="/article/10.1007/s10055-006-0045-3#ref-CR26" id="ref-link-section-d91864e1075">1999</a>) that displays a lightspot at a person’s centre.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">2.</span>
                    
                      <p>The lower awareness of the partner’s presence in the Carpeno setup might be a result of the cAR/PE! user “disappearing” from the Carpeno user’s screen when navigating to the other side of the table in the cAR/PE! room. This often led to confusion on the Carpeno side. Seeing the other person at all times therefore seems to be crucial for the awareness of the other’s presence, even if the audio connection is maintained. In future experimental setups, we therefore have to limit the navigation space for the cAR/PE! user to an area where s/he is always visible to the Carpeno user.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">3.</span>
                    
                      <p>The clear result about the experienced location of the meeting (Q9) suggests that users are very much able to associate a remote encounter with a spatial reference frame somewhere between “here” and “there” as it is defined by the interface. To understand the effects on the user and how exactly we can move both interface types along this dimension will be part of our future research.</p>
                    
                  </li>
                </ol>
              </div></div></section><section aria-labelledby="Sec16"><div class="c-article-section" id="Sec16-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec16">Discussion and future work</h2><div class="c-article-section__content" id="Sec16-content"><p>Our conceptual approach in bringing together co-located and remote collaboration into a single system as well as our first implementation suggests that the Carpeno interface has indeed great potential for enhancing remote face-to-face collaborative creative experiences. Our initial, exploratory user study with Carpeno and the numerous experiences with the single systems cAR/PE! and Coeno lead us to understand requirements of a future Carpeno system and opens up new research areas to work on.</p><p>Our initial assumption was supported, the combination of our two systems can compensate for the flaws in interfaces detected in the separated systems. In particular the incorporation of remote participants into the co-located collaboration is possible and the provision of a table-top environment for the remote participants is of great value, especially in creative tasks like brainstorming or general discussions involving some sort of media. Eventually we can provide a common shared space as well as local shared and private spaces at the same time.</p><p>Direct manipulation on the interactive table is intuitive and can be supported by different interfaces, depending on the particular task to be addressed. For our picture sharing application finger pointing was very appropriate. Participants have different preferences and different tasks require different input devices (e.g. digital pen, tablet PC, Mimio tracking device, etc.). Therefore, one of our goals is to test the different benefits of these devices.</p><p>The incorporation of a table as the central element of our interface (real and virtual) and the consequent integration into a meeting environment (also both real and virtual) leads to the reasonable approach of (“re-”) introducing spatial objects into the process and interface. On the physical side (real world) real objects can be used as part of the creative group processes or as part of the interface (tangible user interface, see (Billinghurst and Kato <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Billinghurst M, Kato H (2002) Collaborative augmented reality. Commun ACM 45(7): 64–70" href="/article/10.1007/s10055-006-0045-3#ref-CR2" id="ref-link-section-d91864e1116">2002</a>; Hauber et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Hauber J, Billinghurst M, Regenbrecht H (2004) Tangible teleconferencing. In: Proceedings of the sixth Asia Pacific conference on human computer interaction (APCHI 2004), Rotorua, 29 June–2 July, 2004. Lecture notes in computer science 3101, Springer, Berlin Heidelberg New York, pp. 143–152" href="/article/10.1007/s10055-006-0045-3#ref-CR7" id="ref-link-section-d91864e1119">2004</a>; Regenbrecht et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Regenbrecht H, Wagner M, Baratoff G (2002) MagicMeeting: a collaborative tangible augmented reality system. Virtual reality: systems, development and applications 6(3), Springer, Berlin Heidelberg New York, pp. 151–166" href="/article/10.1007/s10055-006-0045-3#ref-CR17" id="ref-link-section-d91864e1122">2002</a>). On the virtual side (and within the virtual space) the use of 3D virtual objects representing the real world can be used also either as the object of discussion or as interface elements. Further research is needed here and should be based on existing findings and systems (in particular tangible and perceptual user interfaces, ubiquitous computing, 3D user interfaces).</p><p>For the sake of simplicity and to rapidly allow for an early exploratory study we have excluded some interfaces, which would be very relevant in non-experimental situations. We are going to amend the system with a shared digital whiteboard, better support for gesture communication, and pen-based interaction. Also, the (simultaneous) placement of documents in the shared spaces will be approached based on the experiences made with the single systems. For example, mechanisms already built-in into the Coeno system can be used for a “real estate” saving arrangement of documents onto the limited virtual and real table space.</p><p>While general gaze awareness could be provided with our Carpeno system, eye-to-eye contact is still not possible because of the different locations of the real camera and the virtual participant representation as a video stream. We are working on optical and/or IT solutions to allow for this essential aspect in certain task scenarios (like negotiations). The form of representation of the avatars itself (video stream on a moving virtual plane) was acceptable. This was already tested in earlier studies with the cAR/PE! system. However, to provide even better communication cues and channels, we are going to test whether other forms of representations (e.g. with background eliminating methods) can even enhance the overall quality.</p><p>In addition, our first implementation was mainly limited to one remote and one local person. We are exploring how the system has to be modified to add more local or remote participants. Issues that must be addressed include concerns such as: do all of the participants meet in the local (physical) or the remote (virtual) place? or how does informal communication between co-located participants affect the entire, creative process with the remote participants? These questions have to be answered in the future, involving more creative tasks besides brainstorming and/or picture sharing.</p><p>With our current, integrated approach the development of new interface metaphors and techniques considers the combined support for local and remote collaborative tasks at an early stage. It can be assumed that this consideration leads to more comprehensive and efficient interfaces suitable for both worlds, the local and the distant one. This could be a satisfactory contribution to tool and process development of a converging world of communication and information.</p><p>Last but not least, communication quality can be improved in using the Carpeno approach. Especially support of non-verbal communication cues in relation to a high level of social presence seems to be essential and can be implemented on our current basis. For instance the introduction and evaluation of head-tracking, gaze and workspace awareness supporting techniques for natural gesture recognition, and eye-to-eye contact in remote settings are part of our future research.</p></div></div></section>
                        
                    

                    <section aria-labelledby="notes"><div class="c-article-section" id="notes-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="notes">Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1"><span class="c-article-footnote--listed__index">1.</span><div class="c-article-footnote--listed__content"><p>http://www.smarttech.com/</p></div></li><li class="c-article-footnote--listed__item" id="Fn2"><span class="c-article-footnote--listed__index">2.</span><div class="c-article-footnote--listed__content"><p>http://www.accessgrid.org/</p></div></li><li class="c-article-footnote--listed__item" id="Fn3"><span class="c-article-footnote--listed__index">3.</span><div class="c-article-footnote--listed__content"><p>http://www.hp.com/hpinfo/newsroom/feature_stories/2005/05halo.html</p></div></li><li class="c-article-footnote--listed__item" id="Fn4"><span class="c-article-footnote--listed__index">4.</span><div class="c-article-footnote--listed__content"><p>http://www.smartmeeting.com/</p></div></li><li class="c-article-footnote--listed__item" id="Fn5"><span class="c-article-footnote--listed__index">5.</span><div class="c-article-footnote--listed__content"><p>http://www.alicestreet.com/</p></div></li><li class="c-article-footnote--listed__item" id="Fn6"><span class="c-article-footnote--listed__index">6.</span><div class="c-article-footnote--listed__content"><p>www.anoto.com</p></div></li><li class="c-article-footnote--listed__item" id="Fn7"><span class="c-article-footnote--listed__index">7.</span><div class="c-article-footnote--listed__content"><p>http://www.cv.iit.nrc.ca/research/ar/artag/</p></div></li><li class="c-article-footnote--listed__item" id="Fn8"><span class="c-article-footnote--listed__index">8.</span><div class="c-article-footnote--listed__content"><p>www.mimio.com</p></div></li><li class="c-article-footnote--listed__item" id="Fn9"><span class="c-article-footnote--listed__index">9.</span><div class="c-article-footnote--listed__content"><p>www.nextwindow.com</p></div></li></ol></div></div></section><section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Ashdown, P. Robinson, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Ashdown M, Robinson P (2005) Remote collaboration on desk-sized displays. Computer Animat Virtual Worlds 16(1)" /><p class="c-article-references__text" id="ref-CR1">Ashdown M, Robinson P (2005) Remote collaboration on desk-sized displays. Computer Animat Virtual Worlds 16(1): 41–51</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2Fcav.55" aria-label="View reference 1">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Remote%20collaboration%20on%20desk-sized%20displays&amp;journal=Computer%20Animat%20Virtual%20Worlds&amp;volume=16&amp;issue=1&amp;pages=41-51&amp;publication_year=2005&amp;author=Ashdown%2CM&amp;author=Robinson%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Billinghurst, H. Kato, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Billinghurst M, Kato H (2002) Collaborative augmented reality. Commun ACM 45(7): 64–70" /><p class="c-article-references__text" id="ref-CR2">Billinghurst M, Kato H (2002) Collaborative augmented reality. Commun ACM 45(7): 64–70</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F514236.514265" aria-label="View reference 2">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Collaborative%20augmented%20reality&amp;journal=Commun%20ACM&amp;volume=45&amp;issue=7&amp;pages=64-70&amp;publication_year=2002&amp;author=Billinghurst%2CM&amp;author=Kato%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X. Cao, R. Balakrishnan, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Cao X, Balakrishnan R (2004) VisionWand: interaction techniques for large displays using a passive wand tracke" /><p class="c-article-references__text" id="ref-CR3">Cao X, Balakrishnan R (2004) VisionWand: interaction techniques for large displays using a passive wand tracked in 3D. ACM transactions on graphics, 23(3). In: Proceedings of SIGGRAPH 2004, p. 729</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=VisionWand%3A%20interaction%20techniques%20for%20large%20displays%20using%20a%20passive%20wand%20tracked%20in%203D&amp;journal=ACM%20transactions%20on%20graphics&amp;volume=23&amp;publication_year=2004&amp;author=Cao%2CX&amp;author=Balakrishnan%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Collins M (2004) Eccentric contraptions: an amazing gadgets, gizmos and thingamambobs. David &amp; Charles, Newton" /><p class="c-article-references__text" id="ref-CR4">Collins M (2004) Eccentric contraptions: an amazing gadgets, gizmos and thingamambobs. David &amp; Charles, Newton Abbott</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gutwin C, Greenberg S (1996) Workspace awareness for groupware. In: Tauber M. J. (ed) Conference companion on " /><p class="c-article-references__text" id="ref-CR5">Gutwin C, Greenberg S (1996) Workspace awareness for groupware. In: Tauber M. J. (ed) Conference companion on human factors in computing systems: common ground, Vancouver, CHI ’96, April 13–18, 1996,</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Haller M, Leithinger D, Leitner J, Seifried T (2005) An augmented surface environment for storyboard presentat" /><p class="c-article-references__text" id="ref-CR6">Haller M, Leithinger D, Leitner J, Seifried T (2005) An augmented surface environment for storyboard presentations. ACM SIGGRAPH 2005, Poster Session, Los Angeles, August 2005 </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hauber J, Billinghurst M, Regenbrecht H (2004) Tangible teleconferencing. In: Proceedings of the sixth Asia Pa" /><p class="c-article-references__text" id="ref-CR7">Hauber J, Billinghurst M, Regenbrecht H (2004) Tangible teleconferencing. In: Proceedings of the sixth Asia Pacific conference on human computer interaction (APCHI 2004), Rotorua, 29 June–2 July, 2004. Lecture notes in computer science 3101, Springer, Berlin Heidelberg New York, pp. 143–152</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hauber J, Regenbrecht H, Hills A, Cockburn A, Billinghurst M (2005) Social Presence in two- and three-dimensio" /><p class="c-article-references__text" id="ref-CR8">Hauber J, Regenbrecht H, Hills A, Cockburn A, Billinghurst M (2005) Social Presence in two- and three-dimensional videoconferencing. In: Proceedings of eighth annual international workshop on presence, London/UK, September 21–23, 2005, pp. 189–198</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hills A, Hauber J, Regenbrecht H (2005) Videos in space: a study on presence in video mediating communication " /><p class="c-article-references__text" id="ref-CR9">Hills A, Hauber J, Regenbrecht H (2005) Videos in space: a study on presence in video mediating communication systems. Short paper in proceedings of ICAT University of Canterbury, New Zealand, 5–8 December, 2005</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Haller M, Leithinger D, Leitner J, Seifried T (2005) An augmented surface environment for storyboard presentat" /><p class="c-article-references__text" id="ref-CR10">Haller M, Leithinger D, Leitner J, Seifried T (2005) An augmented surface environment for storyboard presentations. ACM SIGGRAPH 2005, Poster Session, Los Angeles, August 2005 </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hollan J, Stornetta S (1992) Beyond being there. In: Proceedings of the SIGCHI conference on human factors in " /><p class="c-article-references__text" id="ref-CR11">Hollan J, Stornetta S (1992) Beyond being there. In: Proceedings of the SIGCHI conference on human factors in computing systems. ACM, Monterey, 1992, pp. 119–125</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Inkpen K (1997) Adapting the human computer interface to support collaborative learning environments for child" /><p class="c-article-references__text" id="ref-CR12">Inkpen K (1997) Adapting the human computer interface to support collaborative learning environments for children. PhD Dissertation, Department of Computer Science, University of British Columbia, 1997</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ishii H, Ullmer B (1997) Tangible bits: towards seamless interfaces between people, bits and atoms. In: Procee" /><p class="c-article-references__text" id="ref-CR13">Ishii H, Ullmer B (1997) Tangible bits: towards seamless interfaces between people, bits and atoms. In: Proceedings of conference on human factors in computing systems (CHI ‘97). ACM, Atlanta, March 1997, pp. 234–241</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kauff P, Schreer O (2002) An immersive 3D video-conferencing system using shared virtual team user environment" /><p class="c-article-references__text" id="ref-CR14">Kauff P, Schreer O (2002) An immersive 3D video-conferencing system using shared virtual team user environments. In: Proceedings of the fourth international conference on collaborative virtual environments. ACM, Bonn, 2002, pp. 105–112</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="T. Kelly, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Kelly T (2001) The art of innovation. Doubleday/Random House, New York" /><p class="c-article-references__text" id="ref-CR15">Kelly T (2001) The art of innovation. Doubleday/Random House, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20art%20of%20Innovation&amp;publication_year=2001&amp;author=Kelly%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Nakanishi H, Yoshida C, Nishimura T, Ishida T (1998) FreeWalk: a three-dimensional meeting-place for communiti" /><p class="c-article-references__text" id="ref-CR16">Nakanishi H, Yoshida C, Nishimura T, Ishida T (1998) FreeWalk: a three-dimensional meeting-place for communities. In: Ishida T (ed) Community computing: collaboration over global information networks. Wiley, London, pp. 55–89</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Regenbrecht H, Wagner M, Baratoff G (2002) MagicMeeting: a collaborative tangible augmented reality system. Vi" /><p class="c-article-references__text" id="ref-CR17">Regenbrecht H, Wagner M, Baratoff G (2002) MagicMeeting: a collaborative tangible augmented reality system. Virtual reality: systems, development and applications 6(3), Springer, Berlin Heidelberg New York, pp. 151–166</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Regenbrecht, T. Lum, P. Kohler, C. Ott, M. Wagner, W. Wilke, E. Mueller, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Regenbrecht H, Lum T, Kohler P, Ott C, Wagner M, Wilke W, Mueller E (2004) Using augmented virtuality for remo" /><p class="c-article-references__text" id="ref-CR18">Regenbrecht H, Lum T, Kohler P, Ott C, Wagner M, Wilke W, Mueller E (2004) Using augmented virtuality for remote collaboration. Presence: teleoperators and virtual environments 13(3), MIT Press, Cambridge, pp. 338–354</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Using%20augmented%20virtuality%20for%20remote%20collaboration&amp;journal=Presence%3A%20teleoperators%20and%20virtual%20environments&amp;volume=13&amp;issue=3&amp;pages=338-354&amp;publication_year=2004&amp;author=Regenbrecht%2CH&amp;author=Lum%2CT&amp;author=Kohler%2CP&amp;author=Ott%2CC&amp;author=Wagner%2CM&amp;author=Wilke%2CW&amp;author=Mueller%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rekimoto J, Saitoh M (1999) Augmented surfaces: a spatially continuous workspace for hybrid computing environm" /><p class="c-article-references__text" id="ref-CR19">Rekimoto J, Saitoh M (1999) Augmented surfaces: a spatially continuous workspace for hybrid computing environments. In CHI ‘99: Proceedings of the SIGCHI conference on human factors in computing systems, 1999</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Sellen, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Sellen A (1995) Remote conversations: The effects of mediating talk with technology. Human Comp Interact 10(4)" /><p class="c-article-references__text" id="ref-CR20">Sellen A (1995) Remote conversations: The effects of mediating talk with technology. Human Comp Interact 10(4):401–444</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1207%2Fs15327051hci1004_2" aria-label="View reference 20">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Remote%20conversations%3A%20The%20effects%20of%20mediating%20talk%20with%20technology&amp;journal=Human%20Comp%20Interact&amp;volume=10&amp;issue=4&amp;pages=401-444&amp;publication_year=1995&amp;author=Sellen%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Short J, Williams E, Christie B (1976) The social psychology of telecommunications. Wiley, London" /><p class="c-article-references__text" id="ref-CR21">Short J, Williams E, Christie B (1976) The social psychology of telecommunications. Wiley, London</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Stefik, G. Foster, D. Bobrow, K. Kahn, S. Lanning, L. Suchman, " /><meta itemprop="datePublished" content="1987" /><meta itemprop="headline" content="Stefik M, Foster G, Bobrow D, Kahn K, Lanning S, Suchman L (1987) Beyond the chalkboard: computer support for " /><p class="c-article-references__text" id="ref-CR22">Stefik M, Foster G, Bobrow D, Kahn K, Lanning S, Suchman L (1987) Beyond the chalkboard: computer support for collaboration and problem solving in meetings. Commun ACM. 30(1), pp. 32–47</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Beyond%20the%20chalkboard%3A%20computer%20support%20for%20collaboration%20and%20problem%20solving%20in%20meetings&amp;journal=Commun%20ACM&amp;volume=30&amp;issue=1&amp;pages=32-47&amp;publication_year=1987&amp;author=Stefik%2CM&amp;author=Foster%2CG&amp;author=Bobrow%2CD&amp;author=Kahn%2CK&amp;author=Lanning%2CS&amp;author=Suchman%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Stewart J, Bederson B, Druin A (1999) Single display groupware: a model for co-present collaboration. In: Proc" /><p class="c-article-references__text" id="ref-CR23">Stewart J, Bederson B, Druin A (1999) Single display groupware: a model for co-present collaboration. In: Proceedings of human factors in computing systems (CHI 99). ACM, Pittsburgh, pp. 286–293</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Streitz N, Prante P, Röcker C, van Alphen D, Magerkurth C, Stenzel R, Plewe (2003) Ambient displays and mobile" /><p class="c-article-references__text" id="ref-CR24">Streitz N, Prante P, Röcker C, van Alphen D, Magerkurth C, Stenzel R, Plewe (2003) Ambient displays and mobile devices for the creation of social architectural spaces: supporting informal communication and social awareness in organizations. In: public and situated displays: social and interactional aspects of shared display technologies. Kluwer, Dordrecht 2003, pp. 387–409</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Tang A, Boyle M, Greenberg S (2004) Display and presence disparity in mixed presence groupware. In fifth Austr" /><p class="c-article-references__text" id="ref-CR25">Tang A, Boyle M, Greenberg S (2004) Display and presence disparity in mixed presence groupware. In fifth Australasian user interface conference (AUIC2004), Dunedin. In Cockburn A (ed) Conferences in research and practice in information technology, vol 28. </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Vertegaal R (1999) The GAZE groupware system: mediating joint attention in multiparty communication and collab" /><p class="c-article-references__text" id="ref-CR26">Vertegaal R (1999) The GAZE groupware system: mediating joint attention in multiparty communication and collaboration. In: Proceedings of the SIGCHI conference on human factors in computing systems: the CHI is the limit. ACM, Pittsburgh, 1999, pp. 294–301</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-006-0045-3-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgments</h2><div class="c-article-section__content" id="Ack1-content"><p>We would like to thank Claudia Ott, Michael Wagner, Graham Copson and the Technical Support Group at Otago University, and all the participants in our experiments for their great support. In addition, we would like to thank DaimlerChrysler Research and Technology for supporting our work and the anonymous reviewers with their comments, which lead to some very relevant improvements. The Office of Tomorrow project is sponsored by the Austrian Science Fund FFG (FHplus, contract no. 811407) and VoestAlpine Informationstechnologie. Moreover, the authors would like to thank Daniel Leithinger, Jakob Leitner, and Thomas Seifried for the great work in the Coeno project. </p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Information Science, University of Otago, P.O. Box 56, Dunedin, New Zealand</p><p class="c-article-author-affiliation__authors-list">Holger Regenbrecht</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Upper Austria University of Applied Sciences, Frank-Fritsch-Straße, Upper Austria, Austria</p><p class="c-article-author-affiliation__authors-list">Michael Haller</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">University of Canterbury, Christchurch, New Zealand</p><p class="c-article-author-affiliation__authors-list">Joerg Hauber &amp; Mark Billinghurst</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Holger-Regenbrecht"><span class="c-article-authors-search__title u-h3 js-search-name">Holger Regenbrecht</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Holger+Regenbrecht&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Holger+Regenbrecht" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Holger+Regenbrecht%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Michael-Haller"><span class="c-article-authors-search__title u-h3 js-search-name">Michael Haller</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Michael+Haller&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Michael+Haller" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Michael+Haller%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Joerg-Hauber"><span class="c-article-authors-search__title u-h3 js-search-name">Joerg Hauber</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Joerg+Hauber&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Joerg+Hauber" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Joerg+Hauber%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Mark-Billinghurst"><span class="c-article-authors-search__title u-h3 js-search-name">Mark Billinghurst</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Mark+Billinghurst&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Mark+Billinghurst" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Mark+Billinghurst%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-006-0045-3/email/correspondent/c1/new">Holger Regenbrecht</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Carpeno%3A%20interfacing%20remote%20collaborative%20virtual%20environments%20with%20table-top%20interaction&amp;author=Holger%20Regenbrecht%20et%20al&amp;contentID=10.1007%2Fs10055-006-0045-3&amp;publication=1359-4338&amp;publicationDate=2006-09-07&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Regenbrecht, H., Haller, M., Hauber, J. <i>et al.</i> Carpeno: interfacing remote collaborative virtual environments with table-top interaction.
                    <i>Virtual Reality</i> <b>10, </b>95–107 (2006). https://doi.org/10.1007/s10055-006-0045-3</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-006-0045-3.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-02-24">24 February 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-05-15">15 May 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-09-07">07 September 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-10">October 2006</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-006-0045-3" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-006-0045-3</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Collaborative work</span></li><li class="c-article-subject-list__subject"><span itemprop="about">CSCW</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Virtual environments</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Table-top interfaces</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Teleconferencing</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-006-0045-3.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=45;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

