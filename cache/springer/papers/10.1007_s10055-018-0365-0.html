<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Virtual reality crowd simulation: effects of agent density on user exp"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Agent-based crowd simulations are used for modelling building and space usage, allowing designers to explore hypothetical real-world scenarios, including extraordinary events such as evacuations...."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/23/1.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Virtual reality crowd simulation: effects of agent density on user experience and behaviour"/>

    <meta name="dc.source" content="Virtual Reality 2018 23:1"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2018-09-21"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2018 The Author(s)"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Agent-based crowd simulations are used for modelling building and space usage, allowing designers to explore hypothetical real-world scenarios, including extraordinary events such as evacuations. Existing work which engages virtual reality (VR) as a platform for crowd simulations has been primarily focussed on the validation of simulation models through observation; the use of interactions such as gaze to enhance a sense of immersion; or studies of proxemics. In this work, we extend previous studies of proxemics and examine the effects of varying crowd density on user experience and behaviour. We have created a simulation in which participants walk freely and perform a routine manual task, whilst interacting with agents controlled by a typical social force simulation model. We examine and report the effects of crowd density on both affective state and behaviour. Our results show a significant increase in negative affect with density, measured using a self-report scale. We further show significant differences in some aspects of user behaviours, using video analysis, and discuss how our results relate to VR simulation design for mixed human&#8211;agent scenarios."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2018-09-21"/>

    <meta name="prism.volume" content="23"/>

    <meta name="prism.number" content="1"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="19"/>

    <meta name="prism.endingPage" content="32"/>

    <meta name="prism.copyright" content="2018 The Author(s)"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-018-0365-0"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-018-0365-0"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-018-0365-0.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-018-0365-0"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Virtual reality crowd simulation: effects of agent density on user experience and behaviour"/>

    <meta name="citation_volume" content="23"/>

    <meta name="citation_issue" content="1"/>

    <meta name="citation_publication_date" content="2019/03"/>

    <meta name="citation_online_date" content="2018/09/21"/>

    <meta name="citation_firstpage" content="19"/>

    <meta name="citation_lastpage" content="32"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_fulltext_world_readable" content=""/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-018-0365-0"/>

    <meta name="DOI" content="10.1007/s10055-018-0365-0"/>

    <meta name="citation_doi" content="10.1007/s10055-018-0365-0"/>

    <meta name="description" content="Agent-based crowd simulations are used for modelling building and space usage, allowing designers to explore hypothetical real-world scenarios, including e"/>

    <meta name="dc.creator" content="Patrick Dickinson"/>

    <meta name="dc.creator" content="Kathrin Gerling"/>

    <meta name="dc.creator" content="Kieran Hicks"/>

    <meta name="dc.creator" content="John Murray"/>

    <meta name="dc.creator" content="John Shearer"/>

    <meta name="dc.creator" content="Jacob Greenwood"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Ahn J, Wang N, Thalmann D, Boulic R (2012) Within-crowd immersive evaluation of collision avoidance behaviors. In: Proceedings of the ACM SIGGRAPH international conference on virtual-reality continuum and its applications in industry, VRCAI&#8217;12, ACM, New York, pp 231&#8211;238"/>

    <meta name="citation_reference" content="citation_title=Electrodermal activity; citation_publication_date=1992; citation_id=CR2; citation_author=W Boucsein; citation_publisher=Plenum Press"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Vis Comput Graph; citation_title=Going through, going around: a study on individual avoidance of groups; citation_author=J Bruneau, AH Olivier, J Pettr; citation_volume=21; citation_issue=4; citation_publication_date=2015; citation_pages=520-528; citation_doi=10.1109/TVCG.2015.2391862; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Visual Comput Graphics; citation_title=Effects of different types of virtual reality display on presence and learning in a safety training scenario; citation_author=F Buttussi, L Chittaro; citation_volume=24; citation_issue=2; citation_publication_date=2018; citation_pages=1063-1076; citation_doi=10.1109/TVCG.2017.2653117; citation_id=CR4"/>

    <meta name="citation_reference" content="Christou C, Herakleous K, Tzanavari A, Poullis C (2015) Psychophysiological responses to virtual crowds: implications for wearable computing. In: International conference on affective computing and intelligent interaction (ACII), pp 35&#8211;41. 
                    https://doi.org/10.1109/acii.2015.7344548
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Vis Comput; citation_title=Right of way: asymmetric agent interactions in crowds; citation_author=S Curtis, B Zafar, A Gutub, D Manocha; citation_volume=29; citation_issue=12; citation_publication_date=2013; citation_pages=1277-1292; citation_doi=10.1007/s00371-012-0769-x; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_title=The electrodermal system; citation_inbook_title=The handbook of psychophysiology; citation_publication_date=2007; citation_pages=152-191; citation_id=CR7; citation_author=M Dawson; citation_author=A Schell; citation_author=D Filion; citation_publisher=Cambridge University Press"/>

    <meta name="citation_reference" content="citation_journal_title=Field Methods; citation_title=Developing and using a codebook for the analysis of interview data: an example from a professional development research project; citation_author=JT DeCuir-Gunby, PL Marshall, AW McCulloch; citation_volume=23; citation_publication_date=2011; citation_pages=136-155; citation_doi=10.1177/1525822X10388468; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_journal_title=Front Psychol; citation_title=The impact of perception&#168; and presence on emotional reactions: a review of research in virtual reality; citation_author=J Diemer, GW Alpers, HM Peperkorn, Y Shiban, A Muhlberger; citation_volume=6; citation_publication_date=2015; citation_pages=26; citation_doi=10.3389/fpsyg.2015.00026; citation_id=CR9"/>

    <meta name="citation_reference" content="citation_journal_title=PLoS ONE; citation_title=Walking ahead: the headed social force model; citation_author=F Farina, D Fontanelli, A Garulli, A Giannitrapani, D Prattichizzo; citation_volume=12; citation_issue=1; citation_publication_date=2017; citation_pages=e0169734; citation_doi=10.1371/journal.pone.0169734; citation_id=CR11"/>

    <meta name="citation_reference" content="Ferrer G, Garrell A, Sanfeliu A (2013) Robot companion: a social-force based approach with human awareness-navigation in crowded environments. In: 2013 IEEE/RSJ international conference on intelligent robots and systems (IROS), pp 1688&#8211;1694"/>

    <meta name="citation_reference" content="citation_journal_title=Appl Ergon; citation_title=Factors influencing experience in crowds the participant perspective; citation_author=V Filingeri, K Eason, P Waterson, R Haslam; citation_volume=59; citation_issue=Part A; citation_publication_date=2017; citation_pages=431-441; citation_doi=10.1016/j.apergo.2016.09.009; citation_id=CR13"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Appl Percept; citation_title=Obstacle avoidance during walking in real and virtual environments; citation_author=PW Fink, PS Foo, WH Warren; citation_volume=4; citation_issue=1; citation_publication_date=2007; citation_pages=2; citation_doi=10.1145/1227134.1227136; citation_id=CR14"/>

    <meta name="citation_reference" content="citation_journal_title=Presence; citation_title=The responses of people to virtual humans in an immersive virtual environment; citation_author=M Garau, M Slater, DP Pertaub, S Razzaque; citation_volume=14; citation_issue=1; citation_publication_date=2005; citation_pages=104-116; citation_doi=10.1162/1054746053890242; citation_id=CR15"/>

    <meta name="citation_reference" content="citation_journal_title=Gait Posture; citation_title=Characteristics of personal space during obstacle circumvention in physical and virtual environments; citation_author=M G&#233;rin-Lajoie, CL Richards, J Fung, BJ McFadyen; citation_volume=27; citation_issue=2; citation_publication_date=2008; citation_pages=239-247; citation_doi=10.1016/j.gaitpost.2007.03.015; citation_id=CR16"/>

    <meta name="citation_reference" content="citation_journal_title=Am Anthropol; citation_title=A system for the notation of proxemic behavior1; citation_author=ET Hall; citation_volume=65; citation_issue=5; citation_publication_date=1963; citation_pages=1003-1026; citation_doi=10.1525/aa.1963.65.5.02a00020; citation_id=CR17"/>

    <meta name="citation_reference" content="citation_journal_title=Phys Rev E; citation_title=Social force model for pedestrian dynamics; citation_author=D Helbing, P Molnar; citation_volume=51; citation_publication_date=1995; citation_pages=4282-4286; citation_doi=10.1103/PhysRevE.51.4282; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=Pedestr Evacuation Dyn; citation_title=Simulation of pedestrian crowds in normal and evacuation situations; citation_author=D Helbing, IJ Farkas, P Molnar, T Vicsek; citation_volume=21; citation_issue=2; citation_publication_date=2002; citation_pages=21-58; citation_id=CR19"/>

    <meta name="citation_reference" content="Hupont I, Gracia J, Sanagustn L, Gracia MA (2015) How do new visual immersive systems influence gaming qoe? a use case of serious gaming with oculus rift. In: International workshop on quality of multimedia experience (QoMEX), pp 1&#8211;6"/>

    <meta name="citation_reference" content="citation_journal_title=Lancet Infect Dis; citation_title=Crowd and environmental management during mass gatherings; citation_author=A Johansson, M Batty, K Hayashi, OA Bar, D Marcozzi, ZA Memish; citation_volume=12; citation_issue=2; citation_publication_date=2012; citation_pages=150-156; citation_doi=10.1016/S1473-3099(11)70287-0; citation_id=CR21"/>

    <meta name="citation_reference" content="citation_title=A predictive collision avoidance model for pedestrian simulation; citation_inbook_title=Motion in games. MIG 2009; citation_publication_date=2009; citation_id=CR22; citation_author=I Karamouzas; citation_author=P Heil; citation_author=P Beek; citation_author=M Overmars; citation_publisher=Springer"/>

    <meta name="citation_reference" content="Kim S, Bera A, Best A, Chabra R, Manocha D (2016) Interactive and adaptive data-driven crowd simulation. In: 2016 IEEE virtual reality (VR). Greenville, SC, pp 29&#8211;38"/>

    <meta name="citation_reference" content="Kyriakou M, Pan X, Chrysanthou Y (2015) Interaction with virtual agents-comparison of the participants&#8217; experience between an IVR and a semi-IVR system. In: 2015 IEEE virtual reality (VR). Arles, pp 217&#8211;218"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Anim Virtual Worlds; citation_title=Interaction with virtual crowd in immersive and semi-Immersive virtual reality systems; citation_author=M Kyriakou, X Pan, Y Chrysanthou; citation_volume=28; citation_publication_date=2016; citation_pages=e1729; citation_doi=10.1002/cav.1729; citation_id=CR25"/>

    <meta name="citation_reference" content="citation_journal_title=Physica A Stat Mech Appl; citation_title=Modeling, simulation and analysis of the evacuation process on stairs in a multi-floor classroom building of a primary school; citation_author=W Li, Y Li, P Yu, J Gong, S Shen, L Huang, J Liang; citation_volume=469; citation_publication_date=2017; citation_pages=157-172; citation_doi=10.1016/j.physa.2016.11.047; citation_id=CR26"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Appl Percept; citation_title=Proxemics with multiple dynamic characters in an immersive virtual environment; citation_author=J Llobera, B Spanlang, G Ruffini, M Slater; citation_volume=8; citation_issue=1; citation_publication_date=2010; citation_pages=3:1-3:12; citation_doi=10.1145/1857893.1857896; citation_id=CR27"/>

    <meta name="citation_reference" content="citation_journal_title=J R Soc Interface; citation_title=Crowd behaviour during high-stress evacuations in an immersive virtual environment; citation_author=M Moussaid, M Kapadia, T Thrash, RW Sumner, M Gross, D Helbing, C Holscher; citation_volume=13; citation_issue=122; citation_publication_date=2016; citation_pages=20160414; citation_doi=10.1098/rsif.2016.0414; citation_id=CR28"/>

    <meta name="citation_reference" content="Narang S, Best A, Randhavane T, Shapiro A, Manocha D (2016) Pedvr: simulating gaze-based interactions between a real user and virtual crowds. In: Proceedings of the ACM conference on virtual reality software and technology, VRST&#8217;16, ACM, New York, pp 91&#8211;100"/>

    <meta name="citation_reference" content="citation_journal_title=Depress Anxiety; citation_title=Virtual reality exposure therapy in anxiety disorders: a quantitative meta-analysis; citation_author=D Opris, S Pintea, A Garc&#180;&#305;a-Palacios, C Botella, S Szamoskozi, D David; citation_volume=29; citation_issue=2; citation_publication_date=2012; citation_pages=85-93; citation_doi=10.1002/da.20910; citation_id=CR30"/>

    <meta name="citation_reference" content="citation_journal_title=Conscious Cognit; citation_title=Putting yourself in the skin of a black avatar reduces implicit racial bias; citation_author=TC Peck, S Seinfeld, SM Aglioti, M Slater; citation_volume=22; citation_issue=3; citation_publication_date=2013; citation_pages=779-787; citation_doi=10.1016/j.concog.2013.04.016; citation_id=CR31"/>

    <meta name="citation_reference" content="Pelechano N, Allbecky JM (2016) Feeling crowded yet?: crowd simulations for VR. In: 2016 IEEE virtual humans and crowds for immersive environments (VHCIE). Greenville, SC, pp 17&#8211;21"/>

    <meta name="citation_reference" content="citation_title=Virtual crowds: methods, simulation, and control (synthesis lectures on computer graphics and animation); citation_publication_date=2008; citation_id=CR33; citation_author=N Pelechano; citation_author=J Allbeck; citation_author=N Badler; citation_publisher=Morgan and Claypool Publishers"/>

    <meta name="citation_reference" content="Pelechano N, Stocker C, Allbeck J, Badler NI (2008b) Being a part of the crowd: towards validating vr crowds using presence. In: Proceedings of the international conference on autonomous agents and multiagent systems (Aamas), pp 136&#8211;142"/>

    <meta name="citation_reference" content="Rojas FA, Yang HS (2013) Immersive human-in-the-loop hmd evaluation of dynamic group behaviour in a pedestrian crowd simulation that uses group agent-based steering. In: Proceedings of international conference on virtual reality continuum and its applications in industry, VRCAI&#8217;13, ACM, New York, pp 31&#8211;40"/>

    <meta name="citation_reference" content="Rojas FA, Yang HS, Tarnogol FM (2014) Safe navigation of pedestrians in social groups in a virtual urban environment. In: International conference on cyberworlds, pp 31&#8211;38"/>

    <meta name="citation_reference" content="Sanz FA, Olivier AH, Bruder G, Pettr&#233; J, L&#233;cuyer A (2015) Virtual proxemics: locomotion in the presence of obstacles in large immersive projection environments. In: 2015 IEEE virtual reality (VR). Arles, pp 75&#8211;80"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoper Virtual Environ; citation_title=The experience of presence: factor analytic insights; citation_author=T Schubert, F Friedmann, H Regenbrecht; citation_volume=10; citation_issue=3; citation_publication_date=2001; citation_pages=266-281; citation_doi=10.1162/105474601300343603; citation_id=CR38"/>

    <meta name="citation_reference" content="Sohre N, Mackin C, Interrante V, Guy SJ (2017) Evaluating collision avoidance effects on discomfort in virtual environments. In: 2017 IEEE virtual humans and crowds for immersive environments (VHCIE). Los Angeles, CA, pp 1&#8211;5"/>

    <meta name="citation_reference" content="citation_journal_title=Physica A Stat Mech Appl; citation_title=Room evacuation through two contiguous exits; citation_author=IM Sticco, GA Frank, S Cerrotta, CO Dorso; citation_volume=474; citation_publication_date=2017; citation_pages=172-185; citation_doi=10.1016/j.physa.2017.01.079; citation_id=CR40"/>

    <meta name="citation_reference" content="citation_journal_title=Physica A Stat Mech Appl; citation_title=Modeling pedestrian movement at the hall of high-speed railway station during the check-in process; citation_author=T-Q Tang, Y-X Shao, L Chen; citation_volume=467; citation_publication_date=2017; citation_pages=157-166; citation_doi=10.1016/j.physa.2016.10.008; citation_id=CR41"/>

    <meta name="citation_reference" content="citation_title=Crowd simulation for interactive virtual environments and VR training systems; citation_publication_date=2001; citation_id=CR42; citation_author=B Ulicny; citation_author=D Thalmann; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=J Personal Soc Psychol; citation_title=Development and validation of brief measures of positive and negative affect: the panas scales; citation_author=D Watson, LA Clark, A Tellegen; citation_volume=54; citation_issue=6; citation_publication_date=1988; citation_pages=1063; citation_doi=10.1037/0022-3514.54.6.1063; citation_id=CR43"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Appl Percept; citation_title=Personal space in virtual reality; citation_author=LM Wilcox, RS Allison, S Elfassy, C Grelik; citation_volume=3; citation_issue=4; citation_publication_date=2006; citation_pages=412-428; citation_doi=10.1145/1190036.1190041; citation_id=CR44"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoper Virtual Environ; citation_title=Measuring presence in virtual environments: a presence questionnaire; citation_author=BG Witmer, MJ Singer; citation_volume=7; citation_issue=3; citation_publication_date=1998; citation_pages=225-240; citation_doi=10.1162/105474698565686; citation_id=CR45"/>

    <meta name="citation_reference" content="citation_journal_title=Build Environ; citation_title=Modeling crowd evacuation of a building based on seven methodological approaches; citation_author=X Zheng, T Zhong, M Liu; citation_volume=44; citation_issue=3; citation_publication_date=2009; citation_pages=437-445; citation_doi=10.1016/j.buildenv.2008.04.002; citation_id=CR46"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Vis Comput Graph; citation_title=The effect of realistic appearance of virtual characters in immersive environments&#8212;does the character&#8217;s personality play a role?; citation_author=K Zibrek, E Kokkinara, R Mcdonnell; citation_volume=24; citation_issue=4; citation_publication_date=2018; citation_pages=1681-1690; citation_doi=10.1109/TVCG.2018.2794638; citation_id=CR47"/>

    <meta name="citation_author" content="Patrick Dickinson"/>

    <meta name="citation_author_email" content="pdickinson@lincoln.ac.uk"/>

    <meta name="citation_author_institution" content="School of Computer Science, University of Lincoln, Lincoln, UK"/>

    <meta name="citation_author" content="Kathrin Gerling"/>

    <meta name="citation_author_institution" content="e-Media Research Lab, KU Leuven, Leuven, Belgium"/>

    <meta name="citation_author" content="Kieran Hicks"/>

    <meta name="citation_author_institution" content="School of Computer Science, University of Lincoln, Lincoln, UK"/>

    <meta name="citation_author" content="John Murray"/>

    <meta name="citation_author_institution" content="School of Computer Science, University of Hull, Hull, UK"/>

    <meta name="citation_author" content="John Shearer"/>

    <meta name="citation_author_institution" content="School of Computer Science, University of Lincoln, Lincoln, UK"/>

    <meta name="citation_author" content="Jacob Greenwood"/>

    <meta name="citation_author_institution" content="School of Computer Science, University of Lincoln, Lincoln, UK"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-018-0365-0&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2019/03/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-018-0365-0"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Virtual reality crowd simulation: effects of agent density on user experience and behaviour"/>
        <meta property="og:description" content="Agent-based crowd simulations are used for modelling building and space usage, allowing designers to explore hypothetical real-world scenarios, including extraordinary events such as evacuations. Existing work which engages virtual reality (VR) as a platform for crowd simulations has been primarily focussed on the validation of simulation models through observation; the use of interactions such as gaze to enhance a sense of immersion; or studies of proxemics. In this work, we extend previous studies of proxemics and examine the effects of varying crowd density on user experience and behaviour. We have created a simulation in which participants walk freely and perform a routine manual task, whilst interacting with agents controlled by a typical social force simulation model. We examine and report the effects of crowd density on both affective state and behaviour. Our results show a significant increase in negative affect with density, measured using a self-report scale. We further show significant differences in some aspects of user behaviours, using video analysis, and discuss how our results relate to VR simulation design for mixed human–agent scenarios."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Virtual reality crowd simulation: effects of agent density on user experience and behaviour | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-018-0365-0","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Crowd simulation, User experience, Agent density","kwrd":["Crowd_simulation","User_experience","Agent_density"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"Y","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"vgzm.415900-10.1007-s10055-018-0365-0","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-018-0365-0","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=365;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-018-0365-0">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Virtual reality crowd simulation: effects of agent density on user experience and behaviour
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-018-0365-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-018-0365-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
        <li class="c-article-identifiers__item">
            <span class="c-article-identifiers__open" data-test="open-access">Open Access</span>
        </li>
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2018-09-21" itemprop="datePublished">21 September 2018</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Virtual reality crowd simulation: effects of agent density on user experience and behaviour</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Patrick-Dickinson" data-author-popup="auth-Patrick-Dickinson" data-corresp-id="c1">Patrick Dickinson<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><span class="u-js-hide"> 
            <a class="js-orcid" itemprop="url" href="http://orcid.org/0000-0003-3830-8249"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-3830-8249</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Lincoln" /><meta itemprop="address" content="0000 0004 0420 4262, grid.36511.30, School of Computer Science, University of Lincoln, Lincoln, UK" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Kathrin-Gerling" data-author-popup="auth-Kathrin-Gerling">Kathrin Gerling</a></span><span class="u-js-hide"> 
            <a class="js-orcid" itemprop="url" href="http://orcid.org/0000-0002-8449-6124"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-8449-6124</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="KU Leuven" /><meta itemprop="address" content="0000 0001 0668 7884, grid.5596.f, e-Media Research Lab, KU Leuven, Leuven, Belgium" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Kieran-Hicks" data-author-popup="auth-Kieran-Hicks">Kieran Hicks</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Lincoln" /><meta itemprop="address" content="0000 0004 0420 4262, grid.36511.30, School of Computer Science, University of Lincoln, Lincoln, UK" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-John-Murray" data-author-popup="auth-John-Murray">John Murray</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Hull" /><meta itemprop="address" content="0000 0004 0412 8669, grid.9481.4, School of Computer Science, University of Hull, Hull, UK" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-John-Shearer" data-author-popup="auth-John-Shearer">John Shearer</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Lincoln" /><meta itemprop="address" content="0000 0004 0420 4262, grid.36511.30, School of Computer Science, University of Lincoln, Lincoln, UK" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Jacob-Greenwood" data-author-popup="auth-Jacob-Greenwood">Jacob Greenwood</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Lincoln" /><meta itemprop="address" content="0000 0004 0420 4262, grid.36511.30, School of Computer Science, University of Lincoln, Lincoln, UK" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 23</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">19</span>–<span itemprop="pageEnd">32</span>(<span data-test="article-publication-year">2019</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">3167 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">6 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">3 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-018-0365-0/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Agent-based crowd simulations are used for modelling building and space usage, allowing designers to explore hypothetical real-world scenarios, including extraordinary events such as evacuations. Existing work which engages virtual reality (VR) as a platform for crowd simulations has been primarily focussed on the validation of simulation models through observation; the use of interactions such as gaze to enhance a sense of immersion; or studies of proxemics. In this work, we extend previous studies of proxemics and examine the effects of varying crowd density on user experience and behaviour. We have created a simulation in which participants walk freely and perform a routine manual task, whilst interacting with agents controlled by a typical social force simulation model. We examine and report the effects of crowd density on both affective state and behaviour. Our results show a significant increase in negative affect with density, measured using a self-report scale. We further show significant differences in some aspects of user behaviours, using video analysis, and discuss how our results relate to VR simulation design for mixed human–agent scenarios.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Agent-based crowd simulations are widely used for modelling building and space usage. They allow designers to make predictions about hypothetical real-world scenarios, such as day-to-day use of buildings or crowd behaviours at large events (Johansson et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Johansson A, Batty M, Hayashi K, Bar OA, Marcozzi D, Memish ZA (2012) Crowd and environmental management during mass gatherings. Lancet Infect Dis 12(2):150–156. &#xA;                    https://doi.org/10.1016/S1473-3099(11)70287-0&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0365-0#ref-CR21" id="ref-link-section-d19374e405">2012</a>; Tang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Tang T-Q, Shao Y-X, Chen L (2017) Modeling pedestrian movement at the hall of high-speed railway station during the check-in process. Physica A Stat Mech Appl 467:157–166" href="/article/10.1007/s10055-018-0365-0#ref-CR41" id="ref-link-section-d19374e408">2017</a>); they are also used for training and planning of extraordinary events, particularly evacuations (Helbing et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Helbing D, Farkas IJ, Molnar P, Vicsek T (2002) Simulation of pedestrian crowds in normal and evacuation situations. Pedestr Evacuation Dyn 21(2):21–58" href="/article/10.1007/s10055-018-0365-0#ref-CR19" id="ref-link-section-d19374e411">2002</a>; Pelechano et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008a" title="Pelechano N, Allbeck J, Badler N (2008a) Virtual crowds: methods, simulation, and control (synthesis lectures on computer graphics and animation). Morgan and Claypool Publishers, San Rafael" href="/article/10.1007/s10055-018-0365-0#ref-CR33" id="ref-link-section-d19374e414">2008a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Pelechano N, Stocker C, Allbeck J, Badler NI (2008b) Being a part of the crowd: towards validating vr crowds using presence. In: Proceedings of the international conference on autonomous agents and multiagent systems (Aamas), pp 136–142" href="/article/10.1007/s10055-018-0365-0#ref-CR34" id="ref-link-section-d19374e417">b</a>; Zheng et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Zheng X, Zhong T, Liu M (2009) Modeling crowd evacuation of a building based on seven methodological approaches. Build Environ 44(3):437–445" href="/article/10.1007/s10055-018-0365-0#ref-CR46" id="ref-link-section-d19374e421">2009</a>).</p><p>The embedding of human participants directly into large-crowd simulations has considerable potential to generate richer and more informative outcomes. For example, the effects of deploying fire marshalls on evacuation times could be assessed, or the impact of staff training could be evaluated. However, the effectiveness of such applications is dependent on the ability of the simulation to generate the same kind of experiences and behaviours as one might experience in equivalent real-world scenarios. Existing work (for example, Filingeri et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Filingeri V, Eason K, Waterson P, Haslam R (2017) Factors influencing experience in crowds the participant perspective. Appl Ergon 59(Part A):431–441" href="/article/10.1007/s10055-018-0365-0#ref-CR13" id="ref-link-section-d19374e427">2017</a>) has identified and described common themes in typical crowds. These include negative responses to feelings of being overcrowded such as lack of personal space, inability move easily, and anxiety: these factors can be seen to contribute to negative outcomes (such as panic) in extreme situations. The aim of our work is to determine whether such experiences can be reproduced in VR simulations and to what extent they are dependent on crowd density, in order to warrant the use of such simulations with embedded human participants for training, evacuation simulations, or similar scenarios.</p><p>Whilst some existing work has considered the use of crowd simulations in virtual reality (VR) settings, it has generally focused on three areas: firstly, the validation of simulation models by a human observer (Ahn et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Ahn J, Wang N, Thalmann D, Boulic R (2012) Within-crowd immersive evaluation of collision avoidance behaviors. In: Proceedings of the ACM SIGGRAPH international conference on virtual-reality continuum and its applications in industry, VRCAI’12, ACM, New York, pp 231–238" href="/article/10.1007/s10055-018-0365-0#ref-CR1" id="ref-link-section-d19374e433">2012</a>; Kim et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Kim S, Bera A, Best A, Chabra R, Manocha D (2016) Interactive and adaptive data-driven crowd simulation. In: 2016 IEEE virtual reality (VR). Greenville, SC, pp 29–38" href="/article/10.1007/s10055-018-0365-0#ref-CR23" id="ref-link-section-d19374e436">2016</a>; Pelechano et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008a" title="Pelechano N, Allbeck J, Badler N (2008a) Virtual crowds: methods, simulation, and control (synthesis lectures on computer graphics and animation). Morgan and Claypool Publishers, San Rafael" href="/article/10.1007/s10055-018-0365-0#ref-CR33" id="ref-link-section-d19374e439">2008a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Pelechano N, Stocker C, Allbeck J, Badler NI (2008b) Being a part of the crowd: towards validating vr crowds using presence. In: Proceedings of the international conference on autonomous agents and multiagent systems (Aamas), pp 136–142" href="/article/10.1007/s10055-018-0365-0#ref-CR34" id="ref-link-section-d19374e442">b</a>; Rojas and Yang <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Rojas FA, Yang HS (2013) Immersive human-in-the-loop hmd evaluation of dynamic group behaviour in a pedestrian crowd simulation that uses group agent-based steering. In: Proceedings of international conference on virtual reality continuum and its applications in industry, VRCAI’13, ACM, New York, pp 31–40" href="/article/10.1007/s10055-018-0365-0#ref-CR35" id="ref-link-section-d19374e445">2013</a>; Rojas et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Rojas FA, Yang HS, Tarnogol FM (2014) Safe navigation of pedestrians in social groups in a virtual urban environment. In: International conference on cyberworlds, pp 31–38" href="/article/10.1007/s10055-018-0365-0#ref-CR36" id="ref-link-section-d19374e449">2014</a>); secondly, investigations of additional human–agent interactions, such as gestures and gaze (Kyriakou et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Kyriakou M, Pan X, Chrysanthou Y (2016) Interaction with virtual crowd in immersive and semi-Immersive virtual reality systems. Comput Anim Virtual Worlds 28:e1729" href="/article/10.1007/s10055-018-0365-0#ref-CR25" id="ref-link-section-d19374e452">2016</a>; Narang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Narang S, Best A, Randhavane T, Shapiro A, Manocha D (2016) Pedvr: simulating gaze-based interactions between a real user and virtual crowds. In: Proceedings of the ACM conference on virtual reality software and technology, VRST’16, ACM, New York, pp 91–100" href="/article/10.1007/s10055-018-0365-0#ref-CR29" id="ref-link-section-d19374e455">2016</a>); and finally, user response to agent proximity (proxemics). Proxemics is of most relevance to our work, but existing investigations use single agents or objects, or small groups in predefined configurations, rather than full crowd simulation models (Bruneau et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Bruneau J, Olivier AH, Pettr J (2015) Going through, going around: a study on individual avoidance of groups. IEEE Trans Vis Comput Graph 21(4):520–528" href="/article/10.1007/s10055-018-0365-0#ref-CR3" id="ref-link-section-d19374e458">2015</a>; Llobera et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Llobera J, Spanlang B, Ruffini G, Slater M (2010) Proxemics with multiple dynamic characters in an immersive virtual environment. ACM Trans Appl Percept 8(1):3:1–3:12" href="/article/10.1007/s10055-018-0365-0#ref-CR27" id="ref-link-section-d19374e461">2010</a>; Wilcox et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Wilcox LM, Allison RS, Elfassy S, Grelik C (2006) Personal space in virtual reality. ACM Trans Appl Percept 3(4):412–428" href="/article/10.1007/s10055-018-0365-0#ref-CR44" id="ref-link-section-d19374e464">2006</a>; Sanz et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Sanz FA, Olivier AH, Bruder G, Pettré J, Lécuyer A (2015) Virtual proxemics: locomotion in the presence of obstacles in large immersive projection environments. In: 2015 IEEE virtual reality (VR). Arles, pp 75–80" href="/article/10.1007/s10055-018-0365-0#ref-CR37" id="ref-link-section-d19374e468">2015</a>), and also use physiological measures of arousal rather than measures of affect.</p><h3 class="c-article__sub-heading" id="Sec2">Objectives and contributions</h3><p>Our work builds on previous studies to investigate the effect of immersion in a full crowd simulation on user affect and behaviour, using VR. High density in real crowds is known to create negative experiences such as stress, frustration, and discomfort (Filingeri et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Filingeri V, Eason K, Waterson P, Haslam R (2017) Factors influencing experience in crowds the participant perspective. Appl Ergon 59(Part A):431–441" href="/article/10.1007/s10055-018-0365-0#ref-CR13" id="ref-link-section-d19374e478">2017</a>); however, existing work has not directly considered whether such effects might be replicated in VR simulations. We approach VR crowd simulation from this perspective. We use a social forces simulation, adapted from Helbing and Molnar (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Helbing D, Molnar P (1995) Social force model for pedestrian dynamics. Phys Rev E 51:4282–4286" href="/article/10.1007/s10055-018-0365-0#ref-CR18" id="ref-link-section-d19374e481">1995</a>), and insert a human participant, using the HTC Vive platform. Participants undertake a routine manual task, navigate by walking naturally, and human–agent interactions are mediated by the same social force model. Our objectives are:</p><ul class="u-list-style-bullet">
                    <li>
                      <p>To examine the effects of varying agent density in the simulation on participants’ affective state. We hypothesise that users will experience higher levels of negative affect with increasing agent density.</p>
                    </li>
                    <li>
                      <p>To investigate the effect of varying crowd density on participants’ behaviour. Previous works (e.g. Pelechano et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008a" title="Pelechano N, Allbeck J, Badler N (2008a) Virtual crowds: methods, simulation, and control (synthesis lectures on computer graphics and animation). Morgan and Claypool Publishers, San Rafael" href="/article/10.1007/s10055-018-0365-0#ref-CR33" id="ref-link-section-d19374e496">2008a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Pelechano N, Stocker C, Allbeck J, Badler NI (2008b) Being a part of the crowd: towards validating vr crowds using presence. In: Proceedings of the international conference on autonomous agents and multiagent systems (Aamas), pp 136–142" href="/article/10.1007/s10055-018-0365-0#ref-CR34" id="ref-link-section-d19374e499">b</a>) have anecdotally reported observations of gestures and behaviours associated with negative experiences or discomfort, such as perceived collisions or avoidance. We aim to quantify and report the prevalence of such behaviours at varying crowd density, as we believe that this gives additional insight into user experience and may help guide the design and implementation of future VR-based crowd simulations.</p>
                    </li>
                    <li>
                      <p>We further aim to quantify trajectory data across different densities, to support our findings.</p>
                    </li>
                  </ul><p>Previous works on proxemics in VR have used a mixture of physiological measures such as electrodermal activity (EDA), bespoke questionnaires, and trajectory data to investigate user response. EDA is an established measure of arousal, but is also sensitive to users’ physical movement (Boucsein <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Boucsein W (1992) Electrodermal activity. Plenum Press, New York" href="/article/10.1007/s10055-018-0365-0#ref-CR2" id="ref-link-section-d19374e513">1992</a>; Dawson et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Dawson M, Schell A, Filion D (2007) The electrodermal system. In: Cacioppo J, Tassinary L, Berntson G (eds) The handbook of psychophysiology. Cambridge University Press, Cambridge, pp 152–191" href="/article/10.1007/s10055-018-0365-0#ref-CR7" id="ref-link-section-d19374e516">2007</a>), making it unsuitable for studies like ours (in which users navigate by walking and perform manual tasks). Moreover, we are interested in assessing affective state, rather than arousal, as a measure of user experience. To this end, we propose the use of the positive and negative affect schedule (PANAS) self-report scale (Watson et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Watson D, Clark LA, Tellegen A (1988) Development and validation of brief measures of positive and negative affect: the panas scales. J Personal Soc Psychol 54(6):1063" href="/article/10.1007/s10055-018-0365-0#ref-CR43" id="ref-link-section-d19374e519">1988</a>) as a measure of user experience. The PANAS scale is widely used in experimental psychology, and comprises two ten-point scales which assess the subject’s affective state (mood) on both positive and negative dimensions. The questionnaire comprises a number of words which describe emotions (e.g. Excited, Hostile), and participants rate to what extent they feel each of those. Reliability and validity have been reported as good (Watson et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Watson D, Clark LA, Tellegen A (1988) Development and validation of brief measures of positive and negative affect: the panas scales. J Personal Soc Psychol 54(6):1063" href="/article/10.1007/s10055-018-0365-0#ref-CR43" id="ref-link-section-d19374e522">1988</a>). PANAS is also in games user research: previous work has established a relationship between emotions, user experience, and physiological measures, further warranting the use of validated self-report measures where EDA cannot be used reliably. However, we also propose PANAS (as an established measure of affect rather than arousal) as a descriptive and meaningful measure of experience. Despite widespread use in other contexts, only a very small number of VR studies have used the PANAS scale (e.g. Zibrek et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Zibrek K, Kokkinara E, Mcdonnell R (2018) The effect of realistic appearance of virtual characters in immersive environments—does the character’s personality play a role? IEEE Trans Vis Comput Graph 24(4):1681–1690" href="/article/10.1007/s10055-018-0365-0#ref-CR47" id="ref-link-section-d19374e525">2018</a>) to investigate user affect; no previous works have used PANAS to study VR crowd simulations, and none have so far investigated user response to varying crowd density in VR.</p><p>The outcomes from our study comprise the following contributions to the study of VR crowd simulation.</p><ul class="u-list-style-bullet">
                    <li>
                      <p>We use the PANAS self-report measure to evaluate the effect of density on participants’ affective state, while undertaking a simple manual task within the simulation. We demonstrate a significant increase in negative affect between low- and high-density conditions.</p>
                    </li>
                    <li>
                      <p>We use video data collected from participants to show significant changes in participants’ behaviour between density conditions, particularly regarding the use of gestures and reactive behaviours associated with observation and avoidance.</p>
                    </li>
                    <li>
                      <p>We have collected trajectory data from the simulation describing user speed and proximity to agents, which varies across different crowd densities. We use this data, together and post hoc interviews with participants, to support our findings.</p>
                    </li>
                  </ul><p>The remainder of our paper is organised as follows. We present a summary of previous related work in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0365-0#Sec3">2</a>, focusing on recent results which warrant our own study. We proceed to describe our simulation, experimental set-up in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0365-0#Sec7">3</a>, and methodology in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0365-0#Sec10">4</a>. We present our experimental results in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0365-0#Sec13">5</a>, and conclude with a discussion focusing on participants’ interactions within the simulation, relationships to previous work, application areas, and consideration for future work.</p></div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Previous work</h2><div class="c-article-section__content" id="Sec3-content"><p>A considerable body of previous work exists in the field of crowd simulation. The use of VR as a platform is not a new concept (for example, see Ulicny and Thalmann <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Ulicny B, Thalmann D (2001) Crowd simulation for interactive virtual environments and VR training systems. Springer, Vienna, pp 163–170" href="/article/10.1007/s10055-018-0365-0#ref-CR42" id="ref-link-section-d19374e575">2001</a>); however, the technology to properly realise such systems has only recently become widely available. Consequently, most related experimental work has been conducted relatively recently and falls broadly into the following three themes.</p><h3 class="c-article__sub-heading" id="Sec4">Validation of simulation models using VR</h3><p>The validation and comparison of crowd simulations is an active area of research. Some recent work has considered the use of human observation in VR as an objective validation method. For example, work by Pelechano et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008a" title="Pelechano N, Allbeck J, Badler N (2008a) Virtual crowds: methods, simulation, and control (synthesis lectures on computer graphics and animation). Morgan and Claypool Publishers, San Rafael" href="/article/10.1007/s10055-018-0365-0#ref-CR33" id="ref-link-section-d19374e585">2008a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Pelechano N, Stocker C, Allbeck J, Badler NI (2008b) Being a part of the crowd: towards validating vr crowds using presence. In: Proceedings of the international conference on autonomous agents and multiagent systems (Aamas), pp 136–142" href="/article/10.1007/s10055-018-0365-0#ref-CR34" id="ref-link-section-d19374e588">b</a>) is related to our own: they used presence as a metric to compare simulation methods (including social forces). Evaluation was conducted using a bespoke questionnaire and qualitative descriptions of video recordings. VR was also used by Rojas and Yang (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Rojas FA, Yang HS (2013) Immersive human-in-the-loop hmd evaluation of dynamic group behaviour in a pedestrian crowd simulation that uses group agent-based steering. In: Proceedings of international conference on virtual reality continuum and its applications in industry, VRCAI’13, ACM, New York, pp 31–40" href="/article/10.1007/s10055-018-0365-0#ref-CR35" id="ref-link-section-d19374e591">2013</a>) and Rojas et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Rojas FA, Yang HS, Tarnogol FM (2014) Safe navigation of pedestrians in social groups in a virtual urban environment. In: International conference on cyberworlds, pp 31–38" href="/article/10.1007/s10055-018-0365-0#ref-CR36" id="ref-link-section-d19374e594">2014</a>) to study small group formations, and Ahn et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Ahn J, Wang N, Thalmann D, Boulic R (2012) Within-crowd immersive evaluation of collision avoidance behaviors. In: Proceedings of the ACM SIGGRAPH international conference on virtual-reality continuum and its applications in industry, VRCAI’12, ACM, New York, pp 231–238" href="/article/10.1007/s10055-018-0365-0#ref-CR1" id="ref-link-section-d19374e597">2012</a>) used a similar method to compare different collision avoidance algorithms in a street scene. In this case, the user remained stationary, and observed the scene using a CAVE environment. Recently, Kim et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Kim S, Bera A, Best A, Chabra R, Manocha D (2016) Interactive and adaptive data-driven crowd simulation. In: 2016 IEEE virtual reality (VR). Greenville, SC, pp 29–38" href="/article/10.1007/s10055-018-0365-0#ref-CR23" id="ref-link-section-d19374e601">2016</a>) used both 2D screens and HMDs to rate the similarity of simulations to videos of real scenes. Model validation using VR represents an ongoing theme in crowd simulation research, and a recent summary and discussion is provided by Pelechano and Allbecky (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Pelechano N, Allbecky JM (2016) Feeling crowded yet?: crowd simulations for VR. In: 2016 IEEE virtual humans and crowds for immersive environments (VHCIE). Greenville, SC, pp 17–21" href="/article/10.1007/s10055-018-0365-0#ref-CR32" id="ref-link-section-d19374e604">2016</a>).</p><h3 class="c-article__sub-heading" id="Sec5">User experience and human–agent interactions</h3><p>Investigations into user experiences with VR displays are still being made. For example, Buttussi and Chittaro (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Buttussi F, Chittaro L (2018) Effects of different types of virtual reality display on presence and learning in a safety training scenario. IEEE Trans Visual Comput Graphics 24(2):1063–1076" href="/article/10.1007/s10055-018-0365-0#ref-CR4" id="ref-link-section-d19374e615">2018</a>) recently compared VR headsets with 2D displays; they used the IPQ (Schubert et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Schubert T, Friedmann F, Regenbrecht H (2001) The experience of presence: factor analytic insights. Presence Teleoper Virtual Environ 10(3):266–281" href="/article/10.1007/s10055-018-0365-0#ref-CR38" id="ref-link-section-d19374e618">2001</a>) to demonstrate in significantly increased sense of presence when using a high-fidelity headset, in an evacuation simulation. Similarly, work by Hupont et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Hupont I, Gracia J, Sanagustn L, Gracia MA (2015) How do new visual immersive systems influence gaming qoe? a use case of serious gaming with oculus rift. In: International workshop on quality of multimedia experience (QoMEX), pp 1–6" href="/article/10.1007/s10055-018-0365-0#ref-CR20" id="ref-link-section-d19374e621">2015</a>) indicates an increased sense of presence when using a HMD for a forklift simulator.</p><p>A number of researchers have sought to either use virtual agents to enhance users’ immersion or have added additional interactions such as gaze to increase users’ sense of presence. Garau et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Garau M, Slater M, Pertaub DP, Razzaque S (2005) The responses of people to virtual humans in an immersive virtual environment. Presence 14(1):104–116" href="/article/10.1007/s10055-018-0365-0#ref-CR15" id="ref-link-section-d19374e627">2005</a>) demonstrated that user response to virtual characters in VR is to some degree mediated by normal social behaviours; participants experienced a higher sense of personal contact when agents were responsive to them. Narang et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Narang S, Best A, Randhavane T, Shapiro A, Manocha D (2016) Pedvr: simulating gaze-based interactions between a real user and virtual crowds. In: Proceedings of the ACM conference on virtual reality software and technology, VRST’16, ACM, New York, pp 91–100" href="/article/10.1007/s10055-018-0365-0#ref-CR29" id="ref-link-section-d19374e630">2016</a>) adapted the bespoke questionnaire used by Garau et al. in their recent study of agent gaze and showed that participants had a preference for agents who made visual contact with them. Kyriakou et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Kyriakou M, Pan X, Chrysanthou Y (2015) Interaction with virtual agents-comparison of the participants’ experience between an IVR and a semi-IVR system. In: 2015 IEEE virtual reality (VR). Arles, pp 217–218" href="/article/10.1007/s10055-018-0365-0#ref-CR24" id="ref-link-section-d19374e633">2015</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Kyriakou M, Pan X, Chrysanthou Y (2016) Interaction with virtual crowd in immersive and semi-Immersive virtual reality systems. Comput Anim Virtual Worlds 28:e1729" href="/article/10.1007/s10055-018-0365-0#ref-CR25" id="ref-link-section-d19374e636">2016</a>) investigated how collision avoidance and other interactions (gaze and salutations) affected user experience. They found that collision avoidance improves the user’s reported sense of realism, whilst additional behavioural features increased presence. Sohre et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Sohre N, Mackin C, Interrante V, Guy SJ (2017) Evaluating collision avoidance effects on discomfort in virtual environments. In: 2017 IEEE virtual humans and crowds for immersive environments (VHCIE). Los Angeles, CA, pp 1–5" href="/article/10.1007/s10055-018-0365-0#ref-CR39" id="ref-link-section-d19374e639">2017</a>) also found that lack of collision avoidance decreased users’ sense of comfort while walking through a stream of agents.</p><h3 class="c-article__sub-heading" id="Sec6">Proxemics</h3><p>A number of researchers have studied participants’ response to the perceived physical proximity of virtual agents in VR environments. Wilcox et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Wilcox LM, Allison RS, Elfassy S, Grelik C (2006) Personal space in virtual reality. ACM Trans Appl Percept 3(4):412–428" href="/article/10.1007/s10055-018-0365-0#ref-CR44" id="ref-link-section-d19374e650">2006</a>) placed virtual characters into participant’s personal space, using a stereographic display, and guided by the well-known personal proximity zones defined by Hall (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1963" title="Hall ET (1963) A system for the notation of proxemic behavior1. Am Anthropol 65(5):1003–1026" href="/article/10.1007/s10055-018-0365-0#ref-CR17" id="ref-link-section-d19374e653">1963</a>). Electrodermal activity (EDA) was used as a quantifiable metric, which demonstrated that participants’ arousal response to virtual agents was comparable to their responses to real people. Llobera et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Llobera J, Spanlang B, Ruffini G, Slater M (2010) Proxemics with multiple dynamic characters in an immersive virtual environment. ACM Trans Appl Percept 8(1):3:1–3:12" href="/article/10.1007/s10055-018-0365-0#ref-CR27" id="ref-link-section-d19374e656">2010</a>) performed related experiments using a VR HMD and virtual characters which approached the stationary participant in groups of one to four agents. Again, EDA data were collected and showed a similar arousal response to close proximity. The form of the characters did not affect response (representations of inanimate objects were also used). Christou et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Christou C, Herakleous K, Tzanavari A, Poullis C (2015) Psychophysiological responses to virtual crowds: implications for wearable computing. In: International conference on affective computing and intelligent interaction (ACII), pp 35–41. &#xA;                    https://doi.org/10.1109/acii.2015.7344548&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-018-0365-0#ref-CR5" id="ref-link-section-d19374e659">2015</a>) performed a similar study: participants remained stationary in a CAVE environment, and groups of six agents were used, either stopping at predefined distances (similar to Llobera et al.) or passing with the same minimum distances. Similar results were achieved using EDA, and a memory test was also used: cognitive performance was found to be reduced under close proximity.</p><p>Bruneau et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Bruneau J, Olivier AH, Pettr J (2015) Going through, going around: a study on individual avoidance of groups. IEEE Trans Vis Comput Graph 21(4):520–528" href="/article/10.1007/s10055-018-0365-0#ref-CR3" id="ref-link-section-d19374e665">2015</a>) investigated group avoidance behaviour in a VR CAVE environment. Participants were able to adapt their distance from a group of agents, by choosing a trajectory to navigate between two points (crossing the group’s path). Participants used a joystick control to navigate, and trajectories were recorded and used to build an energy-based avoidance behaviour model. A small number of previous studies have studied behaviour of walking participants in VR environments, using static obstructions. Gérin-Lajoie et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Gérin-Lajoie M, Richards CL, Fung J, McFadyen BJ (2008) Characteristics of personal space during obstacle circumvention in physical and virtual environments. Gait Posture 27(2):239–247" href="/article/10.1007/s10055-018-0365-0#ref-CR16" id="ref-link-section-d19374e668">2008</a>) used a static cylinder obstruction to compare avoidance distances of walking pedestrians in both real and virtual reality conditions. They used an HMD for the virtual environment and found that participants allowed slightly larger distances as compared to the real obstruction. Similar results were also reported by Fink et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Fink PW, Foo PS, Warren WH (2007) Obstacle avoidance during walking in real and virtual environments. ACM Trans Appl Percept 4(1):2" href="/article/10.1007/s10055-018-0365-0#ref-CR14" id="ref-link-section-d19374e671">2007</a>). More recently, Sanz et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Sanz FA, Olivier AH, Bruder G, Pettré J, Lécuyer A (2015) Virtual proxemics: locomotion in the presence of obstacles in large immersive projection environments. In: 2015 IEEE virtual reality (VR). Arles, pp 75–80" href="/article/10.1007/s10055-018-0365-0#ref-CR37" id="ref-link-section-d19374e674">2015</a>) similarly compared clearance distances in virtual environments using a stereoscopic immersive projection space. They also found increased distance in the virtual space and increased distance when a static anthropomorphic representation was used, rather than an inanimate object.</p><p>These studies demonstrate that users respond to the physical proximity of virtual characters in ways which are comparable to responses to real people. However, existing work is limited to specific contexts and interpretations. Wilcox et al., Llobera et al., and Christou et al. all used stationary participants and restricted agent interactions. Bruneau et al. allowed participants to move, but again only in a limited way, using a joystick control, in discrete scenarios. The small number of studies using walking participants was limited to single static obstructions. This theme is most closely related to our own, and motivates our examination of user response to varying crowd density. We assert that the successful integration of human and virtual agents within real simulations warrants study of human participants in open scenarios, using naturalistic locomotion methods, motivates our experimental design, presented in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0365-0#Sec10">4</a>. Furthermore, no existing work has directly measured affective state; we believe that this is an important dimension for understanding user experience and response, which compliments other measures, and uses this in our own work.</p></div></div></section><section aria-labelledby="Sec7"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7">Simulation model</h2><div class="c-article-section__content" id="Sec7-content"><p>We implemented our simulation using Unreal Engine 4 (UE4) and the HTC Vive VR platform. Sample screen images (taken in 2D) are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0365-0#Fig1">1</a>. Users held a pair of controllers, which were tracked and appeared in the simulation as a pair of hands. The HMD was also tracked, so that the user could move around the scene by walking: this was the only locomotion method available.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0365-0/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0365-0/MediaObjects/10055_2018_365_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0365-0/MediaObjects/10055_2018_365_Fig1_HTML.jpg" alt="figure1" loading="lazy" width="685" height="971" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Screenshots of the simulation. From top to bottom: low-, medium-, and high-density conditions</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0365-0/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>A larger number of models have been proposed for agent-based crowd simulation. Many of these are based on the well-known and popular social forces model (SFM) by Helbing and Molnar (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Helbing D, Molnar P (1995) Social force model for pedestrian dynamics. Phys Rev E 51:4282–4286" href="/article/10.1007/s10055-018-0365-0#ref-CR18" id="ref-link-section-d19374e715">1995</a>); for example, researchers have recently used this model directly to model evacuation scenarios (Sticco et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Sticco IM, Frank GA, Cerrotta S, Dorso CO (2017) Room evacuation through two contiguous exits. Physica A Stat Mech Appl 474:172–185" href="/article/10.1007/s10055-018-0365-0#ref-CR40" id="ref-link-section-d19374e718">2017</a>) and with adaptations for specific situations (e.g. Li et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Li W, Li Y, Yu P, Gong J, Shen S, Huang L, Liang J (2017) Modeling, simulation and analysis of the evacuation process on stairs in a multi-floor classroom building of a primary school. Physica A Stat Mech Appl 469:157–172" href="/article/10.1007/s10055-018-0365-0#ref-CR26" id="ref-link-section-d19374e721">2017</a>). Adaptations have been proposed to improve model performance (e.g. weighting forward motion, and adding groups, Farina et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Farina F, Fontanelli D, Garulli A, Giannitrapani A, Prattichizzo D (2017) Walking ahead: the headed social force model. PLoS ONE 12(1):e0169734" href="/article/10.1007/s10055-018-0365-0#ref-CR11" id="ref-link-section-d19374e724">2017</a>). It has also been used in some previous investigations of VR simulations (Pelechano et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008a" title="Pelechano N, Allbeck J, Badler N (2008a) Virtual crowds: methods, simulation, and control (synthesis lectures on computer graphics and animation). Morgan and Claypool Publishers, San Rafael" href="/article/10.1007/s10055-018-0365-0#ref-CR33" id="ref-link-section-d19374e727">2008a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Pelechano N, Stocker C, Allbeck J, Badler NI (2008b) Being a part of the crowd: towards validating vr crowds using presence. In: Proceedings of the international conference on autonomous agents and multiagent systems (Aamas), pp 136–142" href="/article/10.1007/s10055-018-0365-0#ref-CR34" id="ref-link-section-d19374e731">b</a>). We have therefore chosen to use a social forces simulation based on Helbing and Molnar (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Helbing D, Molnar P (1995) Social force model for pedestrian dynamics. Phys Rev E 51:4282–4286" href="/article/10.1007/s10055-018-0365-0#ref-CR18" id="ref-link-section-d19374e734">1995</a>) to create our simulation, as a baseline for user experience which can inform researchers and practitioners currently seeking to integrate VR with existing crowd simulations or those looking to design new experiences, with a variety of application areas and models.</p><p>We used the UE4 physics simulation (PhysX 3.3) to apply the model forces: we do not use explicit collision detection, as overlaps are handled by component forces of the model. We parameterised the model by hand, using test sequences observed in VR by two of the authors. These are shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0365-0#Tab1">1</a> and relate to the force equations as described by Pelechano et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008a" title="Pelechano N, Allbeck J, Badler N (2008a) Virtual crowds: methods, simulation, and control (synthesis lectures on computer graphics and animation). Morgan and Claypool Publishers, San Rafael" href="/article/10.1007/s10055-018-0365-0#ref-CR33" id="ref-link-section-d19374e743">2008a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Pelechano N, Stocker C, Allbeck J, Badler NI (2008b) Being a part of the crowd: towards validating vr crowds using presence. In: Proceedings of the international conference on autonomous agents and multiagent systems (Aamas), pp 136–142" href="/article/10.1007/s10055-018-0365-0#ref-CR34" id="ref-link-section-d19374e746">b</a>). The model was parameterised to produce walking speeds close to those of real pedestrians. We took samples of agent walking speeds during our experiments, which are reported in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0365-0#Sec13">5</a>, and show little variation across conditions.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Social force model parameters, used for simulation in unreal engine 4</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0365-0/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Previous work (e.g. Karamouzas et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Karamouzas I, Heil P, Van Beek P, Overmars M (2009) A predictive collision avoidance model for pedestrian simulation. In: Egges A, Geraerts R, Overmars M (eds) Motion in games. MIG 2009. Lecture Notes in Computer Science, vol 5884. Springer, Berlin, Heidelberg" href="/article/10.1007/s10055-018-0365-0#ref-CR22" id="ref-link-section-d19374e888">2009</a>) has noted that collision avoidance in social force models can result in late, high-curvature adjustments to trajectories. In our initial tests, direct head-on approaches between agents occasionally resulted in near-collisions and visible model overlap in bidirectional traffic. To mitigate this, we created early adjustments to head-on collision trajectories: in the case that two agents are travelling directly towards each other, we applied small additional and opposing impulses to each, perpendicular to their direction of travel.</p><p>Finally, we modified the force model to successfully incorporate the human participant as an active agent in the simulation. We note that repulsive forces between agents are symmetric and are tuned to produce mutual deflections which are sufficient to avoid collisions in most cases. However, no repulsive force is experienced by a human participant: in the case of human–agent interactions, the deflections are less, and more apparent collisions (or overlaps) occur. To avoid this, we use an asymmetric force similar to that of Curtis et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Curtis S, Zafar B, Gutub A, Manocha D (2013) Right of way: asymmetric agent interactions in crowds. Vis Comput 29(12):1277–1292" href="/article/10.1007/s10055-018-0365-0#ref-CR6" id="ref-link-section-d19374e895">2013</a>), so that agent forces are scaled when interacting with a human participant. We used a scaling factor of 2.0 in our experiments, which we set by trial and error during testing. This was sufficient to reduce collisions/overlaps to a comparable level. In all other respects, agents responded to the human participant in the same way as to other agents.</p><h3 class="c-article__sub-heading" id="Sec8">Other interactions</h3><p>Previous works (Kyriakou et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Kyriakou M, Pan X, Chrysanthou Y (2016) Interaction with virtual crowd in immersive and semi-Immersive virtual reality systems. Comput Anim Virtual Worlds 28:e1729" href="/article/10.1007/s10055-018-0365-0#ref-CR25" id="ref-link-section-d19374e905">2016</a>; Narang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Narang S, Best A, Randhavane T, Shapiro A, Manocha D (2016) Pedvr: simulating gaze-based interactions between a real user and virtual crowds. In: Proceedings of the ACM conference on virtual reality software and technology, VRST’16, ACM, New York, pp 91–100" href="/article/10.1007/s10055-018-0365-0#ref-CR29" id="ref-link-section-d19374e908">2016</a>) have shown that agent–human interactions such as gaze, salutations, and vocal interactions can increase users’ sense of presence and realism in VR. In our case, we are interested primarily in users response to the crowd simulation model itself. Furthermore, no existing works have investigated the effect of such interactions in high-density simulations, and we consider that they may not be consistent across different crowd densities; for example, agent gaze may increase presence in sparse interactions, but may be unnerving in denser crowds. We therefore omitted such interactions in our experiments, so that differences in user experience across conditions were produced only by agent behaviours generated by the simulation model, participant interactions with the agents, and differences in density. We suggest that the additional effects of agent gaze (for example) could be taken up as future work.</p><h3 class="c-article__sub-heading" id="Sec9">Experimental set-up</h3><p>Agents in the simulation were represented by animated models, created using Adobe Fuse™ and Mixamo™. We used 20 different models to create a heterogeneous crowd, though some repetition of characters was evident. Our scene reproduced the ground floor of a real campus building, constructed from CAD drawings. The area is a busy thoroughfare, with lots of bidirectional pedestrian traffic, and society stalls with staff interacting with passers-by.</p><p>Virtual characters were spawned at a set frequency at each end of the thoroughfare (one every 8 s at low density, 4 s at medium, and 1.75 s at high density) and move to a point at the opposite end, beyond the view of the participant. This appears as a naturalistic flow of pedestrians. A navigation mesh was used to generate way-points, and we varied the spawn rate for each of our experimental conditions (values reported in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0365-0#Sec13">5</a>).</p><p>We constructed a task-based scenario for our study. In the centre of the scene, we defined an area of approximately 14.6 m<sup>2</sup>, bounded by three tables: this area corresponds to the walkable area of the HTC Vive VR environment, such that the participant can walk between the tables in the virtual scene. A top-down view of the area is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0365-0#Fig2">2</a>. The markers A, B, and C show the table positions, and virtual agents traverse the area, with bidirectional pedestrian flow moving left–right in the direction indicated by the arrows. Agents moved across the full width of the area during simulation.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0365-0/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0365-0/MediaObjects/10055_2018_365_Fig2_HTML.png?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0365-0/MediaObjects/10055_2018_365_Fig2_HTML.png" alt="figure2" loading="lazy" width="685" height="375" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>The task area for our user study</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0365-0/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Participants were asked to move objects (bottles and cans) between the three tables, such that all cans were moved to Table C, and all bottles to Table B. This involved making a minimum of 14 distinct journeys perpendicular to the direction of agent traffic flow and 7 parallel journeys. The participant’s virtual hands could be used to pick up a single object at a time, but not to interact with agents. A circular area on the table surface changed colour to indicate completion of the task. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0365-0#Fig3">3</a> shows an example trajectory map for a participant while completing this task. The task is representative of actual tasks which are undertaken in the real-world space on which this virtual environment is modelled (drinks and food are often served from tables). Furthermore, we designed the activity intentionally to create interactions where participants walk both perpendicular and parallel to the flow of agents.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0365-0/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0365-0/MediaObjects/10055_2018_365_Fig3_HTML.png?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0365-0/MediaObjects/10055_2018_365_Fig3_HTML.png" alt="figure3" loading="lazy" width="685" height="315" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Trajectory map for a participant completing the task. Green lines represent agent trajectories, and red lines the participant. The area shown represents a space of approximately 15 m × 7.5 m</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0365-0/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div></div></div></section><section aria-labelledby="Sec10"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Experimental methodology</h2><div class="c-article-section__content" id="Sec10-content"><p>The experiment included three conditions, featuring varying degrees of crowd density. Density levels were set using by controlling character spawn rate, and measured density estimates in the area occupied by the player are reported in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0365-0#Sec13">5</a>. Screenshots from each condition are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0365-0#Fig1">1</a>.</p><h3 class="c-article__sub-heading" id="Sec11">Participants and procedure</h3><p>The study was carried out in the research spaces of the University of Lincoln and approved by the institution’s ethics board, following prescribed health and safety requirements for the use of VR equipment. The simulation was presented simultaneously on the HTC Vive headset and on a projection screen to facilitate video recording. Twenty-five participants (12 female, 13 male, mean age = 31.0, SD = 10.3) participated in the study. 14 participants had previously used VR equipment. The HTC Vive HMD is a wired device, and we took precautions to eliminate interference of the wiring with the participant while conducting their task. The wire was suspended from the ceiling, and the investigator also lifted the wire as required to enable smooth movement while walking. Participants reported post hoc that they were not aware of investigator intervention. Our experimental set-up is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0365-0#Fig4">4</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0365-0/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0365-0/MediaObjects/10055_2018_365_Fig4_HTML.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0365-0/MediaObjects/10055_2018_365_Fig4_HTML.jpg" alt="figure4" loading="lazy" width="685" height="600" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Our experimental set-up</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0365-0/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Participants gave informed consent and were reminded that they could stop the simulation if they felt uncomfortable. They completed a demographics questionnaire and training sequence in which they completed the task required in the conditions, but with no agents present. Participants were then given the opportunity to practise the main task before starting the experimental conditions. We assessed participants affective state before and after the training session. After training, participants entered the first, and then completed another questionnaire to assess their affective state. This process was repeated for all three conditions. The mean duration of trials ranged from 132 s in low density to 148 s in high density. At the end of the study, we conducted a semi-structured exit interview that explored their experience. The study followed a within-subjects design, and conditions were counterbalanced using a Latin square to avoid ordering effects. All sessions were video-recorded to allow for post hoc analysis of participant behaviour.</p><h3 class="c-article__sub-heading" id="Sec12">Measures</h3><p>The experiments included a range of dependent measures including logging of trajectory data within the simulation, participant responses to validated scales, and video data of participant behaviour. We use the positive affect negative affect schedule (PANAS) (Watson et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Watson D, Clark LA, Tellegen A (1988) Development and validation of brief measures of positive and negative affect: the panas scales. J Personal Soc Psychol 54(6):1063" href="/article/10.1007/s10055-018-0365-0#ref-CR43" id="ref-link-section-d19374e1026">1988</a>) as a validated self-report measure of user affect. PANAS has not be previously used for VR-based crowd simulation studies, but is widely used in related fields such as games user research; the scale comprises two dimensions: negative and positive. Based on previous works, which report a negative response to close proximity, we conjecture that discomfort due to crowding will be most evident in the negative dimension, and adopt the null hypothesis: <i>H</i><sub>0</sub> = there is no measurable difference in negative affect associated with changes in density of a virtual crowd.</p><p>We gathered trajectory data from participants: positions and orientations of the participant and agents were logged approximately 30 times/s and time-stamped, along with other events (for example, picking up objects). We post-processed this date in order to extract two metrics. We wish to estimate to what extent participants were impeded and so computed their mean walking speeds when crossing the walkable area: we defined a central area (with boundaries 0.5 m within the walkable area) and computed the speed for each visit into this area (in most cases this correlates to crossing the flow of virtual characters). We computed mean speeds for each participant, for each condition. To connect our work with existing work on proxemics, we also used this data to compute the mean minimum distance to an agent, for each condition. To this end, we took sample points at regular time intervals, and at each sample we computed the distance from the participant to the nearest agent. We were thus able to compute a mean distance to the nearest agent for each participant, across each condition.</p><p>We also wished to conduct a more detailed analysis of player behaviour, to quantify patterns of common behaviour, and also to further examine anecdotal accounts of participant behaviour from previous works (e.g. Pelechano et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008a" title="Pelechano N, Allbeck J, Badler N (2008a) Virtual crowds: methods, simulation, and control (synthesis lectures on computer graphics and animation). Morgan and Claypool Publishers, San Rafael" href="/article/10.1007/s10055-018-0365-0#ref-CR33" id="ref-link-section-d19374e1039">2008a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Pelechano N, Stocker C, Allbeck J, Badler NI (2008b) Being a part of the crowd: towards validating vr crowds using presence. In: Proceedings of the international conference on autonomous agents and multiagent systems (Aamas), pp 136–142" href="/article/10.1007/s10055-018-0365-0#ref-CR34" id="ref-link-section-d19374e1042">b</a>; Narang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Narang S, Best A, Randhavane T, Shapiro A, Manocha D (2016) Pedvr: simulating gaze-based interactions between a real user and virtual crowds. In: Proceedings of the ACM conference on virtual reality software and technology, VRST’16, ACM, New York, pp 91–100" href="/article/10.1007/s10055-018-0365-0#ref-CR29" id="ref-link-section-d19374e1045">2016</a>). Accordingly, we made video recordings of participant behaviour during all conditions. Initial coding schemes were developed through independent iterations by two of the investigators. These focused on aspects such as: different participant actions at distance (e.g. looking, stopping, or changing direction); reactions to close proximity of agents (e.g. side-stepping or reactive hand gestures); participants verbal reactions to the simulation; and operational artefacts, such as equipment adjustments. The coding scheme was developed using a subset of pilot data (five users) collected before the main study. The scheme was refined through iterative coding and comparison of individual videos, by the two investigators, guided by experiences reported by DeCuir-Gunby et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="DeCuir-Gunby JT, Marshall PL, McCulloch AW (2011) Developing and using a codebook for the analysis of interview data: an example from a professional development research project. Field Methods 23:136–155" href="/article/10.1007/s10055-018-0365-0#ref-CR8" id="ref-link-section-d19374e1048">2011</a>). Differences in individual interpretations were discussed and resolved through discussions; instances of potential ambiguity were identified and informal guidelines were agreed. (Although we note that in a some cases, some subjectivity in interpretation of actions remains.) The full data set was then coded by the first investigator.</p><p>The post hoc interviews explored participants’ perceptions of the conditions, feelings about real crowds, and to what extent they found the simulated behaviour realistic. We also enquired about interactions with the virtual agents, and whether participants found it easy or hard to move around. Interview results are reported to support quantitative findings.</p></div></div></section><section aria-labelledby="Sec13"><div class="c-article-section" id="Sec13-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec13">Results</h2><div class="c-article-section__content" id="Sec13-content"><p>In this section, we present quantitative results from the questionnaires, trajectory, and video data, and we provide qualitative data to further support our findings. Crowd density and speed measures were calculated post hoc from trajectory data. For density, the walkable area was sampled 20 times for each participant, for each condition, and the number of agents counted (500 samples per condition). A density measurement was computed, and the mean and standard variations are reported in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0365-0#Tab2">2</a>. The highest density level corresponds to approximately one agent per 2 m<sup>2</sup>, which can be challenging to negotiate at full walking speed in bidirectional traffic.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Density and speed of virtual agents for each condition, with corresponding spawn intervals</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0365-0/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec14">Participants’ response to the simulation</h3><p>Summary statistics of the results collected from each condition using the PANAS self-report questionnaires are presented in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0365-0#Tab3">3</a>, with corresponding box plots shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0365-0#Fig5">5</a>. The high-density condition showed higher mean values than the medium or low conditions, on the negative dimension, and a lower mean on the positive dimension. Our data showed significant deviation from the normal distribution, so we selected the Friedman test to examine the statistical significance of our results, which showed significant effects on the negative dimension <i>χ</i><sup>2</sup>(2) = 13.975, <i>p</i> = 0.001. Wilcoxon signed-rank tests were used post hoc, with a significance level set at <i>p </i> &lt; 0.05 (0.017 with Bonferroni correction). Statistically significant increases in negative affect were identified between high and medium density conditions (<i>Z</i> = − 2.842, <i>p</i> = 0.004) and high and low density conditions (<i>Z</i> = − 2.725, <i>p</i> = 0.006), establishing an increase in reported negative affect at the higher crowd density. There was no significant difference between the low and medium conditions (<i>Z</i> = − 1.393, <i>p</i> = 0.163). We accordingly reject the null hypothesis <i>H</i><sub>0</sub>. The Wilcoxon signed-rank tests (Bonferroni correction, significance level <i>p </i> &lt; 0.017) revealed no significant effect on positive affect between conditions.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Summary statistics of PANAS results (positive and negative dimensions)</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0365-0/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0365-0/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0365-0/MediaObjects/10055_2018_365_Fig5_HTML.png?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0365-0/MediaObjects/10055_2018_365_Fig5_HTML.png" alt="figure5" loading="lazy" width="685" height="255" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Box plots for positive and negative affect, by condition</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0365-0/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Regarding their responses to the simulation conditions, a number of participant comments mirrored quantitative results regarding negative affect, for example: “The more people there were the more frustrating I think it was<i>”,</i> and <i>“</i>it got more claustrophobic with more people”, another stated “I felt more anxious and more distressed because there were lots of people in the way”. When considering affective state, another aspect that warrants closer examination is participants’ interpretation of agent behaviour that emerged throughout analysis. Several participants described the agents as being “rude” or “aggressive”; for example “they didn’t stop and give way as you would expect from a real crowd they tended to be more aggressive”. Another participant commented: “if they saw me coming they wouldn’t change direction, it would almost elevate hostility. You almost feel like you’re being walked over”.</p><h3 class="c-article__sub-heading" id="Sec15">Trajectory data</h3><p>We used the trajectory data to further quantify features of participant activity and experience, and post-processed it to extract a number of metrics. A data file for one participant, for one condition, was incomplete: we removed this participant from our post-processing. We computed mean speeds for each participant, for each condition, and summary statistics are presented in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0365-0#Tab4">4</a>, with corresponding box plot in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0365-0#Fig6">6</a>. The data passed the Shapiro–Wilk test for normality (<i>p</i> &gt; 0.05). We used a repeated measures one-way ANOVA which revealed a main effect of density on speed at <i>p</i> &lt; 0.05 (<i>F</i>(2,46) = 41.339, <i>p</i> = 0.001, <i>ƞ</i><span class="c-stack">
                    <sup>2</sup><sub>
                    <i>p</i></sub>
                    
                  </span> = 0.977). Post hoc tests with Bonferroni correction showed significant differences between low- and high-density conditions (<i>p </i>= 0.001) and medium and high conditions (<i>p </i>= 0.001).</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 Summary statistics for participant walking speed while crossing flow of virtual agents</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0365-0/tables/4"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0365-0/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0365-0/MediaObjects/10055_2018_365_Fig6_HTML.png?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0365-0/MediaObjects/10055_2018_365_Fig6_HTML.png" alt="figure6" loading="lazy" width="685" height="255" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Box plots for mean velocity and closest approach, by condition</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0365-0/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Qualitative findings further support the notion that crowd density had an impact on participants’ ability to walk and complete their tasks. For example, one participant remarked “when there were less people it seemed less worrying cause there was more space and you could see a line to go through”. Along these lines, another participant stated “it was the only time I forgot what I was supposed to do” when describing the high-density condition. Additionally, there was some evidence that participants had difficulty in navigating past agents because their behaviour did not afford fully naturalistic interactions; for example, one participant reported that “they felt they were aware of me when they were in proximity to me. I didn’t feel they were aware of me in their trajectory”, and “They seemed like they had semi-awareness”. Another participant noted that “they weren’t stopping as they would in real life, like stop and let me go past, obviously, but they were changing direction if I was there”.</p><p>We computed a mean distance to nearest agent for each participant across each condition. The data passed the Shapiro–Wilk test for normality (<i>p</i> &gt; 0.05). Summary statistics are presented in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0365-0#Tab5">5</a>, with corresponding box plot in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0365-0#Fig6">6</a>. A repeated measures ANOVA revealed a main effect of density on proximity (<i>F</i>(2,46) = 766.938, <i>p</i> = 0.001, <i>ƞ</i><span class="c-stack">
                    <sup>2</sup><sub>
                    <i>p</i></sub>
                    
                  </span> = 0.971). Post hoc test with Bonferroni correction showed significant differences between all conditions at <i>p </i>&lt; 0.05 (all at <i>p </i>= 0.001). In Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0365-0#Sec18">6</a>, we discuss how this result connects our work to previous works in VR proxemics. We note that the proximity results in particular may depend to some extent on the model parameters, particularly as the parameters control the speed and rate of change in direction of agents. However, the parameters are consistent across conditions, so we can reasonably consider that the observed difference is due to the change in density of agents and response of the participants.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 Summary statistics for agent proximity</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0365-0/tables/5"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec16">Analysis of video data</h3><p>Our code book comprises 28 separate codes, which we further classified into broad categories, shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0365-0#Tab6">6</a>. We coded all videos from all conditions. Three video files were incomplete or did not record correctly due to equipment failure. We removed data from the corresponding participants, leaving data from 66 videos (22 participants). We then counted the codes in each video and computed the mean number of occurrences for each code (in a single video) for each condition. We used the Friedman test to identify eight codes which showed statistically significant differences (<i>p </i>&lt;0.05) between conditions, as described in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0365-0#Tab7">7</a>. We further used the Wilcoxon signed-rank post hoc test to identify statistically significant differences between pairs of conditions within the identified behaviours (assuming significance at 0.017 with Bonferroni correction). We then used the Wilcoxon signed pair test post hoc to identify statistically significant differences between pairs of conditions for those behaviours. These are shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0365-0#Tab8">8</a>.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-6"><figure><figcaption class="c-article-table__figcaption"><b id="Tab6" data-test="table-caption">Table 6 Behavioural code summary</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0365-0/tables/6"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-7"><figure><figcaption class="c-article-table__figcaption"><b id="Tab7" data-test="table-caption">Table 7 Statistically significant behaviours</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0365-0/tables/7"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-8"><figure><figcaption class="c-article-table__figcaption"><b id="Tab8" data-test="table-caption">Table 8 Post hoc tests on significant behaviours</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0365-0/tables/8"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>The codes in Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0365-0#Tab7">7</a> and <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0365-0#Tab8">8</a> mainly relate to considered actions and reactive behaviours (which show the biggest differentials in occurrences). Observational behaviours occur with high frequency in all conditions, but show no significant differences between densities with the exception of the watching behaviour which is prevalent in low and medium density. As with the affect measures, there is most differential between the high-density condition and the other two.</p><p>Interview results further explain some of these codes, suggesting that a few participants initially tried to interact with the agents in an experimental fashion, for example, speaking to or physically touch agents. For example, one participant commented that “I did say sorry once which was a bit odd”. From the perspective of future applications, this does hint at possible challenges for mixed human-agent VR simulations, if interactions are not fully intuitive (where simulations only model human movement, but not communication). Interviews also supplied evidence that some participants may be able to disassociate themselves from the simulation in order to complete the task. One participant stated “you realise they just of bounce off of you after a while oh well, just carry on walking through them” and another similarly said “The crowds activity didn’t really affect me at all, as soon as I realised that me bumping into them had no effect it didn’t seem to matter”.</p><h3 class="c-article__sub-heading" id="Sec17">Findings</h3><p>Here, we present our main findings with a focus on our initial research questions around the impact of crowd density on user experience and behaviour. Most significantly, our results show that high crowd density has a negative impact on participants’ affective state, as demonstrated by quantitative results for negative affect along with qualitative feedback from participants. This suggests that participants generally perceived high crowd density in VR as an uncomfortable experience, mirroring responses to real-world crowds, reported in previous works (for example, Filingeri et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Filingeri V, Eason K, Waterson P, Haslam R (2017) Factors influencing experience in crowds the participant perspective. Appl Ergon 59(Part A):431–441" href="/article/10.1007/s10055-018-0365-0#ref-CR13" id="ref-link-section-d19374e2703">2017</a>). However, interview feedback also suggests that certain agent behaviours were perceived as rude, possibly contributing to negative perceptions among participants. Thus, we conjecture that negative affect may be attributed to a combination of agent proximity and behavioural artefacts produced by the simulation model.</p><p>Additionally, we have shown through video analysis that higher crowd density affects participant behaviour on various levels, suggesting that participants found it more difficult to carry out the task in the high-density conditions. In terms of movement planning, the number of direction changes increased with density, and higher numbers of planned stops were observed at high density. Participants visually tracked agents more frequently in low density, and four reactive behaviours (avoiding and deflecting gestures, small reactions, and sudden stops) also occurred more often in high density. Interestingly, participant feedback generally supports the suggestion that higher density affected movement planning and execution; however, there was some evidence that a lack of realistic communication led to unnatural behaviours (for example, completely ignoring agents while carrying out the experimental task).</p></div></div></section><section aria-labelledby="Sec18"><div class="c-article-section" id="Sec18-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec18">Discussion</h2><div class="c-article-section__content" id="Sec18-content"><p>Our work explores the impact of crowd density on user experience in VR settings; it complements and extends existing work by evaluating user affect and behaviour when participants are performing a task-based activity in a continuous social forces-based simulation. Our results show a significant increase in negative affect in high crowd density as well as significant reduction in participant movement speed, increased proximity, and changes in some types of behaviour. Here, we discuss our results with a focus on the impact of crowd density in VR settings; we consider the implications of our findings for models of crowd behaviour, applications of VR crowds, and we generalise our findings beyond our experimental setting.</p><h3 class="c-article__sub-heading" id="Sec19">The impact of crowd density in VR settings</h3><p>A key motivation for our work is the potential to embed human participants into existing simulation models, for the purpose of developing a more detailed understanding of human behaviour in crowds of different densities. The advantages of including human participants are that existing agent models are comparatively simple and do not capture the full range of human response and behaviour (e.g. Moussaid et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Moussaid M, Kapadia M, Thrash T, Sumner RW, Gross M, Helbing D, Holscher C (2016) Crowd behaviour during high-stress evacuations in an immersive virtual environment. J R Soc Interface 13(122):20160414" href="/article/10.1007/s10055-018-0365-0#ref-CR28" id="ref-link-section-d19374e2726">2016</a>). However, crowd density is an important variable factor in real-life settings: evacuations or other extraordinary events are often characterised by unusually high crowd densities. Our results indicate a clear response to crowd density in VR, and we thus assert the utility of such simulation scenarios, and the intentional creation of stressful or challenging crowd conditions, which could help to better inform processes such evacuation planning, building design, event management, and training.</p><p>Our work contrasts with previous work in proxemics which uses either stationary participants or non-naturalistic control methods, such as game controllers. We used the HTC Vive platform, in which participants walk in a natural way while interacting with agents and are represented by a pair of hands with which they can interact with the environment. This incorporates a kinaesthetic dimension to the study: participants have a finer level control over interactions, proximity, and behaviour which they can express naturally through body movement and which are also subject to natural constraints such as balance.</p><p>We observed differentials in proximity by density, shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0365-0#Tab5">5</a>: these appear small compared to the granularities used in proxemics studies, but they show a significant effect which is the result of interactions between participants’ response to proximity, the movement-based interface provided by the platform, and the simulation itself. We believe that these give a more useful and deeper insight into user experience and response to increasing crowd density than previous studies and can help guide the design of mixed human–agent simulations.</p><h3 class="c-article__sub-heading" id="Sec20">Leveraging self-reported affect as indicator of human response to crowd density</h3><p>We again draw attention to the measurements and metrics used in our study. Previous works have mainly utilised participant presence (e.g. Witmer and Singer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Witmer BG, Singer MJ (1998) Measuring presence in virtual environments: a presence questionnaire. Presence Teleoper Virtual Environ 7(3):225–240" href="/article/10.1007/s10055-018-0365-0#ref-CR45" id="ref-link-section-d19374e2746">1998</a>), bespoke questionnaires, trajectory data, and bio-physical measures such as EDA. We have instead used the PANAS scale (Watson et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Watson D, Clark LA, Tellegen A (1988) Development and validation of brief measures of positive and negative affect: the panas scales. J Personal Soc Psychol 54(6):1063" href="/article/10.1007/s10055-018-0365-0#ref-CR43" id="ref-link-section-d19374e2749">1988</a>) which evaluates users’ affective state, rather than their perceptive or cognitive response. Previous work has correlated presence and emotional response (e.g. Diemer et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Diemer J, Alpers GW, Peperkorn HM, Shiban Y, Muhlberger A (2015) The impact of perception¨ and presence on emotional reactions: a review of research in virtual reality. Front Psychol 6:26" href="/article/10.1007/s10055-018-0365-0#ref-CR9" id="ref-link-section-d19374e2752">2015</a>); however, we believe that the affect scale, which is widely used in experimental psychology and games user research, gives a direct and validated measure of experience and user outcomes from a design perspective. Moreover, unlike EDA, which measures arousal, PANAS is suited to experimental contexts with significant user movement (e.g. walking). We have also systematically categorised and quantified user behaviours (previously reported anecdotally), and we believe that such measures are useful additional tools for future study.</p><h3 class="c-article__sub-heading" id="Sec21">Reconsidering models of crowd behaviour</h3><p>The combination of qualitative and quantitative data offers the opportunity to gain further insights into the use of models of crowd behaviour for human interaction, further addressing participants’ response to the simulation, agent behaviour, and interpretation of quantitative measures.</p><p>Many participants made comments about the general behaviour of agents which indicates a negative response or interpretation: for example, using descriptors such as “aggressive” or “rude”. These are direct responses to the simulation model, which, like most crowd simulations, is not explicitly designed for human interaction. This may be further exacerbated by an increase in artefacts such as rapid changes in agent direction and orientation, which are more common in higher densities and may influence user experience; however, participants did not comment on such artefacts. Together, this introduces a number of questions around the design of simulations which incorporate human participants, which warrant further study.</p><p>A number of previous works have looked at the use of gestures and other interactions in VR simulations, and the layering of such interactions on top of existing simulation models may go some way to alleviating this problem in future. This is a potentially interesting direction of future study, with good results reported by, for example, Narang et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Narang S, Best A, Randhavane T, Shapiro A, Manocha D (2016) Pedvr: simulating gaze-based interactions between a real user and virtual crowds. In: Proceedings of the ACM conference on virtual reality software and technology, VRST’16, ACM, New York, pp 91–100" href="/article/10.1007/s10055-018-0365-0#ref-CR29" id="ref-link-section-d19374e2769">2016</a>) and Kyriakou et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Kyriakou M, Pan X, Chrysanthou Y (2016) Interaction with virtual crowd in immersive and semi-Immersive virtual reality systems. Comput Anim Virtual Worlds 28:e1729" href="/article/10.1007/s10055-018-0365-0#ref-CR25" id="ref-link-section-d19374e2772">2016</a>); however, as we have noted, combining such techniques with varying density conditions is not necessarily straightforward. For example, there is potential for conflicting and confusing behaviours to arise and also for seemingly positive interactions to produce negative effects when combined with other conditions. For example, experiencing eye contact may put the user at ease in a sparsely populated environment, but could be intimidating or upsetting when experienced repeatedly in a dense crowd. As mentioned, we have omitted such interactions in order to isolate user response to the simulation model and density conditions; however, the use of such interactions warrants deeper consideration.</p><h3 class="c-article__sub-heading" id="Sec22">Application areas for VR crowd simulations</h3><p>Given that our work suggests an impact of virtual crowd density on the behaviour and affective state of individuals, we believe that it motivates the further study of simulations that prepare individuals for possibly challenging situations; for example, guiding evacuations. To this end, VR simulations could not only be used to induce negative affect through large sizes of crowds, but would also offer the opportunity to further adapt environmental factors that can contribute to difficult human behaviour, e.g. lighting and visibility, environmental noise, and comparable factors.</p><p>Additionally, there are a number of other potential application areas worthy of further consideration. We note firstly that VR has been widely used in therapy; for example, for treatment of anxiety conditions (Opris et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Opris D, Pintea S, Garc´ıa-Palacios A, Botella C, Szamoskozi S, David D (2012) Virtual reality exposure therapy in anxiety disorders: a quantitative meta-analysis. Depress Anxiety 29(2):85–93" href="/article/10.1007/s10055-018-0365-0#ref-CR30" id="ref-link-section-d19374e2787">2012</a>). We believe that our results motivate further study of the use of crowd simulations to either directly treat anxiety associated with crowds, or to use crowds to affect higher levels of stress or anxiety associated with other scenarios or tasks.</p><p>We also note that social force models are used outside of crowd simulations: for example, in robotics, such models are used to mediate human–robot interactions (HRI) (for example, Ferrer et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Ferrer G, Garrell A, Sanfeliu A (2013) Robot companion: a social-force based approach with human awareness-navigation in crowded environments. In: 2013 IEEE/RSJ international conference on intelligent robots and systems (IROS), pp 1688–1694" href="/article/10.1007/s10055-018-0365-0#ref-CR12" id="ref-link-section-d19374e2793">2013</a>). The use of VR crowd simulations could thus be developed as an effective research tools for HRI, for example, enabling the creation of extraordinary scenarios or the hypothetical deployment of large number of robots.</p></div></div></section><section aria-labelledby="Sec23"><div class="c-article-section" id="Sec23-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec23">Limitations and future work</h2><div class="c-article-section__content" id="Sec23-content"><p>We believe that our results are both more general and more detailed than previous studies in VR Crowd simulation. However, our findings need to be interpreted in the light of the following limitations. Our study employed a repeated-measures design that only offered short bouts of interaction with the VR simulation. To fully understand the impact of crowd density on human and agent behaviour, and possibly explore application to real-world scenarios, longer-term study of participants’ response to such simulations is warranted. Likewise, future work should explore the possibility of combining different measures of participant response to crowd simulations, for example, by combining self-report measures such as the PANAS questionnaire with physiological measures and integrate existing work that utilises means of measuring interaction between humans and agents, e.g. gaze.</p><p>In terms of technology, the HTC Vive only offers a restricted walkable area (which is typical of room-scale VR systems). This currently limits the scale and types of scenarios in which a human participant can engage. We propose that other methods of locomotion (or combined methods) could be investigated to alleviate this restriction. Teleportation methods are commonly used in games for movement over distance; however, we consider that the ability to displace oneself might substantially alter the effects we have described in this paper.</p><p>In our study, we represented participants in VR using a pair of active hands. Some previous works (Peck et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Peck TC, Seinfeld S, Aglioti SM, Slater M (2013) Putting yourself in the skin of a black avatar reduces implicit racial bias. Conscious Cognit 22(3):779–787" href="/article/10.1007/s10055-018-0365-0#ref-CR31" id="ref-link-section-d19374e2811">2013</a>) have shown that full body representation can significantly increase user’s sense of agency and ownership, and the use of such representations may alter users’ experience of virtual crowds. We also note that HMD view angle is narrower than normal human vision. This is common with HMDs; however, in dense situations this could contribute to increased sense of crowding, as peripheral vision is effectively reduced, or to some of the reported behaviours. For example, sudden reactions or gestures could, in some cases, be due to delayed perception of agents outside of the field of view.</p><p>Our findings (particularly comments made by participants) indicate that our choice of simulation model has had a direct affect on participants’ experiences. Indeed, this is unavoidable, as different models are likely to produce different behavioural artefacts. We used the social forces model by Helbing and Molnar (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Helbing D, Molnar P (1995) Social force model for pedestrian dynamics. Phys Rev E 51:4282–4286" href="/article/10.1007/s10055-018-0365-0#ref-CR18" id="ref-link-section-d19374e2817">1995</a>) as a baseline for user experience, as this model has been used extensively, and many adaptations have been proposed and are still being investigated by researchers. Predictive models (e.g. Karamouzas et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Karamouzas I, Heil P, Van Beek P, Overmars M (2009) A predictive collision avoidance model for pedestrian simulation. In: Egges A, Geraerts R, Overmars M (eds) Motion in games. MIG 2009. Lecture Notes in Computer Science, vol 5884. Springer, Berlin, Heidelberg" href="/article/10.1007/s10055-018-0365-0#ref-CR22" id="ref-link-section-d19374e2820">2009</a>) might provide a more positive user experience, and we propose to make comparisons with such models as future work. Despite the limitations of using a single model, we suggest that our results in high-density situations generalise to other models, where close contact is unavoidable.</p><p>Finally, we believe that the success of mixed human–agent simulations in VR require a new perspective on crowd simulation models. Currently, work in this area is focussed on determining whether agents’ interaction with each other appears realistic to a human observer. Such models also need to appear realistic when they are mediating interactions between agents and humans, so that participants can interact with them more naturally. This presents a quite different challenge for future work.</p></div></div></section><section aria-labelledby="Sec24"><div class="c-article-section" id="Sec24-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec24">Conclusion</h2><div class="c-article-section__content" id="Sec24-content"><p>In this paper, we explored the impact of crowd density on user experience and behaviour in VR simulations. We contribute a study of user affect and behaviour using a task-based scenario in a continuous simulation, in which we use crowd density as independent variable.</p><p>Our results demonstrate a significant increase in negative affect and reactive behaviour with increasing crowd density, which correlates with previous work in proxemics, and also with participants accounts of feelings about real crowds, suggesting that participants respond to crowd density in VR in a comparable way to real crowd situations. This opens up new opportunities for the refinement of simulation models along with the application of VR to explore crowd simulation along with human behaviour and suggests that VR can be leveraged to create virtual experiences that allow for the study of human behaviour that can be extrapolated to human response and action in real-world settings.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ahn J, Wang N, Thalmann D, Boulic R (2012) Within-crowd immersive evaluation of collision avoidance behaviors." /><p class="c-article-references__text" id="ref-CR1">Ahn J, Wang N, Thalmann D, Boulic R (2012) Within-crowd immersive evaluation of collision avoidance behaviors. In: Proceedings of the ACM SIGGRAPH international conference on virtual-reality continuum and its applications in industry, VRCAI’12, ACM, New York, pp 231–238</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="W. Boucsein, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Boucsein W (1992) Electrodermal activity. Plenum Press, New York" /><p class="c-article-references__text" id="ref-CR2">Boucsein W (1992) Electrodermal activity. Plenum Press, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Electrodermal%20activity&amp;publication_year=1992&amp;author=Boucsein%2CW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Bruneau, AH. Olivier, J. Pettr, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Bruneau J, Olivier AH, Pettr J (2015) Going through, going around: a study on individual avoidance of groups. " /><p class="c-article-references__text" id="ref-CR3">Bruneau J, Olivier AH, Pettr J (2015) Going through, going around: a study on individual avoidance of groups. IEEE Trans Vis Comput Graph 21(4):520–528</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTVCG.2015.2391862" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Going%20through%2C%20going%20around%3A%20a%20study%20on%20individual%20avoidance%20of%20groups&amp;journal=IEEE%20Trans%20Vis%20Comput%20Graph&amp;volume=21&amp;issue=4&amp;pages=520-528&amp;publication_year=2015&amp;author=Bruneau%2CJ&amp;author=Olivier%2CAH&amp;author=Pettr%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="F. Buttussi, L. Chittaro, " /><meta itemprop="datePublished" content="2018" /><meta itemprop="headline" content="Buttussi F, Chittaro L (2018) Effects of different types of virtual reality display on presence and learning i" /><p class="c-article-references__text" id="ref-CR4">Buttussi F, Chittaro L (2018) Effects of different types of virtual reality display on presence and learning in a safety training scenario. IEEE Trans Visual Comput Graphics 24(2):1063–1076</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTVCG.2017.2653117" aria-label="View reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Effects%20of%20different%20types%20of%20virtual%20reality%20display%20on%20presence%20and%20learning%20in%20a%20safety%20training%20scenario&amp;journal=IEEE%20Trans%20Visual%20Comput%20Graphics&amp;volume=24&amp;issue=2&amp;pages=1063-1076&amp;publication_year=2018&amp;author=Buttussi%2CF&amp;author=Chittaro%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Christou C, Herakleous K, Tzanavari A, Poullis C (2015) Psychophysiological responses to virtual crowds: impli" /><p class="c-article-references__text" id="ref-CR5">Christou C, Herakleous K, Tzanavari A, Poullis C (2015) Psychophysiological responses to virtual crowds: implications for wearable computing. In: International conference on affective computing and intelligent interaction (ACII), pp 35–41. <a href="https://doi.org/10.1109/acii.2015.7344548">https://doi.org/10.1109/acii.2015.7344548</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Curtis, B. Zafar, A. Gutub, D. Manocha, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Curtis S, Zafar B, Gutub A, Manocha D (2013) Right of way: asymmetric agent interactions in crowds. Vis Comput" /><p class="c-article-references__text" id="ref-CR6">Curtis S, Zafar B, Gutub A, Manocha D (2013) Right of way: asymmetric agent interactions in crowds. Vis Comput 29(12):1277–1292</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs00371-012-0769-x" aria-label="View reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Right%20of%20way%3A%20asymmetric%20agent%20interactions%20in%20crowds&amp;journal=Vis%20Comput&amp;volume=29&amp;issue=12&amp;pages=1277-1292&amp;publication_year=2013&amp;author=Curtis%2CS&amp;author=Zafar%2CB&amp;author=Gutub%2CA&amp;author=Manocha%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="M. Dawson, A. Schell, D. Filion, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Dawson M, Schell A, Filion D (2007) The electrodermal system. In: Cacioppo J, Tassinary L, Berntson G (eds) Th" /><p class="c-article-references__text" id="ref-CR7">Dawson M, Schell A, Filion D (2007) The electrodermal system. In: Cacioppo J, Tassinary L, Berntson G (eds) The handbook of psychophysiology. Cambridge University Press, Cambridge, pp 152–191</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20handbook%20of%20psychophysiology&amp;pages=152-191&amp;publication_year=2007&amp;author=Dawson%2CM&amp;author=Schell%2CA&amp;author=Filion%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JT. DeCuir-Gunby, PL. Marshall, AW. McCulloch, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="DeCuir-Gunby JT, Marshall PL, McCulloch AW (2011) Developing and using a codebook for the analysis of intervie" /><p class="c-article-references__text" id="ref-CR8">DeCuir-Gunby JT, Marshall PL, McCulloch AW (2011) Developing and using a codebook for the analysis of interview data: an example from a professional development research project. Field Methods 23:136–155</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1177%2F1525822X10388468" aria-label="View reference 8">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Developing%20and%20using%20a%20codebook%20for%20the%20analysis%20of%20interview%20data%3A%20an%20example%20from%20a%20professional%20development%20research%20project&amp;journal=Field%20Methods&amp;volume=23&amp;pages=136-155&amp;publication_year=2011&amp;author=DeCuir-Gunby%2CJT&amp;author=Marshall%2CPL&amp;author=McCulloch%2CAW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Diemer, GW. Alpers, HM. Peperkorn, Y. Shiban, A. Muhlberger, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Diemer J, Alpers GW, Peperkorn HM, Shiban Y, Muhlberger A (2015) The impact of perception¨ and presence on emo" /><p class="c-article-references__text" id="ref-CR9">Diemer J, Alpers GW, Peperkorn HM, Shiban Y, Muhlberger A (2015) The impact of perception¨ and presence on emotional reactions: a review of research in virtual reality. Front Psychol 6:26</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3389%2Ffpsyg.2015.00026" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20impact%20of%20perception%C2%A8%20and%20presence%20on%20emotional%20reactions%3A%20a%20review%20of%20research%20in%20virtual%20reality&amp;journal=Front%20Psychol&amp;volume=6&amp;publication_year=2015&amp;author=Diemer%2CJ&amp;author=Alpers%2CGW&amp;author=Peperkorn%2CHM&amp;author=Shiban%2CY&amp;author=Muhlberger%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="F. Farina, D. Fontanelli, A. Garulli, A. Giannitrapani, D. Prattichizzo, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Farina F, Fontanelli D, Garulli A, Giannitrapani A, Prattichizzo D (2017) Walking ahead: the headed social for" /><p class="c-article-references__text" id="ref-CR11">Farina F, Fontanelli D, Garulli A, Giannitrapani A, Prattichizzo D (2017) Walking ahead: the headed social force model. PLoS ONE 12(1):e0169734</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1371%2Fjournal.pone.0169734" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Walking%20ahead%3A%20the%20headed%20social%20force%20model&amp;journal=PLoS%20ONE&amp;volume=12&amp;issue=1&amp;publication_year=2017&amp;author=Farina%2CF&amp;author=Fontanelli%2CD&amp;author=Garulli%2CA&amp;author=Giannitrapani%2CA&amp;author=Prattichizzo%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ferrer G, Garrell A, Sanfeliu A (2013) Robot companion: a social-force based approach with human awareness-nav" /><p class="c-article-references__text" id="ref-CR12">Ferrer G, Garrell A, Sanfeliu A (2013) Robot companion: a social-force based approach with human awareness-navigation in crowded environments. In: 2013 IEEE/RSJ international conference on intelligent robots and systems (IROS), pp 1688–1694</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="V. Filingeri, K. Eason, P. Waterson, R. Haslam, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Filingeri V, Eason K, Waterson P, Haslam R (2017) Factors influencing experience in crowds the participant per" /><p class="c-article-references__text" id="ref-CR13">Filingeri V, Eason K, Waterson P, Haslam R (2017) Factors influencing experience in crowds the participant perspective. Appl Ergon 59(Part A):431–441</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.apergo.2016.09.009" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Factors%20influencing%20experience%20in%20crowds%20the%20participant%20perspective&amp;journal=Appl%20Ergon&amp;volume=59&amp;issue=Part%20A&amp;pages=431-441&amp;publication_year=2017&amp;author=Filingeri%2CV&amp;author=Eason%2CK&amp;author=Waterson%2CP&amp;author=Haslam%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="PW. Fink, PS. Foo, WH. Warren, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Fink PW, Foo PS, Warren WH (2007) Obstacle avoidance during walking in real and virtual environments. ACM Tran" /><p class="c-article-references__text" id="ref-CR14">Fink PW, Foo PS, Warren WH (2007) Obstacle avoidance during walking in real and virtual environments. ACM Trans Appl Percept 4(1):2</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F1227134.1227136" aria-label="View reference 13">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Obstacle%20avoidance%20during%20walking%20in%20real%20and%20virtual%20environments&amp;journal=ACM%20Trans%20Appl%20Percept&amp;volume=4&amp;issue=1&amp;publication_year=2007&amp;author=Fink%2CPW&amp;author=Foo%2CPS&amp;author=Warren%2CWH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Garau, M. Slater, DP. Pertaub, S. Razzaque, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Garau M, Slater M, Pertaub DP, Razzaque S (2005) The responses of people to virtual humans in an immersive vir" /><p class="c-article-references__text" id="ref-CR15">Garau M, Slater M, Pertaub DP, Razzaque S (2005) The responses of people to virtual humans in an immersive virtual environment. Presence 14(1):104–116</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F1054746053890242" aria-label="View reference 14">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20responses%20of%20people%20to%20virtual%20humans%20in%20an%20immersive%20virtual%20environment&amp;journal=Presence&amp;volume=14&amp;issue=1&amp;pages=104-116&amp;publication_year=2005&amp;author=Garau%2CM&amp;author=Slater%2CM&amp;author=Pertaub%2CDP&amp;author=Razzaque%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Gérin-Lajoie, CL. Richards, J. Fung, BJ. McFadyen, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Gérin-Lajoie M, Richards CL, Fung J, McFadyen BJ (2008) Characteristics of personal space during obstacle circ" /><p class="c-article-references__text" id="ref-CR16">Gérin-Lajoie M, Richards CL, Fung J, McFadyen BJ (2008) Characteristics of personal space during obstacle circumvention in physical and virtual environments. Gait Posture 27(2):239–247</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.gaitpost.2007.03.015" aria-label="View reference 15">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Characteristics%20of%20personal%20space%20during%20obstacle%20circumvention%20in%20physical%20and%20virtual%20environments&amp;journal=Gait%20Posture&amp;volume=27&amp;issue=2&amp;pages=239-247&amp;publication_year=2008&amp;author=G%C3%A9rin-Lajoie%2CM&amp;author=Richards%2CCL&amp;author=Fung%2CJ&amp;author=McFadyen%2CBJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="ET. Hall, " /><meta itemprop="datePublished" content="1963" /><meta itemprop="headline" content="Hall ET (1963) A system for the notation of proxemic behavior1. Am Anthropol 65(5):1003–1026" /><p class="c-article-references__text" id="ref-CR17">Hall ET (1963) A system for the notation of proxemic behavior1. Am Anthropol 65(5):1003–1026</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1525%2Faa.1963.65.5.02a00020" aria-label="View reference 16">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20system%20for%20the%20notation%20of%20proxemic%20behavior1&amp;journal=Am%20Anthropol&amp;volume=65&amp;issue=5&amp;pages=1003-1026&amp;publication_year=1963&amp;author=Hall%2CET">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Helbing, P. Molnar, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Helbing D, Molnar P (1995) Social force model for pedestrian dynamics. Phys Rev E 51:4282–4286" /><p class="c-article-references__text" id="ref-CR18">Helbing D, Molnar P (1995) Social force model for pedestrian dynamics. Phys Rev E 51:4282–4286</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1103%2FPhysRevE.51.4282" aria-label="View reference 17">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Social%20force%20model%20for%20pedestrian%20dynamics&amp;journal=Phys%20Rev%20E&amp;volume=51&amp;pages=4282-4286&amp;publication_year=1995&amp;author=Helbing%2CD&amp;author=Molnar%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Helbing, IJ. Farkas, P. Molnar, T. Vicsek, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Helbing D, Farkas IJ, Molnar P, Vicsek T (2002) Simulation of pedestrian crowds in normal and evacuation situa" /><p class="c-article-references__text" id="ref-CR19">Helbing D, Farkas IJ, Molnar P, Vicsek T (2002) Simulation of pedestrian crowds in normal and evacuation situations. Pedestr Evacuation Dyn 21(2):21–58</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Simulation%20of%20pedestrian%20crowds%20in%20normal%20and%20evacuation%20situations&amp;journal=Pedestr%20Evacuation%20Dyn&amp;volume=21&amp;issue=2&amp;pages=21-58&amp;publication_year=2002&amp;author=Helbing%2CD&amp;author=Farkas%2CIJ&amp;author=Molnar%2CP&amp;author=Vicsek%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hupont I, Gracia J, Sanagustn L, Gracia MA (2015) How do new visual immersive systems influence gaming qoe? a " /><p class="c-article-references__text" id="ref-CR20">Hupont I, Gracia J, Sanagustn L, Gracia MA (2015) How do new visual immersive systems influence gaming qoe? a use case of serious gaming with oculus rift. In: International workshop on quality of multimedia experience (QoMEX), pp 1–6</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Johansson, M. Batty, K. Hayashi, OA. Bar, D. Marcozzi, ZA. Memish, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Johansson A, Batty M, Hayashi K, Bar OA, Marcozzi D, Memish ZA (2012) Crowd and environmental management durin" /><p class="c-article-references__text" id="ref-CR21">Johansson A, Batty M, Hayashi K, Bar OA, Marcozzi D, Memish ZA (2012) Crowd and environmental management during mass gatherings. Lancet Infect Dis 12(2):150–156. <a href="https://doi.org/10.1016/S1473-3099(11)70287-0">https://doi.org/10.1016/S1473-3099(11)70287-0</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS1473-3099%2811%2970287-0" aria-label="View reference 20">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Crowd%20and%20environmental%20management%20during%20mass%20gatherings&amp;journal=Lancet%20Infect%20Dis&amp;doi=10.1016%2FS1473-3099%2811%2970287-0&amp;volume=12&amp;issue=2&amp;pages=150-156&amp;publication_year=2012&amp;author=Johansson%2CA&amp;author=Batty%2CM&amp;author=Hayashi%2CK&amp;author=Bar%2COA&amp;author=Marcozzi%2CD&amp;author=Memish%2CZA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="I. Karamouzas, P. Heil, P. Beek, M. Overmars, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Karamouzas I, Heil P, Van Beek P, Overmars M (2009) A predictive collision avoidance model for pedestrian simu" /><p class="c-article-references__text" id="ref-CR22">Karamouzas I, Heil P, Van Beek P, Overmars M (2009) A predictive collision avoidance model for pedestrian simulation. In: Egges A, Geraerts R, Overmars M (eds) Motion in games. MIG 2009. Lecture Notes in Computer Science, vol 5884. Springer, Berlin, Heidelberg</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Motion%20in%20games.%20MIG%202009&amp;publication_year=2009&amp;author=Karamouzas%2CI&amp;author=Heil%2CP&amp;author=Beek%2CP&amp;author=Overmars%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kim S, Bera A, Best A, Chabra R, Manocha D (2016) Interactive and adaptive data-driven crowd simulation. In: 2" /><p class="c-article-references__text" id="ref-CR23">Kim S, Bera A, Best A, Chabra R, Manocha D (2016) Interactive and adaptive data-driven crowd simulation. In: 2016 IEEE virtual reality (VR). Greenville, SC, pp 29–38</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kyriakou M, Pan X, Chrysanthou Y (2015) Interaction with virtual agents-comparison of the participants’ experi" /><p class="c-article-references__text" id="ref-CR24">Kyriakou M, Pan X, Chrysanthou Y (2015) Interaction with virtual agents-comparison of the participants’ experience between an IVR and a semi-IVR system. In: 2015 IEEE virtual reality (VR). Arles, pp 217–218</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Kyriakou, X. Pan, Y. Chrysanthou, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Kyriakou M, Pan X, Chrysanthou Y (2016) Interaction with virtual crowd in immersive and semi-Immersive virtual" /><p class="c-article-references__text" id="ref-CR25">Kyriakou M, Pan X, Chrysanthou Y (2016) Interaction with virtual crowd in immersive and semi-Immersive virtual reality systems. Comput Anim Virtual Worlds 28:e1729</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2Fcav.1729" aria-label="View reference 24">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Interaction%20with%20virtual%20crowd%20in%20immersive%20and%20semi-Immersive%20virtual%20reality%20systems&amp;journal=Comput%20Anim%20Virtual%20Worlds&amp;volume=28&amp;publication_year=2016&amp;author=Kyriakou%2CM&amp;author=Pan%2CX&amp;author=Chrysanthou%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="W. Li, Y. Li, P. Yu, J. Gong, S. Shen, L. Huang, J. Liang, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Li W, Li Y, Yu P, Gong J, Shen S, Huang L, Liang J (2017) Modeling, simulation and analysis of the evacuation " /><p class="c-article-references__text" id="ref-CR26">Li W, Li Y, Yu P, Gong J, Shen S, Huang L, Liang J (2017) Modeling, simulation and analysis of the evacuation process on stairs in a multi-floor classroom building of a primary school. Physica A Stat Mech Appl 469:157–172</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.physa.2016.11.047" aria-label="View reference 25">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Modeling%2C%20simulation%20and%20analysis%20of%20the%20evacuation%20process%20on%20stairs%20in%20a%20multi-floor%20classroom%20building%20of%20a%20primary%20school&amp;journal=Physica%20A%20Stat%20Mech%20Appl&amp;volume=469&amp;pages=157-172&amp;publication_year=2017&amp;author=Li%2CW&amp;author=Li%2CY&amp;author=Yu%2CP&amp;author=Gong%2CJ&amp;author=Shen%2CS&amp;author=Huang%2CL&amp;author=Liang%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Llobera, B. Spanlang, G. Ruffini, M. Slater, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Llobera J, Spanlang B, Ruffini G, Slater M (2010) Proxemics with multiple dynamic characters in an immersive v" /><p class="c-article-references__text" id="ref-CR27">Llobera J, Spanlang B, Ruffini G, Slater M (2010) Proxemics with multiple dynamic characters in an immersive virtual environment. ACM Trans Appl Percept 8(1):3:1–3:12</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F1857893.1857896" aria-label="View reference 26">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proxemics%20with%20multiple%20dynamic%20characters%20in%20an%20immersive%20virtual%20environment&amp;journal=ACM%20Trans%20Appl%20Percept&amp;volume=8&amp;issue=1&amp;pages=3%3A1-3%3A12&amp;publication_year=2010&amp;author=Llobera%2CJ&amp;author=Spanlang%2CB&amp;author=Ruffini%2CG&amp;author=Slater%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Moussaid, M. Kapadia, T. Thrash, RW. Sumner, M. Gross, D. Helbing, C. Holscher, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Moussaid M, Kapadia M, Thrash T, Sumner RW, Gross M, Helbing D, Holscher C (2016) Crowd behaviour during high-" /><p class="c-article-references__text" id="ref-CR28">Moussaid M, Kapadia M, Thrash T, Sumner RW, Gross M, Helbing D, Holscher C (2016) Crowd behaviour during high-stress evacuations in an immersive virtual environment. J R Soc Interface 13(122):20160414</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1098%2Frsif.2016.0414" aria-label="View reference 27">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Crowd%20behaviour%20during%20high-stress%20evacuations%20in%20an%20immersive%20virtual%20environment&amp;journal=J%20R%20Soc%20Interface&amp;volume=13&amp;issue=122&amp;publication_year=2016&amp;author=Moussaid%2CM&amp;author=Kapadia%2CM&amp;author=Thrash%2CT&amp;author=Sumner%2CRW&amp;author=Gross%2CM&amp;author=Helbing%2CD&amp;author=Holscher%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Narang S, Best A, Randhavane T, Shapiro A, Manocha D (2016) Pedvr: simulating gaze-based interactions between " /><p class="c-article-references__text" id="ref-CR29">Narang S, Best A, Randhavane T, Shapiro A, Manocha D (2016) Pedvr: simulating gaze-based interactions between a real user and virtual crowds. In: Proceedings of the ACM conference on virtual reality software and technology, VRST’16, ACM, New York, pp 91–100</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Opris, S. Pintea, A. Garc´ıa-Palacios, C. Botella, S. Szamoskozi, D. David, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Opris D, Pintea S, Garc´ıa-Palacios A, Botella C, Szamoskozi S, David D (2012) Virtual reality exposure therap" /><p class="c-article-references__text" id="ref-CR30">Opris D, Pintea S, Garc´ıa-Palacios A, Botella C, Szamoskozi S, David D (2012) Virtual reality exposure therapy in anxiety disorders: a quantitative meta-analysis. Depress Anxiety 29(2):85–93</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2Fda.20910" aria-label="View reference 29">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20exposure%20therapy%20in%20anxiety%20disorders%3A%20a%20quantitative%20meta-analysis&amp;journal=Depress%20Anxiety&amp;volume=29&amp;issue=2&amp;pages=85-93&amp;publication_year=2012&amp;author=Opris%2CD&amp;author=Pintea%2CS&amp;author=Garc%C2%B4%C4%B1a-Palacios%2CA&amp;author=Botella%2CC&amp;author=Szamoskozi%2CS&amp;author=David%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="TC. Peck, S. Seinfeld, SM. Aglioti, M. Slater, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Peck TC, Seinfeld S, Aglioti SM, Slater M (2013) Putting yourself in the skin of a black avatar reduces implic" /><p class="c-article-references__text" id="ref-CR31">Peck TC, Seinfeld S, Aglioti SM, Slater M (2013) Putting yourself in the skin of a black avatar reduces implicit racial bias. Conscious Cognit 22(3):779–787</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.concog.2013.04.016" aria-label="View reference 30">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Putting%20yourself%20in%20the%20skin%20of%20a%20black%20avatar%20reduces%20implicit%20racial%20bias&amp;journal=Conscious%20Cognit&amp;volume=22&amp;issue=3&amp;pages=779-787&amp;publication_year=2013&amp;author=Peck%2CTC&amp;author=Seinfeld%2CS&amp;author=Aglioti%2CSM&amp;author=Slater%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pelechano N, Allbecky JM (2016) Feeling crowded yet?: crowd simulations for VR. In: 2016 IEEE virtual humans a" /><p class="c-article-references__text" id="ref-CR32">Pelechano N, Allbecky JM (2016) Feeling crowded yet?: crowd simulations for VR. In: 2016 IEEE virtual humans and crowds for immersive environments (VHCIE). Greenville, SC, pp 17–21</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="N. Pelechano, J. Allbeck, N. Badler, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Pelechano N, Allbeck J, Badler N (2008a) Virtual crowds: methods, simulation, and control (synthesis lectures " /><p class="c-article-references__text" id="ref-CR33">Pelechano N, Allbeck J, Badler N (2008a) Virtual crowds: methods, simulation, and control (synthesis lectures on computer graphics and animation). Morgan and Claypool Publishers, San Rafael</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20crowds%3A%20methods%2C%20simulation%2C%20and%20control%20%28synthesis%20lectures%20on%20computer%20graphics%20and%20animation%29&amp;publication_year=2008&amp;author=Pelechano%2CN&amp;author=Allbeck%2CJ&amp;author=Badler%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pelechano N, Stocker C, Allbeck J, Badler NI (2008b) Being a part of the crowd: towards validating vr crowds u" /><p class="c-article-references__text" id="ref-CR34">Pelechano N, Stocker C, Allbeck J, Badler NI (2008b) Being a part of the crowd: towards validating vr crowds using presence. In: Proceedings of the international conference on autonomous agents and multiagent systems (Aamas), pp 136–142</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rojas FA, Yang HS (2013) Immersive human-in-the-loop hmd evaluation of dynamic group behaviour in a pedestrian" /><p class="c-article-references__text" id="ref-CR35">Rojas FA, Yang HS (2013) Immersive human-in-the-loop hmd evaluation of dynamic group behaviour in a pedestrian crowd simulation that uses group agent-based steering. In: Proceedings of international conference on virtual reality continuum and its applications in industry, VRCAI’13, ACM, New York, pp 31–40</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rojas FA, Yang HS, Tarnogol FM (2014) Safe navigation of pedestrians in social groups in a virtual urban envir" /><p class="c-article-references__text" id="ref-CR36">Rojas FA, Yang HS, Tarnogol FM (2014) Safe navigation of pedestrians in social groups in a virtual urban environment. In: International conference on cyberworlds, pp 31–38</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sanz FA, Olivier AH, Bruder G, Pettré J, Lécuyer A (2015) Virtual proxemics: locomotion in the presence of obs" /><p class="c-article-references__text" id="ref-CR37">Sanz FA, Olivier AH, Bruder G, Pettré J, Lécuyer A (2015) Virtual proxemics: locomotion in the presence of obstacles in large immersive projection environments. In: 2015 IEEE virtual reality (VR). Arles, pp 75–80</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Schubert, F. Friedmann, H. Regenbrecht, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Schubert T, Friedmann F, Regenbrecht H (2001) The experience of presence: factor analytic insights. Presence T" /><p class="c-article-references__text" id="ref-CR38">Schubert T, Friedmann F, Regenbrecht H (2001) The experience of presence: factor analytic insights. Presence Teleoper Virtual Environ 10(3):266–281</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474601300343603" aria-label="View reference 37">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20experience%20of%20presence%3A%20factor%20analytic%20insights&amp;journal=Presence%20Teleoper%20Virtual%20Environ&amp;volume=10&amp;issue=3&amp;pages=266-281&amp;publication_year=2001&amp;author=Schubert%2CT&amp;author=Friedmann%2CF&amp;author=Regenbrecht%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sohre N, Mackin C, Interrante V, Guy SJ (2017) Evaluating collision avoidance effects on discomfort in virtual" /><p class="c-article-references__text" id="ref-CR39">Sohre N, Mackin C, Interrante V, Guy SJ (2017) Evaluating collision avoidance effects on discomfort in virtual environments. In: 2017 IEEE virtual humans and crowds for immersive environments (VHCIE). Los Angeles, CA, pp 1–5</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="IM. Sticco, GA. Frank, S. Cerrotta, CO. Dorso, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Sticco IM, Frank GA, Cerrotta S, Dorso CO (2017) Room evacuation through two contiguous exits. Physica A Stat " /><p class="c-article-references__text" id="ref-CR40">Sticco IM, Frank GA, Cerrotta S, Dorso CO (2017) Room evacuation through two contiguous exits. Physica A Stat Mech Appl 474:172–185</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.physa.2017.01.079" aria-label="View reference 39">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Room%20evacuation%20through%20two%20contiguous%20exits&amp;journal=Physica%20A%20Stat%20Mech%20Appl&amp;volume=474&amp;pages=172-185&amp;publication_year=2017&amp;author=Sticco%2CIM&amp;author=Frank%2CGA&amp;author=Cerrotta%2CS&amp;author=Dorso%2CCO">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T-Q. Tang, Y-X. Shao, L. Chen, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Tang T-Q, Shao Y-X, Chen L (2017) Modeling pedestrian movement at the hall of high-speed railway station durin" /><p class="c-article-references__text" id="ref-CR41">Tang T-Q, Shao Y-X, Chen L (2017) Modeling pedestrian movement at the hall of high-speed railway station during the check-in process. Physica A Stat Mech Appl 467:157–166</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.physa.2016.10.008" aria-label="View reference 40">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 40 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Modeling%20pedestrian%20movement%20at%20the%20hall%20of%20high-speed%20railway%20station%20during%20the%20check-in%20process&amp;journal=Physica%20A%20Stat%20Mech%20Appl&amp;volume=467&amp;pages=157-166&amp;publication_year=2017&amp;author=Tang%2CT-Q&amp;author=Shao%2CY-X&amp;author=Chen%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="B. Ulicny, D. Thalmann, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Ulicny B, Thalmann D (2001) Crowd simulation for interactive virtual environments and VR training systems. Spr" /><p class="c-article-references__text" id="ref-CR42">Ulicny B, Thalmann D (2001) Crowd simulation for interactive virtual environments and VR training systems. Springer, Vienna, pp 163–170</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 41 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Crowd%20simulation%20for%20interactive%20virtual%20environments%20and%20VR%20training%20systems&amp;pages=163-170&amp;publication_year=2001&amp;author=Ulicny%2CB&amp;author=Thalmann%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Watson, LA. Clark, A. Tellegen, " /><meta itemprop="datePublished" content="1988" /><meta itemprop="headline" content="Watson D, Clark LA, Tellegen A (1988) Development and validation of brief measures of positive and negative af" /><p class="c-article-references__text" id="ref-CR43">Watson D, Clark LA, Tellegen A (1988) Development and validation of brief measures of positive and negative affect: the panas scales. J Personal Soc Psychol 54(6):1063</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2F0022-3514.54.6.1063" aria-label="View reference 42">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 42 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Development%20and%20validation%20of%20brief%20measures%20of%20positive%20and%20negative%20affect%3A%20the%20panas%20scales&amp;journal=J%20Personal%20Soc%20Psychol&amp;volume=54&amp;issue=6&amp;publication_year=1988&amp;author=Watson%2CD&amp;author=Clark%2CLA&amp;author=Tellegen%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="LM. Wilcox, RS. Allison, S. Elfassy, C. Grelik, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Wilcox LM, Allison RS, Elfassy S, Grelik C (2006) Personal space in virtual reality. ACM Trans Appl Percept 3(" /><p class="c-article-references__text" id="ref-CR44">Wilcox LM, Allison RS, Elfassy S, Grelik C (2006) Personal space in virtual reality. ACM Trans Appl Percept 3(4):412–428</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F1190036.1190041" aria-label="View reference 43">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 43 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Personal%20space%20in%20virtual%20reality&amp;journal=ACM%20Trans%20Appl%20Percept&amp;volume=3&amp;issue=4&amp;pages=412-428&amp;publication_year=2006&amp;author=Wilcox%2CLM&amp;author=Allison%2CRS&amp;author=Elfassy%2CS&amp;author=Grelik%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="BG. Witmer, MJ. Singer, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Witmer BG, Singer MJ (1998) Measuring presence in virtual environments: a presence questionnaire. Presence Tel" /><p class="c-article-references__text" id="ref-CR45">Witmer BG, Singer MJ (1998) Measuring presence in virtual environments: a presence questionnaire. Presence Teleoper Virtual Environ 7(3):225–240</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474698565686" aria-label="View reference 44">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 44 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Measuring%20presence%20in%20virtual%20environments%3A%20a%20presence%20questionnaire&amp;journal=Presence%20Teleoper%20Virtual%20Environ&amp;volume=7&amp;issue=3&amp;pages=225-240&amp;publication_year=1998&amp;author=Witmer%2CBG&amp;author=Singer%2CMJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X. Zheng, T. Zhong, M. Liu, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Zheng X, Zhong T, Liu M (2009) Modeling crowd evacuation of a building based on seven methodological approache" /><p class="c-article-references__text" id="ref-CR46">Zheng X, Zhong T, Liu M (2009) Modeling crowd evacuation of a building based on seven methodological approaches. Build Environ 44(3):437–445</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.buildenv.2008.04.002" aria-label="View reference 45">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 45 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Modeling%20crowd%20evacuation%20of%20a%20building%20based%20on%20seven%20methodological%20approaches&amp;journal=Build%20Environ&amp;volume=44&amp;issue=3&amp;pages=437-445&amp;publication_year=2009&amp;author=Zheng%2CX&amp;author=Zhong%2CT&amp;author=Liu%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Zibrek, E. Kokkinara, R. Mcdonnell, " /><meta itemprop="datePublished" content="2018" /><meta itemprop="headline" content="Zibrek K, Kokkinara E, Mcdonnell R (2018) The effect of realistic appearance of virtual characters in immersiv" /><p class="c-article-references__text" id="ref-CR47">Zibrek K, Kokkinara E, Mcdonnell R (2018) The effect of realistic appearance of virtual characters in immersive environments—does the character’s personality play a role? IEEE Trans Vis Comput Graph 24(4):1681–1690</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTVCG.2018.2794638" aria-label="View reference 46">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 46 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effect%20of%20realistic%20appearance%20of%20virtual%20characters%20in%20immersive%20environments%E2%80%94does%20the%20character%E2%80%99s%20personality%20play%20a%20role%3F&amp;journal=IEEE%20Trans%20Vis%20Comput%20Graph&amp;volume=24&amp;issue=4&amp;pages=1681-1690&amp;publication_year=2018&amp;author=Zibrek%2CK&amp;author=Kokkinara%2CE&amp;author=Mcdonnell%2CR">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-018-0365-0-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">School of Computer Science, University of Lincoln, Lincoln, UK</p><p class="c-article-author-affiliation__authors-list">Patrick Dickinson, Kieran Hicks, John Shearer &amp; Jacob Greenwood</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">e-Media Research Lab, KU Leuven, Leuven, Belgium</p><p class="c-article-author-affiliation__authors-list">Kathrin Gerling</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">School of Computer Science, University of Hull, Hull, UK</p><p class="c-article-author-affiliation__authors-list">John Murray</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Patrick-Dickinson"><span class="c-article-authors-search__title u-h3 js-search-name">Patrick Dickinson</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Patrick+Dickinson&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Patrick+Dickinson" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Patrick+Dickinson%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Kathrin-Gerling"><span class="c-article-authors-search__title u-h3 js-search-name">Kathrin Gerling</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Kathrin+Gerling&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Kathrin+Gerling" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Kathrin+Gerling%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Kieran-Hicks"><span class="c-article-authors-search__title u-h3 js-search-name">Kieran Hicks</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Kieran+Hicks&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Kieran+Hicks" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Kieran+Hicks%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-John-Murray"><span class="c-article-authors-search__title u-h3 js-search-name">John Murray</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;John+Murray&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=John+Murray" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22John+Murray%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-John-Shearer"><span class="c-article-authors-search__title u-h3 js-search-name">John Shearer</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;John+Shearer&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=John+Shearer" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22John+Shearer%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Jacob-Greenwood"><span class="c-article-authors-search__title u-h3 js-search-name">Jacob Greenwood</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Jacob+Greenwood&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jacob+Greenwood" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jacob+Greenwood%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-018-0365-0/email/correspondent/c1/new">Patrick Dickinson</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content">
                <p><b>Open Access</b> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<a href="http://creativecommons.org/licenses/by/4.0/" rel="license" itemprop="license">http://creativecommons.org/licenses/by/4.0/</a>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</p>
              <p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Virtual%20reality%20crowd%20simulation%3A%20effects%20of%20agent%20density%20on%20user%20experience%20and%20behaviour&amp;author=Patrick%20Dickinson%20et%20al&amp;contentID=10.1007%2Fs10055-018-0365-0&amp;publication=1359-4338&amp;publicationDate=2018-09-21&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-018-0365-0" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-018-0365-0" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Dickinson, P., Gerling, K., Hicks, K. <i>et al.</i> Virtual reality crowd simulation: effects of agent density on user experience and behaviour.
                    <i>Virtual Reality</i> <b>23, </b>19–32 (2019). https://doi.org/10.1007/s10055-018-0365-0</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-018-0365-0.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-02-08">08 February 2018</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-09-14">14 September 2018</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-09-21">21 September 2018</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2019-03-05">05 March 2019</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-018-0365-0" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-018-0365-0</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Crowd simulation</span></li><li class="c-article-subject-list__subject"><span itemprop="about">User experience</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Agent density</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-018-0365-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=365;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

