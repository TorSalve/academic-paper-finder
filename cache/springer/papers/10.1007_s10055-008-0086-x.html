<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Tangled reality"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Leonardo da Vinci was a strong advocate for using sketches to stimulate the human imagination. Sketching is often considered to be integral to the process of design, providing an open workspace for..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/12/1.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Tangled reality"/>

    <meta name="dc.source" content="Virtual Reality 2008 12:1"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2008-02-29"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2008 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Leonardo da Vinci was a strong advocate for using sketches to stimulate the human imagination. Sketching is often considered to be integral to the process of design, providing an open workspace for ideas. For these same reasons, children use sketching as a simple way to express visual ideas. By merging the abstraction of human drawings and the freedom of virtual reality with the tangibility of physical tokens, Tangled Reality creates a rich mixed reality workspace. Tangled Reality allows users to build virtual environments based on simple colored sketches and traverse them using physical vehicles overlayed with virtual imagery. This setup allows the user to &#8220;build&#8221; and &#8220;experience&#8221; mixed reality simulations without ever touching a standard computer interface."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2008-02-29"/>

    <meta name="prism.volume" content="12"/>

    <meta name="prism.number" content="1"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="37"/>

    <meta name="prism.endingPage" content="45"/>

    <meta name="prism.copyright" content="2008 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-008-0086-x"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-008-0086-x"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-008-0086-x.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-008-0086-x"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Tangled reality"/>

    <meta name="citation_volume" content="12"/>

    <meta name="citation_issue" content="1"/>

    <meta name="citation_publication_date" content="2008/03"/>

    <meta name="citation_online_date" content="2008/02/29"/>

    <meta name="citation_firstpage" content="37"/>

    <meta name="citation_lastpage" content="45"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-008-0086-x"/>

    <meta name="DOI" content="10.1007/s10055-008-0086-x"/>

    <meta name="citation_doi" content="10.1007/s10055-008-0086-x"/>

    <meta name="description" content="Leonardo da Vinci was a strong advocate for using sketches to stimulate the human imagination. Sketching is often considered to be integral to the process "/>

    <meta name="dc.creator" content="Kevin Ponto"/>

    <meta name="dc.creator" content="Falko Kuester"/>

    <meta name="dc.creator" content="Robert Nideffer"/>

    <meta name="dc.creator" content="Simon Penny"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Adamczyk JW (2005) Autocosm: gardens of thuban. In: Proceedings of the ACM SIGGRAPH 05 electronic art and animation catalog, 2005"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph; citation_title=The magicbook: a transitional ar interface; citation_author=M Billinghurst, H Kato, I Poupyrev, K Imamoto,  K Tachibana; citation_volume=25; citation_issue=5; citation_publication_date=2001; citation_pages=745-753; citation_doi=10.1016/S0097-8493(01)00117-0; citation_id=CR3"/>

    <meta name="citation_reference" content="Brady A, MacDonald B, Oakley I, Hughes S, O&#8217;Modhrain S (2002) Relay: a futuristic interface for remote driving. In: Proceedings of EuroHaptics, pp 8&#8211;10"/>

    <meta name="citation_reference" content="Chun B, Ishii H, Orbanes J, Pardiso J, Wisneski C (1999) Pingpongplus: design of an athletic-tangible interface for computer-supported cooperative play. CHI &#8242;99: Proceedings of the SIGCHI conference on Human factors in computing systems, pp 394&#8211;401"/>

    <meta name="citation_reference" content="citation_journal_title=Leonardo; citation_title=Amplifying the mind&#8217;s eye: sketching and visual cognition; citation_author=J Fish, S Scrivener; citation_volume=23; citation_issue=1; citation_publication_date=1990; citation_pages=117-126; citation_doi=10.2307/1578475; citation_id=CR6"/>

    <meta name="citation_reference" content="Ishii H, Ulmer B (1997) Tangible bits: towards seamless interfaces between people, bits and atoms. CHI &#8242;97: Proceedings of the SIGCHI conference on Human factors in computing systems, pp 234&#8211;241"/>

    <meta name="citation_reference" content="Kaplan AE, Keshav S, Schryer NL, Venutolo JH (1997) An internet accessible telepresence. AT&amp;T Bell Laboratories, Murray Hill"/>

    <meta name="citation_reference" content="Kato H, Billinghurst M, Poupyrev I, Imamoto K, Tachibana K (2000) Virtual object manipulation on a table-top ar environment. In: Proceedings of 1st international symposium on augmented reality (ISAR&#8217;00), pp 111&#8211;119"/>

    <meta name="citation_reference" content="citation_title=Artificial reality; citation_publication_date=1983; citation_id=CR11; citation_author=M Krugger; citation_publisher=Addison-Wesley"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoper Virtual Environ; citation_title=Augmented reality as a tool to aid the telerobotic exploration and characterization of remote environments; citation_author=SW Lawson, JRG Pretlove, AC Wheeler; citation_volume=11; citation_issue=4; citation_publication_date=2002; citation_pages=352-367; citation_doi=10.1162/105474602760204273; citation_id=CR12"/>

    <meta name="citation_reference" content="Metaxas G, Metin B, Schneider J, Shapiro G, Zhou W, Markopoulos P (2005) Scorpiodrome: an exploration in mixed reality social gaming for children. In: Proceedings of ACM conference on advances in computer entertainment"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=Virtual bounds: a teleoperated mixed reality; citation_author=K Ponto, F Kuester, R Nideffer, S Penny; citation_volume=10; citation_issue=1; citation_publication_date=2006; citation_pages=41-47; citation_doi=10.1007/s10055-006-0030-x; citation_id=CR14"/>

    <meta name="citation_reference" content="Schweikardt E, Gross MD (1998) Digital clay: deriving digital models from freehand sketches. In: Proceedings of ACADIA 1998, pp 202&#8211;211"/>

    <meta name="citation_reference" content="Skubic M, Bailey C, Chronis G (2003) A sketch interface for mobile robots. In: IEEE international conference on systems, man and cybernetics"/>

    <meta name="citation_reference" content="Smotherman M (1999) A brief history of microprogramming. 
                    http://www.cs.clemson.edu/~mark/uprog.html
                    
                  
                        "/>

    <meta name="citation_reference" content="Sugimoto M, Kojima M, Nakamura A, Kagotani G, Nii H, Inami M (2005) Augmented coliseum: display-based computing for augmented reality inspiration computing robot. In: Proceedings of horizontal interactive human-computer systems, pp 3&#8211;8"/>

    <meta name="citation_reference" content="Taylor R, Robinett W, Chi V, Brooks F, Wright W, Williams R, Snyder E (1993) A virtual-reality interface for the nanomanipulator: a scanning tunneling microscope. In: 20th Annual conference on Computer graphics and interactive techniques"/>

    <meta name="citation_author" content="Kevin Ponto"/>

    <meta name="citation_author_email" content="kponto@uci.edu"/>

    <meta name="citation_author_institution" content="Arts Computation Engineering, Calit2 Center of Gravity, Laboratory for Game Culture and Technology, The University of California, Irvine, USA"/>

    <meta name="citation_author" content="Falko Kuester"/>

    <meta name="citation_author_institution" content="Arts Computation Engineering, Calit2 Center of Gravity, Laboratory for Game Culture and Technology, The University of California, Irvine, USA"/>

    <meta name="citation_author" content="Robert Nideffer"/>

    <meta name="citation_author_institution" content="Arts Computation Engineering, Calit2 Center of Gravity, Laboratory for Game Culture and Technology, The University of California, Irvine, USA"/>

    <meta name="citation_author" content="Simon Penny"/>

    <meta name="citation_author_institution" content="Arts Computation Engineering, Calit2 Center of Gravity, Laboratory for Game Culture and Technology, The University of California, Irvine, USA"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-008-0086-x&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2008/03/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-008-0086-x"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Tangled reality"/>
        <meta property="og:description" content="Leonardo da Vinci was a strong advocate for using sketches to stimulate the human imagination. Sketching is often considered to be integral to the process of design, providing an open workspace for ideas. For these same reasons, children use sketching as a simple way to express visual ideas. By merging the abstraction of human drawings and the freedom of virtual reality with the tangibility of physical tokens, Tangled Reality creates a rich mixed reality workspace. Tangled Reality allows users to build virtual environments based on simple colored sketches and traverse them using physical vehicles overlayed with virtual imagery. This setup allows the user to “build” and “experience” mixed reality simulations without ever touching a standard computer interface."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Tangled reality | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-008-0086-x","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Mixed reality, Augmented reality, Teleoperations, Edutainment","kwrd":["Mixed_reality","Augmented_reality","Teleoperations","Edutainment"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-008-0086-x","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-008-0086-x","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=86;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-008-0086-x">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Tangled reality
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-008-0086-x.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-008-0086-x.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2008-02-29" itemprop="datePublished">29 February 2008</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Tangled reality</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Kevin-Ponto" data-author-popup="auth-Kevin-Ponto" data-corresp-id="c1">Kevin Ponto<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="The University of California" /><meta itemprop="address" content="grid.266093.8, 0000000106687243, Arts Computation Engineering, Calit2 Center of Gravity, Laboratory for Game Culture and Technology, The University of California, Irvine, CA, 92697, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Falko-Kuester" data-author-popup="auth-Falko-Kuester">Falko Kuester</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="The University of California" /><meta itemprop="address" content="grid.266093.8, 0000000106687243, Arts Computation Engineering, Calit2 Center of Gravity, Laboratory for Game Culture and Technology, The University of California, Irvine, CA, 92697, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Robert-Nideffer" data-author-popup="auth-Robert-Nideffer">Robert Nideffer</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="The University of California" /><meta itemprop="address" content="grid.266093.8, 0000000106687243, Arts Computation Engineering, Calit2 Center of Gravity, Laboratory for Game Culture and Technology, The University of California, Irvine, CA, 92697, USA" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Simon-Penny" data-author-popup="auth-Simon-Penny">Simon Penny</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="The University of California" /><meta itemprop="address" content="grid.266093.8, 0000000106687243, Arts Computation Engineering, Calit2 Center of Gravity, Laboratory for Game Culture and Technology, The University of California, Irvine, CA, 92697, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 12</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">37</span>–<span itemprop="pageEnd">45</span>(<span data-test="article-publication-year">2008</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">114 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">0 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-008-0086-x/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Leonardo da Vinci was a strong advocate for using sketches to stimulate the human imagination. Sketching is often considered to be integral to the process of design, providing an open workspace for ideas. For these same reasons, children use sketching as a simple way to express visual ideas. By merging the abstraction of human drawings and the freedom of virtual reality with the tangibility of physical tokens, <i>Tangled Reality</i> creates a rich mixed reality workspace. <i>Tangled Reality</i> allows users to build virtual environments based on simple colored sketches and traverse them using physical vehicles overlayed with virtual imagery. This setup allows the user to “build” and “experience” mixed reality simulations without ever touching a standard computer interface.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Studies have shown that humans acquire visual knowledge through a series of visual glances, each lasting less then 1/4 of a second. Very little of the field of view is actually analyzed in great detail by the human mind. What makes sketches so powerful is their ability to play on this element of the human cognitive process. Studies have shown that humans can recognize representations from simple line drawings as rapidly as from detailed photographs (Fish and Scrivener <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1990" title="Fish J, Scrivener S (1990) Amplifying the mind’s eye: sketching and visual cognition. Leonardo 23(1):117–126" href="/article/10.1007/s10055-008-0086-x#ref-CR6" id="ref-link-section-d80842e320">1990</a>).</p><p>The abstraction inherent in the sketches is often considered to be a vital component in the process of design. For this reason, Lenardo da Vinci was an advocate of sketching as a way to stimulate the imagination. Sketching allows people to communicate ideas in a way that can be seen as abstract but at the same time very literal and representive.</p><p>Virtuality also can be seen as a bridge between the metaphysical and the absolute. In the post World War II era, scientists were finally able to build complex models entirely inside of a computer. Suddenly, scientists were able to test their theories without the recurring costs (i.e., the time and money needed to make physical models). In many ways, this could be considered the birthplace of the modern day virtual world.</p><p>Since these days, computing power has increased exponentially. Simulations that were once considered to be too complicated for computers are now seen in realtime inside of general computer games. Yet the interfaces into these computers have remained rather isolated from their virtual environments. Most computer-users’ only feedback from their physical-world actions comes in the form of optical feedback accompanied by limited audio feedback. Some controllers provide users with haptic feedback, but this usually is done as an effect only.</p><p>
                        <i>Tangled Reality</i> presents a new approach to making and exploring virtual environments in physical ways. The system does not require any special or exotic equipment as far as the user is concerned. Users simply draw an environment on a standard 3 × 5 in. index card using multiple colored markers. The system aims to be as intuitive as possible, allowing users to generate complex environments without knowledge of the inner workings of the translation process. This allows a person or child who has never used the system before to be able to generate environments with very little instruction.</p><p>Users are then able to interface with the user-generated environment by placing a small remote control vehicle on a projection surface. The vehicle is captured by an overhead camera and is referenced into the generated virtual environment. An overhead world view is projected down onto the vehicle surface while a first person perspective is projected onto a hanging screen in back of the floor projection. Users are able to move the vehicle around the virtual environment through a standard driving interface (i.e., steering wheel and pedals). The vehicle is able to generate virtual world forces, while the virtual world is able to generate feedbacks in return on the physical vehicle.</p><p>
                        <i>Tangled Reality</i> draws heavily from a variety of disciplines. Fields such as teleoperation, augmented and mixed reality, machine vision, digital image processing, tangible interfaces as well as sketch-based interfaces have all provided an inspirational framework for this project. <i>Tangled Reality</i> uses many of the same components as <i>Virtual Bounds</i> (Ponto et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Ponto K, Kuester F, Nideffer R, Penny S (2006) Virtual bounds: a teleoperated mixed reality. Virtual Real 10(1):41–47" href="/article/10.1007/s10055-008-0086-x#ref-CR14" id="ref-link-section-d80842e350">2006</a>) but uses these components to achieve a different goal. Instead of attemping to create a system in which virtual actions cause real world actions, <i>Tangled Reality</i> allows users to more closely generate and traverse virtual environments through the physical blending of the lines between the virtual and the physical worlds. See Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0086-x#Fig1">1</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0086-x#Fig2">2</a> for actual and schematic views of the system.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig1_HTML.jpg" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>The system at work</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>A schematic front view of the system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>This research has potential applications in the field of edutainment. Users can create, explore, and experience by way of haptic feedback, mixed reality environments without ever touching a keyboard or mouse, nor ever looking at a computer monitor. By using simple schemes (such as color-based sketching) and playing on users common experiences (such as using an input which mimics a CD ROM) drive we have made a mixed reality system that is easily accessible for children to play with and learn from.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Related work</h2><div class="c-article-section__content" id="Sec2-content"><p>Image processing and object recognition are vital components of mixed reality systems. Krueger (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1983" title="Krugger M (1983) Artificial reality. Addison-Wesley, Reading" href="/article/10.1007/s10055-008-0086-x#ref-CR11" id="ref-link-section-d80842e409">1983</a>) was an early pioneer in the field of virtual reality and human computer interaction systems in the 1960s and 1970s. His work focused on systems in which user actions could be interpreted directly without the user communicating through a physical interface. His most recognized work, <i>Videoplace</i>, used innovative techniques to gather user information. The user was placed in front of a screen with backlighting, allowing a computer vision system to acquire user actions.</p><p>Researchers at the University of Missouri used sketching as a method to create transportation routes (Skubic et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Skubic M, Bailey C, Chronis G (2003) A sketch interface for mobile robots. In: IEEE international conference on systems, man and cybernetics" href="/article/10.1007/s10055-008-0086-x#ref-CR16" id="ref-link-section-d80842e418">2003</a>). The researchers used a PDA to gather the sketch data in order to make the system more easily editable (i.e., providing the ability for users to easily delete objects as well as facilitate undo functionality). Users were able to sketch simple maps with labeled obstacles and motion paths. By extracting these meta-data from the sketch, robots could be directed with knowledge of the surrounding enviroment.</p><p>
                        <i>Digital Clay</i> (Schweikardt and Gross <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Schweikardt E, Gross MD (1998) Digital clay: deriving digital models from freehand sketches. In: Proceedings of ACADIA 1998, pp 202–211" href="/article/10.1007/s10055-008-0086-x#ref-CR15" id="ref-link-section-d80842e427">1998</a>) provides a method for turning perspective sketches into three-dimensional (3D) models. Most programs that generate 3D models proceed from two or more two-dimensional (2D) viewpoints (i.e., sideview and topview). While this makes it easy for a computer program to recreate a 3D shape, it is often difficult for humans to visualize how multiple 2D views will look in a 3D perspective view. <i>Digital Clay</i> uses algorithms to determine faces from a perspective sketch and is able to create a 3D model. This project is an incredibly powerful tool for architects and designers.</p><p>Adamczyk (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Adamczyk JW (2005) Autocosm: gardens of thuban. In: Proceedings of the ACM SIGGRAPH 05 electronic art and animation catalog, 2005" href="/article/10.1007/s10055-008-0086-x#ref-CR1" id="ref-link-section-d80842e436">2005</a>) presented his work, <i>Autocosm: Gardens of Thuban</i> at the 2005 SIGGRAPH Electronic Theater. This work was shown as a pre-show live performance before the rest of the films were screened. <i>Autocosm: Gardens of Thuban</i> worked as a performance piece incorporating elements of animation, theater, dance, painting, sculpture, music, and interactive art. The virtual world of <i>Autocosm: Gardens of Thuban</i> began with a “blank” environment. Adamczyk “flew” through this environment with a joystick while music was mixed in the background. As the viewer was flown around the world, Adamczyk added virtual “plants” by sketching on a graphics tablet. The attributes of these virtual creations were directly controlled by the attributes of the stroke used to generate them. This piece is an interesting example of using abstract representation to create virtual creators and environments.</p><p>Several researchers have tried to integrate haptics with teleoperations to create a more “realistic” feel for the operator. Taylor et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Taylor R, Robinett W, Chi V, Brooks F, Wright W, Williams R, Snyder E (1993) A virtual-reality interface for the nanomanipulator: a scanning tunneling microscope. In: 20th Annual conference on Computer graphics and interactive techniques" href="/article/10.1007/s10055-008-0086-x#ref-CR18" id="ref-link-section-d80842e452">1993</a>) developed a virtual reality interface for a scanning, tunneling microscope, allowing users to touch and feel a surface at a microscopic level. Users were also allowed to make controlled modifications, such as sculpting, at an atomic scale. In another example, researchers used haptics to emulate the feel of piloting a teleoperated vehicle directly. Brady et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Brady A, MacDonald B, Oakley I, Hughes S, O’Modhrain S (2002) Relay: a futuristic interface for remote driving. In: Proceedings of EuroHaptics, pp 8–10" href="/article/10.1007/s10055-008-0086-x#ref-CR4" id="ref-link-section-d80842e455">2002</a>) developed a system to relay forces and torques experienced by a teleoperated vehicle back on the user’s controller. This allowed those piloting the vehicle to experience the same sensations that they would have experienced inside the vehicle.</p><p>Remote controlled (RC) devices have been used as an interface for a wide range of applications. Kaplan et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Kaplan AE, Keshav S, Schryer NL, Venutolo JH (1997) An internet accessible telepresence. AT&amp;T Bell Laboratories, Murray Hill" href="/article/10.1007/s10055-008-0086-x#ref-CR9" id="ref-link-section-d80842e461">1997</a>) presented internet accessible telepresence systems for a RC vehicle. By using a camera which was mounted on the front of the RC car, a user could drive the vehicle through a first-person perspective. Lawson et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Lawson SW, Pretlove JRG, Wheeler AC (2002) Augmented reality as a tool to aid the telerobotic exploration and characterization of remote environments. Presence Teleoper Virtual Environ 11(4):352–367" href="/article/10.1007/s10055-008-0086-x#ref-CR12" id="ref-link-section-d80842e464">2002</a>) created an augmented teleoperated system by combining a small RC vehicle’s perspective with a virtual environment. These teleoperation systems combine the advantages of viewpoint and remote control, while superimposing additional information, such as spatial dimensions, to enhance the user’s situational (or environmental) awareness.</p><p>Ishii and Ulmer (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Ishii H, Ulmer B (1997) Tangible bits: towards seamless interfaces between people, bits and atoms. CHI ′97: Proceedings of the SIGCHI conference on Human factors in computing systems, pp 234–241" href="/article/10.1007/s10055-008-0086-x#ref-CR8" id="ref-link-section-d80842e470">1997</a>) of the MIT Media Laboratory coined the term “tangible bits”, to describe these types of systems that involve physical action. As stated by Ishii and Ulmer,
</p><blockquote class="c-blockquote"><div class="c-blockquote__body">
                  <p>“Tangible Bits is an attempt to bridge the gap between cyberspace and the physical environment by making digital information (bits) tangible. We are developing ways to make bits accessible through the physical environment.” (Ishii and Ulmer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Ishii H, Ulmer B (1997) Tangible bits: towards seamless interfaces between people, bits and atoms. CHI ′97: Proceedings of the SIGCHI conference on Human factors in computing systems, pp 234–241" href="/article/10.1007/s10055-008-0086-x#ref-CR8" id="ref-link-section-d80842e477">1997</a>)</p>
                </div></blockquote>
                     <p>Chun et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Chun B, Ishii H, Orbanes J, Pardiso J, Wisneski C (1999) Pingpongplus: design of an athletic-tangible interface for computer-supported cooperative play. CHI ′99: Proceedings of the SIGCHI conference on Human factors in computing systems, pp 394–401" href="/article/10.1007/s10055-008-0086-x#ref-CR5" id="ref-link-section-d80842e485">1999</a>) used this concept of mixed reality to create an interface for an athletic-tangible computer supported cooperative play, termed <i>PingPongPlus</i>. The authors utilized an overhead camera to track a ping-pong ball during a normal ping-pong match. In this system, an overhead projector projected images onto the table to augment the real world game play. Different modes were created, in which different goals and images were displayed which enabled different types of gameplay. Chun et al. were not only able to augment reality, but also translate it, by creating new game interaction paradigms with which the participants could interact.</p><p>Other researchers, such as Billinghurst, have used machine vision to create augmented reality interfaces (Kato et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Kato H, Billinghurst M, Poupyrev I, Imamoto K, Tachibana K (2000) Virtual object manipulation on a table-top ar environment. In: Proceedings of 1st international symposium on augmented reality (ISAR’00), pp 111–119" href="/article/10.1007/s10055-008-0086-x#ref-CR10" id="ref-link-section-d80842e494">2000</a>; Billinghurst et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Billinghurst M, Kato H, Poupyrev I, Imamoto K, Tachibana K (2001) The magicbook: a transitional ar interface. Comput Graph 25(5):745–753" href="/article/10.1007/s10055-008-0086-x#ref-CR3" id="ref-link-section-d80842e497">2001</a>). By determining the placement and orientation of real world objects (fiducials), virtual objects could be overlaid in a manner corresponding to the user’s perspective. Users of these systems were commonly required to wear a clear head-mounted-display in order to achieve this hybrid viewpoint. The main advantage of this augmented reality technique was that a 3D view incorporating both the virtual and physical world was available. Other mixed reality projects have used remote control vehicles for the purposes of gaming (Sugimoto et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Sugimoto M, Kojima M, Nakamura A, Kagotani G, Nii H, Inami M (2005) Augmented coliseum: display-based computing for augmented reality inspiration computing robot. In: Proceedings of horizontal interactive human-computer systems, pp 3–8" href="/article/10.1007/s10055-008-0086-x#ref-CR13" id="ref-link-section-d80842e500">2005</a>; Metaxas et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Metaxas G, Metin B, Schneider J, Shapiro G, Zhou W, Markopoulos P (2005) Scorpiodrome: an exploration in mixed reality social gaming for children. In: Proceedings of ACM conference on advances in computer entertainment" href="/article/10.1007/s10055-008-0086-x#ref-CR7" id="ref-link-section-d80842e503">2005</a>). These systems utilize different technologies to implement the same style of mixed reality system. These systems were meant for entertainment, and have very similar interaction paradigms to common video shooter-style games. In this respect. these systems were extremely different to that of <i>Tangled Reality</i>.</p></div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Technical approach</h2><div class="c-article-section__content" id="Sec3-content"><p>The setup for <i>Tangled Reality</i> was comprised of three sections, the vision system, the client system and the cabinet system. Each component is described below.</p><h3 class="c-article__sub-heading" id="Sec4">Vision system</h3><p>The Vision Server was used to determine the position and orientation of the RC Vehicle. A digital camera equipped with a Firewire interface was mounted over the projection area. The camera was able to capture 24-bit images at 640 × 480 pixel resolution at 30 frames per s. This camera was mounted 10 ft above the surface and had a field-of-view (FOV) of an 8 ×  6 ft area, resulting in an image that was 0.113 × 0.09 in. per pixel.</p><p>A 1.25 GHz Macintosh G4 was connected to the iSight camera via the Firewire port. Custom software was written to extract frames from the camera and determine the RC vehicle’s position and orientation. The software was able to capture and process 25 640 × 480 pixel frames per s. The acquired data were passed to the Client System via an user datagram protocol (UDP) stream. For more information on the innerworkings of this process, refer to <i>Virtual Bounds</i> (Ponto et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Ponto K, Kuester F, Nideffer R, Penny S (2006) Virtual bounds: a teleoperated mixed reality. Virtual Real 10(1):41–47" href="/article/10.1007/s10055-008-0086-x#ref-CR14" id="ref-link-section-d80842e532">2006</a>).</p><h3 class="c-article__sub-heading" id="Sec5">Client system</h3><p>The User Client was responsible for coordinating all user interfaces and other servers. A dual 1.5 GHz Macintosh G5 computer was chosen. The User Client was directly connected to the control system which was comprised of a steering wheel and foot pedals as well as to the transmitter box. The User Client was also connected to the vision server and the cabinet server through UDP streams. In addition, it was connected to two digital projectors, one for the overhead view and one for the first-person perspective view.</p><p>A transmitter box was created by first disassembling a ZipZapsSE RC vehicle transmitter box (see below). Since the ZipZapsSE has proportional controls, controlling the device with a computer was somewhat more complicated then simply flipping switches with a transistor. An ATMEGA48 was selected as the interface between the User Client and the RC vehicle. By using pulse width modulation (PWM) through a large bypass capacitor (220 mf), voltage levels were able to be controlled and thus, converted into proportional control signals (i.e., more voltage would mean the front wheels would turn more to the right). The electronics were encased in plastic with switches and LEDs for user I/O.</p><p>Two projectors were set up for the demonstration installation. One was mounted approximately 12 ft off of the floor and set at a 90° angle to project directly down at the floor screen. The projected image was 57 × 76 in. Since the floor did not provide an optimal projection surface, a piece of light colored vinyl flooring material was used as the projection screen. Given the lighting conditions of the space, this material proved to be an adequate projection surface. A frame constructed of rigid foam provided soft physical boundaries for the RC vehicle as well as demarcating the bounds of the mixed reality workspace.</p><p>The second projector was mounted on a wall 30 ft from a hanging screen on which it was projecting. The hanging screen was 12 × 9 ft in size and was hung so the lower edge was 2 ft off of the floor. The projection size was 6 × 8 ft.</p><p>The RC Vehicle chosen was a ZipZapsSE. The ZipZapsSE has small form factor, 1/64 normal size, and proportional steering and speed control. The ZipZapsSE was available at an inexpensive price from local retailers. The price and availability allowed vehicles to be easily replaced. A new casing was made for the vehicle with the front of the vehicle colored orange and the back colored yellow. This configuration was necessary for the color-tracking process. (See <i>Virtual Bounds</i> Ponto et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Ponto K, Kuester F, Nideffer R, Penny S (2006) Virtual bounds: a teleoperated mixed reality. Virtual Real 10(1):41–47" href="/article/10.1007/s10055-008-0086-x#ref-CR14" id="ref-link-section-d80842e555">2006</a> for specifications on the color-tracking process.) See Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0086-x#Fig3">3</a> for schematic.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Data and processing</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec6">Cabinet system</h3><p>One part of the Cabinet System was the Cabinet Server. The Cabinet Server consisted of four main components: a light, a camera, an interface board (the Arduino) and a charger for the RC vehicle. The light used was a cylindrical full spectrum lamp. This provided uniform illumination of the sketched environment card while it was being imaged by the camera. The original off-the-shelf light was equipped with a capacitive touch on/off switch. This switch was bypassed with a capacitor to ground which was controlled by an ATMEGA8. A standard Dell power supply was removed from an old computer in order to power the cabinet. The enable line was shorted in order for the unit to turn on. An Arduino was used to interface between the Cabinet Server and the other electronics physically located inside the cabinet. This Arduino was a simple board consisting of a Atmel ATMEGA8, a USB port and header pins. The Cabinet Server communicated to the Arduino via the USB port on an emulated serial stream. The Arduino then set the pins according to the input received. It also monitored the charger and sent serial responses back to the Cabinet Server regarding the charger status (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0086-x#Fig4">4</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Cabinet server flowchart</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0086-x#Fig5">5</a> shows the data flow of the components inside the cabinet. The system was started when a user put a vehicle on the charger. This event was registered in the micro-controller and was passed on to the Cabinet Server. The Cabinet Server then sent the appropriate signals to the micro-controller to eject the card drive and to turn on the light. The Cabinet Server then analyzed the images from the camera to determine if the card drive was open or closed. Once the server determined the drive was closed, the system began the map acquisition process described below. Once this process was complete, the Cabinet Server sent a message to the interface client that a new message had been created. The message was stored on the network shared volume and a message was sent to the interface client informing it that a new image had been created. Finally, the Cabinet Server sent the signal to the micro-controller to turn off the light.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Sketch vision system flowchart</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The Cabinet Server was tasked with running all of the electronics inside of the cabinet and communicating with the User Client. A 1.25 GHz Macintosh G4 was chosen because the software from the vision server could easily be rewritten for the vision requirements of this server. The Cabinet Server was connected to a second iSight camera and the Arduino board for interfacing with the other electronics. The Cabinet Server communicated with the User Client via UDP streams. All generated images were stored on a shared network that was accessible via both computers.</p><p>The card drive was created as an efficient method to reproducibly position the sketched environment card under the camera and then return it to the user. The first step in the process was dismantling an old CD ROM drive. The exterior casing, laser and spindle were all removed. This allowed the CD tray to move freely from an open state to a closed state. A piece of rigid foam was milled out to be the size of a 3 × 5 in. index card with indentations on the sides to allow for users to easily remove cards once inserted. Leads were attached to the CD ROM eject button and taken into a transistor which was controlled by an ATMEGA8 microprocessor.</p><p>The Logitech WingMan Formula Force GP was chosen for the vehicle input device. The system worked like a standard car interface. Turning the steering wheel would turn the wheels of the RC vehicle proportionally. The pedals worked like those of bumper cars, for example the right pedal made the car go forward while the left pedal made the car go in reverse. The steering wheel had forcefeedback which was activated in response to actions of the RC vehicle.</p><h3 class="c-article__sub-heading" id="Sec7">Sketch vision system</h3><p>The second part of the Cabinet System was the Sketch Vision System. The purpose of the Sketch Vision System was to translate tangible drawings into virtual environments in a way that was as easy and intuitive as possible. Many sketch-based interfaces use a sketch-based grammar by tracking users’ pen movements in order to generate 3D virtual objects. By recognizing shapes and symbols, users can draw both objects and actions on the same space. This extra gain in functionality comes at the price of extra complexity as users must know the grammar of the system in order to use it.</p><p>The goals of <i>Tangible Reality</i> were very different from most sketch-based interfaces as it was designed for a very specific application and aimed to be accessible for a different kind of audience. Users were given an index card and four colored makers (yellow, green, blue and brown) and instructed to draw a map. Each color represented a different type of terrain (blue for water, brown for dirt, green for grass and yellow for sand). The intuitiveness of this system relied on user’s background and understanding of what a map was in this context (i.e., an overhead perspective looking straight down into an environment). Index cards were chosen because they present an area that was large enough to create details, but not so large that the coloring process was overly tedious. Cards also present a noteworthy reference to older computer interfaces (e.g., punch cards) (Smotherman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Smotherman M (1999) A brief history of microprogramming. &#xA;                    http://www.cs.clemson.edu/~mark/uprog.html&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-008-0086-x#ref-CR17" id="ref-link-section-d80842e653">2005</a>).</p><p>The Sketch Vision System was designed to create a simple and straight-forward interface that would also have power for abstraction. While it is impossible to create a one to one correspondence between a drawing and a 3D world, a simple approach would be to create a literal map substituting terrain types for colors. Unfortunately, the system would have to decide what kind of terrain to fill in for blank spaces. In this configuration, the user would have to color the entire card, even for simple images. To help mitigate this problem, the <i>Tangible Reality</i> system used a process similar to the flood fill algorithm. When the system encountered an uncolored pixel, it would attempt to determine if the pixel was surrounded by a color. If so, it would set the pixel color to the surrounding color. If the pixel was not within a closed color boundary, it would try to negotiate the color which should be set for the value by examining all surrounding pixel values. The system would also attempt to interpolate between different types of terrain to create a more believable environment.</p><p>A pixel was selected iteratively through the acquired image (matching the cards rotation and dimensions) to produce a terrain image. The system first checked to see if the pixel value was within the tolerance of any of the four colors that were predefined. If so, the value of the output image was set accordingly. If the pixel value did not match any of the predefined image colors, eight paths were traversed in different directions as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0086-x#Fig6">6</a>. Neighboring pixels were tested along the path until a pixel with a color within the matching tolerance was found. If no neighbors with pixel values that fulfilled the matching requirement, the value for dirt was returned. Once all eight paths had terminated, the maximum matching color was set for the pixel. For example, in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0086-x#Fig6">6</a> the pixel with the X was being tested. Since it was white (uncolored), paths would emanate from the center. In this case, all surrounding pixels were green in the color, so the outputted pixel would be set as green. This process became more complicated for cases in which the pixel was not enclosed by a boundary. In this case, rays were weighted for length termination and color in order to determine the appropriate fill color. This method proved to provide users with the “desired” generated environment most of the time.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Pixel diagram</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        </div></div></section><section aria-labelledby="Sec8"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Map and interface</h2><div class="c-article-section__content" id="Sec8-content"><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0086-x#Fig7">7</a> shows the process of converting the generated map image into a virtual environment. The code was written in an ARB fragment shader as to make the process very light on the CPU. First the program loaded all textures for grass, water, dirt, and sand. Each one of these textures was multiplied by the color channel defined for that type of texture (i.e., blue for water). After this process was complete, effects were added. The water was shifted to create a flowing effect and banks along the waters edge were created for added realism. This process allowed for a single rectangle to be rendered in the overhead view. The only modification for the first-person perspective was the addition of height. Height was given to be a set amount for a type of terrain and was then interpolated between terrains. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0086-x#Fig8">8</a> shows the results of this process.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig7_HTML.gif?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig7_HTML.gif" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>GPU flowchart</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig8_HTML.jpg?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig8_HTML.jpg" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Progression from user drawing (<i>far left</i>) to image map representation (l<i>eft center</i>) to screen capture of generated environment (overhead view<i> right center</i> and first person perspective<i> far right</i>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>These terrains were used to influence both the virtual characters as well as the physical probe. Different types of terrains created different types of driving behaviors, with dirt being faster and easier then other types of terrain such as grass.</p><p>Virtual balls were also affected by this terrain as each type of terrain was given its own friction coefficient. Simple physics were applied to these balls, so that they would roll down hills, bounce off walls and interact with the vehicle itself. Users were able to “push” these virtual balls around the world they had created. When two balls were pushed together, they would merge to create a larger ball. Mass was taken into consideration so that larger balls would “weigh” more and be harder for the vehicle to push.</p></div></div></section><section aria-labelledby="Sec9"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">In practice</h2><div class="c-article-section__content" id="Sec9-content"><p>
                        <i>Tangled Reality</i> was exhibited from May 19–27, 2006 in the the Beall Center for Arts and Technology at the University of California, Irvine. More than 100 people (many children among them) attended the show’s exhibition, and over two hundred virtual environments were generated.</p><p>This presentation surfaced several issues that have since been corrected for. The driving system was created for an average size adult. Children who were approximately 48 in. tall were able to use the system in its standard configuration, but children smaller than that had problems reaching both the pedals and the steering wheel. This did not stop the overly ambitious children who found ways to use the system in pairs (as seen in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0086-x#Fig9">9</a>). Since the initial exhibition, risers for pedals were added to accommodate a wider range of users. The system had to have many of the internal connections reinforced as many of the children put the system through a wide range of forces.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig9_HTML.jpg?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig9_HTML.jpg" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>On the<i> left</i>, a user operating the system in a standard fashion. On the<i> right</i>, two small users working together</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     </div></div></section><section aria-labelledby="Sec10"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Applications</h2><div class="c-article-section__content" id="Sec10-content"><p>
                        <i>Tangled Reality</i> aims to create a simple and straightforward way to create and explore virtual environments. Sketching skills are part of childhood development and are a common way for children to express their imagination. By giving children makers and paper, the process of creation is fairly intuitive for most. Children can explore the enviroment in two ways, either by using the steering wheel and pedals or by simply moving the car using their hands (as seen in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0086-x#Fig10">10</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig10_HTML.jpg?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0086-x/MediaObjects/10055_2008_86_Fig10_HTML.jpg" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>User demonstating the tangible nature of the system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0086-x/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Both methods allow for different types of interactions. Many children, when given the system, liked to use the driving interface as it let them be more like grown ups. This method also allowed for feedback to be given through a haptic controller. Users who interfaced with the system through tangible freehand movement of vehicles would not get the feedback forces, but would be able to still see the first person perspective and interface with the virtual world. This allowed those users who are uncomfortable using a standard car interface to still experience the system in a the same way they would playing in a sandbox.</p><p>In the interaction paradigm set up for the Beall Center for Arts and Technology exhibition users were able to “push” balls around the virtual world they had created. Through the system children were able to learn about physics in a way which was fun and entertaining. Even though this was a simple interaction paradigm, knowledge can be garnered. The <i>Tangled Reality</i> system is very versatile and can easily be used in a variety of other learning based projects.</p></div></div></section><section aria-labelledby="Sec11"><div class="c-article-section" id="Sec11-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec11">Conclusion</h2><div class="c-article-section__content" id="Sec11-content"><p>
                        <i>Tangled Reality</i> presents a mixed reality workspace allowing users to both create and experience virtual worlds through tangible interfaces in a way which is relatively easy and intuitive. This work is a step in the direction of seamless interfaces in which traditional imput devices (e.g., keyboard, mouse) are not required. This allows for a wide range of audience members to be able to use the system effectively and is specially designed to be in tune with the construction modality of children. Future work may include developing new types of exploratory procedures, such as multi-agent simulations.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Adamczyk JW (2005) Autocosm: gardens of thuban. In: Proceedings of the ACM SIGGRAPH 05 electronic art and anim" /><p class="c-article-references__text" id="ref-CR1">Adamczyk JW (2005) Autocosm: gardens of thuban. In: Proceedings of the ACM SIGGRAPH 05 electronic art and animation catalog, 2005</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Billinghurst, H. Kato, I. Poupyrev, K. Imamoto, K. Tachibana, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Billinghurst M, Kato H, Poupyrev I, Imamoto K, Tachibana K (2001) The magicbook: a transitional ar interface. " /><p class="c-article-references__text" id="ref-CR3">Billinghurst M, Kato H, Poupyrev I, Imamoto K, Tachibana K (2001) The magicbook: a transitional ar interface. Comput Graph 25(5):745–753</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0097-8493%2801%2900117-0" aria-label="View reference 2">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20magicbook%3A%20a%20transitional%20ar%20interface&amp;journal=Comput%20Graph&amp;volume=25&amp;issue=5&amp;pages=745-753&amp;publication_year=2001&amp;author=Billinghurst%2CM&amp;author=Kato%2CH&amp;author=Poupyrev%2CI&amp;author=Imamoto%2CK&amp;author=Tachibana%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Brady A, MacDonald B, Oakley I, Hughes S, O’Modhrain S (2002) Relay: a futuristic interface for remote driving" /><p class="c-article-references__text" id="ref-CR4">Brady A, MacDonald B, Oakley I, Hughes S, O’Modhrain S (2002) Relay: a futuristic interface for remote driving. In: Proceedings of EuroHaptics, pp 8–10</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chun B, Ishii H, Orbanes J, Pardiso J, Wisneski C (1999) Pingpongplus: design of an athletic-tangible interfac" /><p class="c-article-references__text" id="ref-CR5">Chun B, Ishii H, Orbanes J, Pardiso J, Wisneski C (1999) Pingpongplus: design of an athletic-tangible interface for computer-supported cooperative play. CHI ′99: Proceedings of the SIGCHI conference on Human factors in computing systems, pp 394–401</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Fish, S. Scrivener, " /><meta itemprop="datePublished" content="1990" /><meta itemprop="headline" content="Fish J, Scrivener S (1990) Amplifying the mind’s eye: sketching and visual cognition. Leonardo 23(1):117–126" /><p class="c-article-references__text" id="ref-CR6">Fish J, Scrivener S (1990) Amplifying the mind’s eye: sketching and visual cognition. Leonardo 23(1):117–126</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.2307%2F1578475" aria-label="View reference 5">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Amplifying%20the%20mind%E2%80%99s%20eye%3A%20sketching%20and%20visual%20cognition&amp;journal=Leonardo&amp;volume=23&amp;issue=1&amp;pages=117-126&amp;publication_year=1990&amp;author=Fish%2CJ&amp;author=Scrivener%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ishii H, Ulmer B (1997) Tangible bits: towards seamless interfaces between people, bits and atoms. CHI ′97: Pr" /><p class="c-article-references__text" id="ref-CR8">Ishii H, Ulmer B (1997) Tangible bits: towards seamless interfaces between people, bits and atoms. CHI ′97: Proceedings of the SIGCHI conference on Human factors in computing systems, pp 234–241</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kaplan AE, Keshav S, Schryer NL, Venutolo JH (1997) An internet accessible telepresence. AT&amp;T Bell Laboratorie" /><p class="c-article-references__text" id="ref-CR9">Kaplan AE, Keshav S, Schryer NL, Venutolo JH (1997) An internet accessible telepresence. AT&amp;T Bell Laboratories, Murray Hill</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kato H, Billinghurst M, Poupyrev I, Imamoto K, Tachibana K (2000) Virtual object manipulation on a table-top a" /><p class="c-article-references__text" id="ref-CR10">Kato H, Billinghurst M, Poupyrev I, Imamoto K, Tachibana K (2000) Virtual object manipulation on a table-top ar environment. In: Proceedings of 1st international symposium on augmented reality (ISAR’00), pp 111–119</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="M. Krugger, " /><meta itemprop="datePublished" content="1983" /><meta itemprop="headline" content="Krugger M (1983) Artificial reality. Addison-Wesley, Reading" /><p class="c-article-references__text" id="ref-CR11">Krugger M (1983) Artificial reality. Addison-Wesley, Reading</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Artificial%20reality&amp;publication_year=1983&amp;author=Krugger%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SW. Lawson, JRG. Pretlove, AC. Wheeler, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Lawson SW, Pretlove JRG, Wheeler AC (2002) Augmented reality as a tool to aid the telerobotic exploration and " /><p class="c-article-references__text" id="ref-CR12">Lawson SW, Pretlove JRG, Wheeler AC (2002) Augmented reality as a tool to aid the telerobotic exploration and characterization of remote environments. Presence Teleoper Virtual Environ 11(4):352–367</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474602760204273" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Augmented%20reality%20as%20a%20tool%20to%20aid%20the%20telerobotic%20exploration%20and%20characterization%20of%20remote%20environments&amp;journal=Presence%20Teleoper%20Virtual%20Environ&amp;volume=11&amp;issue=4&amp;pages=352-367&amp;publication_year=2002&amp;author=Lawson%2CSW&amp;author=Pretlove%2CJRG&amp;author=Wheeler%2CAC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Metaxas G, Metin B, Schneider J, Shapiro G, Zhou W, Markopoulos P (2005) Scorpiodrome: an exploration in mixed" /><p class="c-article-references__text" id="ref-CR7">Metaxas G, Metin B, Schneider J, Shapiro G, Zhou W, Markopoulos P (2005) Scorpiodrome: an exploration in mixed reality social gaming for children. In: Proceedings of ACM conference on advances in computer entertainment</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Ponto, F. Kuester, R. Nideffer, S. Penny, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Ponto K, Kuester F, Nideffer R, Penny S (2006) Virtual bounds: a teleoperated mixed reality. Virtual Real 10(1" /><p class="c-article-references__text" id="ref-CR14">Ponto K, Kuester F, Nideffer R, Penny S (2006) Virtual bounds: a teleoperated mixed reality. Virtual Real 10(1):41–47</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10055-006-0030-x" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20bounds%3A%20a%20teleoperated%20mixed%20reality&amp;journal=Virtual%20Real&amp;volume=10&amp;issue=1&amp;pages=41-47&amp;publication_year=2006&amp;author=Ponto%2CK&amp;author=Kuester%2CF&amp;author=Nideffer%2CR&amp;author=Penny%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Schweikardt E, Gross MD (1998) Digital clay: deriving digital models from freehand sketches. In: Proceedings o" /><p class="c-article-references__text" id="ref-CR15">Schweikardt E, Gross MD (1998) Digital clay: deriving digital models from freehand sketches. In: Proceedings of ACADIA 1998, pp 202–211</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Skubic M, Bailey C, Chronis G (2003) A sketch interface for mobile robots. In: IEEE international conference o" /><p class="c-article-references__text" id="ref-CR16">Skubic M, Bailey C, Chronis G (2003) A sketch interface for mobile robots. In: IEEE international conference on systems, man and cybernetics</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Smotherman M (1999) A brief history of microprogramming. http://www.cs.clemson.edu/~mark/uprog.html&#xA;          " /><p class="c-article-references__text" id="ref-CR17">Smotherman M (1999) A brief history of microprogramming. <a href="http://www.cs.clemson.edu/~mark/uprog.html">http://www.cs.clemson.edu/~mark/uprog.html</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sugimoto M, Kojima M, Nakamura A, Kagotani G, Nii H, Inami M (2005) Augmented coliseum: display-based computin" /><p class="c-article-references__text" id="ref-CR13">Sugimoto M, Kojima M, Nakamura A, Kagotani G, Nii H, Inami M (2005) Augmented coliseum: display-based computing for augmented reality inspiration computing robot. In: Proceedings of horizontal interactive human-computer systems, pp 3–8</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Taylor R, Robinett W, Chi V, Brooks F, Wright W, Williams R, Snyder E (1993) A virtual-reality interface for t" /><p class="c-article-references__text" id="ref-CR18">Taylor R, Robinett W, Chi V, Brooks F, Wright W, Williams R, Snyder E (1993) A virtual-reality interface for the nanomanipulator: a scanning tunneling microscope. In: 20th Annual conference on Computer graphics and interactive techniques</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-008-0086-x-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Arts Computation Engineering, Calit2 Center of Gravity, Laboratory for Game Culture and Technology, The University of California, Irvine, CA, 92697, USA</p><p class="c-article-author-affiliation__authors-list">Kevin Ponto, Falko Kuester, Robert Nideffer &amp; Simon Penny</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Kevin-Ponto"><span class="c-article-authors-search__title u-h3 js-search-name">Kevin Ponto</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Kevin+Ponto&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Kevin+Ponto" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Kevin+Ponto%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Falko-Kuester"><span class="c-article-authors-search__title u-h3 js-search-name">Falko Kuester</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Falko+Kuester&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Falko+Kuester" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Falko+Kuester%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Robert-Nideffer"><span class="c-article-authors-search__title u-h3 js-search-name">Robert Nideffer</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Robert+Nideffer&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Robert+Nideffer" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Robert+Nideffer%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Simon-Penny"><span class="c-article-authors-search__title u-h3 js-search-name">Simon Penny</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Simon+Penny&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Simon+Penny" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Simon+Penny%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-008-0086-x/email/correspondent/c1/new">Kevin Ponto</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Tangled%20reality&amp;author=Kevin%20Ponto%20et%20al&amp;contentID=10.1007%2Fs10055-008-0086-x&amp;publication=1359-4338&amp;publicationDate=2008-02-29&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Ponto, K., Kuester, F., Nideffer, R. <i>et al.</i> Tangled reality.
                    <i>Virtual Reality</i> <b>12, </b>37–45 (2008). https://doi.org/10.1007/s10055-008-0086-x</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-008-0086-x.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-06-24">24 June 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2007-07-23">23 July 2007</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-02-29">29 February 2008</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-03">March 2008</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-008-0086-x" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-008-0086-x</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Mixed reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Augmented reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Teleoperations</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Edutainment</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-008-0086-x.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=86;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

