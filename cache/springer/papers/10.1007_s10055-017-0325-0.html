<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Kinesthetic interactions in museums: conveying cultural heritage by ma"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Kinesthetic interactions allow users to interact with 3D applications through their body movements and hand gestures. When kinesthetic applications are introduced in museums and heritage..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/22/2.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Kinesthetic interactions in museums: conveying cultural heritage by making use of ancient tools and (re-) constructing artworks"/>

    <meta name="dc.source" content="Virtual Reality 2017 22:2"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2017-09-22"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2017 Springer-Verlag London Ltd."/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Kinesthetic interactions allow users to interact with 3D applications through their body movements and hand gestures. When kinesthetic applications are introduced in museums and heritage institutions, they add embodiment to visitor experience. An appropriate fit for kinesthetic technology in museums rests on visitors engaging in purposeful body movements and hand gestures that convey meanings about both intangible and tangible heritage. This paper presents the design, development and evaluation of a kinesthetic application of sculpturing Cycladic figurines, which places the user at the role of an ancient craftsman who creates a figurine with bare-hand movements (translated by Leap Motion to respective sculpting actions) in a simplified virtual environment. The Cycladic sculpture application has been evaluated in laboratory and field testing (as part of a wider educational activity in the museum) with positive results on usability, fun and learning. We identify several benefits as well as challenges of designing kinesthetic interactions in museums and we report on design issues that need to be taken into account in similar applications."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2017-09-22"/>

    <meta name="prism.volume" content="22"/>

    <meta name="prism.number" content="2"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="103"/>

    <meta name="prism.endingPage" content="118"/>

    <meta name="prism.copyright" content="2017 Springer-Verlag London Ltd."/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-017-0325-0"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-017-0325-0"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-017-0325-0.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-017-0325-0"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Kinesthetic interactions in museums: conveying cultural heritage by making use of ancient tools and (re-) constructing artworks"/>

    <meta name="citation_volume" content="22"/>

    <meta name="citation_issue" content="2"/>

    <meta name="citation_publication_date" content="2018/06"/>

    <meta name="citation_online_date" content="2017/09/22"/>

    <meta name="citation_firstpage" content="103"/>

    <meta name="citation_lastpage" content="118"/>

    <meta name="citation_article_type" content="S.I. : VR and AR Serious Games"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-017-0325-0"/>

    <meta name="DOI" content="10.1007/s10055-017-0325-0"/>

    <meta name="citation_doi" content="10.1007/s10055-017-0325-0"/>

    <meta name="description" content="Kinesthetic interactions allow users to interact with 3D applications through their body movements and hand gestures. When kinesthetic applications are int"/>

    <meta name="dc.creator" content="Panayiotis Koutsabasis"/>

    <meta name="dc.creator" content="Spyros Vosinakis"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=Developing serious games for cultural heritage: a state-of-the-art review; citation_author=EF Anderson, L McLoughlin, F Liarokapis, C Peters, P Petridis, S Freitas; citation_volume=14; citation_issue=4; citation_publication_date=2010; citation_pages=255-275; citation_doi=10.1007/s10055-010-0177-3; citation_id=CR1"/>

    <meta name="citation_reference" content="Barton AJ, Goeser C (2013) Transforming the art museum experience: gallery one. museums and the web. 
                    http://mw2013.museumsandtheweb.com/paper/transforming-the-art-museum-experience-gallery-one-2/
                    
                  
                "/>

    <meta name="citation_reference" content="citation_journal_title=J Comput Cult Herit (JOCCH); citation_title=Design of an interactive experience with medieval illuminations: a journey into the beauty and meaning of medieval Portuguese manuscripts; citation_author=N Correia, T Rom&#227;o, A Ricardo; citation_volume=7; citation_issue=2; citation_publication_date=2014; citation_pages=13; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_title=Intrinsic motivation in museums: Why does one want to learn?; citation_inbook_title=Public institutions for personal learning: Establishing a research agenda; citation_publication_date=1995; citation_pages=67-77; citation_id=CR4; citation_author=M Csikszentmihalyi; citation_author=K Hermanson; citation_publisher=American Association of Museums"/>

    <meta name="citation_reference" content="De Paolis LT, Aloisio G, Celentano MG, Oliva L, Vecchio P (2011) Experiencing a town of the Middle Ages: an application for the edutainment in cultural heritage. In: 2011 IEEE 3rd international conference on communication software and networks (ICCSN). pp 169&#8211;174. IEEE"/>

    <meta name="citation_reference" content="England D (2011) Whole body interaction: An introduction. In: Whole Body Interaction Springer, London, pp. 1-5"/>

    <meta name="citation_reference" content="Fanini B, d&#8217;Annibale E, Demetrescu E, Ferdani D, Pagano A (2015) Engaging and shared gesture-based interaction for museums the case study of K2R international expo in Rome. In: 2015 Digital heritage, vol 1, pp 263&#8211;270. IEEE"/>

    <meta name="citation_reference" content="Fogtmann MH, Fritsch J, Kortbek KJ (2008) Kinesthetic interaction: revealing the bodily potential in interaction design. In: Proceedings of the 20th Australasian conference on computer-human interaction: designing for habitus and habitat, pp 89&#8211;96. ACM"/>

    <meta name="citation_reference" content="citation_journal_title=Sensors; citation_title=An analysis of the precision and reliability of the leap motion sensor and its suitability for static and dynamic tracking; citation_author=J Guna, G Jakus, M Poga&#269;nik, S Toma&#382;i&#269;, J Sodnik; citation_volume=14; citation_issue=2; citation_publication_date=2014; citation_pages=3702-3720; citation_doi=10.3390/s140203702; citation_id=CR9"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=Collaborative virtual sculpting with haptic feedback; citation_author=C Gunn; citation_volume=10; citation_issue=2; citation_publication_date=2006; citation_pages=73-83; citation_doi=10.1007/s10055-006-0044-4; citation_id=CR10"/>

    <meta name="citation_reference" content="citation_title=Learning in the museum; citation_publication_date=2002; citation_id=CR11; citation_author=GE Hein; citation_publisher=Routledge"/>

    <meta name="citation_reference" content="Hern&#225;ndez-Ib&#225;&#241;ez LA, Barneche-Naya V, Mihura-L&#243;pez R (2016) Natural interaction and movement paradigms. A comparison of usability for a kinect enabled museum installation. In: International conference on learning and collaboration technologies, Springer, Berlin, pp 145&#8211;155"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=Physically touching and tasting virtual objects enhances the realism of virtual experiences; citation_author=HG Hoffman, A Hollander, K Schroder, S Rousseau, T Furness; citation_volume=3; citation_issue=4; citation_publication_date=1998; citation_pages=226-234; citation_doi=10.1007/BF01408703; citation_id=CR13"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Inf Educ Technol; citation_title=The potential of kinect in education; citation_author=HMJ Hsu; citation_volume=1; citation_issue=5; citation_publication_date=2011; citation_pages=365; citation_id=CR14"/>

    <meta name="citation_reference" content="Hunicke R, LeBlanc M, Zubek R (2004) MDA: a formal approach to game design and game research. In: Proceedings of the AAAI workshop on challenges in game AI"/>

    <meta name="citation_reference" content="Koutsabasis P, Domouzis C (2016) Mid-air browsing and selection in image collections. In: International working conference on advanced visual interfaces (AVI) 2016. ACM"/>

    <meta name="citation_reference" content="Koutsabasis P, Vosinakis S (2016) Adult and children user experience with leap motion in digital heritage: the Cycladic sculpture application. In: Euro-mediterranean conference. Springer, Berlin, pp 350&#8211;361"/>

    <meta name="citation_reference" content="Leap Motion App Store. 
                    https://apps.leapmotion.com/
                    
                  
                "/>

    <meta name="citation_reference" content="citation_title=Evaluating children&#8217;s interactive products: principles and practices for interaction designers; citation_publication_date=2008; citation_id=CR19; citation_author=P Markopoulos; citation_author=JC Read; citation_author=S MacFarlane; citation_author=J Hoysniemi; citation_publisher=Morgan Kaufmann"/>

    <meta name="citation_reference" content="citation_title=Selection-based mid-air text entry on large displays; citation_inbook_title=IFIP conference on human&#8211;computer interaction; citation_publication_date=2013; citation_pages=401-418; citation_id=CR20; citation_author=A Markussen; citation_author=MR Jakobsen; citation_author=K Hornb&#230;k; citation_publisher=Springer"/>

    <meta name="citation_reference" content="McDonnell K, Qin H, Wlodarczyk R (2001) Virtual clay: a real-time sculpting system with haptic toolkits. In: Proceedings of the 2001 symposium on Interactive 3D graphics. ACM"/>

    <meta name="citation_reference" content="citation_journal_title=J Cult Herit; citation_title=Learning cultural heritage by serious games; citation_author=M Mortara, CE Catalano, F Bellotti, G Fiucci, M Houry-Panchetti, P Petridis; citation_volume=15; citation_issue=3; citation_publication_date=2014; citation_pages=318-325; citation_doi=10.1016/j.culher.2013.04.004; citation_id=CR22"/>

    <meta name="citation_reference" content="Nancel M, Wagner J, Pietriga E, Chapuis O, Mackay W (2011) Mid-air pan-and-zoom on wall-sized displays. In: Proceedings of the SIGCHI conference on human factors in computing systems, pp 177&#8211;186. ACM"/>

    <meta name="citation_reference" content="citation_title=The Early Cycladic sculptor: materials and methods; citation_inbook_title=Early Cycladic Art in North American Collections; citation_publication_date=1987; citation_pages=90-102; citation_id=CR24; citation_author=E Oustinoff; citation_publisher=Virginia Museum of Fine Arts"/>

    <meta name="citation_reference" content="Papadatos Y, Venieris E (2016) An experimental approach to the manufacture of Cycladic-type figurines with folded arms: preliminary observations. In: Early Cycladic Sculpture in Context. Oxbow Books, Oxford, pp 483&#8211;490"/>

    <meta name="citation_reference" content="Papadimitriou N (2015) How were they created? Materials and techniques of crafting ancient artefacts. A publication of the Museum of Cycladic Art. ISBN: 978-618-5060-12-1 (In Greek)"/>

    <meta name="citation_reference" content="Pescarin S, Pietroni E, Rescic L, Wallerg&#229;rd M, Omar K, Rufa C (2013) NICH: a preliminary theoretical study on Natural Interaction applied to Cultural Heritage contexts. In: Digital heritage international congress 2013, vol 1, pp 355&#8211;362. IEEE"/>

    <meta name="citation_reference" content="citation_journal_title=J Comput Cult Herit; citation_title=Interacting with virtual reconstructions in museums: the Etruscanning Project; citation_author=E Pietroni, A Adami; citation_volume=7; citation_issue=2; citation_publication_date=2014; citation_pages=9; citation_doi=10.1145/2611375; citation_id=CR28"/>

    <meta name="citation_reference" content="Prazina I, Balic K, Prses K, Rizvic S, Okanovic V (2016) Interaction with virtual objects in a natural way. In: 39th international convention on information and communication technology, electronics and microelectronics (MIPRO) 2016, Opatija, Croatia, May 30&#8211;June 3, 2016. IEEE, pp 358&#8211;361"/>

    <meta name="citation_reference" content="Ramani K, Lee Jr K, Jasti R (2014) zPots: a virtual pottery experience with spatial interactions using the leap motion device. In: CHI&#8217;14 extended abstracts on human factors in computing systems. ACM"/>

    <meta name="citation_reference" content="citation_journal_title=Cogn Technol Work; citation_title=Validating the Fun Toolkit: an instrument for measuring children&#8217;s opinions of technology; citation_author=JC Read; citation_volume=10; citation_issue=2; citation_publication_date=2008; citation_pages=119-128; citation_doi=10.1007/s10111-007-0069-9; citation_id=CR30"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Comput Surv (CSUR); citation_title=The perception of egocentric distances in virtual environments-a review; citation_author=RS Renner, BM Velichkovsky, JR Helmert; citation_volume=46; citation_issue=2; citation_publication_date=2013; citation_pages=23; citation_doi=10.1145/2543581.2543590; citation_id=CR31"/>

    <meta name="citation_reference" content="citation_title=Multiuser collaborative exploration of immersive photorealistic virtual environments in public spaces; citation_inbook_title=International conference on virtual and mixed reality; citation_publication_date=2009; citation_pages=235-243; citation_id=CR32; citation_author=S Robertson; citation_author=B Jones; citation_author=T O&#8217;Quinn; citation_author=P Presti; citation_author=J Wilson; citation_author=M Gandy; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=ACM SIGGRAPH Comput Graph; citation_title=Free-form deformation of solid geometric models; citation_author=T Sederberg, S Parry; citation_volume=20; citation_issue=4; citation_publication_date=1986; citation_pages=151-160; citation_doi=10.1145/15886.15903; citation_id=CR33"/>

    <meta name="citation_reference" content="Sheng J, Balakrishnan R, Singh K (2006) An interface for virtual 3D sculpting via physical proxy. GRAPHITE 6"/>

    <meta name="citation_reference" content="Van Eck W, Kolstee Y (2012) The augmented painting: playful interaction with multi-spectral images. In: 2012 IEEE international symposium on mixed and augmented reality-arts, media, and humanities (ISMAR-AMH), pp 65&#8211;69. IEEE"/>

    <meta name="citation_reference" content="Von Hardenberg C, B&#233;rard F (2001) Bare-hand human&#8211;computer interaction. In: Proceedings of the 2001 workshop on perceptive user interfaces. pp 1&#8211;8. ACM"/>

    <meta name="citation_reference" content="Vosinakis S, Xenakis I (2011) A virtual world installation in an art exhibition: providing a shared interaction space for local and remote visitors. In: Rethinking technology in Museums 2011"/>

    <meta name="citation_reference" content="Vosinakis S, Koutsabasis P, Makris D, Sagia E (2016) A kinesthetic approach to digital heritage using leap motion: the Cycladic sculpture application. In: 8th International conference on games and virtual worlds for serious applications (VS-GAMES), Barcelona. IEEE"/>

    <meta name="citation_reference" content="citation_title=Intuitional 3D museum navigation system using Kinect; citation_inbook_title=Information technology convergence; citation_publication_date=2013; citation_pages=587-596; citation_id=CR39; citation_author=CS Wang; citation_author=DJ Chiang; citation_author=YC Wei; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=J Vis Comput Anim; citation_title=Virtual 3d sculpting; citation_author=J Wong, R Lau, L Ma; citation_volume=11; citation_issue=3; citation_publication_date=2000; citation_pages=155-166; citation_doi=10.1002/1099-1778(200007)11:3&lt;155::AID-VIS225&gt;3.0.CO;2-7; citation_id=CR40"/>

    <meta name="citation_reference" content="citation_journal_title=Vis Comput; citation_title=A functional model for constructive solid geometry; citation_author=G Wyvill, TL Kunii; citation_volume=1; citation_issue=1; citation_publication_date=1985; citation_pages=3-14; citation_doi=10.1007/BF01901265; citation_id=CR41"/>

    <meta name="citation_author" content="Panayiotis Koutsabasis"/>

    <meta name="citation_author_email" content="kgp@aegean.gr"/>

    <meta name="citation_author_institution" content="Department of Product and Systems Design Engineering, Interactive Systems Design Lab, University of the Aegean, Ermoupolis, Greece"/>

    <meta name="citation_author" content="Spyros Vosinakis"/>

    <meta name="citation_author_email" content="spyrosv@aegean.gr"/>

    <meta name="citation_author_institution" content="Department of Product and Systems Design Engineering, Interactive Systems Design Lab, University of the Aegean, Ermoupolis, Greece"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-017-0325-0&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2018/06/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-017-0325-0"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Kinesthetic interactions in museums: conveying cultural heritage by making use of ancient tools and (re-) constructing artworks"/>
        <meta property="og:description" content="Kinesthetic interactions allow users to interact with 3D applications through their body movements and hand gestures. When kinesthetic applications are introduced in museums and heritage institutions, they add embodiment to visitor experience. An appropriate fit for kinesthetic technology in museums rests on visitors engaging in purposeful body movements and hand gestures that convey meanings about both intangible and tangible heritage. This paper presents the design, development and evaluation of a kinesthetic application of sculpturing Cycladic figurines, which places the user at the role of an ancient craftsman who creates a figurine with bare-hand movements (translated by Leap Motion to respective sculpting actions) in a simplified virtual environment. The Cycladic sculpture application has been evaluated in laboratory and field testing (as part of a wider educational activity in the museum) with positive results on usability, fun and learning. We identify several benefits as well as challenges of designing kinesthetic interactions in museums and we report on design issues that need to be taken into account in similar applications."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Kinesthetic interactions in museums: conveying cultural heritage by making use of ancient tools and (re-) constructing artworks | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-017-0325-0","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Cultural heritage, Digital heritage, Kinesthetic interaction, Cycladic figurine, User experience, Usability testing, Field study, Leap Motion","kwrd":["Cultural_heritage","Digital_heritage","Kinesthetic_interaction","Cycladic_figurine","User_experience","Usability_testing","Field_study","Leap_Motion"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-017-0325-0","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-017-0325-0","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=325;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-017-0325-0">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Kinesthetic interactions in museums: conveying cultural heritage by making use of ancient tools and (re-) constructing artworks
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-017-0325-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-017-0325-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">S.I. : VR and AR Serious Games</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2017-09-22" itemprop="datePublished">22 September 2017</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Kinesthetic interactions in museums: conveying cultural heritage by making use of ancient tools and (re-) constructing artworks</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Panayiotis-Koutsabasis" data-author-popup="auth-Panayiotis-Koutsabasis">Panayiotis Koutsabasis</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of the Aegean" /><meta itemprop="address" content="0000 0004 0622 2931, grid.7144.6, Department of Product and Systems Design Engineering, Interactive Systems Design Lab, University of the Aegean, Ermoupolis, Greece" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Spyros-Vosinakis" data-author-popup="auth-Spyros-Vosinakis" data-corresp-id="c1">Spyros Vosinakis<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><span class="u-js-hide"> 
            <a class="js-orcid" itemprop="url" href="http://orcid.org/0000-0003-1735-4297"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-1735-4297</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of the Aegean" /><meta itemprop="address" content="0000 0004 0622 2931, grid.7144.6, Department of Product and Systems Design Engineering, Interactive Systems Design Lab, University of the Aegean, Ermoupolis, Greece" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 22</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">103</span>–<span itemprop="pageEnd">118</span>(<span data-test="article-publication-year">2018</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">865 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">8 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-017-0325-0/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Kinesthetic interactions allow users to interact with 3D applications through their body movements and hand gestures. When kinesthetic applications are introduced in museums and heritage institutions, they add embodiment to visitor experience. An appropriate fit for kinesthetic technology in museums rests on visitors engaging in purposeful body movements and hand gestures that convey meanings about both intangible and tangible heritage. This paper presents the design, development and evaluation of a kinesthetic application of sculpturing Cycladic figurines, which places the user at the role of an ancient craftsman who creates a figurine with bare-hand movements (translated by Leap Motion to respective sculpting actions) in a simplified virtual environment. The Cycladic sculpture application has been evaluated in laboratory and field testing (as part of a wider educational activity in the museum) with positive results on usability, fun and learning. We identify several benefits as well as challenges of designing kinesthetic interactions in museums and we report on design issues that need to be taken into account in similar applications.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Presentation and dissemination of cultural heritage have gained significant benefits from the advances in digital technology during the last decade. A wide range of informative and entertaining applications related to culture have been made available to the public through Web pages, mobile devices and interactive installations within physical exhibition spaces. These applications follow established trends in edutainment software, like virtual worlds, serious games, interactive storytelling, location-based games, augmented reality, etc. (Anderson et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Anderson EF, McLoughlin L, Liarokapis F, Peters C, Petridis P, de Freitas S (2010) Developing serious games for cultural heritage: a state-of-the-art review. Virtual Real 14(4):255–275" href="/article/10.1007/s10055-017-0325-0#ref-CR1" id="ref-link-section-d51797e336">2010</a>; Mortara et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Mortara M, Catalano CE, Bellotti F, Fiucci G, Houry-Panchetti M, Petridis P (2014) Learning cultural heritage by serious games. J Cult Herit 15(3):318–325" href="/article/10.1007/s10055-017-0325-0#ref-CR22" id="ref-link-section-d51797e339">2014</a>), and their content conveys tangible and intangible aspects of cultural heritage.</p><p>Many cultural heritage applications place emphasis in presenting content, rather than having users interact with it and gain from this experience. Usually, the focus is on offering high-quality renderings of artifacts, constructions or places and letting users freely navigate and observe them. In some cases, the digital environments are enhanced with animated content (e.g., virtual humans), but still, user intervention is limited. This happens mainly due to the fact that tangible items, such as objects or structures, are usually placed at the center of attention in cultural heritage, and thus, users are expected to learn through observing and exploring the content, rather than performing some non-typical interactions with it. Furthermore, the interaction affordances of Web and mobile applications are limited by the capabilities of the execution platforms; the keyboard-and-mouse and the multi-touch interaction paradigms are the common cases. On the other hand, museum installations do not have such limitations and offer plenty of room for experimenting with alternative interaction techniques.</p><p>The possibility of kinesthetic interactions may expand the potential of digital-heritage applications into new paradigms. The kinesthetic approach is considered as an important pedagogy for museum education; according to Hein (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Hein GE (2002) Learning in the museum. Routledge, London" href="/article/10.1007/s10055-017-0325-0#ref-CR11" id="ref-link-section-d51797e348">2002</a>) ‘field-independent learners, global learners, or learners who favor a bodily kinesthetic mode use their preferred style independent of the subject that is to be learned, although certain kinds of learning activities lend themselves more readily to one learning style or another.’ Kinesthetic interaction seems to afford experiencing intangible aspects of cultural heritage, e.g., those related to habits, rituals, activities, crafts, etc. Additionally, gesture-based interactions are more suitable input methods for 3D environments compared to typical 2D interaction modalities, because they involve natural motion in three dimensions. Finally, natural and intuitive interactions are expected to make the experience more fun and, as such, to retain the user interest and engagement for a longer period of time (Hsu <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Hsu HMJ (2011) The potential of kinect in education. Int J Inf Educ Technol 1(5):365" href="/article/10.1007/s10055-017-0325-0#ref-CR14" id="ref-link-section-d51797e351">2011</a>).</p><p>Recent advances in sensor technology have led to novel low-cost devices that can track human body motion with an acceptable level of accuracy and, thus, support kinesthetic interactions. The first popular device of this type has been the Nintendo Wiimote, a game controller in the form of a remote control, able to track natural hand motion using an accelerometer. Nowadays, sensors have become more accurate and natural; they can track human motion using computer vision technology, with no need for wearable devices or handheld props. Two notable examples are Microsoft Kinect and Leap Motion. The first can track the position and movement of the whole body and recognize user gestures, while the latter is limited to the placement and motion of the hands. One must note, however, that Leap Motion’s hand tracking capabilities are significantly more accurate and fast compared to Microsoft Kinect, as it provides detailed hand and finger tracking at high-frame rates (Guna et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Guna J, Jakus G, Pogačnik M, Tomažič S, Sodnik J (2014) An analysis of the precision and reliability of the leap motion sensor and its suitability for static and dynamic tracking. Sensors 14(2):3702–3720" href="/article/10.1007/s10055-017-0325-0#ref-CR9" id="ref-link-section-d51797e357">2014</a>). As such, it is more suited for kinesthetic activities that emphasize on delicate movements of the hand.</p><p>The usage of low-cost kinesthetic technology in cultural heritage applications is still limited, but there seems to be a growing interest in this direction of research and development (Pescarin et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Pescarin S, Pietroni E, Rescic L, Wallergård M, Omar K, Rufa C (2013) NICH: a preliminary theoretical study on Natural Interaction applied to Cultural Heritage contexts. In: Digital heritage international congress 2013, vol 1, pp 355–362. IEEE" href="/article/10.1007/s10055-017-0325-0#ref-CR27" id="ref-link-section-d51797e364">2013</a>). The majority of applications use kinesthetic interactions for navigating spaces, examining content and information browsing. Furthermore, the impact of these applications on the visitor user experience is largely unknown: Most applications do not present a clear added value to the experience and there are a few rigorous studies of their usability.</p><p>The aim of our research is to explore and assess the potential benefits and pitfalls of the kinesthetic approach in cultural heritage applications in museums and public exhibition spaces. We explore a novel paradigm of kinesthetic interactions in cultural heritage, where visitors use digital artifacts and imitate actions and activities of cultural value, for example, in crafts and rituals. In our research, we adopt a user-centered design and evaluation approach that includes user studies about usability, experience and learning to gain more insights into the effects of this technology on users.</p><p>This paper presents the design, development and evaluation of a kinesthetic digital heritage application, in which users are engaged in a simplified virtual sculpting process of creating Cycladic figurines by applying respective gestures with their bare hands. The learning objectives of the application are to recognize the main stages involved in the process of constructing a figurine and to learn about ancient tools and materials used in each stage through an experiential and embodied understanding. We have evaluated the Cycladic sculpture application in two subsequent laboratory studies (10 adults and 10 children, respectively) and a field study (74 pupils, teenagers). The results are very positive regarding usability, fun and learning. Out of this experience, we outline several interaction design issues that affect the potential of kinesthetic applications as small-sized, self-contained museum installations that can engage visitors in entertaining embodied interactions and convey meaning of cultural value.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Background and related work</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Kinesthetic interaction</h3><p>Kinesthetic interaction offers an understanding of interaction with interactive environments with a focus on the awareness and perception of the body and its movements as mediated by interactive technologies, and it has been defined (Fogtmann et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Fogtmann MH, Fritsch J, Kortbek KJ (2008) Kinesthetic interaction: revealing the bodily potential in interaction design. In: Proceedings of the 20th Australasian conference on computer-human interaction: designing for habitus and habitat, pp 89–96. ACM" href="/article/10.1007/s10055-017-0325-0#ref-CR8" id="ref-link-section-d51797e385">2008</a>) as ‘when the body in motion experiences the world through interactive technologies.’ Kinesthetic interaction rests on the fact that our body is the foundation for the way we experience and interact with our surroundings. Simply put, kinesthetic interaction is about exercising user movements (of many kinds, including body movements and postures, feet movements, free-hand movements and gestures, palm movements and finger gestures) to interact with a computer, a distant display or a technologically enhanced room or environment.</p><p>Over the last few years, kinesthetic interaction has materialized in more specific areas like whole body, mid-air and bare-hand interaction. Whole-body interaction (England <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="England D (2011) Whole body interaction: An introduction. In: Whole Body Interaction Springer, London, pp. 1-5" href="/article/10.1007/s10055-017-0325-0#ref-CR6" id="ref-link-section-d51797e391">2011</a>) refers to the use of body movements and postures to interact with a distant display, like the TV set, mainly in home gaming scenarios like dancing, gymnastics, football, etc. Mid-air interaction refers to the use of hand gestures in the mid-air to interact with distant displays by applying gestures, typically in scenarios of content manipulation and exploration, for example, with information spaces on wall-sized displays (Nancel et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Nancel M, Wagner J, Pietriga E, Chapuis O, Mackay W (2011) Mid-air pan-and-zoom on wall-sized displays. In: Proceedings of the SIGCHI conference on human factors in computing systems, pp 177–186. ACM" href="/article/10.1007/s10055-017-0325-0#ref-CR23" id="ref-link-section-d51797e394">2011</a>), for text entry (Markussen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Markussen A, Jakobsen MR, Hornbæk K (2013) Selection-based mid-air text entry on large displays. IFIP conference on human–computer interaction. Springer, Berlin, pp 401–418" href="/article/10.1007/s10055-017-0325-0#ref-CR20" id="ref-link-section-d51797e397">2013</a>), for navigation and selection on image galleries (Koutsabasis and Domouzis <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Koutsabasis P, Domouzis C (2016) Mid-air browsing and selection in image collections. In: International working conference on advanced visual interfaces (AVI) 2016. ACM" href="/article/10.1007/s10055-017-0325-0#ref-CR16" id="ref-link-section-d51797e400">2016</a>), etc. Finally, bare-hands interaction (Von Hardenberg and Bérard <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Von Hardenberg C, Bérard F (2001) Bare-hand human–computer interaction. In: Proceedings of the 2001 workshop on perceptive user interfaces. pp 1–8. ACM" href="/article/10.1007/s10055-017-0325-0#ref-CR36" id="ref-link-section-d51797e403">2001</a>) refers to the use of the hand palms and fingers mainly for desktop or kiosk-oriented interactions.</p><p>Kinesthetic interaction is rapidly evolving into a robust and affordable human–computer interaction style due to the emergence of accessory-free sensors that provide ‘skeleton’ models of the human silhouette and the human hand in real time. Nowadays, the most important sensors that support kinesthetic interactions are the Microsoft Kinect, which affords whole body and mid-air interactions, and the Leap Motion which affords bare-hand interactions. The Microsoft Kinect sensor, comprises of a depth and a color infrared camera (along with other sensors like a microphone array), tracks up to six people in real-time video (up to 30 fps) in a cone-like space of 54° vertical width and up to 8 m away, providing a skeleton stream of 25 points per silhouette (version 2.0). The Leap Motion sensor, comprises of two depth infrared cameras, tracks the human hands in real-time video (up to 200 fps) in a parachute-like space of approximately 0.6 m maximum height and width providing a skeleton stream of 26 points per hand palm.</p><p>The creation of digital models with natural gestures has long been studied in VR, before accessory-free kinesthetic control. Many approaches have been presented that allow users to construct or deform a 3D geometry using hand interactions. The user actions are interpreted as operations on the 3D model, either directly based on the collisions of the virtual fingers with the model or indirectly using digital tools. These operations change the shape of the 3D model using approaches such as free-form deformation (Sederberg and Parry <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1986" title="Sederberg T, Parry S (1986) Free-form deformation of solid geometric models. ACM SIGGRAPH Comput Graph 20(4):151–160" href="/article/10.1007/s10055-017-0325-0#ref-CR33" id="ref-link-section-d51797e412">1986</a>) or constructive solid geometry (Wyvill and Kunii <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1985" title="Wyvill G, Kunii TL (1985) A functional model for constructive solid geometry. Vis Comput 1(1):3–14" href="/article/10.1007/s10055-017-0325-0#ref-CR41" id="ref-link-section-d51797e415">1985</a>). Various types of equipment have been used, including high-end VR gloves (Wong et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Wong J, Lau R, Ma L (2000) Virtual 3d sculpting. J Vis Comput Anim 11(3):155–166" href="/article/10.1007/s10055-017-0325-0#ref-CR40" id="ref-link-section-d51797e418">2000</a>), force-feedback haptic devices in single-user (McDonnell et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="McDonnell K, Qin H, Wlodarczyk R (2001) Virtual clay: a real-time sculpting system with haptic toolkits. In: Proceedings of the 2001 symposium on Interactive 3D graphics. ACM" href="/article/10.1007/s10055-017-0325-0#ref-CR21" id="ref-link-section-d51797e421">2001</a>) or collaborative setups (Gunn <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Gunn C (2006) Collaborative virtual sculpting with haptic feedback. Virtual Real 10(2):73–83" href="/article/10.1007/s10055-017-0325-0#ref-CR10" id="ref-link-section-d51797e424">2006</a>), a deformable physical prop combined with markers on the fingers (Sheng et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Sheng J, Balakrishnan R, Singh K (2006) An interface for virtual 3D sculpting via physical proxy. GRAPHITE 6" href="/article/10.1007/s10055-017-0325-0#ref-CR34" id="ref-link-section-d51797e428">2006</a>), etc. In a recent work, the Leap Motion controller has been used as an input device in an application for virtual pottery with brush and shaping tools (Ramani et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Ramani K, Lee Jr K, Jasti R (2014) zPots: a virtual pottery experience with spatial interactions using the leap motion device. In: CHI’14 extended abstracts on human factors in computing systems. ACM" href="/article/10.1007/s10055-017-0325-0#ref-CR29" id="ref-link-section-d51797e431">2014</a>). The main goal of this group of applications is to create interfaces that aid designers in the creation of 3D models. Their emphasis is on usability and performance and not necessarily to mimic the real process; the latter is mostly used as a metaphor. The focus of our work is different. It is about getting an embodied understanding of an ancient craft by performing the main actions of the creation stages in a gamified environment.</p><h3 class="c-article__sub-heading" id="Sec4">Kinesthetic interaction for cultural heritage installations</h3><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec5">Navigation and object manipulation</h4><p>Kinesthetic interactions, if appropriately designed, can provide intuitive input for user navigation in 3D environments. This is a principal focus of kinesthetic applications in the domain of digital heritage as it helps users explore reconstructed buildings or places. Furthermore, a considerable number of cultural heritage projects have exploited kinesthetic interactions for 3D object manipulation, which is also necessary for examining small-sized artifacts.</p><p>Early kinesthetic applications in cultural heritage were based on the Wii remote (Wiimote) sensor;<sup><a href="#Fn1"><span class="u-visually-hidden">Footnote </span>1</a></sup> with this handheld device, visitors could point on a screen and interact with the content like using a regular mouse and perform natural hand movements that were recognized by the system and translated to actions in the digital environment. In the work of Vosinakis and Xenakis (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Vosinakis S, Xenakis I (2011) A virtual world installation in an art exhibition: providing a shared interaction space for local and remote visitors. In: Rethinking technology in Museums 2011" href="/article/10.1007/s10055-017-0325-0#ref-CR37" id="ref-link-section-d51797e462">2011</a>) the Wiimote was used to interact with a multiuser virtual world in a public installation in an art exhibition. Users could look around or move inside the space using a combination of Wiimote buttons and natural hand motions. In the work of Robertson et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Robertson S, Jones B, O’Quinn T, Presti P, Wilson J, Gandy M (2009) Multiuser collaborative exploration of immersive photorealistic virtual environments in public spaces. International conference on virtual and mixed reality. Springer, Berlin, pp 235–243" href="/article/10.1007/s10055-017-0325-0#ref-CR32" id="ref-link-section-d51797e465">2009</a>), up to three users could simultaneously use the Wiimote controllers to interact with multimedia content presented on a large display screen. The device was used to select content on the screen with pointing gestures and to change the camera view using its direction buttons. In the work of De Paolis et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="De Paolis LT, Aloisio G, Celentano MG, Oliva L, Vecchio P (2011) Experiencing a town of the Middle Ages: an application for the edutainment in cultural heritage. In: 2011 IEEE 3rd international conference on communication software and networks (ICCSN). pp 169–174. IEEE" href="/article/10.1007/s10055-017-0325-0#ref-CR5" id="ref-link-section-d51797e468">2011</a>), the user navigation in a reconstructed town of the Middle Ages has been supported by a combination of Wiimote controller and Wii balance board. Standing on the balance board, users can lean their body toward the desired direction to steer their avatar in the 3D environment, while using the Wiimote to change the focus of attention.</p><p>The introduction of low-cost optical technology to recognize human body posture and motion eliminated the need for any additional handheld or wearable devices and created new prospects for natural kinesthetic interactions in the cultural heritage domain. In most cases, the Kinect sensor is used for navigating in 3D environments. Wang et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Wang CS, Chiang DJ, Wei YC (2013) Intuitional 3D museum navigation system using Kinect. Information technology convergence. Springer, Dordrecht, pp 587–596" href="/article/10.1007/s10055-017-0325-0#ref-CR39" id="ref-link-section-d51797e474">2013</a>) propose an intuitive approach for navigating in virtual museums using Kinect, which combines hand gestures, body movement and voice commands. Hernández-Ibáñez et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Hernández-Ibáñez LA, Barneche-Naya V, Mihura-López R (2016) Natural interaction and movement paradigms. A comparison of usability for a kinect enabled museum installation. In: International conference on learning and collaboration technologies, Springer, Berlin, pp 145–155" href="/article/10.1007/s10055-017-0325-0#ref-CR12" id="ref-link-section-d51797e477">2016</a>) compare two common interaction techniques for navigating inside reconstructed 3D spaces using Kinect: a ‘metaphorical’ approach based on hand gestures and a ‘natural’ one based on body movement and rotation. Both techniques yielded positive results with a slight shortfall of the first approach regarding easiness of reading information in the environment. Pescarin et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Pescarin S, Pietroni E, Rescic L, Wallergård M, Omar K, Rufa C (2013) NICH: a preliminary theoretical study on Natural Interaction applied to Cultural Heritage contexts. In: Digital heritage international congress 2013, vol 1, pp 355–362. IEEE" href="/article/10.1007/s10055-017-0325-0#ref-CR27" id="ref-link-section-d51797e480">2013</a>) present some early results from the development of a database of suitable gestures for cultural heritage applications with devices such as Kinect. They have identified several generic interactions needed in VR applications for cultural heritage and asked participants from various cultural background to propose suitable gestures for each of these interactions.</p><p>A notable project in this direction is Etruscanning (Pietroni and Adami <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Pietroni E, Adami A (2014) Interacting with virtual reconstructions in museums: the Etruscanning Project. J Comput Cult Herit 7(2):9" href="/article/10.1007/s10055-017-0325-0#ref-CR28" id="ref-link-section-d51797e486">2014</a>), which digitally re-created and restored the original context of the Etruscan graves and includes a large-scale virtual reality installation of whole-body interactions with projected 3D content using the Kinect sensor. Users can make simple moves into the physical space to control their representation (avatar) inside an Etruscan grave (e.g., walk a step forward in the physical space to make the avatar walk, walk a step back to make the avatar stop, etc.). In addition, they can apply mid-air gestures to interact with digital objects in the grave. Users need to learn a gesture vocabulary to control their avatar.</p><p>In a few cases, the Leap Motion controller has been used instead of Kinect, to support more delicate hand movements. A simple approach for examining exhibits of a Web-based virtual museum is presented in (Prazina et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Prazina I, Balic K, Prses K, Rizvic S, Okanovic V (2016) Interaction with virtual objects in a natural way. In: 39th international convention on information and communication technology, electronics and microelectronics (MIPRO) 2016, Opatija, Croatia, May 30–June 3, 2016. IEEE, pp 358–361" href="/article/10.1007/s10055-017-0325-0#ref-CR42" id="ref-link-section-d51797e493">2016</a>), where users can grasp and rotate objects using their virtual hand. Another similar application found in the Leap Motion app store is ‘TomBraining, the Gallery.’<sup><a href="#Fn2"><span class="u-visually-hidden">Footnote </span>2</a></sup> It offers a virtual tour to a collection of 250 paintings, and visitors can use the Leap Motion controller to travel in the virtual world using respective gestures. This is the only application in the Leap Motion app store (out of 230) related to cultural heritage.</p><p>Finally, the work of (Fanini et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Fanini B, d’Annibale E, Demetrescu E, Ferdani D, Pagano A (2015) Engaging and shared gesture-based interaction for museums the case study of K2R international expo in Rome. In: 2015 Digital heritage, vol 1, pp 263–270. IEEE" href="/article/10.1007/s10055-017-0325-0#ref-CR7" id="ref-link-section-d51797e512">2015</a>) is an interesting example of a comprehensive gesture-based installation within a museum in which Kinect and Leap Motion sensors are combined. The installation comprises of two systems: (a) a Kinect-based installation with a projected screen with which a user with an embodied digital representation (avatar) may navigate in restored sites of ancient Rome, and (b) a kiosk-based application in which another user may inspect digital artifacts with bare-hand interactions supported by the Leap Motion controller. The installation integrates various technologies and supports the transfer of artifacts from the first installation to the second. The evaluation results are encouraging overall, but it is reported that users were required to guess the appropriate manipulations regarding the kiosk-based application.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec6">Other embodied interactions</h4><p>There are only a few public installations related to cultural heritage which support kinesthetic interactions beyond navigating digital spaces or browsing collections. The Gallery One project at the Cleveland Museum of Art (USA) comprises of several impressive interactive installations (Barton and Goeser <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Barton AJ, Goeser C (2013) Transforming the art museum experience: gallery one. museums and the web. &#xA;                    http://mw2013.museumsandtheweb.com/paper/transforming-the-art-museum-experience-gallery-one-2/&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-017-0325-0#ref-CR2" id="ref-link-section-d51797e523">2013</a>). It includes a Kinect-based app that invites users to make poses to match those of statues of the museum. This is a simple app that motivates users to perform embodied interactions with digital content, to ‘discover’ an artwork. Another interesting example is a temporary installation at the Van Gogh Museum, which included a ‘digital spray can’ (Van Eck and Kolstee <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Van Eck W, Kolstee Y (2012) The augmented painting: playful interaction with multi-spectral images. In: 2012 IEEE international symposium on mixed and augmented reality-arts, media, and humanities (ISMAR-AMH), pp 65–69. IEEE" href="/article/10.1007/s10055-017-0325-0#ref-CR35" id="ref-link-section-d51797e526">2012</a>). Using a digitally modified spray can, users could virtually spray on a painting displayed on a large screen and reveal alternative captures of that painting, such as infrared, X-ray, ultraviolet, etc.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec7">Making use of ancient tools to reconstruct artworks</h4><p>An affordance of kinesthetic interaction that has not been explored so far in digital-heritage applications is that of engaging users in simplified scenarios of (re-) using, and (re-) constructing ancient artifacts to convey aspects of both tangible and intangible heritage. Kinesthetic interactions offer a natural and experiential means of user embodiment for tasks of ancient craftsmen and artists like sculpting, constructing and painting. Few applications aim at conveying cultural heritage through constructing artworks, but there are no examples that employ kinesthetic interaction. For example, Correia et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Correia N, Romão T, Ricardo A et al (2014) Design of an interactive experience with medieval illuminations: a journey into the beauty and meaning of medieval Portuguese manuscripts. J Comput Cult Herit (JOCCH) 7(2):13" href="/article/10.1007/s10055-017-0325-0#ref-CR3" id="ref-link-section-d51797e537">2014</a>) present an interactive installation that consists of three components: virtual scriptorium, interactive panel and augmented book, in which users make use of a pen-based interface to recreate Portuguese medieval illuminations onto a digital or physical book surface.</p><p>If visitors of a cultural site make use of a highly interactive kinesthetic application that places them into the role of an ancient craftsman or artist, they may constructively learn about ancient artifacts (that may be exhibited at the site) as well as seamlessly reflect on the effort, history and values related to human creation.</p><p>Additionally, given that kinesthetic interaction is still emerging, but it is possibly immature for professional applications like those of the domain of cultural heritage, it is important to assess their performance by designing and testing novel applications that take full advantage of their tracking capabilities.</p><p>Our work addresses these aims. We present the design of the Cycladic sculpture application that engages users making use of ancient stone tools to (re-) create Cycladic figurines, through kinesthetic interaction. Then we outline the iterative, user-centered evaluation of the application with respect to usability, fun and learning.</p></div></div></section><section aria-labelledby="Sec8"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Design of the Cycladic sculpture application</h2><div class="c-article-section__content" id="Sec8-content"><h3 class="c-article__sub-heading" id="Sec9">Sources and contextual research</h3><p>The process of Cycladic figurine creation has been experimentally investigated by Oustinoff (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Oustinoff E (1987) The Early Cycladic sculptor: materials and methods. In: Getz-Preziosi P (ed) Early Cycladic Art in North American Collections. Virginia Museum of Fine Arts, Richmond, pp 90–102" href="/article/10.1007/s10055-017-0325-0#ref-CR24" id="ref-link-section-d51797e563">1987</a>), who was the first to verify the materials and methods used by the craftspeople of the Early Cyclades for the manufacture of Cycladic-type figurines. According to Oustinoff, the main stages (and respective stony tools) of crafting Cycladic figurines are (a) carving, i.e., starting from a flat piece of marble, the craftsman uses a hard tool made of emery to remove the surrounding pieces of marble until the initial form of the figurine is revealed; (b) smoothing, i.e., the sculptor uses pumice rock to rub the surface of the statue, in order to give it a finer, more curved shape and to create the details; (c) engraving: a hard and sharp tool based on obsidian rock was used to engrave the marble to add more detail and to shape the outlines of specific parts of the body, such as the face, the arms and the legs. This crafting process is outlined at an illustrative book regarding the Cycladic sculpture process officially distributed by the Museum of Cycladic art (Papadimitriou <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Papadimitriou N (2015) How were they created? Materials and techniques of crafting ancient artefacts. A publication of the Museum of Cycladic Art. ISBN: 978-618-5060-12-1 (In Greek)" href="/article/10.1007/s10055-017-0325-0#ref-CR26" id="ref-link-section-d51797e566">2015</a>—respective information is also provided in the museum’s Website<sup><a href="#Fn3"><span class="u-visually-hidden">Footnote </span>3</a></sup>).</p><p>Since the work of Oustinoff, no other experimental investigations were made on crafting Cycladic figurines with the exception of the work of Papadatos and Venieris (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Papadatos Y, Venieris E (2016) An experimental approach to the manufacture of Cycladic-type figurines with folded arms: preliminary observations. In: Early Cycladic Sculpture in Context. Oxbow Books, Oxford, pp 483–490" href="/article/10.1007/s10055-017-0325-0#ref-CR25" id="ref-link-section-d51797e585">2016</a>) who have validated the identified stages of crafting (they call them: percussion, abrasion and refining). However, they further suggest that it is possible to use only obsidian tools (of various shapes) for all stages and that the choice of the rock should be a matter of convenience or availability among different Cycladic islands.</p><p>During the design of Cycladic sculpting application, we conducted interviews with these domain experts, in particular with Nikos Papadimitriou, who is the author of the illustrative book on Cycladic sculpture crafting and the curator of the respective exhibition at the Museum of Cycladic art, as well as with Yiannis Papadatos and Epaminontas Venieris who have conducted the experimental study on Cycladic figurine crafting.</p><h3 class="c-article__sub-heading" id="Sec10">Learning objectives, user tasks and challenges</h3><p>The Cycladic sculpting application places the user in the role of the ancient craftsman or sculptor and requires from her to construct a Cycladic figurine with the stony tools of ancient times. The main learning objectives of the Cycladic sculpting application are to allow the user to:</p><ol class="u-list-style-none">
                    <li>
                      <span class="u-custom-list-number">1.</span>
                      
                        <p>recognize the main stages involved in the process of creating a figurine,</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">2.</span>
                      
                        <p>learn the stone tools (material and shapes) used in each of these stages, and</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">3.</span>
                      
                        <p>acquire a more experiential and embodied understanding of the process in each stage.</p>
                      
                    </li>
                  </ol>
<p>When the program starts, the user finds herself immersed in the sculptor’s workspace and can see her ‘virtual hands’ i.e., the 3D representation of her hands in the scene. Then, the user must go through three main stages of constructing the figurine, by selecting the appropriate tool and imitating the task of using it. Throughout the process, the user sees the sculpture in a 3D form starting from a piece of marble and slowly taking the form of the figurine. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig1">1</a> shows indicative screenshots from various user interactions with the environment.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0325-0/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0325-0/MediaObjects/10055_2017_325_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0325-0/MediaObjects/10055_2017_325_Fig1_HTML.jpg" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Successive screenshots showing the effect of user actions during the main interactions with the environment: <b>a</b> selection, <b>b</b> carving, <b>c</b> smoothing, <b>d</b> engraving and <b>e</b> rotating the statue</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0325-0/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>Each of the identified stages has two phases: the selection of the tool and its application with corresponding gestures.</p><p>In the selection phase, the user has to identify the correct tool that matches the requested task. By lowering her hand, the camera is rotated down, and she can see the three tools arranged in front of the statue. When the user brings the virtual hand above a tool, it is being highlighted, and its name is displayed (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig1">1</a>a, middle). To select a tool, the user has to perform a grasping gesture with her hand. If a grasping gesture is detected and the user’s virtual hand collides with the tool, the tool is appropriately attached to her hand, as if she is actually holding it (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig1">1</a>a, right). If the user selects a wrong tool, the application provides feedback explaining why the tool is not appropriate for this task. In that case, the tool automatically leaves her hand and returns to its starting position.</p><p>In the task phase, the user has to use the tool appropriately on the statue mimicking sculpting movements with her hand in order to complete the stage. Initially, the application presents a message and an animated clip to explain how the user should perform the task in that stage. Then, the user is applying the tool on the sculpture and sees the impact of her actions on the form of the model. While performing, the user receives feedback about her progress through a progress bar and about her errors through warning messages and designated sounds. Finally, when the task is completed, the user is notified with a message and a music clip that the stage is over, and the application progresses to the next one.</p><p>During carving, the user must remove the exterior pieces of marble using the emery tool (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig1">1</a>b). The outline of the target shape is visualized so that the user knows which are the correct places to hit. Using the information provided from Leap Motion sensor, the system attempts to detect fast hand motion toward the statue. If the edge of the tool collides with the marble with a relatively fast speed, the marble shows a crack (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig1">1</a>b, middle), a sound of carving stone is played and a particle system generates the effect of small pieces of marble falling on the ground. Then, a second hit on the same piece results in the piece detaching from the statue and falling down (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig1">1</a>b, right). If the user hits three times inside the target shape, it is marked as an error and appropriate feedback is produced.</p><p>During smoothing, the user must rub the exterior part of the statue with the pumice stone, to transform the crude edges into more detailed surfaces (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig1">1</a>c). The outline of the target shape is visualized, so the user has to rub all the pieces outside this. To detect the rubbing process, the system checks whether the tool collides with the exterior parts, and, if so, it has to detect quite fast hand motion. A respective sound is played, and a particle system visually indicates the process. When a piece of marble is being rubbed, it initially becomes semi-transparent (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig1">1</a>c, middle), so that the user is informed that she is making progress, and then it fully disappears (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig1">1</a>c, right). An error is marked if rubbing motion is detected in parts of the statue that must not be removed for one second.</p><p>During engraving, the user has to engrave the marked areas of the statue using the pointy obsidian tool to add finer detail in the nose, the hands and feet (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig1">1</a>d). The process of engraving requires slower and more focused hand movements. Therefore, the user perspective changes, and the program zooms in the statue, so that the hand motions can be mapped to smaller movements. The process is split into three parts: the face, the body and the legs.</p><p>When the user completes a part, the game progresses to the next one, and the camera zooms to the respective area of the statue. Each part that needs to be engraved is a thick line segment, in some cases slightly curved. The user has to bring the pointy edge of the obsidian tool on the segment and move the tool slowly and repeatedly across it in order to be engraved (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig1">1</a>d, left and middle). The segments to be engraved are designated with blue color to be easily recognized on the statue. Technically, each segment that has to be removed is split into multiple objects. When each of these objects detects engraving motion, it is removed, and the engraved part of the statue is revealed (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig1">1</a>d, right). When the engraving task is detected, a respective sound and particle system is being visualized to give feedback that the tool is actually touching the statue. If an engraving process outside the designated segments is detected continuously for more than one second, the system considers it an error.</p><p>The three stages have been designed to have a progressive difficulty regarding the concentration and accuracy needed to complete them. In the first task (carving), the user only has to hit the pieces of marble outside the statue with the tool. In the next task (smoothing), the parts that need to be rubbed are smaller in size. Furthermore, she does not just have to bring her tool to these parts, but also to make a rubbing motion while the tool is touching the marble. In the final stage (engraving), the task is similar, but it requires finer movement of the hand. Again, the tool has to touch the marble, but the tool’s edge is considerably smaller and the motion that the hand has to make is also more precise. So when the user completes a task, the next one adds extra challenge. This is in accordance with the theory of flow in museum visits (Csikszentmihalyi and Hermason <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Csikszentmihalyi M, Hermanson K (1995) Intrinsic motivation in museums: Why does one want to learn? In: Falk JH, Dierking LD (eds) Public institutions for personal learning: Establishing a research agenda, American Association of Museums, Washington, DC, pp. 67–77" href="/article/10.1007/s10055-017-0325-0#ref-CR4" id="ref-link-section-d51797e733">1995</a>), according to which the challenges should match the users’ skills.</p><p>After the three stages are completed, the statue is replaced by a detailed 3D model of an actual figurine with a similar shape and size, which makes the user understand how the final statue would look like. The user can freely rotate the statue using hand gestures in order to be able to carefully observe it from various angles (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig1">1</a>e).</p><h3 class="c-article__sub-heading" id="Sec11">Implementation</h3><p>The Cycladic sculpture application has been implemented in Unity Game engine using Leap Motion Orion SDK. In its current version, it supports only interactions with the right hand and includes a single figurine. The prototype implementation is part of a larger project intended to be installed as a public installation for children and adults in exhibition halls related to Cycladic art.</p><p>The main logic of the application during the physical challenges is the following:</p><p>In the beginning of each stage, the shape of the marble visualized in the scene is composed of:</p><ul class="u-list-style-bullet">
                    <li>
                      <p>the <i>resulting model</i>, which is the shape it will have at the end of the stage, and</p>
                    </li>
                    <li>
                      <p>a set of <i>target objects</i>, which have to be removed by the user during the stage.</p>
                    </li>
                  </ul>
<p>These models are presented in a seamless way as a single object. Additionally, the edge of the resulting model is depicted to give the user a visual indication about the areas she has to remove to complete the stage.</p><p>During each stage, the system constantly tests for collisions between the edge of the tool that the user is holding and the objects that define the marble in its current form. If a collision is detected with a target object, then the system examines the velocity of each hit to decide if the action is valid or not, based on the requirements of each stage. If the action is valid, the ‘energy’ of the target object is reduced and respective visual and audio feedback is sent to the user to notify her that the action has succeeded; otherwise, it is simply ignored. After a number of successful actions, depending on the stage, the target object is completely removed and the progress indicator updated accordingly. If the user accidentally hits the resulting model instead of a target object, the action is considered wrong and an audio and textual warning is sent as feedback.</p><p>When all target objects have been removed, the stage is completed and the application progresses to the next one. The resulting piece of marble is again divided into a new resulting model and a new set of target objects. Finally, when all three stages are over, the model is replaced with a detailed model of the actual figurine, which the user can manipulate.</p></div></div></section><section aria-labelledby="Sec12"><div class="c-article-section" id="Sec12-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec12">Evaluation</h2><div class="c-article-section__content" id="Sec12-content"><p>The evaluation of the Cycladic sculpture application was an iterative process that occurred first in the laboratory and then in the field. We report on a total of three evaluation studies, the first two occurred in the computer laboratory and the third one in a more extended field test.</p><p>In the laboratory studies, we investigated the usability and UX of the Cycladic sculpture application in order to get feedback on possible corrections and fixes; therefore, we organized controlled tests with two types of users: adults and children, who are two broad target groups.</p><p>In the field testing study, we assessed the UX in a real setting of educational visits of schools at the museum. We set up an improved version of the Cycladic sculpture application (based on the findings of the two laboratory studies) and we observed and recorded not only UX issues but also the learning effectiveness of playing with the Cycladic sculpture application, especially about whether the participants could recall the stages and the types of tools used in the crafting process.</p><p>In this section, we outline the two laboratory studies regarding the experiment design and results, which are described in detail in (Vosinakis et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Vosinakis S, Koutsabasis P, Makris D, Sagia E (2016) A kinesthetic approach to digital heritage using leap motion: the Cycladic sculpture application. In: 8th International conference on games and virtual worlds for serious applications (VS-GAMES), Barcelona. IEEE" href="/article/10.1007/s10055-017-0325-0#ref-CR38" id="ref-link-section-d51797e806">2016</a>; Koutsabasis and Vosinakis <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Koutsabasis P, Vosinakis S (2016) Adult and children user experience with leap motion in digital heritage: the Cycladic sculpture application. In: Euro-mediterranean conference. Springer, Berlin, pp 350–361" href="/article/10.1007/s10055-017-0325-0#ref-CR17" id="ref-link-section-d51797e809">2016</a>), respectively. Then we present the results of the field study in detail and reflect on these in terms of previous laboratory studies; obviously not for reasons of any comparison since that these are quite different studies but to better explain the evolution of the application to a level that it may be employed in a real setting.</p><h3 class="c-article__sub-heading" id="Sec13">Laboratory studies</h3><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec14">Participants</h4><p>In the first laboratory study, a total of ten (10) users participated on a voluntary basis (nine men, one woman, av. age: 27, SD 7.52); all right-handed; seven participants were students of design engineering of various levels (undergraduate, postgraduate, Ph.D) and three were faculty. Seven participants had limited previous experience with the Leap Motion device. The second study involved ten (10) children (seven girls, three boys, av. age: 10.4, SD 0.44) all right-handed; all were of the fourth grade of elementary school and they were acquainted with Cycladic figurines from their history class; one had limited previous experience with the Leap Motion.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec15">Procedure</h4><p>The procedure was identical for both studies, including:</p><ul class="u-list-style-bullet">
                      <li>
                        <p>Welcome—explanation of the purpose of this study.</p>
                      </li>
                      <li>
                        <p>Familiarization—users freely explored and played the game; at the same time, they were probed to think aloud and provide comments about their experience.</p>
                      </li>
                      <li>
                        <p>Play—users played the game once with logging activated (time to complete task, number of errors); they were not interrupted and they focused on performance.</p>
                      </li>
                      <li>
                        <p>Post-test remarks and questionnaire.</p>
                      </li>
                    </ul>
<h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec16">Measures</h4><p>The measures collected in these studies were:</p><ul class="u-list-style-bullet">
                      <li>
                        <p>UX issues: They were mainly identified during the think-aloud session, but also during play (from observation) and from post-test remarks (self-reported). After the end of all tests, UX issues were processed and coded: this included rewriting (so that a single statement resulted to the same issue), identifying common issues among users and matching issues into wider UX and usability principles.</p>
                      </li>
                      <li>
                        <p>Spontaneous verbal comments; they were recorded during the think-aloud phase.</p>
                      </li>
                      <li>
                        <p>Performance metrics: task time and errors, measured by the application during the play phase. Errors were of the following types: to select the wrong tool, to apply the tool on an incorrect area and to perform an inappropriate gesture repeatedly.</p>
                      </li>
                      <li>
                        <p>Questionnaire responses. Both adults and children filled in the fun toolkit (Read <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Read JC (2008) Validating the Fun Toolkit: an instrument for measuring children’s opinions of technology. Cogn Technol Work 10(2):119–128" href="/article/10.1007/s10055-017-0325-0#ref-CR30" id="ref-link-section-d51797e891">2008</a>), which is a simple and validated instrument to assess the user experience in child–computer interaction. An additional question was added to examine learning effect, that asked users to match tools (emery, pumice and obsidian) with respective tasks.</p>
                      </li>
                    </ul>
<h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec17">Results</h4><p>The overall user experience was positive for all users in both laboratory studies: no participant had a negative response about the app, while children were generally more excited than adults. Regarding performance, this was comparable between adults and children, without statistically significant differences in task time and errors (Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig3">3</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig4">4</a>), despite that most adults (7/10) had some experience with the Leap Motion in contrast to children (1/10); in addition, children were more focused with fewer errors. Regarding qualitative UX, we identified 36 issues (out of think aloud and observation) that were grouped in eight (8) categories: look and feel, tracking, feedback, user positioning, control/reach, gesturing, gamification and visibility. Some of these issues could be improved by redesigning or enhancing the functionality of the app, while others were about technology limitations and instant failures (e.g., lost hand tracking).</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec18">Design improvements</h4><p>Following the evaluation results, we have made a number of modifications in the application to improve the visual quality of the environment and to tackle some of the identified issues.</p><p>Regarding the look and feel of the applications, the improvements were the following:</p><ul class="u-list-style-bullet">
                      <li>
                        <p>We have changed the virtual hands from simplified robotic hands made of primitives to realistic ones. We decided that the simplified hands did not match well with the rest of the environment.</p>
                      </li>
                      <li>
                        <p>We have enhanced the scene lighting to improve the depiction of the environment and figurines, while keeping the shadows strong enough as they are an important depth cue for the task.</p>
                      </li>
                      <li>
                        <p>We have enhanced the particle effects generated during the collision of a tool with the marble, to give stronger feedback that the task is properly applied.</p>
                      </li>
                    </ul>
<p>Regarding the physical challenges, we made the following improvements:</p><ul class="u-list-style-bullet">
                      <li>
                        <p>The rules for proper smoothing and engraving have been relaxed, to make these stages easier. We noted that some users had difficulty to apply the tools correctly.</p>
                      </li>
                      <li>
                        <p>We readjusted the camera and virtual hands’ position with respect to the statue to avoid some ‘extreme’ positions that made users stretch their hands too much during the tasks. In the improved version, the hand trajectories required to complete the tasks were limited to a considerably smaller space.</p>
                      </li>
                    </ul>
<p>Finally, we added an inactivity timer that restarts the application, which is required for public unassisted usage.</p><h3 class="c-article__sub-heading" id="Sec19">Field study</h3><p>Field studies are different from usability testing in several dimensions. In field studies, user interaction occurs in an authentic place and context while the evaluator does not have high control of the process, in contrast to usability testing that occurs in the computer lab. In addition, in field studies, social factors like the presence and interactions with others as well as environmental factors like lighting and noise affect the evaluation results.</p><p>Field testing with children and teenagers presents several challenges including (adapted from Markopoulos et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Markopoulos P, Read JC, MacFarlane S, Hoysniemi J (2008) Evaluating children’s interactive products: principles and practices for interaction designers. Morgan Kaufmann, Burlington" href="/article/10.1007/s10055-017-0325-0#ref-CR19" id="ref-link-section-d51797e977">2008</a>) who refer in school settings) that: (1) the evaluation should fit within a session and support the wider activity goals, (2) the evaluation should have a high degree of structure and continuity and should get back on track from unexpected events (like system crashes or field distractions) and (3) the experimenter should adapt to the administrative and regulatory framework of the institution (the particular museum) where the field testing occurs.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec20">Context: educational activity ‘marble yesterday and today’</h4><p>The Cycladic sculpture app was part of an educational activity entitled ‘Marble Yesterday and Today,’<sup><a href="#Fn4"><span class="u-visually-hidden">Footnote </span>4</a></sup> which was organized by the Museum of Cycladic Art<sup><a href="#Fn5"><span class="u-visually-hidden">Footnote </span>5</a></sup> and the Piraeus Bank Group Cultural Foundation (PIOP).<sup><a href="#Fn6"><span class="u-visually-hidden">Footnote </span>6</a></sup> The activity was hosted by one of the museums of the PIOP network, the Museum of Marble Crafts<sup><a href="#Fn7"><span class="u-visually-hidden">Footnote </span>7</a></sup> in Tinos island, Cyclades, Greece. The event was meant to celebrate the inscription of Tinos marble craftsmanship on the UNESCO Representative List of the Intangible Cultural Heritage of Humanity. The program runs for 2 days, and it was designed for schools and the public, and included (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig2">2</a>):</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0325-0/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0325-0/MediaObjects/10055_2017_325_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0325-0/MediaObjects/10055_2017_325_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Moments of the educational activity: <b>a</b> live workshop of ‘how they were made?,’ <b>b</b> pupils drawing on a Cycladic figurine, <b>c</b> sculpture artists during demonstration, <b>d</b> museum-kit activity, <b>e</b> pupils and teachers over the Cycladic sculpture app, <b>f</b> children playing with the app</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0325-0/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<ul class="u-list-style-bullet">
                      <li>
                        <p>Live workshop of ancient marble-working techniques</p>
                      </li>
                      <li>
                        <p>Presentation of modern sculptures produced by Tinian artists</p>
                      </li>
                      <li>
                        <p>Educational program with the MCA museum-kit ‘Cycladic culture’</p>
                      </li>
                      <li>
                        <p>Interactions with the Cycladic sculpture app</p>
                      </li>
                    </ul>
<p>During the days of the educational activity, the Cycladic sculpture app was installed in three laptops which were constantly available for museum visitors. One of these laptops was connected to the projector so that nearby visitors could watch from a distance. At least one of the researchers was constantly nearby to observe users as they played and gather feedback as well as help when necessary. Furthermore, three scheduled visits of local schools occurred; during these visits, we conducted field testing.</p><h3 class="c-article__sub-heading" id="Sec21">Participants and procedure</h3><p>Field testing occurred in a total of eight sessions, which lasted for approximately 1 h each and included groups of 10–12 pupils at a time. A total number of 74 pupils of local secondary schools participated. They were all teenagers, between 11 and 15 years, av. age: 12.62, SD: 1.39, 48 girls. Few pupils had seen the Leap Motion device before (4/74). They came into interact with the Cycladic sculpture app after they had visited the other workshops and they were accompanied by their teachers. The participants were both right-handed and left-handed, since that the field study occurred in a realistic setting and there were no other criteria for user recruitment/selection. The process of field testing involved:</p><ul class="u-list-style-bullet">
                    <li>
                      <p>Introduction: a short talk about the app and the Leap Motion device along with a rapid demonstration of use (5′).</p>
                    </li>
                    <li>
                      <p>Play: Pupils played the game once, in turns. If time remained, some played again. During play, logging was enabled to record task time and errors per operation. (ranged approximately from 6 to 9 min per user)</p>
                    </li>
                    <li>
                      <p>Questionnaire: Pupils filled in a simple questionnaire on a voluntary basis and 61 answers were collected.</p>
                    </li>
                    <li>
                      <p>Short retrospective interviews were made with several users about their user experience (3′).</p>
                    </li>
                  </ul>
<h3 class="c-article__sub-heading" id="Sec22">Measures</h3><p>The measures collected were:</p><ul class="u-list-style-bullet">
                    <li>
                      <p>UX issues: They were identified during play (from observation) and from post-test remarks (self-reported).</p>
                    </li>
                    <li>
                      <p>Performance metrics: task time and errors, measured by the application during the play phase.</p>
                    </li>
                    <li>
                      <p>Questionnaire responses. The adapted version of the fun toolkit (Read <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Read JC (2008) Validating the Fun Toolkit: an instrument for measuring children’s opinions of technology. Cogn Technol Work 10(2):119–128" href="/article/10.1007/s10055-017-0325-0#ref-CR30" id="ref-link-section-d51797e1173">2008</a>) that was used in previous studies was employed.</p>
                    </li>
                  </ul>
<h3 class="c-article__sub-heading" id="Sec23">Results</h3><p>We present the results of the field study in terms of (a) overall impressions recorded during our retrospective interviews with the participants as well as their questionnaire responses; (b) performance measures, i.e., task time and errors, as these were logged from the app; (c) perceived usability and (d) learning effectiveness as these were provided by participants in questionnaire responses; (e) UX issues, as these were observed during the field tests and discussed with users in retrospective interviews.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec24">Overall impression</h4><p>The participants filled in the smileyometer of the fun toolkit to indicate how they liked the app. The clear majority thought that the app was ‘Brilliant’ (65.57%) or ‘Really Good’ (26.22%), while four participants thought that the app was ‘Good’ (8.19%) and one ‘Not Very Good’ (1.6%); none thought that the app was ‘Awful,’ which is the last option of the smileyometer.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec25">Performance (task time and errors)</h4><p>User performance was generally improved in comparison with previous controlled studies. This was expected due to the improvements made upon the app; however, we were unsure about the level of anticipated improvement due to the nature of the testing procedure: The field test has several inevitable distractions for users.</p><p>Regarding task time (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig3">3</a>), users were slightly slower at the carve task in comparison with the previous controlled studies. This is attributed to the fact that in this field, users were not permitted to familiarize themselves with the app (which was the case in the user testing sessions). On the contrary, they had to start using the app at once, which caused delays during the first phase (carving). Further on, at the smoothen phase users performed significantly faster than both controlled studies, and this was also the case with the engraving phase between teenagers and children.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0325-0/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0325-0/MediaObjects/10055_2017_325_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0325-0/MediaObjects/10055_2017_325_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Average time to task for the three studies</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0325-0/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>Regarding errors (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig4">4</a>), the picture was mixed in comparison with the controlled studies. During carving, average errors were at a middle level in comparison with the other studies, while they were decreased during the smoothening phase and increased during the engraving phase. We expected a possible increase of errors due to the distractions caused from others during play. Nonetheless, no significant changes in errors were found.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0325-0/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0325-0/MediaObjects/10055_2017_325_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0325-0/MediaObjects/10055_2017_325_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Average errors for the three studies</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0325-0/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec26">Perceived usability</h4><p>The participants were asked to provide their view on the ease of use of the three tools at a 4-point Likert scale question (Was it easy to use?). Participant responses are depicted in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig5">5</a>. Overall, they were very positive for the first two tools (carve, smoothen) which were found either ‘Very easy’ or ‘Easy’ for the clear majority of users (&gt; 80%). Participants provided mixed responses for the third tool (engraving): 11.48% found it very easy; 26.23% found it easy; 47.54% found it ‘not so easy’ and 14.75% found it difficult. This was expected since that this is the most difficult tool to use by design.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0325-0/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0325-0/MediaObjects/10055_2017_325_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0325-0/MediaObjects/10055_2017_325_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Participant responses to questions about fun and perceived usability</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0325-0/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>The participants were also asked to provide their response to the question ‘Would you do it again?’ for each tool, at a 3-point Likert scale (yes, maybe or no). Participant responses are depicted in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0325-0#Fig5">5</a>. There is a clear majority of participants who would like to play again with the app for all tools (carve: 77.77%, smoothen: 80.33% and engrave: 60.66%). This result is very encouraging, especially regarding the engraving tool for which most participants reported that it was difficult to use.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec27">Learning effectiveness</h4><p>Participants were asked to match the types of tools with respective tasks (by drawing lines from ‘tool’ to ‘task’ on the questionnaire). This question examined if pupils indeed learned about the types of stones used as tools in the past. The responses were correct to a very high degree: Pupils connected carving to emery to a 91.8%, smoothening to pumice to 96.72% and engraving to obsidian to a 91.80%. Despite that it was not a direct goal of the participants to learn about the specific materials used, they did so seamlessly at a very satisfactory degree.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec28">UX issues</h4><p>During the field tests, we observed users and noted reactions and responses; furthermore, we discussed with several users after playing with the app. The main issues identified are as follows:</p><ul class="u-list-style-bullet">
                      <li>
                        <p>Hand Tracking: The Leap Motion sensor may suddenly lose hand tracking or it may track the left hand for the right (and vice versa)—both fails are frustrating for users. It may not respond with high precision on hand movements, e.g., a hand fist may not show precisely as such on the virtual hand. In some cases, user clothing (long or wide sleeves) and accessories (metal rings or bracelets) affect sensor tracking—it would be a useful improvement of the sensor API to identify possible reasons for lost tracking so that the developer can appropriately notify the user.</p>
                      </li>
                      <li>
                        <p>User positioning: Some flexibility to user positioning with respect to the Leap Motion device and the screen must be allowed, especially if users of multiple heights and arm lengths are to be using the system.</p>
                      </li>
                      <li>
                        <p>Look and Feel:</p><ul class="u-list-style-bullet">
                            <li>
                              <p>Many users do not have a good perception of depth, especially when they held any stone tool and attempted an operation onto the figurine, despite that shadow feedback was implemented. This considerably delayed some users.</p>
                            </li>
                            <li>
                              <p>Users experience fatigue if they must hold their hands in the mid-air for long—depending on the user and the arm stance, this interval may range from a few seconds to half a minute. In earlier versions of the app, users did experience fatigue; however, in the field tests, only two or three users reported fatigue due to improvements made.</p>
                            </li>
                            <li>
                              <p>In addition, some users also found it strange that the virtual hand penetrated the digital figurine. Since that there is no force feedback in bare-hand interaction, this is a design issue with tradeoffs in either case: either the user has complete control on the virtual hand (with the consequence that it may penetrate other digital objects), or the hand obeys physics and does not always follow the physical hand’s motion, which will be unexpected for the user.</p>
                            </li>
                          </ul>

                      </li>
                    </ul>
</div></div></section><section aria-labelledby="Sec29"><div class="c-article-section" id="Sec29-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec29">Discussion</h2><div class="c-article-section__content" id="Sec29-content"><h3 class="c-article__sub-heading" id="Sec30">Design considerations</h3><p>To the best of our knowledge, there are no previous studies that make use of bare-hand kinesthetic interaction to convey cultural heritage through (re)constructing artworks in a role-playing manner. After an iterative process of design development and evaluation, we have found that this approach is technically feasible, engaging and useful, provided it is carefully designed. Building on the experiences gained from subsequent design and evaluation, we outline some design considerations that for future applications with similar aims.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec31">Simplified movements and gestures</h4><p>The creation of a Cycladic figurine is a delicate process over hard tools and material, which ultimately requires thousands of repeated moves. The available technology is not close enough to the high accuracy and precision required that would allow such delicate operations. Therefore, this app was not designed to resemble this painstaking process, although it would be of value in terms of heritage. Specifically, the creation of figurines such as the one we used in our application using the ancient tools is estimated to last around between 20 and 30 h (Papadatos and Venieris <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Papadatos Y, Venieris E (2016) An experimental approach to the manufacture of Cycladic-type figurines with folded arms: preliminary observations. In: Early Cycladic Sculpture in Context. Oxbow Books, Oxford, pp 483–490" href="/article/10.1007/s10055-017-0325-0#ref-CR25" id="ref-link-section-d51797e1365">2016</a>). Although the design could be improved to reflect this, we undertook an approach that allows users to gain results over simplified moves with few operations to serve the main learning goals of the app. On the other hand, it is a challenging design task to simplify and shorten the process so that the various actions may be completed at acceptable times with gestures that are easy to learn and mimic. A challenging issue in this respect is to make sure that the important messages are still conveyed even after the simplification of the tasks included in the application.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec32">Personalization</h4><p>Another aspect of this kind of applications that should be looked at carefully is to make room for personalization and self-expression. This has been also mentioned by some users during the evaluations. They would like to be able to influence the final outcome and maybe create something unique. Such an addition is certainly a fun and motivating factor worth exploring (Hunicke et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Hunicke R, LeBlanc M, Zubek R (2004) MDA: a formal approach to game design and game research. In: Proceedings of the AAAI workshop on challenges in game AI" href="/article/10.1007/s10055-017-0325-0#ref-CR15" id="ref-link-section-d51797e1376">2004</a>). It is, nevertheless, still challenging to find a proper balance between uncontrolled freedom of expression that would possibly lead to unexpected/poor results, and pre-designed fully controllable outcome. A possible extension toward this end for our application would be to let users freely paint on top of the statue, using the colors and techniques of ancient times. Another one that would need careful planning and a different implementation approach would be to let users slightly affect the final shape and engravings of the statue based on their actions, but within some controlled limits.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec33">Perception of depth in bare hands interaction</h4><p>A clear finding from our studies is that a lot of users had difficulties in depth perception. They were moving their hand thinking that they were working on the marble, but their virtual tool was not touching the stone at all. Most of them quickly realized that and repositioned their hands, but still, this difficulty was sometimes a source of irritation. Designers should be very careful in providing adequate depth cues to minimize this effect, e.g., add some extra visual effects to indicate the distance between the tool and the target, even with a small compromise in realism. The use of stereoscopy might also improve depth perception, as implied by related research (Renner et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Renner RS, Velichkovsky BM, Helmert JR (2013) The perception of egocentric distances in virtual environments-a review. ACM Comput Surv (CSUR) 46(2):23" href="/article/10.1007/s10055-017-0325-0#ref-CR31" id="ref-link-section-d51797e1387">2013</a>). Visitors could use 3D glasses or an HMD to view the environment, and thus get much more immersive experience. On the other hand, the introduction of this additional hardware in a public installation is not always easy.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec34">Feedback</h4><p>A further issue with bare-hand interactions is the lack of any haptic or tactile feedback. Even if users had adequate depth perception, they would still not get clear feedback about the success of their action and they would miss the feeling of applying force on an object. Furthermore, although they are supposed to hold a tool, their hand is actually empty. A previous study provides evidence that physically touching a virtual object enhances the realism of the experience (Hoffman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Hoffman HG, Hollander A, Schroder K, Rousseau S, Furness T (1998) Physically touching and tasting virtual objects enhances the realism of virtual experiences. Virtual Real 3(4):226–234" href="/article/10.1007/s10055-017-0325-0#ref-CR13" id="ref-link-section-d51797e1399">1998</a>). In our application, we used a typical sensory substitution approach with sounds and particle effects to give an imminent reaction of the environment when a successful hit was performed, which seems to have worked quite well. More specifically, we provided detailed and differentiated audio feedback for each (sub) task, and we have found that a repertoire of sounds needs to be identified, produced and tested during prototyping. We are currently experimenting with a future version of our application, in which tangible objects in the forms of ancient tools will be provided, and they will create a vibrating feedback when a collision is detected. Although not as sophisticated as high-end force-feedback systems, we believe that this addition will have positive effects on immersion and enjoyment.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec35">Error tolerance</h4><p>Kinesthetic interaction is a new interaction paradigm; there is no value in allowing users to make errors or mistakes since that it is also painstaking for them to recover from these or revert. Therefore, we adhered to the following design conventions for the Cycladic sculpture app:</p><ul class="u-list-style-bullet">
                      <li>
                        <p>virtual grasping by letting the hand penetrate the digital object and allowing users to make a clear first gesture,</p>
                      </li>
                      <li>
                        <p>stick object to hand, after grab; it is not effective to allow users to drop digital tools,</p>
                      </li>
                      <li>
                        <p>warn users about mistakes, but not punish them. For example, differentiate sound feedback or show warning messages but do not destroy the statue.</p>
                      </li>
                    </ul>
<p>Public installations supporting kinesthetic interactions should be designed to be tolerant to errors. On the one hand, it is expected that the sensors will produce some erroneous results due to noise, sensing capabilities and other limitations of the environment. On the other, there will be a great variety of users with respect to their previous experience with technology and interactive systems; from people who are already familiar with natural interfaces to others who have rarely used an interactive application before and are not aware of the capabilities and limitations of tracking technology. It is therefore expected that they may have some unexpected performance regarding their pose, gestures and general attitude toward the environment. The system should be well designed to handle difficulties such as these without confusing or irritating users. Ideally, it should be able to identify the reason behind an unexpected behavior and offer some extra assistance. For example, if frequent tracking errors are detected, the system could ask the user to check whether her hands are not properly placed or whether she is wearing some long sleeves or jewelry that affect the sensing performance. Or, if a user is constantly missing the spot due to depth misperception, it could show an extra side view of the environment to help her understand the distance between the virtual tool and the target.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec36">Gamification</h4><p>The environment could be enhanced with gamification elements to make the experience more engaging. This was particularly mentioned in the second laboratory study from children. Interesting dimensions that could be explored are challenge, competition and rewards. The environment could include well-designed challenges with increasing difficulty to retain a state of flow, which is partially embedded in the current version. It could further provide score and errors or even a scoreboard to make the process more challenging and competitive. Finally, badges and locked content could be also offered as means of reward to increase player satisfaction and engagement. One has, however, to think carefully about the time spent by each user while interacting with the system; public installations should provide short and easy to complete experiences that leave the visitors satisfied without delaying too much other users waiting to interact.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec37">Ergonomics of system setup</h4><p>Another consideration regarding this type of applications is the system setup in a public space. In contrast to Kinect, Leap Motion has a limited effective area and the users’ hands must be quite close to the sensor. On the other hand, the setup of a public installation should ideally be able to work successfully for most visitors regardless of their height and arm length. This means that either the user has to be seated, or the placement of the sensor should be somehow adjustable to comply for various height differences. A static sensor placement for standing users will probably exclude young children or even very tall people.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec38">Issues of installation in the museum</h4><p>The Cycladic sculpture application is a small-sized installation that may be discretely seeded into a physical museum collection in the form of an interactive kiosk. In contrast to other kinesthetic installations that are large in scale and require considerable free space for users to move and room for projected display, this application may be situated in a kiosk close to the figurines and crafting tools. This would allow a seamless coupling of physical exhibits and interactive technology in an affordable manner regarding required space, budget and operational costs. Furthermore, the application may be conceptually connected to Cycladic figurines that are present in the physical exhibition. In this way, for example, a user might choose to create another figurine type and in accordance to select appropriate tools and make respective operations. Furthermore, users could identify these tools or figurines in the physical collection and be motived to further seek for exhibits; the latter could be enhanced with mobile technologies and gamification scenarios.</p><h3 class="c-article__sub-heading" id="Sec39">Limitations</h3><p>We identify some limitations of our work. A wider issue that stems from the current content of the Cycladic sculpture app is that this includes one Cycladic figurine, that with folded arms. We are working toward extending the application to include more figurines with different poses; when these are introduced and tested, additional issues of UX may be identified. Another limitation is that we did not control the gender bias of the laboratory user tests. In these tests, we employed participants on a voluntary basis with the primary goal to gather UX issues from observation and think aloud; since that that we saw that the process was generative and several issues were identified on the way, we did not decide to control gender bias. One last limitation is that the manipulation of tools is made with the right hand only. We are extending the application to support manipulations with both hands.</p></div></div></section><section aria-labelledby="Sec40"><div class="c-article-section" id="Sec40-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec40">Conclusions</h2><div class="c-article-section__content" id="Sec40-content"><p>There are few public installations related to cultural heritage which support kinesthetic interactions beyond navigating digital spaces or browsing collections. We have presented the design, development and evaluation of the Cycladic sculpture application, which conveys elements of cultural heritage via placing the user in the role of an ancient craftsman who constructs a figurine. The cultural elements conveyed include (a) the creation phases of a Cycladic figurine; (b) the stone tools employed; (c) the iterative (and tiring) actions to be applied onto the marble. From the field evaluation, we found that users learned about these during playing with the application seamlessly, while they also had much fun. Furthermore, during the iterative testing and redesign of the application, we have identified several interaction design issues that we envisage they will be found useful for other designers and developers in similar applications. The Cycladic sculpture application itself may be extended in several dimensions including personalization, linking to physical collections as well as adding tangible elements and tactile feedback; we are currently working toward these developments.</p></div></div></section>
                        
                    

                    <section aria-labelledby="notes"><div class="c-article-section" id="notes-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="notes">Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1"><span class="c-article-footnote--listed__index">1.</span><div class="c-article-footnote--listed__content"><p>
                                <a href="https://en.wikipedia.org/wiki/Wii_Remote">https://en.wikipedia.org/wiki/Wii_Remote</a>.</p></div></li><li class="c-article-footnote--listed__item" id="Fn2"><span class="c-article-footnote--listed__index">2.</span><div class="c-article-footnote--listed__content"><p>
                                <a href="https://apps.leapmotion.com/apps/tombraining-the-gallery-trial/windows">https://apps.leapmotion.com/apps/tombraining-the-gallery-trial/windows</a>.</p></div></li><li class="c-article-footnote--listed__item" id="Fn3"><span class="c-article-footnote--listed__index">3.</span><div class="c-article-footnote--listed__content"><p>
                            <a href="https://www.cycladic.gr/">https://www.cycladic.gr/</a>.</p></div></li><li class="c-article-footnote--listed__item" id="Fn4"><span class="c-article-footnote--listed__index">4.</span><div class="c-article-footnote--listed__content"><p>
                                <a href="https://www.cycladic.gr/en/page/to-marmaro-chthes-kai-simera">https://www.cycladic.gr/en/page/to-marmaro-chthes-kai-simera</a>.</p></div></li><li class="c-article-footnote--listed__item" id="Fn5"><span class="c-article-footnote--listed__index">5.</span><div class="c-article-footnote--listed__content"><p>
                                <a href="https://www.cycladic.gr/en">https://www.cycladic.gr/en</a>.</p></div></li><li class="c-article-footnote--listed__item" id="Fn6"><span class="c-article-footnote--listed__index">6.</span><div class="c-article-footnote--listed__content"><p>
                                <a href="http://www.piop.gr/en/">http://www.piop.gr/en/</a>.</p></div></li><li class="c-article-footnote--listed__item" id="Fn7"><span class="c-article-footnote--listed__index">7.</span><div class="c-article-footnote--listed__content"><p>
                                <a href="http://www.piop.gr/en/diktuo-mouseiwn/Mouseio-Marmarotexnias-Tinou/to-mouseio.aspx">http://www.piop.gr/en/diktuo-mouseiwn/Mouseio-Marmarotexnias-Tinou/to-mouseio.aspx</a>.</p></div></li></ol></div></div></section><section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EF. Anderson, L. McLoughlin, F. Liarokapis, C. Peters, P. Petridis, S. Freitas, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Anderson EF, McLoughlin L, Liarokapis F, Peters C, Petridis P, de Freitas S (2010) Developing serious games fo" /><p class="c-article-references__text" id="ref-CR1">Anderson EF, McLoughlin L, Liarokapis F, Peters C, Petridis P, de Freitas S (2010) Developing serious games for cultural heritage: a state-of-the-art review. Virtual Real 14(4):255–275</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10055-010-0177-3" aria-label="View reference 1">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Developing%20serious%20games%20for%20cultural%20heritage%3A%20a%20state-of-the-art%20review&amp;journal=Virtual%20Real&amp;volume=14&amp;issue=4&amp;pages=255-275&amp;publication_year=2010&amp;author=Anderson%2CEF&amp;author=McLoughlin%2CL&amp;author=Liarokapis%2CF&amp;author=Peters%2CC&amp;author=Petridis%2CP&amp;author=Freitas%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Barton AJ, Goeser C (2013) Transforming the art museum experience: gallery one. museums and the web. http://mw" /><p class="c-article-references__text" id="ref-CR2">Barton AJ, Goeser C (2013) Transforming the art museum experience: gallery one. museums and the web. <a href="http://mw2013.museumsandtheweb.com/paper/transforming-the-art-museum-experience-gallery-one-2/">http://mw2013.museumsandtheweb.com/paper/transforming-the-art-museum-experience-gallery-one-2/</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="N. Correia, T. Romão, A. Ricardo, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Correia N, Romão T, Ricardo A et al (2014) Design of an interactive experience with medieval illuminations: a " /><p class="c-article-references__text" id="ref-CR3">Correia N, Romão T, Ricardo A et al (2014) Design of an interactive experience with medieval illuminations: a journey into the beauty and meaning of medieval Portuguese manuscripts. J Comput Cult Herit (JOCCH) 7(2):13</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Design%20of%20an%20interactive%20experience%20with%20medieval%20illuminations%3A%20a%20journey%20into%20the%20beauty%20and%20meaning%20of%20medieval%20Portuguese%20manuscripts&amp;journal=J%20Comput%20Cult%20Herit%20%28JOCCH%29&amp;volume=7&amp;issue=2&amp;publication_year=2014&amp;author=Correia%2CN&amp;author=Rom%C3%A3o%2CT&amp;author=Ricardo%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="M. Csikszentmihalyi, K. Hermanson, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Csikszentmihalyi M, Hermanson K (1995) Intrinsic motivation in museums: Why does one want to learn? In: Falk J" /><p class="c-article-references__text" id="ref-CR4">Csikszentmihalyi M, Hermanson K (1995) Intrinsic motivation in museums: Why does one want to learn? In: Falk JH, Dierking LD (eds) Public institutions for personal learning: Establishing a research agenda, American Association of Museums, Washington, DC, pp. 67–77</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Public%20institutions%20for%20personal%20learning%3A%20Establishing%20a%20research%20agenda&amp;pages=67-77&amp;publication_year=1995&amp;author=Csikszentmihalyi%2CM&amp;author=Hermanson%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="De Paolis LT, Aloisio G, Celentano MG, Oliva L, Vecchio P (2011) Experiencing a town of the Middle Ages: an ap" /><p class="c-article-references__text" id="ref-CR5">De Paolis LT, Aloisio G, Celentano MG, Oliva L, Vecchio P (2011) Experiencing a town of the Middle Ages: an application for the edutainment in cultural heritage. In: 2011 IEEE 3rd international conference on communication software and networks (ICCSN). pp 169–174. IEEE</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="England D (2011) Whole body interaction: An introduction. In: Whole Body Interaction Springer, London, pp. 1-5" /><p class="c-article-references__text" id="ref-CR6">England D (2011) Whole body interaction: An introduction. In: Whole Body Interaction Springer, London, pp. 1-5</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fanini B, d’Annibale E, Demetrescu E, Ferdani D, Pagano A (2015) Engaging and shared gesture-based interaction" /><p class="c-article-references__text" id="ref-CR7">Fanini B, d’Annibale E, Demetrescu E, Ferdani D, Pagano A (2015) Engaging and shared gesture-based interaction for museums the case study of K2R international expo in Rome. In: 2015 Digital heritage, vol 1, pp 263–270. IEEE</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fogtmann MH, Fritsch J, Kortbek KJ (2008) Kinesthetic interaction: revealing the bodily potential in interacti" /><p class="c-article-references__text" id="ref-CR8">Fogtmann MH, Fritsch J, Kortbek KJ (2008) Kinesthetic interaction: revealing the bodily potential in interaction design. In: Proceedings of the 20th Australasian conference on computer-human interaction: designing for habitus and habitat, pp 89–96. ACM</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Guna, G. Jakus, M. Pogačnik, S. Tomažič, J. Sodnik, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Guna J, Jakus G, Pogačnik M, Tomažič S, Sodnik J (2014) An analysis of the precision and reliability of the le" /><p class="c-article-references__text" id="ref-CR9">Guna J, Jakus G, Pogačnik M, Tomažič S, Sodnik J (2014) An analysis of the precision and reliability of the leap motion sensor and its suitability for static and dynamic tracking. Sensors 14(2):3702–3720</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3390%2Fs140203702" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20analysis%20of%20the%20precision%20and%20reliability%20of%20the%20leap%20motion%20sensor%20and%20its%20suitability%20for%20static%20and%20dynamic%20tracking&amp;journal=Sensors&amp;volume=14&amp;issue=2&amp;pages=3702-3720&amp;publication_year=2014&amp;author=Guna%2CJ&amp;author=Jakus%2CG&amp;author=Poga%C4%8Dnik%2CM&amp;author=Toma%C5%BEi%C4%8D%2CS&amp;author=Sodnik%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Gunn, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Gunn C (2006) Collaborative virtual sculpting with haptic feedback. Virtual Real 10(2):73–83" /><p class="c-article-references__text" id="ref-CR10">Gunn C (2006) Collaborative virtual sculpting with haptic feedback. Virtual Real 10(2):73–83</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10055-006-0044-4" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Collaborative%20virtual%20sculpting%20with%20haptic%20feedback&amp;journal=Virtual%20Real&amp;volume=10&amp;issue=2&amp;pages=73-83&amp;publication_year=2006&amp;author=Gunn%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="GE. Hein, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Hein GE (2002) Learning in the museum. Routledge, London" /><p class="c-article-references__text" id="ref-CR11">Hein GE (2002) Learning in the museum. Routledge, London</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20in%20the%20museum&amp;publication_year=2002&amp;author=Hein%2CGE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hernández-Ibáñez LA, Barneche-Naya V, Mihura-López R (2016) Natural interaction and movement paradigms. A comp" /><p class="c-article-references__text" id="ref-CR12">Hernández-Ibáñez LA, Barneche-Naya V, Mihura-López R (2016) Natural interaction and movement paradigms. A comparison of usability for a kinect enabled museum installation. In: International conference on learning and collaboration technologies, Springer, Berlin, pp 145–155</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HG. Hoffman, A. Hollander, K. Schroder, S. Rousseau, T. Furness, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Hoffman HG, Hollander A, Schroder K, Rousseau S, Furness T (1998) Physically touching and tasting virtual obje" /><p class="c-article-references__text" id="ref-CR13">Hoffman HG, Hollander A, Schroder K, Rousseau S, Furness T (1998) Physically touching and tasting virtual objects enhances the realism of virtual experiences. Virtual Real 3(4):226–234</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2FBF01408703" aria-label="View reference 13">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Physically%20touching%20and%20tasting%20virtual%20objects%20enhances%20the%20realism%20of%20virtual%20experiences&amp;journal=Virtual%20Real&amp;volume=3&amp;issue=4&amp;pages=226-234&amp;publication_year=1998&amp;author=Hoffman%2CHG&amp;author=Hollander%2CA&amp;author=Schroder%2CK&amp;author=Rousseau%2CS&amp;author=Furness%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HMJ. Hsu, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Hsu HMJ (2011) The potential of kinect in education. Int J Inf Educ Technol 1(5):365" /><p class="c-article-references__text" id="ref-CR14">Hsu HMJ (2011) The potential of kinect in education. Int J Inf Educ Technol 1(5):365</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20potential%20of%20kinect%20in%20education&amp;journal=Int%20J%20Inf%20Educ%20Technol&amp;volume=1&amp;issue=5&amp;publication_year=2011&amp;author=Hsu%2CHMJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hunicke R, LeBlanc M, Zubek R (2004) MDA: a formal approach to game design and game research. In: Proceedings " /><p class="c-article-references__text" id="ref-CR15">Hunicke R, LeBlanc M, Zubek R (2004) MDA: a formal approach to game design and game research. In: Proceedings of the AAAI workshop on challenges in game AI</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Koutsabasis P, Domouzis C (2016) Mid-air browsing and selection in image collections. In: International workin" /><p class="c-article-references__text" id="ref-CR16">Koutsabasis P, Domouzis C (2016) Mid-air browsing and selection in image collections. In: International working conference on advanced visual interfaces (AVI) 2016. ACM</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Koutsabasis P, Vosinakis S (2016) Adult and children user experience with leap motion in digital heritage: the" /><p class="c-article-references__text" id="ref-CR17">Koutsabasis P, Vosinakis S (2016) Adult and children user experience with leap motion in digital heritage: the Cycladic sculpture application. In: Euro-mediterranean conference. Springer, Berlin, pp 350–361</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Leap Motion App Store. https://apps.leapmotion.com/&#xA;                " /><p class="c-article-references__text" id="ref-CR18">Leap Motion App Store. <a href="https://apps.leapmotion.com/">https://apps.leapmotion.com/</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="P. Markopoulos, JC. Read, S. MacFarlane, J. Hoysniemi, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Markopoulos P, Read JC, MacFarlane S, Hoysniemi J (2008) Evaluating children’s interactive products: principle" /><p class="c-article-references__text" id="ref-CR19">Markopoulos P, Read JC, MacFarlane S, Hoysniemi J (2008) Evaluating children’s interactive products: principles and practices for interaction designers. Morgan Kaufmann, Burlington</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Evaluating%20children%E2%80%99s%20interactive%20products%3A%20principles%20and%20practices%20for%20interaction%20designers&amp;publication_year=2008&amp;author=Markopoulos%2CP&amp;author=Read%2CJC&amp;author=MacFarlane%2CS&amp;author=Hoysniemi%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="A. Markussen, MR. Jakobsen, K. Hornbæk, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Markussen A, Jakobsen MR, Hornbæk K (2013) Selection-based mid-air text entry on large displays. IFIP conferen" /><p class="c-article-references__text" id="ref-CR20">Markussen A, Jakobsen MR, Hornbæk K (2013) Selection-based mid-air text entry on large displays. IFIP conference on human–computer interaction. Springer, Berlin, pp 401–418</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=IFIP%20conference%20on%20human%E2%80%93computer%20interaction&amp;pages=401-418&amp;publication_year=2013&amp;author=Markussen%2CA&amp;author=Jakobsen%2CMR&amp;author=Hornb%C3%A6k%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="McDonnell K, Qin H, Wlodarczyk R (2001) Virtual clay: a real-time sculpting system with haptic toolkits. In: P" /><p class="c-article-references__text" id="ref-CR21">McDonnell K, Qin H, Wlodarczyk R (2001) Virtual clay: a real-time sculpting system with haptic toolkits. In: Proceedings of the 2001 symposium on Interactive 3D graphics. ACM</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Mortara, CE. Catalano, F. Bellotti, G. Fiucci, M. Houry-Panchetti, P. Petridis, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Mortara M, Catalano CE, Bellotti F, Fiucci G, Houry-Panchetti M, Petridis P (2014) Learning cultural heritage " /><p class="c-article-references__text" id="ref-CR22">Mortara M, Catalano CE, Bellotti F, Fiucci G, Houry-Panchetti M, Petridis P (2014) Learning cultural heritage by serious games. J Cult Herit 15(3):318–325</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.culher.2013.04.004" aria-label="View reference 22">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20cultural%20heritage%20by%20serious%20games&amp;journal=J%20Cult%20Herit&amp;volume=15&amp;issue=3&amp;pages=318-325&amp;publication_year=2014&amp;author=Mortara%2CM&amp;author=Catalano%2CCE&amp;author=Bellotti%2CF&amp;author=Fiucci%2CG&amp;author=Houry-Panchetti%2CM&amp;author=Petridis%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Nancel M, Wagner J, Pietriga E, Chapuis O, Mackay W (2011) Mid-air pan-and-zoom on wall-sized displays. In: Pr" /><p class="c-article-references__text" id="ref-CR23">Nancel M, Wagner J, Pietriga E, Chapuis O, Mackay W (2011) Mid-air pan-and-zoom on wall-sized displays. In: Proceedings of the SIGCHI conference on human factors in computing systems, pp 177–186. ACM</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="E. Oustinoff, " /><meta itemprop="datePublished" content="1987" /><meta itemprop="headline" content="Oustinoff E (1987) The Early Cycladic sculptor: materials and methods. In: Getz-Preziosi P (ed) Early Cycladic" /><p class="c-article-references__text" id="ref-CR24">Oustinoff E (1987) The Early Cycladic sculptor: materials and methods. In: Getz-Preziosi P (ed) Early Cycladic Art in North American Collections. Virginia Museum of Fine Arts, Richmond, pp 90–102</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Early%20Cycladic%20Art%20in%20North%20American%20Collections&amp;pages=90-102&amp;publication_year=1987&amp;author=Oustinoff%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Papadatos Y, Venieris E (2016) An experimental approach to the manufacture of Cycladic-type figurines with fol" /><p class="c-article-references__text" id="ref-CR25">Papadatos Y, Venieris E (2016) An experimental approach to the manufacture of Cycladic-type figurines with folded arms: preliminary observations. In: Early Cycladic Sculpture in Context. Oxbow Books, Oxford, pp 483–490</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Papadimitriou N (2015) How were they created? Materials and techniques of crafting ancient artefacts. A public" /><p class="c-article-references__text" id="ref-CR26">Papadimitriou N (2015) How were they created? Materials and techniques of crafting ancient artefacts. A publication of the Museum of Cycladic Art. ISBN: 978-618-5060-12-1 (In Greek)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pescarin S, Pietroni E, Rescic L, Wallergård M, Omar K, Rufa C (2013) NICH: a preliminary theoretical study on" /><p class="c-article-references__text" id="ref-CR27">Pescarin S, Pietroni E, Rescic L, Wallergård M, Omar K, Rufa C (2013) NICH: a preliminary theoretical study on Natural Interaction applied to Cultural Heritage contexts. In: Digital heritage international congress 2013, vol 1, pp 355–362. IEEE</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="E. Pietroni, A. Adami, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Pietroni E, Adami A (2014) Interacting with virtual reconstructions in museums: the Etruscanning Project. J Co" /><p class="c-article-references__text" id="ref-CR28">Pietroni E, Adami A (2014) Interacting with virtual reconstructions in museums: the Etruscanning Project. J Comput Cult Herit 7(2):9</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F2611375" aria-label="View reference 28">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Interacting%20with%20virtual%20reconstructions%20in%20museums%3A%20the%20Etruscanning%20Project&amp;journal=J%20Comput%20Cult%20Herit&amp;volume=7&amp;issue=2&amp;publication_year=2014&amp;author=Pietroni%2CE&amp;author=Adami%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Prazina I, Balic K, Prses K, Rizvic S, Okanovic V (2016) Interaction with virtual objects in a natural way. In" /><p class="c-article-references__text" id="ref-CR42">Prazina I, Balic K, Prses K, Rizvic S, Okanovic V (2016) Interaction with virtual objects in a natural way. In: 39th international convention on information and communication technology, electronics and microelectronics (MIPRO) 2016, Opatija, Croatia, May 30–June 3, 2016. IEEE, pp 358–361</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ramani K, Lee Jr K, Jasti R (2014) zPots: a virtual pottery experience with spatial interactions using the lea" /><p class="c-article-references__text" id="ref-CR29">Ramani K, Lee Jr K, Jasti R (2014) zPots: a virtual pottery experience with spatial interactions using the leap motion device. In: CHI’14 extended abstracts on human factors in computing systems. ACM</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JC. Read, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Read JC (2008) Validating the Fun Toolkit: an instrument for measuring children’s opinions of technology. Cogn" /><p class="c-article-references__text" id="ref-CR30">Read JC (2008) Validating the Fun Toolkit: an instrument for measuring children’s opinions of technology. Cogn Technol Work 10(2):119–128</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10111-007-0069-9" aria-label="View reference 31">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Validating%20the%20Fun%20Toolkit%3A%20an%20instrument%20for%20measuring%20children%E2%80%99s%20opinions%20of%20technology&amp;journal=Cogn%20Technol%20Work&amp;volume=10&amp;issue=2&amp;pages=119-128&amp;publication_year=2008&amp;author=Read%2CJC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RS. Renner, BM. Velichkovsky, JR. Helmert, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Renner RS, Velichkovsky BM, Helmert JR (2013) The perception of egocentric distances in virtual environments-a" /><p class="c-article-references__text" id="ref-CR31">Renner RS, Velichkovsky BM, Helmert JR (2013) The perception of egocentric distances in virtual environments-a review. ACM Comput Surv (CSUR) 46(2):23</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F2543581.2543590" aria-label="View reference 32">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20perception%20of%20egocentric%20distances%20in%20virtual%20environments-a%20review&amp;journal=ACM%20Comput%20Surv%20%28CSUR%29&amp;volume=46&amp;issue=2&amp;publication_year=2013&amp;author=Renner%2CRS&amp;author=Velichkovsky%2CBM&amp;author=Helmert%2CJR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="S. Robertson, B. Jones, T. O’Quinn, P. Presti, J. Wilson, M. Gandy, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Robertson S, Jones B, O’Quinn T, Presti P, Wilson J, Gandy M (2009) Multiuser collaborative exploration of imm" /><p class="c-article-references__text" id="ref-CR32">Robertson S, Jones B, O’Quinn T, Presti P, Wilson J, Gandy M (2009) Multiuser collaborative exploration of immersive photorealistic virtual environments in public spaces. International conference on virtual and mixed reality. Springer, Berlin, pp 235–243</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=International%20conference%20on%20virtual%20and%20mixed%20reality&amp;pages=235-243&amp;publication_year=2009&amp;author=Robertson%2CS&amp;author=Jones%2CB&amp;author=O%E2%80%99Quinn%2CT&amp;author=Presti%2CP&amp;author=Wilson%2CJ&amp;author=Gandy%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Sederberg, S. Parry, " /><meta itemprop="datePublished" content="1986" /><meta itemprop="headline" content="Sederberg T, Parry S (1986) Free-form deformation of solid geometric models. ACM SIGGRAPH Comput Graph 20(4):1" /><p class="c-article-references__text" id="ref-CR33">Sederberg T, Parry S (1986) Free-form deformation of solid geometric models. ACM SIGGRAPH Comput Graph 20(4):151–160</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F15886.15903" aria-label="View reference 34">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Free-form%20deformation%20of%20solid%20geometric%20models&amp;journal=ACM%20SIGGRAPH%20Comput%20Graph&amp;volume=20&amp;issue=4&amp;pages=151-160&amp;publication_year=1986&amp;author=Sederberg%2CT&amp;author=Parry%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sheng J, Balakrishnan R, Singh K (2006) An interface for virtual 3D sculpting via physical proxy. GRAPHITE 6" /><p class="c-article-references__text" id="ref-CR34">Sheng J, Balakrishnan R, Singh K (2006) An interface for virtual 3D sculpting via physical proxy. GRAPHITE 6</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Van Eck W, Kolstee Y (2012) The augmented painting: playful interaction with multi-spectral images. In: 2012 I" /><p class="c-article-references__text" id="ref-CR35">Van Eck W, Kolstee Y (2012) The augmented painting: playful interaction with multi-spectral images. In: 2012 IEEE international symposium on mixed and augmented reality-arts, media, and humanities (ISMAR-AMH), pp 65–69. IEEE</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Von Hardenberg C, Bérard F (2001) Bare-hand human–computer interaction. In: Proceedings of the 2001 workshop o" /><p class="c-article-references__text" id="ref-CR36">Von Hardenberg C, Bérard F (2001) Bare-hand human–computer interaction. In: Proceedings of the 2001 workshop on perceptive user interfaces. pp 1–8. ACM</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Vosinakis S, Xenakis I (2011) A virtual world installation in an art exhibition: providing a shared interactio" /><p class="c-article-references__text" id="ref-CR37">Vosinakis S, Xenakis I (2011) A virtual world installation in an art exhibition: providing a shared interaction space for local and remote visitors. In: Rethinking technology in Museums 2011</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Vosinakis S, Koutsabasis P, Makris D, Sagia E (2016) A kinesthetic approach to digital heritage using leap mot" /><p class="c-article-references__text" id="ref-CR38">Vosinakis S, Koutsabasis P, Makris D, Sagia E (2016) A kinesthetic approach to digital heritage using leap motion: the Cycladic sculpture application. In: 8th International conference on games and virtual worlds for serious applications (VS-GAMES), Barcelona. IEEE</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="CS. Wang, DJ. Chiang, YC. Wei, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Wang CS, Chiang DJ, Wei YC (2013) Intuitional 3D museum navigation system using Kinect. Information technology" /><p class="c-article-references__text" id="ref-CR39">Wang CS, Chiang DJ, Wei YC (2013) Intuitional 3D museum navigation system using Kinect. Information technology convergence. Springer, Dordrecht, pp 587–596</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 40 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Information%20technology%20convergence&amp;pages=587-596&amp;publication_year=2013&amp;author=Wang%2CCS&amp;author=Chiang%2CDJ&amp;author=Wei%2CYC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Wong, R. Lau, L. Ma, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Wong J, Lau R, Ma L (2000) Virtual 3d sculpting. J Vis Comput Anim 11(3):155–166" /><p class="c-article-references__text" id="ref-CR40">Wong J, Lau R, Ma L (2000) Virtual 3d sculpting. J Vis Comput Anim 11(3):155–166</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2F1099-1778%28200007%2911%3A3%3C155%3A%3AAID-VIS225%3E3.0.CO%3B2-7" aria-label="View reference 41">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 41 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%203d%20sculpting&amp;journal=J%20Vis%20Comput%20Anim&amp;volume=11&amp;issue=3&amp;pages=155-166&amp;publication_year=2000&amp;author=Wong%2CJ&amp;author=Lau%2CR&amp;author=Ma%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Wyvill, TL. Kunii, " /><meta itemprop="datePublished" content="1985" /><meta itemprop="headline" content="Wyvill G, Kunii TL (1985) A functional model for constructive solid geometry. Vis Comput 1(1):3–14" /><p class="c-article-references__text" id="ref-CR41">Wyvill G, Kunii TL (1985) A functional model for constructive solid geometry. Vis Comput 1(1):3–14</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2FBF01901265" aria-label="View reference 42">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 42 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20functional%20model%20for%20constructive%20solid%20geometry&amp;journal=Vis%20Comput&amp;volume=1&amp;issue=1&amp;pages=3-14&amp;publication_year=1985&amp;author=Wyvill%2CG&amp;author=Kunii%2CTL">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-017-0325-0-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>We would like to thank Nikolas Papadimitriou curator of Antiquities at the Museum of Cycladic Art for the coordination of the event ‘Marble Yesterday and Today,’ as well as Yiannis Papadatos, Nondas Verieris and all other participants for the fruitful discussions onto the value of kinesthetic interactive applications for conveying tangible and intangible heritage.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Department of Product and Systems Design Engineering, Interactive Systems Design Lab, University of the Aegean, Ermoupolis, Greece</p><p class="c-article-author-affiliation__authors-list">Panayiotis Koutsabasis &amp; Spyros Vosinakis</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Panayiotis-Koutsabasis"><span class="c-article-authors-search__title u-h3 js-search-name">Panayiotis Koutsabasis</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Panayiotis+Koutsabasis&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Panayiotis+Koutsabasis" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Panayiotis+Koutsabasis%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Spyros-Vosinakis"><span class="c-article-authors-search__title u-h3 js-search-name">Spyros Vosinakis</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Spyros+Vosinakis&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Spyros+Vosinakis" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Spyros+Vosinakis%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-017-0325-0/email/correspondent/c1/new">Spyros Vosinakis</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Kinesthetic%20interactions%20in%20museums%3A%20conveying%20cultural%20heritage%20by%20making%20use%20of%20ancient%20tools%20and%20%28re-%29%20constructing%20artworks&amp;author=Panayiotis%20Koutsabasis%20et%20al&amp;contentID=10.1007%2Fs10055-017-0325-0&amp;publication=1359-4338&amp;publicationDate=2017-09-22&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-017-0325-0" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-017-0325-0" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Koutsabasis, P., Vosinakis, S. Kinesthetic interactions in museums: conveying cultural heritage by making use of ancient tools and (re-) constructing artworks.
                    <i>Virtual Reality</i> <b>22, </b>103–118 (2018). https://doi.org/10.1007/s10055-017-0325-0</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-017-0325-0.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-12-09">09 December 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2017-09-13">13 September 2017</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2017-09-22">22 September 2017</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-06">June 2018</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-017-0325-0" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-017-0325-0</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Cultural heritage</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Digital heritage</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Kinesthetic interaction</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Cycladic figurine</span></li><li class="c-article-subject-list__subject"><span itemprop="about">User experience</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Usability testing</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Field study</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Leap Motion</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-017-0325-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=325;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

