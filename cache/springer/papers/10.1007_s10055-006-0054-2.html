<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Virtual realia: maneuverable computer 3D models and their use in learn"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Two experiments compared real and virtual models as aids for learning assembly skills. In Experiment 1, ten participants individually studied either a fully assembled model, or a computer-generated..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/10/3.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Virtual realia: maneuverable computer 3D models and their use in learning assembly skills"/>

    <meta name="dc.source" content="Virtual Reality 2006 10:3"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2006-10-17"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2006 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Two experiments compared real and virtual models as aids for learning assembly skills. In Experiment 1, ten participants individually studied either a fully assembled model, or a computer-generated one, in exploded view, that could be spatially manipulated in any direction. Participants then assembled the object in front of a video camera. ANOVA indicated virtual model are studied significantly longer but yield faster assembly than a real model. Experiment 2 used the same treatments plus a fully assembled virtual mode, randomly assigned to 28 participants who studied the aid, assembled the model, and then repeated the task from memory 3&#160;days later. ANOVA indicated no differences between the three groups in assembly speed or accuracy. However, participants studied the exploded virtual model significantly longer than the two intact views of the model suggesting the former may impose a greater cognitive load due to the additional visual information it provides."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2006-10-17"/>

    <meta name="prism.volume" content="10"/>

    <meta name="prism.number" content="3"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="283"/>

    <meta name="prism.endingPage" content="292"/>

    <meta name="prism.copyright" content="2006 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-006-0054-2"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-006-0054-2"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-006-0054-2.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-006-0054-2"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Virtual realia: maneuverable computer 3D models and their use in learning assembly skills"/>

    <meta name="citation_volume" content="10"/>

    <meta name="citation_issue" content="3"/>

    <meta name="citation_publication_date" content="2006/12"/>

    <meta name="citation_online_date" content="2006/10/17"/>

    <meta name="citation_firstpage" content="283"/>

    <meta name="citation_lastpage" content="292"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-006-0054-2"/>

    <meta name="DOI" content="10.1007/s10055-006-0054-2"/>

    <meta name="citation_doi" content="10.1007/s10055-006-0054-2"/>

    <meta name="description" content="Two experiments compared real and virtual models as aids for learning assembly skills. In Experiment 1, ten participants individually studied either a full"/>

    <meta name="dc.creator" content="William A. Kealy"/>

    <meta name="dc.creator" content="Chitra P. Subramaniam"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Reality; citation_title=Evaluating the effectiveness of augmented reality displays for a manual assembly task; citation_author=KM Baird, W Barfield; citation_volume=4; citation_publication_date=1999; citation_pages=250-259; citation_doi=10.1007/BF01421808; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_journal_title=Cognit Instr; citation_title=Constructing virtual worlds: tracing the historical development of learner practices; citation_author=SA Barab, KE Hay, M Barnett, K Squire; citation_volume=19; citation_issue=1; citation_publication_date=2001; citation_pages=47-94; citation_doi=10.1207/S1532690XCI1901_2; citation_id=CR2"/>

    <meta name="citation_reference" content="citation_journal_title=Hum Factors Ergon Manuf; citation_title=Virtual assembly planning; citation_author=HJ Bullinger, M Richter, KA Seidel; citation_volume=10; citation_issue=3; citation_publication_date=2000; citation_pages=331-341; citation_doi=10.1002/1520-6564(200022)10:3&lt;331::AID-HFM7&gt;3.0.CO;2-D; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_journal_title=J Verbal Learn Verbal Behav; citation_title=Levels of processing: a framework for memory research; citation_author=F Craik, R Lockhart; citation_volume=11; citation_publication_date=1972; citation_pages=761-784; citation_doi=10.1016/S0022-5371(72)80001-X; citation_id=CR4"/>

    <meta name="citation_reference" content="Cycore (2005) Cult 3D. Retrieved from the World Wide Web at 
                    http://www.cult3d.com/
                    
                  
                "/>

    <meta name="citation_reference" content="citation_journal_title=Hum Factors Ergon Manuf; citation_title=Evaluation of visual display techniques for assembly sequence planning; citation_author=J Gerace, JJ Gallimore; citation_volume=11; citation_issue=3; citation_publication_date=2001; citation_pages=213-231; citation_doi=10.1002/hfm.1011; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Educ; citation_title=Who benefits from virtuality?; citation_author=B Harper, JG Hedberg, R Wright; citation_volume=34; citation_publication_date=2000; citation_pages=163-176; citation_doi=10.1016/S0360-1315(99)00043-3; citation_id=CR7"/>

    <meta name="citation_reference" content="Hoffman H, Groen J, Rousseau S, Hollander A, Winn W, Wells M, Furness T (1996) Tactile augmentation: enhancing presence in virtual reality with tactile feedback from real objects. In: Paper presented at the meeting of the American Psychological Society, San Francisco"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Hum Comput Interact; citation_title=Virtual chess: meaning enhances users&#8217; sense of presence in virtual environments; citation_author=HG Hoffman, J Prothero, MJ Wells, J Groen; citation_volume=10; citation_issue=3; citation_publication_date=1998; citation_pages=251-263; citation_doi=10.1207/s15327590ijhc1003_3; citation_id=CR9"/>

    <meta name="citation_reference" content="citation_journal_title=Assem Autom; citation_title=Preliminary investigation of virtual assembly constructing; citation_author=L Jiangsheng, Y Yingxue; citation_volume=24; citation_issue=4; citation_publication_date=2004; citation_pages=379-385; citation_doi=10.1108/01445150410562589; citation_id=CR10"/>

    <meta name="citation_reference" content="citation_title=Image and brain: the resolution of the imagery debate; citation_publication_date=1994; citation_id=CR11; citation_author=SM Kosslyn; citation_publisher=MIT Press"/>

    <meta name="citation_reference" content="citation_journal_title=Rev Educ Res; citation_title=Learning with media; citation_author=RB Kozma; citation_volume=61; citation_issue=2; citation_publication_date=1991; citation_pages=179-211; citation_doi=10.2307/1170534; citation_id=CR12"/>

    <meta name="citation_reference" content="citation_journal_title=IEICE Trans Inf Syst; citation_title=A taxonomy of mixed reality visual displays; citation_author=P Milgram, F Kishino; citation_volume=E77-D; citation_issue=12; citation_publication_date=1994; citation_pages=1321-1329; citation_id=CR13"/>

    <meta name="citation_reference" content="citation_journal_title=Learn Instr; citation_title=Cognitive processes and strategies employed by children to learn spatial representations; citation_author=H Pillay; citation_volume=8; citation_issue=1; citation_publication_date=1998; citation_pages=1-18; citation_doi=10.1016/S0959-4752(97)00030-3; citation_id=CR14"/>

    <meta name="citation_reference" content="citation_title=An anthropologist on Mars: seven paradoxical tales; citation_publication_date=1995; citation_id=CR15; citation_author=OW Sacks; citation_publisher=Knopf"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Virtual Environ; citation_title=Musings on telepresence and virtual presence; citation_author=TB Sheridan; citation_volume=1; citation_issue=1; citation_publication_date=1992; citation_pages=120-126; citation_id=CR16"/>

    <meta name="citation_reference" content="Sheridan TB (2000) Interaction, imagination and immersion: some research needs. In: Proceedings of the ACM symposium on virtual reality software and technology, Seoul"/>

    <meta name="citation_reference" content="citation_journal_title=J Commun; citation_title=Defining virtual reality: dimensions determining telepresence; citation_author=J Steuer; citation_volume=42; citation_issue=4; citation_publication_date=1992; citation_pages=73-93; citation_doi=10.1111/j.1460-2466.1992.tb00812.x; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Reality; citation_title=Two-handed assembly with immersive task planning in virtual reality; citation_author=H Sun, B Hujun; citation_volume=6; citation_publication_date=2002; citation_pages=11-20; citation_doi=10.1007/BF01408565; citation_id=CR19"/>

    <meta name="citation_reference" content="citation_journal_title=Cogn Sci; citation_title=Cognitive load during problem solving: effects on learning; citation_author=J Sweller; citation_volume=12; citation_publication_date=1988; citation_pages=257-285; citation_doi=10.1016/0364-0213(88)90023-7; citation_id=CR20"/>

    <meta name="citation_reference" content="citation_journal_title=J Exp Psychol Hum Percept Perform; citation_title=Attentional control within 3-D space; citation_author=J Theeuwes, P Atchley, AF Kramer; citation_volume=24; citation_issue=5; citation_publication_date=1998; citation_pages=1476-1485; citation_doi=10.1037/0096-1523.24.5.1476; citation_id=CR21"/>

    <meta name="citation_reference" content="Windschitl M, Winn W (2000) A virtual environment designed to help students understand science. In: Fishman B, O&#8217;Connor-Divelbiss C (eds) Fourth international conference of the learning sciences. Erlbaum, Mahwah"/>

    <meta name="citation_reference" content="citation_journal_title=Educ Psychol Rev; citation_title=Current trends in educational technology research: The study of learning environments; citation_author=W Winn; citation_volume=14; citation_issue=3; citation_publication_date=2002; citation_pages=331-351; citation_doi=10.1023/A:1016068530070; citation_id=CR23"/>

    <meta name="citation_reference" content="citation_journal_title=Assem Autom; citation_title=Training with virtual reality; citation_author=G Wittenberg; citation_volume=15; citation_issue=3; citation_publication_date=1995; citation_pages=12-14; citation_doi=10.1108/01445159510094570; citation_id=CR24"/>

    <meta name="citation_author" content="William A. Kealy"/>

    <meta name="citation_author_email" content="wkealy@coedu.usf.edu"/>

    <meta name="citation_author_institution" content="Instructional Technology Program, University of South Florida, Tampa, USA"/>

    <meta name="citation_author" content="Chitra P. Subramaniam"/>

    <meta name="citation_author_institution" content="Instructional Technology Program, University of South Florida, Tampa, USA"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-006-0054-2&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2006/12/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-006-0054-2"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Virtual realia: maneuverable computer 3D models and their use in learning assembly skills"/>
        <meta property="og:description" content="Two experiments compared real and virtual models as aids for learning assembly skills. In Experiment 1, ten participants individually studied either a fully assembled model, or a computer-generated one, in exploded view, that could be spatially manipulated in any direction. Participants then assembled the object in front of a video camera. ANOVA indicated virtual model are studied significantly longer but yield faster assembly than a real model. Experiment 2 used the same treatments plus a fully assembled virtual mode, randomly assigned to 28 participants who studied the aid, assembled the model, and then repeated the task from memory 3&amp;nbsp;days later. ANOVA indicated no differences between the three groups in assembly speed or accuracy. However, participants studied the exploded virtual model significantly longer than the two intact views of the model suggesting the former may impose a greater cognitive load due to the additional visual information it provides."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Virtual realia: maneuverable computer 3D models and their use in learning assembly skills | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-006-0054-2","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Virtual Reality, Real Model, Augmented Reality, Instructional Material, Virtual Object","kwrd":["Virtual_Reality","Real_Model","Augmented_Reality","Instructional_Material","Virtual_Object"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-006-0054-2","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-006-0054-2","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-b0018c9f69.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-c02f1b37f0.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=54;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-006-0054-2">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Virtual realia: maneuverable computer 3D models and their use in learning assembly skills
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-006-0054-2.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-006-0054-2.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2006-10-17" itemprop="datePublished">17 October 2006</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Virtual realia: maneuverable computer 3D models and their use in learning assembly skills</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-William_A_-Kealy" data-author-popup="auth-William_A_-Kealy" data-corresp-id="c1">William A. Kealy<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of South Florida" /><meta itemprop="address" content="grid.170693.a, 000000012353285X, Instructional Technology Program, University of South Florida, 4202 E. Fowler Avenue, EDU162, Tampa, FL, 33620-5650, USA" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Chitra_P_-Subramaniam" data-author-popup="auth-Chitra_P_-Subramaniam">Chitra P. Subramaniam</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of South Florida" /><meta itemprop="address" content="grid.170693.a, 000000012353285X, Instructional Technology Program, University of South Florida, 4202 E. Fowler Avenue, EDU162, Tampa, FL, 33620-5650, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 10</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">283</span>–<span itemprop="pageEnd">292</span>(<span data-test="article-publication-year">2006</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">129 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">3 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-006-0054-2/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Two experiments compared real and virtual models as aids for learning assembly skills. In Experiment 1, ten participants individually studied either a fully assembled model, or a computer-generated one, in exploded view, that could be spatially manipulated in any direction. Participants then assembled the object in front of a video camera. ANOVA indicated virtual model are studied significantly longer but yield faster assembly than a real model. Experiment 2 used the same treatments plus a fully assembled virtual mode, randomly assigned to 28 participants who studied the aid, assembled the model, and then repeated the task from memory 3 days later. ANOVA indicated no differences between the three groups in assembly speed or accuracy. However, participants studied the exploded virtual model significantly longer than the two intact views of the model suggesting the former may impose a greater cognitive load due to the additional visual information it provides.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Virtual realia: use of computer-based 3D displays for learning assembly skills</h2><div class="c-article-section__content" id="Sec1-content"><p>An important distinction that arose early issues in the history of virtual reality (VR) was how the notion of <i>presence</i> differed from that of <i>telepresence</i>. In the early 1990s, some used the term <i>presence</i> to describe the natural perception one has of being in an environment, whether virtual or real. On the other hand, <i>telepresence</i>, was considered a specialized instance of <i>presence</i> that dealt with teleoperation systems for remote manipulation or extended control of a distant environment (Sheridan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Sheridan TB (1992) Musings on telepresence and virtual presence. Presence Teleoperators Virtual Environ 1(1):120–126" href="/article/10.1007/s10055-006-0054-2#ref-CR16" id="ref-link-section-d40654e314">1992</a>). Examples of telepresence include systems for remotely handling dangerous substances such as radioactive material or the operation by a surgeon on a patient located hundreds of miles away. Other VR proponents, by contrast, held that <i>telepresence</i> referred to all situations in which the percipient experiences, in varying degrees, the mediated and real environment concurrently. Theoretically, then, the less one is aware that the experience is mediated, the more one approaches <i>presence</i> (Steuer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Steuer J (1992) Defining virtual reality: dimensions determining telepresence. J Commun 42(4):73–93" href="/article/10.1007/s10055-006-0054-2#ref-CR18" id="ref-link-section-d40654e323">1992</a>).</p><p>However, whether both actual, remotely telecommunicated environments and synthetically created (i.e., virtual) environments fall under the rubric of telepresence or presence, the former expression has generally fallen into disuse during the past decade. Some, in fact, define presence as the “sensation of going into a computer-simulated environment” that is synonymous with sensory immersion (Hoffman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Hoffman HG, Prothero J, Wells MJ, Groen J (1998) Virtual chess: meaning enhances users’ sense of presence in virtual environments. Int J Hum Comput Interact 10(3):251–263" href="/article/10.1007/s10055-006-0054-2#ref-CR9" id="ref-link-section-d40654e329">1998</a>). At the same time, there has been greater attention by educational researchers on environments that are high in “virtuality” or degree of immersion that the experience affords (Harper et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Harper B, Hedberg JG, Wright R (2000) Who benefits from virtuality? Comput Educ 34:163–176" href="/article/10.1007/s10055-006-0054-2#ref-CR7" id="ref-link-section-d40654e332">2000</a>; Windschitl and Winn <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Windschitl M, Winn W (2000) A virtual environment designed to help students understand science. In: Fishman B, O’Connor-Divelbiss C (eds) Fourth international conference of the learning sciences. Erlbaum, Mahwah" href="/article/10.1007/s10055-006-0054-2#ref-CR22" id="ref-link-section-d40654e335">2000</a>; Barab et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Barab SA, Hay KE, Barnett M, Squire K (2001) Constructing virtual worlds: tracing the historical development of learner practices. Cognit Instr 19(1):47–94" href="/article/10.1007/s10055-006-0054-2#ref-CR2" id="ref-link-section-d40654e338">2001</a>).</p><p>This research focuses instead on learning with remotely controlled computer-generated objects in place of actual objects. Since, real objects or specimens fall under a venerable class of educational media known as “realia,” we use the term <i>virtual realia</i> (Vr) in this report in referring to synthetic objects than can be manipulated and inspected remotely. In particular, this report explores the effectiveness of Vr for learning assembly skills at a distance. We first discuss the similarities and differences between virtual environments (i.e., VR) and Vr in terms of immersion, purpose, and the position of viewers relative to what they perceive. Next, we make an argument for the need for research with Vr to understand its cognitive capacities with respect the potential for improving assembly performance. Finally, we report on two experiments that compare the efficacy of a Vr model and a real model for performing and learning a simple assembly task.</p><h3 class="c-article__sub-heading" id="Sec2">Virtual realia defined</h3><p>Current computer technology allows the spatial manipulation of computer-generated objects shown on a computer monitor through mouse movement and operation. These Vr objects are vector-based images that one can rotate, zoom, and pan (with six degrees of freedom) when viewed on a computer display using a web browser or a variety of software applications (e.g., Microsoft Word, PowerPoint, Adobe Acrobat). The particular Vr technology used in this study was Cult3D, a free software “plug-in” developed in 1996 by Cycore (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Cycore (2005) Cult 3D. Retrieved from the World Wide Web at &#xA;                    http://www.cult3d.com/&#xA;                    &#xA;                  &#xA;                " href="/article/10.1007/s10055-006-0054-2#ref-CR5" id="ref-link-section-d40654e354">2005</a>), which also has the capability for creating “walkthrough” virtual environments. Creation of Vr objects is a three-step process whereby one first renders the object using a 3D modeling program such as 3D Studio Max, Maya, Viz, or Plasma. The completed model is then imported into the free Cult3D Designer program, which is used to create the virtual environment and specify, among other things, the viewer’s perspective relative to the computer-generated objects, degrees of freedom of movement, ambient lighting, and Newtonian physics (e.g., objects moved may or may not continue in motion). The final step involves importing the completed Cult3D object into a Microsoft Office or Adobe Acrobat document. Installation of the Cult3D plug-in allows one to view and manipulate the Vr object by simply opening the document with the application that created it.</p><p>Virtual realia shares many of the same characteristics as VR, while in other ways the two experiences differ substantially. Vr displays, for example, simulate the experiences of manipulating a real object but without the need for the immersive environment characteristic of VR. Following the Extent of Presence Metaphor dimension of Milgram and Kishino’s (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Milgram P, Kishino F (1994) A taxonomy of mixed reality visual displays. IEICE Trans Inf Syst E77-D(12):1321–1329" href="/article/10.1007/s10055-006-0054-2#ref-CR13" id="ref-link-section-d40654e360">1994</a>) “virtuality continuum,” Vr is essentially a window-on-the-world with a fixed monoscopic viewpoint; changes in the viewer’s head position do not result in different perspectives of the object. Immersive virtual environments, by comparison, lie at the other end of the spectrum and permit looking around an object by moving one’s head position. Therefore, a fundamental difference between Vr and VR is that the latter is a true 3D representation that may be either viewer or object-centered while the latter is exclusively viewer-centered (Kosslyn <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Kosslyn SM (1994) Image and brain: the resolution of the imagery debate. MIT Press, Cambridge" href="/article/10.1007/s10055-006-0054-2#ref-CR11" id="ref-link-section-d40654e363">1994</a>). In other words, changes in the relative positions of a 2D object’s components result from shifts in the viewer’s perspective. The same may be true for objects viewed in a three dimensional environment, whether real or virtual. However, in such an environment, an object may also appear to change shape (e.g., through foreshortening), not due to an altered position of the viewer, but because the object itself has moved to a different position.</p><p>Both Vr and VR are vector images, thereby allowing almost limitless visual acuity whether one, respectively, drags an object up to the picture plane of a display or “walks” to it. This common attribute, in which closer scrutiny of an object or scene yields potentially greater detail, is an important factor in the capacity of Vr and VR for motivating exploration and discovery. The capacity for altering the viewer’s experience of scale relative to that of a given object, however, is probably more difficult to accomplish in Vr than VR. An extremely zoomed in view of a virtual object, such as a tree for instance, would appear to be merely a tree at close inspection, not a giant one.</p><p>Reproduction fidelity, or the degree to which “the synthesizing display is able to reproduce the actual or intended images of the objects being displayed,” (Milgram and Kishino <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Milgram P, Kishino F (1994) A taxonomy of mixed reality visual displays. IEICE Trans Inf Syst E77-D(12):1321–1329" href="/article/10.1007/s10055-006-0054-2#ref-CR13" id="ref-link-section-d40654e371">1994</a>) is determined by both the number of senses employed (i.e., breadth) and the resolution or fidelity (i.e., depth) of each one used (Steuer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Steuer J (1992) Defining virtual reality: dimensions determining telepresence. J Commun 42(4):73–93" href="/article/10.1007/s10055-006-0054-2#ref-CR18" id="ref-link-section-d40654e374">1992</a>). Because, sensory breadth contributes more than sensory depth to the experience of presence, it follows that reproduction fidelity is easier to achieve in Vr versus VR, yet more critical to the success of the latter. In VR, sensory breadth enhances the experience of immersion and aids percipients in suppressing disbelief (Sheridan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Sheridan TB (2000) Interaction, imagination and immersion: some research needs. In: Proceedings of the ACM symposium on virtual reality software and technology, Seoul" href="/article/10.1007/s10055-006-0054-2#ref-CR17" id="ref-link-section-d40654e377">2000</a>) in their experience of “being there.” In the case of Vr, on the other hand, there is less to gain from immersion, primarily because the purpose for which it is designed differs from that of VR. Virtual realia is intended to facilitate the inspection of a real object through spatial manipulation of a surrogate and, in that sense, serves as a discovery tool. Virtual reality, by comparison, facilitates discovery and change in conceptual understanding through movement and action within an artificial environment.</p><h3 class="c-article__sub-heading" id="Sec3">Assembly performance and Vr</h3><p>Use of VR for learning how to assemble a given set of components is an intuitively appealing idea since it theoretically holds the potential for acquiring such skills at a distance and in a way that may be more experiential and authentic than from technical manuals, drawings, and photographs. Currently, however, most applications of VR related to assembly performance have dealt not with assembly skills, but assembly planning, where input devices such as data gloves and eye tracking mechanisms record motor movements for later analysis (Bullinger et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Bullinger HJ, Richter M, Seidel KA (2000) Virtual assembly planning. Hum Factors Ergon Manuf 10(3):331–341" href="/article/10.1007/s10055-006-0054-2#ref-CR3" id="ref-link-section-d40654e389">2000</a>; Gerace and Gallimore <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Gerace J, Gallimore JJ (2001) Evaluation of visual display techniques for assembly sequence planning. Hum Factors Ergon Manuf 11(3):213–231" href="/article/10.1007/s10055-006-0054-2#ref-CR6" id="ref-link-section-d40654e392">2001</a>; Sun and Hujun <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Sun H, Hujun B (2002) Two-handed assembly with immersive task planning in virtual reality. Virtual Reality 6:11–20" href="/article/10.1007/s10055-006-0054-2#ref-CR19" id="ref-link-section-d40654e395">2002</a>; Jiangsheng and Yingxue <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Jiangsheng L, Yingxue Y (2004) Preliminary investigation of virtual assembly constructing. Assem Autom 24(4):379–385" href="/article/10.1007/s10055-006-0054-2#ref-CR10" id="ref-link-section-d40654e398">2004</a>). Though not an example of assembly training, per se, a study by Wittenberg (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Wittenberg G (1995) Training with virtual reality. Assem Autom 15(3):12–14" href="/article/10.1007/s10055-006-0054-2#ref-CR24" id="ref-link-section-d40654e401">1995</a>), showed that use of either immersive or augmented VR for learning the operation of a robotic assembly line produced results that were comparable to those trained in a physical lab setting. One reason that there is scant research on learning assembly skills with VR is that the technology necessary for providing trainees with virtual objects capable of manipulation and assembly in a virtual space has not yet arrived. One solution to this problem has been to bypass the use of full immersion VR entirely and, instead, explore the use of “mixed reality” displays (Milgram and Kishino <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Milgram P, Kishino F (1994) A taxonomy of mixed reality visual displays. IEICE Trans Inf Syst E77-D(12):1321–1329" href="/article/10.1007/s10055-006-0054-2#ref-CR13" id="ref-link-section-d40654e405">1994</a>). One example of this is “augmented reality” whereby an assembly task is performed while instructions and job aids are viewed in the same spatial location as the object to be assembled. In a study using this approach, Baird and Barfield (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Baird KM, Barfield W (1999) Evaluating the effectiveness of augmented reality displays for a manual assembly task. Virtual Reality 4:250–259" href="/article/10.1007/s10055-006-0054-2#ref-CR1" id="ref-link-section-d40654e408">1999</a>) found augmented reality yielded faster and more accurate assembly of a motherboard than either a 5-page illustrated manual or the same information presented in a CAI program. However, in this case the CAI consisted of a linear PowerPoint presentation and not exemplary of CAI with characteristically high interactivity. Further, the reported outcome dealt with assembly performance, not assembly learning. This raises the important issue of whether it is more profitable to use VR technologies for performance improvement or skill acquisition. In some circumstances, use of VR as a permanent performance support system in the workplace may produce a smaller ROI than employing a more technologically modest form of VR that trainees use as a scaffold for learning performance skills. We adopted the latter view in exploring the feasibility in using a low-cost virtual model as a job aid for learning an assembly skill.</p><p>The speculation that Vr models can serve as effective tools for learning assembly tasks is based on evidence that assembly performance is enhanced by prior study of a real model of the completed construction. In an experiment by Pillay (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Pillay H (1998) Cognitive processes and strategies employed by children to learn spatial representations. Learn Instr 8(1):1–18" href="/article/10.1007/s10055-006-0054-2#ref-CR14" id="ref-link-section-d40654e414">1998</a>), children individually assembled an abstract object using pieces from a Meccano set after studying one of four types of representations of the completed construction: an orthographic drawing, an exploded isometric drawing, the actual completed model, or both isometric drawing and model. Results showed participants who studied a model before trying to assemble it, both immediately and 3 days later, made significantly more correct assemblies of parts, in less time, and with fewer additional looks than those using either an orthographic or an isometric drawing. Those studying a real model of the completed assembly could build a mental model by directly encoding spatial information. By contrast, those with drawings had to first translate two-dimensional aids into a three dimensional mental representation, thereby incurring a greater cognitive load (Sweller <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Sweller J (1988) Cognitive load during problem solving: effects on learning. Cogn Sci 12:257–285" href="/article/10.1007/s10055-006-0054-2#ref-CR20" id="ref-link-section-d40654e417">1988</a>) during the task that left fewer mental resources available for learning.</p><p>At first glance, there should be little difference between the efficacy of real and virtual model for learning an assembly task. Nevertheless, the two representations differ in three potentially important ways. One is that, as mentioned earlier, Vr models offer greater visual acuity than real models. Practical limits exist in how physically close one can visually scrutinize the details of a real model before they become blurry whereas the vector images of virtual models are always sharply defined. Conceivably, this reflects a cognitive capacity (Kozma <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Kozma RB (1991) Learning with media. Rev Educ Res 61(2):179–211" href="/article/10.1007/s10055-006-0054-2#ref-CR12" id="ref-link-section-d40654e423">1991</a>) among Vr models that distinguished them from real models since the potential of the former for closer inspection could manifest itself in deeper mental processing (Craik and Lockhart <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1972" title="Craik F, Lockhart R (1972) Levels of processing: a framework for memory research. J Verbal Learn Verbal Behav 11:761–784" href="/article/10.1007/s10055-006-0054-2#ref-CR4" id="ref-link-section-d40654e426">1972</a>).</p><p>A second way that Vr models differ from real ones is in the tactile information the latter provide as they are handled and examined. Little is currently known about the contribution that the sense of touch makes to learning from visual media. Nevertheless, the critical yet underestimated relationship between vision and touch is underscored by neurologist Oliver Sacks (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Sacks OW (1995) An anthropologist on Mars: seven paradoxical tales. Knopf, New York" href="/article/10.1007/s10055-006-0054-2#ref-CR15" id="ref-link-section-d40654e432">1995</a>) in his report of a man who regained sight after roughly five decades of blindness and experienced enormous difficulties in reconciling visual and tactile information. Ironically, although haptics appeared long before the other senses in the evolution of creatures, the technology for virtually representing touch has lagged behind that of vision and hearing (Sheridan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Sheridan TB (2000) Interaction, imagination and immersion: some research needs. In: Proceedings of the ACM symposium on virtual reality software and technology, Seoul" href="/article/10.1007/s10055-006-0054-2#ref-CR17" id="ref-link-section-d40654e435">2000</a>). One attempt to overcome this technological hurdle has been the use of a “tactile augmentation” strategy whereby persons grasp virtual objects with a virtual hand while simultaneously touching a real object with the free hand. In one study, tactile augmentation was compared with attempts to touch the same virtual objects without accompanying tactile input. Participants experiencing VR with tactile augmentation gave significantly higher ratings of presence than those experienced VR alone (Hoffman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Hoffman H, Groen J, Rousseau S, Hollander A, Winn W, Wells M, Furness T (1996) Tactile augmentation: enhancing presence in virtual reality with tactile feedback from real objects. In: Paper presented at the meeting of the American Psychological Society, San Francisco" href="/article/10.1007/s10055-006-0054-2#ref-CR8" id="ref-link-section-d40654e438">1996</a>).</p><p>Finally, we speculated that an exploded view of a Vr model would provide a cognitive capacity heretofore unrealized with the possible exception of encasing the exploded components in a clear medium such as plastic or glass. Exploded views are generally helpful because they clearly show the articulation of components through connecting dashed lines. Yet, this type of depiction may be detrimental in a dynamic 3D environment since the simultaneous visibility of foreground and background components would likely increase cognitive load. In support of this view, research shows that planes at different depths disrupt attention to a specific depth plane when components at each depth are of the same color, which is the case with the Vr model used in the study (Theeuwes et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Theeuwes J, Atchley P, Kramer AF (1998) Attentional control within 3-D space. J Exp Psychol Hum Percept Perform 24(5):1476–1485" href="/article/10.1007/s10055-006-0054-2#ref-CR21" id="ref-link-section-d40654e445">1998</a>). Hence, an important goal of our inquiry was to follow Winn’s (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Winn W (2002) Current trends in educational technology research: The study of learning environments. Educ Psychol Rev 14(3):331–351" href="/article/10.1007/s10055-006-0054-2#ref-CR23" id="ref-link-section-d40654e448">2002</a>) recommendation for researchers to study the characteristics of virtual environments that help or hinder learning.</p></div></div></section><section aria-labelledby="Sec4"><div class="c-article-section" id="Sec4-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec4">Experiment 1</h2><div class="c-article-section__content" id="Sec4-content"><h3 class="c-article__sub-heading" id="Sec5">Method</h3><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec6">Design and subjects</h4><p>The base design for the study was a posttest-only between groups comparison with random assignment of participants to either study a real model (RM) or a virtual realia (Vr) display prior to an assembly task. Ten female undergraduate education majors enrolled in an instructional technology course participated in the study, earning extra credit towards the course grade for their participation.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec7">Materials</h4>
                    <h3 class="c-article__sub-heading">Real model</h3>
                    <p>After locating a Meccano dealer, we obtained the identical pieces used in Pillay’s (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Pillay H (1998) Cognitive processes and strategies employed by children to learn spatial representations. Learn Instr 8(1):1–18" href="/article/10.1007/s10055-006-0054-2#ref-CR14" id="ref-link-section-d40654e479">1998</a>) study: 12 metal plates, 12 bolts, and 12 nuts; all materials were made of a silver-colored metal except for the brass nuts and the largest of the plates, measuring 3″ × 1.5″, that was painted bright yellow. We purchased two sets of these materials, one to build a fully-assembled model (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0054-2#Fig1">1</a>) that served as the study display for the RM treatment and a second set for use by all participants in completing the assembly task. By using the same materials as Pillay, we reasoned, the results from this study could serve as a benchmark for comparing data from the current investigation.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0054-2/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0054-2/MediaObjects/10055_2006_54_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0054-2/MediaObjects/10055_2006_54_Fig1_HTML.jpg" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>The real model of the completed Meccano assembly</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0054-2/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                    
                  
                    <h3 class="c-article__sub-heading">Virtual model</h3>
                    <p>Using the real model as a guide, we developed a 3D computer model using AutoDesk 3D Studio Max program. The completed rendering depicted the model in the same exploded view as the isometric drawing from Pillay’s experiment. Using this rendering, we then built the virtual model with Cycore Cult3D Designer, exporting the completed file into a simple HTML program for display in a Netscape browser. Finally, the HTML file was installed on a Dell Latitude laptop computer with a Pentium III 750 MHz processor, 256 MB of RAM, and a 15″ diagonal viewing area set to 800 × 600 dpi resolution. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0054-2#Fig2">2</a> shows the finished display.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0054-2/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0054-2/MediaObjects/10055_2006_54_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0054-2/MediaObjects/10055_2006_54_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>The virtual model (Vr) display in exploded view</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0054-2/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                    
                  <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec8">Procedures</h4><p>Participation in the study spanned a two-week period; those arriving for the study in the first week were assigned to the model condition while those in the second week received the Vr treatment. Experimental sessions were held in a college office containing a conference table and a few chairs. Upon arrival at a scheduled session, a participant sat at the conference table with a second small card table located adjacent to the right. For those in the RM condition, a white unmarked shoebox, placed approximately 18″ in front of them, covered the model. Instead of the shoebox, those in the Vr condition saw an opened laptop computer in the same position showing a blank screen. In both conditions, a six-inch clear plastic bowl, placed in the center of the small adjacent table, contained all the pieces required for the assembly task. To the right of the bowl was placed a quarter-inch crescent wrench and a small flat-bladed screwdriver. A video camera placed 45° to the side of the front table ran continuously during each experimental session to record participants’ study and assembly behavior.</p><p>Each participant was given an overview of the task to be performed and told that the model to be assembled bore no resemblance to a real-world object. The participant was also informed that all the pieces needed to complete the assembly task were located in the plastic bowl and that there was no deception or trick involved. All participants were told that, following a 2-min period to become familiar with the tools and parts they would be using, they would be allowed to study a job aid that would assist them in assembling the object. The experimenter told participants they could study this aid for as long as desired. However, once they indicated they had studied enough and were ready to start assembling the model, the job aid would not be available for viewing. Additional looks at this information, nevertheless, could be requested if they found themselves at a point where they were unable to complete the task. Finally, the experimenter informed participants that the video camera only focused on their hand movements and that they could not be personally identified on the recorded videotape.</p><p>Following the overview, participants in the Vr condition were shown an example of a Cult3D display on the laptop—a simple block of metal with drilled holes that appeared distinctively different from the Meccano model. With this model, participants learned how to work the mouse to spatially manipulate an object shown and practiced using the technology. The instructional segment lasted about 1 min with 4 min allotted for practice time. After this period, participants in the Vr condition, like those in the model group, familiarized themselves with the Meccano parts and tools for 2 min. During this time, the experimenter loaded the Cult3D rendering of the Meccano model on the laptop. Once the tool familiarization phase was over, participants returned all disassembled parts to the bowl and rotated their chair to face the hidden job aid. Either the experimenter then lifted the shoebox to reveal the fully assembled model to those in the RM condition or, in the case of the Vr condition, moved the mouse to close the screen saver and present the Vr display. Once participants indicated they were ready to begin the assembly task, the job aid was again hidden from sight.</p><p>Participants then began the assembly task and were permitted an additional look at the instructional material only after being granted permission by the experimenter. At no time was a participant allowed to concurrently view the job aid and perform the assembly task or compare their progress to the completed real or virtual model. Once participants stated that the assembly task was finished, they were instructed to rate, from one to ten, the difficulty of the task, with ten representing the greatest difficulty.</p><p>All participants completed the experimental session in less than one hour.</p><h3 class="c-article__sub-heading" id="Sec9">Results and discussion</h3><p>Following each session, we examined the completed assembly, counting the number of parts that were correctly connected (maximum possible was 14 connections). Additionally, we viewed the videotapes of the constructions by participants to identify: (1) total time spent studying the instructional material prior to beginning the assembly task; (2) the frequency of remedial looks at the instructional material; (3) total time spent on remedial looks; (4) number of correct assemblies; (5) total time used to complete the assembly task; and (6) any special strategies used by participants to complete the task. Following the calculation of descriptive statistics, all data were entered into separate one-way ANOVAs with an alpha of 0.05 assumed for all tests of significance.</p><p>As Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-006-0054-2#Tab1">1</a> shows, participants in the Vr condition spent approximately three times longer examining their instructional material before beginning model assembly compared to those viewing a real model. Further, time on the task by the Vr group was roughly half of that exhibited by those who studied a completed model. ANOVA of the data confirmed that participants studied virtual models significantly longer, <i>F</i>(l, 9) = 23.49, <i>P</i> &lt; 0.01, than real models. Additionally, participants in the Vr condition took significantly less time, <i>F</i>(1, 9) = 8.89, <i>P</i> = 0.02, to complete the task. None of the other between-group comparisons reached significance.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Assembly task performance following study of either a real or a virtual model</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-006-0054-2/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Although these results are tentative given the small sample sizes involved, they are nonetheless encouraging. The fact that participants viewing virtual models examined their materials significantly longer than those who studied a real model suggests Vr displays demand greater “mindfulness” than the use of real models. One explanation for this is that greater concentration and attentiveness was required to spatially manipulate Vr displays compared to real models. This might have produced heightened processing attention among those with computer displays, thereby explaining the much shorter time this group needed to complete the assembly task. Alternatively, the attention allocation differences between the Vr treatment and the real model might have been due to a novelty effect. This thesis is discounted, however, by the fact that participants appeared to rapidly develop skill in manipulating the 3D image, often saying they were ready long before the 4-min practice phase was over. Further, none of the participants expressed amazement or even curiosity about the 3D technology.</p><p>One unexpected outcome of the study was that all of the Vr participants presented their completed model as a two-part assembly. Examination of the Vr display revealed that the rendering was incorrect and that a dashed line connecting the disc-shaped plate to the rest of the model had been omitted. While this error clearly influenced assembly performance, it seems unlikely that its effect on either overall study time or total time of assembly was significant. On the other hand, it suggests that those using Vr displays are very attentive to small details in the models depicted. This speculation is also supported by the fact that all Vr participants remembered to insert two washers in their proper places whereas those in the real model condition frequently omitted such details in their assemblies.</p></div></div></section><section aria-labelledby="Sec10"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Experiment 2</h2><div class="c-article-section__content" id="Sec10-content"><p>In addition to the small sample size and erroneous display, we identified an additional problem in the aforementioned study: the Vr display consisted of an exploded view while the real model showed the target construction in a fully assembled state. Hence, performance based on differences in the mode of presentation, Vr or RM, was confounded by variations in display format—assembled versus exploded. Our second experiment addressed these shortcomings. We also designed this study to determine how well participants could perform the assembly task from memory 3 days after their initial performance. In Pillay’s experiment, participants in Trial 2 repeated all phases performed in Trial 1 including pre-assembly study of instructional displays. By contrast, the current study required participants to assemble the object in Trial 2 entirely from what they had learned in Trial 1. This, we believed, would provide evidence on the amount of cognitive load encountered during the study phase of the experiment, especially by those viewing an exploded Vr display.</p><p>Another important aim of this study was to determine whether viewing an exploded view of a virtual model adds or detracts from assembly performance. On the one hand, such a display (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0054-2#Fig2">2</a>) might increase one’s assembly performance compared to a Vr display of the same object, but fully assembled, because the former clearly articulates how model components are connected better than even the real model itself. On the other hand, it could be argued that an exploded view decreases performance because one is able to view through open spaces created by the separated parts to perceive spatial relationships occurring at the front and back of the model simultaneously. It is feasible that such displays could provide viewers with too much information.</p><h3 class="c-article__sub-heading" id="Sec11">Method</h3><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec12">Design</h4><p>The study involved contrasting three types of instructional aids—a real model (RM), a virtual model fully assembled (Vr-A), and a virtual model in exploded view (Vr-E)—for performing the same assembly task twice with a 3-day interval between assemblies. Hence, the experimental design was a 3 Display (RM vs. Vr-A vs. Vr-E) × 2 Trial mixed factorial design where display was varied between participants and trial served as a repeated measure. Criterion measures on both trials included time required to complete the assembly task and the number of correct connections made in the completed assembly. Additional dependent measures collected during Trial 1 included the amount of pre-assembly study time and the number of additional looks at the stimulus display requested by participants during the assembly task.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec13">Subjects</h4><p>Participants in the study consisted of 28 lower-division undergraduates who participated individually in the study. With the exception of four participants, all were education majors recruited from several different classes. Participants were randomly assigned to the three treatment conditions in the following proportions: nine persons (six females and three males) to the RM condition, ten (seven females and three males) to the Vr-A treatment, and nine (seven females and two males) to the Vr-E group. Randomization was achieved by alternating the experimental condition that was set up independent of the sign up sheet used by participants to schedule themselves for a session. In this way, each of the three treatments had the same chance of being used at different times of the day without regard to what participant was scheduled to participate at a given time.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec14">Materials</h4><p>Both the real model and exploded virtual model in Experiment 1 were used for the RM and Vr-E treatments, respectively, in the present study. For the Vr-A treatment, we created an additional display depicting all the Meccano pieces in a fully assembled state. For each of the Vr displays, we created a one-slide PowerPoint program for presenting the information during the experiment. We installed these files on the same laptop computer used in Experiment 1. In this study, however, we attached a black cardboard rectangle to the top edge of the screen with two pieces of tape so that, when flipped over, it covered the entire screen area.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec15">Procedures</h4><p>Research sessions were held in the same windowless college office used in the previous study. Our procedures were identical to those we used in Experiment 1 with the following exceptions: (1) participants returned 3 days after the assembly task to repeat their performance in a second trial; (2) at the end of Trial 2, participants were asked to rate, on a scale of 0 to 5, the mental effort involved in the assembly task; and (3) participants were asked to rate, on a scale of 0 to 5, the usefulness of the instructional display in completing the assembly task.</p><h3 class="c-article__sub-heading" id="Sec16">Results and discussion</h3><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec17">Scoring</h4><p>Two graduate students viewed the 56 videotapes (two per participant) to accurately record: (1) total time spent studying the instructional material prior to beginning the assembly task; (2) the frequency of remedial looks at the instructional material; (3) total time spent on remedial looks; (4) number of correct assemblies; (5) total time used to complete the assembly task. To determine accuracy of assembly, the number of correct connections among the attached elements was counted, with 12 being a perfect score.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec18">Assembly performance</h4>
                    <h3 class="c-article__sub-heading">Assembly accuracy</h3>
                    <p>An alpha of 0.05 was used for all statistical tests. The mean percentages of correct connections made during the assembly task for the RM, Vr-A, and Vr-E groups were, respectively, 77, 57 and 64% on Trial 1 and 75, 68, and 69% on Trial 2. Data on assembly task accuracy was entered into a 3 Display (RM vs. Vr-A vs. Vr-E) × 2 Trial repeated measures ANOVA. Results showed no significant differences for either the main effects of Display and Trial or for the Display × Trial interactions.</p>
                  
                    <h3 class="c-article__sub-heading">Time on task</h3>
                    <p>ANOVA comparing the time each group took to complete the assembly during both trials showed no significant main effect for Display or for the Display × Trial interaction. As expected, the main effect for Trial was significant for time on task, <i>F</i>(1, 25) = 34.37, <i>P</i> &lt; 0.001. Participants in all groups (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0054-2#Fig3">3</a>) dramatically reduced the time required to complete their assemblies between Trial 1 and Trial 2. Through the greatest reduction in assembly time was accomplished by the Vr-A group, the difference between this and the other treatment groups was not statistically significant.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0054-2/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0054-2/MediaObjects/10055_2006_54_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0054-2/MediaObjects/10055_2006_54_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Relative reduction in time on the assembly task by the three treatment groups between trials 1 and 2</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0054-2/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                    
                  
                    <h3 class="c-article__sub-heading">Study time</h3>
                    <p>The mean times spent by participants in the RM, Vr-A, and Vr-E groups to study their respective job aids were 131.7, 184.0, and 252.1 s, respectively. A one-way ANOVA indicated significant, <i>F</i>(2, 25) = 4.84, <i>P</i> &lt; 0.02, differences between the groups. A Newman–Keuls post hoc test of the data revealed that study time by those in the Vr-E group was significantly longer than participants in the RM group. A similar pattern was evident in the mean total times, in seconds, of remedial look backs requested by participants in the RM, Vr-A, and Vr-E groups: 42.2, 57.7, and 86.7, respectively. However, due to the high variability within groups, these means were not significantly different from one another.</p>
                  
                    <h3 class="c-article__sub-heading">Relationship between study and time on task</h3>
                    <p>Based on the large differences between groups in how long their job aid was studied, the relationship between this variable and the amount of time on the assembly task was studied in detail. Total study time was first calculated for each participant by adding the time spent studying the aid with all the accumulated time a participant spent on remedial look backs. The relationship between total study time and total assembly time (i.e., the assembly times for Trials 1 and 2 combined) was then analyzed, indicating a significant, <i>r</i> = 0.52, <i>P</i> &lt; 0.01, correlation between the two variables.</p>
                    <p>Next, the interrelationship between assembly times and scores for each trial, study time, look back time, and participants’ ratings on the usefulness of their display was examined separately for each group. Study time and the time to complete the assembly during Trial 1 was significantly correlated among Vr-A participants, <i>r</i> = 0.68, <i>P</i> = 0.03, and nearly so among those viewing a real model, <i>r</i> = 0.61, <i>P</i> = 0.08. Among Vr-E participants, however, there was little correlation, <i>r</i> = 0.23, <i>P</i> = 0.56, between these variables. Total look back times, meanwhile were significantly correlated with the Trial 1 assembly task for both the RM group, <i>r</i> = 0.80, <i>P</i> = 0.01, and the Vr-E group, <i>r</i> = 0.75, <i>P</i> = 0.02.</p>
                    <p>As one might expect, there was a significant correlation between Trial 1 and Trial 2 in the time taken to complete the assembly by participants viewing either real model (<i>r</i> = 0.81, <i>P</i> &lt; 0.01) or the fully assembled virtual model (<i>r</i> = 0.63, <i>P</i> &lt; 0.05). On the contrary, times on assembly performance for Trial 1 and Trial 2 by those in the Vr-E group showed an almost perfect non-correlation (<i>r</i> = -0.01, <i>P</i> &lt; 0.98). There were no significant correlations, other than those already stated, that arose from this analysis.</p>
                  <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec19">Participant ratings</h4><p>Following the assembly activity in Trial 2, participants were asked to rate, on a scale of 0 to 5, both the mental effort involved in the task and the usefulness of the aid studied during Trial 1 (with 5 indicating greatest effort or usefulness, respectively). Participants did not vary significantly in their perceived effort of the task, which received a mean rating of 2.7 for the entire population. The highest mean difficulty rating came from Vr-E group (2.9) while the lowest was from Vr-A participants (2.5). In terms of the job aid’s usefulness, the RM, Vr-A, and Vr-E groups rated it, respectively, 4.2, 4.8, and 4.6. However, a Kruskal–Wallis one-way ANOVA did not indicate that these differences were statistically significant.</p><p>An important purpose of the current experiment was to validate the results from Experiment 1. In that regard, this study can only be considered a partial success. As in the previous study, the virtual model (exploded view) was studied longer than the real model. However, the opposite was true when the criterion measure was assembly time; participants with the real model took longer to complete the assembly compared to those in the Vr-E condition. Unfortunately, in this study the differences were only significant for study time, not assembly time.</p><p>The differences, however slight, between the RM and Vr-E groups on assembly time in Trial 1 seemed to vanish entirely by the second trial. This suggests that the significant differences for time on task between the real and virtual model in Experiment 1 were only transient; had this study incorporated a second trial, both groups would have likely been equivalent in performance. By contrast, the reduced assembly time in Trial 2 by the Vr-A group relative to the other conditions hints at potential long-term learning gains with this type of display. Though not significant by conventional standards, the performance by Vr-A participants in Trial 2 is important since it represents a saving of over 2 min on a task of roughly 15 min (a reduction of about 15% over the real model). Further, the Meccano assembly task was easy for participants; it would be interesting to see whether a Vr-A display reduces assembly time even further for authentic tasks that are of greater complexity.</p><p>Clearly, participants who were provided a virtual model in an exploded view studied their display far longer than those viewing a real model. One explanation for this could be either the novelty or difficulty in using an interactive 3D training aid. However, when participants familiarized themselves with the technology by using a practice display, many tried to quit well before the end of the allotted 2 min, saying they had practiced enough. Additionally, the novelty of this technology would have also been evident among Vr-A participants, whose mean study time was closer to the RM group than the Vr-E group. Hence, it is unlikely that the longer study by Vr-E participants was due to the newness of the technology.</p><p>Another possible reason for the longer study by Vr-E participants is that their display was more difficult to understand. If so, the additional cognitive load imposed by the exploded view’s visual would conceivably have an adverse effect on learning even though the performance task itself may have been accomplished. One measure of the actual learning that occurred is the subsequent performance on the same task after a prolonged delay. For example, on a task of moderate difficulty, such as the Meccano assembly, participants should improve with each successive test in proportion to their native ability. This was clearly the case with the RM and Vr-A groups; both showed significant correlations in time on task between the two trials. By contrast, the relationship between time scores in Trial 1 and 2 among participants in the Vr-E group was virtually nonexistent, hinting that no real learning had occurred. Another measure of learning, the relationship between study and performance, was present in the Vr-A and RM groups, but not for Vr-E participants.</p><p>The thesis that a greater cognitive load accompanies study of a virtual model in an exploded view is further supported, albeit weakly, by ratings of participants on the difficulty of the assembly task. Out of the three treatment groups, Vr-E participants rated the assembly task most difficult while Vr-A participants rated the task least difficult. These differences were not significant but might have been greater if the ratings had been obtained after Trial 1 rather than following the relative success of participants during Trial 2.</p></div></div></section><section aria-labelledby="Sec20"><div class="c-article-section" id="Sec20-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec20">General discussion</h2><div class="c-article-section__content" id="Sec20-content"><p>The failure of the current study to replicate the significantly superior performance of the virtual model uncovered in the Experiment 1 was disappointing. With the data from the Experiment 2, it now appears that the relatively longer study of the Vr-E display compared to the real model in the pilot may be due more to a higher cognitive demand by the former rather than shallow processing of the latter.</p><p>In addition to extending the pilot study, this experiment attempted to replicate the earlier study by Pillay (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Pillay H (1998) Cognitive processes and strategies employed by children to learn spatial representations. Learn Instr 8(1):1–18" href="/article/10.1007/s10055-006-0054-2#ref-CR14" id="ref-link-section-d40654e1098">1998</a>), using the assembly performance by participants who viewed the model as baseline data. We compared Pillay’s results with the outcomes from out two experiments (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0054-2#Fig4">4</a>) by calculating, in each case and for every treatment, the mean number of seconds per correctly assembled piece. One striking aspect of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0054-2#Fig4">4</a> is that participants who viewed a real model in Pillay’s study were outperformed by every other group represented (a shorter bar indicates better performance). This can be explained by the fact that Pillay’s participants were children with a mean age of 14.2 years. In our two experiments, by contrast, participants were undergraduate students. Nevertheless, the improvement in assembly performance between trial 1 and 2 for participants who study a real model were roughly the same proportion in both Pillay’s and the current study.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0054-2/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0054-2/MediaObjects/10055_2006_54_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0054-2/MediaObjects/10055_2006_54_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Comparison of performance by participants in on the same assembly tasks following study or real or virtual models</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0054-2/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>Perhaps the most important insight gained from the graphic depiction of these experiments is that, in the case of the two studies incorporating virtual models, participants’ performance was essentially identical for all treatments by Trial 2. This may indicate, as suggested earlier, that the task may have been too easy for adult participants and that the lack of significant differences in performance between groups might be due to a ceiling effect.</p><p>Our research explored the feasibility of using virtual realia as job performance aids for completing a simple assembly task. Based on the evidence gained from the two studies, virtual models appear to be at least as effective as real models for training persons on assembly tasks. Using these new learning tools, people are able to assemble objects with speed and accuracy after minimal practice.</p><p>An important next step in this research will be to test whether participants can use virtual models for authentic on-the-job tasks with considerably higher complexity than the 12-piece object used here. If virtual realia proves to be effective for everyday jobs such as equipment repair and maintenance, it will have enormous ramifications for Internet-based training. Virtual models, hopefully then, can serve as the “missing link” that will enable trainers to finally provide distributed knowledge for acquiring psychomotor skills.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="KM. Baird, W. Barfield, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Baird KM, Barfield W (1999) Evaluating the effectiveness of augmented reality displays for a manual assembly t" /><p class="c-article-references__text" id="ref-CR1">Baird KM, Barfield W (1999) Evaluating the effectiveness of augmented reality displays for a manual assembly task. Virtual Reality 4:250–259</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2FBF01421808" aria-label="View reference 1">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Evaluating%20the%20effectiveness%20of%20augmented%20reality%20displays%20for%20a%20manual%20assembly%20task&amp;journal=Virtual%20Reality&amp;volume=4&amp;pages=250-259&amp;publication_year=1999&amp;author=Baird%2CKM&amp;author=Barfield%2CW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SA. Barab, KE. Hay, M. Barnett, K. Squire, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Barab SA, Hay KE, Barnett M, Squire K (2001) Constructing virtual worlds: tracing the historical development o" /><p class="c-article-references__text" id="ref-CR2">Barab SA, Hay KE, Barnett M, Squire K (2001) Constructing virtual worlds: tracing the historical development of learner practices. Cognit Instr 19(1):47–94</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1207%2FS1532690XCI1901_2" aria-label="View reference 2">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Constructing%20virtual%20worlds%3A%20tracing%20the%20historical%20development%20of%20learner%20practices&amp;journal=Cognit%20Instr&amp;volume=19&amp;issue=1&amp;pages=47-94&amp;publication_year=2001&amp;author=Barab%2CSA&amp;author=Hay%2CKE&amp;author=Barnett%2CM&amp;author=Squire%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HJ. Bullinger, M. Richter, KA. Seidel, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Bullinger HJ, Richter M, Seidel KA (2000) Virtual assembly planning. Hum Factors Ergon Manuf 10(3):331–341" /><p class="c-article-references__text" id="ref-CR3">Bullinger HJ, Richter M, Seidel KA (2000) Virtual assembly planning. Hum Factors Ergon Manuf 10(3):331–341</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2F1520-6564%28200022%2910%3A3%3C331%3A%3AAID-HFM7%3E3.0.CO%3B2-D" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20assembly%20planning&amp;journal=Hum%20Factors%20Ergon%20Manuf&amp;volume=10&amp;issue=3&amp;pages=331-341&amp;publication_year=2000&amp;author=Bullinger%2CHJ&amp;author=Richter%2CM&amp;author=Seidel%2CKA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="F. Craik, R. Lockhart, " /><meta itemprop="datePublished" content="1972" /><meta itemprop="headline" content="Craik F, Lockhart R (1972) Levels of processing: a framework for memory research. J Verbal Learn Verbal Behav " /><p class="c-article-references__text" id="ref-CR4">Craik F, Lockhart R (1972) Levels of processing: a framework for memory research. J Verbal Learn Verbal Behav 11:761–784</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0022-5371%2872%2980001-X" aria-label="View reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Levels%20of%20processing%3A%20a%20framework%20for%20memory%20research&amp;journal=J%20Verbal%20Learn%20Verbal%20Behav&amp;volume=11&amp;pages=761-784&amp;publication_year=1972&amp;author=Craik%2CF&amp;author=Lockhart%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cycore (2005) Cult 3D. Retrieved from the World Wide Web at http://www.cult3d.com/&#xA;                " /><p class="c-article-references__text" id="ref-CR5">Cycore (2005) Cult 3D. Retrieved from the World Wide Web at <a href="http://www.cult3d.com/">http://www.cult3d.com/</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Gerace, JJ. Gallimore, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Gerace J, Gallimore JJ (2001) Evaluation of visual display techniques for assembly sequence planning. Hum Fact" /><p class="c-article-references__text" id="ref-CR6">Gerace J, Gallimore JJ (2001) Evaluation of visual display techniques for assembly sequence planning. Hum Factors Ergon Manuf 11(3):213–231</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2Fhfm.1011" aria-label="View reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Evaluation%20of%20visual%20display%20techniques%20for%20assembly%20sequence%20planning&amp;journal=Hum%20Factors%20Ergon%20Manuf&amp;volume=11&amp;issue=3&amp;pages=213-231&amp;publication_year=2001&amp;author=Gerace%2CJ&amp;author=Gallimore%2CJJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="B. Harper, JG. Hedberg, R. Wright, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Harper B, Hedberg JG, Wright R (2000) Who benefits from virtuality? Comput Educ 34:163–176" /><p class="c-article-references__text" id="ref-CR7">Harper B, Hedberg JG, Wright R (2000) Who benefits from virtuality? Comput Educ 34:163–176</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0360-1315%2899%2900043-3" aria-label="View reference 7">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Who%20benefits%20from%20virtuality%3F&amp;journal=Comput%20Educ&amp;volume=34&amp;pages=163-176&amp;publication_year=2000&amp;author=Harper%2CB&amp;author=Hedberg%2CJG&amp;author=Wright%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hoffman H, Groen J, Rousseau S, Hollander A, Winn W, Wells M, Furness T (1996) Tactile augmentation: enhancing" /><p class="c-article-references__text" id="ref-CR8">Hoffman H, Groen J, Rousseau S, Hollander A, Winn W, Wells M, Furness T (1996) Tactile augmentation: enhancing presence in virtual reality with tactile feedback from real objects. In: Paper presented at the meeting of the American Psychological Society, San Francisco</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HG. Hoffman, J. Prothero, MJ. Wells, J. Groen, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Hoffman HG, Prothero J, Wells MJ, Groen J (1998) Virtual chess: meaning enhances users’ sense of presence in v" /><p class="c-article-references__text" id="ref-CR9">Hoffman HG, Prothero J, Wells MJ, Groen J (1998) Virtual chess: meaning enhances users’ sense of presence in virtual environments. Int J Hum Comput Interact 10(3):251–263</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1207%2Fs15327590ijhc1003_3" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20chess%3A%20meaning%20enhances%20users%E2%80%99%20sense%20of%20presence%20in%20virtual%20environments&amp;journal=Int%20J%20Hum%20Comput%20Interact&amp;volume=10&amp;issue=3&amp;pages=251-263&amp;publication_year=1998&amp;author=Hoffman%2CHG&amp;author=Prothero%2CJ&amp;author=Wells%2CMJ&amp;author=Groen%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Jiangsheng, Y. Yingxue, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Jiangsheng L, Yingxue Y (2004) Preliminary investigation of virtual assembly constructing. Assem Autom 24(4):3" /><p class="c-article-references__text" id="ref-CR10">Jiangsheng L, Yingxue Y (2004) Preliminary investigation of virtual assembly constructing. Assem Autom 24(4):379–385</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1108%2F01445150410562589" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Preliminary%20investigation%20of%20virtual%20assembly%20constructing&amp;journal=Assem%20Autom&amp;volume=24&amp;issue=4&amp;pages=379-385&amp;publication_year=2004&amp;author=Jiangsheng%2CL&amp;author=Yingxue%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="SM. Kosslyn, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Kosslyn SM (1994) Image and brain: the resolution of the imagery debate. MIT Press, Cambridge" /><p class="c-article-references__text" id="ref-CR11">Kosslyn SM (1994) Image and brain: the resolution of the imagery debate. MIT Press, Cambridge</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Image%20and%20brain%3A%20the%20resolution%20of%20the%20imagery%20debate&amp;publication_year=1994&amp;author=Kosslyn%2CSM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RB. Kozma, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="Kozma RB (1991) Learning with media. Rev Educ Res 61(2):179–211" /><p class="c-article-references__text" id="ref-CR12">Kozma RB (1991) Learning with media. Rev Educ Res 61(2):179–211</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1541850" aria-label="View reference 12 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.2307%2F1170534" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20with%20media&amp;journal=Rev%20Educ%20Res&amp;volume=61&amp;issue=2&amp;pages=179-211&amp;publication_year=1991&amp;author=Kozma%2CRB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Milgram, F. Kishino, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Milgram P, Kishino F (1994) A taxonomy of mixed reality visual displays. IEICE Trans Inf Syst E77-D(12):1321–1" /><p class="c-article-references__text" id="ref-CR13">Milgram P, Kishino F (1994) A taxonomy of mixed reality visual displays. IEICE Trans Inf Syst E77-D(12):1321–1329</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20taxonomy%20of%20mixed%20reality%20visual%20displays&amp;journal=IEICE%20Trans%20Inf%20Syst&amp;volume=E77-D&amp;issue=12&amp;pages=1321-1329&amp;publication_year=1994&amp;author=Milgram%2CP&amp;author=Kishino%2CF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Pillay, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Pillay H (1998) Cognitive processes and strategies employed by children to learn spatial representations. Lear" /><p class="c-article-references__text" id="ref-CR14">Pillay H (1998) Cognitive processes and strategies employed by children to learn spatial representations. Learn Instr 8(1):1–18</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0959-4752%2897%2900030-3" aria-label="View reference 14">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Cognitive%20processes%20and%20strategies%20employed%20by%20children%20to%20learn%20spatial%20representations&amp;journal=Learn%20Instr&amp;volume=8&amp;issue=1&amp;pages=1-18&amp;publication_year=1998&amp;author=Pillay%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="OW. Sacks, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Sacks OW (1995) An anthropologist on Mars: seven paradoxical tales. Knopf, New York" /><p class="c-article-references__text" id="ref-CR15">Sacks OW (1995) An anthropologist on Mars: seven paradoxical tales. Knopf, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20anthropologist%20on%20Mars%3A%20seven%20paradoxical%20tales&amp;publication_year=1995&amp;author=Sacks%2COW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="TB. Sheridan, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Sheridan TB (1992) Musings on telepresence and virtual presence. Presence Teleoperators Virtual Environ 1(1):1" /><p class="c-article-references__text" id="ref-CR16">Sheridan TB (1992) Musings on telepresence and virtual presence. Presence Teleoperators Virtual Environ 1(1):120–126</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Musings%20on%20telepresence%20and%20virtual%20presence&amp;journal=Presence%20Teleoperators%20Virtual%20Environ&amp;volume=1&amp;issue=1&amp;pages=120-126&amp;publication_year=1992&amp;author=Sheridan%2CTB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sheridan TB (2000) Interaction, imagination and immersion: some research needs. In: Proceedings of the ACM sym" /><p class="c-article-references__text" id="ref-CR17">Sheridan TB (2000) Interaction, imagination and immersion: some research needs. In: Proceedings of the ACM symposium on virtual reality software and technology, Seoul</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Steuer, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Steuer J (1992) Defining virtual reality: dimensions determining telepresence. J Commun 42(4):73–93" /><p class="c-article-references__text" id="ref-CR18">Steuer J (1992) Defining virtual reality: dimensions determining telepresence. J Commun 42(4):73–93</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fj.1460-2466.1992.tb00812.x" aria-label="View reference 18">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Defining%20virtual%20reality%3A%20dimensions%20determining%20telepresence&amp;journal=J%20Commun&amp;volume=42&amp;issue=4&amp;pages=73-93&amp;publication_year=1992&amp;author=Steuer%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Sun, B. Hujun, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Sun H, Hujun B (2002) Two-handed assembly with immersive task planning in virtual reality. Virtual Reality 6:1" /><p class="c-article-references__text" id="ref-CR19">Sun H, Hujun B (2002) Two-handed assembly with immersive task planning in virtual reality. Virtual Reality 6:11–20</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1029.16024" aria-label="View reference 19 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2FBF01408565" aria-label="View reference 19">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Two-handed%20assembly%20with%20immersive%20task%20planning%20in%20virtual%20reality&amp;journal=Virtual%20Reality&amp;volume=6&amp;pages=11-20&amp;publication_year=2002&amp;author=Sun%2CH&amp;author=Hujun%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Sweller, " /><meta itemprop="datePublished" content="1988" /><meta itemprop="headline" content="Sweller J (1988) Cognitive load during problem solving: effects on learning. Cogn Sci 12:257–285" /><p class="c-article-references__text" id="ref-CR20">Sweller J (1988) Cognitive load during problem solving: effects on learning. Cogn Sci 12:257–285</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2F0364-0213%2888%2990023-7" aria-label="View reference 20">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Cognitive%20load%20during%20problem%20solving%3A%20effects%20on%20learning&amp;journal=Cogn%20Sci&amp;volume=12&amp;pages=257-285&amp;publication_year=1988&amp;author=Sweller%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Theeuwes, P. Atchley, AF. Kramer, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Theeuwes J, Atchley P, Kramer AF (1998) Attentional control within 3-D space. J Exp Psychol Hum Percept Perfor" /><p class="c-article-references__text" id="ref-CR21">Theeuwes J, Atchley P, Kramer AF (1998) Attentional control within 3-D space. J Exp Psychol Hum Percept Perform 24(5):1476–1485</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1037%2F0096-1523.24.5.1476" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Attentional%20control%20within%203-D%20space&amp;journal=J%20Exp%20Psychol%20Hum%20Percept%20Perform&amp;volume=24&amp;issue=5&amp;pages=1476-1485&amp;publication_year=1998&amp;author=Theeuwes%2CJ&amp;author=Atchley%2CP&amp;author=Kramer%2CAF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Windschitl M, Winn W (2000) A virtual environment designed to help students understand science. In: Fishman B," /><p class="c-article-references__text" id="ref-CR22">Windschitl M, Winn W (2000) A virtual environment designed to help students understand science. In: Fishman B, O’Connor-Divelbiss C (eds) Fourth international conference of the learning sciences. Erlbaum, Mahwah</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="W. Winn, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Winn W (2002) Current trends in educational technology research: The study of learning environments. Educ Psyc" /><p class="c-article-references__text" id="ref-CR23">Winn W (2002) Current trends in educational technology research: The study of learning environments. Educ Psychol Rev 14(3):331–351</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1023%2FA%3A1016068530070" aria-label="View reference 23">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Current%20trends%20in%20educational%20technology%20research%3A%20The%20study%20of%20learning%20environments&amp;journal=Educ%20Psychol%20Rev&amp;volume=14&amp;issue=3&amp;pages=331-351&amp;publication_year=2002&amp;author=Winn%2CW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Wittenberg, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Wittenberg G (1995) Training with virtual reality. Assem Autom 15(3):12–14" /><p class="c-article-references__text" id="ref-CR24">Wittenberg G (1995) Training with virtual reality. Assem Autom 15(3):12–14</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1108%2F01445159510094570" aria-label="View reference 24">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Training%20with%20virtual%20reality&amp;journal=Assem%20Autom&amp;volume=15&amp;issue=3&amp;pages=12-14&amp;publication_year=1995&amp;author=Wittenberg%2CG">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-006-0054-2-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Instructional Technology Program, University of South Florida, 4202 E. Fowler Avenue, EDU162, Tampa, FL, 33620-5650, USA</p><p class="c-article-author-affiliation__authors-list">William A. Kealy &amp; Chitra P. Subramaniam</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-William_A_-Kealy"><span class="c-article-authors-search__title u-h3 js-search-name">William A. Kealy</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;William A.+Kealy&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=William A.+Kealy" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22William A.+Kealy%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Chitra_P_-Subramaniam"><span class="c-article-authors-search__title u-h3 js-search-name">Chitra P. Subramaniam</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Chitra P.+Subramaniam&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Chitra P.+Subramaniam" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Chitra P.+Subramaniam%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-006-0054-2/email/correspondent/c1/new">William A. Kealy</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Virtual%20realia%3A%20maneuverable%20computer%203D%20models%20and%20their%20use%20in%20learning%20assembly%20skills&amp;author=William%20A.%20Kealy%20et%20al&amp;contentID=10.1007%2Fs10055-006-0054-2&amp;publication=1359-4338&amp;publicationDate=2006-10-17&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Kealy, W.A., Subramaniam, C.P. Virtual realia: maneuverable computer 3D models and their use in learning assembly skills.
                    <i>Virtual Reality</i> <b>10, </b>283–292 (2006). https://doi.org/10.1007/s10055-006-0054-2</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-006-0054-2.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2005-12-20">20 December 2005</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-05-22">22 May 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-10-17">17 October 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-12">December 2006</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-006-0054-2" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-006-0054-2</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Virtual Reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Real Model</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Augmented Reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Instructional Material</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Virtual Object</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-006-0054-2.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=54;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

