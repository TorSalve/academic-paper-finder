<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Guidelines for haptic interpersonal communication applications: an exp"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="A new method for researching haptic interaction styles is presented, based on a layered interaction model and a classification of existing devices. The method is illustrated by designing a new foot..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/9/2.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Guidelines for haptic interpersonal communication applications: an exploration of foot interaction styles"/>

    <meta name="dc.source" content="Virtual Reality 2005 9:2"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2005-12-03"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2005 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="A new method for researching haptic interaction styles is presented, based on a layered interaction model and a classification of existing devices. The method is illustrated by designing a new foot interaction device. The aim of which is to enhance non-verbal communication over a computer network. A layered protocols interaction model allows to consider all aspects of the haptic communication process: the intention to perform an action, limitations of the human body, and specifications of the communication device and the network. We demonstrate how this model can be used to derive design-guidelines by analyzing and classifying existing communication devices. By designing and evaluating a foot interaction device, we not only demonstrate that feet are suited for personal, concealed communication over a network, but also show the added value of the design-guidelines. Results of user tests provide clues for designing stimuli for foot interaction and indicate applications of foot communication devices."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2005-12-03"/>

    <meta name="prism.volume" content="9"/>

    <meta name="prism.number" content="2"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="177"/>

    <meta name="prism.endingPage" content="191"/>

    <meta name="prism.copyright" content="2005 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-005-0016-0"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-005-0016-0"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-005-0016-0.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-005-0016-0"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Guidelines for haptic interpersonal communication applications: an exploration of foot interaction styles"/>

    <meta name="citation_volume" content="9"/>

    <meta name="citation_issue" content="2"/>

    <meta name="citation_publication_date" content="2006/03"/>

    <meta name="citation_online_date" content="2005/12/03"/>

    <meta name="citation_firstpage" content="177"/>

    <meta name="citation_lastpage" content="191"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-005-0016-0"/>

    <meta name="DOI" content="10.1007/s10055-005-0016-0"/>

    <meta name="citation_doi" content="10.1007/s10055-005-0016-0"/>

    <meta name="description" content="A new method for researching haptic interaction styles is presented, based on a layered interaction model and a classification of existing devices. The met"/>

    <meta name="dc.creator" content="A.F. Rovers"/>

    <meta name="dc.creator" content="H.A. van Essen"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_title=The mobile connection: The cell phone&#8217;s impact on society; citation_publication_date=2004; citation_id=CR1; citation_author=RC Ling; citation_publisher=Morgan Kaufmann Publishers Inc"/>

    <meta name="citation_reference" content="Brave S, Dahley A (1997) Intouch: medium for haptic interpersonal communication, Extended abstracts of CHI&#8217;97, Atlanta GA, pp 363&#8211;364"/>

    <meta name="citation_reference" content="Chang A, O&#8217;Modhrains S, Jacob R, Gunther E, Ishii H (2002) Comtouch: Design of a vibrotactile communication device, Proceedings of DIS&#8217;02, London, England, pp 312&#8211;320; doi: 10.1145/778712.778755"/>

    <meta name="citation_reference" content="Rovers AF, Essen van HA (2004) HIM: A Framework for haptic instant messaging, Extended abstracts of CHI 2004, Vienna, Austria, pp 1313&#8211;1316; doi: 10.1145/985921.986052"/>

    <meta name="citation_reference" content="LaViola JL, Feliz DA, Keefe D, Zeleznik RC (2001) Hands-free multi-scale navigation in virtual environments, Proceedings of SI3D&#8217;01, Research Triangle Park, NC, pp 9&#8211;15; doi: 10.1145/364338.364339"/>

    <meta name="citation_reference" content="Pearson G, Weiser M (1986) Of moles and men: The design of foot controls for workstations, Proceedings of SIGCHI&#8217;86, Boston, MA, pp 333&#8211;339; doi: 10.1145/22627.22392"/>

    <meta name="citation_reference" content="Paradiso JA, Morris SJ, Benbasat AY, Asmussen E (2004) Interactive therapy with instrumented footwear, extended abstracts of CHI&#8217;04, Vienna, Austria, pp 1341&#8211;1343; doi: 10.1145/985921.986059"/>

    <meta name="citation_reference" content="Whitton MC, Cohn JV, Feasel J, Zimmons P, Razzaque S, Poulton SJ, McLeod B, Brooks FP (2005) Comparing VE locomotion interfaces, Proceedings of IEEE Virtual Reality 2005, Bonn; doi: 10.1109/VR.2005.25"/>

    <meta name="citation_reference" content="Templeman JN, Denbrook PS, Sibert LE (1999) Virtual locomotion: Walking in place through virtual environments, Presence: teleoperators and virtual environments, vol 8, Nr. 6, The MIT Press, Cambridge, pp 598&#8211;617"/>

    <meta name="citation_reference" content="Pakkanen T, Raisamo R (2004) Appropriateness of foot interaction for non-accurate spatial tasks, Extended abstracts of CHI2004, Vienna, Austria, pp 1123&#8211;1126; doi: 10.1145/985921.986004"/>

    <meta name="citation_reference" content="Hoffmann ER (1991) A comparison of hand and foot movement times, Ergonomics 34(4), April, Taylor &amp; Francis, London, pp 397&#8211;406; PMID: 1860460"/>

    <meta name="citation_reference" content="citation_journal_title=Exp Brain Res; citation_title=Mechanoreceptive afferents in the human sural nerve; citation_author=M Trulsson; citation_volume=137; citation_publication_date=2001; citation_pages=111-116; citation_id=CR12"/>

    <meta name="citation_reference" content="Essen HA van, Rovers AF (2005) Layered protocols approach to analyze haptic communication over a network, Proceedings of World Haptics 2005, Pisa, Italy; doi: 10.1109/WHC.2005.85"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Man Mach Stud; citation_title=Layered protocols for computer-human dialogue I: principles; citation_author=MM Taylor; citation_volume=28; citation_publication_date=1988; citation_pages=175-218; citation_id=CR14"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Man Mach Stud; citation_title=Layered protocols for computer-human dialogue II: some practical issues; citation_author=MM Taylor; citation_volume=28; citation_publication_date=1988; citation_pages=219-257; citation_id=CR15"/>

    <meta name="citation_reference" content="citation_title=An introduction to human factors analysis; citation_publication_date=1998; citation_id=CR16; citation_author=CD Wickens; citation_author=SE Gordon; citation_author=Y Liu; citation_publisher=Addison-Wesley Inc"/>

    <meta name="citation_reference" content="citation_title=The ecological approach to visual perception; citation_publication_date=1979; citation_id=CR17; citation_author=JJ Gibson; citation_publisher=Houghton Mifflin"/>

    <meta name="citation_reference" content="citation_title=User centered system design: New perspective on human-computer interaction; citation_publication_date=1986; citation_id=CR18; citation_author=DA Norman; citation_author=SW Draper; citation_publisher=Lawrence Erlbaum Associates Inc"/>

    <meta name="citation_reference" content="citation_title=The design of everyday things; citation_publication_date=1988; citation_id=CR19; citation_author=DA Norman; citation_publisher=The MIT press"/>

    <meta name="citation_reference" content="IJsselsteijn WA (2004) Presence in Dept, PhD Thesis, Eindhoven University of Technology, J.F. Schoutenschool for User-System Interaction Research"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Ind Electron; citation_title=Web-interfaced, force-reflecting teleoperation systems; citation_author=R Oboe; citation_volume=48; citation_issue=6; citation_publication_date=2001; citation_pages=1257-1265; citation_doi=10.1109/41.969406; citation_id=CR21"/>

    <meta name="citation_reference" content="Souayed GT, Gaiti D, Yu W, Dodds G, Marshall A (2004) Experimental study of haptic interaction in distributed virtual environments. Proceedings of Eurohaptics, Munchen, Germany, pp 260&#8211;266"/>

    <meta name="citation_reference" content="citation_title=Telephonic arm wrestling; citation_publication_date=1986; citation_id=CR23; citation_author=N White; citation_author=D Back; citation_publisher=The strategic arts initiative symposium"/>

    <meta name="citation_reference" content="Paulos E (2003) Connexus: A communal interface&#8221;. Tech.Report IRB-TR-03-011, Intel Research"/>

    <meta name="citation_reference" content="Fels S, Takahashi S, Chung C (2001) PlesioPhone: An cell phone and telephone based interactive artwork, (
                    http://hct.ece.ubc.ca/research/plesiophone
                    
                  )"/>

    <meta name="citation_reference" content="Fogg BJ, Cutler LD, Arnold P, Eisbach PC (1998) HandJive: A device for interpersonal haptic entertainment, Proceedings of CHI &#8216;98, Los Angeles, CA, pp 57&#8211;64; doi: 10.1145/274644.274653"/>

    <meta name="citation_reference" content="Goldberg K, Wallace R (1993) Data dentata, visual proceedings of SIGGRAPH &#8216;93, Anaheim, CA"/>

    <meta name="citation_reference" content="Dodge C (1997) The Bed: A medium for intimate communication. Extened abstracts of CHI 97, Atlanta, GA, pp 371&#8211;372"/>

    <meta name="citation_reference" content="Grimmer N (2001) Heart2Heart, winner of Intel student design competition"/>

    <meta name="citation_reference" content="McGaig G, Fels S (2002) The 2Hearts Project: Enhancing non-verbal communication through music and graphics, (
                    http://hct.ece.ubc.ca/research/2hearts
                    
                  )"/>

    <meta name="citation_reference" content="Oakley I, O&#8217;Modhrain S (2002) Contact IM: Exploring asynchronous touch over distance, proceedings of CSCW 2002"/>

    <meta name="citation_reference" content="Tollmar K, Junestrand S, Torgny O (2000) Virtually living together, Proceedings of DIS 2000, New York City, NY, pp 83&#8211;91; doi: 10.1145/347642.347670"/>

    <meta name="citation_reference" content="Hansson R, Skogg T (2001) The LoveBomb: Encouraging the communication of emotions in public space, Extended abstracts of CHI&#8217;01, pp 433&#8211;434; doi: 10.1145/634067.634319"/>

    <meta name="citation_reference" content="Rovers AF, Essen HA van (2004) Design and evaluation of hapticons for enriched instant messaging, Proceedings of EuroHaptics&#8217;04, Munich, Germany"/>

    <meta name="citation_reference" content="citation_journal_title=Proc ASME Dyn Syst Control Div; citation_title=A Psychophysical study of sensory saltation with an open response paradigm, DSC vol 69-2; citation_author=H Tan, A Lim, R Taylor; citation_volume=2; citation_publication_date=2000; citation_pages=1109-1115; citation_id=CR35"/>

    <meta name="citation_reference" content="Erp JBF van (2002) Guidelines for the use of vibro-tactile displays in human computer interaction, Proceedings of EuroHaptics&#8217;02"/>

    <meta name="citation_reference" content="Rovers AF, Essen HA van (2005) FootIO: Design and evaluation of a device to enable foot interaction over a computer network. Proceedings of WorldHaptics 2005, Pisa, Italy, pp 521&#8211;522; doi: 10.1109/WHC.2005.56"/>

    <meta name="citation_reference" content="Brave S, Nass C, Sirinian CE (2001) Force-feedback in computer-mediated communication, Proceedings of UAHCI&#8217;01, New Orleans, LA"/>

    <meta name="citation_author" content="A.F. Rovers"/>

    <meta name="citation_author_email" content="A.F.Rovers@tue.nl"/>

    <meta name="citation_author_institution" content="Department of Industrial Design, Eindhoven University of Technology, Eindhoven, The Netherlands"/>

    <meta name="citation_author" content="H.A. van Essen"/>

    <meta name="citation_author_institution" content="Department of Industrial Design, Eindhoven University of Technology, Eindhoven, The Netherlands"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-005-0016-0&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2006/03/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-005-0016-0"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Guidelines for haptic interpersonal communication applications: an exploration of foot interaction styles"/>
        <meta property="og:description" content="A new method for researching haptic interaction styles is presented, based on a layered interaction model and a classification of existing devices. The method is illustrated by designing a new foot interaction device. The aim of which is to enhance non-verbal communication over a computer network. A layered protocols interaction model allows to consider all aspects of the haptic communication process: the intention to perform an action, limitations of the human body, and specifications of the communication device and the network. We demonstrate how this model can be used to derive design-guidelines by analyzing and classifying existing communication devices. By designing and evaluating a foot interaction device, we not only demonstrate that feet are suited for personal, concealed communication over a network, but also show the added value of the design-guidelines. Results of user tests provide clues for designing stimuli for foot interaction and indicate applications of foot communication devices."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Guidelines for haptic interpersonal communication applications: an exploration of foot interaction styles | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-005-0016-0","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Haptic interaction, Foot interaction, Layered protocols, Communication, Hapticons","kwrd":["Haptic_interaction","Foot_interaction","Layered_protocols","Communication","Hapticons"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-005-0016-0","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-005-0016-0","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=16;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-005-0016-0">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Guidelines for haptic interpersonal communication applications: an exploration of foot interaction styles
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-005-0016-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-005-0016-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2005-12-03" itemprop="datePublished">03 December 2005</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Guidelines for haptic interpersonal communication applications: an exploration of foot interaction styles</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-A_F_-Rovers" data-author-popup="auth-A_F_-Rovers" data-corresp-id="c1">A.F. Rovers<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Eindhoven University of Technology" /><meta itemprop="address" content="grid.6852.9, 0000000403988763, Department of Industrial Design, Eindhoven University of Technology, Den Dolech 2 (HG 2.59), 5612AZ, Eindhoven, The Netherlands" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-H_A_-Essen" data-author-popup="auth-H_A_-Essen">H.A. van Essen</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Eindhoven University of Technology" /><meta itemprop="address" content="grid.6852.9, 0000000403988763, Department of Industrial Design, Eindhoven University of Technology, Den Dolech 2 (HG 2.59), 5612AZ, Eindhoven, The Netherlands" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 9</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">177</span>–<span itemprop="pageEnd">191</span>(<span data-test="article-publication-year">2006</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">605 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">27 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">3 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-005-0016-0/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>A new method for researching haptic interaction styles is presented, based on a layered interaction model and a classification of existing devices. The method is illustrated by designing a new foot interaction device. The aim of which is to enhance non-verbal communication over a computer network. A layered protocols interaction model allows to consider all aspects of the haptic communication process: the intention to perform an action, limitations of the human body, and specifications of the communication device and the network. We demonstrate how this model can be used to derive design-guidelines by analyzing and classifying existing communication devices. By designing and evaluating a foot interaction device, we not only demonstrate that feet are suited for personal, concealed communication over a network, but also show the added value of the design-guidelines. Results of user tests provide clues for designing stimuli for foot interaction and indicate applications of foot communication devices.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>People use different communication technologies to stay in touch with remotely located relatives and friends (i.e. pagers, phone, and instant messaging). Although there have been many developments in this field [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Ling RC (2004) The mobile connection: The cell phone’s impact on society. Morgan Kaufmann Publishers Inc., San Fransisco, Los Altos, CA" href="/article/10.1007/s10055-005-0016-0#ref-CR1" id="ref-link-section-d30864e295">1</a>–<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Chang A, O’Modhrains S, Jacob R, Gunther E, Ishii H (2002) Comtouch: Design of a vibrotactile communication device, Proceedings of DIS’02, London, England, pp 312–320; doi: 10.1145/778712.778755" href="/article/10.1007/s10055-005-0016-0#ref-CR3" id="ref-link-section-d30864e298">3</a>], these devices don’t have the same effect as meeting someone in the real world. Often subtle non-verbal cues like facial expressions, body language, intonation, and interacting with personal space are lost. We want to enrich communication devices by adding a haptic channel, because haptics is the most direct and intimate way of person-to-person (P2P) interaction. Even though adding haptic cues to a communication channel can never meet the haptic contact in the real world, we demonstrate that the experience of remote touch can be used to enrich interpersonal communication over distance.</p><p>In order to understand and improve the design of haptic enabled communication devices, we use an iterative design-research approach. By designing and evaluating protoypes of simple haptic devices, the opportunities for haptic interpersonal interaction become visible.</p><p>When designing a device that takes into account user needs, human interaction skills, and technical possibilities, one encounters a complex problem encompassing several fields of expertise. An interaction model is required to fully understand what is happening during the haptic enabled communication activity. Such a model not only enables analyzing a particular device in depth, but also reveals relationships between device characteristics and their effect on the overall communication process (e.g. feasibility, presence feeling, etc.). This is derived by by comparing similar existing devices with a classification parameter set.</p><p>The insights from the prototypes, the classification parameters and the interaction model are combined to derive design guidelines for enriching communication that can be used by researchers to develop the next generation of communication devices like small wearables, force feedback computer IO devices, etc.</p><p>In this paper FootIO–a foot interaction device linked to the Haptic instant messenger [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Rovers AF, Essen van HA (2004) HIM: A Framework for haptic instant messaging, Extended abstracts of CHI 2004, Vienna, Austria, pp 1313–1316; doi: 10.1145/985921.986052" href="/article/10.1007/s10055-005-0016-0#ref-CR4" id="ref-link-section-d30864e311">4</a>] that we designed earlier—is presented as a research carrier to investigate opportunities for haptic interpersonal communication with the feet. Within our iterative research-by-design approach, the design of the device is based on earlier research results and the interaction model, and at the same time adds to the further development of the interaction model.</p><p>Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-005-0016-0#Sec2">2</a> introduces the opportunities for foot interaction. In Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-005-0016-0#Sec5">3</a> our new haptic communication model is presented. Also the applicability of the model to analyze particular devices is demonstrated. By doing a classification of existing devices with the interaction model as basis, new design guidelines are derived in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-005-0016-0#Sec8">4</a>. Next, the design of the foot interaction device and results of user experiments are presented and explained by using the interaction model. Finally, the new design approach is discussed and conclusions are presented in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-005-0016-0#Sec26">6</a>.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Foot interaction and virtual environments</h2><div class="c-article-section__content" id="Sec2-content"><p>In known applications of foot interaction devices, feet are used only for relatively simple tasks. Considering the physical properties of sensor and motor skills of feet, more complex interactions should be possible. In this section we present an overview of different categories of existing devices and interaction styles. Obvious applications are controlling graphical user interfaces and providing additional information channels in hands- and eye-busy situations.</p><p>As touching someone’s feet is often considered to be intimate, constructing a foot interaction device appears to be a logical step to enable meaningful, personal, intimate, and concealed communication over a network. Feet might also be used to (hands-free) control the user interface of such a communication device. Moreover, feet interaction can and should be fun!</p><h3 class="c-article__sub-heading" id="Sec3">Foot interaction styles</h3><p>Four groups of devices can be classified, ordered accordingly to their complexity of interaction styles. The first group of devices merely exploits foot interaction for simple toggle actions in hands-busy or hands-dirty situation. Think about foot-controlled transcribers, toilet flushing devices and current switching on professional welding tools. Foot interaction has also been used in experimental setups to perform secondary tasks in virtual reality. For example, a button press can be simulated by tapping the heels of the step WIM shoes [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="LaViola JL, Feliz DA, Keefe D, Zeleznik RC (2001) Hands-free multi-scale navigation in virtual environments, Proceedings of SI3D’01, Research Triangle Park, NC, pp 9–15; doi: 10.1145/364338.364339" href="/article/10.1007/s10055-005-0016-0#ref-CR5" id="ref-link-section-d30864e345">5</a>].</p><p>The second group of devices uses foot interaction to control a single parameter. For example, in sewing machines the speed of the machine is controlled by a foot pedal. Similar controls can be found in devices to control volume and effects of musical instruments.</p><p>The third group consists of devices where the feet are used to control multiple parameters. A well-known application is the control of a car (i.e. clutch, throttle, and brakes). In the HCI world also foot-operated controls are well-known as replacements to the traditional mouse to control the <i>x</i>- and <i>y</i>-co-ordinate. Pearson presented a study on the design of these so-called “moles” already at CHI ‘86 [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Pearson G, Weiser M (1986) Of moles and men: The design of foot controls for workstations, Proceedings of SIGCHI’86, Boston, MA, pp 333–339; doi: 10.1145/22627.22392" href="/article/10.1007/s10055-005-0016-0#ref-CR6" id="ref-link-section-d30864e359">6</a>] (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-005-0016-0#Fig1">1</a>).
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Moles: swing, pendulum, footpanel [source: (6)] © 1986 ACM Inc. Included here by permission</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>The fourth group consists of devices—known as intelligent footwear—equipped with a microcontroller, sensors and actuators. This category forms the foot version of wearable computers. Wearables are worn by people as clothing or accessories and help people retrieve information on site. However, commercial applications, like the Vectra-Sense “Raven ThinkShoe” and “Adidas 1” however, are not intended to interact with the user or another device, but merely to adapt parameters like damping and support according to the environment and activity of the user. Therefore, more interesting members of this group are experimental research studies like the instrumented CyberShoe by Paradiso [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Paradiso JA, Morris SJ, Benbasat AY, Asmussen E (2004) Interactive therapy with instrumented footwear, extended abstracts of CHI’04, Vienna, Austria, pp 1341–1343; doi: 10.1145/985921.986059" href="/article/10.1007/s10055-005-0016-0#ref-CR7" id="ref-link-section-d30864e386">7</a>] (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-005-0016-0#Fig2">2</a>a), which demonstrate novel interaction styles: user tracking, expressive displays, and rehabilitation feedback.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Examples of intelligent footwear. <b>a</b> left MIT CyberShoe [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Paradiso JA, Morris SJ, Benbasat AY, Asmussen E (2004) Interactive therapy with instrumented footwear, extended abstracts of CHI’04, Vienna, Austria, pp 1341–1343; doi: 10.1145/985921.986059" href="/article/10.1007/s10055-005-0016-0#ref-CR7" id="ref-link-section-d30864e405">7</a>] and <b>b</b> right: Gaiter [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Templeman JN, Denbrook PS, Sibert LE (1999) Virtual locomotion: Walking in place through virtual environments, Presence: teleoperators and virtual environments, vol 8, Nr. 6, The MIT Press, Cambridge, pp 598–617" href="/article/10.1007/s10055-005-0016-0#ref-CR9" id="ref-link-section-d30864e411">9</a>]</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Furthermore, in virtual reality applications, sensor-based foot interaction is used for instance as locomotion interface that enables users to move through virtual spaces on foot. This is one of the unsolved problems in virtual environment systems research [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Whitton MC, Cohn JV, Feasel J, Zimmons P, Razzaque S, Poulton SJ, McLeod B, Brooks FP (2005) Comparing VE locomotion interfaces, Proceedings of IEEE Virtual Reality 2005, Bonn; doi: 10.1109/VR.2005.25" href="/article/10.1007/s10055-005-0016-0#ref-CR8" id="ref-link-section-d30864e427">8</a>]. Ingenious mechanical locomotion interfaces allow appropriate body movement (leg position, foot steps, etc.) to control walking speed and direction instead of hand-held controllers. An example is the Gaiter [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Templeman JN, Denbrook PS, Sibert LE (1999) Virtual locomotion: Walking in place through virtual environments, Presence: teleoperators and virtual environments, vol 8, Nr. 6, The MIT Press, Cambridge, pp 598–617" href="/article/10.1007/s10055-005-0016-0#ref-CR9" id="ref-link-section-d30864e430">9</a>] system, a sensor-based locomotion control that allows the user to move through a VE by walking in place. The motion of the legs is characterized by force sensors placed on shoe insoles and six-DOF trackers attached to the knees (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-005-0016-0#Fig2">2</a>b). Foot interaction contributes to a higher sense of presence and more natural experience in VE, not only with respect to position, but also by enriching the perception of the environment.</p><p>In the examples mentioned in this section, feet are mostly used for relatively simple tasks like on/off toggle actions (e.g. pedal light switch) or manipulating a single variable (e.g. footmouse). Moreover, the interaction styles mostly involve whole-foot interaction. However, we are interested in more subtle sub-foot interaction styles—both using kinesthetic (“force feedback”) and cutaneous (“touch”) feedback—which in future applications can be used for more complex interactions than adjusting simple parameters. We also intend to incorporate intimacy and emotions by enabling meaningful haptic feedback signals.</p><p>Foot wearables provide opportunities for stimulating P2P communication, free from the desktop. FootIO proposes to design shoe inlays for interpersonal communication. As a basic form of network communication we consider instant messaging. We evaluate the foot interaction device in a haptic instant messaging environment HIM [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Rovers AF, Essen van HA (2004) HIM: A Framework for haptic instant messaging, Extended abstracts of CHI 2004, Vienna, Austria, pp 1313–1316; doi: 10.1145/985921.986052" href="/article/10.1007/s10055-005-0016-0#ref-CR4" id="ref-link-section-d30864e441">4</a>]. FootIO is a research carrier and of course practical issues such as comfort level, aesthetics, acceptance, and massive introduction by the user group remain work in progress.</p><h3 class="c-article__sub-heading" id="Sec4">Interaction possibilities of the feet</h3><p>For designing new interaction styles, a close look at the physical properties of the foot like the sensor and motor skills is necessary.</p><p>The appropriateness of foot interaction for manipulating graphical user interfaces with “non-accurate spatial tasks” has been investigated by Pakkanen and Raisamo [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Pakkanen T, Raisamo R (2004) Appropriateness of foot interaction for non-accurate spatial tasks, Extended abstracts of CHI2004, Vienna, Austria, pp 1123–1126; doi: 10.1145/985921.986004" href="/article/10.1007/s10055-005-0016-0#ref-CR10" id="ref-link-section-d30864e454">10</a>]. They found that when using the foot to control a large trackball that is placed on the floor, feet are on average 1.6 times slower to finish a task (i.e. selecting a picture on the screen), 1.2 times less accurate, and 1.6 times less comfortable when compared to manipulating the same ball with the hands. Earlier Hoffman found that for “accurate tasks” feet are 1.7–2 times slower than hands [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Hoffmann ER (1991) A comparison of hand and foot movement times, Ergonomics 34(4), April, Taylor &amp; Francis, London, pp 397–406; PMID: 1860460" href="/article/10.1007/s10055-005-0016-0#ref-CR11" id="ref-link-section-d30864e457">11</a>]. Although foot interaction is not as fast as hand interaction, these experiments show that foot interaction still appears fast enough for many tasks.</p><p>Research to the foot’s sensory system has shown that all basic nerve types which are present in the hand, i.e. both types of slow adapting (SA-I and SA-II) and both types of fast adapting mechanoreceptors (FA-I and FA-II) are also present over the whole sole of the foot [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Trulsson M (2001) Mechanoreceptive afferents in the human sural nerve, Exp Brain Res 137:111–116; PMID: 11310164" href="/article/10.1007/s10055-005-0016-0#ref-CR12" id="ref-link-section-d30864e463">12</a>] (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-005-0016-0#Fig3">3</a>). However, the sensitivity of the foot is lower because the spatial distribution of sensors over the foot is less dense and skin beneath the foot usually is thicker compared to the hand. Also the fact that most humans are not trained to use feet as sensing device, makes accurate vibration detection with the feet more difficult. Although both motor skills and perception qualities of the feet are poor compared to the—extremely accurate—haptic qualities of the hand, we are convinced that these are sufficient to enable many new interaction styles.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Location and relative size of receptive fields of 104 mechanoreceptors located in the skin of the foot for slowly adapting (<i>SA</i>) and fast adapting (<i>FA</i>) units. The <i>dotted line</i> indicates the border between the glabrous (“hairy”) and non-glabrous skin (source [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Trulsson M (2001) Mechanoreceptive afferents in the human sural nerve, Exp Brain Res 137:111–116; PMID: 11310164" href="/article/10.1007/s10055-005-0016-0#ref-CR12" id="ref-link-section-d30864e488">12</a>])</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                </div></div></section><section aria-labelledby="Sec5"><div class="c-article-section" id="Sec5-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec5">Layered protocols haptic interaction model</h2><div class="c-article-section__content" id="Sec5-content"><p>This section presents the interaction model that is the theoretical framework in our research explorations into new haptic interaction styles. Our approach is to combine more or less traditional communication models (mainly based on abstract notions of message, transmission, and encoding of information) with modern insights from Human Computer Interaction theories [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Essen HA van, Rovers AF (2005) Layered protocols approach to analyze haptic communication over a network, Proceedings of World Haptics 2005, Pisa, Italy; doi: 10.1109/WHC.2005.85" href="/article/10.1007/s10055-005-0016-0#ref-CR13" id="ref-link-section-d30864e509">13</a>]. We apply the method of layered protocols (LP) to formulate a new interaction model that adequately describes haptic communication between two persons over a network. The LP approach was designed in the eighties by Taylor [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Taylor MM (1988) Layered protocols for computer-human dialogue I: principles. Int J Man Mach Stud 28:175–218" href="/article/10.1007/s10055-005-0016-0#ref-CR14" id="ref-link-section-d30864e512">14</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Taylor MM (1988) Layered protocols for computer-human dialogue II: some practical issues. Int J Man Mach Stud 28:219–257" href="/article/10.1007/s10055-005-0016-0#ref-CR15" id="ref-link-section-d30864e515">15</a>] and separates interaction into multiple levels where each lower level provides a more detailed description of the processes in the level above. For each level, the relationship between input and output can be described explicitly by protocols.</p><p>The resulting interaction model distinguishes all interactions and their corresponding protocols at different levels of the haptic communication channel: the interpretation in the brain, the psychophysical properties of the human sensory system, and the specifications of the particular haptic device and network connection, which are used. The goal of the model is threefold, firstly it is a tool to analyze haptic interaction projects to identify problems and opportunities, second, it directs to solution areas of these problems and opportunities in terms of theory and knowledge in different areas of science and design, and thirdly it helps propose design guidelines for new devices for haptic interaction.</p><p>In subsection <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-005-0016-0#Sec6">3.1</a> the new LP haptic interaction model is presented and briefly explained. A detailed, constructive description of the model can be found in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Essen HA van, Rovers AF (2005) Layered protocols approach to analyze haptic communication over a network, Proceedings of World Haptics 2005, Pisa, Italy; doi: 10.1109/WHC.2005.85" href="/article/10.1007/s10055-005-0016-0#ref-CR13" id="ref-link-section-d30864e526">13</a>], but the model is still being extended. In subsection <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-005-0016-0#Sec7">3.2</a> we indicate the opportunities of the model to consider the haptic communication problem from the perspective of different fields of science, and indicate opportunities to analyze a particular device in depth. Subsequent, in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-005-0016-0#Sec8">4</a>, the model is a backbone for a thorough classification and evaluation process of haptic communication devices.</p><h3 class="c-article__sub-heading" id="Sec6">Haptic interaction model</h3><p>The top, or fourth, layer of the interaction model depicted in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-005-0016-0#Fig4">4</a>, is based on the generic structure of traditional communication models and describes the exchange of messages and required transformations (i.e. encoding and decoding) between communication partners. In our model, this mental layer describes the transformation of intended messages to intended haptic actions.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Layered protocol interaction model for haptic communication over a network</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>As described by theories from both cognitive and ecological psychology, a “performer” (only existing in the brain of the communicating partners) generates a communicable action based on the communication intentions of the person, on previous messages, on knowledge of the remote partner and communication device (represented by a mental model interacting with the performer), and on (triggering) events from outside.</p><p>Depending on the modality, different theories can be used to describe the transition from intended message to intended action. This often involves a mapping between different modalities. Also the intuitiveness of the mapping should be considered [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Wickens CD, Gordon SE, Liu Y (1998) An introduction to human factors analysis. Addison-Wesley Inc., Reading, MA" href="/article/10.1007/s10055-005-0016-0#ref-CR16" id="ref-link-section-d30864e568">16</a>].</p><p>When communicating through a (haptic) communication device, it is assumed that the user will be aware of the communication device, knows how to operate the device and therefore create his or her intentions accordingly. Gibson’s theory on affordances can be included in the transform block to describe the device interactions by the user [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Gibson JJ (1979) The ecological approach to visual perception. Houghton Mifflin, Boston, MA" href="/article/10.1007/s10055-005-0016-0#ref-CR17" id="ref-link-section-d30864e574">17</a>–<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Norman DA (1988) The design of everyday things. The MIT press, Cambridge, MA" href="/article/10.1007/s10055-005-0016-0#ref-CR19" id="ref-link-section-d30864e577">19</a>]. In addition, presence theories can be used to evaluate to what extend mediated messages from different modalities can generate a sense of “being together” between two remote communication partners [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="IJsselsteijn WA (2004) Presence in Dept, PhD Thesis, Eindhoven University of Technology, J.F. Schoutenschool for User-System Interaction Research" href="/article/10.1007/s10055-005-0016-0#ref-CR20" id="ref-link-section-d30864e580">20</a>].</p><p>However, essential for the LP approach, the intended action link between the transformed output of the sender and the input of the interpreter at the receiving side can be considered as being only virtual because the real communication does not take place in the brains of the performers but rather at a lower level: the human sensory system.</p><p>The physical layer describes the transformation between intended and actual haptic actions due to motor and perception limitations of the human body. Many experiments have been reported in scientific literature, which describe both the perception and motor possibilities and limitations of the human body in terms of bandwidths, reaction times and absolute ranges. The fact that perception and motor skills can influence one another is represented in the model by a “cross talk” connection in the new layer.</p><p>Again, haptic communication does often not take place directly between two users, but through a device or shared object. The actual signal will be disturbed at a lower layer where the real data communication takes place. The second, or device layer, introduces a sensor and actuator layer, combined with a controller.</p><p>The device layer describes the transformation of the message caused by technological limitations and transformations in the haptic communication device. In contrast to the two top layers, detailed mathematical models and well-defined technical characteristics can be used to describe signal transformation in the device accurately. The controller block of the device forms the intelligent part of the device and its contents typically depend on the application ranging from basic signal processing, to artificial intelligence, to emotional and affective models. Because actuator and sensor can influence each other, a cross talk connection is introduced in the model.</p><p>The controller in the device also initiates communication between the haptic devices over the actual information carrier, be it a copper wire or a wireless internet connection. Therefore, the coded signal connection between the two controllers is merely virtual: in reality the controllers will be connected through a network. The network layer describes the actual link between the two communication partners in our model. An introduction to network properties and their influence on remote operation is provided by Oboe [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Oboe R (2001) Web-interfaced, force-reflecting teleoperation systems. IEEE Trans Ind Electron 48(6):1257–1265" href="/article/10.1007/s10055-005-0016-0#ref-CR21" id="ref-link-section-d30864e595">21</a>]. The relationship between network properties and the perception of haptic cues is investigated by Souayed [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Souayed GT, Gaiti D, Yu W, Dodds G, Marshall A (2004) Experimental study of haptic interaction in distributed virtual environments. Proceedings of Eurohaptics, Munchen, Germany, pp 260–266" href="/article/10.1007/s10055-005-0016-0#ref-CR22" id="ref-link-section-d30864e598">22</a>].</p><p>Of course this final layer can also be further divided into lower layers, which describe network communication on the level of bits and electric pulses. For our purposes (i.e. haptic communication over the internet) sufficient protocols and IO models exist at this level to consider the network connection as the “real connection”.</p><h3 class="c-article__sub-heading" id="Sec7">Analysis of haptic communication devices</h3><p>This subsection describes three different application opportunities for using the model to analyze a particular device [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Essen HA van, Rovers AF (2005) Layered protocols approach to analyze haptic communication over a network, Proceedings of World Haptics 2005, Pisa, Italy; doi: 10.1109/WHC.2005.85" href="/article/10.1007/s10055-005-0016-0#ref-CR13" id="ref-link-section-d30864e612">13</a>]. These three opportunities are analysis per layer, analysis of the horizontal virtual layers and analysis of the vertical actual information stream, respectively.</p><p>First, as indicated above, the interaction model identifies relevant theories per single layer. This provides opportunities for analyzing devices or processes, to identify problems and opportunities and direct to solution areas in terms of existing theory and expertise per layer.</p><p>Second, the virtual links (that have been made explicit in the LP approach) and their perception can be analyzed. The contents of the lower layers deviate more and more from the perceived communication process in the top layer. Still, communication partners will probably be only conscious of the things, which are happening in the top layer. When designing the contents of a certain layer, only the quality and the content of the signal that is directly entering and leaving the layer are relevant. The actual processes in the lower layers can be neglected while their effect remains present.</p><p>Finally, the actual information streams between the layers can be analyzed. Although the model representation might suggest that only a single, continuous information stream flows between the layers, signals obviously can have a discrete character and can comprise information from more than one modality.</p><p>The information streams reflect both the quality of the communicated message as well as the design requirements for particular functionality in devices.</p><p>As the user’s intention is recursively encoded into sub-intentions until it finally has been transformed into a sequence of actions at the bottom layer, the quality of the communicated message propagates from the lower to higher layers. This implies that the user level of satisfaction depends on how well the lower levels have been designed and implemented. On the other hand, the design requirements, i.e. “what” needs to be communicated to a lower layer with “what quality”, propagate from higher to lower layers. This implies that the designer of a layer needs to be aware of the next higher level intentions. Moreover, the design requirements do not simply add up to a list of requirements for the bottom layer, but propagate in a secondary way through the specification of the quality properties of the IO signals of the layer. This analysis provides insight where important (problems with) message transformations occur.</p></div></div></section><section aria-labelledby="Sec8"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Classification: deriving new design guidelines</h2><div class="c-article-section__content" id="Sec8-content"><p>The previous section demonstrates that insights from existing theory per layer can be used to better understand and fine-tune behavior of specific devices. However, the insights in correlations between theoretical properties and system behavior (e.g. user experience, signal transformations, and communication goals) obtained during the design process of one device do not have to be generic and applicable when designing another device. This section presents a methodology to derive new design guidelines by comparing and classifying existing communication devices by a four-step approach.</p><p>A four-step classification process compares different existing communication devices to obtain insight in the correlations between theoretical properties and system behavior, leading to new design guidelines.</p><h3 class="c-article__sub-heading" id="Sec9">Selection of devices</h3><p>As a first step in the classification process, a set of fourteen haptically enriched communication devices have been selected. This set comprises some classical conceptual projects, is representative for all projects, and is sufficiently diverse and rich to enable deriving new design guidelines (i.e. coverage of all parameters in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab1">1</a>). The diverseness of the set can be illustrated by considering the following five brief descriptions: </p><ol class="u-list-style-none">
                    <li>
                      <span class="u-custom-list-number">(a)</span>
                      
                        <p>
                                    <i>InTouch</i> [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Brave S, Dahley A (1997) Intouch: medium for haptic interpersonal communication, Extended abstracts of CHI’97, Atlanta GA, pp 363–364" href="/article/10.1007/s10055-005-0016-0#ref-CR2" id="ref-link-section-d30864e659">2</a>]: two sets of three cylindrical rollers act as if they are physically connected. This enables two persons, separated by distance, to interact by creating the illusion of manipulating a shared object. A feeling of presence is communicated by using haptics.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">(b)</span>
                      
                        <p>
                                    <i>Telephonic arm wrestling</i> [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="White N, Back D (1986) Telephonic arm wrestling. The strategic arts initiative symposium, Italy" href="/article/10.1007/s10055-005-0016-0#ref-CR23" id="ref-link-section-d30864e676">23</a>]: two motorized force-transmitting systems are interconnected by a telephonic data-link and enable two contestants, in different cities, to arm-wrestle. Explicit information (i.e. “Feel how strong I am”) is communicated.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">(c)</span>
                      
                        <p>
                                    <i>Connexus</i> [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Paulos E (2003) Connexus: A communal interface”. Tech.Report IRB-TR-03-011, Intel Research" href="/article/10.1007/s10055-005-0016-0#ref-CR24" id="ref-link-section-d30864e693">24</a>]: a wearable device that uses a rich set of sensors and actuators (i.e. temperature, vibration motor, accelerometer, microphone, etc.) to communicate the basic knowledge of a persons state to each other.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">(d)</span>
                      
                        <p>
                                    <i>Plesio phone</i>: <i>air phone</i> [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Fels S, Takahashi S, Chung C (2001) PlesioPhone: An cell phone and telephone based interactive artwork, (&#xA;                    http://hct.ece.ubc.ca/research/plesiophone&#xA;                    &#xA;                  )" href="/article/10.1007/s10055-005-0016-0#ref-CR25" id="ref-link-section-d30864e713">25</a>]: conceptual communication device in which two persons talk to each other through plastic masks on their faces connected to each others ears by a plastic tube. This enables them to carry their private space with them while they walk and communicate intimate body signals (i.e. respiration and breath).</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">(e)</span>
                      
                        <p>
                                    <i>Haptic IM</i> [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Rovers AF, Essen van HA (2004) HIM: A Framework for haptic instant messaging, Extended abstracts of CHI 2004, Vienna, Austria, pp 1313–1316; doi: 10.1145/985921.986052" href="/article/10.1007/s10055-005-0016-0#ref-CR4" id="ref-link-section-d30864e730">4</a>]: instant messenger application extended with haptic icons and vibration input and output devices. This project demonstrates the enrichment of an explicit communication tool with a haptic channel.</p>
                      
                    </li>
                  </ol><p>For the full set of selected projects please refer to Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab1">1</a> and the references therein [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Brave S, Dahley A (1997) Intouch: medium for haptic interpersonal communication, Extended abstracts of CHI’97, Atlanta GA, pp 363–364" href="/article/10.1007/s10055-005-0016-0#ref-CR2" id="ref-link-section-d30864e740">2</a>–<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Rovers AF, Essen van HA (2004) HIM: A Framework for haptic instant messaging, Extended abstracts of CHI 2004, Vienna, Austria, pp 1313–1316; doi: 10.1145/985921.986052" href="/article/10.1007/s10055-005-0016-0#ref-CR4" id="ref-link-section-d30864e743">4</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="White N, Back D (1986) Telephonic arm wrestling. The strategic arts initiative symposium, Italy" href="/article/10.1007/s10055-005-0016-0#ref-CR23" id="ref-link-section-d30864e747">23</a>–<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Hansson R, Skogg T (2001) The LoveBomb: Encouraging the communication of emotions in public space, Extended abstracts of CHI’01, pp 433–434; doi: 10.1145/634067.634319" href="/article/10.1007/s10055-005-0016-0#ref-CR33" id="ref-link-section-d30864e750">33</a>].
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Classification step 2 technical parameters directly related to the layers of the model</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-005-0016-0/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <h3 class="c-article__sub-heading" id="Sec10">Classification in parameters per layer</h3><p>A second step in the classification process is the introduction of a fixed set of classification parameters, which allows comparison between devices. This set of parameters closely relates to the LP interaction model: the parameters are grouped per layer. Each parameter is defined by properties in corresponding theory and terminology.</p><p>All devices have been studied in detail. Information published by the corresponding authors is used to assess the parameters. Whenever explicit technical or user evaluation data is not available, common sense, and results from similar devices are used to fill the blank spots.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec11">Layer 4: mental</h4>
                    <ol class="u-list-style-none">
                      <li>
                        <span class="u-custom-list-number">(a)</span>
                        
                          <p>
                                        <b>Goal</b>, the main intention of the communication event: explicit information exchange, support a feeling of presence, convey emotion.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">(b)</span>
                        
                          <p>
                                        <b>Participants</b> setup: one-to-one, many-to-many, and one-to-many.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">(c)</span>
                        
                          <p>
                                        <b>Language</b>, type of enriched signals used: based on an intuitive or using a pre-defined coded language.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">(d)</span>
                        
                          <p>
                                        <b>Consciousness</b>: level of user awareness of content being communicated to the other party, <i>conscious</i>, or <i>subconscious</i>.</p>
                        
                      </li>
                    </ol>
                  <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec12">Layer 3: physical</h4>
                    <ol class="u-list-style-none">
                      <li>
                        <span class="u-custom-list-number">(a)</span>
                        
                          <p>
                                        <b>Modality</b>, the essence of the communication is uni-modal or multi-modal.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">(b)</span>
                        
                          <p>
                                        <b>Mapping</b>, the transformation between intended message to intended action can be skewed across different modalities.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">(c)</span>
                        
                          <p>
                                        <b>Haptics</b>, the type of signals used in communication: kinesthetic, cutaneous vibrations, or cutaneous other (i.e. temperature) signals.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">(d)</span>
                        
                          <p>
                                        <b>LocationIO</b>: the location of the input (sensors) and output (actuators) of the device can be located at the same spot or different spots on the body.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">(e)</span>
                        
                          <p>
                                        <b>Nonverbal</b>, the impact of the haptic channel relative to possible non-verbal channels in the whole communication stream.</p>
                        
                      </li>
                    </ol>
                  <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec13">Layer 2: device</h4>
                    <ol class="u-list-style-none">
                      <li>
                        <span class="u-custom-list-number">(a)</span>
                        
                          <p>
                                        <b>Feedback</b> between user and device can be continuously generated, only when user explicitly asks for it, or at special events.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">(b)</span>
                        
                          <p>
                                        <b>Direction</b> of signal transmission can be uni-directional (i.e. only in one direction; one sender and one receiver), bi-directional (data exchanged in both directions over one signal carrier) or two times uni<i>-directional</i> (data exchange in both directions over two separate channels).</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">(c)</span>
                        
                          <p>
                                        <b>Timing</b> of communication between device and network/data exchange can be generated continuously, only when remote device or network explicitly asks for it or at event base.</p>
                        
                      </li>
                    </ol>
                  <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec14">Layer 1: network</h4>
                        <ol class="u-list-style-none">
                      <li>
                        <span class="u-custom-list-number">(a)</span>
                        
                          <p>
                                        <b>Mode</b> of net work communication by a turn-taking mechanism (asynchronous) or simultaneously (synchronous).</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">(b)</span>
                        
                          <p>
                                        <b>Buffering</b>, signals can be <i>buffered</i> or only sent once (<i>unbuffered</i>) with the risk of not being read by the other party.</p>
                        
                      </li>
                    </ol><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab1">1</a> shows the resulting classification. All scales are proportional to the appropriate property. The size of the bullets determine to what extend the properties hold for the device.</p><p>This table helps to understand devices, provide more insight in concept and operating principle, and identify problem and solutions areas in terms of specifications. Although possible, the table is not intended to seek correlations between different theoretical parameters (such as for example “consciousness” and “at event feedback”) because this does not take the goal or context of the communication device in mind and might be too device specific. More insight on such correlation can be obtained by using the associated theories, as discussed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-005-0016-0#Sec6">3.1</a>. In addition, the table is not suited to indicate niche design opportunities for “new” devices because the set of selected devices was deliberately limited to a representative selection.</p><h3 class="c-article__sub-heading" id="Sec15">Evaluation and meta properties</h3><p>The main function of Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab1">1</a> is to support finding correlations between classification parameters and overall system behavior (e.g. user experience, signal transformations, and communication goals), which cannot be found by using a theoretical approach only. Therefore, in a third step in the classification process, overall remarks about the strengths and weaknesses of the devices have been collected by using available evaluations of the existing devices. These evaluations comprise user experiences, formal user tests, knowledge from design practice, and intended design goals. From the collection of remarks, a list of similar remarks for different devices has been compiled. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab2">2</a> presents a part of this list with remarks, which are relevant for the FootIO design.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Classification step 3a similar system behavior remarks for different devices</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-005-0016-0/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Although the classification with the theoretical parameters in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab1">1</a> provides many new insights and can result in new design guidelines, there are still properties of devices that cannot be assigned to a single parameter. From the selected remarks in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab2">2</a>, a second classification scheme with meta properties has been defined which helps to indicate these hidden correlations. These meta properties are:</p><ol class="u-list-style-none">
                    <li>
                      <span class="u-custom-list-number">(1)</span>
                      
                        <p>
                                    <b>Intimacy</b>: perceived intimacy.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">(2)</span>
                      
                        <p>
                                    <b>Concealed</b> communication: to what extend is the communication hidden for the environment.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">(3)</span>
                      
                        <p>
                                    <b>Supported actions</b>: to what extend is the user convinced that the device correctly supports his/her actions.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">(4)</span>
                      
                        <p>
                                    <b>Expressiveness of actions</b>: to what extend do the communicated actions and events enable the user to express meaning.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">(5)</span>
                      
                        <p>
                                    <b>Perceived delay</b>: significance of the delay perceived by the user (for e.g. in arm wresting the user will experience a delay of 0.1 s as long while a delay of seconds or even minutes doesn’t have to be annoying in instant messaging).</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">(6)</span>
                      
                        <p>
                                    <b>Expiration</b>: how long remains the received message “valid” or “meaningful”.</p>
                      
                    </li>
                  </ol><p>In contrast to the theoretical parameters that directly relate to layers in the model, meta-parameters are often linked to multiple layers simultaneously. For example, “expressiveness of action” is not only influenced by the associations/meanings that exist in the mental layer, but also by the motor skills of the user, and by the technical features of the device.</p><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab3">3</a> shows the classification with this set of parameters. All scales are proportional. The size of the bullets determine to what extend the properties hold for the device.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Classification step 3b meta properties that don’t directly relate to model layers</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-005-0016-0/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <h3 class="c-article__sub-heading" id="Sec16">New design guidelines</h3><p>By correlating the user remarks from the previous subsection with the technical parameters (Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab1">1</a> and <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab3">3</a>) and with the meta properties (Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab2">2</a> and <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab3">3</a>), new design guidelines can be derived. For example, the design guidelines, which are most relevant for the FootIO design are:</p><ol class="u-list-style-none">
                    <li>
                      <span class="u-custom-list-number">(1)</span>
                      
                        <p>An illusion of manipulating a shared object can be generated by putting the input and output spot closely together on the body of the operator. This can be illustrated by comparing devices like InTouch, HandJive, and Telephonic Arm wrestling, with devices that use separated input output systems like ComTouch, Connexus and ContactIM. Note that according to our model problems can occur when motor skills and perception (or actuator and sensors in layer 3) interfere.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">(2)</span>
                      
                        <p>The cognitive workload for operating a device can be decreased by using associations, which people already have. For example, the HapticIM system uses vibration signals, which are associated with their intended meaning. Also the Bed and the Heart2Heart support this finding.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">(3)</span>
                      
                        <p>Device interaction can be enriched and made more interesting by using multimodal interaction that provides multiple information streams simultaneously. For example, see the reviews of Connexus, The Bed and the 2Hearts Project.</p>
                      
                    </li>
                  </ol><p>The meta properties are introduced during the correlation process to capture design guidelines which would otherwise not have been identified. When these design guidelines are applied in the design process for a new device, the meta properties need to be specified in terms of technical parameters.</p></div></div></section><section aria-labelledby="Sec17"><div class="c-article-section" id="Sec17-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec17">FootIO</h2><div class="c-article-section__content" id="Sec17-content"><p>A foot interaction device has been constructed as a research carrier to investigate both the opportunities for local interface interaction and for haptic interpersonal communication with the feet. This section first introduces the design of the FootIO prototypes, followed by the results of the user experiments. We interpret some results by using the interaction model and design guidelines presented in the previous section.</p><h3 class="c-article__sub-heading" id="Sec18">Implementation of the prototype</h3><p>As our research aims to explore the interaction opportunities of the feet, it focuses on two aspects of interaction: first, local interface interaction with the device, and secondly interpersonal communication using the device. Both aspects are studied with respect to input and output capabilities of the device.</p><p>Although eventually these interaction devices will be embedded in an “intelligent” shoe, the FootIO prototype has been implemented as a food-bed-shaped device to evade problems with respect to miniaturization, robustness, and power consumption. The foot-bed shape is not only natural and similar to the shape of a shoe, but also fixates the position of the foot relative to the actuators. For now only the input opportunities of the foot will be explored. A prototype with actuators at 15 locations has been constructed. In the near future, the device will be equipped with sensors to enable full interface control by foot interaction. Because the FootIO device does not have input capabilities yet, another external device needs to be used for input to explore the communication objectives.</p><p>To facilitate the design of advanced interaction styles—like generating haptic vibration patterns [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Rovers AF, Essen HA van (2004) Design and evaluation of hapticons for enriched instant messaging, Proceedings of EuroHaptics’04, Munich, Germany" href="/article/10.1007/s10055-005-0016-0#ref-CR34" id="ref-link-section-d30864e1271">34</a>]—a matrix of tactors (vibration actuators, i.e. pager motors) will be embedded in the FootIO device. Because the receptive resolution of the foot is low, and because sensory saltation (i.e. the illusion that a set of spaced-apart taps is perceived as one continuous stroke) effects might be used to generate phantom stimuli at locations in-between the actual tactor locations [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Tan H, Lim A, Taylor R (2000) A Psychophysical study of sensory saltation with an open response paradigm, DSC vol 69-2. Proc ASME Dyn Syst Control Div 2:1109–1115" href="/article/10.1007/s10055-005-0016-0#ref-CR35" id="ref-link-section-d30864e1274">35</a>], the number of actuators can be limited. Cross talk between actuators (i.e. propagation of vibrations from a tactor over the whole foot-bed) needs to be restricted.</p><p>Different type of stimuli can be offered, varied in amplitude and frequency content. In order to be able to generate patterns, the vibration amplitude of the individual tactors needs to be controllable. Van Erp [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Erp JBF van (2002) Guidelines for the use of vibro-tactile displays in human computer interaction, Proceedings of EuroHaptics’02" href="/article/10.1007/s10055-005-0016-0#ref-CR36" id="ref-link-section-d30864e1280">36</a>] has formulated general guidelines (not foot specific), for cutaneous vibration stimuli. According to this study, only four absolute vibration intensity levels can be detected. For FootIO, however, no absolute encoding or static signals will be used. Instead, it is more likely that people will be sensitive for changes in the signal. To generate fluently changing vibration signals, and to be able to create high quality haptic effects, clearly more amplitude levels per tactor are required. Fifteen or more levels provide sufficient freedom of design when a matrix of tactors is used to stimulate a foot. Van Erp also showed that the temporal sensitivity of vibration perception is high: up to 10 ms time pulses and gaps can detected when using a single actuator in a tactile array. This defines the timing and bandwidth of the actuators.</p><p>As actuators, ordinary pager motors (1E110) where selected for the tactors. These actuators are not only cheap, but are also small enough to embed in real shoes in more advanced prototypes in the near future. When a constant DC voltage is applied to the motor, a vibration with a fixed combination of amplitude and frequency results. Both amplitude and frequency of the vibration increase with increasing voltage. In order to prevent cross talk between tactors, they are mechanically isolated from the food bed by means of embedding the tactors freely in an oversized hole, fixed with a silicone gel at the bottom (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-005-0016-0#Fig5">5</a>). A sliced PVC bead has been attached to the tactor to improve the vibration transfer to the user and also to make the actuator location more clear.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Tactor fixation</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>The vibration intensity of the tactors is controlled by a custom microcontroller board. At the PC, a control library has been implemented in C# to communicate with the microcontroller and control the hardware. The library contains straight forward control commands which enable users to easily implement patterns for the FootIO and do rapid prototyping of interaction styles. In addition, the library can easily be linked to applications that facilitate interaction research, and is compatible with the HapticIM system that has been created earlier to easily explore haptic interaction over a computer network</p><p>The HapticIM system [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Rovers AF, Essen van HA (2004) HIM: A Framework for haptic instant messaging, Extended abstracts of CHI 2004, Vienna, Austria, pp 1313–1316; doi: 10.1145/985921.986052" href="/article/10.1007/s10055-005-0016-0#ref-CR4" id="ref-link-section-d30864e1313">4</a>] provides all features of a regular client/server-based messenger such as seeing who is online and sending text messages. In addition the HapticIM system allows the implementation of haptic icons that can be triggered by using special input devices or by using a special hapticons code (comparable to “smileys”) in the message. If a keyboard is used as input device, than text messages and codes trigger the FootIO vibration patterns (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-005-0016-0#Fig8">8</a>). An output plug-in has been created that links to the FootIO library. The HapticIM client application takes care of the network communication and coupling between the messages and the FootIO hardware.</p><h3 class="c-article__sub-heading" id="Sec19">Preliminary experiment and improvement of prototype</h3><p>One of the obvious problems when designing a foot interaction device is the form factor. Not only the fact that foot dimensions differ significantly among people, but also the poor “grasping” capability of the foot, make it difficult to determine the optimal location of sensors and actuators in the device. Therefore, the device or the location of the actuators needs to be scalable or at least fit for most people.</p><p>A first prototype has been constructed from separate modules that can be connected to a rail, providing the opportunity to tune the dimensions of the resulting footbed to the foot of the user [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Rovers AF, Essen HA van (2005) FootIO: Design and evaluation of a device to enable foot interaction over a computer network. Proceedings of WorldHaptics 2005, Pisa, Italy, pp 521–522; doi: 10.1109/WHC.2005.56" href="/article/10.1007/s10055-005-0016-0#ref-CR37" id="ref-link-section-d30864e1329">37</a>]. In addition, form studies suggested that eight actuators are sufficient for an initial exploration of foot input capabilities. The eight tactors are placed beneath each toe and at three strategic locations: heel, ball, and midfoot (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-005-0016-0#Fig6">6</a>a). The vibration motors can be controlled with 15 intensity levels per channel at a bandwidth of 100 Hz.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig6_HTML.jpg?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig6_HTML.jpg" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>FootIO <b>a</b> first prototype and (<b>b</b>) final modular/adjustable prototype</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Fourteen design students participated in a series of preliminary perception experiments. A first experiment showed that users are quite able to identify stimuli on single actuators at distinct positions like the big toe and in the middle of the foot. Identification near the small toes was more difficult. The results of a second experiment demonstrated that correctly identifying simple vibration patterns over multiple actuators is more difficult. Participants were asked to sketch the pattern that was “haptically” drawn beneath their left foot on a feedback form. During the experiment eight basic shapes (i.e. toes-left-to-right, vibration from top-to-bottom, etc) were tested with varying pulse-time and overlay parameter. The experiment shows that approximately 29% of the patterns were identified correctly and 35% with a small error. For many applications these scores are probably too low to use foot interaction as an interface element.</p><p>Despite the carefully considered tactor position, the disappointing results are mainly caused by bad contact between the tactors and the foot for individual users. Also the graphical representation, which participants used to express the patterns was difficult to comprehend. Moreover, the results differed in detail and tidiness, making the interpretation of the drawn patterns difficult.</p><p>By using the observations of these preliminary experiments, a second prototype has been constructed (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-005-0016-0#Fig6">6</a>b). In this prototype the longitudinal position of the tactors can again be changed by shifting modules along a rail. In addition, the transversal position of the tactors and the height of the modules have been made adjustable to fit the device more accurately to the width of the foot and to enable a better contact between the tactors and the foot.</p><p>Also the location and number of tactors has been changed. The number of tactors near the small toes has been reduced, while the number of tactors at the remaining part of the foot has been increased to enable projecting vibration patterns in transversal direction and to enable projecting signals with redundancy (i.e. using multiple tactors simultaneously to represent a single signal) to compensate for bad contact between some tactors and the foot.</p><p>The vibration motors are controlled by an improved microcontroller board with 50 intensity levels per channel and a bandwidth of 400 Hz.</p><h3 class="c-article__sub-heading" id="Sec20">Experimental setup</h3><p>According to our research objectives, two types of experiments have been conducted with the new prototype to test the FootIO opportunities. The first set of experiments focuses mainly on the perception capabilities of the user for local interaction with the device (what can be sensed with the FootIO device), while the second set considers the added value of using FootIO in human-to-human communication over a network.</p><p>The experiments were carried out among two groups. The first group consisted of ten design students (age 19–27), while the second group consisted of high school teenagers (age 14–18), which frequently use instant messaging applications to communicate with friends. Prior to each experiment, the FootIO device was adjusted to fit the right foot of the participants.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec21">Perception experiment</h4><p>In the first task, a subset of 28 stimuli semi-randomly selected from the patterns shown in Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab4">4</a>, <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab5">5</a>, <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab6">6</a>, and <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab7">7</a> had to be identified by the participants. During each trial the stimuli was played once, after which the participant had to present the best matching pattern from a multiple choice selection consisting of all patterns listed in the same table. During the experiment music was played to simulate some distraction (of a multi-user task) and to camouflage the sound of the vibration patters (avoid the “what you hear is what you feel” effect).
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 Perception experiment: longitudinal patterns</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-005-0016-0/tables/4"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 Perception experiment: transversal patterns</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-005-0016-0/tables/5"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-6"><figure><figcaption class="c-article-table__figcaption"><b id="Tab6" data-test="table-caption">Table 6 Perception experiment: zigzag patterns</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-005-0016-0/tables/6"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-7"><figure><figcaption class="c-article-table__figcaption"><b id="Tab7" data-test="table-caption">Table 7 Perception experiment: alternating patterns</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-005-0016-0/tables/7"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                    <p>Before starting the experiment, the notation of the vibration pattern was explained to the participants. All participants indicated that the notation was clear for them and could be related to the sample patterns, which were presented. The multiple-choice approach was selected because of the interpretation and notation problems in the earlier experiments. In order to test our hypothesis that using a multiple choice approach is justified, participants were asked to draw the patterns of five stimuli presented in a second task (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-005-0016-0#Fig7">7</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig7_HTML.gif?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig7_HTML.gif" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Example of patterns as recognized by one of the participants</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                    <p>The results from the first task are presented in Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab4">4</a>, <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab5">5</a>, <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab6">6</a>, and <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab7">7</a>. Each row contains the stimuli, which were presented, while the columns indicate how often (percentage) the stimuli was recognized as the pattern shown at the top row. For example, Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab4">4</a> indicates that pattern 0 was recognized correctly as pattern 0 by 98% of the participants and in 2% of the cases as pattern 17. To envision the composition of the error in misinterpretation of the patterns, the full dataset is presented in the tables. Results are discussed in the next subsection.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec22">Negotiation game</h4><p>As the overall goals for our research aim at enriched human-to-human communication over a network, in this experiment we investigate how foot interaction by means of our FootIO prototype can be used for communication between two persons over a network. A qualitative approach is required to research this [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Brave S, Nass C, Sirinian CE (2001) Force-feedback in computer-mediated communication, Proceedings of UAHCI’01, New Orleans, LA" href="/article/10.1007/s10055-005-0016-0#ref-CR38" id="ref-link-section-d30864e1526">38</a>].</p><p>In our haptic instant message application we set up a negotiation game, which challenges the competitors to use the FootIO device and become involved in the game. Once involved in the game a realistic conversation might result.</p><p>According to the story, three pirates find a treasure consisting of golden coins and they agree to play a game to share this treasure. The goal of the game is for each to receive a maximum of coins. The game is played with three participants: two in possession of the FootIO device and a third (instructed) player. During each round of the game, ten coins need to be shared among the three pirates. The rules of the game imply that only participants, which are sufficiently modest, and can convince their fellow-players to give him/her some coins, will receive the claimed coins at the end of the round.</p><p>The catch of the game is that negotiation takes place through the HIM chat-box (where only text can be used). Players are physically separated and emoticons (smileys) to express emotions are strictly prohibited! Instead, the two participants with FootIO are allowed to use the predefined hapticon codes, which generates a FootIO vibration at the other side (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-005-0016-0#Fig8">8</a>). One chat window is used per user, to prevent users from seeing the messages send to the other participant.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig8_HTML.gif?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-005-0016-0/MediaObjects/10055_2005_16_Fig8_HTML.gif" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Hapticons used in the negotiation game</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-005-0016-0/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                    <p>After playing the game, the added value of using haptics is evaluated by an open enquiry.</p><h3 class="c-article__sub-heading" id="Sec23">Discussion of the results</h3><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec24">Perception experiment</h4><p>The perception experiment shows that users are able to identify vibration patterns in the longitudinal direction very accurately (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab4">4</a>, recognition rate 90–100%). In the transversal direction the location of the stimuli is perceived well, but users are not able to identify the direction of the movement sufficiently accurately (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab5">5</a>, recognition rate for moving patterns 45%). Although the direction of a moving pattern is often wrongly interpreted (i.e. wrong direction or static pattern), the transversal static patterns [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Rovers AF, Essen HA van (2004) Design and evaluation of hapticons for enriched instant messaging, Proceedings of EuroHaptics’04, Munich, Germany" href="/article/10.1007/s10055-005-0016-0#ref-CR34" id="ref-link-section-d30864e1580">34</a>–<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Erp JBF van (2002) Guidelines for the use of vibro-tactile displays in human computer interaction, Proceedings of EuroHaptics’02" href="/article/10.1007/s10055-005-0016-0#ref-CR36" id="ref-link-section-d30864e1583">36</a>] are again recognized very well (approximately 90%). The difference between the recognition rate of longitudinal and transversal patterns can be explained by the smaller number of tactors, tighter spacing, and stronger mechanical coupling in the transversal direction. These effects are also explained by theories of layer 2 (psychophysics: spacing of receptors) and layer 3 (device: cross talk between actuators) of the interaction model.</p><p>Participants indicate that selecting the appropriate patterns from Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab6">6</a> was difficult because they are not able to remember the exact pattern once the stimulus was played. Only when the stimulus ends at a distinct position like the big toe or heel, they have confidence in the correctness of their selected answer. These results are partly explained by the difficulty of recognizing transversal patterns, but also by effects that occur in the mental layer of the interaction model; humans have difficulties in remembering sequences of several items [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Wickens CD, Gordon SE, Liu Y (1998) An introduction to human factors analysis. Addison-Wesley Inc., Reading, MA" href="/article/10.1007/s10055-005-0016-0#ref-CR16" id="ref-link-section-d30864e1592">16</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Norman DA (1988) The design of everyday things. The MIT press, Cambridge, MA" href="/article/10.1007/s10055-005-0016-0#ref-CR19" id="ref-link-section-d30864e1595">19</a>]. However, once familiar with the graphic representation of the patterns, users should be able to identify these patterns better (if triggered prior to playing).</p><p>The alternating patterns from Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-005-0016-0#Tab7">7</a> were not recognized accurately during the experiment. Perceived cross talk between stimuli made users doubt between stimulus 39 and 37/38, respectively.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec25">Negotiation game</h4><p>The inquiry held after playing the negotiation game shows a major difference between the opinion of the teenager and the students-group. Teenagers were more enthusiastic and were intrigued by the idea of using text, smileys, and hapticons at the same time. In contrast, the students responded more commonsensical and reserved.</p><p>Both groups indicated that the “thunder” and “swirl” hapticons were most used.</p><p>This can not only be explained by the fact that their meaning was more clear than “forward” and “backward”, but also because of the lower cognitive workload. Although participants were able to differentiate between “backward” and “forward” during the perception experiments, they were not able during the chat-game because there already was a too high workload caused by the chat and negotiation game itself. This effect has already been explained by layer 1 of the interaction model and the design guidelines presented in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-005-0016-0#Sec10">4.2</a>. However, also the suggestive names might have had a significant influence.</p><p>The hapticons were not only used to enrich the chat message, but also used to ask attention from the chatter when he or she didn’t respond sufficiently fast. This appeared to work, for users were tempted to have a look at the chat window of the FootIO chatter even when being in conversation with the non-FootIO chatter. In addition the bond with the FootIO chatter was described often as “stronger” and “more fun”. Especially the teenager group was convinced that the interpretation of the hapticon messages was the same for both FootIO chatters, but still liked to have a list with a predefined meaning of the signals (“just as with emoticons”).</p><p>Many participants indicated that it was difficult to image the feeling of the other person. This was not only caused by the lack of a monitor function (i.e. feel yourself what you send), but also by the decoupling of input (i.e. foot) and output (i.e. keyboard and hands). In general, the use of the hapticons is seen as fun, and receiving the patterns is indicated as nicer than sending the patterns. Finally, the teenagers’ judgment of the device may be influenced by the looks of the device; they experienced the device as “big” and “complicated” and found it difficult to image the final (wearable) product. The student group already was familiar with the application of (rough) prototypes and didn’t explicitly make this remark.</p></div></div></section><section aria-labelledby="Sec26"><div class="c-article-section" id="Sec26-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec26">Discussion and conclusions</h2><div class="c-article-section__content" id="Sec26-content"><p>A new device that enables foot interaction has been build and evaluated. Experiments and user tests provide clues for designing stimuli (i.e. vibration patterns which are drawn on the sole of the foot), which can be perceived sufficiently accurate (&gt;80%) to be used in an interface:</p><ol class="u-list-style-none">
                  <li>
                    <span class="u-custom-list-number">(1)</span>
                    
                      <p>When using moving vibration patterns, these should preferably be encoded in the longitudinal direction because this enables for a bigger number of tactors, and an increased spacing between the tactors.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">(2)</span>
                    
                      <p>In the transversal direction users are able to detect the location of vibration patterns. Users recognized a static pattern correctly as “static”, but “moving” patterns caused confusion; users were not able to tell the direction of the movement or identified the pattern as “static”.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">(3)</span>
                    
                      <p>Recognizing more complex patterns like a “zigzag” is difficult because of the cognitive workload and challenge to remember complex patterns. However, when using natural associations or metaphors, the cognitive workload can be lowered and patterns can be identified correctly.</p>
                    
                  </li>
                </ol><p>In order to test the effect of using foot interaction in communication, the FootIO device has been connected to the haptic instant messenger application and a negotiation game has been played. Although the meaning of the hapticons, which were used during the experiment was not yet unambiguous, all users used the hapticons abundantly to draw attention and emphasize certain messages. All users experienced the addition of haptic effects as “more fun” and “richer”. We showed that the design of the FootIO system can also be used as a research carrier to evaluate opportunities to investigate generic design guidelines for haptic interpersonal communication devices.</p><p>We demonstrated the usefulness of using a LP approach to analyze haptic communication between two users over a computer network for a particular device. We also showed that our model can be used as a backbone to derive generic design guidelines for new haptic communication devices, by classifying existing communication devices and linking their strong and weak points to parameters of the model. The LP model makes the haptic communication process more transparent.</p><p>The design of the FootIO system illustrated that this approach enables to perform a more structured analysis of the foot interaction device by pointing to existing theories in the different layers of the model. In addition, the findings from the negotiation game are in line with the design guidelines.</p><p>Concluding, we state that a model based approach has an added value when designing new interaction devices. By designing more prototypes, not only of FootIO but also with other haptic interaction styles, we will study the remaining parameters of the model and derive more design guidelines.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="RC. Ling, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Ling RC (2004) The mobile connection: The cell phone’s impact on society. Morgan Kaufmann Publishers Inc., San" /><span class="c-article-references__counter">1.</span><p class="c-article-references__text" id="ref-CR1">Ling RC (2004) The mobile connection: The cell phone’s impact on society. Morgan Kaufmann Publishers Inc., San Fransisco, Los Altos, CA</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20mobile%20connection%3A%20The%20cell%20phone%E2%80%99s%20impact%20on%20society&amp;publication_year=2004&amp;author=Ling%2CRC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Brave S, Dahley A (1997) Intouch: medium for haptic interpersonal communication, Extended abstracts of CHI’97," /><span class="c-article-references__counter">2.</span><p class="c-article-references__text" id="ref-CR2">Brave S, Dahley A (1997) Intouch: medium for haptic interpersonal communication, Extended abstracts of CHI’97, Atlanta GA, pp 363–364</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chang A, O’Modhrains S, Jacob R, Gunther E, Ishii H (2002) Comtouch: Design of a vibrotactile communication de" /><span class="c-article-references__counter">3.</span><p class="c-article-references__text" id="ref-CR3">Chang A, O’Modhrains S, Jacob R, Gunther E, Ishii H (2002) Comtouch: Design of a vibrotactile communication device, Proceedings of DIS’02, London, England, pp 312–320; doi: 10.1145/778712.778755</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rovers AF, Essen van HA (2004) HIM: A Framework for haptic instant messaging, Extended abstracts of CHI 2004, " /><span class="c-article-references__counter">4.</span><p class="c-article-references__text" id="ref-CR4">Rovers AF, Essen van HA (2004) HIM: A Framework for haptic instant messaging, Extended abstracts of CHI 2004, Vienna, Austria, pp 1313–1316; doi: 10.1145/985921.986052</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="LaViola JL, Feliz DA, Keefe D, Zeleznik RC (2001) Hands-free multi-scale navigation in virtual environments, P" /><span class="c-article-references__counter">5.</span><p class="c-article-references__text" id="ref-CR5">LaViola JL, Feliz DA, Keefe D, Zeleznik RC (2001) Hands-free multi-scale navigation in virtual environments, Proceedings of SI3D’01, Research Triangle Park, NC, pp 9–15; doi: 10.1145/364338.364339</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pearson G, Weiser M (1986) Of moles and men: The design of foot controls for workstations, Proceedings of SIGC" /><span class="c-article-references__counter">6.</span><p class="c-article-references__text" id="ref-CR6">Pearson G, Weiser M (1986) Of moles and men: The design of foot controls for workstations, Proceedings of SIGCHI’86, Boston, MA, pp 333–339; doi: 10.1145/22627.22392</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Paradiso JA, Morris SJ, Benbasat AY, Asmussen E (2004) Interactive therapy with instrumented footwear, extende" /><span class="c-article-references__counter">7.</span><p class="c-article-references__text" id="ref-CR7">Paradiso JA, Morris SJ, Benbasat AY, Asmussen E (2004) Interactive therapy with instrumented footwear, extended abstracts of CHI’04, Vienna, Austria, pp 1341–1343; doi: 10.1145/985921.986059</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Whitton MC, Cohn JV, Feasel J, Zimmons P, Razzaque S, Poulton SJ, McLeod B, Brooks FP (2005) Comparing VE loco" /><span class="c-article-references__counter">8.</span><p class="c-article-references__text" id="ref-CR8">Whitton MC, Cohn JV, Feasel J, Zimmons P, Razzaque S, Poulton SJ, McLeod B, Brooks FP (2005) Comparing VE locomotion interfaces, Proceedings of IEEE Virtual Reality 2005, Bonn; doi: 10.1109/VR.2005.25</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Templeman JN, Denbrook PS, Sibert LE (1999) Virtual locomotion: Walking in place through virtual environments," /><span class="c-article-references__counter">9.</span><p class="c-article-references__text" id="ref-CR9">Templeman JN, Denbrook PS, Sibert LE (1999) Virtual locomotion: Walking in place through virtual environments, Presence: teleoperators and virtual environments, vol 8, Nr. 6, The MIT Press, Cambridge, pp 598–617</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pakkanen T, Raisamo R (2004) Appropriateness of foot interaction for non-accurate spatial tasks, Extended abst" /><span class="c-article-references__counter">10.</span><p class="c-article-references__text" id="ref-CR10">Pakkanen T, Raisamo R (2004) Appropriateness of foot interaction for non-accurate spatial tasks, Extended abstracts of CHI2004, Vienna, Austria, pp 1123–1126; doi: 10.1145/985921.986004</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hoffmann ER (1991) A comparison of hand and foot movement times, Ergonomics 34(4), April, Taylor &amp; Francis, Lo" /><span class="c-article-references__counter">11.</span><p class="c-article-references__text" id="ref-CR11">Hoffmann ER (1991) A comparison of hand and foot movement times, Ergonomics 34(4), April, Taylor &amp; Francis, London, pp 397–406; PMID: 1860460</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Trulsson, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Trulsson M (2001) Mechanoreceptive afferents in the human sural nerve, Exp Brain Res 137:111–116; PMID: 113101" /><span class="c-article-references__counter">12.</span><p class="c-article-references__text" id="ref-CR12">Trulsson M (2001) Mechanoreceptive afferents in the human sural nerve, Exp Brain Res 137:111–116; PMID: 11310164</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Mechanoreceptive%20afferents%20in%20the%20human%20sural%20nerve&amp;journal=Exp%20Brain%20Res&amp;volume=137&amp;pages=111-116&amp;publication_year=2001&amp;author=Trulsson%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Essen HA van, Rovers AF (2005) Layered protocols approach to analyze haptic communication over a network, Proc" /><span class="c-article-references__counter">13.</span><p class="c-article-references__text" id="ref-CR13">Essen HA van, Rovers AF (2005) Layered protocols approach to analyze haptic communication over a network, Proceedings of World Haptics 2005, Pisa, Italy; doi: 10.1109/WHC.2005.85</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MM. Taylor, " /><meta itemprop="datePublished" content="1988" /><meta itemprop="headline" content="Taylor MM (1988) Layered protocols for computer-human dialogue I: principles. Int J Man Mach Stud 28:175–218" /><span class="c-article-references__counter">14.</span><p class="c-article-references__text" id="ref-CR14">Taylor MM (1988) Layered protocols for computer-human dialogue I: principles. Int J Man Mach Stud 28:175–218</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Layered%20protocols%20for%20computer-human%20dialogue%20I%3A%20principles&amp;journal=Int%20J%20Man%20Mach%20Stud&amp;volume=28&amp;pages=175-218&amp;publication_year=1988&amp;author=Taylor%2CMM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MM. Taylor, " /><meta itemprop="datePublished" content="1988" /><meta itemprop="headline" content="Taylor MM (1988) Layered protocols for computer-human dialogue II: some practical issues. Int J Man Mach Stud " /><span class="c-article-references__counter">15.</span><p class="c-article-references__text" id="ref-CR15">Taylor MM (1988) Layered protocols for computer-human dialogue II: some practical issues. Int J Man Mach Stud 28:219–257</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Layered%20protocols%20for%20computer-human%20dialogue%20II%3A%20some%20practical%20issues&amp;journal=Int%20J%20Man%20Mach%20Stud&amp;volume=28&amp;pages=219-257&amp;publication_year=1988&amp;author=Taylor%2CMM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="CD. Wickens, SE. Gordon, Y. Liu, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Wickens CD, Gordon SE, Liu Y (1998) An introduction to human factors analysis. Addison-Wesley Inc., Reading, M" /><span class="c-article-references__counter">16.</span><p class="c-article-references__text" id="ref-CR16">Wickens CD, Gordon SE, Liu Y (1998) An introduction to human factors analysis. Addison-Wesley Inc., Reading, MA</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20introduction%20to%20human%20factors%20analysis&amp;publication_year=1998&amp;author=Wickens%2CCD&amp;author=Gordon%2CSE&amp;author=Liu%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="JJ. Gibson, " /><meta itemprop="datePublished" content="1979" /><meta itemprop="headline" content="Gibson JJ (1979) The ecological approach to visual perception. Houghton Mifflin, Boston, MA" /><span class="c-article-references__counter">17.</span><p class="c-article-references__text" id="ref-CR17">Gibson JJ (1979) The ecological approach to visual perception. Houghton Mifflin, Boston, MA</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20ecological%20approach%20to%20visual%20perception&amp;publication_year=1979&amp;author=Gibson%2CJJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="DA. Norman, SW. Draper, " /><meta itemprop="datePublished" content="1986" /><meta itemprop="headline" content="Norman DA, Draper SW (1986) User centered system design: New perspective on human-computer interaction. Lawren" /><span class="c-article-references__counter">18.</span><p class="c-article-references__text" id="ref-CR18">Norman DA, Draper SW (1986) User centered system design: New perspective on human-computer interaction. Lawrence Erlbaum Associates Inc., Hillsdale, NJ</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=User%20centered%20system%20design%3A%20New%20perspective%20on%20human-computer%20interaction&amp;publication_year=1986&amp;author=Norman%2CDA&amp;author=Draper%2CSW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="DA. Norman, " /><meta itemprop="datePublished" content="1988" /><meta itemprop="headline" content="Norman DA (1988) The design of everyday things. The MIT press, Cambridge, MA" /><span class="c-article-references__counter">19.</span><p class="c-article-references__text" id="ref-CR19">Norman DA (1988) The design of everyday things. The MIT press, Cambridge, MA</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20design%20of%20everyday%20things&amp;publication_year=1988&amp;author=Norman%2CDA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="IJsselsteijn WA (2004) Presence in Dept, PhD Thesis, Eindhoven University of Technology, J.F. Schoutenschool f" /><span class="c-article-references__counter">20.</span><p class="c-article-references__text" id="ref-CR20">IJsselsteijn WA (2004) Presence in Dept, PhD Thesis, Eindhoven University of Technology, J.F. Schoutenschool for User-System Interaction Research</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Oboe, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Oboe R (2001) Web-interfaced, force-reflecting teleoperation systems. IEEE Trans Ind Electron 48(6):1257–1265" /><span class="c-article-references__counter">21.</span><p class="c-article-references__text" id="ref-CR21">Oboe R (2001) Web-interfaced, force-reflecting teleoperation systems. IEEE Trans Ind Electron 48(6):1257–1265</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F41.969406" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Web-interfaced%2C%20force-reflecting%20teleoperation%20systems&amp;journal=IEEE%20Trans%20Ind%20Electron&amp;volume=48&amp;issue=6&amp;pages=1257-1265&amp;publication_year=2001&amp;author=Oboe%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Souayed GT, Gaiti D, Yu W, Dodds G, Marshall A (2004) Experimental study of haptic interaction in distributed " /><span class="c-article-references__counter">22.</span><p class="c-article-references__text" id="ref-CR22">Souayed GT, Gaiti D, Yu W, Dodds G, Marshall A (2004) Experimental study of haptic interaction in distributed virtual environments. Proceedings of Eurohaptics, Munchen, Germany, pp 260–266</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="N. White, D. Back, " /><meta itemprop="datePublished" content="1986" /><meta itemprop="headline" content="White N, Back D (1986) Telephonic arm wrestling. The strategic arts initiative symposium, Italy" /><span class="c-article-references__counter">23.</span><p class="c-article-references__text" id="ref-CR23">White N, Back D (1986) Telephonic arm wrestling. The strategic arts initiative symposium, Italy</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Telephonic%20arm%20wrestling&amp;publication_year=1986&amp;author=White%2CN&amp;author=Back%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Paulos E (2003) Connexus: A communal interface”. Tech.Report IRB-TR-03-011, Intel Research" /><span class="c-article-references__counter">24.</span><p class="c-article-references__text" id="ref-CR24">Paulos E (2003) Connexus: A communal interface”. Tech.Report IRB-TR-03-011, Intel Research</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fels S, Takahashi S, Chung C (2001) PlesioPhone: An cell phone and telephone based interactive artwork, (http:" /><span class="c-article-references__counter">25.</span><p class="c-article-references__text" id="ref-CR25">Fels S, Takahashi S, Chung C (2001) PlesioPhone: An cell phone and telephone based interactive artwork, (<a href="http://hct.ece.ubc.ca/research/plesiophone">http://hct.ece.ubc.ca/research/plesiophone</a>)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fogg BJ, Cutler LD, Arnold P, Eisbach PC (1998) HandJive: A device for interpersonal haptic entertainment, Pro" /><span class="c-article-references__counter">26.</span><p class="c-article-references__text" id="ref-CR26">Fogg BJ, Cutler LD, Arnold P, Eisbach PC (1998) HandJive: A device for interpersonal haptic entertainment, Proceedings of CHI ‘98, Los Angeles, CA, pp 57–64; doi: 10.1145/274644.274653</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Goldberg K, Wallace R (1993) Data dentata, visual proceedings of SIGGRAPH ‘93, Anaheim, CA" /><span class="c-article-references__counter">27.</span><p class="c-article-references__text" id="ref-CR27">Goldberg K, Wallace R (1993) Data dentata, visual proceedings of SIGGRAPH ‘93, Anaheim, CA</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dodge C (1997) The Bed: A medium for intimate communication. Extened abstracts of CHI 97, Atlanta, GA, pp 371–" /><span class="c-article-references__counter">28.</span><p class="c-article-references__text" id="ref-CR28">Dodge C (1997) The Bed: A medium for intimate communication. Extened abstracts of CHI 97, Atlanta, GA, pp 371–372</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Grimmer N (2001) Heart2Heart, winner of Intel student design competition" /><span class="c-article-references__counter">29.</span><p class="c-article-references__text" id="ref-CR29">Grimmer N (2001) Heart2Heart, winner of Intel student design competition</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="McGaig G, Fels S (2002) The 2Hearts Project: Enhancing non-verbal communication through music and graphics, (h" /><span class="c-article-references__counter">30.</span><p class="c-article-references__text" id="ref-CR30">McGaig G, Fels S (2002) The 2Hearts Project: Enhancing non-verbal communication through music and graphics, (<a href="http://hct.ece.ubc.ca/research/2hearts">http://hct.ece.ubc.ca/research/2hearts</a>)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Oakley I, O’Modhrain S (2002) Contact IM: Exploring asynchronous touch over distance, proceedings of CSCW 2002" /><span class="c-article-references__counter">31.</span><p class="c-article-references__text" id="ref-CR31">Oakley I, O’Modhrain S (2002) Contact IM: Exploring asynchronous touch over distance, proceedings of CSCW 2002</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Tollmar K, Junestrand S, Torgny O (2000) Virtually living together, Proceedings of DIS 2000, New York City, NY" /><span class="c-article-references__counter">32.</span><p class="c-article-references__text" id="ref-CR32">Tollmar K, Junestrand S, Torgny O (2000) Virtually living together, Proceedings of DIS 2000, New York City, NY, pp 83–91; doi: 10.1145/347642.347670</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hansson R, Skogg T (2001) The LoveBomb: Encouraging the communication of emotions in public space, Extended ab" /><span class="c-article-references__counter">33.</span><p class="c-article-references__text" id="ref-CR33">Hansson R, Skogg T (2001) The LoveBomb: Encouraging the communication of emotions in public space, Extended abstracts of CHI’01, pp 433–434; doi: 10.1145/634067.634319</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rovers AF, Essen HA van (2004) Design and evaluation of hapticons for enriched instant messaging, Proceedings " /><span class="c-article-references__counter">34.</span><p class="c-article-references__text" id="ref-CR34">Rovers AF, Essen HA van (2004) Design and evaluation of hapticons for enriched instant messaging, Proceedings of EuroHaptics’04, Munich, Germany</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Tan, A. Lim, R. Taylor, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Tan H, Lim A, Taylor R (2000) A Psychophysical study of sensory saltation with an open response paradigm, DSC " /><span class="c-article-references__counter">35.</span><p class="c-article-references__text" id="ref-CR35">Tan H, Lim A, Taylor R (2000) A Psychophysical study of sensory saltation with an open response paradigm, DSC vol 69-2. Proc ASME Dyn Syst Control Div 2:1109–1115</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20Psychophysical%20study%20of%20sensory%20saltation%20with%20an%20open%20response%20paradigm%2C%20DSC%20vol%2069-2&amp;journal=Proc%20ASME%20Dyn%20Syst%20Control%20Div&amp;volume=2&amp;pages=1109-1115&amp;publication_year=2000&amp;author=Tan%2CH&amp;author=Lim%2CA&amp;author=Taylor%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Erp JBF van (2002) Guidelines for the use of vibro-tactile displays in human computer interaction, Proceedings" /><span class="c-article-references__counter">36.</span><p class="c-article-references__text" id="ref-CR36">Erp JBF van (2002) Guidelines for the use of vibro-tactile displays in human computer interaction, Proceedings of EuroHaptics’02</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rovers AF, Essen HA van (2005) FootIO: Design and evaluation of a device to enable foot interaction over a com" /><span class="c-article-references__counter">37.</span><p class="c-article-references__text" id="ref-CR37">Rovers AF, Essen HA van (2005) FootIO: Design and evaluation of a device to enable foot interaction over a computer network. Proceedings of WorldHaptics 2005, Pisa, Italy, pp 521–522; doi: 10.1109/WHC.2005.56</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Brave S, Nass C, Sirinian CE (2001) Force-feedback in computer-mediated communication, Proceedings of UAHCI’01" /><span class="c-article-references__counter">38.</span><p class="c-article-references__text" id="ref-CR38">Brave S, Nass C, Sirinian CE (2001) Force-feedback in computer-mediated communication, Proceedings of UAHCI’01, New Orleans, LA</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-005-0016-0-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Department of Industrial Design, Eindhoven University of Technology, Den Dolech 2 (HG 2.59), 5612AZ, Eindhoven, The Netherlands</p><p class="c-article-author-affiliation__authors-list">A.F. Rovers &amp; H.A. van Essen</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-A_F_-Rovers"><span class="c-article-authors-search__title u-h3 js-search-name">A.F. Rovers</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;A.F.+Rovers&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=A.F.+Rovers" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22A.F.+Rovers%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-H_A_-Essen"><span class="c-article-authors-search__title u-h3 js-search-name">H.A. van Essen</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;H.A.+van+Essen&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=H.A.+van+Essen" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22H.A.+van+Essen%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-005-0016-0/email/correspondent/c1/new">A.F. Rovers</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Guidelines%20for%20haptic%20interpersonal%20communication%20applications%3A%20an%20exploration%20of%20foot%20interaction%20styles&amp;author=A.F.%20Rovers%20et%20al&amp;contentID=10.1007%2Fs10055-005-0016-0&amp;publication=1359-4338&amp;publicationDate=2005-12-03&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Rovers, A., van Essen, H. Guidelines for haptic interpersonal communication applications: an exploration of foot interaction styles.
                    <i>Virtual Reality</i> <b>9, </b>177–191 (2006). https://doi.org/10.1007/s10055-005-0016-0</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-005-0016-0.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2005-07-29">29 July 2005</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2005-10-07">07 October 2005</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2005-12-03">03 December 2005</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-03">March 2006</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-005-0016-0" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-005-0016-0</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Haptic interaction</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Foot interaction</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Layered protocols</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Communication</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Hapticons</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-005-0016-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=16;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

