<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Visual immersive haptic mathematics"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="In the modern urban society, human brain is not being sufficiently trained to deal with problems which require 3D perception. As a result, when teaching subjects richly infused with mathematics it..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/13/4.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Visual immersive haptic mathematics"/>

    <meta name="dc.source" content="Virtual Reality 2009 13:4"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2009-09-02"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2009 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="In the modern urban society, human brain is not being sufficiently trained to deal with problems which require 3D perception. As a result, when teaching subjects richly infused with mathematics it is usually a challenge for the learners to follow the instructor and visualize how mathematical concepts reflect in 3D geometry and colors. We have proposed an approach that would allow for defining complex geometry, visual appearance and tangible physical properties of the virtual objects using language of mathematical functions. It allows the learners to get immersed within the 3D scene and explore the shapes which are being modeled visually and haptically. We illustrate this concept using our function-based extension of X3D and VRML. Besides definition of objects with mathematical functions straight in the scene file, standard X3D and VRML objects can be converted to tangible ones as well as augmented with function-defined visual appearances. Since the function-defined models are small in size, it is possible to perform their collaborative interactive modifications with concurrent synchronous visualization at each client computer with any required level of detail."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2009-09-02"/>

    <meta name="prism.volume" content="13"/>

    <meta name="prism.number" content="4"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="221"/>

    <meta name="prism.endingPage" content="234"/>

    <meta name="prism.copyright" content="2009 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-009-0133-2"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-009-0133-2"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-009-0133-2.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-009-0133-2"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Visual immersive haptic mathematics"/>

    <meta name="citation_volume" content="13"/>

    <meta name="citation_issue" content="4"/>

    <meta name="citation_publication_date" content="2009/12"/>

    <meta name="citation_online_date" content="2009/09/02"/>

    <meta name="citation_firstpage" content="221"/>

    <meta name="citation_lastpage" content="234"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-009-0133-2"/>

    <meta name="DOI" content="10.1007/s10055-009-0133-2"/>

    <meta name="citation_doi" content="10.1007/s10055-009-0133-2"/>

    <meta name="description" content="In the modern urban society, human brain is not being sufficiently trained to deal with problems which require 3D perception. As a result, when teaching su"/>

    <meta name="dc.creator" content="Alexei Sourin"/>

    <meta name="dc.creator" content="Lei Wei"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=Int Educ J; citation_title=Effect of instructions on spatial visualization ability in civil engineering students; citation_author=M Alias, TR Black, DR Gray; citation_volume=3; citation_issue=1; citation_publication_date=2002; citation_pages=1-12; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Appl Eng Educ; citation_title=Tools for teaching mathematics: a case for Java and VRML; citation_author=LC Guimar&#227;es, RG Barbastefano, E Belfort; citation_volume=8; citation_issue=3&#8211;4; citation_publication_date=2000; citation_pages=157-161; citation_doi=10.1002/1099-0542(2000)8:3/4&lt;157::AID-CAE4&gt;3.0.CO;2-9; citation_id=CR2"/>

    <meta name="citation_reference" content="Kaufmann H, Schmalstieg D (2006) Designing immersive virtual reality for geometry education. In: IEEE virtual reality conference, VR 2006. IEEE CS Press, pp 51&#8211;58"/>

    <meta name="citation_reference" content="Kunimune S, Nagasaki E (1996) Curriculum changes on lower secondary school mathematics of Japan&#8212;focused on geometry. Eighth international congress on mathematical education. Retrieved 8 January 2008 from 
                    http://www.fi.uu.nl/en/Icme-8/WG13_6.html
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph; citation_title=Function-based shape modelling extension of the virtual reality modelling language; citation_author=Q Liu, A Sourin; citation_volume=30; citation_issue=4; citation_publication_date=2006; citation_pages=629-645; citation_doi=10.1016/j.cag.2006.03.006; citation_id=CR5"/>

    <meta name="citation_reference" content="citation_journal_title=Vis Comput; citation_title=Function-defined shape metamorphoses in visual cyberworlds; citation_author=Q Liu, A Sourin; citation_volume=22; citation_issue=12; citation_publication_date=2006; citation_pages=977-990; citation_doi=10.1007/s00371-006-0044-0; citation_id=CR6"/>

    <meta name="citation_reference" content="Mathematics Syllabus Primary. Ministry of Education Singapore (2009) Retrieved from 
                    http://www.moe.gov.sg/education/syllabuses/sciences/files/maths-primary-2007.pdf
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Vis Comput; citation_title=Function representation in geometric modeling: concepts, implementations and applications; citation_author=A Pasko, V Adzhiev, A Sourin, V Savchenko; citation_volume=11; citation_issue=8; citation_publication_date=1995; citation_pages=429-446; citation_doi=10.1007/BF02464333; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_journal_title=CyberPsychol Behav; citation_title=MAT3D: a virtual reality modeling language environment for the teaching and learning of mathematics; citation_author=A Pasqualotti, CM Dal Sasso Freitas; citation_volume=5; citation_issue=5; citation_publication_date=2002; citation_pages=409-422; citation_doi=10.1089/109493102761022832; citation_id=CR9"/>

    <meta name="citation_reference" content="citation_journal_title=J Ind Teach Educ; citation_title=Novice drafters&#8217; spatial visualization development: influence of instructional methods and individual learning styles; citation_author=SA Scribner, AA Anderson; citation_volume=42; citation_issue=2; citation_publication_date=2005; citation_pages=38-60; citation_id=CR10"/>

    <meta name="citation_reference" content="Secondary Mathematics Syllabuses, Ministry of Education Singapore (2009) Retrieved from 
                    http://www.moe.gov.sg/education/syllabuses/sciences/files/maths-secondary.pdf
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=J Comput Assist Learn; citation_title=A virtual reality application for geometry classes; citation_author=KS Song, WY Lee; citation_volume=18; citation_publication_date=2002; citation_pages=149-156; citation_doi=10.1046/j.0266-4909.2001.00222.x; citation_id=CR12"/>

    <meta name="citation_reference" content="Sourin A, Wei L (2008) Visual immersive haptic rendering on the Web. Seventh ACM SIGGRAPH international conference on virtual-reality continuum and its applications in industry, VRCAI 2008, 8&#8211;9 December"/>

    <meta name="citation_reference" content="TSG 16 (2004) Visualisation in the teaching and learning of mathematics. In: Tenth international congress of mathematical education. 4&#8211;11 July 2004, Copenhagen, Denmark, from 
                    http://www.icme-organisers.dk/tsg16
                    
                  
                        "/>

    <meta name="citation_reference" content="TSG 20 (2008) Visualization in the teaching and learning of mathematics. In: Eleventh international congress of mathematical education. 6&#8211;13 July 2008, Monterrey, Mexico, from 
                    http://tsg.icme11.org/tsg/show/21
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Vis Comput; citation_title=Function-based visualization and haptic rendering in shared virtual spaces; citation_author=L Wei, A Sourin, O Sourina; citation_volume=24; citation_issue=5; citation_publication_date=2008; citation_pages=871-880; citation_doi=10.1007/s00371-008-0285-1; citation_id=CR16"/>

    <meta name="citation_reference" content="citation_title=Function-based haptic collaboration in X3D. In: Proceedings of Web3D 2009, 16&#8211;17 June Darmstadt; citation_publication_date=2009; citation_id=CR17; citation_author=L Wei; citation_author=A Sourin; citation_author=H Stocker; citation_publisher=ACM Press"/>

    <meta name="citation_reference" content="Yeh A, Nason R (2004) VRMath: a 3D microworld for learning 3D geometry. In: Cantoni L, McLoughlin C (eds) Proceedings of world conference on educational multimedia, hypermedia and telecommunications 2004, AACE, Chesapeake, VA, pp 2183&#8211;2194"/>

    <meta name="citation_author" content="Alexei Sourin"/>

    <meta name="citation_author_email" content="assourin@ntu.edu.sg"/>

    <meta name="citation_author_institution" content="Nanyang Technological University, Singapore, Singapore"/>

    <meta name="citation_author" content="Lei Wei"/>

    <meta name="citation_author_email" content="weil0004@ntu.edu.sg"/>

    <meta name="citation_author_institution" content="Nanyang Technological University, Singapore, Singapore"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-009-0133-2&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2009/12/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-009-0133-2"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Visual immersive haptic mathematics"/>
        <meta property="og:description" content="In the modern urban society, human brain is not being sufficiently trained to deal with problems which require 3D perception. As a result, when teaching subjects richly infused with mathematics it is usually a challenge for the learners to follow the instructor and visualize how mathematical concepts reflect in 3D geometry and colors. We have proposed an approach that would allow for defining complex geometry, visual appearance and tangible physical properties of the virtual objects using language of mathematical functions. It allows the learners to get immersed within the 3D scene and explore the shapes which are being modeled visually and haptically. We illustrate this concept using our function-based extension of X3D and VRML. Besides definition of objects with mathematical functions straight in the scene file, standard X3D and VRML objects can be converted to tangible ones as well as augmented with function-defined visual appearances. Since the function-defined models are small in size, it is possible to perform their collaborative interactive modifications with concurrent synchronous visualization at each client computer with any required level of detail."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Visual immersive haptic mathematics | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-009-0133-2","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Shape and surface modeling, Virtual reality, Physically based modeling, Shape modeling, Haptic collaboration, Shared virtual spaces, Electronic education","kwrd":["Shape_and_surface_modeling","Virtual_reality","Physically_based_modeling","Shape_modeling","Haptic_collaboration","Shared_virtual_spaces","Electronic_education"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-009-0133-2","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-009-0133-2","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=133;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-009-0133-2">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Visual immersive haptic mathematics
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-009-0133-2.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-009-0133-2.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2009-09-02" itemprop="datePublished">02 September 2009</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Visual immersive haptic mathematics</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Alexei-Sourin" data-author-popup="auth-Alexei-Sourin" data-corresp-id="c1">Alexei Sourin<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Nanyang Technological University" /><meta itemprop="address" content="grid.59025.3b, 0000000122240361, Nanyang Technological University, Singapore, Singapore" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Lei-Wei" data-author-popup="auth-Lei-Wei">Lei Wei</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Nanyang Technological University" /><meta itemprop="address" content="grid.59025.3b, 0000000122240361, Nanyang Technological University, Singapore, Singapore" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 13</b>, Article number: <span data-test="article-number">221</span> (<span data-test="article-publication-year">2009</span>)
            <a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">227 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">11 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">0 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-009-0133-2/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>In the modern urban society, human brain is not being sufficiently trained to deal with problems which require 3D perception. As a result, when teaching subjects richly infused with mathematics it is usually a challenge for the learners to follow the instructor and visualize how mathematical concepts reflect in 3D geometry and colors. We have proposed an approach that would allow for defining complex geometry, visual appearance and tangible physical properties of the virtual objects using language of mathematical functions. It allows the learners to get immersed within the 3D scene and explore the shapes which are being modeled visually and haptically. We illustrate this concept using our function-based extension of X3D and VRML. Besides definition of objects with mathematical functions straight in the scene file, standard X3D and VRML objects can be converted to tangible ones as well as augmented with function-defined visual appearances. Since the function-defined models are small in size, it is possible to perform their collaborative interactive modifications with concurrent synchronous visualization at each client computer with any required level of detail.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Although the right hemisphere of the human brain is responsible for spatial visualization, the authors believe that in our modern world most people do not use it to the full extent as everything around us is often simplified to pictures or symbols of 3D objects displayed on screens, billboards, etc. As a result, the brain is not being sufficiently trained to deal with problems which require 3D perception. General weakening of spatial perception and binocular vision, in particular (see, for example, Alias et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Alias M, Black TR, Gray DR (2002) Effect of instructions on spatial visualization ability in civil engineering students. Int Educ J 3(1):1–12" href="/article/10.1007/s10055-009-0133-2#ref-CR1" id="ref-link-section-d641e304">2002</a>; Scribner and Anderson <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Scribner SA, Anderson AA (2005) Novice drafters’ spatial visualization development: influence of instructional methods and individual learning styles. J Ind Teach Educ 42(2):38–60" href="/article/10.1007/s10055-009-0133-2#ref-CR10" id="ref-link-section-d641e307">2005</a>) and <a href="http://www.vision3d.com/whycant.html">http://www.vision3d.com/whycant.html</a>), has been de facto acknowledged and reflected in education systems of different countries by making curriculum structures more geometry oriented starting from the primary or even pre-school level. For example, in Japan teaching Euclidean geometry is introduced at lower secondary school mathematics level (Kunimune and Nagasaki <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Kunimune S, Nagasaki E (1996) Curriculum changes on lower secondary school mathematics of Japan—focused on geometry. Eighth international congress on mathematical education. Retrieved 8 January 2008 from &#xA;                    http://www.fi.uu.nl/en/Icme-8/WG13_6.html&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-009-0133-2#ref-CR4" id="ref-link-section-d641e317">1996</a>). In the Singapore, Mathematics Syllabus Primary (Mathematics Syllabus Primary <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Mathematics Syllabus Primary. Ministry of Education Singapore (2009) Retrieved from &#xA;                    http://www.moe.gov.sg/education/syllabuses/sciences/files/maths-primary-2007.pdf&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-009-0133-2#ref-CR7" id="ref-link-section-d641e320">2009</a>) and the Secondary Mathematics Syllabuses (Secondary Mathematics Syllabuses <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Secondary Mathematics Syllabuses, Ministry of Education Singapore (2009) Retrieved from &#xA;                    http://www.moe.gov.sg/education/syllabuses/sciences/files/maths-secondary.pdf&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-009-0133-2#ref-CR11" id="ref-link-section-d641e324">2009</a>), one of the listed competences which learners can gain from mathematics training is “Spatial visualization”. The importance and specifics of visualization in the teaching and learning of mathematics was also discussed as a special topic at the 10th and 11th International Congresses of Mathematical Education (TSG <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="TSG 16 (2004) Visualisation in the teaching and learning of mathematics. In: Tenth international congress of mathematical education. 4–11 July 2004, Copenhagen, Denmark, from &#xA;                    http://www.icme-organisers.dk/tsg16&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-009-0133-2#ref-CR14" id="ref-link-section-d641e327">2004</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="TSG 20 (2008) Visualization in the teaching and learning of mathematics. In: Eleventh international congress of mathematical education. 6–13 July 2008, Monterrey, Mexico, from &#xA;                    http://tsg.icme11.org/tsg/show/21&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-009-0133-2#ref-CR15" id="ref-link-section-d641e330">2008</a>). However, due to many reasons, strengthening the spatial visualization is still not emphasized as much as other competences. As a result, school children often find it difficult to deal with 3D objects, such as forming different figures of concrete 3D models, identifying the nets of solid figures and engaging in vector analysis. At the university level, there are many subjects requiring advance spatial visualization skills such as calculus, computer graphics, computer animation, geometric modeling, computer-aided design, etc. However, for the same reason as discussed above, it is usually a challenge for the students to follow the instructor and visualize how mathematical concepts reflect in 3D geometry and colors.</p><p>There are a few commercially available software tools which are commonly used for doing research on mathematics and geometry as well as for learning and teaching these subjects, e.g., Mathcad (<a href="http://www.ptc.com/appserver/mkt/products">http://www.ptc.com/appserver/mkt/products</a>), Maple (<a href="http://www.maplesoft.com">http://www.maplesoft.com</a>), Mathematica (<a href="http://www.wolfram.com/products/mathematica">http://www.wolfram.com/products/mathematica</a>), MATLAB (<a href="http://www.mathworks.com/products/matlab">http://www.mathworks.com/products/matlab</a>), and Geometer’s Sketchpad (<a href="http://www.dynamicgeometry.com">http://www.dynamicgeometry.com</a>). Among other features, these tools allow learners to perform visualization of geometric shapes (2D/3D curves and surfaces) and some provide further means for making web-enabled interactive applications. However, when using these tools, the learners are only able to see images while it could be more educational to get immersed within the 3D scene and explore the shapes which are being modeled. Moreover, it would be even more beneficial if this immersion could be done collaboratively with other learners and the instructor.</p><p>There are a few examples of such collaborative approaches to learning geometry in virtual augmented worlds using VRML and on the web (Guimarães et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Guimarães LC, Barbastefano RG, Belfort E (2000) Tools for teaching mathematics: a case for Java and VRML. Comput Appl Eng Educ 8(3–4):157–161" href="/article/10.1007/s10055-009-0133-2#ref-CR2" id="ref-link-section-d641e374">2000</a>; Kaufmann and Schmalstieg <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Kaufmann H, Schmalstieg D (2006) Designing immersive virtual reality for geometry education. In: IEEE virtual reality conference, VR 2006. IEEE CS Press, pp 51–58" href="/article/10.1007/s10055-009-0133-2#ref-CR3" id="ref-link-section-d641e377">2006</a>; Pasqualotti and Dal Sasso Freitas <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Pasqualotti A, Dal Sasso Freitas CM (2002) MAT3D: a virtual reality modeling language environment for the teaching and learning of mathematics. CyberPsychol Behav 5(5):409–422" href="/article/10.1007/s10055-009-0133-2#ref-CR9" id="ref-link-section-d641e380">2002</a>; Song and Lee <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Song KS, Lee WY (2002) A virtual reality application for geometry classes. J Comput Assist Learn 18:149–156" href="/article/10.1007/s10055-009-0133-2#ref-CR12" id="ref-link-section-d641e383">2002</a>; Yeh and Nason <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Yeh A, Nason R (2004) VRMath: a 3D microworld for learning 3D geometry. In: Cantoni L, McLoughlin C (eds) Proceedings of world conference on educational multimedia, hypermedia and telecommunications 2004, AACE, Chesapeake, VA, pp 2183–2194" href="/article/10.1007/s10055-009-0133-2#ref-CR18" id="ref-link-section-d641e386">2004</a>); however, these projects are restricted to a limited class of geometric objects and only teach geometry rather than provide the learner with an ability to see the geometric shapes behind the mathematical formulas and illustrate how mathematics creates and supports immersive virtual spaces, as we are proposing to do in our project. Also, learning in shared virtual spaces subjects richly infused with mathematics and geometry requires for developing of interoperable data formats for exchanging mathematical objects across the Internet (e.g., project Intergeo, <a href="http://www.inter2geo.eu">http://www.inter2geo.eu</a>).</p><p>In this paper, we seek to develop an efficient way of modeling virtual objects and sharing them in cyberspace. Instead of traditionally used polygon and voxel based models, we are using relatively small mathematical functions, which define the properties of the virtual objects. We are also using haptic force-feedback so that the learners can also make physical contact with mathematically defined objects in the virtual scene, as well as with other learners. With the arrival on the consumer market of affordable interactive 3D touch devices (e.g., Novint Falcon, <a href="http://home.novint.com">http://home.novint.com</a>), haptic communication may soon become as common as interactions using mouses and joysticks. In Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0133-2#Sec2">2</a>, we discuss the visual and haptic rendering pipelines for the function-defined objects. We introduce the VRML and X3D implementation of our approach in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0133-2#Sec3">3</a>, and give a few modeling examples in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0133-2#Sec4">4</a>. In Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0133-2#Sec5">5</a>, we describe the interactive collaborative virtual modeling tool designed for teaching shape modeling, which is further elaborated in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0133-2#Sec6">6</a>. Finally in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0133-2#Sec7">7</a>, we summarize the work done.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Function-based visual and haptic rendering pipelines</h2><div class="c-article-section__content" id="Sec2-content"><p>Through vision we receive most of the information about the world around us. This is rather a passive information collection process while touch is an active and bi-directional process. It allows us to perceive tangible properties of objects through stimulation of skin which has different sensitivity in different parts of our body. We also manipulate objects as well as exert forces to receive a force feedback from them. Compared to vision, very little has been done to make touch a regular part of communication with a computer, especially in shared virtual spaces, while it is a very important part of our real life. Since our senses are complementary, we propose to put it all together using mathematical functions and procedures as building blocks. We will define models of objects in 3D space and time continuum, where the time is considered as yet another coordinate which can be positive and negative.</p><p>We propose to define geometry of the virtual objects, as well as their visual appearance, and tangible physical properties, by concurrent using of <i>implicit</i>, <i>explicit</i> and <i>parametric</i> function definitions. Separation of geometry and visual appearance is a common approach in different web visualization and computer graphics data formats and software libraries like VRML, X3D, Java3D, OpenGL, Open Inventor, etc. Therefore, our concept of independent definition of geometry, appearance and physics naturally can fit there. In our previous research (Liu and Sourin <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Liu Q, Sourin A (2006a) Function-based shape modelling extension of the virtual reality modelling language. Comput Graph 30(4):629–645" href="/article/10.1007/s10055-009-0133-2#ref-CR5" id="ref-link-section-d641e446">2006</a>; Liu and Sourin <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Liu Q, Sourin A (2006b) Function-defined shape metamorphoses in visual cyberworlds. Vis Comput 22(12):977–990" href="/article/10.1007/s10055-009-0133-2#ref-CR6" id="ref-link-section-d641e449">2006</a>), we successfully implemented it with application to VRML and X3D for defining geometric objects with different visual appearances. At the present stage of our project, we expand our considerations to three components of the objects in shared virtual spaces: geometry, visual appearance, and tangible physical properties, which we define separately in their own domains by implicit, explicit or parametric functions and then merge together into one virtual object. We define visual appearance properties as 3D colors and geometric textures which are applied to underlying geometry. Tangible physical properties are defined as surface friction and tension, as well as inner density and forces associated with the underlying geometry. We have published preliminary results of the project in (Wei et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Wei L, Sourin A, Sourina O (2008) Function-based visualization and haptic rendering in shared virtual spaces. Vis Comput 24(5):871–880" href="/article/10.1007/s10055-009-0133-2#ref-CR16" id="ref-link-section-d641e453">2008</a>) while in this paper we elaborate on the details of the visual and haptic rendering pipelines used in the VRML and X3D implementations of our modeling approach.</p><p>We define <i>implicit functions</i> as <i>f</i>(<i>x, y, z, t</i>) = 0, where <i>x, y, z</i> are Cartesian coordinates and <i>t</i> is the time. When used for defining geometry, the function equals to zero for the points located on the surface of an object. Hence, a spherical surface is defined by equation: <i>R</i>
                        <sup>2</sup> − <i>x</i>
                        <sup>2</sup> − <i>y</i>
                        <sup>2</sup> − <i>z</i>
                        <sup>2</sup> = 0.</p><p>
                        <i>Explicit functions</i> are defined as <i>g</i> <i>=</i> <i>f</i>(<i>x, y, z, t</i>). The function value <i>g</i> computed at any point of the 3D modeling space can be used either as a value of some physical property like density, or as an argument for other functions (e.g., to define colors or parameters of transformations), or as an indicator of the sampled point location. Thus, explicit functions can be used to define bounded solid objects in the FRep sense (Pasko et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Pasko A, Adzhiev V, Sourin A, Savchenko V (1995) Function representation in geometric modeling: concepts, implementations and applications. Vis Comput 11(8):429–446" href="/article/10.1007/s10055-009-0133-2#ref-CR8" id="ref-link-section-d641e518">1995</a>). In this case, the function equals to zero for the points located on the surface of a shape, positive values indicate points inside the shape, and negative values are for the points which are outside the shape. To illustrate it, let us consider an example of function <span class="mathjax-tex">\( g = \sqrt {x^{2} + y^{2} + z^{2} } \)</span> which defines a distance from the origin to any point with Cartesian coordinates (<i>x</i>, <i>y</i>, <i>z</i>). If now we use function <span class="mathjax-tex">\( g = R - \sqrt {x^{2} + y^{2} + z^{2} } \ge 0,\)</span> it will define a solid origin-centered sphere with radius <i>R</i>. In fact, this function <i>g</i> = <i>f</i>(<i>x</i>, <i>y</i>, <i>z</i>) is a function of 3 variables in 4-dimensional space and it has a meaning of a distance from the points inside the sphere to the nearest point on its surface. Without imposing such a meaning, the equation of a solid sphere could be also written as <i>g</i> = <i>R</i>
                        <sup>2</sup> − <i>x</i>
                        <sup>2</sup> − <i>y</i>
                        <sup>2</sup> − <i>z</i>
                        <sup>2</sup> ≥ 0. The original geometry of the sphere can be modified by addition of a 3D solid texture which can be done by displacing the function values with another texture function <i>texture</i> (<i>x</i>, <i>y</i>, <i>z</i>): <i>g</i> = <i>R</i>
                        <sup>2</sup> − <i>x</i>
                        <sup>2</sup> − <i>y</i>
                        <sup>2</sup> − <i>z</i>
                        <sup>2</sup> + <i>texture</i> (<i>x</i>, <i>y</i>, <i>z</i>) ≥ 0. Addition of time <i>t</i> to the parameters of the function will allow us to make variable time-dependent shapes. For example, a sphere bouncing up and down by height <i>a</i> during time <i>t</i> = [0, 1] can be defined as <i>g</i> = <i>R</i>
                        <sup>2</sup> − <i>x</i>
                        <sup>2</sup> − (<i>y</i> − <i>a</i>sin(<i>t</i>π))<sup>2</sup> − <i>z</i>
                        <sup>2</sup> ≥ 0.</p><p>
                        <i>Parametric functions</i> are, in fact, explicit functions of some parametric coordinates <i>u, v, w</i> and time <i>t</i>. They can define curves, surfaces, solid objects, vector coordinates and colors as:</p><div id="Equa" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ \begin{aligned} x &amp; = f_{1} \left( {u|,v|,w|,t} \right);\quad y = \, f_{2} \left( {u|,v|,w|,t} \right);\quad z = f_{3} \left( {u|,v|,w|,t} \right) \\ r &amp; = \varphi_{1} \left( {u|,v|,w|,t} \right);\quad g = \varphi_{2} \left( {u|,v|,w|,t} \right);\quad b = \varphi_{3} \left( {u|,v|,w|,t} \right) \\ \end{aligned} $$</span></div></div><p>where <i>x, y, z</i> are Cartesian coordinates of the points or vectors, and <i>r, g,</i>
                        <i>b</i> are values of colors. To define a curve, only one or the <i>u</i>, <i>v</i>, and <i>w</i> parameters will be used; to define a surface, 2 parameters are required; and to define a solid object or 3D color, 3 parameters will be used. When <i>t</i> is added, these objects will become time dependent. For example, the bouncing solid sphere which color changes from green to red as a function of its height could be then defined as:</p><div id="Equb" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ \begin{aligned} x &amp; = wR\cos v\cos u \\ y &amp; = wR\sin u + a\sin (t\pi ) \\ z &amp; = wR\sin v\cos u \\ r &amp; = \sin (t\pi ) \\ g &amp; = 1 - \sin (t\pi ) \\ b &amp; = 0 \\ u &amp; \, = \left[ {0, \, 2\pi \left] {,\;v = } \right[0, \, \pi \left] {,\;w = } \right[0, \, 1\left] {,\;t = } \right[0, \, 1} \right]. \\ \end{aligned} $$</span></div></div>
                     <p>Though we permit any combinations of implicit, explicit and parametric functions for defining the components of the shapes, only those illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig1">1</a> appear to have practical applications.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Definition of geometry, appearance and physics of shapes by implicit, explicit and parametric functions</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     </div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Extending X3D and VRML with function-based definitions</h2><div class="c-article-section__content" id="Sec3-content"><p>The goal of our project is to augment X3D and VRML with function-defined objects. Polygons, points and lines are used as output primitives in X3D and VRML viewers. When making extensions of X3D and VRML, there are three ways of how to plug into their visualization pipeline: plug-in customisation, External Authoring Interface (EAI), and X3D/VRML script.</p><p>Plug-in customisation is done by developing a Dynamic Link Library (DLL) using Software Development Kits (SDK) provided by viewer vendors. Plug-ins are usually implemented in C++. The viewers are only required to download and install the plug-in and declare the respective external prototype. After that, the usage of the extended node is transparent. The major problem of plug-in customisation is that it is always browser dependent. It is impossible to port it from one browser to another even under the same platform.</p><p>EAI is used for embedding the viewer into an application or an applet, which is either independent or within a Web browser. It can be called through both the COM interface and Java classes. Thus, languages such as C++ and Java can be used to develop applications or applets through EAI. Besides this, since it is a part of the X3D/VRML standard, all browsers support it, which ensures better compatibility. However, since it is used for creating external programs, the extensions thus implemented cannot be integrated into the browser.</p><p>X3D/VRML script supports not only JavaScript and Java, but C++ as well. By writing a specific string in the <i>url</i> field, the browser automatically loads a library file and executes the code provided by the library. This execution method is called native script. The library files for different browsers have only a slight difference, so the source code can be ported with only minor modifications. This method of using X3D/VRML and native scripts can provide the best performance with only a little compromise of the rules. Besides this, any programming language migration can be done quickly since the mechanism does not change.</p><p>By comparing these three methods, we selected for our implementation X3D/VRML script and C++. It requires from the extending part to create output primitives and add them to the output primitives created by the viewers in their visualization pipelines (Liu and Sourin <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Liu Q, Sourin A (2006a) Function-based shape modelling extension of the virtual reality modelling language. Comput Graph 30(4):629–645" href="/article/10.1007/s10055-009-0133-2#ref-CR5" id="ref-link-section-d641e792">2006</a>).</p><p>The necessity to plug into the existing visualization pipeline requires that in our visual and haptic rendering pipelines the geometry has to come first followed by the appearance and physics properties which have to be associated with it (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig2">2</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Visual and haptic rendering pipelines for the function-defined objects in VRML and X3D</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Firstly, the visual rendering pipeline is attended. The implicit, explicit and parametric function definitions of the geometry are rendered to create output primitives which are polygons and lines in the X3D/VRML rendering pipeline. If there was any 3D texture defined for the shape by either explicit or parametric displacement of the underlying geometry, it will be taken into account at this stage as well.</p><p>Next, the color is mapped to the vertices of the output primitives. The color can be defined either parametrically or explicitly. When parametric functions are used, the color vector is defined as <b>C</b> = <b>F</b>(<i>u, v, w, t</i>) where <b>C</b> = [r g b] and <i>u</i>,<i>v</i> and <i>w</i> are the Cartesian coordinates of a point in 3D modeling space for which the color is defined. When explicit functions are used, the value <i>g</i> of the explicit function <i>g</i> <i>=</i> <i>f</i> (<i>x, y, z, t</i>) is mapped to color vectors <b>C</b> = [r g b] by some (e.g. linear) interpolation on the given key function values {<i>g</i>
                        <sub>
                  <i>i</i>
                </sub>} and the respective colors {<b>C</b>
                        <i>i</i>}. These considerations are applied to different components of the illumination model including diffuse, specular, ambient and emissive colors as well as transparency and shininess. The 3D color thus defined can be then sampled by any geometry (which can be time dependent) hence making a colored object. The color, transparency and shininess can vary across the surface and volume of the object as defined by the respective functions.</p><p>The haptic rendering pipeline is engaged when there is a haptic device used with the application. Haptic interaction usually assumes that there is a scene being visualized that serves as a guide for the haptic device. Function parser receives coordinates of the 3D haptic contact point <i>h</i> = (<i>x, y, z</i>) and three orientation angles of the haptic actuator (<i>roll, pitch, yaw</i>). The haptic contact point is then tested whether it collides with any of the objects for which tangible properties are defined. Then, the force vectors to be applied to the haptic actuator (displacement and torque) are calculated as a result of the combined force created by the surface, density and force field properties definitions. For haptic devices with several contact points, these calculations have to be done for all of them.</p><p>Modeling of the three components of the objects—geometry, visual appearance and physical properties—can be performed either in the same coordinate system or in different coordinate domains which will then be mapped to one modeling coordinate system of the virtual object. The domains are defined by the bounding boxes (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig3">3</a>) which specify their location and coordinate scaling. Hence, each of the components can be defined in some normalized domain and then used for making an instance of an object with different size and location. For each of the components, an individual instance transformation has to be defined. The resulting object is obtained by merging together the instances of geometry, appearance and physical properties. This approach allows us to make libraries of predefined geometries, appearances and physical properties to be used in different applications.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Assembling geometric objects from geometry, appearance and physical properties defined in their own coordinate domains</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Implementing the proposed approach in X3D and its predecessor VRML, we add new <i>FShape</i> and <i>FTransform</i> nodes. The <i>FShape</i> node contains other ten nodes in the same way how the standard X3D/VRML Shape node is organized. These nodes are <i>FGeometry</i>, <i>FAppearance</i> (with <i>FMaterial</i> and <i>FTexture3D</i>) and <i>FPhysics</i> which contains <i>FSurface</i> (with <i>FFriction, FTension</i>)<i>, FDensity,</i> and <i>FForce</i>. These nodes can be used alone as well as together with the standard X3D and VRML nodes (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig4">4</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Extended function-defined and standard nodes of VRML and X3D</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The <i>FShape</i> node is a container for the <i>FGeometry</i> or any standard X3D/VRML <i>geometry</i> node, and the <i>FAppearance</i> or the standard <i>Appearance</i> node. These nodes define the geometry and the appearance of the shape, respectively.</p><p>The <i>FGeometry</i> node is designed to define the geometry using functions typed straight in the code as individual formulas and java-style function scripts or stored as algorithmic procedures in binary libraries.</p><p>The <i>FAppearance</i> node may contain the <i>FMaterial</i> or the standard X3D/VRML <i>Material</i> nodes, as well as the standard color <i>Texture</i> and the function-based <i>FTexture3D</i> nodes. In the <i>FMaterial</i> node, the components of the illumination model are defined using functions in a way how it can be done in the <i>FGeometry</i> node, i.e. in analytical formulas, scripts or DLLs. The <i>FTexture3D</i> node contains a displacement function for the geometry defined in the <i>FGeometry</i> node.</p><p>The <i>FPhysics</i> node is used for defining physical properties associated with the shape’s geometry. The <i>FPhysics</i> contains the <i>FSurface</i>, <i>FDensity</i> and <i>FForse</i> nodes.</p><p>The <i>FSurface</i> node defines surface physical properties. It includes the <i>FFriction</i> and the <i>FTension</i> nodes. The <i>FFriction</i> node is used for defining friction on the surface which can be examined by moving a haptic device actuator on the surface. The <i>FTension</i> node defines the force which has to be applied to the haptic actuator to penetrate the surface of the object. The surface friction and tension are defined by explicit functions of coordinates <i>x, y, z</i> and the time <i>t</i> in analytical formulas, scripts or DLLs. Hence, the surface friction and tension can vary on different parts of the surface.</p><p>The <i>FDensity</i> node is used for defining material density of the shape. It can be examined by moving a haptic device actuator inside the visible or invisible boundary of the shape. The density is defined by explicit functions of coordinates <i>x, y, z</i> and the time <i>t</i> in analytical formulas, scripts or DLLs, and hence it can vary within the volume of the shape<i>.</i> The surface of the shape can be made non-tangible, while the shape still might have density inside it to define some amorphous or liquid shapes without distinct boundaries.</p><p>The <i>FForce</i> node is used for defining a force field associated with the geometry of the shape. The force vector at each point of the space is defined by three functions of its <i>x</i>, <i>y</i>, and <i>z</i> coordinates and the time <i>t</i> in analytical formulas, scripts or DLLs. The force can be felt by placing the haptic device actuator into the area where the force field is defined. Moving the actuator within the density and the force fields will produce a combined haptic effect.</p><p>The <i>FShape</i> node may be called from the <i>FTransform</i> node or from the standard <i>Transform</i> node. The <i>FTranform</i> node defines affine transformation which can be functions of time, as well as any other operations over the function-defined shapes. These are predefined set-theoretic (Boolean) intersection, union, difference, as well as any other function-defined set-theoretic and any other operations, e.g. <i>r</i> functions, shape morphing, etc.</p><p>There can be two ways of how the function-defined models of virtual objects can be used in shared virtual X3D and VRML scenes when haptic interaction is used.</p><p>First, the function-defined objects can be used within a virtual scene on their own with the geometry, appearance and physical properties defined by individual functions, scripts or procedures stored in binary libraries. In that case, all standard X3D/VRML shapes are transparent for haptic rendering even if they have common points with the function-defined shapes. Besides this, the appearance of the function-defined geometry can be declared transparent so that this invisible geometry can be used as a container for the physical properties which can be superimposed with the standard shapes. This mode can be used for modeling phenomena that can only be explored haptically (e.g., modeling wind in a virtual scene) or would require a standard X3D/VRML geometry for its visual representation (e.g., water flow can be simulated as an animated texture image with a function-defined force field associated with it). All standard shapes still will be transparent for haptic rendering even if they have common points with the invisible function-defined geometric container.</p><p>Second, besides using function-defined objects on their own, standard shapes of X3D and VRML can be turned into tangible surfaces and solid objects by associating them (grouping) with the function-defined appearance and physical properties. In that case we can significantly augment the standard X3D/VRML shapes by adding new function-defined appearance as well as allow for haptic rendering of any standard shape in the scene; features which cannot be achieved by the standard shape nodes of X3D/VRML.</p><p>When haptic interaction is used, any of the objects in the virtual scene, standard or function-defined, can be used as a haptic tool avatar. This is provided by assigning a special reserved name for such an object (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig5">5</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig5_HTML.jpg?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig5_HTML.jpg" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>A VRML ball is used as a haptic tool avatar. It is placed on the surface of the virtual sea in the Sunset Beach scene in Cybertown (<a href="http://www.cybertown.com">http://www.cybertown.com</a>). The ball floats on the moving sea waves and the handle of the haptic device follows its motion up and down</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Currently, we are supporting desktop haptic devices from SensAble (Omni, Desktop and Premium 6DOF) and Novint Falcon. Above the device-dependent layer of the haptic plug-in, we have placed a common interface layer, which is a wrapper layer to handle different drivers and libraries from different vendors, and to expose a group of commonly used interfaces to the developer. By introducing this layer, we make the rest of the software device independent. The collision detection is implemented both at the level of polygons, which are obtained at the end of the X3D/VRML visualization pipeline for both standard and function-defined objects, and at the level of function definitions for the function-defined objects. The later works much faster than the polygon-based collision detection and is not restricted by the number of polygons generated in the models. When a haptic device is used to explore the virtual scene, as soon as the haptic interaction point collides with a virtual object in the scene, the whole node will be sent back to the haptic plug-in. By checking the definition of the object, the plug-in will get to know whether the object is a standard object (Shape node) or a function-based object (FShape node). If the object is a standard Shape node, the plug-in will automatically switch to the polygonal collision detection mode, which we previously published in (Sourin and Wei <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Sourin A, Wei L (2008) Visual immersive haptic rendering on the Web. Seventh ACM SIGGRAPH international conference on virtual-reality continuum and its applications in industry, VRCAI 2008, 8–9 December" href="/article/10.1007/s10055-009-0133-2#ref-CR13" id="ref-link-section-d641e1175">2008</a>). However, if the object is an FShape node, the plug-in will then get the specific collision detection mode for this FShape. If the polygonal collision mode specified for the FShape node, the plug-in will perform collision detection with the polygons generated from the FGeometry function definition. If the function-based collision mode is specified, the function definition of FGeometry will be directly retrieved within the plug-in and used for computing the collision detection based on the function values rather than on polygons (Wei et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Wei L, Sourin A, Sourina O (2008) Function-based visualization and haptic rendering in shared virtual spaces. Vis Comput 24(5):871–880" href="/article/10.1007/s10055-009-0133-2#ref-CR16" id="ref-link-section-d641e1178">2008</a>).</p></div></div></section><section aria-labelledby="Sec4"><div class="c-article-section" id="Sec4-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec4">Examples of modeling with functions</h2><div class="c-article-section__content" id="Sec4-content"><p>Let’s consider a few examples. To ease reading and save space, the codes of the examples are written using VRML-style encoding; however, XML encoding for X3D can be used as well.</p><p>Examples of function definitions of two spheres, as it was discussed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0133-2#Sec2">2</a>, are given in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig6">6</a>. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig6">6</a>a, the sphere is defined by an explicit FRep function with a solid texture defined as a displacement noise function and a color defined by three parametric functions. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig6">6</a>b, a parametrically defined sphere bounces up and down with its color changing as a function of height and time.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Examples of function definitions in the extended VRML code. <b>a</b> A solid textured sphere is defined by explicit FRep functions; <b>b</b> a bouncing sphere with a time-dependent color is defined parametrically</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig7">7</a>, an example of modeling a tangible “watermelon” is given. The geometry, appearance and physical properties of this object are defined with explicit FRep functions (Pasko et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Pasko A, Adzhiev V, Sourin A, Savchenko V (1995) Function representation in geometric modeling: concepts, implementations and applications. Vis Comput 11(8):429–446" href="/article/10.1007/s10055-009-0133-2#ref-CR8" id="ref-link-section-d641e1235">1995</a>). The geometry is a CSG object defined as a sphere with a piece cut away from it by a semi-infinite solid object defined by 3 planes:</p><div id="Equc" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ func = (1 - x^{2} - y^{2} - z^{2} )\&amp; ( - \left( {\left( {z - x} \right)\&amp; y\&amp; z)} \right) \ge 0 $$</span></div></div><p>where the set-theoretic intersection is denoted as &amp;. The set-theoretic operations are implemented in the extension both by min/max and <i>r</i> functions (Pasko et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Pasko A, Adzhiev V, Sourin A, Savchenko V (1995) Function representation in geometric modeling: concepts, implementations and applications. Vis Comput 11(8):429–446" href="/article/10.1007/s10055-009-0133-2#ref-CR8" id="ref-link-section-d641e1252">1995</a>). It is up to the user to decide which continuity of the resulting function is required to select the operation implementation to be used.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig7_HTML.gif?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig7_HTML.gif" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Modeling “watermelon” by assembling the object from geometry, appearance, and tangible surface properties and inner density</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The color is then represented by a 3D color field defined in the same geometric coordinate space. The function of this field is defined as a distance from the origin</p><div id="Equd" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ dist = \sqrt {x^{2} + y^{2} + z^{2} } $$</span></div></div><p>with distortions defined by a specially designed noise function</p><div id="Eque" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ noise = 0.01\left( {\sin \left( {12{\text{a}}\tan \left( {x, \, z + 0.04\sin \left( {25y} \right)} \right)} \right) - 0.7} \right). $$</span></div></div>
                     <p>The function values are then linearly mapped to the color values according to a designed color map. The uneven shape of the color iso-surfaces was used for making green patterns on the surface of the “watermelon”. This was achieved by mapping the respective function values from 0.98 to 1 to RGB values of colors ranging from [0 1 0] to [0 0.2 0]. The colors inside the watermelon are also created by linear mapping of the respective color function values to different grades from yellow, through white, and finally to red colors.</p><p>The density inside the watermelon is defined as a distance function script with a value 0.8 near the surface and a variable value <i>g</i> inside it:</p><div id="Equf" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ g = 0.3 + 0.2\sin \left( {120\pi x} \right)\sin \left( {120\pi y} \right)\sin \left( {120\pi z} \right) $$</span></div></div>
                     <p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig7">7</a>, the density values are displayed with different colors and intensities. The zoomed section of the inner part shows how the density changes to simulate a crunchy body of the watermelon. The surface friction and tension are constant 0.1 and 1, respectively. The whole FShape object definition code is built by putting together the four fragments of the code given in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig7">7</a>.</p><p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig8">8</a>, we make a scene from standard and function-defined shapes. The fan is made from standard polygonal VRML objects. It is defined as a touch sensor so that when it is clicked its blades will start rotating. The surfaces of the standard objects—fan, cabinet and carpet—are made tangible by grouping them with a function-defined object which has only a tangible surface property defined. An air-flow is defined functionally within a transparent geometric cone which is attached to the fan blades, as displayed in the figure. The surface of the cone, which is defined by parametric functions, is used for triggering collision detection. When the fan starts blowing, the force field will be activated as well, and it can be felt with a haptic device when its virtual contact point is placed inside the invisible cone. In this example, we also illustrate how different properties can be modeled in different coordinate domains and then mapped into one object. Hence, the force field is originally defined in a unit bounding box which is then mapped to the bounding box defined for the geometric container, which is the cone.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig8_HTML.gif?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig8_HTML.gif" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Making tangible wind in a shared virtual scene. An air-flow is defined by parametric functions within a transparent geometric cone which is attached to the fan blades. A collision with the invisible cone triggers the interaction with the force field</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     </div></div></section><section aria-labelledby="Sec5"><div class="c-article-section" id="Sec5-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec5">Collaborative virtual modeling tool</h2><div class="c-article-section__content" id="Sec5-content"><p>Since writing meaningful mathematical function and scripts can be a challenge, especially when there is a need to obtain 3D coordinates of the objects in the virtual scene, we have developed a shared virtual tool where the users are able to collaboratively model complex 3D shapes by defining their geometry, appearance and physical properties using analytical implicit, explicit and parametric functions and scripts (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig9">9</a>). The tool visualizes the language of mathematics in forms of curves, surfaces and solid objects. The users may go inside the 3D scene being modeled and explore it by walking through it, as well as haptically investigate it.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig9_HTML.gif?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig9_HTML.gif" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Walking through the Klein Bottle. The surface of the object is defined parametrically. It is then interactively painted using implicitly defined tools</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>At a first glance out tool shares some aspects with conventional math software tools mentioned in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0133-2#Sec1">1</a>; however, it has totally different aim and goal. The tool is not intended for making high-end geometric models, such as those that can be created with CAD tools like Maya and 3D Studio MAX. Instead, it rather emphasizes the modeling process itself by demonstrating how complex geometry, appearance and physical properties can be defined by small mathematical formulas. The users select from the predefined sets initial shape, tools, geometric and appearance operations or define them analytically by typing mathematical formulas. Models defined by analytical formulas or function scripts can be easily modified on-the-fly in the virtual scene either by editing the formulas or by doing iterative interactive modifications. To apply a virtual tool, the user clicks at any point on the object being modeled. The 3D object representing the current tool will be placed to the scene at the selected point. The size, position and orientation of the tool can be changed interactively either with the haptic device or with a common mouse. After placing the tool, the user selects one of the predefined operations to modify the geometry or the color of the object. In the screen shot which is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig9">9</a>, three such operations are defined: removing of material, depositing of material and applying color. Removing material subtracts the object representing the tool from the current object. Depositing material unifies the tool with the current object. Coloring operation blends the color assigned to the tool with the current 3D color of the object according to the transparency assigned to the tool. The color blending is performed only at the part of the current object that intersects with the tool. When the tool is not transparent, the color of the tool overrides the color of the current object at the application area. There is also a set of commands, which the learners can type in the chat box of the browser and immediately see how the shape changes. The software filters out the shape-modeling commands from other chat messages and processes them accordingly. The function description of the current shape can be generated and saved for future use on its own or within X3D or VRML virtual scenes.</p><p>The tool is developed as a server–client application. The shared collaboration when using this tool is achieved by exchanging models of the virtual objects between the clients. Since the size of the function-defined models is small, it can easily be done. The server (blaxxun communication platform) is only used for broadcasting messages with models and commands to all the participating clients.</p><p>To avoid making simultaneous changes to the model by several clients, we employ the common floor control mechanism implemented through the locking mechanism provided by the blaxxun communication platform. The platform server can maintain a lock, which the clients can activate or release. Once a client activates the lock, no other clients can do it. Only the client activates the lock and make modifications to the current virtual object. For a fair collaboration (i.e., each client should have the same priority to make modifications), the lock should be activated and released automatically when the client wants to modify the scene. If the lock is already obtained by another client, the modification is ignored. This can avoid the situation when the client, who acquired the editing lock, may refuse or forget to release it. Furthermore, such activate–release process can be transparent to the clients and hence can be done automatically by the modeling tool whenever the clients want to apply a modification to the scene.</p><p>To synchronize all the clients within the same session, we use only model and command transmissions.</p><p>At the first glance, it seems to be reasonable to use only message transmission in order to synchronize all the clients. This sounds attractive because the collaborative design process is normally done by incremental application of modifications to the current model. Theoretically, if there is no network transmission error and all the users joined the session before the modeling process starts, each modification to the current model can be propagated to all the clients as one message. However, in reality network transmission errors occur frequently if the data is transmitted over the Internet instead of a local area network (LAN). Furthermore, for collaborative design tool it is also possible to have users joining in the middle of the design process, or loading a previously saved model. Such events must be detected and a recovery mechanism should be provided, however, it is quite challenging. Moreover, one of the advantages of using the function-based models is their small size so that they can be easily exchanged over the Internet. Hence, the whole modified model can be exchanged after each modification is applied to the current object, and therefore no clients can be continuously desynchronized after joining the modeling session. The whole current model will be transmitted to a new client connecting to the ongoing modeling session so that the new user will immediately see the current model concurrently with others.</p><p>The selected communication platform provides sufficient mechanisms to communicate between the clients, as well as between the clients and the server, which is called shared events. Hence, there was no need to create our own protocol or use other existing protocols for this tool.</p><p>The following framework was designed for using the blaxxun communication for collaborative modeling (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig10">10</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig10_HTML.gif?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig10_HTML.gif" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Diagram of the events in the collaborative modeling tool framework</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The main events in such collaborative system are:</p><ul class="u-list-style-bullet">
                  <li>
                    <p>New client joins the modeling session;</p>
                  </li>
                  <li>
                    <p>The model is modified;</p>
                  </li>
                  <li>
                    <p>New model is loaded;</p>
                  </li>
                  <li>
                    <p>The model has to be saved or exported for further use.</p>
                  </li>
                </ul>
                     <p>When a new client joints the collaborative design session, the user has to see the scene in its current status with all the modifications which could have been made by other users before the new one joined them. It means the most recently updated model of the scene has to be forwarded to this client. With reference to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig9">9</a>, when a new client has been initialized it first detects whether the joining session is a new session or an existing session. This is done by inspecting a lock <i>P_S_PILOT_Init_Responsor</i> implemented using a pilot lock <i>P_S_PILOT</i> provided by blaxxun API. This lock is obtained by the primary client who joined the session first. This client will be responsible to send the current modeling object to new clients joining the design session. If the client finds that the pilot lock is available, the session is declared as a new session. For a new session, some original or void scene has to be loaded and visualized. If the client finds that the pilot lock has already been acquired, the client sends a message to request the current scene. When the primary client left the session, the pilot lock will assign one of the available clients to be the primary client.</p><p>When the scene is modified by any of the clients, the modifications must propagate to all other clients and update the scene as they see it on their computers. The scene can be defined by either the standard X3D/VRML code or by their function-based extension. For the proposed framework, it is only essential that the scene description has to be done in ASCII form to be transmitted as messages and that the scene browsers at the client computers should be able to render the received scene descriptions. With reference to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig10">10</a>, when an object modification is done by any of the clients, the modification lock <i>P_S_LOCK_Shape_Edit,</i> based on the <i>P_S_LOCK</i> of blaxxun API, has to be checked. If any other client is modifying the shape at the same time, the modification to the current model will not be allowed. Otherwise, the modification is converted into a message and sent to the server which will broadcast it to all the clients participating in the design session. The modification lock will be released by the client after the modification message is successfully sent.</p><p>When a new scene is loaded or reset by any of the clients, the new scene has to be delivered to all the participants. Since the design session is web-based, the scene model can be entered through an HTML text box. Then, it will be sent as a message by a certain java script to all the clients participating in the design session.</p><p>Finally, the users should be able to save the design at any time on their client computers. With reference to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig9">9</a>, the source code of the scene is assembled as strings in X3D, VRML or any other ASCII formats which the application may require. After this, the strings are printed in the console pane of the X3D/VRML browser using <i>Browser.print()</i> function of the browser, since neither X3D/VRML Script nor java script in HTML can access local hard drives due to security reasons. The code can be then manually copied from the console pane to a file which the client will open on the hard drive.</p><p>The messages are transmitted as shared events over the network. When a new shared event arrives at the client, the message is processed by <i>receiveMessage()</i>. If a complete message has been received, according to the message type, different methods are called. If the message contains the whole scene, the current modeling scene is replaced. This is used for loading a new scene or initializing the current modeling scene when a new client joins the session. If the message contains modifications, the current modeling scene is modified according to the modifications. If the message requests the current modeling scene, only the primary client will send back the whole current scene. In this connection, we have found several limitations of shared event support provided by the blaxxun communication platform, namely:</p><ol class="u-list-style-none">
                  <li>
                    <span class="u-custom-list-number">1.</span>
                    
                      <p>CRLF (Carriage Return/Line Feed) characters are not permitted in the message string;</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">2.</span>
                    
                      <p>Parts of messages can be lost while being transmitted;</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">3.</span>
                    
                      <p>There is a limitation on the length of strings transmitted by the shared event.</p>
                    
                  </li>
                </ol>
                     <p>We have successfully bypassed these limitations in our framework as described below.</p><p>Since presence of CRLF characters is essential to make the text messages editable when we need to save the scene source code, we replace CRLF with special characters and restore them after receiving the message. In our modeling tool, we use ‘\’ character to represent CRLF characters in the transmitted messages.</p><p>In order to solve the partial transmission problem, we added a prefix and suffix to each message transmitted over the Internet. In our implementation, prefix ‘@’ and suffix ‘#’ are used. When the prefix is found in the received message, the modeling tool begins to accumulate the received data until the suffix can be found. By doing this, we can successfully receive the messages.</p><p>According to our experiments, the maximum length of the string in shared event is around 1,000 characters. Since the shared event can break a message into several chunks, we can also break a long message into several parts. Each part must be less than 1,000 characters to be transmitted over the Internet without any loss. We also used another lock to indicate if anyone is sending a message over the shared event, so that no parts of two different messages can be mixed together.</p></div></div></section><section aria-labelledby="Sec6"><div class="c-article-section" id="Sec6-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec6">Implicit fantasies and parametric metamorphoses</h2><div class="c-article-section__content" id="Sec6-content"><p>The developed software is used in collaborative work when teaching students of the School of Computer Engineering in Nanyang Technological University in Singapore as a part of the computer graphics assignment “Implicit Fantasies and Parametric Metamorphoses in Cyberworlds”. The students are asked to create virtual scenes with objects defined by implicit, explicit and parametric functions. The objects must be created with set-theoretic operations from simple building block defined by functions straight in the scene code or using the interactive tool described in Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-009-0133-2#Sec5">5</a>. The objects must have continuous level of detail, which can naturally be provided by using different resolution parameters in the function definitions for different distances to the observer. The objects must also be developed with morphing and animation transformations, also defined by mathematical functions. An example of a function-based definition of a virtual clock showing the actual time is given in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig11">11</a>. Here, time-dependent transformations are used for moving the clock hands so that they follow the actual time which is synchronized by obtaining the timer events from the computer clock. In the mathematical formulas, the time variable <i>t</i> increments from 0 to 1 while this range maps to the actual time used in the scene within each node in a field <i>cycleInterval</i>. Hence, the second hand makes one full 2π rotation for 60 s, minute hand – for 60 × 60 = 3,600 s, and hour hand for 12 × 60 × 60 = 43,200 s. The rotation angle of the hour hand is adjusted by the hour zone of Singapore, which is GMT − 8 h: 2π × (8/12). The geometric objects used in the scene and their color are defined by parametric functions.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig11_HTML.gif?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig11_HTML.gif" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>An example of making a virtual clock by parametric functions and time-dependent affine transformations</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>This assignment immerses the students into the world of mathematical definitions and teaches them how to see geometry, motions and colors behind mathematical formulas. A few examples of what the students are able to achieve after only five lab sessions are given in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-009-0133-2#Fig12">12</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig12_HTML.jpg?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-009-0133-2/MediaObjects/10055_2009_133_Fig12_HTML.jpg" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Student assignments “Implicit fantasies and parametric metamorphoses”: virtual VRML and X3D scenes where some objects are defined by implicit and parametric functions</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-009-0133-2/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>A short video illustrating some of the experiments with the developed software is available at <a href="http://intune.ntu.edu.sg/SCE/courses/Alexei/Video/vihamat.wmv">http://intune.ntu.edu.sg/SCE/courses/Alexei/Video/vihamat.wmv</a>.</p></div></div></section><section aria-labelledby="Sec7"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7">Conclusion</h2><div class="c-article-section__content" id="Sec7-content"><p>We have developed a function-based approach to web visualization where relatively small mathematical formulas are used for defining the object’s geometry, appearance and physical properties. It allows the user to get immersed within the 3D scene and explore the shapes which are being modeled visually and haptically. To illustrate this concept, we developed a function-based extension of X3D and VRML. With this extension, we are able to provide haptic feedback from both standard objects of X3D/VRML, as well as from advanced 3D solid objects and force fields defined by mathematical functions and procedures. We have designed and developed an innovative application for collaborative teaching of subjects requiring strong 3D geometric interpretations of the theoretical issues, which, in turn, caters to the diverse needs of learners and has the space for continuous improvement and expansion. Our software unifies, under one roof, and provides learners with the ability to: (1) interactively visualize geometry and appearance defined by analytical formulas, (2) perform a walkthrough the created scene, as well as haptically explore it, and (3) make the scene a part of any other shared virtual scene defined by X3D and VRML. As well our tool puts the emphasis on the modeling process itself by demonstrating how geometry, appearance and physical properties can be defined by mathematical formulas. Another benefit is that the software does not require purchasing any licenses and is available anytime anywhere on any Internet-connected computer.</p><p>Currently, we are working on development of the collaborative visual haptic mathematics tool based on the new platform, BS Collaborate (<a href="http://www.bitmanagement.com">http://www.bitmanagement.com</a>) (Wei et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Wei L, Sourin A, Stocker H (2009) Function-based haptic collaboration in X3D. In: Proceedings of Web3D 2009, 16–17 June Darmstadt. ACM Press, Germany, pp 15–23" href="/article/10.1007/s10055-009-0133-2#ref-CR17" id="ref-link-section-d641e1644">2009</a>), and on incorporating a physics engine into it.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Alias, TR. Black, DR. Gray, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Alias M, Black TR, Gray DR (2002) Effect of instructions on spatial visualization ability in civil engineering" /><p class="c-article-references__text" id="ref-CR1">Alias M, Black TR, Gray DR (2002) Effect of instructions on spatial visualization ability in civil engineering students. Int Educ J 3(1):1–12</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Effect%20of%20instructions%20on%20spatial%20visualization%20ability%20in%20civil%20engineering%20students&amp;journal=Int%20Educ%20J&amp;volume=3&amp;issue=1&amp;pages=1-12&amp;publication_year=2002&amp;author=Alias%2CM&amp;author=Black%2CTR&amp;author=Gray%2CDR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="LC. Guimarães, RG. Barbastefano, E. Belfort, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Guimarães LC, Barbastefano RG, Belfort E (2000) Tools for teaching mathematics: a case for Java and VRML. Comp" /><p class="c-article-references__text" id="ref-CR2">Guimarães LC, Barbastefano RG, Belfort E (2000) Tools for teaching mathematics: a case for Java and VRML. Comput Appl Eng Educ 8(3–4):157–161</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2F1099-0542%282000%298%3A3%2F4%3C157%3A%3AAID-CAE4%3E3.0.CO%3B2-9" aria-label="View reference 2">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Tools%20for%20teaching%20mathematics%3A%20a%20case%20for%20Java%20and%20VRML&amp;journal=Comput%20Appl%20Eng%20Educ&amp;volume=8&amp;issue=3%E2%80%934&amp;pages=157-161&amp;publication_year=2000&amp;author=Guimar%C3%A3es%2CLC&amp;author=Barbastefano%2CRG&amp;author=Belfort%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kaufmann H, Schmalstieg D (2006) Designing immersive virtual reality for geometry education. In: IEEE virtual " /><p class="c-article-references__text" id="ref-CR3">Kaufmann H, Schmalstieg D (2006) Designing immersive virtual reality for geometry education. In: IEEE virtual reality conference, VR 2006. IEEE CS Press, pp 51–58</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kunimune S, Nagasaki E (1996) Curriculum changes on lower secondary school mathematics of Japan—focused on geo" /><p class="c-article-references__text" id="ref-CR4">Kunimune S, Nagasaki E (1996) Curriculum changes on lower secondary school mathematics of Japan—focused on geometry. Eighth international congress on mathematical education. Retrieved 8 January 2008 from <a href="http://www.fi.uu.nl/en/Icme-8/WG13_6.html">http://www.fi.uu.nl/en/Icme-8/WG13_6.html</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Q. Liu, A. Sourin, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Liu Q, Sourin A (2006a) Function-based shape modelling extension of the virtual reality modelling language. Co" /><p class="c-article-references__text" id="ref-CR5">Liu Q, Sourin A (2006a) Function-based shape modelling extension of the virtual reality modelling language. Comput Graph 30(4):629–645</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.cag.2006.03.006" aria-label="View reference 5">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Function-based%20shape%20modelling%20extension%20of%20the%20virtual%20reality%20modelling%20language&amp;journal=Comput%20Graph&amp;volume=30&amp;issue=4&amp;pages=629-645&amp;publication_year=2006&amp;author=Liu%2CQ&amp;author=Sourin%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Q. Liu, A. Sourin, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Liu Q, Sourin A (2006b) Function-defined shape metamorphoses in visual cyberworlds. Vis Comput 22(12):977–990" /><p class="c-article-references__text" id="ref-CR6">Liu Q, Sourin A (2006b) Function-defined shape metamorphoses in visual cyberworlds. Vis Comput 22(12):977–990</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs00371-006-0044-0" aria-label="View reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Function-defined%20shape%20metamorphoses%20in%20visual%20cyberworlds&amp;journal=Vis%20Comput&amp;volume=22&amp;issue=12&amp;pages=977-990&amp;publication_year=2006&amp;author=Liu%2CQ&amp;author=Sourin%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mathematics Syllabus Primary. Ministry of Education Singapore (2009) Retrieved from http://www.moe.gov.sg/educ" /><p class="c-article-references__text" id="ref-CR7">Mathematics Syllabus Primary. Ministry of Education Singapore (2009) Retrieved from <a href="http://www.moe.gov.sg/education/syllabuses/sciences/files/maths-primary-2007.pdf">http://www.moe.gov.sg/education/syllabuses/sciences/files/maths-primary-2007.pdf</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Pasko, V. Adzhiev, A. Sourin, V. Savchenko, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Pasko A, Adzhiev V, Sourin A, Savchenko V (1995) Function representation in geometric modeling: concepts, impl" /><p class="c-article-references__text" id="ref-CR8">Pasko A, Adzhiev V, Sourin A, Savchenko V (1995) Function representation in geometric modeling: concepts, implementations and applications. Vis Comput 11(8):429–446</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2FBF02464333" aria-label="View reference 8">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Function%20representation%20in%20geometric%20modeling%3A%20concepts%2C%20implementations%20and%20applications&amp;journal=Vis%20Comput&amp;volume=11&amp;issue=8&amp;pages=429-446&amp;publication_year=1995&amp;author=Pasko%2CA&amp;author=Adzhiev%2CV&amp;author=Sourin%2CA&amp;author=Savchenko%2CV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Pasqualotti, CM. Dal Sasso Freitas, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Pasqualotti A, Dal Sasso Freitas CM (2002) MAT3D: a virtual reality modeling language environment for the teac" /><p class="c-article-references__text" id="ref-CR9">Pasqualotti A, Dal Sasso Freitas CM (2002) MAT3D: a virtual reality modeling language environment for the teaching and learning of mathematics. CyberPsychol Behav 5(5):409–422</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1089%2F109493102761022832" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=MAT3D%3A%20a%20virtual%20reality%20modeling%20language%20environment%20for%20the%20teaching%20and%20learning%20of%20mathematics&amp;journal=CyberPsychol%20Behav&amp;volume=5&amp;issue=5&amp;pages=409-422&amp;publication_year=2002&amp;author=Pasqualotti%2CA&amp;author=Dal%20Sasso%20Freitas%2CCM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SA. Scribner, AA. Anderson, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Scribner SA, Anderson AA (2005) Novice drafters’ spatial visualization development: influence of instructional" /><p class="c-article-references__text" id="ref-CR10">Scribner SA, Anderson AA (2005) Novice drafters’ spatial visualization development: influence of instructional methods and individual learning styles. J Ind Teach Educ 42(2):38–60</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Novice%20drafters%E2%80%99%20spatial%20visualization%20development%3A%20influence%20of%20instructional%20methods%20and%20individual%20learning%20styles&amp;journal=J%20Ind%20Teach%20Educ&amp;volume=42&amp;issue=2&amp;pages=38-60&amp;publication_year=2005&amp;author=Scribner%2CSA&amp;author=Anderson%2CAA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Secondary Mathematics Syllabuses, Ministry of Education Singapore (2009) Retrieved from http://www.moe.gov.sg/" /><p class="c-article-references__text" id="ref-CR11">Secondary Mathematics Syllabuses, Ministry of Education Singapore (2009) Retrieved from <a href="http://www.moe.gov.sg/education/syllabuses/sciences/files/maths-secondary.pdf">http://www.moe.gov.sg/education/syllabuses/sciences/files/maths-secondary.pdf</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="KS. Song, WY. Lee, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Song KS, Lee WY (2002) A virtual reality application for geometry classes. J Comput Assist Learn 18:149–156" /><p class="c-article-references__text" id="ref-CR12">Song KS, Lee WY (2002) A virtual reality application for geometry classes. J Comput Assist Learn 18:149–156</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1046%2Fj.0266-4909.2001.00222.x" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20virtual%20reality%20application%20for%20geometry%20classes&amp;journal=J%20Comput%20Assist%20Learn&amp;volume=18&amp;pages=149-156&amp;publication_year=2002&amp;author=Song%2CKS&amp;author=Lee%2CWY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sourin A, Wei L (2008) Visual immersive haptic rendering on the Web. Seventh ACM SIGGRAPH international confer" /><p class="c-article-references__text" id="ref-CR13">Sourin A, Wei L (2008) Visual immersive haptic rendering on the Web. Seventh ACM SIGGRAPH international conference on virtual-reality continuum and its applications in industry, VRCAI 2008, 8–9 December</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="TSG 16 (2004) Visualisation in the teaching and learning of mathematics. In: Tenth international congress of m" /><p class="c-article-references__text" id="ref-CR14">TSG 16 (2004) Visualisation in the teaching and learning of mathematics. In: Tenth international congress of mathematical education. 4–11 July 2004, Copenhagen, Denmark, from <a href="http://www.icme-organisers.dk/tsg16">http://www.icme-organisers.dk/tsg16</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="TSG 20 (2008) Visualization in the teaching and learning of mathematics. In: Eleventh international congress o" /><p class="c-article-references__text" id="ref-CR15">TSG 20 (2008) Visualization in the teaching and learning of mathematics. In: Eleventh international congress of mathematical education. 6–13 July 2008, Monterrey, Mexico, from <a href="http://tsg.icme11.org/tsg/show/21">http://tsg.icme11.org/tsg/show/21</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Wei, A. Sourin, O. Sourina, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Wei L, Sourin A, Sourina O (2008) Function-based visualization and haptic rendering in shared virtual spaces. " /><p class="c-article-references__text" id="ref-CR16">Wei L, Sourin A, Sourina O (2008) Function-based visualization and haptic rendering in shared virtual spaces. Vis Comput 24(5):871–880</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs00371-008-0285-1" aria-label="View reference 16">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Function-based%20visualization%20and%20haptic%20rendering%20in%20shared%20virtual%20spaces&amp;journal=Vis%20Comput&amp;volume=24&amp;issue=5&amp;pages=871-880&amp;publication_year=2008&amp;author=Wei%2CL&amp;author=Sourin%2CA&amp;author=Sourina%2CO">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="L. Wei, A. Sourin, H. Stocker, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Wei L, Sourin A, Stocker H (2009) Function-based haptic collaboration in X3D. In: Proceedings of Web3D 2009, 1" /><p class="c-article-references__text" id="ref-CR17">Wei L, Sourin A, Stocker H (2009) Function-based haptic collaboration in X3D. In: Proceedings of Web3D 2009, 16–17 June Darmstadt. ACM Press, Germany, pp 15–23</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Function-based%20haptic%20collaboration%20in%20X3D.%20In%3A%20Proceedings%20of%20Web3D%202009%2C%2016%E2%80%9317%20June%20Darmstadt&amp;pages=15-23&amp;publication_year=2009&amp;author=Wei%2CL&amp;author=Sourin%2CA&amp;author=Stocker%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Yeh A, Nason R (2004) VRMath: a 3D microworld for learning 3D geometry. In: Cantoni L, McLoughlin C (eds) Proc" /><p class="c-article-references__text" id="ref-CR18">Yeh A, Nason R (2004) VRMath: a 3D microworld for learning 3D geometry. In: Cantoni L, McLoughlin C (eds) Proceedings of world conference on educational multimedia, hypermedia and telecommunications 2004, AACE, Chesapeake, VA, pp 2183–2194</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-009-0133-2-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgments</h2><div class="c-article-section__content" id="Ack1-content"><p>This work was supported by the Singapore National Research Foundation Interactive Digital Media R&amp;D Program, under research Grant NRF2008IDM-IDM004-002 “Visual and Haptic Rendering in Co-Space”.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Nanyang Technological University, Singapore, Singapore</p><p class="c-article-author-affiliation__authors-list">Alexei Sourin &amp; Lei Wei</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Alexei-Sourin"><span class="c-article-authors-search__title u-h3 js-search-name">Alexei Sourin</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Alexei+Sourin&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Alexei+Sourin" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Alexei+Sourin%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Lei-Wei"><span class="c-article-authors-search__title u-h3 js-search-name">Lei Wei</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Lei+Wei&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Lei+Wei" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Lei+Wei%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-009-0133-2/email/correspondent/c1/new">Alexei Sourin</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Visual%20immersive%20haptic%20mathematics&amp;author=Alexei%20Sourin%20et%20al&amp;contentID=10.1007%2Fs10055-009-0133-2&amp;publication=1359-4338&amp;publicationDate=2009-09-02&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Sourin, A., Wei, L. Visual immersive haptic mathematics.
                    <i>Virtual Reality</i> <b>13, </b>221 (2009). https://doi.org/10.1007/s10055-009-0133-2</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-009-0133-2.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2009-02-27">27 February 2009</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2009-08-19">19 August 2009</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2009-09-02">02 September 2009</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-009-0133-2" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-009-0133-2</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Shape and surface modeling</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Virtual reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Physically based modeling</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Shape modeling</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Haptic collaboration</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Shared virtual spaces</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Electronic education</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-009-0133-2.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=133;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

