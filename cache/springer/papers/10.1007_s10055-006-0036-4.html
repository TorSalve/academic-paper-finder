<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="&#8220;Making it real&#8221;: exploring the potential of augmented rea"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="The use of augmented reality (AR) in formal education could prove a key component in future learning environments that are richly populated with a blend of hardware and software applications...."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/10/3.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="&#8220;Making it real&#8221;: exploring the potential of augmented reality for teaching primary school science"/>

    <meta name="dc.source" content="Virtual Reality 2006 10:3"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2006-11-14"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2006 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="The use of augmented reality (AR) in formal education could prove a key component in future learning environments that are richly populated with a blend of hardware and software applications. However, relatively little is known about the potential of this technology to support teaching and learning with groups of young children in the classroom. Analysis of teacher&#8211;child dialogue in a comparative study between use of an AR virtual mirror interface and more traditional science teaching methods for 10-year-old children, revealed that the children using AR were less engaged than those using traditional resources. We suggest four design requirements that need to be considered if AR is to be successfully adopted into classroom practice. These requirements are: flexible content that teachers can adapt to the needs of their children, guided exploration so learning opportunities can be maximised, in a limited time, and attention to the needs of institutional and curricular requirements."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2006-11-14"/>

    <meta name="prism.volume" content="10"/>

    <meta name="prism.number" content="3"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="163"/>

    <meta name="prism.endingPage" content="174"/>

    <meta name="prism.copyright" content="2006 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-006-0036-4"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-006-0036-4"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-006-0036-4.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-006-0036-4"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="&#8220;Making it real&#8221;: exploring the potential of augmented reality for teaching primary school science"/>

    <meta name="citation_volume" content="10"/>

    <meta name="citation_issue" content="3"/>

    <meta name="citation_publication_date" content="2006/12"/>

    <meta name="citation_online_date" content="2006/11/14"/>

    <meta name="citation_firstpage" content="163"/>

    <meta name="citation_lastpage" content="174"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-006-0036-4"/>

    <meta name="DOI" content="10.1007/s10055-006-0036-4"/>

    <meta name="citation_doi" content="10.1007/s10055-006-0036-4"/>

    <meta name="description" content="The use of augmented reality (AR) in formal education could prove a key component in future learning environments that are richly populated with a blend of"/>

    <meta name="dc.creator" content="Lucinda Kerawalla"/>

    <meta name="dc.creator" content="Rosemary Luckin"/>

    <meta name="dc.creator" content="Simon Seljeflot"/>

    <meta name="dc.creator" content="Adrian Woolard"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Vir Env; citation_title=A survey of augmented reality; citation_author=R Azuma; citation_volume=6; citation_issue=4; citation_publication_date=1997; citation_pages=355-388; citation_id=CR1"/>

    <meta name="citation_reference" content="Bajura M, Fuchs H, Ohbuchi R (1992) Merging virtual objects with the real world: seeing ultrasound imagery within the patient. In: Proceedings of SIGGRAPH &#8217;92. ACM Press, New York, pp 203&#8211;210"/>

    <meta name="citation_reference" content="citation_journal_title=J Sci Educ Technol; citation_title=Virtual solar system project: learning through a technology- rich, inquiry-based, participatory learning environment; citation_author=null Barab; citation_volume=9; citation_issue=1; citation_publication_date=2000; citation_pages=7-25; citation_doi=10.1023/A:1009416822783; citation_id=CR3"/>

    <meta name="citation_reference" content="Billinghurst M (2003) Augmented reality in education. New Horizons for Learning IX (1)"/>

    <meta name="citation_reference" content="Billinghurst M, Kato H, Poupyrev I (2001) The MagicBook: a transitional AR interface. Comput Graph 745&#8211;753"/>

    <meta name="citation_reference" content="Caudell T, Mizell D (1992) Augmented reality: an application of heads-up display technology to manual manufacturing processes. In: Proceedings of the 25th Hawaii international conference on systems science Kauai Hawaii 2:659&#8211;669, 7&#8211;10 January 1992"/>

    <meta name="citation_reference" content="Cole M (1996) Cultural psychology. The Belnap Press of Harvard University Press, Cambridge"/>

    <meta name="citation_reference" content="Crook C (1994) Computers and the collaborative experience of learning. Routledge, London"/>

    <meta name="citation_reference" content="Edwards D, Mercer N (1987) Common Knowledge: the development of joint understanding in the classroom. Methuen, London"/>

    <meta name="citation_reference" content="citation_journal_title=Presence; citation_title=Judgments of the distance to nearby virtual objects: interaction of viewing conditions and accommodative demand; citation_author=SR Ellis, BM Menges; citation_volume=6; citation_issue=4; citation_publication_date=1997; citation_pages=452-460; citation_id=CR10"/>

    <meta name="citation_reference" content="citation_journal_title=Commun ACM; citation_title=Knowledge-based augmented reality; citation_author=S Feiner, B Macintyre, D Seligmann; citation_volume=36; citation_issue=7; citation_publication_date=1993; citation_pages=53-62; citation_doi=10.1145/159544.159587; citation_id=CR11"/>

    <meta name="citation_reference" content="Fjeld M, Schar S, Signorello D, Krueger H (2002) Alternative tools for tangible interaction: a usability evaluation. In: IEEE and ACM international symposium on mixed and augmented reality (ISMAR), Darmstadt, Germany"/>

    <meta name="citation_reference" content="de Freitas S, Levene M (2005) Wearable and mobile devices for informal learning. In: Encyclopaedia of human computer interaction. Information Science Publishing, USA"/>

    <meta name="citation_reference" content="Lalioti V, Woolard A (2003) Mixed reality productions of the future. BBC R&amp;D White Paper available at 
                    http://www.bbc.co.uk/rd/pubs/whp/whp-pdf-files/WHP071.pdf
                    
                   (accessed 20/04/06)"/>

    <meta name="citation_reference" content="citation_journal_title=Curriculum J; citation_title=Broadening access to the curriculum through using technology to link home and school: a critical analysis of reforms to improve educational attainment for all K-12 students; citation_author=C Lewin, D Mavers, B Somekh; citation_volume=14; citation_issue=1; citation_publication_date=2003; citation_pages=23-54; citation_doi=10.1080/0958517032000055974; citation_id=CR15"/>

    <meta name="citation_reference" content="McKenzie J, Darnell D. (2003) A report into augmented reality storytelling in the context of a children&#8217;s workshop. Centre for Children&#8217;s Literature and Christchurch College of Education, New Zealand. 
                    http://www.hitlabnz.org/fileman_store/2004-eyeMagic_workshop.pdf
                    
                   (accessed 20/04/06)"/>

    <meta name="citation_reference" content="Piekarski W, Smith R, Thomas B (2004) Designing backpacks for high fidelity mobile outdoor augmented reality. In: 2nd international symposium on mixed and augmented reality, Tokyo, Japan"/>

    <meta name="citation_reference" content="citation_journal_title=Presence Teleoperators Vir Env; citation_title=Optical versus video see-through head-mounted displays in medical visualization; citation_author=JP Rolland, H Fuchs; citation_volume=9; citation_issue=3; citation_publication_date=2000; citation_pages=287-309; citation_doi=10.1162/105474600566808; citation_id=CR18"/>

    <meta name="citation_reference" content="Shelton B (2003) Augmented reality and education: current projects and the potential for classroom learning. New Horizons Learning IX (1)"/>

    <meta name="citation_reference" content="Shelton B, Hedley N (2002) Using augmented reality for teaching earth&#8211;sun relationships to undergraduate geography students. In: The 1st IEEE international augmented reality toolkit workshop. Darmstadt, Germany"/>

    <meta name="citation_reference" content="citation_journal_title=Tech Inst Cogn Learning; citation_title=Exploring a cognitive basis for learning spatial relationships with augmented reality; citation_author=B Shelton, N Hedley; citation_volume=1; citation_publication_date=2003; citation_pages=323-357; citation_id=CR21"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Comput Graph Appl; citation_title=New realities in aircraft design and manufacture; citation_author=D Sims; citation_volume=14; citation_issue=2; citation_publication_date=1994; citation_pages=91; citation_doi=10.1109/38.267487; citation_id=CR22"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Spectr; citation_title=The information warrior; citation_author=EC Urban; citation_volume=32; citation_issue=11; citation_publication_date=1995; citation_pages=66-70; citation_id=CR23"/>

    <meta name="citation_reference" content="Vygotsky (1979) Mind in society: the development of higher psychological processes. In: Cole M, John-Steiner V, Scribner S, Souberman E (eds and trans) Harvard University Press, Cambridge"/>

    <meta name="citation_reference" content="Wertsch J (1991) A sociocultural approach to socially shared cognition. In: Perspectives on socially shared cognition. In: Resnick L, Levine J, Teasley S (eds) American Psychological Association, Washington"/>

    <meta name="citation_reference" content="citation_journal_title=J Child Psychol Psychiatry; citation_title=The role of tutoring in problem solving; citation_author=D Wood, J Bruner, G Ross; citation_volume=17; citation_publication_date=1976; citation_pages=89-100; citation_id=CR26"/>

    <meta name="citation_author" content="Lucinda Kerawalla"/>

    <meta name="citation_author_email" content="cindyker@fsmail.net"/>

    <meta name="citation_author_institution" content="IDEAs Lab, Department of Informatics, University of Sussex, East Sussex, UK"/>

    <meta name="citation_author" content="Rosemary Luckin"/>

    <meta name="citation_author_institution" content="London Knowledge Lab, Institute of Education, London, UK"/>

    <meta name="citation_author" content="Simon Seljeflot"/>

    <meta name="citation_author_institution" content="Creative Research and Development, British Broadcasting Corporation, London, UK"/>

    <meta name="citation_author" content="Adrian Woolard"/>

    <meta name="citation_author_institution" content="Creative Research and Development, British Broadcasting Corporation, London, UK"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-006-0036-4&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2006/12/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-006-0036-4"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="“Making it real”: exploring the potential of augmented reality for teaching primary school science"/>
        <meta property="og:description" content="The use of augmented reality (AR) in formal education could prove a key component in future learning environments that are richly populated with a blend of hardware and software applications. However, relatively little is known about the potential of this technology to support teaching and learning with groups of young children in the classroom. Analysis of teacher–child dialogue in a comparative study between use of an AR virtual mirror interface and more traditional science teaching methods for 10-year-old children, revealed that the children using AR were less engaged than those using traditional resources. We suggest four design requirements that need to be considered if AR is to be successfully adopted into classroom practice. These requirements are: flexible content that teachers can adapt to the needs of their children, guided exploration so learning opportunities can be maximised, in a limited time, and attention to the needs of institutional and curricular requirements."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>“Making it real”: exploring the potential of augmented reality for teaching primary school science | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-006-0036-4","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Augmented reality, Educational dialogue, Primary classroom, Design requirements","kwrd":["Augmented_reality","Educational_dialogue","Primary_classroom","Design_requirements"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-006-0036-4","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-006-0036-4","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=36;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-006-0036-4">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            “Making it real”: exploring the potential of augmented reality for teaching primary school science
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-006-0036-4.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-006-0036-4.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2006-11-14" itemprop="datePublished">14 November 2006</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">“Making it real”: exploring the potential of augmented reality for teaching primary school science</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Lucinda-Kerawalla" data-author-popup="auth-Lucinda-Kerawalla" data-corresp-id="c1">Lucinda Kerawalla<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Sussex" /><meta itemprop="address" content="grid.12082.39, 0000000419367590, IDEAs Lab, Department of Informatics, University of Sussex, Falmer, East Sussex, BN1 9QH, UK" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Rosemary-Luckin" data-author-popup="auth-Rosemary-Luckin">Rosemary Luckin</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Institute of Education" /><meta itemprop="address" content="grid.83440.3b, 0000000121901201, London Knowledge Lab, Institute of Education, 23-29 Emerald Street, London, WC1N 3QS, UK" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Simon-Seljeflot" data-author-popup="auth-Simon-Seljeflot">Simon Seljeflot</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Creative Research and Development, British Broadcasting Corporation" /><meta itemprop="address" content="grid.28371.3f, 000000009830888X, Creative Research and Development, British Broadcasting Corporation, 8th Floor NW, Bush House, 76 Strand, London, WC2B 4PH, UK" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Adrian-Woolard" data-author-popup="auth-Adrian-Woolard">Adrian Woolard</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Creative Research and Development, British Broadcasting Corporation" /><meta itemprop="address" content="grid.28371.3f, 000000009830888X, Creative Research and Development, British Broadcasting Corporation, 8th Floor NW, Bush House, 76 Strand, London, WC2B 4PH, UK" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 10</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">163</span>–<span itemprop="pageEnd">174</span>(<span data-test="article-publication-year">2006</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">5766 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">175 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">1 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-006-0036-4/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>The use of augmented reality (AR) in formal education could prove a key component in future learning environments that are richly populated with a blend of hardware and software applications. However, relatively little is known about the potential of this technology to support teaching and learning with groups of young children in the classroom. Analysis of teacher–child dialogue in a comparative study between use of an AR virtual mirror interface and more traditional science teaching methods for 10-year-old children, revealed that the children using AR were less engaged than those using traditional resources. We suggest four design requirements that need to be considered if AR is to be successfully adopted into classroom practice. These requirements are: flexible content that teachers can adapt to the needs of their children, guided exploration so learning opportunities can be maximised, in a limited time, and attention to the needs of institutional and curricular requirements.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><h3 class="c-article__sub-heading" id="Sec2">Background</h3><p>Augmented reality (AR) has the potential to engage and motivate learners to explore material from a variety of differing perspectives, and has been shown to be particularly useful for teaching subject matter that students could not possibly experience first hand in the real world (e.g. Shelton and Hedley <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Shelton B, Hedley N (2002) Using augmented reality for teaching earth–sun relationships to undergraduate geography students. In: The 1st IEEE international augmented reality toolkit workshop. Darmstadt, Germany" href="/article/10.1007/s10055-006-0036-4#ref-CR20" id="ref-link-section-d48172e364">2002</a>). It also affords the demonstration of spatial relationships and the interactions of elements within a 3D space (e.g. Shelton and Hedley <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Shelton B, Hedley N (2003) Exploring a cognitive basis for learning spatial relationships with augmented reality. Tech Inst Cogn Learning 1:323–357" href="/article/10.1007/s10055-006-0036-4#ref-CR21" id="ref-link-section-d48172e367">2003</a>) whilst providing the potential for seamless interaction between the real and virtual worlds (e.g. Billinghurst <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Billinghurst M (2003) Augmented reality in education. New Horizons for Learning IX (1)" href="/article/10.1007/s10055-006-0036-4#ref-CR4" id="ref-link-section-d48172e370">2003</a>; Shelton <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Shelton B (2003) Augmented reality and education: current projects and the potential for classroom learning. New Horizons Learning IX (1)" href="/article/10.1007/s10055-006-0036-4#ref-CR19" id="ref-link-section-d48172e373">2003</a>). It could prove a key element as educational technology developers move towards a vision of learning environments richly populated with a blend of hardware and software applications.</p><p>However, we know relatively little about how primary school teachers could incorporate the use of AR into their lessons, or the design requirements necessary if this is to be achieved. The focus of our interest as researchers is in the nature of the affordances and constraints offered by AR technology to both learners and teachers within the formal, schooled education sector of the UK. The nature of the National Curriculum infrastructure means that teachers very often have a limited space of time (about 30–45 min) in which to cover a large amount of the necessary material. This limits the freedom that both they and their pupils have to explore complex subject matter. AR applications could help here, but we need to understand in more detail what design principles apply to their development if we are to build AR tools that give children a rich interactive experience whilst still fulfilling National Curriculum and institutional requirements.</p><p>In this paper we introduce the nature of AR: the technology used and the ways in which it has already been applied to educational contexts. We then describe an empirical study conducted with 133 children aged 9–10 years and their teachers from five London schools. We focus on a comparison of the dialogue used by teachers engaged in teaching about the earth, sun and moon using either AR or more traditional methods. Our analysis uses two main data sources: video recordings of the teaching sessions and audio recordings of interviews with teachers. We illustrate that teachers are positive about the potential benefits of AR for teaching subjects such as earth, sun and moon and believe in particular that it could make such subject matter accessible to children in a manner that ‘brings it to life’. However, applications need increased interactivity and flexibility in order to enable users to control more aspects of the digital augmentation: teachers and children need to be able to slow down or stop the animation sequences to explore and question events as they happen.</p><p>Our approach is informed by socio-cultural theory and in particular the belief that learning is both mediated by and distributed across the whole learning context (e.g. Cole <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Cole M (1996) Cultural psychology. The Belnap Press of Harvard University Press, Cambridge" href="/article/10.1007/s10055-006-0036-4#ref-CR7" id="ref-link-section-d48172e383">1996</a>; Wertsch <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Wertsch J (1991) A sociocultural approach to socially shared cognition. In: Perspectives on socially shared cognition. In: Resnick L, Levine J, Teasley S (eds) American Psychological Association, Washington" href="/article/10.1007/s10055-006-0036-4#ref-CR25" id="ref-link-section-d48172e386">1991</a>; Vygotsky <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1979" title="Vygotsky (1979) Mind in society: the development of higher psychological processes. In: Cole M, John-Steiner V, Scribner S, Souberman E (eds and trans) Harvard University Press, Cambridge" href="/article/10.1007/s10055-006-0036-4#ref-CR24" id="ref-link-section-d48172e389">1979</a>). This theoretical stance prioritises the social nature of learning and the inclusion into human activity of a mediatory tool that fundamentally transforms the nature of that activity so that the focus of analysis becomes “the individual functioning together with a mediational means” (Wertsch <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Wertsch J (1991) A sociocultural approach to socially shared cognition. In: Perspectives on socially shared cognition. In: Resnick L, Levine J, Teasley S (eds) American Psychological Association, Washington" href="/article/10.1007/s10055-006-0036-4#ref-CR25" id="ref-link-section-d48172e392">1991</a>, p 92). The whole is then greater than the sum of its parts so the investigative focus is on the exploration of individuals-using-technology-in-settings (Crook <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Crook C (1994) Computers and the collaborative experience of learning. Routledge, London" href="/article/10.1007/s10055-006-0036-4#ref-CR8" id="ref-link-section-d48172e395">1994</a>).</p><h3 class="c-article__sub-heading" id="Sec3">What is AR?</h3><p>Augmented reality is not synonymous with virtual reality (VR). One of the main differences is that whilst VR can immerse the user so that they cannot see the real world around them, AR allows the user to see a real world that is supplemented with virtual elements. The effects of AR are similar to those achieved in the film ‘Who framed Roger rabbit?’ (Azuma <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Azuma R (1997) A survey of augmented reality. Presence Teleoperators Vir Env 6(4):355–388" href="/article/10.1007/s10055-006-0036-4#ref-CR1" id="ref-link-section-d48172e406">1997</a>) in that the viewer can simultaneously see the real world and the added virtual elements. AR environments also offer 3D, real time interactivity (ibid). Historically, AR has been of particular benefit when teaching or training people in potentially hazardous environments where real world experience is necessary but the actual presence of people in such an environment would incur an unacceptably high level of risk. For example, experiencing the touch and feel of a human limb and its resistance against a biopsy needle is important in medical training. However, the risk of using a real limb is too great so overlaying an artificial limb with an ultrasound image of a real limb is beneficial in training medics in real world procedures (Bajura et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Bajura M, Fuchs H, Ohbuchi R (1992) Merging virtual objects with the real world: seeing ultrasound imagery within the patient. In: Proceedings of SIGGRAPH ’92. ACM Press, New York, pp 203–210" href="/article/10.1007/s10055-006-0036-4#ref-CR2" id="ref-link-section-d48172e409">1992</a>). AR has also been used for training in manufacturing (e.g. Caudell and Mizell <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Caudell T, Mizell D (1992) Augmented reality: an application of heads-up display technology to manual manufacturing processes. In: Proceedings of the 25th Hawaii international conference on systems science Kauai Hawaii 2:659–669, 7–10 January 1992" href="/article/10.1007/s10055-006-0036-4#ref-CR6" id="ref-link-section-d48172e412">1992</a>), aircraft manufacture (e.g. Sims <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Sims D (1994) New realities in aircraft design and manufacture. IEEE Comput Graph Appl 14(2):91" href="/article/10.1007/s10055-006-0036-4#ref-CR22" id="ref-link-section-d48172e415">1994</a>), repairing printers (Feiner et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Feiner S, Macintyre B, Seligmann D (1993) Knowledge-based augmented reality. Commun ACM 36(7):53–62" href="/article/10.1007/s10055-006-0036-4#ref-CR11" id="ref-link-section-d48172e418">1993</a>) and military training (e.g. Urban <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Urban EC (1995) The information warrior. IEEE Spectr 32(11):66–70" href="/article/10.1007/s10055-006-0036-4#ref-CR23" id="ref-link-section-d48172e422">1995</a>). It is also possible to make AR portable in a backpack, for use outdoors (e.g. Piekarski et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Piekarski W, Smith R, Thomas B (2004) Designing backpacks for high fidelity mobile outdoor augmented reality. In: 2nd international symposium on mixed and augmented reality, Tokyo, Japan" href="/article/10.1007/s10055-006-0036-4#ref-CR17" id="ref-link-section-d48172e425">2004</a>).</p><h3 class="c-article__sub-heading" id="Sec4">Augmented reality in formal education</h3><p>The use of AR in formal education is in its infancy. Shelton and Hedley (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Shelton B, Hedley N (2002) Using augmented reality for teaching earth–sun relationships to undergraduate geography students. In: The 1st IEEE international augmented reality toolkit workshop. Darmstadt, Germany" href="/article/10.1007/s10055-006-0036-4#ref-CR20" id="ref-link-section-d48172e436">2002</a>) began to explore its use as a tool for undergraduate teaching in 2000. They found that it was especially useful for teaching about subject matter that students could not possibly experience first hand in the real world. For example, Shelton and Hedley (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Shelton B, Hedley N (2002) Using augmented reality for teaching earth–sun relationships to undergraduate geography students. In: The 1st IEEE international augmented reality toolkit workshop. Darmstadt, Germany" href="/article/10.1007/s10055-006-0036-4#ref-CR20" id="ref-link-section-d48172e439">2002</a>) have explored the use of AR in teaching undergraduates about earth–sun relationships in terms of axial tilt and solstices. Analysis of the students’ physical interactions with the AR interface and their verbal interactions with their tutor revealed that the students who achieved larger changes in understanding manipulated the virtual image in a cycle of ‘move, examine and move again’. They could rotate the image and view it from different perspectives and in this way they were able to challenge their misconceptions and build a new understanding. Shelton et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Shelton B, Hedley N (2002) Using augmented reality for teaching earth–sun relationships to undergraduate geography students. In: The 1st IEEE international augmented reality toolkit workshop. Darmstadt, Germany" href="/article/10.1007/s10055-006-0036-4#ref-CR20" id="ref-link-section-d48172e442">2002</a>) argue that the 3D nature of the experience was integral to the students’ understanding of the inter-relationships between the earth and the sun, as was the high degree of control that they had over what they wanted to explore. They conclude that this AR interface provides a superior level of cognitive access to complex visualisations compared to conventional desktop interfaces.</p><p>In the current study we build upon this previous research by providing teachers and children with an animated virtual representation of a spinning earth and a sun that they can rotate to aid understanding of the relationship between sunlight and night and day. The earth can be viewed as if standing on the sun (the visible side of the earth is in day time), or from outer space beyond the dark side of the earth (the visible side of the earth is in night time). We explore how these affordances are used by the children and their teacher.</p><p>Previous work has also assessed the effectiveness of AR in teaching about other domains, such as molecular structure for older learners (Fjeld et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Fjeld M, Schar S, Signorello D, Krueger H (2002) Alternative tools for tangible interaction: a usability evaluation. In: IEEE and ACM international symposium on mixed and augmented reality (ISMAR), Darmstadt, Germany" href="/article/10.1007/s10055-006-0036-4#ref-CR12" id="ref-link-section-d48172e450">2002</a>) as well as its use in younger children’s storytelling (McKenzie and Darnell <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="McKenzie J, Darnell D. (2003) A report into augmented reality storytelling in the context of a children’s workshop. Centre for Children’s Literature and Christchurch College of Education, New Zealand. &#xA;                    http://www.hitlabnz.org/fileman_store/2004-eyeMagic_workshop.pdf&#xA;                    &#xA;                   (accessed 20/04/06)" href="/article/10.1007/s10055-006-0036-4#ref-CR16" id="ref-link-section-d48172e453">2003</a>; Billinghurst et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Billinghurst M, Kato H, Poupyrev I (2001) The MagicBook: a transitional AR interface. Comput Graph 745–753" href="/article/10.1007/s10055-006-0036-4#ref-CR5" id="ref-link-section-d48172e456">2001</a>). More recently, AR has been used to support informal learning in museums and educational exhibits (de Freitas and Levene <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="de Freitas S, Levene M (2005) Wearable and mobile devices for informal learning. In: Encyclopaedia of human computer interaction. Information Science Publishing, USA" href="/article/10.1007/s10055-006-0036-4#ref-CR13" id="ref-link-section-d48172e459">2005</a>). However, much of this work has required users to wear a see-through head mounted display. This is expensive and cumbersome and can lead to problems such as poor depth perception (e.g. Rolland and Fuchs <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Rolland JP, Fuchs H (2000) Optical versus video see-through head-mounted displays in medical visualization. Presence Teleoperators Vir Env 9(3):287–309" href="/article/10.1007/s10055-006-0036-4#ref-CR18" id="ref-link-section-d48172e462">2000</a>) and discomfort (e.g. Ellis and Menges <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Ellis SR, Menges BM (1997) Judgments of the distance to nearby virtual objects: interaction of viewing conditions and accommodative demand. Presence 6(4):452–460" href="/article/10.1007/s10055-006-0036-4#ref-CR10" id="ref-link-section-d48172e466">1997</a>). In an attempt to overcome these problems, the ‘virtual-mirror’ interface uses a computer screen or whiteboard (this will be discussed in more detail in Sect. 2.1 below) instead of head-mounted displays. This has the additional advantage of making the material simultaneously available to more than one viewer. It is therefore more suitable for use in classrooms with larger groups of young learners and is more suited as a tool to support collaborative and scaffolded (Wood et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1976" title="Wood D, Bruner J, Ross G (1976) The role of tutoring in problem solving. J Child Psychol Psychiatry 17:89–100" href="/article/10.1007/s10055-006-0036-4#ref-CR26" id="ref-link-section-d48172e469">1976</a>) learning. Work exploring the use of this interface was undertaken by BBC Creative R&amp;D in 2003 (Lalioti and Woolard <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Lalioti V, Woolard A (2003) Mixed reality productions of the future. BBC R&amp;D White Paper available at &#xA;                    http://www.bbc.co.uk/rd/pubs/whp/whp-pdf-files/WHP071.pdf&#xA;                    &#xA;                   (accessed 20/04/06)" href="/article/10.1007/s10055-006-0036-4#ref-CR14" id="ref-link-section-d48172e472">2003</a>), forming the springboard for the current study.</p><p>The use of the virtual mirror interface with large class groups has yet to be thoroughly explored. However, work using head-sets with children has shown AR to be highly engaging for this age group and some teachers report that it has potential to, for example, extend children’s higher level thinking skills and to make it possible for them to visualise a concept and manipulate it in order to realise it (McKenzie and Darnell <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="McKenzie J, Darnell D. (2003) A report into augmented reality storytelling in the context of a children’s workshop. Centre for Children’s Literature and Christchurch College of Education, New Zealand. &#xA;                    http://www.hitlabnz.org/fileman_store/2004-eyeMagic_workshop.pdf&#xA;                    &#xA;                   (accessed 20/04/06)" href="/article/10.1007/s10055-006-0036-4#ref-CR16" id="ref-link-section-d48172e478">2003</a>). Shelton et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Shelton B, Hedley N (2003) Exploring a cognitive basis for learning spatial relationships with augmented reality. Tech Inst Cogn Learning 1:323–357" href="/article/10.1007/s10055-006-0036-4#ref-CR21" id="ref-link-section-d48172e481">2003</a>) acknowledge that there are many unanswered questions about the potential benefits of AR in education and suggest that further work is needed if we are to understand how the affordances and constraints of the interface and the virtual image compare to more traditional teaching methods. The current research compares the use of AR, using the virtual mirror interface, with traditional teaching methods to teach 10 year olds about the inter-relationships between the earth, sun and (in the traditional sessions only) the moon.</p></div></div></section><section aria-labelledby="Sec5"><div class="c-article-section" id="Sec5-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec5">Using AR to teach about the earth, the sun and day and night in a simulated classroom context</h2><div class="c-article-section__content" id="Sec5-content"><h3 class="c-article__sub-heading" id="Sec6">The AR virtual mirror interface</h3><p>Children in the UK primary school classroom are frequently taught in groups sitting on the floor in front of an interactive whiteboard. The virtual mirror interface is particularly suited for this scenario and is relatively inexpensive because it requires no head-mounted displays, is highly portable and relatively quick and easy to set up. The interface can be achieved through the integration of:</p><ul class="u-list-style-bullet">
                    <li>
                      <p>ARToolkit software and virtual 3D content created using a virtual 3D modelling package;</p>
                    </li>
                    <li>
                      <p>a whiteboard and projector;</p>
                    </li>
                    <li>
                      <p>a web camera positioned on top of the whiteboard.</p>
                    </li>
                  </ul><p>The web camera relays a mirror-image of the children (and their surroundings) onto the whiteboard. The children hold an AR ‘tile’ (a card with a black 2D geometric shape mounted on a white background) in view of the web camera, the ARToolkit software recognises this in real time, and attaches the 3D image to the tile. On the whiteboard it therefore appears that the child/ren holding the tile are instead holding a 3D digital image. The result can be seen in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0036-4#Fig1">1</a>.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0036-4/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0036-4/MediaObjects/10055_2006_36_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0036-4/MediaObjects/10055_2006_36_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Children using the virtual mirror AR interface with a teacher</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0036-4/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0036-4#Fig1">1</a>, the web camera is mounted on top of the whiteboard and is capturing the two children holding the tile, as well as other members of their class who are sitting on the floor behind them. The image that has been attached to this tile is an animation of the earth spinning on its axis, as well as bright yellow arrows representing light from the sun. The digital image also contains a small girl who gets into bed when she is in darkness (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0036-4#Fig2">2</a>a) and out of bed when it gets light (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0036-4#Fig2">2</a>b), as the earth rotates on its axis. There is also an animated clock with hands that move through 12 h for each period of night and day. It is possible to physically rotate the tile so the earth can be viewed from outer space beyond the dark side of the earth (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0036-4#Fig2">2</a>a), as if standing on the sun (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0036-4#Fig2">2</a>b) or as if adjacent to the sun (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0036-4#Fig2">2</a>c).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-006-0036-4/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0036-4/MediaObjects/10055_2006_36_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-006-0036-4/MediaObjects/10055_2006_36_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>
                          <b>a</b> View from the dark side of the earth, with the girl in bed. <b>b</b> View as if standing on the sun, with the girl awake. <b>c</b> View as if adjacent to the sun, with the girl awake at midday</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-006-0036-4/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>The benefits of this AR virtual mirror interface are that users can interact with the 3D content via the interface without having to wear headsets, and the metaphor of a mirror and how it works is familiar to most users; when a child moves to their right, their image also moves to their right on the screen. The size of the image can be controlled by moving the tile towards the web camera (to enlarge) or away from it (to reduce). This interface allows learners to hold tiles and to explore and identify the characteristics of components of the virtual 3D model by inspection of its content as well as by rotating the tile so that the image can be seen from different perspectives.</p><h3 class="c-article__sub-heading" id="Sec7">Methodology</h3><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec8">Participants and teaching sessions</h4><p>Year 5 children (mean age 10 years) and their teachers from five London primary schools were invited to participate. In total, 133 children attended the five teaching sessions with their class teachers and classroom assistants. The mean of the class size across these five sessions was 27 and the total session length was two hours. The teachers and children were not told in advance that they would be using AR because we were keen to explore their initial reactions to the technology and assess the ease with which teachers with no prior training could use it. They were, however, told that they would have the opportunity to experience some new technology that they had probably never seen before.</p><p>Upon arrival, the children were divided into two groups and a researcher familiarised each group with the AR technology using two AR tiles. Each tile displayed an animated fictional character that waved and bowed and introduced themselves via a text bubble. The children sat on the floor in front of the whiteboard whilst a researcher demonstrated how to align the tile with the web cam, prevent occlusion of the image by keeping fingers away, move the tile towards and away from the web cam to increase and decrease the size of the image, and rotate and tilt the tile to change the viewer’s perspective. Following this, each child chose a character, stood in front of the whiteboard and spent a few minutes practising with the tile individually whilst the rest of the group observed. We were encouraged by the fact that there was no evidence that the children were confused by holding a 2D tile that visually represented a 3D image.</p><p>Following the familiarisation session, the class was split into three groups of around nine children. Each group of children participated in two out of four teaching sessions of 45 min each, with a short refreshment break in-between. These sessions were two of:</p><ol class="u-list-style-none">
                      <li>
                        <span class="u-custom-list-number">1.</span>
                        
                          <p>An AR session led by a teacher who had experience of using AR.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">2.</span>
                        
                          <p>An AR session led by the children’s own class teacher, who had observed the first session and had undergone a short 10 minute training session with the trained teacher.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">3.</span>
                        
                          <p>A traditional teaching session led by one of 2 ex-primary-school teachers on the research team. These two teachers each used methods with which they were familiar and comfortable. Teacher A first used a large print book (Smith 1994) designed for group work. Children volunteered to read paragraphs and were invited to participate as actors in role-playing the movement of the earth and the moon around the sun. Teacher B did not use a book but instead talked about the solar system in general then asked the children to help in a demonstration using a tennis ball on a string to represent the earth and a torch to represent the sun. This variety was useful in that it represented some of the different teaching methods and resources used in various schools.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">4.</span>
                        
                          <p>A session using the BBC ReviseWise website using their material for Key Stage 2. The children each sat at their own PC and proceeded through the pages and quiz at their own pace.</p>
                        
                      </li>
                    </ol><p>Details of the distribution of groups across activities are in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-006-0036-4#Tab1">1</a> (not all data was used in the final analysis; see Sect. 3.1 for details).
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 The distribution of groups across the four activities</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-006-0036-4/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <p>All of the sessions were videotaped, as were the sessions when the class teachers were given training by the teacher with experience of AR. Unfortunately, due to the high volume of child conversation during the website sessions it was not possible to hear each child’s contributions, so these sessions were not analysed. We therefore focus our analysis on the AR and traditional teaching sessions.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec9">Class teacher interviews</h4><p>We were keen to obtain feedback from the children’s class teachers and all five participated in a semi-structured, audio recorded, telephone interview organised around key questions (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-006-0036-4#Tab2">2</a> for schedule). These were conducted within a few days of the session.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Class teachers’ telephone interview schedule</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-006-0036-4/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  </div></div></section><section aria-labelledby="Sec10"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Analysis and findings </h2><div class="c-article-section__content" id="Sec10-content"><h3 class="c-article__sub-heading" id="Sec11">Data analysis</h3><p>Analysis focused on three data sources: the video-recorded lessons carried out by the AR-trained teacher; video footage of the traditional teaching sessions, and audio files of the five telephone interviews with the children’s class teachers. There was a large amount of video footage to analyse so, for practical reasons, 10 min sections from three AR and three traditional teaching sessions were transcribed. We were keen to capture when the teacher led the class and when the children were participating, so the point at which the teacher invited children to participate was identified on the tape and 5 min were transcribed either side of this point.</p><p>The transcriptions were coded and analysed using NUD*IST qualitative analysis software to identify emergent themes. Utterances were divided into those made by teachers and those made by children. Across both the AR and traditional teaching sessions, three main types of teacher utterance were identified: </p><ol class="u-list-style-none">
                    <li>
                      <span class="u-custom-list-number">1.</span>
                      
                        <p>Questions (e.g. “does the earth spin?”).</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">2.</span>
                      
                        <p>Statements (e.g. “the equator goes around the middle of the earth”).</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">3.</span>
                      
                        <p>Technical resource comments (e.g. “hold the tile in view of the camera” or “there’s not enough space for you to spin around”).</p>
                      
                    </li>
                  </ol><p>The questioning category of the teacher’s utterances were more concerned with engaging the children in the session and these are of greatest interest to this discussion. The teacher’s questions could be categorised into those that:</p><ul class="u-list-style-bullet">
                    <li>
                      <p>Encouraged children to relate what they knew</p>
                    </li>
                    <li>
                      <p>Encouraged children to describe what they could see.</p>
                    </li>
                  </ul><p>Each of these question types could be subcategorised further as illustrated in Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-006-0036-4#Tab3">3</a> and <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-006-0036-4#Tab4">4</a> along with the percentage contribution of each type to the total of teacher questions.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 subcategories of teacher questions that encouraged children to relate what they know</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-006-0036-4/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 subcategories of teacher’s questions that encouraged children to describe what they could see</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-006-0036-4/tables/4"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>A coding scheme was developed that represented each type of sub-category. These codes were then applied to the transcripts. Two of the transcriptions (one AR and one traditional teaching) were independently, double-coded by a second person. There was 96% agreement between the two coders. NUD*IST was then used first to count incidences of each code and then to sort codes into categories. In this way it was possible to conceptualise how codes were related. Children’s utterances were also coded. They were mostly replies in direct response to the teachers’ questions; they mirrored the category of the teacher’s utterances, so are not considered any further here.</p><h3 class="c-article__sub-heading" id="Sec12">Comparing teacher dialogue across AR and traditional teaching sessions </h3><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec13">Teacher questions in the AR sessions: clarifying the relationship between elements on the screen</h4><p>Interestingly, only 8.3% of the teacher’s questions involved asking the children to use AR to explore the relationships between elements. This relatively low percentage is surprising because previous work has suggested that one of the main advantages of using AR would be to display relationships and movements between elements in 3D space. The children were also given only limited opportunity to explore relationships for themselves; most was carried out by the teacher. Children’s replies to the teacher’s questions were not lengthy and often consisted of just one word. On average, the teacher contributed 1,700 words to a ten minute interchange and the children contributed only 175. The excerpts below are examples of when the teacher was standing at the front of the group, holding and manipulating the tile herself, with the children sitting on the floor in front of the whiteboard:</p>
                    <div class="c-article-table-container"><div class="c-article-table-border c-table-scroll-wrapper"><div class="c-table-scroll-wrapper__content" data-component-scroll-wrapper=""><table class="data last-table"><thead class="c-article-table-head"><tr><th class="u-text-left " colspan="3">
                              Excerpt 1
                            </th></tr></thead><tbody><tr><td class="u-text-left ">
                              1
                            </td><td class="u-text-left " colspan="2">
                              T: I want you to have a look at what’s happening to the person, when
                            </td></tr><tr><td class="u-text-left ">
                              2
                            </td><td class="u-text-left " colspan="2">
                              they go round to the sunny side of the earth, and what’s happening to the
                            </td></tr><tr><td class="u-text-left ">
                              3
                            </td><td class="u-text-left " colspan="2">
                              person when they go round to the other side of the earth...
                            </td></tr><tr><td class="u-text-left ">
                              4
                            </td><td class="u-text-left " colspan="2">
                              C: She wakes up.
                            </td></tr><tr><td class="u-text-left ">
                              5
                            </td><td class="u-text-left " colspan="2">
                              T: She wakes up. Excellent. Fantastic. OK, right, she wakes up. And
                            </td></tr><tr><td class="u-text-left ">
                              6
                            </td><td class="u-text-left " colspan="2">
                              what’s happening at the time when the earth is rotating away from the
                            </td></tr><tr><td class="u-text-left ">
                              7
                            </td><td class="u-text-left " colspan="2">
                              sun. What happens to her then?
                            </td></tr><tr><td class="u-text-left ">
                              8
                            </td><td class="u-text-left " colspan="2">
                              C: It’s turning night and day.
                            </td></tr><tr><td class="u-text-left ">
                              9
                            </td><td class="u-text-left " colspan="2">
                              T: It’s turning night and day. Fantastic. So, we can see that the earth is
                            </td></tr><tr><td class="u-text-left ">
                              10
                            </td><td class="u-text-left " colspan="2">
                              rotating towards the sun, and when it rotates towards the sun, what time
                            </td></tr><tr><td class="u-text-left ">
                              11
                            </td><td class="u-text-left " colspan="2">
                              of the day or night is it then, when the earth rotates to face the sun?
                            </td></tr><tr><td class="u-text-left ">
                              12
                            </td><td class="u-text-left " colspan="2">
                              C: Daytime
                            </td></tr><tr><td class="u-text-left ">
                              13
                            </td><td class="u-text-left " colspan="2">
                              T: It’s daytime. You’re absolutely right
                            </td></tr></tbody></table></div></div></div>
                  <p> Here, the teacher begins to introduce the concept of night and day by asking the children to watch what happens to a little girl (she gets into bed when her side of the earth spins into darkness and gets up again when its light, over and over again). She then asks the children to watch what happens when the earth spins away from the sun, a child describes how it turns from day into night and another child provides the correct term ‘daytime’ to describe the earth when it is in the sun’s light.</p><p>In excerpt two, the teacher uses the AR animation to illustrate that the earth rotates around a stationary sun:</p>
                    <div class="c-article-table-container"><div class="c-article-table-border c-table-scroll-wrapper"><div class="c-table-scroll-wrapper__content" data-component-scroll-wrapper=""><table class="data last-table"><thead class="c-article-table-head"><tr><th class="u-text-left " colspan="3">
                              Excerpt 2
                            </th></tr></thead><tbody><tr><td class="u-text-left ">
                              1
                            </td><td class="u-text-left " colspan="2">
                              T: So the earth spins or rotates around its own axis as it is doing there.
                            </td></tr><tr><td class="u-text-left ">
                              2
                            </td><td class="u-text-left " colspan="2">
                              Is the sun moving?
                            </td></tr><tr><td class="u-text-left ">
                              3
                            </td><td class="u-text-left " colspan="2">
                              C’s [chorus]: No.
                            </td></tr><tr><td class="u-text-left ">
                              4
                            </td><td class="u-text-left " colspan="2">
                              T: Does the sun move?
                            </td></tr><tr><td class="u-text-left ">
                              5
                            </td><td class="u-text-left " colspan="2">
                              C’s [chorus]: No.
                            </td></tr><tr><td class="u-text-left ">
                              6
                            </td><td class="u-text-left " colspan="2">
                              T: No. It’s really important that we remember that as well. So that the
                            </td></tr><tr><td class="u-text-left ">
                              7
                            </td><td class="u-text-left " colspan="2">
                              sun doesn’t move, the earth does.
                            </td></tr></tbody></table></div></div></div>
                  <p>These are good examples of how the technology can be used to teach about the relationships between elements but, unfortunately, the children’s role is rather passive, similar to when watching a video or an animation on a web page. The teacher is holding the tile and the children are asked only to watch and interpret events from a distance. The children’s’ contributions are short; they are brief descriptions of what they can see, they do not involve explanations of why things occur and they are not manipulating the tile to find out things. If we look more closely at the children’s replies, they are all providing the correct vocabulary as required by the National Curriculum, (‘night’ and ‘day’, ‘day time’). The teacher tightly guided these interactions. She drew the children’s attention to salient facts, made sure they knew the necessary vocabulary and used the AR as a tool to illustrate the inter-relationships between the earth’s spin and the occurrence of night and day. However, the children were not given the opportunity to explore concepts or to ask questions.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec14">Teacher questions in the AR sessions: the children’s turn to hold a tile</h4><p>Excerpts three and four are from periods of time when some children were standing at the front of the group, using the AR tile themselves. These examples demonstrate that, again, the children remained relatively passive and that they were asked to replicate what the teacher had previously carried out:</p>
                    <div class="c-article-table-container"><div class="c-article-table-border c-table-scroll-wrapper"><div class="c-table-scroll-wrapper__content" data-component-scroll-wrapper=""><table class="data last-table"><thead class="c-article-table-head"><tr><th class="u-text-left " colspan="3">
                              Excerpt 3
                            </th></tr></thead><tbody><tr><td class="u-text-left ">
                              1
                            </td><td class="u-text-left " colspan="2">
                              T: If you three come out, and you see if you can
                            </td></tr><tr><td class="u-text-left ">
                              2
                            </td><td class="u-text-left " colspan="2">
                              rotate it for me, so that we’re looking at the
                            </td></tr><tr><td class="u-text-left ">
                              3
                            </td><td class="u-text-left " colspan="2">
                              world when it’s in darkness, so the dark part of
                            </td></tr><tr><td class="u-text-left ">
                              4
                            </td><td class="u-text-left " colspan="2">
                              the world is in darkness [one child has hold
                            </td></tr><tr><td class="u-text-left ">
                              5
                            </td><td class="u-text-left " colspan="2">
                              of the tile]. And if you angle
                            </td></tr><tr><td class="u-text-left ">
                              6
                            </td><td class="u-text-left " colspan="2">
                              it slightly, so we can see, um, from the, slightly more underneath rather
                            </td></tr><tr><td class="u-text-left ">
                              7
                            </td><td class="u-text-left " colspan="2">
                              than from on top. Fantastic. OK. Tell me what country you can see
                            </td></tr><tr><td class="u-text-left ">
                              8
                            </td><td class="u-text-left " colspan="2">
                              passing. Yes?
                            </td></tr><tr><td class="u-text-left ">
                              9
                            </td><td class="u-text-left " colspan="2">
                              C: I see, er, Russia.
                            </td></tr><tr><td class="u-text-left ">
                              10
                            </td><td class="u-text-left " colspan="2">
                              T: OK, excellent, Russia. What’s that one there now, again, OK, coming
                            </td></tr><tr><td class="u-text-left ">
                              11
                            </td><td class="u-text-left " colspan="2">
                              round now, it’s darkness in ... what’s that one there, the continent?
                            </td></tr><tr><td class="u-text-left ">
                              12
                            </td><td class="u-text-left " colspan="2">
                              [they continue identifying several more countries]
                            </td></tr><tr><td class="u-text-left ">
                              13
                            </td><td class="u-text-left " colspan="2">
                              T: That’s fantastic. Just hold it there for me. So we’re exactly as we were
                            </td></tr><tr><td class="u-text-left ">
                              14
                            </td><td class="u-text-left " colspan="2">
                              before, we’re on the sun, as if we’re looking at the earth, and the earth is
                            </td></tr><tr><td class="u-text-left ">
                              15
                            </td><td class="u-text-left " colspan="2">
                              turning towards the sun, and it’s in daylight.
                            </td></tr></tbody></table></div></div></div>
                  <p>In excerpt three, the teacher asks three children to come to the front of the class to have a go. However, their role is rather passive; she tells them how to hold the tile (lines 4–7 and 13), and which views to find in the animation (lines 1–2, 6) for her (1, 13) which are “exactly as we were before” (13–14) when she did it previously. They are being asked to replicate what she has already done but this time they are also asked to identify the countries and continents that are going past as the earth rotates through light and darkness. This is an effective way to help children understand how day and night occur in different places on the earth but the children are obeying instructions and are watching it happen rather than making it happen for themselves; they stand in one place and hold the tile stationary. A similar scenario is exemplified in excerpt 4:</p>
                    <div class="c-article-table-container"><div class="c-article-table-border c-table-scroll-wrapper"><div class="c-table-scroll-wrapper__content" data-component-scroll-wrapper=""><table class="data last-table"><thead class="c-article-table-head"><tr><th class="u-text-left " colspan="3">
                              Excerpt 4
                            </th></tr></thead><tbody><tr><td class="u-text-left ">
                              1
                            </td><td class="u-text-left " colspan="2">
                              T: Can you come and show us midnight?
                            </td></tr><tr><td class="u-text-left ">
                              2
                            </td><td class="u-text-left " colspan="2">
                              [child gets up and holds the tile]
                            </td></tr><tr><td class="u-text-left ">
                              3
                            </td><td class="u-text-left " colspan="2">
                              T: That’s it. Now, remember, you’re holding up that corner there, that’s
                            </td></tr><tr><td class="u-text-left ">
                              4
                            </td><td class="u-text-left " colspan="2">
                              it, great. OK, excellent. We’ve got midnight here. We’re watching the
                            </td></tr><tr><td class="u-text-left ">
                              5
                            </td><td class="u-text-left " colspan="2">
                              part of the earth, as it comes right away from the sun, it’s rotating right
                            </td></tr><tr><td class="u-text-left ">
                              6
                            </td><td class="u-text-left " colspan="2">
                              the way towards midnight. Excellent, thank you very much.
                            </td></tr></tbody></table></div></div></div>
                  <p>In this example, the teacher, again, instructs the child on exactly what to find (line 1) and how to hold the tile (3). The teacher describes what they are watching (4–5) and the child is not encouraged to make a verbal contribution before being thanked (6) and sitting back on the floor.</p><p>This section has demonstrated the role that institutional constraints play in realising the potential of new technologies. Lessons are short and it is possible that, in this case, in order to facilitate the delivery of all the material required by the national curriculum there was not enough time for the teacher to allow the children to explore for themselves. There appears to be a gap between the national curriculum, with its delivery-based focus, and exploratory learning engendered by new technologies (Lewin et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Lewin C, Mavers D, Somekh B (2003) Broadening access to the curriculum through using technology to link home and school: a critical analysis of reforms to improve educational attainment for all K-12 students. Curriculum J 14(1):23–54" href="/article/10.1007/s10055-006-0036-4#ref-CR15" id="ref-link-section-d48172e2258">2003</a>) that this teacher was, understandably, unable to bridge.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec15">Teacher questions in the traditional teaching sessions</h4><p>Teacher questions in the traditional teaching sessions were focused on the content of the large book that was used, or on the children’s role-play.</p>
                    <h3 class="c-article__sub-heading">Book content</h3>
                    <p>The book was used as a visual and factual resource: children were asked to use the pictures to ascertain the relative positions and sizes of the earth, sun and moon, or to read the text. This is illustrated in the following excerpts:</p>
                  
                    <div class="c-article-table-container"><div class="c-article-table-border c-table-scroll-wrapper"><div class="c-table-scroll-wrapper__content" data-component-scroll-wrapper=""><table class="data last-table"><thead class="c-article-table-head"><tr><th class="u-text-left " colspan="3">
                              Excerpt 5
                            </th></tr></thead><tbody><tr><td class="u-text-left ">
                              1
                            </td><td class="u-text-left " colspan="2">
                              T: [holding open the book] So where’s our sun? Can you point to the sun?
                            </td></tr><tr><td class="u-text-left ">
                              2
                            </td><td class="u-text-left " colspan="2">
                              C: [points]
                            </td></tr><tr><td class="u-text-left ">
                              3
                            </td><td class="u-text-left " colspan="2">
                              T: Brilliant, OK. Fantastic. What’s the third planet from the sun?
                            </td></tr><tr><td class="u-text-left ">
                              4
                            </td><td class="u-text-left " colspan="2">
                              C: Um, is it Venus?
                            </td></tr><tr><td class="u-text-left ">
                              5
                            </td><td class="u-text-left " colspan="2">
                              T: The third one. Can you count the third one along?
                            </td></tr><tr><td class="u-text-left ">
                              6
                            </td><td class="u-text-left " colspan="2">
                              C: Earth.
                            </td></tr><tr><td class="u-text-left ">
                              7
                            </td><td class="u-text-left " colspan="2">
                              T: Earth—brilliant. You can see us here, we’re the third planet from the
                            </td></tr><tr><td class="u-text-left ">
                              8
                            </td><td class="u-text-left " colspan="2">
                              sun. Is the Earth smaller, or bigger than the sun?
                            </td></tr><tr><td class="u-text-left ">
                              9
                            </td><td class="u-text-left " colspan="2">
                              C: Smaller.
                            </td></tr><tr><td class="u-text-left ">
                              10
                            </td><td class="u-text-left " colspan="2">
                              T: Smaller, fantastic, OK.
                            </td></tr></tbody></table></div></div></div>
                  
                    <div class="c-article-table-container"><div class="c-article-table-border c-table-scroll-wrapper"><div class="c-table-scroll-wrapper__content" data-component-scroll-wrapper=""><table class="data last-table"><thead class="c-article-table-head"><tr><th class="u-text-left " colspan="3">
                              Excerpt 6
                            </th></tr></thead><tbody><tr><td class="u-text-left ">
                              1
                            </td><td class="u-text-left " colspan="2">
                              T: Can we have a volunteer to read this paragraph here? [points to a child].
                            </td></tr><tr><td class="u-text-left ">
                              2
                            </td><td class="u-text-left " colspan="2">
                              C [reading from the book]: The sun is so big that you could fit the earth
                            </td></tr><tr><td class="u-text-left ">
                              3
                            </td><td class="u-text-left " colspan="2">
                              inside it more than a million times. Compared with some other stars,
                            </td></tr><tr><td class="u-text-left ">
                              4
                            </td><td class="u-text-left " colspan="2">
                              though, the sun is tiny.
                            </td></tr><tr><td class="u-text-left ">
                              5
                            </td><td class="u-text-left " colspan="2">
                              T: OK. Compared with other stars, it’s tiny, but you see how enormous it
                            </td></tr><tr><td class="u-text-left ">
                              6
                            </td><td class="u-text-left " colspan="2">
                              is compared to the earth. A fact about the moon [child’s name]?
                            </td></tr><tr><td class="u-text-left ">
                              7
                            </td><td class="u-text-left " colspan="2">
                              C: Shall I read it?
                            </td></tr><tr><td class="u-text-left ">
                              8
                            </td><td class="u-text-left " colspan="2">
                              T: Yes please, if you could just read the first little bit
                            </td></tr><tr><td class="u-text-left ">
                              9
                            </td><td class="u-text-left " colspan="2">
                              C [reading]: The moon spins around and around the earth. It is about four
                            </td></tr><tr><td class="u-text-left ">
                              10
                            </td><td class="u-text-left " colspan="2">
                              times smaller than our planet.
                            </td></tr><tr><td class="u-text-left ">
                              11
                            </td><td class="u-text-left " colspan="2">
                              T: OK. So in order of size, if we’re thinking about size and shape, what
                            </td></tr><tr><td class="u-text-left ">
                              12
                            </td><td class="u-text-left " colspan="2">
                              shape are they, first of all?
                            </td></tr></tbody></table></div></div></div>
                  <p>The question answer interchanges in excerpts 5 and 6 are similar to those that occurred during the AR teaching sessions, the main difference being that here the children are supplying the answers by reading the text or interpreting the diagrams. Throughout the two transcribed book-reading sections, the teacher also made three non-questioning utterances that provided additional information that was not available in the book e.g. “<i>We can see the sun and it doesn’t move</i>”<i>.</i> This is interesting in that it provides information that a 2D, static resource, such as book, cannot provide and that AR does provide; the teacher then used role-play to teach these aspects.</p>
                    <h3 class="c-article__sub-heading">Role-play content</h3>
                    <p>Children were asked to become active participants in role-playing movements and relationships. This is an interesting contrast to the AR sessions in which they watched the screen. In both the traditional and the AR sessions, 81% of the teacher’s questions were using the children as a resource of information. However, an important difference is that children in traditional teaching sessions were asked to provide information about movements, relationships and sizes that they could not see; they had to tell the volunteers what to do, whereas the children using AR were asked to inspect the animation and to tell what they could see. These differences are exemplified in excerpt 7, part of a traditional teaching session where the teacher has already asked a volunteer to ‘be’ the sun and is asking for someone else to ‘be’ the earth:</p>
                  
                    <div class="c-article-table-container"><div class="c-article-table-border c-table-scroll-wrapper"><div class="c-table-scroll-wrapper__content" data-component-scroll-wrapper=""><table class="data last-table"><thead class="c-article-table-head"><tr><th class="u-text-left " colspan="3">
                              Excerpt 7
                            </th></tr></thead><tbody><tr><td class="u-text-left ">
                              1
                            </td><td class="u-text-left " colspan="2">
                              T: Who’d like to be the earth? Come and show us, [child’s name]. Now,
                            </td></tr><tr><td class="u-text-left ">
                              2
                            </td><td class="u-text-left " colspan="2">
                              someone, can somebody place where we think the earth should stand?
                            </td></tr><tr><td class="u-text-left ">
                              3
                            </td><td class="u-text-left " colspan="2">
                              [child name], come and help us.
                            </td></tr><tr><td class="u-text-left ">
                              4
                            </td><td class="u-text-left " colspan="2">
                              C: [coming to the group at the front] Um, she should stand, um, there
                            </td></tr><tr><td class="u-text-left ">
                              5
                            </td><td class="u-text-left " colspan="2">
                              [goes back to his place].
                            </td></tr><tr><td class="u-text-left ">
                              6
                            </td><td class="u-text-left " colspan="2">
                              T: About there. Would we agree?
                            </td></tr><tr><td class="u-text-left ">
                              7
                            </td><td class="u-text-left " colspan="2">
                              C (all): Yeees.
                            </td></tr><tr><td class="u-text-left ">
                              8
                            </td><td class="u-text-left " colspan="2">
                              T: OK. For today, she’s going to stand about there. Now, what do we
                            </td></tr><tr><td class="u-text-left ">
                              9
                            </td><td class="u-text-left " colspan="2">
                              want her to do? Is the earth going to stand still, or is the earth going to
                            </td></tr><tr><td class="u-text-left ">
                              10
                            </td><td class="u-text-left " colspan="2">
                              move, or to orbit?
                            </td></tr><tr><td class="u-text-left ">
                              11
                            </td><td class="u-text-left " colspan="2">
                              C: Move?
                            </td></tr><tr><td class="u-text-left ">
                              12
                            </td><td class="u-text-left " colspan="2">
                              T: It’s going to move, it’s going to orbit. Do you know, what it’s going
                            </td></tr><tr><td class="u-text-left ">
                              13
                            </td><td class="u-text-left " colspan="2">
                              to do?
                            </td></tr><tr><td class="u-text-left ">
                              14
                            </td><td class="u-text-left " colspan="2">
                              C: Turn round.
                            </td></tr><tr><td class="u-text-left ">
                              15
                            </td><td class="u-text-left " colspan="2">
                              T: Ah, OK. So can you show us? Can you make her do it?
                            </td></tr><tr><td class="u-text-left ">
                              16
                            </td><td class="u-text-left " colspan="2">
                              [A child comes to the front, and pushes the girl being the earth forwards
                            </td></tr><tr><td class="u-text-left ">
                              17
                            </td><td class="u-text-left " colspan="2">
                              in a complete circle around the girl being the sun].
                            </td></tr><tr><td class="u-text-left ">
                              18
                            </td><td class="u-text-left " colspan="2">
                              T: And what’s the other way she’s going round? It’s ...
                            </td></tr><tr><td class="u-text-left ">
                              19
                            </td><td class="u-text-left " colspan="2">
                              C: She’s spinning around.
                            </td></tr><tr><td class="u-text-left ">
                              20
                            </td><td class="u-text-left " colspan="2">
                              T: She’s spinning! She’s going to spin at the same time.
                            </td></tr><tr><td class="u-text-left ">
                              21
                            </td><td class="u-text-left " colspan="2">
                              Can you do that? [laughs] Just give us one spin.
                            </td></tr><tr><td class="u-text-left ">
                              22
                            </td><td class="u-text-left " colspan="2">
                              [earth spins around once]
                            </td></tr><tr><td class="u-text-left ">
                              23
                            </td><td class="u-text-left " colspan="2">
                              T: OK. So she’s going to spin. We call that spinning on the axis. Do you
                            </td></tr><tr><td class="u-text-left ">
                              24
                            </td><td class="u-text-left " colspan="2">
                              think you can show us? [laughs] Have a go.
                            </td></tr><tr><td class="u-text-left ">
                              25
                            </td><td class="u-text-left " colspan="2">
                              [the earth child spins and orbits around the sun child].
                            </td></tr><tr><td class="u-text-left ">
                              26
                            </td><td class="u-text-left " colspan="2">
                              T: Perfect. Absolutely perfect.
                            </td></tr></tbody></table></div></div></div>
                  <p> In excerpt 7, it is clear that the children are more active, both verbally and physically, than those in the participatory section of the AR sessions. This traditional teaching session is still closely guided and supported by the teacher, but the children build up their own role play. In this excerpt, the teacher asks them who would like to volunteer (line 1), where the actor should stand (2), for instructions on how the actors should move (9, 10, 12–13, 15, 18), for role-played examples of actions (21, 23, 24) and also whether the children agree that the actors are doing the right thing (6). The children are building and animating their own representation rather than passively watching it unfold in an AR animation.</p><p>In excerpt 8, there are further examples of the children’s active involvement. Here, they decide the speed at which a child representing the speed at which a child representing the earth should spin (5 and 7), as well as the distance he should stand (10) from the child representing the sun.</p>
                    <div class="c-article-table-container"><div class="c-article-table-border c-table-scroll-wrapper"><div class="c-table-scroll-wrapper__content" data-component-scroll-wrapper=""><table class="data last-table"><thead class="c-article-table-head"><tr><th class="u-text-left " colspan="3">
                              Excerpt 8
                            </th></tr></thead><tbody><tr><td class="u-text-left ">
                              1
                            </td><td class="u-text-left " colspan="2">
                              T: He’s going to travel around the sun. Can you show us how he might
                            </td></tr><tr><td class="u-text-left ">
                              2
                            </td><td class="u-text-left " colspan="2">
                              do that?
                            </td></tr><tr><td class="u-text-left ">
                              3
                            </td><td class="u-text-left " colspan="2">
                              [the earth child moves around the sun child].
                            </td></tr><tr><td class="u-text-left ">
                              4
                            </td><td class="u-text-left " colspan="2">
                              T: That’s it
                            </td></tr><tr><td class="u-text-left ">
                              5
                            </td><td class="u-text-left " colspan="2">
                              C: Not that fast!
                            </td></tr><tr><td class="u-text-left ">
                              6
                            </td><td class="u-text-left " colspan="2">
                              T: Not that fast, OK, so how do you want him to be?
                            </td></tr><tr><td class="u-text-left ">
                              7
                            </td><td class="u-text-left " colspan="2">
                              C: A bit slower.
                            </td></tr><tr><td class="u-text-left ">
                              8
                            </td><td class="u-text-left " colspan="2">
                              T: A bit slower; let’s try a bit slower. And is he going to be that close?
                            </td></tr><tr><td class="u-text-left ">
                              9
                            </td><td class="u-text-left " colspan="2">
                              C [chorus]: No
                            </td></tr><tr><td class="u-text-left ">
                              10
                            </td><td class="u-text-left " colspan="2">
                              T: How far do you want him to be?
                            </td></tr><tr><td class="u-text-left ">
                              11
                            </td><td class="u-text-left " colspan="2">
                              T: OK. So in order of size, if we’re thinking about size and shape, what
                            </td></tr></tbody></table></div></div></div>
                  <p>In this section, we have seen how the levels of child participation and engagement in the traditional teaching sessions were higher than in the AR sessions. However, these examples also give an indication how difficult it can be to role-play the complex inter-relationships between the earth, sun and moon (avoiding child collisions and dizziness), and hence where AR could make a positive contribution.</p></div></div></section><section aria-labelledby="Sec16"><div class="c-article-section" id="Sec16-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec16">Teacher interviews</h2><div class="c-article-section__content" id="Sec16-content"><p>The teachers’ interviews were transcribed and categorised. The teacher’s and children’s initial reactions upon seeing their first AR image were of delight and amazement. They had never seen the technology before and were fascinated by how it worked to produce an image from the tile. The children were smiling and animated and voiced their enthusiasm, e.g. “<i>woah! That’s sooo cool</i>!” and “<i>that’s amazing, how does it do that?</i>”<i>.</i> They were all very keen to find out how it worked and to have a go for themselves.</p><p>The teachers were particularly impressed by how AR can make traditionally inaccessible subject matter available to the children: “<i>It takes something that you would never experience because it’s in outer space</i>”<i>.</i> Two teachers said they enjoyed it when the subject matter suddenly became ‘real’ for their children and they understood relationships that had previously been difficult to grasp. One said, “<i>I saw one boy and he was saying that he could see that it was the sun that was shining straight on [the earth]. He can see that picture in his head now rather than just being told it, or like with a globe and a torch and having to work out what stands for what</i>”<i>.</i>
              </p><p>Other teachers supported this observation as they realised the benefits of 3D imagery and movement over traditional 2D teaching resources in “<i>making it real</i>”<i>.</i> One explained that “<i>we</i>’<i>ve </i>[<i>hitherto</i>]<i> had to make do with pictures, and most are still life pictures so they don</i>’<i>t get the true effect of the movement. I then had to go one step further by using drama</i>,<i> but then too it could possibly lose the essence of what you</i>’<i>re actually trying to get across</i>”<i>.</i> Being able to rotate the tile and take different perspectives of the 3D image was also adding an extra dimension: “<i>I really liked it when you could turn it round and see the other side of the earth in darkness</i>,<i> that was really good</i>...<i>round the other side of things that you would n</i>’<i>t normally see</i>”. All of these comments suggest that teachers found AR particularly useful for making the subject matter accessible and real. They all stated that if AR was available for them to use in their classrooms, they would use it as an additional resource, alongside more traditional media, to reinforce points already made and to help counter misunderstandings. One teacher of a class with a high proportion of children with special educational needs, said that AR would be particularly useful to her as “<i>they need to have it in so many different ways that they can share</i>”<i>.</i>
              </p><p>However, the teachers also voiced some apprehensions; some expressed concern about the inflexibility of the content. As mentioned above, they had access to two tiles, each of which was programmed to display a substantial amount of animation. For example, one tile contained the earth rotating and orbiting the sun, the moon orbiting the earth plus an animated clock and a girl that got into bed at sunset and got up again at dawn (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-006-0036-4#Fig1">1</a>). Three teachers said that they would like more control over the content, specifically the ability to break it down into stages so that elements are gradually introduced rather than all of them being present from the beginning: “<i>It would be useful if you could have just the moon and the earth</i>,<i> and then a second stage where you could have the sun in the middle and the earth and the moon going round it</i>”<i>.</i> None of the teachers spoke about the utility of asking the children to do this themselves, and the ways in which the children could explore concepts by adding and removing elements but this was probably a function of the fact that the technology was very new to them and they did not realise its full potential.</p><p>Two of the teachers were also concerned about flexibility in terms of being able to pause or stop the animation. One said “I found that at certain points I wanted to pause, I wanted to freeze the picture so as to point to it and ask more questions about it. I couldn’t do that because it gives continuous movement of the picture at all times”. The other teacher was concerned about the speed at which the animation occurred, making it difficult for some children to understand what was happening: “I could see that there were a couple of the strugglers and I said ‘how many hours is a day?’ and they were looking blankly, so I said, ‘look at the clock’, but the clock goes too fast for them. It would be good to slow it down and also to stop it at various times and ask ‘is it day time or night time in England at the moment?’”. The inclusion of this type of flexibility in future versions of the software will make it more adaptable to children of different abilities.</p><p>Four of the five teachers also said that they found it difficult to focus on doing several things at once: keeping the tile within range of the web cam, preventing image occlusion with their fingers, talking to their class and controlling them, all at the same time. One teacher said, “<i>I was having to focus on holding the tile and it kept flickering on and off. Because I was concentrating all the time on doing that I wasn</i>’<i>t able to look at the kids. Its hard think about what you</i>’<i>re saying and try to explain something fluently when your whole attention is placed on holding the tile</i>”<i>.</i> However, they all recognised that it would become easier with practice and one teacher could foresee how AR had the potential to make her class management easier: “<i>You stand at an angle, keeping your eye on the class as well as the subject matter</i>...<i>which makes it better than the traditional way of scribing and turning your back to the rest of the class.</i>
                <i>I really advocate the use of it</i>”<i>.</i>
              </p></div></div></section><section aria-labelledby="Sec17"><div class="c-article-section" id="Sec17-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec17">Discussion</h2><div class="c-article-section__content" id="Sec17-content"><p>Overall, this study has been successful in supporting and providing evidence for the potential that AR offers to formal education. Our comparison between teachers’ use of AR with their use of traditional teaching materials has illustrated that AR can be used to help 10-year-old children understand how the earth and sun interact in 3D space to give rise to day and night. However, we also found that children taught using our AR software were less engaged than those involved in role-play; teachers were more likely to ask the children to watch an AR animation and describe it, compared to the role play sessions in which children were encouraged to create and control the roles of the actors. The interviewed teachers also recognised the potential of AR technology, but said that they would like it to be more flexible and controllable, so that they could add and remove separate elements, and slow down or stop the animation sequences. Their feedback suggests that these features would enable them to involve their children more in, for example, exploring the relationships between elements by altering parameters.</p><p>These findings support previous work that has explored the use of both AR and VR for teaching where the focus has been on designing environments that students can manipulate and explore so as to promote inquiry-based learning. For example, Shelton and Hedley (Shelton and Hedley <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Shelton B, Hedley N (2002) Using augmented reality for teaching earth–sun relationships to undergraduate geography students. In: The 1st IEEE international augmented reality toolkit workshop. Darmstadt, Germany" href="/article/10.1007/s10055-006-0036-4#ref-CR20" id="ref-link-section-d48172e3333">2002</a>; Shelton and Hedley <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Shelton B, Hedley N (2003) Exploring a cognitive basis for learning spatial relationships with augmented reality. Tech Inst Cogn Learning 1:323–357" href="/article/10.1007/s10055-006-0036-4#ref-CR21" id="ref-link-section-d48172e3336">2003</a>) argue that the 3D nature of the AR experience, together with providing learners with an opportunity to manipulate time, position, angles, rotation and revolution, and encouraging them to reflect upon the implications of their actions, are key to achieving changes in understanding. They argue (Shelton and Hedley <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Shelton B, Hedley N (2002) Using augmented reality for teaching earth–sun relationships to undergraduate geography students. In: The 1st IEEE international augmented reality toolkit workshop. Darmstadt, Germany" href="/article/10.1007/s10055-006-0036-4#ref-CR20" id="ref-link-section-d48172e3339">2002</a>) that there is no need to pretend that an apple is the sun (or, in the case of the current study, that a classmate is the sun) when a learner can be provided with a digital sun that can be manipulated. Barab, Hay, Squire, Barnett, Schmidt, Karrigan, Yamagat-Lynch and Johnson (Barab et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Barab S, Hay K, Squire K, Barnett M, Schmidt R, Karrigan K, Yamagat-Lynch L, Johnson C (2000) Virtual solar system project: learning through a technology- rich, inquiry-based, participatory learning environment. J Sci Educ Technol 9(1):7–25" href="/article/10.1007/s10055-006-0036-4#ref-CR3" id="ref-link-section-d48172e3342">2000</a>) gave undergraduates an opportunity to use 3D modelling tools to construct VR models of the solar system. They found this was an effective way to promote grounded understanding as the students discovered facts about, for example, the relative sizes of elements, in order to be able to build them. This study involves a different level and type of engagement to that described by Shelton and Hedley and is a further example of how learners can be encouraged to become more actively engaged in the learning process.</p><p>Our adoption of a socio-cultural approach that focuses on the exploration of individuals-using-technology-in-settings (Crook <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Crook C (1994) Computers and the collaborative experience of learning. Routledge, London" href="/article/10.1007/s10055-006-0036-4#ref-CR8" id="ref-link-section-d48172e3348">1994</a>) has enabled a better understanding of how the institutional context had a role in mediating how AR was used by the teachers in the current study. The AR content was designed by BBC Creative R&amp;D specifically as a tool to support the teaching of KS2 science within National Curriculum requirements. The teacher was asked to use the technology as if she were teaching NC material in a real classroom. She therefore tended to use familiar teaching methods that facilitated the delivery of a lot of specific material and key words in a limited time. She could not, for example, run an unstructured session where children were left by themselves to experiment with the technology as this would not guarantee that lesson aims had been met. This is consistent with much classroom practice and demonstrates the impact of the institutional context on the manner in which teachers use technology in the classroom.</p><p>These findings, together with those discussed above, have enabled us to extract the following design requirements for future classroom-based AR applications:</p><ul class="u-list-style-bullet">
                  <li>
                    <p>AR content must be flexible so that teachers can adapt it to the needs of individual children. It should be possible to add and remove elements and to change the speed of animations.</p>
                  </li>
                  <li>
                    <p>AR systems need to deliver curriculum material in the same amount of time as more traditional teaching methods.</p>
                  </li>
                  <li>
                    <p>Children must be able to explore AR content and this exploration should be carefully scaffolded so as to maximise learning opportunities.</p>
                  </li>
                  <li>
                    <p>The development of educational AR applications must take into account the nature and constraints of the institutional context into which it is to be introduced. This would suggest that there are benefits to be gained from a user-centred design approach.</p>
                  </li>
                </ul><p>If AR is to be used as an effective learning tool within future primary classrooms in the UK, the challenge for designers, and for teachers, is to scaffold children’s explorations and manipulations of the AR elements within carefully designed parameters to ensure that specific learning aims can be achieved within a relatively short period of time. Teacher’s questions need to be less about what the children can see and more about describing the effects of what they have done and what they have learnt from their actions.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Azuma, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Azuma R (1997) A survey of augmented reality. Presence Teleoperators Vir Env 6(4):355–388" /><p class="c-article-references__text" id="ref-CR1">Azuma R (1997) A survey of augmented reality. Presence Teleoperators Vir Env 6(4):355–388</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20survey%20of%20augmented%20reality&amp;journal=Presence%20Teleoperators%20Vir%20Env&amp;volume=6&amp;issue=4&amp;pages=355-388&amp;publication_year=1997&amp;author=Azuma%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bajura M, Fuchs H, Ohbuchi R (1992) Merging virtual objects with the real world: seeing ultrasound imagery wit" /><p class="c-article-references__text" id="ref-CR2">Bajura M, Fuchs H, Ohbuchi R (1992) Merging virtual objects with the real world: seeing ultrasound imagery within the patient. In: Proceedings of SIGGRAPH ’92. ACM Press, New York, pp 203–210</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content=". Barab, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Barab S, Hay K, Squire K, Barnett M, Schmidt R, Karrigan K, Yamagat-Lynch L, Johnson C (2000) Virtual solar sy" /><p class="c-article-references__text" id="ref-CR3">Barab S, Hay K, Squire K, Barnett M, Schmidt R, Karrigan K, Yamagat-Lynch L, Johnson C (2000) Virtual solar system project: learning through a technology- rich, inquiry-based, participatory learning environment. J Sci Educ Technol 9(1):7–25</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1023%2FA%3A1009416822783" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20solar%20system%20project%3A%20learning%20through%20a%20technology-%20rich%2C%20inquiry-based%2C%20participatory%20learning%20environment&amp;journal=J%20Sci%20Educ%20Technol&amp;volume=9&amp;issue=1&amp;pages=7-25&amp;publication_year=2000&amp;author=Barab%2C">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Billinghurst M (2003) Augmented reality in education. New Horizons for Learning IX (1)" /><p class="c-article-references__text" id="ref-CR4">Billinghurst M (2003) Augmented reality in education. New Horizons for Learning IX (1)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Billinghurst M, Kato H, Poupyrev I (2001) The MagicBook: a transitional AR interface. Comput Graph 745–753" /><p class="c-article-references__text" id="ref-CR5">Billinghurst M, Kato H, Poupyrev I (2001) The MagicBook: a transitional AR interface. Comput Graph 745–753</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Caudell T, Mizell D (1992) Augmented reality: an application of heads-up display technology to manual manufact" /><p class="c-article-references__text" id="ref-CR6">Caudell T, Mizell D (1992) Augmented reality: an application of heads-up display technology to manual manufacturing processes. In: Proceedings of the 25th Hawaii international conference on systems science Kauai Hawaii 2:659–669, 7–10 January 1992</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cole M (1996) Cultural psychology. The Belnap Press of Harvard University Press, Cambridge" /><p class="c-article-references__text" id="ref-CR7">Cole M (1996) Cultural psychology. The Belnap Press of Harvard University Press, Cambridge</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Crook C (1994) Computers and the collaborative experience of learning. Routledge, London" /><p class="c-article-references__text" id="ref-CR8">Crook C (1994) Computers and the collaborative experience of learning. Routledge, London</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Edwards D, Mercer N (1987) Common Knowledge: the development of joint understanding in the classroom. Methuen," /><p class="c-article-references__text" id="ref-CR9">Edwards D, Mercer N (1987) Common Knowledge: the development of joint understanding in the classroom. Methuen, London</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SR. Ellis, BM. Menges, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Ellis SR, Menges BM (1997) Judgments of the distance to nearby virtual objects: interaction of viewing conditi" /><p class="c-article-references__text" id="ref-CR10">Ellis SR, Menges BM (1997) Judgments of the distance to nearby virtual objects: interaction of viewing conditions and accommodative demand. Presence 6(4):452–460</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Judgments%20of%20the%20distance%20to%20nearby%20virtual%20objects%3A%20interaction%20of%20viewing%20conditions%20and%20accommodative%20demand&amp;journal=Presence&amp;volume=6&amp;issue=4&amp;pages=452-460&amp;publication_year=1997&amp;author=Ellis%2CSR&amp;author=Menges%2CBM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Feiner, B. Macintyre, D. Seligmann, " /><meta itemprop="datePublished" content="1993" /><meta itemprop="headline" content="Feiner S, Macintyre B, Seligmann D (1993) Knowledge-based augmented reality. Commun ACM 36(7):53–62" /><p class="c-article-references__text" id="ref-CR11">Feiner S, Macintyre B, Seligmann D (1993) Knowledge-based augmented reality. Commun ACM 36(7):53–62</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F159544.159587" aria-label="View reference 11">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Knowledge-based%20augmented%20reality&amp;journal=Commun%20ACM&amp;volume=36&amp;issue=7&amp;pages=53-62&amp;publication_year=1993&amp;author=Feiner%2CS&amp;author=Macintyre%2CB&amp;author=Seligmann%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fjeld M, Schar S, Signorello D, Krueger H (2002) Alternative tools for tangible interaction: a usability evalu" /><p class="c-article-references__text" id="ref-CR12">Fjeld M, Schar S, Signorello D, Krueger H (2002) Alternative tools for tangible interaction: a usability evaluation. In: IEEE and ACM international symposium on mixed and augmented reality (ISMAR), Darmstadt, Germany</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="de Freitas S, Levene M (2005) Wearable and mobile devices for informal learning. In: Encyclopaedia of human co" /><p class="c-article-references__text" id="ref-CR13">de Freitas S, Levene M (2005) Wearable and mobile devices for informal learning. In: Encyclopaedia of human computer interaction. Information Science Publishing, USA</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lalioti V, Woolard A (2003) Mixed reality productions of the future. BBC R&amp;D White Paper available at http://w" /><p class="c-article-references__text" id="ref-CR14">Lalioti V, Woolard A (2003) Mixed reality productions of the future. BBC R&amp;D White Paper available at <a href="http://www.bbc.co.uk/rd/pubs/whp/whp-pdf-files/WHP071.pdf">http://www.bbc.co.uk/rd/pubs/whp/whp-pdf-files/WHP071.pdf</a> (accessed 20/04/06)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Lewin, D. Mavers, B. Somekh, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Lewin C, Mavers D, Somekh B (2003) Broadening access to the curriculum through using technology to link home a" /><p class="c-article-references__text" id="ref-CR15">Lewin C, Mavers D, Somekh B (2003) Broadening access to the curriculum through using technology to link home and school: a critical analysis of reforms to improve educational attainment for all K-12 students. Curriculum J 14(1):23–54</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F0958517032000055974" aria-label="View reference 15">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Broadening%20access%20to%20the%20curriculum%20through%20using%20technology%20to%20link%20home%20and%20school%3A%20a%20critical%20analysis%20of%20reforms%20to%20improve%20educational%20attainment%20for%20all%20K-12%20students&amp;journal=Curriculum%20J&amp;volume=14&amp;issue=1&amp;pages=23-54&amp;publication_year=2003&amp;author=Lewin%2CC&amp;author=Mavers%2CD&amp;author=Somekh%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="McKenzie J, Darnell D. (2003) A report into augmented reality storytelling in the context of a children’s work" /><p class="c-article-references__text" id="ref-CR16">McKenzie J, Darnell D. (2003) A report into augmented reality storytelling in the context of a children’s workshop. Centre for Children’s Literature and Christchurch College of Education, New Zealand. <a href="http://www.hitlabnz.org/fileman_store/2004-eyeMagic_workshop.pdf">http://www.hitlabnz.org/fileman_store/2004-eyeMagic_workshop.pdf</a> (accessed 20/04/06)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Piekarski W, Smith R, Thomas B (2004) Designing backpacks for high fidelity mobile outdoor augmented reality. " /><p class="c-article-references__text" id="ref-CR17">Piekarski W, Smith R, Thomas B (2004) Designing backpacks for high fidelity mobile outdoor augmented reality. In: 2nd international symposium on mixed and augmented reality, Tokyo, Japan</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JP. Rolland, H. Fuchs, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Rolland JP, Fuchs H (2000) Optical versus video see-through head-mounted displays in medical visualization. Pr" /><p class="c-article-references__text" id="ref-CR18">Rolland JP, Fuchs H (2000) Optical versus video see-through head-mounted displays in medical visualization. Presence Teleoperators Vir Env 9(3):287–309</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1162%2F105474600566808" aria-label="View reference 18">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Optical%20versus%20video%20see-through%20head-mounted%20displays%20in%20medical%20visualization&amp;journal=Presence%20Teleoperators%20Vir%20Env&amp;volume=9&amp;issue=3&amp;pages=287-309&amp;publication_year=2000&amp;author=Rolland%2CJP&amp;author=Fuchs%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Shelton B (2003) Augmented reality and education: current projects and the potential for classroom learning. N" /><p class="c-article-references__text" id="ref-CR19">Shelton B (2003) Augmented reality and education: current projects and the potential for classroom learning. New Horizons Learning IX (1)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Shelton B, Hedley N (2002) Using augmented reality for teaching earth–sun relationships to undergraduate geogr" /><p class="c-article-references__text" id="ref-CR20">Shelton B, Hedley N (2002) Using augmented reality for teaching earth–sun relationships to undergraduate geography students. In: The 1st IEEE international augmented reality toolkit workshop. Darmstadt, Germany</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="B. Shelton, N. Hedley, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Shelton B, Hedley N (2003) Exploring a cognitive basis for learning spatial relationships with augmented reali" /><p class="c-article-references__text" id="ref-CR21">Shelton B, Hedley N (2003) Exploring a cognitive basis for learning spatial relationships with augmented reality. Tech Inst Cogn Learning 1:323–357</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Exploring%20a%20cognitive%20basis%20for%20learning%20spatial%20relationships%20with%20augmented%20reality&amp;journal=Tech%20Inst%20Cogn%20Learning&amp;volume=1&amp;pages=323-357&amp;publication_year=2003&amp;author=Shelton%2CB&amp;author=Hedley%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Sims, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Sims D (1994) New realities in aircraft design and manufacture. IEEE Comput Graph Appl 14(2):91" /><p class="c-article-references__text" id="ref-CR22">Sims D (1994) New realities in aircraft design and manufacture. IEEE Comput Graph Appl 14(2):91</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F38.267487" aria-label="View reference 22">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=New%20realities%20in%20aircraft%20design%20and%20manufacture&amp;journal=IEEE%20Comput%20Graph%20Appl&amp;volume=14&amp;issue=2&amp;publication_year=1994&amp;author=Sims%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EC. Urban, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Urban EC (1995) The information warrior. IEEE Spectr 32(11):66–70" /><p class="c-article-references__text" id="ref-CR23">Urban EC (1995) The information warrior. IEEE Spectr 32(11):66–70</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20information%20warrior&amp;journal=IEEE%20Spectr&amp;volume=32&amp;issue=11&amp;pages=66-70&amp;publication_year=1995&amp;author=Urban%2CEC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Vygotsky (1979) Mind in society: the development of higher psychological processes. In: Cole M, John-Steiner V" /><p class="c-article-references__text" id="ref-CR24">Vygotsky (1979) Mind in society: the development of higher psychological processes. In: Cole M, John-Steiner V, Scribner S, Souberman E (eds and trans) Harvard University Press, Cambridge</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Wertsch J (1991) A sociocultural approach to socially shared cognition. In: Perspectives on socially shared co" /><p class="c-article-references__text" id="ref-CR25">Wertsch J (1991) A sociocultural approach to socially shared cognition. In: Perspectives on socially shared cognition. In: Resnick L, Levine J, Teasley S (eds) American Psychological Association, Washington</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Wood, J. Bruner, G. Ross, " /><meta itemprop="datePublished" content="1976" /><meta itemprop="headline" content="Wood D, Bruner J, Ross G (1976) The role of tutoring in problem solving. J Child Psychol Psychiatry 17:89–100" /><p class="c-article-references__text" id="ref-CR26">Wood D, Bruner J, Ross G (1976) The role of tutoring in problem solving. J Child Psychol Psychiatry 17:89–100</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20role%20of%20tutoring%20in%20problem%20solving&amp;journal=J%20Child%20Psychol%20Psychiatry&amp;volume=17&amp;pages=89-100&amp;publication_year=1976&amp;author=Wood%2CD&amp;author=Bruner%2CJ&amp;author=Ross%2CG">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-006-0036-4-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">IDEAs Lab, Department of Informatics, University of Sussex, Falmer, East Sussex, BN1 9QH, UK</p><p class="c-article-author-affiliation__authors-list">Lucinda Kerawalla</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">London Knowledge Lab, Institute of Education, 23-29 Emerald Street, London, WC1N 3QS, UK</p><p class="c-article-author-affiliation__authors-list">Rosemary Luckin</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Creative Research and Development, British Broadcasting Corporation, 8th Floor NW, Bush House, 76 Strand, London, WC2B 4PH, UK</p><p class="c-article-author-affiliation__authors-list">Simon Seljeflot &amp; Adrian Woolard</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Lucinda-Kerawalla"><span class="c-article-authors-search__title u-h3 js-search-name">Lucinda Kerawalla</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Lucinda+Kerawalla&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Lucinda+Kerawalla" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Lucinda+Kerawalla%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Rosemary-Luckin"><span class="c-article-authors-search__title u-h3 js-search-name">Rosemary Luckin</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Rosemary+Luckin&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Rosemary+Luckin" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Rosemary+Luckin%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Simon-Seljeflot"><span class="c-article-authors-search__title u-h3 js-search-name">Simon Seljeflot</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Simon+Seljeflot&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Simon+Seljeflot" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Simon+Seljeflot%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Adrian-Woolard"><span class="c-article-authors-search__title u-h3 js-search-name">Adrian Woolard</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Adrian+Woolard&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Adrian+Woolard" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Adrian+Woolard%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-006-0036-4/email/correspondent/c1/new">Lucinda Kerawalla</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=%E2%80%9CMaking%20it%20real%E2%80%9D%3A%20exploring%20the%20potential%20of%20augmented%20reality%20for%20teaching%20primary%20school%20science&amp;author=Lucinda%20Kerawalla%20et%20al&amp;contentID=10.1007%2Fs10055-006-0036-4&amp;publication=1359-4338&amp;publicationDate=2006-11-14&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Kerawalla, L., Luckin, R., Seljeflot, S. <i>et al.</i> “Making it real”: exploring the potential of augmented reality for teaching primary school science.
                    <i>Virtual Reality</i> <b>10, </b>163–174 (2006). https://doi.org/10.1007/s10055-006-0036-4</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-006-0036-4.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2005-12-20">20 December 2005</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-05-22">22 May 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-11-14">14 November 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-12">December 2006</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-006-0036-4" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-006-0036-4</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Augmented reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Educational dialogue</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Primary classroom</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Design requirements</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-006-0036-4.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=36;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

