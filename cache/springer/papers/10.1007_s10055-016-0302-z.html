<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Reusing heterogeneous data for the conceptual design of shapes in virt"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Today, digital data such as 2D images, 3D meshes and 3D point clouds are widely used to design virtual environments (VE). Most of the time, only one type of those multimodal data is used to..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/21/3.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Reusing heterogeneous data for the conceptual design of shapes in virtual environments"/>

    <meta name="dc.source" content="Virtual Reality 2016 21:3"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2016-11-30"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2016 Springer-Verlag London"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Today, digital data such as 2D images, 3D meshes and 3D point clouds are widely used to design virtual environments (VE). Most of the time, only one type of those multimodal data is used to describe and specify the shapes of the objects. However, a single object can be seen as a combination of components linked with constraints specifying the relationships and the rigid transformations defining their arrangement. Thus, the definition of new methods able to combine any kind of multimodal data in an easy way would allow non-experts of VE to rapidly mock up objects and scenes. In this paper, we propose a new shape description model together with its associated constraints toolbox enabling the description of complex shapes from multimodal data. Not only rigid transformations are considered but also scale modifications according to the specified context of the constraint setting. The heterogeneous virtual objects (i.e., composed by scalable multimodal components) then result from the resolution of a constraint satisfaction problem through an optimization approach. The proposed approach is illustrated and validated with examples obtained using our prototype software."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2016-11-30"/>

    <meta name="prism.volume" content="21"/>

    <meta name="prism.number" content="3"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="127"/>

    <meta name="prism.endingPage" content="144"/>

    <meta name="prism.copyright" content="2016 Springer-Verlag London"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-016-0302-z"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-016-0302-z"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-016-0302-z.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-016-0302-z"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Reusing heterogeneous data for the conceptual design of shapes in virtual environments"/>

    <meta name="citation_volume" content="21"/>

    <meta name="citation_issue" content="3"/>

    <meta name="citation_publication_date" content="2017/09"/>

    <meta name="citation_online_date" content="2016/11/30"/>

    <meta name="citation_firstpage" content="127"/>

    <meta name="citation_lastpage" content="144"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-016-0302-z"/>

    <meta name="DOI" content="10.1007/s10055-016-0302-z"/>

    <meta name="citation_doi" content="10.1007/s10055-016-0302-z"/>

    <meta name="description" content="Today, digital data such as 2D images, 3D meshes and 3D point clouds are widely used to design virtual environments (VE). Most of the time, only one type o"/>

    <meta name="dc.creator" content="Zongcheng Li"/>

    <meta name="dc.creator" content="Franca Giannini"/>

    <meta name="dc.creator" content="Jean-Philippe Pernot"/>

    <meta name="dc.creator" content="Philippe V&#233;ron"/>

    <meta name="dc.creator" content="Bianca Falcidieno"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=Graph Models; citation_title=The HybridTree: mixing skeletal implicit surfaces, triangle meshes, and point sets in a free-form modeling system; citation_author=R All&#232;gre, E Galin, R Chaine, S Akkouche; citation_volume=68; citation_issue=1; citation_publication_date=2006; citation_pages=42-64; citation_doi=10.1016/j.gmod.2005.09.001; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Aided Des; citation_title=Subdivision surfaces integrated in a CAD system; citation_author=M Antonelli, C Beccari, G Casciola, R Ciarloni, S Morigi; citation_volume=45; citation_issue=11; citation_publication_date=2013; citation_pages=1294-1305; citation_doi=10.1016/j.cad.2013.06.007; citation_id=CR2"/>

    <meta name="citation_reference" content="citation_journal_title=Theoret Comput Sci; citation_title=Reeb graphs for shape analysis and applications; citation_author=S Biasotti, D Giorgi, M Spagnuolo, B Falcidieno; citation_volume=392; citation_issue=1&#8211;3; citation_publication_date=2008; citation_pages=5-22; citation_doi=10.1016/j.tcs.2007.10.018; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Pattern Anal Mach Intell; citation_title=Fuzzy relative position between objects in image processing: a morphological approach; citation_author=I Bloch; citation_volume=21; citation_issue=7; citation_publication_date=1999; citation_pages=657-664; citation_doi=10.1109/34.777378; citation_id=CR4"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Aided Design Appl; citation_title=Towards a declarative modelling approach built on top of a CAD modeller; citation_author=D D&#233;criteau, J-P Pernot, M Daniel; citation_volume=13; citation_issue=6; citation_publication_date=2016; citation_pages=737-746; citation_doi=10.1080/16864360.2016.1168215; citation_id=CR5"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graph; citation_title=Reverse engineering of architectural buildings based on a hybrid modeling approach; citation_author=L Deluca, P V&#233;ron, M Florenzano; citation_volume=30; citation_issue=2; citation_publication_date=2006; citation_pages=160-176; citation_doi=10.1016/j.cag.2006.01.020; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_journal_title=Int Arch Photogr Remote Sens Spatial Inf Sci; citation_title=Semi-automatic 3D reconstruction of occluded and unmarked surfaces from widely separated views; citation_author=SF El-Hakim; citation_volume=34; citation_issue=5; citation_publication_date=2002; citation_pages=143-145; citation_id=CR7"/>

    <meta name="citation_reference" content="Falcidieno B, Spagnuolo M, Alliez P, Quak E, Vavalis E, Houstis C (2004) Towards the semantics of digital shapes: the AIM@SHAPE approach. EWIMT"/>

    <meta name="citation_reference" content="citation_journal_title=Fuzzy Sets Syst; citation_title=Fuzzy spatial relation ontology for image interpretation; citation_author=C Hudelot, J Atif, I Bloch; citation_volume=159; citation_issue=15; citation_publication_date=2008; citation_pages=1929-1951; citation_doi=10.1016/j.fss.2008.02.011; citation_id=CR9"/>

    <meta name="citation_reference" content="citation_journal_title=Math Comput Model; citation_title=Simulated annealing: practice versus theory; citation_author=L Ingber; citation_volume=18; citation_issue=11; citation_publication_date=1993; citation_pages=29-57; citation_doi=10.1016/0895-7177(93)90204-C; citation_id=CR10"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graphics Forum; citation_title=Exploring shape variations by 3D-model decomposition and part-based recombination; citation_author=A Jain, T Thorm&#228;hlen, T Ritschel, H-P Seidel; citation_volume=31; citation_issue=2; citation_publication_date=2012; citation_pages=631-640; citation_doi=10.1111/j.1467-8659.2012.03042.x; citation_id=CR11"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Graph; citation_title=Symmetric architecture modeling with a single image; citation_author=N Jiang, P Tan, LF Cheong; citation_volume=28; citation_issue=5; citation_publication_date=2009; citation_pages=1-8; citation_doi=10.1145/1618452.1618459; citation_id=CR12"/>

    <meta name="citation_reference" content="Lee J, Funkhouser T (2008) Sketch-based search and composition of 3D models. In: EUROGRAPHICS workshop on sketch-based interfaces and modeling, 2008"/>

    <meta name="citation_reference" content="citation_title=Shape analysis and classification: theory and practice; citation_publication_date=2000; citation_id=CR14; citation_author=C Luciano da Fontoura; citation_author=J Roberto Marcondes Cesar; citation_publisher=CRC Press"/>

    <meta name="citation_reference" content="Mathematica9 (2016) Available: 
                    http://www.wolfram.com/mathematica/new-in-9/
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=SIAM J Optim; citation_title=On the implementation of a primal-dual interior point method; citation_author=S Mehrotra; citation_volume=2; citation_publication_date=1992; citation_pages=575-601; citation_doi=10.1137/0802028; citation_id=CR16"/>

    <meta name="citation_reference" content="Mitra N, Wand M, Zhang H, Cohen-Or D, Kim V, Huang Q-X (2013) Structure-aware shape processing. In: SIGGRAPH Asia 2013 courses. ACM, New York"/>

    <meta name="citation_reference" content="citation_journal_title=Comput J; citation_title=A simplex method for function minimization; citation_author=J Nelder, R Mead; citation_volume=7; citation_publication_date=1965; citation_pages=308-313; citation_doi=10.1093/comjnl/7.4.308; citation_id=CR18"/>

    <meta name="citation_reference" content="Office Room (2016) Available: 
                    http://www.decosee.com/2014/04/07/modern-office-room-minimalist-idea-23394.html
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Comput Aided Des; citation_title=Towards recovery of complex shapes in meshes using digital images for reverse engineering applications; citation_author=M Panchetti, J-P Pernot, P V&#233;ron; citation_volume=42; citation_issue=8; citation_publication_date=2010; citation_pages=693-707; citation_doi=10.1016/j.cad.2010.01.004; citation_id=CR20"/>

    <meta name="citation_reference" content="Pernot J-P, Falcidieno B, Giannini F, L&#233;on J-C (2008) Hybrid models deformation tool for free-form shapes manipulation. In: ASME 2008 international design engineering technical conferences &amp; design and automation conference, New-York"/>

    <meta name="citation_reference" content="citation_journal_title=Dr. Dobb&#8217;s J; citation_title=Differential evolution; citation_author=K Price, R Storn; citation_volume=264; citation_publication_date=1997; citation_pages=18-24; citation_id=CR22"/>

    <meta name="citation_reference" content="Reeb G (1946) Sur les points singuliers d&#8217;une forme de Pfaff compl&#232;tement int&#233;grable ou d&#8217;une fonction num&#233;rique. Comptes-rendus de l&#8217;Acad&#233;mie des Sciences, pp 848&#8211;849"/>

    <meta name="citation_reference" content="Repository TS (2011&#8211;2015) Shape repository. 
                    http://visionair.ge.imati.cnr.it/ontologies/shapes/
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_title=Zig Zag: the surprising path to greater creativity; citation_publication_date=2013; citation_id=CR25; citation_author=K Sawyer; citation_publisher=Jossey-Bass"/>

    <meta name="citation_reference" content="citation_journal_title=J Creative Behav; citation_title=Idea-generation techniques: a formulary of active ingredients; citation_author=G Smith; citation_volume=32; citation_issue=2; citation_publication_date=1998; citation_pages=107-133; citation_doi=10.1002/j.2162-6057.1998.tb00810.x; citation_id=CR26"/>

    <meta name="citation_reference" content="Takemura CM (2008) Modelagem de posi&#231;&#245;es relativas de formas complexas para an&#225;lise de configura&#231;&#227;o espacial. Doutorado em Ci&#234;ncias da Computa&#231;&#227;o, Universidade de S&#227;o Paulo"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Comput Entertain; citation_title=The role of semantics in games and simulations; citation_author=T Tutenel, R Bidarra, RM Smelik, KJ Kraker; citation_volume=6; citation_issue=4; citation_publication_date=2008; citation_pages=1-35; citation_doi=10.1145/1461999.1462009; citation_id=CR28"/>

    <meta name="citation_reference" content="Unity3D (2016) Available: 
                    http://www.unity3.com
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_title=Linear programming: foundations and extensions; citation_publication_date=2001; citation_id=CR30; citation_author=R Vanderbei; citation_publisher=Springer"/>

    <meta name="citation_reference" content="Wendrich R (2009&#8211;2016) Raw shaping form finding project. 
                    www.rawshaping.com
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Comput Graphics Forum; citation_title=Sketch-to-design: context-based part assembly; citation_author=X Xie, K Xu, NJ Mitra, D Cohen-Or, W Gong, Q Su, B Chen; citation_volume=32; citation_issue=8; citation_publication_date=2013; citation_pages=233-245; citation_doi=10.1111/cgf.12200; citation_id=CR32"/>

    <meta name="citation_author" content="Zongcheng Li"/>

    <meta name="citation_author_email" content="Zongcheng.Li@ensam.eu"/>

    <meta name="citation_author_institution" content="LSIS UMR CNRS 7296, Arts et M&#233;tiers ParisTech, Aix-En-Provence, France"/>

    <meta name="citation_author_institution" content="IMATI-CNR, Genoa, Italy"/>

    <meta name="citation_author" content="Franca Giannini"/>

    <meta name="citation_author_email" content="Franca.Giannini@ge.imati.cnr.it"/>

    <meta name="citation_author_institution" content="IMATI-CNR, Genoa, Italy"/>

    <meta name="citation_author" content="Jean-Philippe Pernot"/>

    <meta name="citation_author_email" content="Jean-Philippe.Pernot@ensam.eu"/>

    <meta name="citation_author_institution" content="LSIS UMR CNRS 7296, Arts et M&#233;tiers ParisTech, Aix-En-Provence, France"/>

    <meta name="citation_author" content="Philippe V&#233;ron"/>

    <meta name="citation_author_email" content="Philippe.Veron@ensam.eu"/>

    <meta name="citation_author_institution" content="LSIS UMR CNRS 7296, Arts et M&#233;tiers ParisTech, Aix-En-Provence, France"/>

    <meta name="citation_author" content="Bianca Falcidieno"/>

    <meta name="citation_author_email" content="Bianca.Falcidieno@ge.imati.cnr.it"/>

    <meta name="citation_author_institution" content="IMATI-CNR, Genoa, Italy"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-016-0302-z&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2017/09/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-016-0302-z"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Reusing heterogeneous data for the conceptual design of shapes in virtual environments"/>
        <meta property="og:description" content="Today, digital data such as 2D images, 3D meshes and 3D point clouds are widely used to design virtual environments (VE). Most of the time, only one type of those multimodal data is used to describe and specify the shapes of the objects. However, a single object can be seen as a combination of components linked with constraints specifying the relationships and the rigid transformations defining their arrangement. Thus, the definition of new methods able to combine any kind of multimodal data in an easy way would allow non-experts of VE to rapidly mock up objects and scenes. In this paper, we propose a new shape description model together with its associated constraints toolbox enabling the description of complex shapes from multimodal data. Not only rigid transformations are considered but also scale modifications according to the specified context of the constraint setting. The heterogeneous virtual objects (i.e., composed by scalable multimodal components) then result from the resolution of a constraint satisfaction problem through an optimization approach. The proposed approach is illustrated and validated with examples obtained using our prototype software."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Reusing heterogeneous data for the conceptual design of shapes in virtual environments | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-016-0302-z","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Virtual reality, Conceptual design, Shape and object description, Heterogeneous data, Constraint satisfaction problem","kwrd":["Virtual_reality","Conceptual_design","Shape_and_object_description","Heterogeneous_data","Constraint_satisfaction_problem"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-016-0302-z","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-016-0302-z","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=302;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-016-0302-z">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Reusing heterogeneous data for the conceptual design of shapes in virtual environments
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-016-0302-z.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-016-0302-z.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2016-11-30" itemprop="datePublished">30 November 2016</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Reusing heterogeneous data for the conceptual design of shapes in virtual environments</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Zongcheng-Li" data-author-popup="auth-Zongcheng-Li">Zongcheng Li</a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Arts et Métiers ParisTech" /><meta itemprop="address" content="0000 0001 2194 6047, grid.434207.6, LSIS UMR CNRS 7296, Arts et Métiers ParisTech, Aix-En-Provence, France" /></span><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="IMATI-CNR" /><meta itemprop="address" content="IMATI-CNR, Genoa, Italy" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Franca-Giannini" data-author-popup="auth-Franca-Giannini">Franca Giannini</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="IMATI-CNR" /><meta itemprop="address" content="IMATI-CNR, Genoa, Italy" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Jean_Philippe-Pernot" data-author-popup="auth-Jean_Philippe-Pernot" data-corresp-id="c1">Jean-Philippe Pernot<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Arts et Métiers ParisTech" /><meta itemprop="address" content="0000 0001 2194 6047, grid.434207.6, LSIS UMR CNRS 7296, Arts et Métiers ParisTech, Aix-En-Provence, France" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Philippe-V_ron" data-author-popup="auth-Philippe-V_ron">Philippe Véron</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Arts et Métiers ParisTech" /><meta itemprop="address" content="0000 0001 2194 6047, grid.434207.6, LSIS UMR CNRS 7296, Arts et Métiers ParisTech, Aix-En-Provence, France" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Bianca-Falcidieno" data-author-popup="auth-Bianca-Falcidieno">Bianca Falcidieno</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="IMATI-CNR" /><meta itemprop="address" content="IMATI-CNR, Genoa, Italy" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 21</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">127</span>–<span itemprop="pageEnd">144</span>(<span data-test="article-publication-year">2017</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">345 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">1 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">1 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-016-0302-z/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Today, digital data such as 2D images, 3D meshes and 3D point clouds are widely used to design virtual environments (VE). Most of the time, only one type of those multimodal data is used to describe and specify the shapes of the objects. However, a single object can be seen as a combination of components linked with constraints specifying the relationships and the rigid transformations defining their arrangement. Thus, the definition of new methods able to combine any kind of multimodal data in an easy way would allow non-experts of VE to rapidly mock up objects and scenes. In this paper, we propose a new shape description model together with its associated constraints toolbox enabling the description of complex shapes from multimodal data. Not only rigid transformations are considered but also scale modifications according to the specified context of the constraint setting. The heterogeneous virtual objects (i.e., composed by scalable multimodal components) then result from the resolution of a constraint satisfaction problem through an optimization approach. The proposed approach is illustrated and validated with examples obtained using our prototype software.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Due to the great advances in acquisition devices and modeling tools, a huge amount of digital data (e.g., images, videos, 3D models such as point clouds, meshes or B-Rep models) is becoming now available in various application domains. In particular, virtual environments (VE) make use of those digital data allowing more attractive and more effectual communication and simulation of real or not (yet) existing environments and objects. Despite those available datasets and possibly associated metadata, the design of application-oriented VE still results from a long and tedious iterative modeling and modification process that involves several actors (e.g., experts of the application domain, 3D modelers and virtual reality (VR) programmers, designers or communications/marketing experts). Depending on the targeted application, the number and the profiles of the involved actors may change. Today’s limitations and difficulties are mainly due to the lack of strong relationships between the expert of the domain having creative ideas, the digitally skilled actors, the tools and the shape models taking part to the VE development process. Actually, existing tools mainly focus on the detailed geometric definition of the shapes and are not suitable to effectively support the collaboration between the experts in the creative process of the VR environment and the related assets specification. In addition, the huge amount of available digital data is not fully exploited. Clearly, those data could be used as a source of inspiration for new solutions, being innovative ideas frequently coming from the (unforeseen) combination of existing elements (Sawyer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Sawyer K (2013) Zig Zag: the surprising path to greater creativity. Jossey-Bass, New York" href="/article/10.1007/s10055-016-0302-z#ref-CR25" id="ref-link-section-d54960e376">2013</a>). Therefore, the availability of software tools allowing the reuse and combination of such digital data would be an effective support for the conceptual design phase of both single shapes and VR environments.</p><p>The process of generating new ideas can be perceived as the first and most critical part of the creative design. Most of the time, the innovative ideas are produced by iterating back and forth between multiple sources. Smith (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Smith G (1998) Idea-generation techniques: a formulary of active ingredients. J Creative Behav 32(2):107–133" href="/article/10.1007/s10055-016-0302-z#ref-CR26" id="ref-link-section-d54960e382">1998</a>) has summarized 172 methods for generating ideas. Actually, the most creative ideas are coming from copying and combining existing things (Sawyer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Sawyer K (2013) Zig Zag: the surprising path to greater creativity. Jossey-Bass, New York" href="/article/10.1007/s10055-016-0302-z#ref-CR25" id="ref-link-section-d54960e385">2013</a>). Earlier, Albert Einstein was used to say about his thoughts: “Words do not play any role in my thought; instead, I think in signs and images which I can copy and combine (Albert Einstein).”</p><p>However, even if taking ideas from different compositions, to mentally combine and rearrange them together with specific relations and structures is very common and popular in creative conceptual design, existing digital tools weakly support such a modeling process. Some approaches are appearing in 3D shape modeling. Jain et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Jain A, Thormählen T, Ritschel T, Seidel H-P (2012) Exploring shape variations by 3D-model decomposition and part-based recombination. Comput Graphics Forum 31(2):631–640" href="/article/10.1007/s10055-016-0302-z#ref-CR11" id="ref-link-section-d54960e391">2012</a>) have set up a system to create new shapes by blending between shapes taken from a database. Similar approaches can also be found in sketch-based modeling and search system (Xie et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Xie X, Xu K, Mitra NJ, Cohen-Or D, Gong W, Su Q, Chen B (2013) Sketch-to-design: context-based part assembly. Comput Graphics Forum 32(8):233–245" href="/article/10.1007/s10055-016-0302-z#ref-CR32" id="ref-link-section-d54960e394">2013</a>; Lee and Funkhouser <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Lee J, Funkhouser T (2008) Sketch-based search and composition of 3D models. In: EUROGRAPHICS workshop on sketch-based interfaces and modeling, 2008" href="/article/10.1007/s10055-016-0302-z#ref-CR13" id="ref-link-section-d54960e397">2008</a>). However, such a combination is difficult when combining heterogeneous data being represented in terms of different elements and at different levels of information granularity. This paper addresses such a difficult problem of combining multimodal data, and possibly associated semantics, in a unified way so as to stimulate the creativity of the end users and ease the generation of conceptual models in the early design phases of the VE development process. The aim of our proposal is definitively not to replace the existing tools but rather to find a way to combine their outputs in an efficient and unified way so as to stimulate the creativity of the end users.</p><p>The paper is organized as it follows. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0302-z#Sec2">2</a> reviews the state of the art in this domain. The proposed generic shape description model is then introduced in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0302-z#Sec6">3</a> together with its constitutive elements. The GSDM modeler and its associated interface are presented in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0302-z#Sec24">4</a>. This new modeling approach is then illustrated and validated in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0302-z#Sec25">5</a> through several examples mixing different heterogeneous data according to different scenarios. The last section concludes this paper and gives directions for future work.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Related works</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Toward modeling with heterogeneous data</h3><p>Overall, the idea of combing different types of documents and information is not completely new. In product modeling, PDM (product data management) systems aggregate different digital documents related to a specific product and its associated lifecycle. In construction industry, BIM (building information modeling) aims at including and formalizing all the data (possibly of different dimensionality) involved in the design, construction and usage of buildings and infrastructures. Similarly, GIS (geographical information systems) are sophisticated systems dealing with heterogeneous data, combining 2D vector and raster data with 3D data as well as text information to represent and analyze geospatial data. They are generally supported by database systems, and all the considered elements are georeferenced. Thus, their positioning is rather standard and because of their usage almost no interaction with the shape elements is applied. Unfortunately, the above systems and methods do not really refer to combining heterogeneous data in the sense that we intend to do, i.e., with each specific type of input considered as a part of the shape of a single object. Moreover, no specific attention is paid to give easy user interaction capabilities for the reciprocal adjustment of the elements and their simultaneous manipulation.</p><p>However, various research attempts (Pernot et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Pernot J-P, Falcidieno B, Giannini F, Léon J-C (2008) Hybrid models deformation tool for free-form shapes manipulation. In: ASME 2008 international design engineering technical conferences &amp; design and automation conference, New-York" href="/article/10.1007/s10055-016-0302-z#ref-CR21" id="ref-link-section-d54960e430">2008</a>; Allègre et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Allègre R, Galin E, Chaine R, Akkouche S (2006) The HybridTree: mixing skeletal implicit surfaces, triangle meshes, and point sets in a free-form modeling system. Graph Models 68(1):42–64" href="/article/10.1007/s10055-016-0302-z#ref-CR1" id="ref-link-section-d54960e433">2006</a>; Antonelli et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Antonelli M, Beccari C, Casciola G, Ciarloni R, Morigi S (2013) Subdivision surfaces integrated in a CAD system. Comput Aided Des 45(11):1294–1305" href="/article/10.1007/s10055-016-0302-z#ref-CR2" id="ref-link-section-d54960e436">2013</a>) and current commercial 3D system developers are working on combining different 3D representations to take advantage of their properties for shape manipulation and to allow the exploitation and reuse of existing models. These systems deal with 3D data, while text is used mostly for annotation purposes, and 2D images are often applied as textures to 3D models. Texture mapping has made it possible to simulate near-photorealistic 3D models in real time. This is a very common way to represent 2D and 3D shapes altogether. In most 3D video games, 2D planar surfaces with transparent texture mapping are usually used together with closed 3D surfaces to simulate objects (e.g., grass, leaves or trees). Similarly, CAD (computer-aided design) systems accept the simultaneous usage of images and 3D models either for rendering purposes or for simulating a shape. For example, to model buildings or industrial installations, images can be used to represent internal or environmental furnishings of 3D building components. Image-based modeling (IBM) techniques are also used for reconstructing architectural models (Jiang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Jiang N, Tan P, Cheong LF (2009) Symmetric architecture modeling with a single image. ACM Trans Graph 28(5):1–8" href="/article/10.1007/s10055-016-0302-z#ref-CR12" id="ref-link-section-d54960e439">2009</a>; El-Hakim <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="El-Hakim SF (2002) Semi-automatic 3D reconstruction of occluded and unmarked surfaces from widely separated views. Int Arch Photogr Remote Sens Spatial Inf Sci 34(5):143–145" href="/article/10.1007/s10055-016-0302-z#ref-CR7" id="ref-link-section-d54960e442">2002</a>; Deluca et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Deluca L, Véron P, Florenzano M (2006) Reverse engineering of architectural buildings based on a hybrid modeling approach. Comput Graph 30(2):160–176" href="/article/10.1007/s10055-016-0302-z#ref-CR6" id="ref-link-section-d54960e446">2006</a>; Panchetti et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Panchetti M, Pernot J-P, Véron P (2010) Towards recovery of complex shapes in meshes using digital images for reverse engineering applications. Comput Aided Des 42(8):693–707" href="/article/10.1007/s10055-016-0302-z#ref-CR20" id="ref-link-section-d54960e449">2010</a>). Other approaches try to improve the way shapes can be defined interactively in a VR environment (Wendrich <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009–2016" title="Wendrich R (2009–2016) Raw shaping form finding project. &#xA;                    www.rawshaping.com&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0302-z#ref-CR31" id="ref-link-section-d54960e452">2009–2016</a>). However, they do not necessarily focus on the conceptual design phase where the user is more interesting in the combination of several multimodal data rather than on the generation of a final 3D model to be used for further animations. Finally, texts can be used today to design new shapes, but their semantic meaning is somehow treated as descriptive sentences to describe new shapes (Décriteau et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Décriteau D, Pernot J-P, Daniel M (2016) Towards a declarative modelling approach built on top of a CAD modeller. Comput Aided Design Appl 13(6):737–746" href="/article/10.1007/s10055-016-0302-z#ref-CR5" id="ref-link-section-d54960e455">2016</a>).</p><p>Actually, today’s limitations are due to the lack of generic shape description models able to support the combination and simultaneous modification and interaction of heterogeneous data in a unified environment. As such, the purpose of this work is to propose a new shape description model able to handle heterogeneous data and easy to be generated, manipulated and modified.</p><h3 class="c-article__sub-heading" id="Sec4">Structure-based shape descriptors</h3><p>Most shape description techniques consider information related to the contours and/or regions of the shape. Some of these techniques may transform 2D/3D space coordinates into another space to get useful information. Color and light information are also used to describe a shape. Additional algorithms have been developed providing structure-based and more meaningful descriptors. As those techniques are typically used for extracting information from well-defined shapes, their main applications are shape classification and retrieval. However, some of these techniques can be potentially used for modeling new shapes, especially graph- or structure-based techniques, which might turn out to be very useful to align or assemble several shapes (Mitra et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Mitra N, Wand M, Zhang H, Cohen-Or D, Kim V, Huang Q-X (2013) Structure-aware shape processing. In: SIGGRAPH Asia 2013 courses. ACM, New York" href="/article/10.1007/s10055-016-0302-z#ref-CR17" id="ref-link-section-d54960e469">2013</a>).</p><p>A shape skeleton (or topological skeleton) is a thin version of a shape, obtained from points, which hold the same distance to its boundaries. There are several mathematical definitions used in the literature to define a skeleton. Different algorithms have been applied to compute it. The concept of skeleton is also interchangeable as “medial axis” and “thinning.” Reeb graphs represent the evolution of the level sets of a real-valued function defined over the surface bounding the object (Reeb <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1946" title="Reeb G (1946) Sur les points singuliers d’une forme de Pfaff complètement intégrable ou d’une fonction numérique. Comptes-rendus de l’Académie des Sciences, pp 848–849" href="/article/10.1007/s10055-016-0302-z#ref-CR23" id="ref-link-section-d54960e475">1946</a>; Biasotti et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Biasotti S, Giorgi D, Spagnuolo M, Falcidieno B (2008) Reeb graphs for shape analysis and applications. Theoret Comput Sci 392(1–3):5–22" href="/article/10.1007/s10055-016-0302-z#ref-CR3" id="ref-link-section-d54960e478">2008</a>). A Reeb graph, as it strongly preserves the topological information of a shape, has been widely used in different areas. If the function used to calculate Reeb graph is on a special flat space, then the results form a polytree which is also named contour tree. As skeletons, Reeb graphs are also helpful for image segmentation.</p><p>Those graph-based shape descriptors have a strong potential usage to define or align shapes. For example, the one straight segment of a skeleton may represent the major orientation axis of this shape. If the shape is used and relocated in another 3D space, then its skeleton is very useful to set the orientation of this shape.</p><p>As a consequence, the proposed approach should take advantage of such potentially available structure-based descriptors to ease the generation, modification and interaction of the combined heterogeneous data. Technically, it means that the proposed framework should support the specification of relationships either at the level of the shapes themselves (i.e., contours and regions) or at the level of the associated shape descriptors. How to do it in a unified way is explained in the next section.</p><h3 class="c-article__sub-heading" id="Sec5">A multilayered shape understanding paradigm</h3><p>Shape representations and description techniques have shown different ways of capturing information from shapes with different aspects. Those features can also be considered as different characteristics for understanding the information associated with shapes. With the development of computer graphics and its application domains, the meaning of “Shape” has become richer.</p><p>A shape can be defined by “Parts” and “Relations” (Luciano da Fontoura and Roberto Marcondes Cesar <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Luciano da Fontoura C, Roberto Marcondes Cesar J (2000) Shape analysis and classification: theory and practice. CRC Press, Boca Raton" href="/article/10.1007/s10055-016-0302-z#ref-CR14" id="ref-link-section-d54960e498">2000</a>). The shape is seen as a set of parts that are spatially arranged through the spatial relations among them. These relations among the shape parts can be classified in different ways (Bloch <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Bloch I (1999) Fuzzy relative position between objects in image processing: a morphological approach. IEEE Trans Pattern Anal Mach Intell 21(7):657–664" href="/article/10.1007/s10055-016-0302-z#ref-CR4" id="ref-link-section-d54960e501">1999</a>; Hudelot et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Hudelot C, Atif J, Bloch I (2008) Fuzzy spatial relation ontology for image interpretation. Fuzzy Sets Syst 159(15):1929–1951" href="/article/10.1007/s10055-016-0302-z#ref-CR9" id="ref-link-section-d54960e504">2008</a>). A possible classification includes the following three types of relation: topological, distance and directional (Takemura <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Takemura CM (2008) Modelagem de posições relativas de formas complexas para análise de configuração espacial. Doutorado em Ciências da Computação, Universidade de São Paulo" href="/article/10.1007/s10055-016-0302-z#ref-CR27" id="ref-link-section-d54960e507">2008</a>). Topological relation, such as “inside,” “outside” and “adjacent,” is invariant to rotation and scaling transformation. Distance relation is linked to quantitative measures. If two shapes are “far from” or “close to,” each other needs to be further specified. Directional relation is characterized by the orientation of angle-based aspects following some reference such as the medial axis, or the segments of the border of a 2D shape.</p><p>In 2004, the European project AIM@SHAPE (Falcidieno et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Falcidieno B, Spagnuolo M, Alliez P, Quak E, Vavalis E, Houstis C (2004) Towards the semantics of digital shapes: the AIM@SHAPE approach. EWIMT" href="/article/10.1007/s10055-016-0302-z#ref-CR8" id="ref-link-section-d54960e513">2004</a>; Repository <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011–2015" title="Repository TS (2011–2015) Shape repository. &#xA;                    http://visionair.ge.imati.cnr.it/ontologies/shapes/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0302-z#ref-CR24" id="ref-link-section-d54960e516">2011–2015</a>) proposed a new way of understanding shapes. Shape is any individual object having a visual appearance, which exists, in some (two-, three- or higher-dimensional) space such as pictures, sketches, images, 3D objects, videos, 4D animations. Shapes are characterized by several properties. They have a geometry (the spatial extent of the object), they can be described by structures (object features and part-whole decomposition), they have semantics (meaning, purpose), and they may also have some interaction with time (e.g., history, shape morphing, animation, video). Finally, they are endowed with attributes (colors, textures, names, attached to an object, its parts and/or its features).</p><p>Compared with the definition of Luciano da Fontoura and Roberto Marcondes Cesar (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Luciano da Fontoura C, Roberto Marcondes Cesar J (2000) Shape analysis and classification: theory and practice. CRC Press, Boca Raton" href="/article/10.1007/s10055-016-0302-z#ref-CR14" id="ref-link-section-d54960e522">2000</a>), this interpretation corresponds to a broader view of shape. The shape parts and their relations can be considered as the structure of shape. Their appearance features such as their colors and textures are grouped as the attributes of the shape. This definition also associates semantics to shapes, which can be used for semantic-based retrieval processes. With this definition, the information associated with shapes can be structured into three different layers including geometric, structural and semantic information levels (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig1">1</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Digital shape represented by two different geometric descriptions: a point cloud (<b>a</b>) and a triangular mesh (<b>b</b>); the structure of the hand model, defined as the configuration of main body with protrusion-like features (<b>c</b>); the corresponding semantically annotated model exploiting its structure (Repository <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011–2015" title="Repository TS (2011–2015) Shape repository. &#xA;                    http://visionair.ge.imati.cnr.it/ontologies/shapes/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0302-z#ref-CR24" id="ref-link-section-d54960e547">2011–2015</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The generic shape description model (GSDM) proposed in this paper has been designed based on those three layers. This enables the possibility to describe multimodal data in a same structure, so as to be able to combine together all the data whatever their representations are. The GSDM is detailed in the next sections. It is part of a framework presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig2">2</a> and used to generate objects for VR applications. Starting from a set of heterogeneous models found on Internet or in any available database (1), a preprocessing phase enriches the models using existing approaches such as skeletonization, cropping, contouring (2) and prepare them for the conceptual design phase. During the conceptual design phase, the GSDM (3) is generated, modified and manipulated using models, methods and tools presented in this paper and detailed in the next sections. Then, the GSDM, which combines enriched heterogeneous models, can be transformed and adapted for different applications (4) using existing approaches such as the creation of meshes from images or the merging of meshes and so on. Again, the aim of the proposed approach is not to replace existing modeling tools used during the pre- and post-processing phases but to advantageously make use of their potential in a unified way so as to foster the emerging of new ideas by a combination of existing objects. Thus, the pre- and post-processing phases will not be part of this paper.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Generic shape description model (GSDM) as part of a modeling framework enabling conceptual design of objects from enriched heterogeneous data</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        </div></div></section><section aria-labelledby="Sec6"><div class="c-article-section" id="Sec6-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec6">Generic shape description model (GSDM)</h2><div class="c-article-section__content" id="Sec6-content"><p>The so-called generic shape description model (GSDM) has been designed to support the specification and modification of shapes composed by several heterogeneous data. This section introduces this new model together with a set of models and tools used to generate and manipulate it.</p><h3 class="c-article__sub-heading" id="Sec7">Overview</h3><p>The GSDM is structured in three levels of information: conceptual level, intermediate level and data level.</p><p>At the conceptual level, three basic elements are defined to describe the object’s constitutive parts as well as the underlying relations: Component, Group and Relation. Components correspond to the raw and potentially enriched heterogeneous data used as input of the conceptual design phase. A Group indicates a shared behavior or meaning among Components, while Relation explains the topological, distance and directional relations between either Components or Groups or Components and Groups. They help the non-expert user to provide an overview of what is going to be described, without requiring a precise specification. Thus, the idea is to work with high-level functionalities that will act on lower levels (intermediate and data levels). The conceptual level is further described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0302-z#Sec12">3.3</a>.</p><p>To have a detailed description of each part, the data level is needed. This level describes a part of an object through three types of information: Geometry, Structure and Semantics. The first two provide information concerning the appearance of a part, whereas the third refers to its meaning. This level is only partially handled by the non-expert user. This level is detailed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0302-z#Sec8">3.2</a>. In this paper, it is assumed that the heterogeneous models used as input of the conceptual design phase went through a preprocessing phase wherein such data level is set up.</p><p>The intermediate level is then introduced as a mean to specify the relation between each part. At this level, the specific geometric and structural information of the constitutive Components and Groups are exploited and linked with specific constraints. For example, two Components/Groups are connected by indicating one’s location related to the other. At this level, the whole geometry or the whole structure of each part is necessarily accessible to the user. To set up those relations, some Key Entities have to be specified to identify the anchorage elements where restrictions on the related locations are defined. Limitations on reciprocal locations between Key Entities are indicated as Constraints. All those information are gathered together at the intermediate level that is further detailed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0302-z#Sec17">3.4</a>. Ideally, the end user does not access it in a direct manner but through the specification of Relations at the conceptual level. The different levels and associated concepts are represented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig3">3</a>. From the users’ point of view, the modeling approach is top-down in the sense that they prefer to work at the conceptual level with Components, Groups and Relations. The user can also operate at the intermediate level to detail the object’ sub-parts arrangements. To ease the instantiation at the different levels, specific mechanisms have been imagined and will be presented in the next sections and notably the so-called smart manipulation/positioning and smart constraining functionalities. The data level is used to represent the heterogeneous information, to specify Key Entities, to visualize Components and to modify the shapes of Components if needed. Constraints and Key Entities are based on the data level and have their own structures. Overall, the structure of the GSDM is bottom-up since lower levels are used as input of higher levels.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Bottom-up structure of the GSDM associated with a top-down modeling approach</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec8">Data level (Geometry, Structure and Semantics)</h3><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec9">Geometry</h4><p>The shape of an object can be represented by different geometric representations. Heterogeneous geometric representations can be used when specifying the GSDM of an object. No assumption is done on the type of data that can be used to represent a shape. This means that at this level, vector and raster 2D and 3D data are addressed altogether, which is different from existing techniques. All those representations are put in the same 3D reference frame where all the manipulations (translation, rotation and scaling) are performed as described in the next sections. Moreover, the GSDM supports multi-representations and multi-resolutions. It means that a given object can be represented by continuous or discrete representations, in 2D or 3D and at different levels of details, all those representations being stored in the GSDM. Examples of 2D and 3D geometric representations are given in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig4">4</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Examples of geometric and structural representations</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec10">Structure</h4><p>Structures can be defined as the relationships between the different parts of an object and are represented by structure-based shape descriptors. In the proposed approach, such descriptors are used to help the user to position different parts possibly defined by heterogeneous data. Therefore, not only users can define relations between the parts and their associated geometric representations, but they can also make use of the available structures to specify how the parts behave in relation to each other.</p><p>Different kinds of structural representations, such as the medial axis, the symmetry axis, the Reeb graph, the skeleton, are suitable for helping the user to specify the relative positioning of the heterogeneous parts constituting an object. Compared to what exists in the CAD domain, our approach is not restricted to the use of a limited set of entities such as the axis of a cylinder or the center point of a circle that can be constrained together to perform the assembly of different parts. In our approach, more complex descriptors can be used to specify the relations between the components to be combined/assembled. Actually, our approach is not limited to the use of geometric entities defining the geometric model itself. It can use any structure that can be extracted from a given geometric representation. This is a strong difference when compared to other existing approaches.</p><p>During the conceptual design phase, the easy manipulation of the structure of an object is very helpful to sketch rapidly how the different components taking part to the GSDM have to be organized and connected. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig4">4</a> illustrates some examples of 3D and 2D geometric representations (Geometry) as well as possible associated structure-based descriptors (Structure). In this way, the geometric models are segmented and their different parts can easily be constrained through their structures.</p><p>Finally, the Structure defined in the GSDM also has an associated Geometry that can be also heterogeneous. At the data level, the Structure of the GSDM can be a combination of different shape descriptors, such as the medial axis or any segmentation obtained from the corresponding geometric representations, either 2D or 3D.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec11">Semantics</h4><p>Semantics is the purpose and meaning of an instance or an action in a specific context. For example, it can be used to either define the names of the parts used in the conceptual design or specify the intention of an instance or an action. Considering our GSDM, different data are reorganized together following user-specified rules. Most of the time, these rules are associated with meanings explaining why this action is done. For example, the user wants to put two parts together. This action of putting things together can be associated with the purpose of geometrically merging the two parts into one, or it can have the purpose of assembling them such that each part maintains its individuality.</p><p>Semantics can also be used for further design phase or information retrieval. There are two kinds of semantics: intrinsic and extrinsic. Intrinsic semantics express the meaning of something that can be obtained directly from it. For example, a surface can be considered as cylindrical if the distances between all the points on the surface to an axis are equal. The intrinsic semantics in the GSDM can be the “type” of the geometry or structure. This intrinsic information can be extracted from the original data with more or less complex computations. Extrinsic semantics refers to additional information independent of the original data under a specific context. For example, some additional information such as the color, the material, the name, the function, the role in the overall object (e.g., chair, seat, legs) can be added to the representations depending on the context. This information is not contained in the instance and therefore has to be attached/added to it. Both intrinsic and extrinsic semantics are stored in the GSDM and can be manipulated following specific rules (e.g., propagation, inheritance), which are not detailed in this paper.</p><h3 class="c-article__sub-heading" id="Sec12">Conceptual level (Component, Group, Relation)</h3><p>As explained in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0302-z#Sec8">3.2</a>, the data level contains the low-level information needed for the definition, structuring, understanding as well for the visualization and manipulation of shapes. However, in our system, the data level is not directly operated by the users who are focusing on the overall conceptual specification of the object to be designed and not in fine-tuning the underlying final geometric models. The user is more focusing on the part-whole decomposition of the object to which behaviors can be directly associated. This motivates the need of a conceptual level manipulated directly by a non-expert to specify the decompositions into Components, Groups and Relations between them.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec13">Component</h4><p>In the design context, a Component is a part of an object which reorganizes together some (possibly one) Geometric and/or Structural representations so as to represent a part with a basic semantic meaning.</p><p>Components are indivisible parts in the sense that they will not be further decomposed. The user can define a part according to its functions or any other purpose. A part can also be split into more parts. When the decomposition of a part offers enough information, or when a further decomposition is meaningless, the user stops decomposing it. In this case, this part can be considered as an indivisible part. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig5">5</a> details an example of two possible decompositions, which depend on the design context and user intent. If the user is interested in providing a global description of the object in relation to the way it is assembled, then the teapot is described by only two parts: the main body and the cover. When the user wants to decompose it according to the functional characteristics of the components, the teapot is decomposed in a container, a spout, a handle and a cover. If further details are required so as to compare this teapot to another one, then the cover can be decomposed in two parts: the spot-like handler and the disk-shaped surface. Consequently, the number of parts highlights both the complexity of the object and how precise a user wants to be.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Two possible decompositions of an object with respect to the design context and user intent</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Components own specific properties. They are representation independent. The meaning conveyed by a specific Component can originate from various ideas and semantics linked to heterogeneous data. In this definition, the number of geometric or structural representations of a Component is not limited. In other words, a Component can have multiple geometric or structural representations as represented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig6">6</a>. Components are also context oriented. An object can be decomposed differently depending on the context as in the example presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig5">5</a>. Finally, every Component could be in turn described according to the three previously defined layers of information: Geometry, Structure and Semantics.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Component with multiple geometric representations</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec14">Group</h4><p>A Group gathers together several Components associating them either a specific meaning, or a behavior, or attributes. For instance, a user may want to group a set of Components so as to select, modify or search them as a single one. In the following, the general term Element will be used to indicate either a Component or a Group.</p><p>Groups own specific properties. A Group is constituted by at least two Elements, i.e., both Components and Groups can be part of other Groups. All the elements in a Group should have a specified semantic meaning to indicate the purpose of being a Group. It explains why different Elements have to be considered as one. For example, they have a similar function, or the same color. A Group can be an Element of another Group and an Element can belong to several Groups. This is the non-exclusive inclusion property.</p><p>Examples of Groups are presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig7">7</a> representing an office room. All the books on the desk can be clustered in a Group called “Books.” The laptop and the mouse form a Group called “PC.” The “PC” and the “Books” can be also considered as a Group sharing the fact that they all are on the desk. Another Group called “Furniture” refers to all the furniture in this office room including the desk and the chair. The chair and the mouse can be also considered as a Group as they are both made by plastic.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig7_HTML.gif?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig7_HTML.gif" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Example of groups (Office Room): <i>blue circles</i> and blocks for Groups and <i>green blocks</i> for Components</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>In this example, it can be noticed that the “Mouse” is shared by four Groups: “PC,” “Plastic,” “On the table” and “Office room.” To reach the element “Mouse” of the Group “Office room,” a minimum of one Group (“Plastic”), and a maximum of two Groups (“On the table” and “PC”) need to be traversed. The number of Groups to traverse to locate an Element is defined as the depth of the Element in this Group. Thus, for an Element in a Group, there might be a minimum depth and a maximum depth. Depth characterizes the complexity of a Group and is transparent to the user. However, it could be used by the algorithms for the manipulation of Groups.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec15">Relation</h4><p>Relations are used to describe the way two Elements (either Components or Groups) are connected together.</p><p>The links between different Elements may express very complex relations relying on complex operations/algorithms. For example, to satisfy the relation expressing the geometric merging of two Components together, the related location of the two Components needs to be specified, as well as their geometric representations and the parameters related to the merging algorithm properly saying. For a non-expert in computer graphics, describing these complex links can be very difficult. Thus, the approach is top-down, i.e., from the purpose to the specification of the Geometry or Structure and associated rules. Additionally, at the conceptual level, Relations are simple semantic indications characterizing the type of relation/operation independently of the representations or of the associated evaluation rules. For the example presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig8">8</a>, the user wants to merge the spout (textual representation) and the container (point cloud representation) of a teapot together as these two Components are connected because water can flow from the container in the spout. Although the two Components have different representations, the Relation can be specified at a top level. In this paper, we do not address the way the Relation is satisfied at the low-level and we stay at the top level while manipulating the conceptual model. Of course, at the low-level, specific algorithms should perform the merging between the point cloud and the textual representation but this is not part of this work. In our approach, Relations can be of four different types: Merging, Assembly, Shaping and Location. The Merging Relation links two elements that have to be geometrically operated to obtain a unique geometric model. This Relation can be compared to the Boolean union operation on geometric models. For example, in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig8">8</a>, the teapot is composed by four different Components each of them having a different geometrical representation: a 2D image for the handle, a point cloud for the container, a 3D mesh for the cover and a text mapped on a plane for the spout. In real life, even if the container and the spout may be produced separately, a merging operation between them can be required such that the spout and the container create a unique continuous volume. Similarly, the container and the handle can be merged. At the conceptual design level, this is acceptable since the aim is not to create the final shape of the object but to express all the information needed to fully specify this Relation. Distinguishing what happens at the conceptual level from what happens at the geometric level allows a complete shape definition not restricted to the use of limited, time-consuming and sometimes unpredictable modeling details and operations. As already stated, the purpose of the GSDM is to provide the representation of how an object should be created by combining subparts, possibly not completely defined. The Relations aim at specifying the links between them. The real merging operation does not take place at this stage but it can be obtained by processing the GSDM once the geometric description of each constituting Component is completely specified and harmonized (i.e., compatible geometric representations on which Boolean operations can be applied). All those post-treatments of the GSDM are performed during the post-processing step as mentioned in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig2">2</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig8_HTML.gif?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig8_HTML.gif" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Examples of Relations between heterogeneous data</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>The Assembly Relation is a notion similar to what exists in CAD systems. Different Elements are connected together without fusing them into a unique geometric representation but simply linking them with different joints. In the example of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig8">8</a>, the container (point cloud) and the cover (3D mesh) are linked with an Assembly Relation.</p><p>The Shaping Relation is used to indicate the intent to modify the shape of an Element, i.e., to reshape it. It is not simply merging the overlapping area of two Elements by cutting the useless areas, but restyling one Element while taking into account the characteristics of another. These two elements may come from different objects. An example is presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig9">9</a> where specific egg-like chairs could be obtained while combining a traditional chair with the shape of an egg.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig9_HTML.gif?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig9_HTML.gif" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Example of possible intents expressed by a Shaping Relation</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Finally, the Location Relation is used to position an object with respect to the others. On the example of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig8">8</a>, the group composed by the container, the spout, the handle and the cover is located with respect to the table on which they lie. As for the Assembly Relation, the Location Relation does not affect the shapes.</p><p>Relations own specific properties. A Relation is only built between two Elements. Actually, a Relation can be built between more than two elements by exploiting the Group notion. For example, if four legs of a table need to be assembled to a desktop, a Group “support” can be created including the four legs and it can be linked to the desktop through an Assembly Relation. As already stated, a Relation aims at specifying the purpose and rules of the link between Elements, and it is independent from the actual representation of each Element. If there is a Relation between Group A and Element (Group) B, then this Relation explains that all the Elements in Group A should have the same kind of relation with B (or with the Elements in B if B is a group). This is the inheritance property. For example, considering the Group of four legs assembled with a desktop, it is not necessary to indicate that each leg is assembled with the desktop. However, it could be necessary to have some Relations between the legs inside of the Group of legs. This inheritance property is managed at programming level, and it is not specified in the data structure. Finally, the uniqueness property indicates that there is only one kind of Relation between two Elements, including the inherited Relation.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec16">Smart positioning</h4><p>For positioning an element, a smart manipulation system has been designed and is accessible through a specific selector. Actually, repositioning a 3D object in professional software requires the user to specify in which direction or on which plane the positioning is applied. In our implementation, this decision is automatically made by the system. If the user wants to reposition an object on a plane, naturally, he/she will prefer to turn the viewer to face this plane so that the movement of the object can be clearly seen. Based on this consideration, two possibilities have been considered to automatically specify planes. One is parallel to the global reference plane crossing the pivot point of the selected element (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig10">10</a>a). The other one is perpendicular to the global reference plane crossing the pivot point of the selected element and facing the user (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig10">10</a>b). The specified plane is highlighted by an orange and transparent color.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig10_HTML.gif?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig10_HTML.gif" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Positioning of a component: <b>a</b> on a plane parallel to the camera, in a <i>top view</i>; <b>b</b> on a perpendicular plane in a <i>side view</i>
                                       </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h3 class="c-article__sub-heading" id="Sec17">Intermediate level (Key Entity and constraint)</h3><p>The intermediate level specifies how the Components are located the ones with respect to the others in the global reference frame of the virtual environment. In the proposed approach, the location and size of each Component is defined by nine variables specifying the position (<i>x</i>
                           <sub>c</sub>, <i>y</i>
                           <sub>c</sub>, <i>z</i>
                           <sub>c</sub>), orientation (<i>α</i>
                           <sub>c</sub>, <i>β</i>
                           <sub>c</sub>, <i>γ</i>
                           <sub>c</sub>) and scale (<i>s</i>
                           <sub>x</sub>, <i>s</i>
                           <sub>y</sub>, <i>s</i>
                           <sub>z</sub>) of its associated reference frame. To give more freedom in the definition of the conceptual heterogeneous shapes, and to prevent over-constrained configurations, three scale factors are used, one along each direction. All those variables (nine for each Component) form the unknowns of an optimization problem where Constraints are set up between Key Entities linking the different reference frames and associated variables. The way the different Components are constrained is explained in the next section, whereas the way the optimization problem is solved is detailed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0302-z#Sec21">3.5</a>.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec18">Key Entity</h4><p>A Key Entity is a geometric primitive (point, line or oriented point) associated with either the geometric or structural representations of a Component, or simply located in its local reference frame. In the proposed approach, the idea is to make use of Key Entities to constrain directly the geometric and structural representations of the Components taking part to the object definition. This is a much more meaningful and natural way of specifying the relative positioning than to do it indirectly through the reference frames.</p><p>There exist two categories of Key Entities: Geometric and Parametric. A Geometric Key Entity of a Component is only related to the local reference frame of the Component, and it is not modified when its geometric or structural representations evolve. For example, a Geometric Key Point defined for a mesh corresponds to a position in the local reference frame of the mesh. Thus, if the mesh is scaled, this point will not move. A Parametric Key Entity can be represented by a point, a line or an oriented point so as to represent a plane. These Key Entities can be associated directly with the geometric or structural representations of a Component such as a vertex of a mesh with its normal. In addition, a Parametric Key Entity can also be created by building rules between other Key Entities. For example, a line can be defined by two points which can either be Geometric or Parametric Key Entities. In this case, it is called a Parametric Indirect Key Entity.</p><p>A Key Entity can be associated not only with a point, a line or an oriented point but also with a combination of them (indicated as an array). It is defined by some parameters from which the coordinates of the represented geometric primitives are obtained. All the proposed Key Entities are listed in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0302-z#Tab1">1</a>, and some of them are illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig11">11</a>. In this figure, <b>E</b>
                              <sub>
                      <b>FoC</b>
                    </sub> is an oriented point on a contour, <b>E</b>
                              <sub>
                      <b>FiC</b>
                    </sub> is a pixel on an image oriented by the normal of the image, <b>E</b>
                              <sub>
                      <b>PW</b>
                    </sub> is a point on the structure of an image, and <b>E</b>
                              <sub>
                      <b>FM</b>
                    </sub> is a point on a mesh.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Classification of the proposed Key Entities (KEs)</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0302-z/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                              <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig11_HTML.gif?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig11_HTML.gif" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Examples of Key Entities</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>The parameters of a Parametric Direct Key Entity include the related Component, the related representation (geometric. such as a 3D mesh, or structural, such as a skeleton) and some numerical parameters necessary to compute the coordinates of the associated geometric element. The parameters to define a Parametric Indirect Key Entity contain the already specified Key Entities and some numeric parameters explaining their relations.</p><p>All the key entities are represented in a 3D space. A Key Entity owns specific properties. It can be represented by a geometric element such as a point, a line, an oriented point or a combination of them (i.e., an array). This indicates the dimension of the Key Entity. A point is a one-dimensional entity, a line and an oriented point are two-dimensional entities, and an array is an n-dimensional entity where n is the sum of its key entities’ dimensions. The dimension of a Key Entity corresponds to the number of <span class="mathjax-tex">\({\mathbb{R}}^{3}\)</span> elements used to specify its representation. For example, <b>E</b>
                              <sub>
                      <b>LC</b>
                    </sub> (an edge of a 2D contour) is represented by a line defined by two points (each of them is an <span class="mathjax-tex">\({\mathbb{R}}^{3}\)</span> space). In other words, each dimension corresponds to an <span class="mathjax-tex">\({\mathbb{R}}^{3}\)</span> instance, which is named as the “dimensional characteristic” of this key entity. A table classifying all the key entities by their dimensions is presented in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0302-z#Tab2">2</a>.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Dimensions of the Key Entities</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0302-z/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Finally, from the presented specification of Key Entities, it can be noticed that the Parametric Key Entity can be associated with the geometric and/or the structural representations of a Component, while in traditional CAD systems, the key entities used to specify constraints in assemblies are only located on its geometric layer. This is the multi-modality property used to enable the simultaneous manipulation of heterogeneous data.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec19">Constraint</h4><p>Constraints limit the relative location of two Key Entities (KEs), and consequently, they constrain the relative positioning of the underlying representations in the virtual environment. If more than two KEs are involved, an array <b>E</b>
                              <sub>
                      <b>A</b>
                    </sub> of KEs is to be used. Constraints are defined by equations or inequalities linking the KEs. The equations and inequalities depend on the type of Constraint. Even for the same Constraint, different combinations of two KEs may require different equations or inequalities. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0302-z#Tab3">3</a> gathers together all the considered Constraints as well as the related possible combinations of KEs (Pt = Point, OPt = Oriented Point, Li = Line).</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Constraints and associated combinations of KEs</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0302-z/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Coincidence is between two points. Colinearity is used to limit the position of a point along a line. Coplanarity is used to keep a point on a surface. Coaxiality forces two lines to be coincident. Insertion constrains two lines to be coaxial; then, it limits the distance between them. Contact is used to put two surfaces touching each other, and tangent is used to constrain a line and a plane or two planes to be tangent. Pattern is used to distribute points along a line or around a point.</p><p>For example, the Contact constraint between two KEs <span class="mathjax-tex">\({\mathbf{E}}_{{\mathbf{1}}}\)</span> and <span class="mathjax-tex">\({\mathbf{E}}_{2}\)</span> 
                              <span class="mathjax-tex">\(\in \left\{ {{\mathbf{E}}_{{\mathbf{F}}} ,{\mathbf{E}}_{{{\mathbf{FoC}}}} ,{\mathbf{E}}_{{{\mathbf{FiC}}}} ,{\mathbf{E}}_{{{\mathbf{FM}}}} ,{\mathbf{E}}_{{{\mathbf{FP}}}} } \right\}\)</span> is defined as follows:</p><div id="Equa" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$${\mathbf{C}}_{{{\mathbf{Ct}}}} \left( {{\mathbf{E}}_{1} ,{\mathbf{E}}_{2} } \right) = e_{0} \left( {{\mathbf{p}}_{{{\mathbf{E}}1}} ,{\mathbf{p}}_{{{\mathbf{E}}2}} ,1} \right)\&amp;\&amp;~e_{3} \left( {{\mathbf{n}}_{{{\mathbf{E}}1}} ,{\mathbf{n}}_{{{\mathbf{E}}2}} } \right)$$</span></div></div><p>where <span class="mathjax-tex">\({\mathbf{p}}_{{{\mathbf{Ei}}}}\)</span> and <span class="mathjax-tex">\({\mathbf{n}}_{{{\mathbf{Ei}}}}\)</span> are, respectively, the geometric point and the normal associated with <span class="mathjax-tex">\({\mathbf{E}}_{{\mathbf{i}}}\)</span>. This constraint is defined by two sets of equations driven by two generalized functions <span class="mathjax-tex">\(e_{0}\)</span> and <span class="mathjax-tex">\(e_{3}\)</span> so that:</p><div id="Equb" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$e_{0} \left( {{\mathbf{V}}_{1} ,{\mathbf{V}}_{2} ,\alpha } \right) \to {\mathbf{ }}V_{1} = = \alpha \cdot {\mathbf{V}}_{2} \to \left[ {\begin{array}{*{20}c} {x1} \\ {y1} \\ {z1} \\ \end{array} } \right] = = \alpha \cdot \left[ {\begin{array}{*{20}c} {x2} \\ {y2} \\ {z2} \\ \end{array} } \right]$$</span></div></div>
                              <div id="Equc" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$e_{3} \left( {{\mathbf{V}}_{1} ,{\mathbf{V}}_{2} } \right) \to \left\{ {\begin{array}{*{20}l} {x1y2 = = x2y1} \hfill \\ {y1z2 = = y2z1} \hfill \\ {z1x2 = = z2x1} \hfill \\ {x1x2 \le 0} \hfill \\ {y1y2 \le 0} \hfill \\ {z1z2 \le 0} \hfill \\ \end{array} } \right.$$</span></div></div><p>In other words, <span class="mathjax-tex">\(e_{0}\)</span> is used to scale a vector with respect to another one using linear equations. When used with <span class="mathjax-tex">\(\alpha \cdot = 1\)</span> it corresponds to a strict equality of two vectors, which can be used to impose a coincidence constraint. <span class="mathjax-tex">\(e_{3}\)</span> imposes that the two vectors are collinear using nonlinear equations coming from a vector product. The inequalities are also used to further constrain the two vectors. When considering the Contact constraint, the inequalities are used to specify the orientation of the normals.</p><p>The constraints that have been considered were thought to be meaningful for users. As a consequence, semantically, some of them can be special cases of others just putting a specific different value. For example, “Coincidence” between two points can be considered as a special case of “Distance” between two points equal to zero. However, the equation to compute distance is not linear. Thus, to maximize the use of linear equations and linear inequalities, “Coincidence” and “Distance” are differently formulated. At the end, six generalized functions <span class="mathjax-tex">\(e_{i}\)</span> have been defined, each of them assigning specific equations and/or inequalities. As mentioned before, <span class="mathjax-tex">\(e_{0}\)</span> is used to scale a vector with respect to another one. <span class="mathjax-tex">\(e_{3}\)</span> to impose that a vector has to be opposite to another one. Actually, the implementation of <span class="mathjax-tex">\(e_{3}\)</span> makes use of <span class="mathjax-tex">\(e_{0}\)</span>. Then, <span class="mathjax-tex">\(e_{1}\)</span> generates one dot product equation so as to define a perpendicularity between two vectors. <span class="mathjax-tex">\(e_{2}\)</span> imposes two vectors to stay parallel. It is a specific configuration of <span class="mathjax-tex">\(e_{0}\)</span>. <span class="mathjax-tex">\(e_{4}\)</span> assigns a single nonlinear equation while considering the distance between two points. And, finally, <span class="mathjax-tex">\(e_{5}\)</span> is used to impose an angle between two vectors. Due to space limit, the six generalized functions are not detailed and all the constraints (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0302-z#Tab3">3</a>) which have been built on top of those equations are also not detailed.</p><p>As the other constitutive classes of the GSDM, Constraints own specific properties. The value of each Constraint is true or false; in other words, it is a Boolean-valued formula. Therefore, conditional operations can be applied between Constraints, such as conditional equal (“==”), conditional AND (“&amp;&amp;”) and conditional OR (“||”). The results of the conditional operations are still Boolean valued. Finally, because of the specification of KEs, the constraints are built both at the structural and the geometric levels.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec20">Smart constraining</h4><p>Clearly, the specification of KEs requires the access to the data level. This step can be tedious and time-consuming for a non-expert user more interested in working at the conceptual level. Thus, specific smart functionalities have been designed so as to automatically identify potential KEs involved in a Relation specified between two Elements and to automatically select the types of Constraint to be specified between those KEs. When two Elements have to be constrained with a specific Relation and a set of Constraints, the system first detects the closest points on each Element and defines Key Entities on the underlying geometric or structural representations. Then, depending on the type of KEs, the Constraints can be automatically defined. All the configurations have not been detailed in this paper. For example, when the two automatically created KEs correspond to two lines, the system computes the angle between them and automatically chooses the closest configuration between either a parallelism (angle smaller than 45°) or a perpendicular (angle greater than 45°). This is illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig12">12</a>. Practically, the smart positioning system (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0302-z#Sec16">3.3.4</a>) is first used to preposition the Elements which are then automatically constrained using the smart constraining approach.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig12_HTML.gif?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig12_HTML.gif" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Automatic specification of Constraints depending on the type of the identified KEs</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h3 class="c-article__sub-heading" id="Sec21">Constraint satisfaction problem solving</h3><p>The final positioning of all the Elements taking part to the heterogeneous object definition requires the fulfillment of all the Constraints. This corresponds to the resolution of a constraint satisfaction problem (CSP) either at the end of the specification process, or every time a new Constraint is added.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec22">Optimization problem formulation</h4><p>In our approach, the optimization problem is decomposed in:</p><ul class="u-list-style-bullet">
                      <li>
                        <p>a set of <span class="mathjax-tex">\(9 \times {\text{N}}_{\text{c}}\)</span> unknown variables whose values have to be found. <span class="mathjax-tex">\(\text{N}_{\text{c}}\)</span> is the number of Components taking part to the object definition. Each Component <i>i</i> has a local reference frame whose position with respect to the global reference frame of the virtual environment is defined by 9 parameters: 3 parameters for the position <span class="mathjax-tex">\({\mathbf{P}}_{\text{i}} = \left( {x_{i} ,y_{i} ,z_{i} } \right)\)</span>, 3 parameters for the orientation <span class="mathjax-tex">\({\mathbf{R}}_{\text{i}} = \left( {\alpha_{i} ,\beta_{i} ,\gamma_{i} } \right)\)</span> and 3 parameters for the scaling <span class="mathjax-tex">\({\mathbf{S}}_{\text{i}} = \left( {s_{xi} ,s_{yi} ,s_{zi} } \right)\)</span>. Each variable has its own definition domain characterizing its possible values. The position and scaling are in <span class="mathjax-tex">\({\mathbb{R}}^{3}\)</span>, whereas the orientation is in <span class="mathjax-tex">\(\left[ { - \pi ,\pi } \right]^{3}\)</span>.</p>
                      </li>
                      <li>
                        <p>a set of constraints/equations limiting the values that the variables can take. Those equations correspond to the ones generated when specifying the previously introduced Constraints.</p>
                      </li>
                      <li>
                        <p>an objective function to be minimized and used to select one among the multiple solutions which satisfy the constraints.</p>
                      </li>
                    </ul>
                           <p>In our approach, the resolution of the optimization problem is performed in Mathematica9 (Mathematica9 <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Mathematica9 (2016) Available: &#xA;                    http://www.wolfram.com/mathematica/new-in-9/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0302-z#ref-CR15" id="ref-link-section-d54960e3680">2016</a>) where several numerical algorithms can be used. For linear problems, simplex algorithms, revised simplex algorithms, interior point algorithms can be used (Vanderbei <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Vanderbei R (2001) Linear programming: foundations and extensions. Springer, Berlin" href="/article/10.1007/s10055-016-0302-z#ref-CR30" id="ref-link-section-d54960e3683">2001</a>). For nonlinear local optimization, the interior point algorithm (Mehrotra <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Mehrotra S (1992) On the implementation of a primal-dual interior point method. SIAM J Optim 2:575–601" href="/article/10.1007/s10055-016-0302-z#ref-CR16" id="ref-link-section-d54960e3686">1992</a>) can also be used. For nonlinear global optimization, Nelder and Mead (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1965" title="Nelder J, Mead R (1965) A simplex method for function minimization. Comput J 7:308–313" href="/article/10.1007/s10055-016-0302-z#ref-CR18" id="ref-link-section-d54960e3689">1965</a>), differential evolution (Price and Storn <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Price K, Storn R (1997) Differential evolution. Dr. Dobb’s J 264:18–24" href="/article/10.1007/s10055-016-0302-z#ref-CR22" id="ref-link-section-d54960e3692">1997</a>), simulated annealing (Ingber <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Ingber L (1993) Simulated annealing: practice versus theory. Math Comput Model 18(11):29–57" href="/article/10.1007/s10055-016-0302-z#ref-CR10" id="ref-link-section-d54960e3696">1993</a>) and random search can be used.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec23">Objective function to be minimized</h4><p>Since the CSP problem is often under-constrained, an objective function has to be added and minimized/maximized. In comparison with traditional CAD systems, which also have to deal with such a freedom, our approach gives the user the possibility to define his/her own functional to be minimized. Thus, the user can have access to a wider variety of shapes satisfying the same set of constraints. Actually, as it is in real life, the idea is to try to minimize the energy used to move the components between their initial locations and the ones satisfying the constraints. Here, the energy to be minimized takes into account the energy required to move, rotate and deform the different Components belonging to the heterogeneous object definition. Basically, for each Component, this energy is composed of:</p><ul class="u-list-style-bullet">
                      <li>
                        <p>a position energy <span class="mathjax-tex">\(w_{\text{pi}}\)</span> characterizing the amount of energy needed to translate the i<sup>th</sup> Component between a position <span class="mathjax-tex">\({\mathbf{P}}_{i}^{k}\)</span> and another one <span class="mathjax-tex">\({\mathbf{P}}_{i}^{k + 1}\)</span>: </p><div id="Equd" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$w_{\text{pi}} = \mu_{\text{pi}} \left\|{\mathbf{P}}_{i}^{k + 1} - {\mathbf{P}}_{i}^{k}\right\|$$</span></div></div><p>where <span class="mathjax-tex">\(\mu_{\text{pi}}\)</span> stands as a factor that can be easily computed from the volume and density factor of the Component.</p>
                      </li>
                      <li>
                        <p>a rotation energy <span class="mathjax-tex">\(w_{\text{ri}}\)</span> characterizing the amount of energy needed to rotate the <i>i</i>th Component from an orientation <span class="mathjax-tex">\({\mathbf{R}}_{i}^{k}\)</span> to another one <span class="mathjax-tex">\({\mathbf{R}}_{i}^{k + 1}\)</span>: </p><div id="Eque" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$w_{\text{ri}} = \mu_{\text{ri}} \left\| {\mathbf{R}}_{i}^{k + 1} - {\mathbf{R}}_{i}^{k} \right\|$$</span></div></div><p> where <span class="mathjax-tex">\(\mu_{\text{ri}}\)</span> stands as a factor that can be easily computed from the volume and density factor of the Component as well as from the radius of rotation, i.e., the distance between the gravity center and the rotation center.</p>
                      </li>
                      <li>
                        <p>a scaling energy <span class="mathjax-tex">\(w_{\text{si}}\)</span> characterizing the amount of energy needed to scale the <i>i</i>th Component from a scale <span class="mathjax-tex">\({\mathbf{S}}_{i}^{k}\)</span> to another one <span class="mathjax-tex">\({\mathbf{S}}_{i}^{k + 1}\)</span>: </p><div id="Equf" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$w_{\text{si}} = \mu_{\text{si}} \left\| {{\mathbf{S}}_{i}^{k + 1} - {\mathbf{S}}_{i}^{k} } \right\|^{2}$$</span></div></div><p>where <span class="mathjax-tex">\(\mu_{\text{ri}}\)</span> can be easily computed from a stiffness coefficient describing how rigid the transformation is. The square comes from the use of the Hooke’s law.</p>
                      </li>
                    </ul>
                           <p>From those definitions, a global energy can be defined and used as the objective function W to be minimized during the resolution of the optimization problem:</p><div id="Equg" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$W = \mathop \sum \limits_{i = 1}^{{N_{c} }} \left( {\mu_{\text{pi}} \left\| {{\mathbf{P}}_{i}^{k + 1} - {\mathbf{P}}_{i}^{k} } \right\| + \mu_{\text{ri}} \left\| {{\mathbf{R}}_{i}^{k + 1} - {\mathbf{R}}_{i}^{k} } \right\| + \mu_{\text{si}} \left\| {{\mathbf{S}}_{i}^{k + 1} - {\mathbf{S}}_{i}^{k} } \right\|^{2} } \right)$$</span></div></div><p>
                              <i>N</i>
                              <sub>c</sub> is the number of Components involved in the GSDM definition. Our objective is to minimize the sum of these three energies. If the position of a Component <span class="mathjax-tex">\(i\)</span> should not change too much, the <span class="mathjax-tex">\(\mu_{\text{pi}}\)</span> parameter can be set up to a very large value. In this sense, a link between the relocations of each Component and a semantic meaning is set up. In other words, the proposed resolution strategy is more meaningful compared with the one integrated in traditional CAD modelers. The importance of semantics for the constraints can be found in Tutenel et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Tutenel T, Bidarra R, Smelik RM, de Kraker KJ (2008) The role of semantics in games and simulations. ACM Comput Entertain 6(4):1–35" href="/article/10.1007/s10055-016-0302-z#ref-CR28" id="ref-link-section-d54960e4582">2008</a>). Thus, different energy factors <span class="mathjax-tex">\(\mu_{\text{pi}}\)</span>, <span class="mathjax-tex">\(\mu_{\text{ri}}\)</span> and <span class="mathjax-tex">\(\mu_{\text{si}}\)</span> can be used for different Components. The energy factors actually limit the flexibilities of positioning, rotating and scaling each Component.</p></div></div></section><section aria-labelledby="Sec24"><div class="c-article-section" id="Sec24-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec24">The GSDM modeler</h2><div class="c-article-section__content" id="Sec24-content"><p>The GSDM introduced in this paper has been implemented in a user-friendly system totally developed by the authors using the C# language based on Unity3D (Unity3D <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Unity3D (2016) Available: &#xA;                    http://www.unity3.com&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0302-z#ref-CR29" id="ref-link-section-d54960e4670">2016</a>). The adopted mathematical tool for solving the CSP is Mathematica.NET/Link 9 (Mathematica9 <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Mathematica9 (2016) Available: &#xA;                    http://www.wolfram.com/mathematica/new-in-9/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10055-016-0302-z#ref-CR15" id="ref-link-section-d54960e4673">2016</a>). The prototype includes three main modules: modeling of the GSDM, visualization of the GSDM and controllers for the graphic user interface (GUI). GSDM modeling deals with the data structures of the different notions of GSDM, together with the initialization (e.g., of a Component), manipulation (e.g., rotate all Components inside a Group), modification (e.g., change the parameters of a Constraint) and CSP solving of the GSDM. GSDM visualization is necessary for the representation of the GSDM (e.g., how to represent the Geometry and the Structure, how to show the Group). GUI controllers are mainly for developing easy and friendly interfaces for non-expert users and for working both with simple mouse and with touch screen modalities.</p><p>The developed system has been conceived to reduce the users’ effort needed to specify the various elements of the GSDM, as shown in the associated video. It includes the smart capabilities defined in Sects. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0302-z#Sec16">3.3.4</a> and <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0302-z#Sec20">3.4.3</a> for positioning components, either by simple drag and drop capabilities or by expressing constraints among them. The user interface has mainly two areas consisting of a 3D viewer and a control panel as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig13">13</a>, and it is designed to be as simple as possible.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-13"><figure><figcaption><b id="Fig13" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 13</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/13" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig13_HTML.gif?as=webp"></source><img aria-describedby="figure-13-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig13_HTML.gif" alt="figure13" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-13-desc"><p>Interface of the developed prototype</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/13" data-track-dest="link:Figure13 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The 3D viewer is the main workspace to select, manipulate and modify the different notions of the GSDM. The control panel includes the main controllers that execute the complex functions of the GSDM. The user can choose between two work modes as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig14">14</a>. One is called “Free mode,” which is conceived for the manipulation of the conceptual level of the GSDM. The other is the “Constraint mode,” which is designed for working on the intermediate level. A mode switch button allows changing from one mode to another. Contextual menu and interaction (mouse and/or touch) behavior are available according to the selected mode. Thus, for instance in the “Constraint mode,” to simplify their specification, the various possible Key Elements are sensible when the mouse moves over. Default constraints are set automatically as described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-016-0302-z#Sec20">3.4.3</a>. If the user is not satisfied, the button “Constraint tree” allows him/her to select the whished constraint among the ones defined in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0302-z#Tab3">3</a>. Analogously, in the “Free mode,” to ease the positioning and sizing of the Components, a new way to manipulate the objects and the viewer in a 3D scene has been designed, using only drag and drop. When an Element is selected, a round spot appears that specifies the number of the element (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig15">15</a>). It is divided into three zones. When the mouse moves over one of the three zones, its color changes and a letter appears: Orange and the letter “M” is for moving/positioning; blue and the letter “R” is for rotating, and purple and “S” is for scaling. Then, if the user presses the selection handler to realize a drag action, then different types of operations are carried out according to the pressed zone.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-14"><figure><figcaption><b id="Fig14" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 14</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/14" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig14_HTML.gif?as=webp"></source><img aria-describedby="figure-14-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig14_HTML.gif" alt="figure14" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-14-desc"><p>Control panel modes: free mode (<b>a</b>), constraint mode (<b>b</b>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/14" data-track-dest="link:Figure14 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-15"><figure><figcaption><b id="Fig15" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 15</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/15" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig15_HTML.gif?as=webp"></source><img aria-describedby="figure-15-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig15_HTML.gif" alt="figure15" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-15-desc"><p>Manipulation of a Component (or Group): <b>a</b> when a Component is selected. <b>b</b>, <b>c</b>, <b>d</b> When the mouse moves over different zones of the selection handle</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/15" data-track-dest="link:Figure15 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     </div></div></section><section aria-labelledby="Sec25"><div class="c-article-section" id="Sec25-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec25">Results</h2><div class="c-article-section__content" id="Sec25-content"><p>To illustrate the potential of the proposed approach, various examples have been tested.</p><p>The first example aims at validating the proposed approach while demonstrating its capacity to manage heterogeneous models in the conceptual design phase. The idea is to design a so-called crazy chair mixing a set of 2D pictures and 3D textured meshes found on Internet. From a set of inputs (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig16">16</a>a) and user-specified Relations linking Key Entities (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig16">16</a>b) with Constraints (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig16">16</a>c), our system generates the solution presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig16">16</a>d. The values of the energy factors are specified in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0302-z#Tab4">4</a> together with some figures characterizing the complexity of the examples. Here, 4 Components have been used and split in 2 Groups. Three Relations have been defined and make use of 6 Constraints involving 14 Key Entities. Overall, this generates 18 linear equations which can be solved in 11.5 s when using a positioning factor set up to 500, a rotation factor set up to 500 and a scaling factor set up 10,000. Setting up a large scaling factor helps keeping the initial size of the heterogeneous models that were initialized using our smart positioning interface.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-16"><figure><figcaption><b id="Fig16" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 16</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/16" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig16_HTML.gif?as=webp"></source><img aria-describedby="figure-16-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig16_HTML.gif" alt="figure16" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-16-desc"><p>Conceptual design of a crazy chair</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/16" data-track-dest="link:Figure16 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 Summary of the GSDM characteristics for the different examples</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-016-0302-z/tables/4"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>If the energy factors are modified, other solutions are found (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig17">17</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-17"><figure><figcaption><b id="Fig17" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 17</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/17" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig17_HTML.gif?as=webp"></source><img aria-describedby="figure-17-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig17_HTML.gif" alt="figure17" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-17-desc"><p>Conceptual design of a crazy chair using different energy factors as mentioned in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0302-z#Tab4">4</a>
                                 </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/17" data-track-dest="link:Figure17 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The second example focuses on the reverse engineering of a mechanical engine (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig18">18</a>). It illustrates the possibility to assemble scanned parts without necessarily reconstructing the CAD models as it is traditionally done in commercial CAD software. Here, Relations and Constraints are specified between discrete representations.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-18"><figure><figcaption><b id="Fig18" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 18</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/18" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig18_HTML.gif?as=webp"></source><img aria-describedby="figure-18-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig18_HTML.gif" alt="figure18" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-18-desc"><p>Reverse engineering of a mechanical engine</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/18" data-track-dest="link:Figure18 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The third example is a configuration of a nuclear site, demonstrating the capacity to rearrange 3D models on a 2D plan, which is useful for architectural design (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-016-0302-z#Fig19">19</a>). Here again, in contrast to what is possible in commercial software, our system really solves a set of Constraints specified between the Key Entities of the image and the Key Entities of the CAD models, thus exploiting heterogeneous data.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-19"><figure><figcaption><b id="Fig19" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 19</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/19" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig19_HTML.gif?as=webp"></source><img aria-describedby="figure-19-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_Fig19_HTML.gif" alt="figure19" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-19-desc"><p>Mixing 3D models of a power plan with 2D plans</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-016-0302-z/figures/19" data-track-dest="link:Figure19 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-016-0302-z#Tab4">4</a> shows the number of Elements defined in the GSDM of these three examples. It shows that the simultaneous manipulation of heterogeneous data has been made possible and is quite fast with respect to the time the user would have to spend to do it manually.</p></div></div></section><section aria-labelledby="Sec26"><div class="c-article-section" id="Sec26-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec26">Conclusion and perspectives</h2><div class="c-article-section__content" id="Sec26-content"><p>This paper has introduced the so-called generic shape description model (GSDM) together with its general structure and associated concepts and definitions. This is the first step for describing shapes with heterogeneous data using a unified approach. Heterogeneous objects are obtained while constraining different components within a unique reference frame. Position, orientation and scale of the components are considered as unknowns of an optimization problem. An extended constraints toolbox has been developed together with the mechanisms to specify them in an easy way. The resolution of the optimization problem tends to minimize a deformation energy involving position, orientation and scaling factors. The proposed approach has been illustrated through several applications requiring the simultaneous manipulation of heterogeneous models in different context. It is clear that using such an approach is more efficient and accurate than what exists in commercial CAD software. However, the development of an effective conceptual design tool based on the GSDM requires the resolution of some research and implementation issues.</p><p>The semantics associated with the current version is mainly used to store information for initializing different constituents of the GSDM, such as the “type” or “reason.” For some specific design contexts and applications, it can be further specified and extended together with the related mechanisms to treat such high-level information.</p><p>The concepts of geometry and structure have been included in the GSDM. In principle, they encompass any geometric and structural representation. In this work, not all the geometric and structural representations have been treated. To effectively exploit all the existing resources, additional representations should be considered. This could be done through the development of new plug-ins. Moreover, even if there exists plenty of algorithms for shape segmentation and structural descriptors’ computation, most of the data available are still containing only pure geometric information. Actually, most of the resources require some human intervention to be used in our system for the component selection. This is a limitation. Additionally, for input data missing structural information, the system automatically creates a structure that is the bounding box, which might limit the specification of the relations between components.</p><p>Of course, the constraints toolbox can also be extended to consider new constraints useful in specific applications not yet treated. User-specified constraints can also be considered to extend even more the capacity of the system.</p><p>Moreover, the relation type of “Shaping” is not fully expressed in this paper, while just a general concept has been proposed. However, such a relation can be of real interest for design and creativity issues. In the post-processing, a fully 3D representation should be generated from the GSDM with its 3D structure and semantics. This requires more advanced techniques in mesh merging and 3D reverse engineering from images. New research on structure and semantics merging is required for their correct updating according to the achieved 3D object model. With both the preprocessing (shape segmentation and structuring) and post-processing phases, we believe that the GSDM can be used in the whole 3D object design process while strongly improving the collaborative conceptual design phase.</p><p>Finally, we can imagine to use GSDM in other application contexts, such as the medical analysis domain for representing different medical data and diagnostic results (CT images, type-B ultrasonic images, etc.) in a unified 3D environment, aligned to a 3D model of a human body. GSDM could also be used as a plug-in for a 3D presentation tool such as Microsoft’s PowerPoint but in 3D. In this case, text and animation abilities should be further developed.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Allègre, E. Galin, R. Chaine, S. Akkouche, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Allègre R, Galin E, Chaine R, Akkouche S (2006) The HybridTree: mixing skeletal implicit surfaces, triangle me" /><p class="c-article-references__text" id="ref-CR1">Allègre R, Galin E, Chaine R, Akkouche S (2006) The HybridTree: mixing skeletal implicit surfaces, triangle meshes, and point sets in a free-form modeling system. Graph Models 68(1):42–64</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.gmod.2005.09.001" aria-label="View reference 1">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1103.68920" aria-label="View reference 1 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20HybridTree%3A%20mixing%20skeletal%20implicit%20surfaces%2C%20triangle%20meshes%2C%20and%20point%20sets%20in%20a%20free-form%20modeling%20system&amp;journal=Graph%20Models&amp;volume=68&amp;issue=1&amp;pages=42-64&amp;publication_year=2006&amp;author=All%C3%A8gre%2CR&amp;author=Galin%2CE&amp;author=Chaine%2CR&amp;author=Akkouche%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Antonelli, C. Beccari, G. Casciola, R. Ciarloni, S. Morigi, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Antonelli M, Beccari C, Casciola G, Ciarloni R, Morigi S (2013) Subdivision surfaces integrated in a CAD syste" /><p class="c-article-references__text" id="ref-CR2">Antonelli M, Beccari C, Casciola G, Ciarloni R, Morigi S (2013) Subdivision surfaces integrated in a CAD system. Comput Aided Des 45(11):1294–1305</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.cad.2013.06.007" aria-label="View reference 2">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Subdivision%20surfaces%20integrated%20in%20a%20CAD%20system&amp;journal=Comput%20Aided%20Des&amp;volume=45&amp;issue=11&amp;pages=1294-1305&amp;publication_year=2013&amp;author=Antonelli%2CM&amp;author=Beccari%2CC&amp;author=Casciola%2CG&amp;author=Ciarloni%2CR&amp;author=Morigi%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Biasotti, D. Giorgi, M. Spagnuolo, B. Falcidieno, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Biasotti S, Giorgi D, Spagnuolo M, Falcidieno B (2008) Reeb graphs for shape analysis and applications. Theore" /><p class="c-article-references__text" id="ref-CR3">Biasotti S, Giorgi D, Spagnuolo M, Falcidieno B (2008) Reeb graphs for shape analysis and applications. Theoret Comput Sci 392(1–3):5–22</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2394982" aria-label="View reference 3 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.tcs.2007.10.018" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1134.68064" aria-label="View reference 3 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Reeb%20graphs%20for%20shape%20analysis%20and%20applications&amp;journal=Theoret%20Comput%20Sci&amp;volume=392&amp;issue=1%E2%80%933&amp;pages=5-22&amp;publication_year=2008&amp;author=Biasotti%2CS&amp;author=Giorgi%2CD&amp;author=Spagnuolo%2CM&amp;author=Falcidieno%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="I. Bloch, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Bloch I (1999) Fuzzy relative position between objects in image processing: a morphological approach. IEEE Tra" /><p class="c-article-references__text" id="ref-CR4">Bloch I (1999) Fuzzy relative position between objects in image processing: a morphological approach. IEEE Trans Pattern Anal Mach Intell 21(7):657–664</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F34.777378" aria-label="View reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Fuzzy%20relative%20position%20between%20objects%20in%20image%20processing%3A%20a%20morphological%20approach&amp;journal=IEEE%20Trans%20Pattern%20Anal%20Mach%20Intell&amp;volume=21&amp;issue=7&amp;pages=657-664&amp;publication_year=1999&amp;author=Bloch%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Décriteau, J-P. Pernot, M. Daniel, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Décriteau D, Pernot J-P, Daniel M (2016) Towards a declarative modelling approach built on top of a CAD modell" /><p class="c-article-references__text" id="ref-CR5">Décriteau D, Pernot J-P, Daniel M (2016) Towards a declarative modelling approach built on top of a CAD modeller. Comput Aided Design Appl 13(6):737–746</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F16864360.2016.1168215" aria-label="View reference 5">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Towards%20a%20declarative%20modelling%20approach%20built%20on%20top%20of%20a%20CAD%20modeller&amp;journal=Comput%20Aided%20Design%20Appl&amp;volume=13&amp;issue=6&amp;pages=737-746&amp;publication_year=2016&amp;author=D%C3%A9criteau%2CD&amp;author=Pernot%2CJ-P&amp;author=Daniel%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Deluca, P. Véron, M. Florenzano, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Deluca L, Véron P, Florenzano M (2006) Reverse engineering of architectural buildings based on a hybrid modeli" /><p class="c-article-references__text" id="ref-CR6">Deluca L, Véron P, Florenzano M (2006) Reverse engineering of architectural buildings based on a hybrid modeling approach. Comput Graph 30(2):160–176</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.cag.2006.01.020" aria-label="View reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Reverse%20engineering%20of%20architectural%20buildings%20based%20on%20a%20hybrid%20modeling%20approach&amp;journal=Comput%20Graph&amp;volume=30&amp;issue=2&amp;pages=160-176&amp;publication_year=2006&amp;author=Deluca%2CL&amp;author=V%C3%A9ron%2CP&amp;author=Florenzano%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SF. El-Hakim, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="El-Hakim SF (2002) Semi-automatic 3D reconstruction of occluded and unmarked surfaces from widely separated vi" /><p class="c-article-references__text" id="ref-CR7">El-Hakim SF (2002) Semi-automatic 3D reconstruction of occluded and unmarked surfaces from widely separated views. Int Arch Photogr Remote Sens Spatial Inf Sci 34(5):143–145</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Semi-automatic%203D%20reconstruction%20of%20occluded%20and%20unmarked%20surfaces%20from%20widely%20separated%20views&amp;journal=Int%20Arch%20Photogr%20Remote%20Sens%20Spatial%20Inf%20Sci&amp;volume=34&amp;issue=5&amp;pages=143-145&amp;publication_year=2002&amp;author=El-Hakim%2CSF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Falcidieno B, Spagnuolo M, Alliez P, Quak E, Vavalis E, Houstis C (2004) Towards the semantics of digital shap" /><p class="c-article-references__text" id="ref-CR8">Falcidieno B, Spagnuolo M, Alliez P, Quak E, Vavalis E, Houstis C (2004) Towards the semantics of digital shapes: the AIM@SHAPE approach. EWIMT</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Hudelot, J. Atif, I. Bloch, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Hudelot C, Atif J, Bloch I (2008) Fuzzy spatial relation ontology for image interpretation. Fuzzy Sets Syst 15" /><p class="c-article-references__text" id="ref-CR9">Hudelot C, Atif J, Bloch I (2008) Fuzzy spatial relation ontology for image interpretation. Fuzzy Sets Syst 159(15):1929–1951</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2521600" aria-label="View reference 9 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.fss.2008.02.011" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Fuzzy%20spatial%20relation%20ontology%20for%20image%20interpretation&amp;journal=Fuzzy%20Sets%20Syst&amp;volume=159&amp;issue=15&amp;pages=1929-1951&amp;publication_year=2008&amp;author=Hudelot%2CC&amp;author=Atif%2CJ&amp;author=Bloch%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Ingber, " /><meta itemprop="datePublished" content="1993" /><meta itemprop="headline" content="Ingber L (1993) Simulated annealing: practice versus theory. Math Comput Model 18(11):29–57" /><p class="c-article-references__text" id="ref-CR10">Ingber L (1993) Simulated annealing: practice versus theory. Math Comput Model 18(11):29–57</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1254392" aria-label="View reference 10 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2F0895-7177%2893%2990204-C" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0819.90080" aria-label="View reference 10 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Simulated%20annealing%3A%20practice%20versus%20theory&amp;journal=Math%20Comput%20Model&amp;volume=18&amp;issue=11&amp;pages=29-57&amp;publication_year=1993&amp;author=Ingber%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Jain, T. Thormählen, T. Ritschel, H-P. Seidel, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Jain A, Thormählen T, Ritschel T, Seidel H-P (2012) Exploring shape variations by 3D-model decomposition and p" /><p class="c-article-references__text" id="ref-CR11">Jain A, Thormählen T, Ritschel T, Seidel H-P (2012) Exploring shape variations by 3D-model decomposition and part-based recombination. Comput Graphics Forum 31(2):631–640</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fj.1467-8659.2012.03042.x" aria-label="View reference 11">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Exploring%20shape%20variations%20by%203D-model%20decomposition%20and%20part-based%20recombination&amp;journal=Comput%20Graphics%20Forum&amp;volume=31&amp;issue=2&amp;pages=631-640&amp;publication_year=2012&amp;author=Jain%2CA&amp;author=Thorm%C3%A4hlen%2CT&amp;author=Ritschel%2CT&amp;author=Seidel%2CH-P">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="N. Jiang, P. Tan, LF. Cheong, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Jiang N, Tan P, Cheong LF (2009) Symmetric architecture modeling with a single image. ACM Trans Graph 28(5):1–" /><p class="c-article-references__text" id="ref-CR12">Jiang N, Tan P, Cheong LF (2009) Symmetric architecture modeling with a single image. ACM Trans Graph 28(5):1–8</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F1618452.1618459" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Symmetric%20architecture%20modeling%20with%20a%20single%20image&amp;journal=ACM%20Trans%20Graph&amp;volume=28&amp;issue=5&amp;pages=1-8&amp;publication_year=2009&amp;author=Jiang%2CN&amp;author=Tan%2CP&amp;author=Cheong%2CLF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lee J, Funkhouser T (2008) Sketch-based search and composition of 3D models. In: EUROGRAPHICS workshop on sket" /><p class="c-article-references__text" id="ref-CR13">Lee J, Funkhouser T (2008) Sketch-based search and composition of 3D models. In: EUROGRAPHICS workshop on sketch-based interfaces and modeling, 2008</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="C. Luciano da Fontoura, J. Roberto Marcondes Cesar, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Luciano da Fontoura C, Roberto Marcondes Cesar J (2000) Shape analysis and classification: theory and practice" /><p class="c-article-references__text" id="ref-CR14">Luciano da Fontoura C, Roberto Marcondes Cesar J (2000) Shape analysis and classification: theory and practice. CRC Press, Boca Raton</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Shape%20analysis%20and%20classification%3A%20theory%20and%20practice&amp;publication_year=2000&amp;author=Luciano%20da%20Fontoura%2CC&amp;author=Roberto%20Marcondes%20Cesar%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mathematica9 (2016) Available: http://www.wolfram.com/mathematica/new-in-9/&#xA;                        " /><p class="c-article-references__text" id="ref-CR15">Mathematica9 (2016) Available: <a href="http://www.wolfram.com/mathematica/new-in-9/">http://www.wolfram.com/mathematica/new-in-9/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Mehrotra, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Mehrotra S (1992) On the implementation of a primal-dual interior point method. SIAM J Optim 2:575–601" /><p class="c-article-references__text" id="ref-CR16">Mehrotra S (1992) On the implementation of a primal-dual interior point method. SIAM J Optim 2:575–601</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1186163" aria-label="View reference 16 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1137%2F0802028" aria-label="View reference 16">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0773.90047" aria-label="View reference 16 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20implementation%20of%20a%20primal-dual%20interior%20point%20method&amp;journal=SIAM%20J%20Optim&amp;volume=2&amp;pages=575-601&amp;publication_year=1992&amp;author=Mehrotra%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mitra N, Wand M, Zhang H, Cohen-Or D, Kim V, Huang Q-X (2013) Structure-aware shape processing. In: SIGGRAPH A" /><p class="c-article-references__text" id="ref-CR17">Mitra N, Wand M, Zhang H, Cohen-Or D, Kim V, Huang Q-X (2013) Structure-aware shape processing. In: SIGGRAPH Asia 2013 courses. ACM, New York</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Nelder, R. Mead, " /><meta itemprop="datePublished" content="1965" /><meta itemprop="headline" content="Nelder J, Mead R (1965) A simplex method for function minimization. Comput J 7:308–313" /><p class="c-article-references__text" id="ref-CR18">Nelder J, Mead R (1965) A simplex method for function minimization. Comput J 7:308–313</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3363409" aria-label="View reference 18 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1093%2Fcomjnl%2F7.4.308" aria-label="View reference 18">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0229.65053" aria-label="View reference 18 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20simplex%20method%20for%20function%20minimization&amp;journal=Comput%20J&amp;volume=7&amp;pages=308-313&amp;publication_year=1965&amp;author=Nelder%2CJ&amp;author=Mead%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Office Room (2016) Available: http://www.decosee.com/2014/04/07/modern-office-room-minimalist-idea-23394.html&#xA;" /><p class="c-article-references__text" id="ref-CR19">Office Room (2016) Available: <a href="http://www.decosee.com/2014/04/07/modern-office-room-minimalist-idea-23394.html">http://www.decosee.com/2014/04/07/modern-office-room-minimalist-idea-23394.html</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Panchetti, J-P. Pernot, P. Véron, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Panchetti M, Pernot J-P, Véron P (2010) Towards recovery of complex shapes in meshes using digital images for " /><p class="c-article-references__text" id="ref-CR20">Panchetti M, Pernot J-P, Véron P (2010) Towards recovery of complex shapes in meshes using digital images for reverse engineering applications. Comput Aided Des 42(8):693–707</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.cad.2010.01.004" aria-label="View reference 20">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Towards%20recovery%20of%20complex%20shapes%20in%20meshes%20using%20digital%20images%20for%20reverse%20engineering%20applications&amp;journal=Comput%20Aided%20Des&amp;volume=42&amp;issue=8&amp;pages=693-707&amp;publication_year=2010&amp;author=Panchetti%2CM&amp;author=Pernot%2CJ-P&amp;author=V%C3%A9ron%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pernot J-P, Falcidieno B, Giannini F, Léon J-C (2008) Hybrid models deformation tool for free-form shapes mani" /><p class="c-article-references__text" id="ref-CR21">Pernot J-P, Falcidieno B, Giannini F, Léon J-C (2008) Hybrid models deformation tool for free-form shapes manipulation. In: ASME 2008 international design engineering technical conferences &amp; design and automation conference, New-York</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Price, R. Storn, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Price K, Storn R (1997) Differential evolution. Dr. Dobb’s J 264:18–24" /><p class="c-article-references__text" id="ref-CR22">Price K, Storn R (1997) Differential evolution. Dr. Dobb’s J 264:18–24</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0888.90135" aria-label="View reference 22 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Differential%20evolution&amp;journal=Dr.%20Dobb%E2%80%99s%20J&amp;volume=264&amp;pages=18-24&amp;publication_year=1997&amp;author=Price%2CK&amp;author=Storn%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Reeb G (1946) Sur les points singuliers d’une forme de Pfaff complètement intégrable ou d’une fonction numériq" /><p class="c-article-references__text" id="ref-CR23">Reeb G (1946) Sur les points singuliers d’une forme de Pfaff complètement intégrable ou d’une fonction numérique. Comptes-rendus de l’Académie des Sciences, pp 848–849</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Repository TS (2011–2015) Shape repository. http://visionair.ge.imati.cnr.it/ontologies/shapes/&#xA;              " /><p class="c-article-references__text" id="ref-CR24">Repository TS (2011–2015) Shape repository. <a href="http://visionair.ge.imati.cnr.it/ontologies/shapes/">http://visionair.ge.imati.cnr.it/ontologies/shapes/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="K. Sawyer, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Sawyer K (2013) Zig Zag: the surprising path to greater creativity. Jossey-Bass, New York" /><p class="c-article-references__text" id="ref-CR25">Sawyer K (2013) Zig Zag: the surprising path to greater creativity. Jossey-Bass, New York</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Zig%20Zag%3A%20the%20surprising%20path%20to%20greater%20creativity&amp;publication_year=2013&amp;author=Sawyer%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Smith, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Smith G (1998) Idea-generation techniques: a formulary of active ingredients. J Creative Behav 32(2):107–133" /><p class="c-article-references__text" id="ref-CR26">Smith G (1998) Idea-generation techniques: a formulary of active ingredients. J Creative Behav 32(2):107–133</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1610684" aria-label="View reference 26 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2Fj.2162-6057.1998.tb00810.x" aria-label="View reference 26">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Idea-generation%20techniques%3A%20a%20formulary%20of%20active%20ingredients&amp;journal=J%20Creative%20Behav&amp;volume=32&amp;issue=2&amp;pages=107-133&amp;publication_year=1998&amp;author=Smith%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Takemura CM (2008) Modelagem de posições relativas de formas complexas para análise de configuração espacial. " /><p class="c-article-references__text" id="ref-CR27">Takemura CM (2008) Modelagem de posições relativas de formas complexas para análise de configuração espacial. Doutorado em Ciências da Computação, Universidade de São Paulo</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Tutenel, R. Bidarra, RM. Smelik, KJ. Kraker, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Tutenel T, Bidarra R, Smelik RM, de Kraker KJ (2008) The role of semantics in games and simulations. ACM Compu" /><p class="c-article-references__text" id="ref-CR28">Tutenel T, Bidarra R, Smelik RM, de Kraker KJ (2008) The role of semantics in games and simulations. ACM Comput Entertain 6(4):1–35</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F1461999.1462009" aria-label="View reference 28">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20role%20of%20semantics%20in%20games%20and%20simulations&amp;journal=ACM%20Comput%20Entertain&amp;volume=6&amp;issue=4&amp;pages=1-35&amp;publication_year=2008&amp;author=Tutenel%2CT&amp;author=Bidarra%2CR&amp;author=Smelik%2CRM&amp;author=Kraker%2CKJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Unity3D (2016) Available: http://www.unity3.com&#xA;                        " /><p class="c-article-references__text" id="ref-CR29">Unity3D (2016) Available: <a href="http://www.unity3.com">http://www.unity3.com</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="R. Vanderbei, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Vanderbei R (2001) Linear programming: foundations and extensions. Springer, Berlin" /><p class="c-article-references__text" id="ref-CR30">Vanderbei R (2001) Linear programming: foundations and extensions. Springer, Berlin</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Linear%20programming%3A%20foundations%20and%20extensions&amp;publication_year=2001&amp;author=Vanderbei%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Wendrich R (2009–2016) Raw shaping form finding project. www.rawshaping.com&#xA;                        " /><p class="c-article-references__text" id="ref-CR31">Wendrich R (2009–2016) Raw shaping form finding project. <a href="http://www.rawshaping.com">www.rawshaping.com</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X. Xie, K. Xu, NJ. Mitra, D. Cohen-Or, W. Gong, Q. Su, B. Chen, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Xie X, Xu K, Mitra NJ, Cohen-Or D, Gong W, Su Q, Chen B (2013) Sketch-to-design: context-based part assembly. " /><p class="c-article-references__text" id="ref-CR32">Xie X, Xu K, Mitra NJ, Cohen-Or D, Gong W, Su Q, Chen B (2013) Sketch-to-design: context-based part assembly. Comput Graphics Forum 32(8):233–245</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1111%2Fcgf.12200" aria-label="View reference 32">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Sketch-to-design%3A%20context-based%20part%20assembly&amp;journal=Comput%20Graphics%20Forum&amp;volume=32&amp;issue=8&amp;pages=233-245&amp;publication_year=2013&amp;author=Xie%2CX&amp;author=Xu%2CK&amp;author=Mitra%2CNJ&amp;author=Cohen-Or%2CD&amp;author=Gong%2CW&amp;author=Su%2CQ&amp;author=Chen%2CB">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-016-0302-z-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>The work has been partially supported by the VISIONAIR project funded by the European Commission under Grant Agreement 262044, the French National project Co-DIVE and by the Italian National Project “Tecnologie e sistemi innovativi per la fabbrica del futuro e Made in Italy.”</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">LSIS UMR CNRS 7296, Arts et Métiers ParisTech, Aix-En-Provence, France</p><p class="c-article-author-affiliation__authors-list">Zongcheng Li, Jean-Philippe Pernot &amp; Philippe Véron</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">IMATI-CNR, Genoa, Italy</p><p class="c-article-author-affiliation__authors-list">Zongcheng Li, Franca Giannini &amp; Bianca Falcidieno</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Zongcheng-Li"><span class="c-article-authors-search__title u-h3 js-search-name">Zongcheng Li</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Zongcheng+Li&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Zongcheng+Li" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Zongcheng+Li%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Franca-Giannini"><span class="c-article-authors-search__title u-h3 js-search-name">Franca Giannini</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Franca+Giannini&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Franca+Giannini" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Franca+Giannini%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Jean_Philippe-Pernot"><span class="c-article-authors-search__title u-h3 js-search-name">Jean-Philippe Pernot</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Jean-Philippe+Pernot&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jean-Philippe+Pernot" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jean-Philippe+Pernot%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Philippe-V_ron"><span class="c-article-authors-search__title u-h3 js-search-name">Philippe Véron</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Philippe+V%C3%A9ron&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Philippe+V%C3%A9ron" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Philippe+V%C3%A9ron%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Bianca-Falcidieno"><span class="c-article-authors-search__title u-h3 js-search-name">Bianca Falcidieno</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Bianca+Falcidieno&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Bianca+Falcidieno" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Bianca+Falcidieno%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-016-0302-z/email/correspondent/c1/new">Jean-Philippe Pernot</a>.</p></div></div></section><section aria-labelledby="Sec27"><div class="c-article-section" id="Sec27-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec27">Electronic supplementary material</h2><div class="c-article-section__content" id="Sec27-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM1"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1007%2Fs10055-016-0302-z/MediaObjects/10055_2016_302_MOESM1_ESM.mp4" data-supp-info-image="">Supplementary material 1 (MP4 107715 kb)</a></h3></div></div></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Reusing%20heterogeneous%20data%20for%20the%20conceptual%20design%20of%20shapes%20in%20virtual%20environments&amp;author=Zongcheng%20Li%20et%20al&amp;contentID=10.1007%2Fs10055-016-0302-z&amp;publication=1359-4338&amp;publicationDate=2016-11-30&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-016-0302-z" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-016-0302-z" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Li, Z., Giannini, F., Pernot, J. <i>et al.</i> Reusing heterogeneous data for the conceptual design of shapes in virtual environments.
                    <i>Virtual Reality</i> <b>21, </b>127–144 (2017). https://doi.org/10.1007/s10055-016-0302-z</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-016-0302-z.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-09-16">16 September 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-11-17">17 November 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-11-30">30 November 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2017-09">September 2017</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-016-0302-z" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-016-0302-z</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Virtual reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Conceptual design</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Shape and object description</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Heterogeneous data</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Constraint satisfaction problem</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-016-0302-z.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=302;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

