<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Mixed prototypes for the evaluation of usability and user experience: "/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Mixed prototyping technology can be used to represent and simulate the behavior of interactive products at low cost and with great flexibility. This preliminary experimental research intends to..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/23/2.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Mixed prototypes for the evaluation of usability and user experience: simulating an interactive electronic device"/>

    <meta name="dc.source" content="Virtual Reality 2018 23:2"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2018-07-13"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2018 Springer-Verlag London Ltd., part of Springer Nature"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Mixed prototyping technology can be used to represent and simulate the behavior of interactive products at low cost and with great flexibility. This preliminary experimental research intends to verify the suitability of using this technology in the evaluation of usability and user experience of interactive products. Users and experts evaluate the mixed prototype of an image projector with regard to its own usability, and also with respect to its ability to be used to evaluate usability and user experience aspects of the real projector. Users perform tasks on both the real projector and its mixed prototype. In regard to these comparative performance evaluations, time to perform the task and number of errors show a clear positive relationship with the difficulty of the task for both mixed prototype and real projector. In regard to more subjective UX evaluations, the results show to be congruent. However, we realize that emotions assigned to the mixed prototype are influenced by the &#8220;fascination&#8221; that augmented reality arises in individuals. Experts evaluate the mixed prototype with respect to aspects of the interaction with the product that it is able to simulate, and with respect to the classes of products best suited to be prototyped. They highlighted the possibility of using the technology to evaluate product performance, ergonomics, and operation. In regard to the classes of products to be prototyped, experts&#8217; suggestions coincided with the classes of products that have already been used in research: household appliances, information and communication devices, and automotive parts and accessories."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2018-07-13"/>

    <meta name="prism.volume" content="23"/>

    <meta name="prism.number" content="2"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="197"/>

    <meta name="prism.endingPage" content="211"/>

    <meta name="prism.copyright" content="2018 Springer-Verlag London Ltd., part of Springer Nature"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-018-0356-1"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-018-0356-1"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-018-0356-1.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-018-0356-1"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Mixed prototypes for the evaluation of usability and user experience: simulating an interactive electronic device"/>

    <meta name="citation_volume" content="23"/>

    <meta name="citation_issue" content="2"/>

    <meta name="citation_publication_date" content="2019/06"/>

    <meta name="citation_online_date" content="2018/07/13"/>

    <meta name="citation_firstpage" content="197"/>

    <meta name="citation_lastpage" content="211"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-018-0356-1"/>

    <meta name="DOI" content="10.1007/s10055-018-0356-1"/>

    <meta name="citation_doi" content="10.1007/s10055-018-0356-1"/>

    <meta name="description" content="Mixed prototyping technology can be used to represent and simulate the behavior of interactive products at low cost and with great flexibility. This prelim"/>

    <meta name="dc.creator" content="Fernanda Gomes Faust"/>

    <meta name="dc.creator" content="Tiago Catecati"/>

    <meta name="dc.creator" content="Isabella de Souza Sierra"/>

    <meta name="dc.creator" content="Fernanda Steinbruch Araujo"/>

    <meta name="dc.creator" content="Alejandro Rafael Garc&#237;a Ram&#237;rez"/>

    <meta name="dc.creator" content="Elton Moura Nickel"/>

    <meta name="dc.creator" content="Marcelo Gitirana Gomes Ferreira"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Interact Des Manuf; citation_title=Mixed reality system for evaluating designability and operability of information appliances; citation_author=H Aoyama, Y Kimishima; citation_volume=3; citation_issue=3; citation_publication_date=2009; citation_pages=157-164; citation_doi=10.1007/s12008-009-0070-z; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_journal_title=J Usab Stud; citation_title=Determining what individual SUS scores mean: adding an adjective rating scale; citation_author=A Bangor, P Kortum, J Miller; citation_volume=4; citation_issue=3; citation_publication_date=2009; citation_pages=114-123; citation_id=CR2"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Ind; citation_title=Mixed prototyping with configurable physical archetype for usability evaluation of product interfaces; citation_author=L Barbieri, A Angilica, F Bruno; citation_volume=64; citation_issue=3; citation_publication_date=2013; citation_pages=310-323; citation_doi=10.1016/j.compind.2012.11.010; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Phys Prototyp; citation_title=Mixed reality distributed platform for collaborative design review of automotive interiors; citation_author=M Bordegoni, G Caruso; citation_volume=7; citation_issue=4; citation_publication_date=2012; citation_pages=243-259; citation_doi=10.1080/17452759.2012.721605; citation_id=CR4"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Interact Des Manuf; citation_title=Mixed prototyping for product assessment: a reference framework; citation_author=M Bordegoni, U Cugini, G Caruso, S Polistina; citation_volume=3; citation_issue=3; citation_publication_date=2009; citation_pages=177-187; citation_doi=10.1007/s12008-009-0073-9; citation_id=CR5"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Haptics; citation_title=Geodesic spline interface for haptic curve rendering; citation_author=M Bordegoni, F Ferrise, M Covarrubias, M Antolini; citation_volume=4; citation_issue=2; citation_publication_date=2011; citation_pages=111-121; citation_doi=10.1109/TOH.2011.1; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_journal_title=Usab Eval Ind; citation_title=SUS-A quick and dirty usability scale; citation_author=J Brooke; citation_volume=189; citation_issue=194; citation_publication_date=1996; citation_pages=4-7; citation_id=CR7"/>

    <meta name="citation_reference" content="citation_journal_title=Eng Comput; citation_title=Reliable behaviour simulation of product interface in mixed reality; citation_author=F Bruno, A Angilica, F Cosco, M Muzzupappa; citation_volume=29; citation_issue=3; citation_publication_date=2013; citation_pages=375-387; citation_doi=10.1007/s00366-012-0293-7; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_title=Designing the new PrEmo: an empirical research on how to improve the emotion measuring tool; citation_publication_date=2009; citation_id=CR9; citation_author=DG Caicedo; citation_author=PM Desmet; citation_publisher=Delf University of Technology"/>

    <meta name="citation_reference" content="citation_journal_title=Procedia Manuf; citation_title=Utilizing end user input in early product development; citation_author=YM Choi; citation_volume=3; citation_publication_date=2015; citation_pages=2244-2250; citation_doi=10.1016/j.promfg.2015.07.368; citation_id=CR10"/>

    <meta name="citation_reference" content="citation_title=Measuring emotions: development and application of an instrument to measure emotional responses to products; citation_inbook_title=Funology: from usability to enjoyment; citation_publication_date=2003; citation_pages=111-124; citation_id=CR11; citation_author=PM Desmet; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Work (Reading, Mass.); citation_title=Use of augmented reality in the usability evaluation of products; citation_author=FG Faust, G Roepke, T Catecati, F Araujo, MG Gomes Ferreira, D Albertazzi; citation_volume=41; citation_issue=1; citation_publication_date=2012; citation_pages=1164-1167; citation_id=CR12"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Aided Des Appl; citation_title=A method for designing users&#8217; experience with industrial products based on a multimodal environment and mixed prototypes; citation_author=F Ferrise, M Bordegoni, S Graziosi; citation_volume=10; citation_issue=3; citation_publication_date=2013; citation_pages=461-474; citation_doi=10.3722/cadaps.2013.461-474; citation_id=CR13"/>

    <meta name="citation_reference" content="citation_journal_title=J Intell Manuf; citation_title=Prototyping strategies for multisensory product experience engineering; citation_author=F Ferrise, S Graziosi, M Bordegoni; citation_volume=28; citation_issue=7; citation_publication_date=2015; citation_pages=1-13; citation_id=CR14"/>

    <meta name="citation_reference" content="citation_journal_title=ETRI J; citation_title=Design evaluation system with visualization and interaction of mobile devices based on virtual reality prototypes; citation_author=DS Jo, UY Yang, WH Son; citation_volume=30; citation_issue=6; citation_publication_date=2008; citation_pages=757-764; citation_doi=10.4218/etrij.08.0108.0209; citation_id=CR15"/>

    <meta name="citation_reference" content="citation_title=The personalities of products; citation_inbook_title=Pleasure with products: beyond usability; citation_publication_date=2002; citation_pages=17-46; citation_id=CR16; citation_author=PW Jordan; citation_publisher=Taylor &amp; Francis"/>

    <meta name="citation_reference" content="citation_journal_title=Acta Univ Agric Silvicult Mendel Brun; citation_title=Usage of Microsoft Kinect for augmented prototyping speed-up; citation_author=J Landa, D Proch&#225;zka; citation_volume=60; citation_issue=2; citation_publication_date=2013; citation_pages=175-180; citation_doi=10.11118/actaun201260020175; citation_id=CR17"/>

    <meta name="citation_reference" content="citation_title=Indroducing PREMO2: new directions for the non-verbal measurement of emotion in design; citation_publication_date=2012; citation_id=CR18; citation_author=G Laurans; citation_author=P Desmet; citation_publisher=Central Saint Martins College Of Arts &amp; Design"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Adv Manuf Technol; citation_title=AR/RP-based tangible interactions for collaborative design evaluation of digital products; citation_author=JY Lee, GW Rhee, H Park; citation_volume=45; citation_issue=7&#8211;8; citation_publication_date=2009; citation_pages=649-665; citation_doi=10.1007/s00170-009-2012-0; citation_id=CR19"/>

    <meta name="citation_reference" content="citation_journal_title=CAD; citation_title=Immersive modeling system (IMMS) for personal electronic products using a multi-modal interface; citation_author=YG Lee, H Park, W Woo, J Ryu, HK Kim, SW Baik; citation_volume=42; citation_issue=5; citation_publication_date=2010; citation_pages=387-401; citation_id=CR20"/>

    <meta name="citation_reference" content="citation_journal_title=CIRP Ann Manuf Technol; citation_title=Virtual and augmented reality technologies for product realization; citation_author=SY Lu, M Shpitalni, R Gadh; citation_volume=48; citation_issue=2; citation_publication_date=1999; citation_pages=471-495; citation_doi=10.1016/S0007-8506(07)63229-6; citation_id=CR21"/>

    <meta name="citation_reference" content="Oikawa MA, de Souza Almeida I, Taketomi T, Yamamoto G, Miyazaki J, Kato H (2012) Augmented prototyping of 3D rigid curved surfaces. In: Mixed and augmented reality (ISMAR), 2012 IEEE international symposium on mixed reality 2012, pp 307&#8211;308"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Ind; citation_title=Design evaluation of information appliances using augmented reality-based tangible interaction; citation_author=H Park, HC Moon; citation_volume=64; citation_issue=7; citation_publication_date=2013; citation_pages=854-868; citation_doi=10.1016/j.compind.2013.05.006; citation_id=CR23"/>

    <meta name="citation_reference" content="citation_journal_title=J Eng Des; citation_title=Design evaluation of digital consumer products using virtual reality-based functional behaviour simulation; citation_author=H Park, JS Son, KH Lee; citation_volume=19; citation_issue=4; citation_publication_date=2008; citation_pages=359-375; citation_doi=10.1080/09544820701474129; citation_id=CR24"/>

    <meta name="citation_reference" content="citation_journal_title=Comput Ind J; citation_title=Tangible augmented prototyping of digital handheld products; citation_author=H Park, HC Moon, J Lee; citation_volume=60; citation_issue=2; citation_publication_date=2009; citation_pages=114-125; citation_doi=10.1016/j.compind.2008.09.001; citation_id=CR25"/>

    <meta name="citation_reference" content="citation_journal_title=J Adv Mech Des Syst Manuf; citation_title=Note on tangible interaction using paper models for ar-based design evaluation; citation_author=H Park, SJ Park, HK Jung; citation_volume=7; citation_issue=5; citation_publication_date=2013; citation_pages=827-835; citation_doi=10.1299/jamdsm.7.827; citation_id=CR26"/>

    <meta name="citation_reference" content="citation_journal_title=J Comput Des Eng; citation_title=Tangible AR interaction based on fingertip touch using small-sized nonsquare markers; citation_author=H Park, H-K Jung, SJ Park; citation_volume=1; citation_issue=4; citation_publication_date=2014; citation_pages=289-297; citation_id=CR27"/>

    <meta name="citation_reference" content="citation_journal_title=J Comput Des Eng; citation_title=Spatial augmented reality for product appearance design evaluation; citation_author=M Park, K Lim, M Kook Seo, S Jon; citation_volume=2; citation_publication_date=2015; citation_pages=38-46; citation_id=CR28"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=Magicmeeting: a collaborative tangible augmented reality system; citation_author=HT Regenbrecht, M Wagner, G Baratoff; citation_volume=6; citation_issue=3; citation_publication_date=2002; citation_pages=151-166; citation_doi=10.1007/s100550200016; citation_id=CR29"/>

    <meta name="citation_reference" content="citation_title=Handbook of usability testing: How to plan, design, and conduct effective tests; citation_publication_date=2008; citation_id=CR30; citation_author=J Rubin; citation_author=D Chisnell; citation_publisher=Wiley"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Interact Des Manuf; citation_title=Touch-sensitive augmented reality system for development of handheld information appliances; citation_author=H Takahashi, T Kawashima; citation_volume=4; citation_issue=1; citation_publication_date=2010; citation_pages=25-33; citation_doi=10.1007/s12008-009-0083-7; citation_id=CR31"/>

    <meta name="citation_reference" content="citation_title=Measuring the user experience: collecting, analysing, and presenting usability matrics; citation_publication_date=2013; citation_id=CR32; citation_author=T Tullis; citation_author=B Albert; citation_publisher=MK Elsevier"/>

    <meta name="citation_reference" content="citation_title=A project guide to UX design: for user experience designers in the field or in the making; citation_publication_date=2009; citation_id=CR33; citation_author=R Unger; citation_author=C Chandler; citation_publisher=New Riders"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Prod Dev; citation_title=The enablers for interactive augmented prototyping; citation_author=J Verlinden, I Horvath; citation_volume=1; citation_issue=1; citation_publication_date=2010; citation_pages=62-88; citation_doi=10.1504/IJPD.2010.032990; citation_id=CR34"/>

    <meta name="citation_reference" content="citation_journal_title=Strojniski Vestnik J Mech Eng; citation_title=Enabling interactive augmented prototyping by a portable hardware and a plug-in-based software architecture; citation_author=J Verlinden, I Horv&#225;th; citation_volume=54; citation_issue=6; citation_publication_date=2008; citation_pages=458-469; citation_id=CR35"/>

    <meta name="citation_reference" content="citation_journal_title=Artif Intell Eng Des Anal Manuf; citation_title=Analyzing opportunities for using interactive augmented prototyping in design practice; citation_author=J Verlinden, I Horv&#225;th; citation_volume=23; citation_publication_date=2009; citation_pages=289-303; citation_doi=10.1017/S0890060409000250; citation_id=CR36"/>

    <meta name="citation_reference" content="citation_journal_title=J WSCG; citation_title=Development of a flexible augmented prototyping system; citation_author=JC Verlinden, A Smit, AW Peeters; citation_volume=11; citation_issue=3; citation_publication_date=2003; citation_pages=496-503; citation_id=CR37"/>

    <meta name="citation_reference" content="Verlinden J, Horv&#225;th I, Edelenbos E (2006). Treatise of technologies for interactive augmented prototyping. In: Proceedings of tools and methods of competitive engineering (TMCE), pp 523&#8211;536"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Interact Des Manuf (IJIDeM); citation_title=Recording augmented reality experiences to capture design reviews; citation_author=J Verlinden, I Horv&#225;th, TJ Nam; citation_volume=3; citation_issue=3; citation_publication_date=2009; citation_pages=189-200; citation_doi=10.1007/s12008-009-0074-8; citation_id=CR39"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Comput Integr Manuf; citation_title=Virtual reality as a support tool in the shoe life cycle; citation_author=G Vigan&#242;, S Mottura, L Greci, M Sacco, CR Bo&#235;r; citation_volume=17; citation_issue=7; citation_publication_date=2004; citation_pages=653-660; citation_doi=10.1080/0951192042000273131; citation_id=CR40"/>

    <meta name="citation_author" content="Fernanda Gomes Faust"/>

    <meta name="citation_author_institution" content="Departamento de Engenharia de Produ&#231;&#227;o e Sistemas, Universidade Federal de Santa Catarina, Florian&#243;polis, Brazil"/>

    <meta name="citation_author" content="Tiago Catecati"/>

    <meta name="citation_author_institution" content="Departamento de Engenharia de Produ&#231;&#227;o e Sistemas, Universidade Federal de Santa Catarina, Florian&#243;polis, Brazil"/>

    <meta name="citation_author" content="Isabella de Souza Sierra"/>

    <meta name="citation_author_institution" content="Departamento de Design, Universidade do Estado de Santa Catarina, Florian&#243;polis, Brazil"/>

    <meta name="citation_author" content="Fernanda Steinbruch Araujo"/>

    <meta name="citation_author_institution" content="Departamento de Design, Universidade do Estado de Santa Catarina, Florian&#243;polis, Brazil"/>

    <meta name="citation_author" content="Alejandro Rafael Garc&#237;a Ram&#237;rez"/>

    <meta name="citation_author_institution" content="Departamento de Computa&#231;&#227;o Aplicada, Universidade do Vale do Itaja&#237;, Florian&#243;polis, Brazil"/>

    <meta name="citation_author" content="Elton Moura Nickel"/>

    <meta name="citation_author_institution" content="Departamento de Design, Universidade do Estado de Santa Catarina, Florian&#243;polis, Brazil"/>

    <meta name="citation_author" content="Marcelo Gitirana Gomes Ferreira"/>

    <meta name="citation_author_email" content="marcelo.gitirana@gmail.com"/>

    <meta name="citation_author_institution" content="Departamento de Design, Universidade do Estado de Santa Catarina, Florian&#243;polis, Brazil"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-018-0356-1&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2019/06/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-018-0356-1"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Mixed prototypes for the evaluation of usability and user experience: simulating an interactive electronic device"/>
        <meta property="og:description" content="Mixed prototyping technology can be used to represent and simulate the behavior of interactive products at low cost and with great flexibility. This preliminary experimental research intends to verify the suitability of using this technology in the evaluation of usability and user experience of interactive products. Users and experts evaluate the mixed prototype of an image projector with regard to its own usability, and also with respect to its ability to be used to evaluate usability and user experience aspects of the real projector. Users perform tasks on both the real projector and its mixed prototype. In regard to these comparative performance evaluations, time to perform the task and number of errors show a clear positive relationship with the difficulty of the task for both mixed prototype and real projector. In regard to more subjective UX evaluations, the results show to be congruent. However, we realize that emotions assigned to the mixed prototype are influenced by the “fascination” that augmented reality arises in individuals. Experts evaluate the mixed prototype with respect to aspects of the interaction with the product that it is able to simulate, and with respect to the classes of products best suited to be prototyped. They highlighted the possibility of using the technology to evaluate product performance, ergonomics, and operation. In regard to the classes of products to be prototyped, experts’ suggestions coincided with the classes of products that have already been used in research: household appliances, information and communication devices, and automotive parts and accessories."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Mixed prototypes for the evaluation of usability and user experience: simulating an interactive electronic device | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-018-0356-1","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Product prototyping, Augmented reality, Mixed prototyping, Usability, User experience","kwrd":["Product_prototyping","Augmented_reality","Mixed_prototyping","Usability","User_experience"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-018-0356-1","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-018-0356-1","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=356;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-018-0356-1">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Mixed prototypes for the evaluation of usability and user experience: simulating an interactive electronic device
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-018-0356-1.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-018-0356-1.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2018-07-13" itemprop="datePublished">13 July 2018</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Mixed prototypes for the evaluation of usability and user experience: simulating an interactive electronic device</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Fernanda_Gomes-Faust" data-author-popup="auth-Fernanda_Gomes-Faust">Fernanda Gomes Faust</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Universidade Federal de Santa Catarina" /><meta itemprop="address" content="0000 0001 2188 7235, grid.411237.2, Departamento de Engenharia de Produção e Sistemas, Universidade Federal de Santa Catarina, Campus Trindade, Florianópolis, Santa Catarina, Brazil" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Tiago-Catecati" data-author-popup="auth-Tiago-Catecati">Tiago Catecati</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Universidade Federal de Santa Catarina" /><meta itemprop="address" content="0000 0001 2188 7235, grid.411237.2, Departamento de Engenharia de Produção e Sistemas, Universidade Federal de Santa Catarina, Campus Trindade, Florianópolis, Santa Catarina, Brazil" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Isabella-Souza_Sierra" data-author-popup="auth-Isabella-Souza_Sierra">Isabella de Souza Sierra</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Universidade do Estado de Santa Catarina" /><meta itemprop="address" content="0000 0001 2150 7271, grid.412287.a, Departamento de Design, Universidade do Estado de Santa Catarina, Av. Buriti, 680, ap. 705B, Itacorubi, Florianópolis, Santa Catarina, CEP 88.034-500, Brazil" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Fernanda_Steinbruch-Araujo" data-author-popup="auth-Fernanda_Steinbruch-Araujo">Fernanda Steinbruch Araujo</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Universidade do Estado de Santa Catarina" /><meta itemprop="address" content="0000 0001 2150 7271, grid.412287.a, Departamento de Design, Universidade do Estado de Santa Catarina, Av. Buriti, 680, ap. 705B, Itacorubi, Florianópolis, Santa Catarina, CEP 88.034-500, Brazil" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Alejandro_Rafael_Garc_a-Ram_rez" data-author-popup="auth-Alejandro_Rafael_Garc_a-Ram_rez">Alejandro Rafael García Ramírez</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Universidade do Vale do Itajaí" /><meta itemprop="address" content="0000 0000 9662 6008, grid.412299.5, Departamento de Computação Aplicada, Universidade do Vale do Itajaí, Campus Itajaí, Florianópolis, Santa Catarina, Brazil" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Elton_Moura-Nickel" data-author-popup="auth-Elton_Moura-Nickel">Elton Moura Nickel</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Universidade do Estado de Santa Catarina" /><meta itemprop="address" content="0000 0001 2150 7271, grid.412287.a, Departamento de Design, Universidade do Estado de Santa Catarina, Av. Buriti, 680, ap. 705B, Itacorubi, Florianópolis, Santa Catarina, CEP 88.034-500, Brazil" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Marcelo_Gitirana-Gomes_Ferreira" data-author-popup="auth-Marcelo_Gitirana-Gomes_Ferreira" data-corresp-id="c1">Marcelo Gitirana Gomes Ferreira<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Universidade do Estado de Santa Catarina" /><meta itemprop="address" content="0000 0001 2150 7271, grid.412287.a, Departamento de Design, Universidade do Estado de Santa Catarina, Av. Buriti, 680, ap. 705B, Itacorubi, Florianópolis, Santa Catarina, CEP 88.034-500, Brazil" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 23</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">197</span>–<span itemprop="pageEnd">211</span>(<span data-test="article-publication-year">2019</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">579 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">1 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-018-0356-1/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        <ul class="c-article-events"><li class="c-article-events__item"><span>A correction to this article is available online at <a href="https://doi.org/10.1007/s10055-018-0361-4">https://doi.org/10.1007/s10055-018-0361-4</a>.</span></li></ul>
                        <ul class="c-article-events">
              <li class="c-article-events__item"><span><a href="#change-history">This article has been updated</a></span></li>
            </ul>
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Mixed prototyping technology can be used to represent and simulate the behavior of interactive products at low cost and with great flexibility. This preliminary experimental research intends to verify the suitability of using this technology in the evaluation of usability and user experience of interactive products. Users and experts evaluate the mixed prototype of an image projector with regard to its own usability, and also with respect to its ability to be used to evaluate usability and user experience aspects of the real projector. Users perform tasks on both the real projector and its mixed prototype. In regard to these comparative performance evaluations, time to perform the task and number of errors show a clear positive relationship with the difficulty of the task for both mixed prototype and real projector. In regard to more subjective UX evaluations, the results show to be congruent. However, we realize that emotions assigned to the mixed prototype are influenced by the “fascination” that augmented reality arises in individuals. Experts evaluate the mixed prototype with respect to aspects of the interaction with the product that it is able to simulate, and with respect to the classes of products best suited to be prototyped. They highlighted the possibility of using the technology to evaluate product performance, ergonomics, and operation. In regard to the classes of products to be prototyped, experts’ suggestions coincided with the classes of products that have already been used in research: household appliances, information and communication devices, and automotive parts and accessories.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Physical prototypes are built throughout the design process in order to evaluate several important aspects of the product under development: esthetics, usability, manufacturability, and so on. These evaluations are important since they subsidize and impact the decisions taken by the product development team (Viganò et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Viganò G, Mottura S, Greci L, Sacco M, Boër CR (2004) Virtual reality as a support tool in the shoe life cycle. Int J Comput Integr Manuf 17(7):653–660" href="/article/10.1007/s10055-018-0356-1#ref-CR40" id="ref-link-section-d14716e498">2004</a>). These three-dimensional prototypes also help communication and collaboration among the members of the team. However, physical prototypes (primarily functional prototypes), due to their high costs and building time, increase the costs and lead-time of the project.</p><p>In this context, designers and engineers use virtual prototypes to simulate and evaluate some technical aspects of the products, before building any physical artifact (Viganò et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Viganò G, Mottura S, Greci L, Sacco M, Boër CR (2004) Virtual reality as a support tool in the shoe life cycle. Int J Comput Integr Manuf 17(7):653–660" href="/article/10.1007/s10055-018-0356-1#ref-CR40" id="ref-link-section-d14716e504">2004</a>). As an example, they can evaluate aerodynamic performance of vehicles, aircraft, and even buildings by using computer simulation, replacing costly wind tunnels, which require a physical prototype of the product.</p><p>More recently, augmented reality (AR) technology arose with the potential to help designers and engineers evaluate several aspects of the product (Verlinden et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Verlinden J, Horváth I, Edelenbos E (2006). Treatise of technologies for interactive augmented prototyping. In: Proceedings of tools and methods of competitive engineering (TMCE), pp 523–536" href="/article/10.1007/s10055-018-0356-1#ref-CR38" id="ref-link-section-d14716e510">2006</a>). Unlike virtual reality (VR), AR technology allows the users to see the real environment where the product, or its virtual representation, is to be used. Among the innovative ways of using AR in the product development process, the creation of mixed prototypes is highlighted (Lu et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Lu SY, Shpitalni M, Gadh R (1999) Virtual and augmented reality technologies for product realization. CIRP Ann Manuf Technol 48(2):471–495" href="/article/10.1007/s10055-018-0356-1#ref-CR21" id="ref-link-section-d14716e513">1999</a>). A “mixed prototype” (MP) (Bordegoni et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Bordegoni M, Cugini U, Caruso G, Polistina S (2009) Mixed prototyping for product assessment: a reference framework. Int J Interact Des Manuf 3(3):177–187" href="/article/10.1007/s10055-018-0356-1#ref-CR5" id="ref-link-section-d14716e516">2009</a>; Ferrise et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Ferrise F, Bordegoni M, Graziosi S (2013) A method for designing users’ experience with industrial products based on a multimodal environment and mixed prototypes. Comput Aided Des Appl 10(3):461–474" href="/article/10.1007/s10055-018-0356-1#ref-CR13" id="ref-link-section-d14716e519">2013</a>)—sometimes termed as “augmented prototyping” (Bordegoni et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Bordegoni M, Cugini U, Caruso G, Polistina S (2009) Mixed prototyping for product assessment: a reference framework. Int J Interact Des Manuf 3(3):177–187" href="/article/10.1007/s10055-018-0356-1#ref-CR5" id="ref-link-section-d14716e522">2009</a>) or “interactive augmented prototyping/IAP” (Landa and Procházka <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Landa J, Procházka D (2013) Usage of Microsoft Kinect for augmented prototyping speed-up. Acta Univ Agric Silvicult Mendel Brun 60(2):175–180" href="/article/10.1007/s10055-018-0356-1#ref-CR17" id="ref-link-section-d14716e526">2013</a>; Oikawa et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Oikawa MA, de Souza Almeida I, Taketomi T, Yamamoto G, Miyazaki J, Kato H (2012) Augmented prototyping of 3D rigid curved surfaces. In: Mixed and augmented reality (ISMAR), 2012 IEEE international symposium on mixed reality 2012, pp 307–308" href="/article/10.1007/s10055-018-0356-1#ref-CR22" id="ref-link-section-d14716e529">2012</a>; Verlinden and Horvath <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Verlinden J, Horváth I (2008) Enabling interactive augmented prototyping by a portable hardware and a plug-in-based software architecture. Strojniski Vestnik J Mech Eng 54(6):458–469" href="/article/10.1007/s10055-018-0356-1#ref-CR35" id="ref-link-section-d14716e532">2008</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Verlinden J, Horváth I (2009) Analyzing opportunities for using interactive augmented prototyping in design practice. Artif Intell Eng Des Anal Manuf 23:289–303" href="/article/10.1007/s10055-018-0356-1#ref-CR36" id="ref-link-section-d14716e535">2009</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Verlinden J, Horvath I (2010) The enablers for interactive augmented prototyping. Int J Prod Dev 1(1):62–88" href="/article/10.1007/s10055-018-0356-1#ref-CR34" id="ref-link-section-d14716e538">2010</a>)—refers to a physical (tangible) model, overlaid with computer-generated 3D virtual elements (augmented reality elements). This kind of prototype enables a more realistic and inexpensive interaction than that provided by purely virtual prototypes using haptic devices (Regenbrecht et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Regenbrecht HT, Wagner M, Baratoff G (2002) Magicmeeting: a collaborative tangible augmented reality system. Virtual Real 6(3):151–166" href="/article/10.1007/s10055-018-0356-1#ref-CR29" id="ref-link-section-d14716e541">2002</a>; Lee et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lee JY, Rhee GW, Park H (2009) AR/RP-based tangible interactions for collaborative design evaluation of digital products. Int J Adv Manuf Technol 45(7–8):649–665" href="/article/10.1007/s10055-018-0356-1#ref-CR19" id="ref-link-section-d14716e545">2009</a>).</p><p>Although there is already research on the use of mixed prototyping in the evaluation of product usability, as is presented in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0356-1#Sec2">2</a>, these focus on pragmatic aspects of the man–product interaction. We did not find research that sought to evaluate this interaction both under pragmatic aspects, or usability (Rubin and Chisnell <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Rubin J, Chisnell D (2008) Handbook of usability testing: How to plan, design, and conduct effective tests, 2nd edn. Wiley, Indianapolis" href="/article/10.1007/s10055-018-0356-1#ref-CR30" id="ref-link-section-d14716e554">2008</a>), and hedonic aspects, also known as user experience (Tullis and Albert <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Tullis T, Albert B (2013) Measuring the user experience: collecting, analysing, and presenting usability matrics. MK Elsevier, London" href="/article/10.1007/s10055-018-0356-1#ref-CR32" id="ref-link-section-d14716e557">2013</a>).</p><p>Thus, this paper presents the development and the usability and user experience (UX) evaluation of a MP of an interactive electronic device: an image projector. Users and experts are invited to interact with, perform tasks on, and evaluate the MP and the product it is supposed to represent. The goal of this study was to evaluate, in a preliminary way, the suitability of MP to evaluate usability and UX of interactive products.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Related work</h2><div class="c-article-section__content" id="Sec2-content"><p>From a systematic literature review on the use of mixed prototypes (MPs) in product design, we observed that few research groups around the world are developing academic research on this theme. In the following, we describe the four main research groups that produced impactful and relevant works in the area.</p><p>In the Netherlands, Professor Jouke Verlinden (Delft University of Technology) leads a team that has researched augmented reality and mixed prototyping for over 20 years (Verlinden et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Verlinden JC, de Smit A, Peeters AW (2003) Development of a flexible augmented prototyping system. J WSCG 11(3):496–503" href="/article/10.1007/s10055-018-0356-1#ref-CR37" id="ref-link-section-d14716e575">2003</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Verlinden J, Horváth I, Nam TJ (2009) Recording augmented reality experiences to capture design reviews. Int J Interact Des Manuf (IJIDeM) 3(3):189–200" href="/article/10.1007/s10055-018-0356-1#ref-CR39" id="ref-link-section-d14716e578">2009</a>; Verlinden and Horvath <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Verlinden J, Horvath I (2010) The enablers for interactive augmented prototyping. Int J Prod Dev 1(1):62–88" href="/article/10.1007/s10055-018-0356-1#ref-CR34" id="ref-link-section-d14716e581">2010</a>). The MPs developed by his team used spatial augmented reality, i.e., images projected on white physical models (manufactured by rapid prototyping techniques). Users interact with the MP via touch screen devices (smartphones and tablets), virtual pointers, and WiiMotes™ (Verlinden and Horváth <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Verlinden J, Horváth I (2008) Enabling interactive augmented prototyping by a portable hardware and a plug-in-based software architecture. Strojniski Vestnik J Mech Eng 54(6):458–469" href="/article/10.1007/s10055-018-0356-1#ref-CR35" id="ref-link-section-d14716e584">2008</a>). Differently from this research group, we chose not to use spatial augmented reality in our experiments, since this augmented reality modality presents a great inconvenience related to the physical interaction between the user and the prototype. When approaching the physical model, the user creates a shadow that affects the overlapped image and therefore the quality of the mixed prototyping system.</p><p>Professor Park Hyungjun (Department of Industrial Engineering at Chosun University) heads mixed prototyping research in South Korea, with the involvement of researchers from other universities from that country. These researchers developed MPs of digital handheld products, such as MP3 players, handheld games, and portable media players, i.e., graspable products (Park et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Park H, Son JS, Lee KH (2008) Design evaluation of digital consumer products using virtual reality-based functional behaviour simulation. J Eng Des 19(4):359–375" href="/article/10.1007/s10055-018-0356-1#ref-CR24" id="ref-link-section-d14716e590">2008</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Park H, Moon HC, Lee J (2009) Tangible augmented prototyping of digital handheld products. Comput Ind J 60(2):114–125" href="/article/10.1007/s10055-018-0356-1#ref-CR25" id="ref-link-section-d14716e593">2009</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Park H, Park SJ, Jung HK (2013) Note on tangible interaction using paper models for ar-based design evaluation. J Adv Mech Des Syst Manuf 7(5):827–835" href="/article/10.1007/s10055-018-0356-1#ref-CR26" id="ref-link-section-d14716e596">2013</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Park H, Jung H-K, Park SJ (2014) Tangible AR interaction based on fingertip touch using small-sized nonsquare markers. J Comput Des Eng 1(4):289–297" href="/article/10.1007/s10055-018-0356-1#ref-CR27" id="ref-link-section-d14716e599">2014</a>; Lee et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lee JY, Rhee GW, Park H (2009) AR/RP-based tangible interactions for collaborative design evaluation of digital products. Int J Adv Manuf Technol 45(7–8):649–665" href="/article/10.1007/s10055-018-0356-1#ref-CR19" id="ref-link-section-d14716e602">2009</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Lee YG, Park H, Woo W, Ryu J, Kim HK, Baik SW et al (2010) Immersive modeling system (IMMS) for personal electronic products using a multi-modal interface. CAD 42(5):387–401" href="/article/10.1007/s10055-018-0356-1#ref-CR20" id="ref-link-section-d14716e606">2010</a>; Park and Moon <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Park H, Moon HC (2013) Design evaluation of information appliances using augmented reality-based tangible interaction. Comput Ind 64(7):854–868" href="/article/10.1007/s10055-018-0356-1#ref-CR23" id="ref-link-section-d14716e609">2013</a>). They build the physical models using rapid prototyping techniques. The functional behavior of the product is simulated using a finite state machine (FSM). This group discusses the importance of multimodal interfaces in the interaction with MPs, and remote collaboration between users and developers. Our experiment resembles the experiments of this research group with regard to augmented reality technology and mixed prototyping: video see-through AR. Our experiments differ, however, with respect to the evaluations carried out on these prototypes. This group emphasizes the evaluation of the functionality and appearance of electronic products.</p><p>In Italy, Monica Bordegoni and Francesco Ferrise, from the Polytechnic of Milan, are important references in the research and development of MPs. For physical interaction with users, their MPs have different types of keys (coupled to electronic interfaces), robotic arms, and linear haptic devices, i.e., actuated strips that conform to the selected curves on a shape (Bordegoni et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Bordegoni M, Cugini U, Caruso G, Polistina S (2009) Mixed prototyping for product assessment: a reference framework. Int J Interact Des Manuf 3(3):177–187" href="/article/10.1007/s10055-018-0356-1#ref-CR5" id="ref-link-section-d14716e615">2009</a>). These linear haptic devices reproduce the surface of the virtual model, allowing the user to understand, in a tactile way, the surfaces visualized through augmented reality (Bordegoni et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Bordegoni M, Ferrise F, Covarrubias M, Antolini M (2011) Geodesic spline interface for haptic curve rendering. IEEE Trans Haptics 4(2):111–121" href="/article/10.1007/s10055-018-0356-1#ref-CR6" id="ref-link-section-d14716e618">2011</a>) (Ferrise et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Ferrise F, Graziosi S, Bordegoni M (2015) Prototyping strategies for multisensory product experience engineering. J Intell Manuf 28(7):1–13" href="/article/10.1007/s10055-018-0356-1#ref-CR14" id="ref-link-section-d14716e621">2015</a>). Bordegoni and Caruso (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Bordegoni M, Caruso G (2012) Mixed reality distributed platform for collaborative design review of automotive interiors. Virtual Phys Prototyp 7(4):243–259" href="/article/10.1007/s10055-018-0356-1#ref-CR4" id="ref-link-section-d14716e624">2012</a>) present a methodology that allows the collaborative design review and modification of components of automotive interiors. Ferrise et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Ferrise F, Bordegoni M, Graziosi S (2013) A method for designing users’ experience with industrial products based on a multimodal environment and mixed prototypes. Comput Aided Des Appl 10(3):461–474" href="/article/10.1007/s10055-018-0356-1#ref-CR13" id="ref-link-section-d14716e627">2013</a>), in turn, developed a methodology, based on a multimodal interaction model (sight, touch, and sound), to analyze human interaction with consumer products from the beginning of the product development process. The research conducted at the Polytechnic of Milan is also based on video see-through AR technology and emphasizes evaluations of ergonomic aspects of home appliances, including usability (pragmatic aspects). However, unlike our experiments, such surveys do not include evaluations of hedonic aspects of the user–product interaction, that is, it does not evaluate the user experience (UX) with the products.</p><p>Once again, in Italy, Fabio Bruno and Maurizio Muzzupappa, from the University of Calabria, also research the use of mixed prototyping. Bruno et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Bruno F, Angilica A, Cosco F, Muzzupappa M (2013) Reliable behaviour simulation of product interface in mixed reality. Eng Comput 29(3):375–387" href="/article/10.1007/s10055-018-0356-1#ref-CR8" id="ref-link-section-d14716e634">2013</a>) developed an approach and architecture that uses models and software commonly used by engineers during product development (Matlab<sup>®</sup> and Simulink<sup>®</sup>) to simulate product behavior, and Virtools™ for visualizing the AR interactive environment. The architecture is used to (mix) prototype and test with a hot mixer. Barbieri et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Barbieri L, Angilica A, Bruno F (2013) Mixed prototyping with configurable physical archetype for usability evaluation of product interfaces. Comput Ind 64(3):310–323" href="/article/10.1007/s10055-018-0356-1#ref-CR3" id="ref-link-section-d14716e641">2013</a>) introduced an experimental physical archetype for mixed prototyping that allows the design of a user interface of a home appliance to be easily changed by the adoption of plug-and-play moving components (knobs and keys). They used this archetype in a comparative test between three alternative control panels of a washing machine. The experiments carried out at the University of Calabria, although focused on evaluations of product usability, still focus essentially on the pragmatic aspects of the user–product interaction, differently from our experiments that consider both the pragmatic aspects (usability) and the hedonic aspects (UX) of the user interaction product.</p><p>Other research groups have also developed mixed prototyping systems in countries such as Japan (Aoyama and Kimishima <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Aoyama H, Kimishima Y (2009) Mixed reality system for evaluating designability and operability of information appliances. Int J Interact Des Manuf 3(3):157–164" href="/article/10.1007/s10055-018-0356-1#ref-CR1" id="ref-link-section-d14716e647">2009</a>; Takahashi and Kawashima <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Takahashi H, Kawashima T (2010) Touch-sensitive augmented reality system for development of handheld information appliances. Int J Interact Des Manuf 4(1):25–33" href="/article/10.1007/s10055-018-0356-1#ref-CR31" id="ref-link-section-d14716e650">2010</a>; Park et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Park M, Lim K, Kook Seo M, Jon S (2015) Spatial augmented reality for product appearance design evaluation. J Comput Des Eng 2:38–46" href="/article/10.1007/s10055-018-0356-1#ref-CR28" id="ref-link-section-d14716e653">2015</a>), South Korea (Jo et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Jo DS, Yang UY, Son WH (2008) Design evaluation system with visualization and interaction of mobile devices based on virtual reality prototypes. ETRI J 30(6):757–764" href="/article/10.1007/s10055-018-0356-1#ref-CR15" id="ref-link-section-d14716e656">2008</a>), and the USA (Choi <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Choi YM (2015) Utilizing end user input in early product development. Procedia Manuf 3:2244–2250" href="/article/10.1007/s10055-018-0356-1#ref-CR10" id="ref-link-section-d14716e659">2015</a>).</p></div></div></section><section aria-labelledby="Sec3"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Materials and methods</h2><div class="c-article-section__content" id="Sec3-content"><h3 class="c-article__sub-heading" id="Sec4">Prototype and experimental setup</h3><p>For the experiments, we developed a mixed prototype (MP), based in the experiments of Park et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Park H, Moon HC, Lee J (2009) Tangible augmented prototyping of digital handheld products. Comput Ind J 60(2):114–125" href="/article/10.1007/s10055-018-0356-1#ref-CR25" id="ref-link-section-d14716e674">2009</a>) of a multimedia projector Epson × 14, since this is a device commonly used in academic settings. We manually sculpted the physical model in PUR, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig1">1</a>. A cavity on the model houses the physical interface (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig1">1</a>a), which contains the keys through which the user interacts with the prototype. This interface is printed in acrylonitrile butadiene styrene (ABS) using a domestic 3D printer (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig1">1</a>b) and is attached to a case containing an Arduino electronic board (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig1">1</a>c). By pressing a particular key, it activates an electronic button positioned just below it. Then, the Arduino processor reads the signal from the button and sends a keyboard command to the FLARToolKit AR software. Lastly, on a computer, the FLARToolKit simulates the actual projector behavior by determining which setup screen shall be projected.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig1_HTML.jpg" alt="figure1" loading="lazy" width="685" height="162" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Physical components of mixed prototype</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig2">2</a>a shows the MP with a fiducial marker properly positioned thereon. This marker is responsible for the correct positioning of the augmented reality on the physical model. We painted the physical model in green, in order to solve the hand occlusion problem, using Chroma key technique. In this technique, the virtual model, shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig2">2</a>b, overlaps the image captured by the webcam in a particular color range only.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig2_HTML.jpg" alt="figure2" loading="lazy" width="685" height="222" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Mixed prototype of multimedia projector Epson <b>× </b>14: physical component (<b>a</b>) and 3D virtual model (<b>b</b>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>There are several technologies available to create AR. We created AR using an LCD monitor with a web camera attached to it, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig3">3</a>a. This decision was due to the simplicity, reliability, low cost, and, above all, for being a less invasive technology, as identified by Park and Moon (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Park H, Moon HC (2013) Design evaluation of information appliances using augmented reality-based tangible interaction. Comput Ind 64(7):854–868" href="/article/10.1007/s10055-018-0356-1#ref-CR23" id="ref-link-section-d14716e749">2013</a>). In this configuration, the AR is displayed on an LCD monitor interposed between the user and the physical model of the product. The user physically interacts with this model and visualizes the MP through the monitor (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig3">3</a>b). In this figure, we can also see the result for the hand occlusion problem, using Chroma key technique. We mapped all possible user actions on the projector (inputs) to perform its configuration as well as all the images that would result from these actions (outputs). This mapping enabled the simulation of the behavior of the projector related to its configuration functions.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig3_HTML.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig3_HTML.jpg" alt="figure3" loading="lazy" width="685" height="254" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Augmented reality for the multimedia projector Epson × 14: setup (<b>a</b>) and displayed image (<b>b</b>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig4">4</a> shows the layout plan for the experiments, and also for expert evaluations, with the MP (1) placed over the table next to the image projector (2) it intended to simulate. A PC (3) and a notebook (4) processed the actions taken on the MP (configuration commands) and subsequently sent to the real projector an image to be projected on a white screen (5). Users calibrated the AR and became familiar with the technology, with a pattern of dots on an A4 sheet of paper (6). The LCD monitor used to display the MP, as explained before, is shown in (7). Two cameras (8) and (9) are used during the experiments to record actions and behaviors of the users. Three chairs (10) next to the LCD monitor are placed to accommodate moderator and observers.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig4_HTML.png?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig4_HTML.png" alt="figure4" loading="lazy" width="685" height="447" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Layout plan for the experiments with users and expert evaluations</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec5">Pretest procedures</h3><p>Prior to the beginning of the experiments, all the material (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0356-1#Sec4">3.1</a>) was pretested with three undergraduate students. We tested the data collection forms and questionnaires for their comprehension, and minor adjustments on the material and setup were made. Moderator and observers were trained on how to: start the equipment; conduct the familiarization test; and proceed when users commit errors or give up, without influencing the results (Rubin and Chisnell <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Rubin J, Chisnell D (2008) Handbook of usability testing: How to plan, design, and conduct effective tests, 2nd edn. Wiley, Indianapolis" href="/article/10.1007/s10055-018-0356-1#ref-CR30" id="ref-link-section-d14716e813">2008</a>).</p><h3 class="c-article__sub-heading" id="Sec6">Users evaluation</h3><p>Eight undergraduate students from the industrial design course of our university took part in the experiments as users’ representatives (non-experts). Tullis and Albert (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Tullis T, Albert B (2013) Measuring the user experience: collecting, analysing, and presenting usability matrics. MK Elsevier, London" href="/article/10.1007/s10055-018-0356-1#ref-CR32" id="ref-link-section-d14716e824">2013</a>) and Rubin and Chisnell (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Rubin J, Chisnell D (2008) Handbook of usability testing: How to plan, design, and conduct effective tests, 2nd edn. Wiley, Indianapolis" href="/article/10.1007/s10055-018-0356-1#ref-CR30" id="ref-link-section-d14716e827">2008</a>) argue that a sample of five to ten participants are suited for the most important system issues to be detected. According to the authors, eighty percent of the usability deficiencies of a product will be exposed by four to five participants. We chose students that were familiar with technological and interactive products, but had not had prior direct contact with the equipment to be tested—or similar—especially with regard to the tasks (configuration of an image projector).</p><p>A moderator, assisted by two observers, conducts the experiments, while encouraging the participants to “think aloud” about their thought process. The moderator contextualizes and explains the tasks, while the observers aid the users in the familiarization with technology, measure the performance time of the tasks, log errors, and write down comments.</p><p>As shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0356-1#Tab1">1</a>, we compared the user performance (task success and time on task) and users’ experience (product personality assignment and emotional response evaluation) when interacting with the image projector (real product) and with the respective MP. The MP was separately evaluated in terms of its own usability, with SUS questionnaires, and also with a questionnaire that focused on the prototype’s ability to simulate the projector in terms of visual aspects, product operation, and haptic feedback (VOF evaluation). Performance evaluations—SUS (Brooke <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Brooke J (1996) SUS-A quick and dirty usability scale. Usab Eval Ind 189(194):4–7" href="/article/10.1007/s10055-018-0356-1#ref-CR7" id="ref-link-section-d14716e839">1996</a>) and VOF evaluation—cover the three main elements of usability: effectiveness, efficiency, and (job) satisfaction. Seeking to understand the UX, we added the product personality assignment (PPA), developed by Jordan (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Jordan PW (2002) The personalities of products. In: Green WS, Jordan PW (eds) Pleasure with products: beyond usability. Taylor &amp; Francis, London, pp 17–46" href="/article/10.1007/s10055-018-0356-1#ref-CR16" id="ref-link-section-d14716e842">2002</a>), as well as an evaluation of the emotional impact on the user (ER evaluation), based on the theory developed by Desmet (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Desmet PM (2003) Measuring emotions: development and application of an instrument to measure emotional responses to products. In: Blythe MA, Overbeeke K, Monk AF, Wright PC (eds) Funology: from usability to enjoyment. Springer, Berlin, pp 111–124" href="/article/10.1007/s10055-018-0356-1#ref-CR11" id="ref-link-section-d14716e845">2003</a>).</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Evaluations and objectives</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0356-1/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>On the arrival of each user, the moderator greets the user and asks them to read and, if agreeable, to sign the informed consent form. After that, the moderator presents to the user the concept of usability (and UX) testing, stressing that the test focused on the product’s usability and not on their personal performance. The moderator explains the objective and the importance of the study. Finally, the moderator explains the test procedures and applies a screening questionnaire based on Rubin and Chisnell (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Rubin J, Chisnell D (2008) Handbook of usability testing: How to plan, design, and conduct effective tests, 2nd edn. Wiley, Indianapolis" href="/article/10.1007/s10055-018-0356-1#ref-CR30" id="ref-link-section-d14716e1221">2008</a>) and Unger and Chandler (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Unger R, Chandler C (2009) A project guide to UX design: for user experience designers in the field or in the making. New Riders, Berkeley" href="/article/10.1007/s10055-018-0356-1#ref-CR33" id="ref-link-section-d14716e1224">2009</a>) in order to verify the user’s knowledge level in relation to similar products, the frequency of use, and on how they would act in case of doubt on using the product. Along with the tests, we also describe the evaluation methods and their contribution to the research.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec7">Performance evaluation</h4><p>After the introductory procedures, the moderator leads the user to the test room where they perform the prescribed activities, using the time they deem necessary, aware that they could quit the trial at any time. Before starting the experiment with the MP, each user has about 1 min to become familiar with augmented reality technology—exploring it freely—and to calibrate the prototype (Chroma key aspects) as predicted in the study of Faust et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Faust FG, Roepke G, Catecati T, Araujo F, Gomes Ferreira MG, Albertazzi D (2012) Use of augmented reality in the usability evaluation of products. Work (Reading, Mass.) 41(1):1164–1167" href="/article/10.1007/s10055-018-0356-1#ref-CR12" id="ref-link-section-d14716e1235">2012</a>).</p><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0356-1#Tab2">2</a> presents the tasks to be performed, both with the MP and with the real projector. These tasks are divided in two versions (A and B), as suggested by Rubin and Chisnell (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Rubin J, Chisnell D (2008) Handbook of usability testing: How to plan, design, and conduct effective tests, 2nd edn. Wiley, Indianapolis" href="/article/10.1007/s10055-018-0356-1#ref-CR30" id="ref-link-section-d14716e1244">2008</a>). Each version has tasks with low, medium, and high complexity levels. The complexity of the tasks is determined by the number of steps required to complete them and also by the predicted frequency of use. This complexity was corroborated in a pretest conducted with four undergraduate students: taking into account the frequency of success and the time to complete the tasks. Half the users perform Version A tasks with the MP and Version B with the projector, while the other half perform Version B with the MP and Version A with the projector. This counterbalancing helps reduce the learning effect between the tests (Tullis and Albert <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Tullis T, Albert B (2013) Measuring the user experience: collecting, analysing, and presenting usability matrics. MK Elsevier, London" href="/article/10.1007/s10055-018-0356-1#ref-CR32" id="ref-link-section-d14716e1247">2013</a>). In each version of tasks, four users started performing with the real projector, while the other four users started with the MP.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Projector setup tasks for the experiment</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0356-1/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>During the experiments, the observers record the completion time (efficiency) and the degree of success (effectiveness) of each task. For the evaluation of user satisfaction when interacting with the MP or the real projector, the observers record the comments externalized by users. Two cameras, strategically positioned, filmed the user carrying out the requested activities to record the interaction of the user’s hands with the physical interface of the prototype or the product. All monitoring and recording of experiments was facilitated by MORAE<sup>®</sup> software, which enables audio and video recording of tasks, and the images of screens accessed by them, as shown in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig5">5</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig6">6</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig5_HTML.png?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig5_HTML.png" alt="figure5" loading="lazy" width="685" height="195" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Experiment with mixed prototype (L) and real projector (R)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig6_HTML.png?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig6_HTML.png" alt="figure6" loading="lazy" width="685" height="252" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Hand positioning, projection on the screen and user, in the AR setup</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec8">System usability scale (SUS)</h4><p>In the experiments, SUS is used to evaluate individually the usability of the prototype, without intending to compare it with the usability of the projector. This is a widely used tool to quickly evaluate the usability of products or systems, as perceived by users, due to its simplicity and reliability, even when used with small samples (Brooke <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Brooke J (1996) SUS-A quick and dirty usability scale. Usab Eval Ind 189(194):4–7" href="/article/10.1007/s10055-018-0356-1#ref-CR7" id="ref-link-section-d14716e1402">1996</a>). The SUS questionnaire consists of ten statements (positive and negative, interleaved), as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig7">7</a>, regarding the usability of the product or system as a whole. Users express their level of agreement with respect to the statements using a 5-point Likert scale.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig7_HTML.png?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig7_HTML.png" alt="figure7" loading="lazy" width="685" height="465" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>SUS questionnaires</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>From the application of SUS questionnaires, we have a score that can range from 0 to 100. A SUS score above 70 indicates an acceptable level of usability of the system or product, and a SUS score below 50 indicates an unacceptable usability (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig8">8</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig8_HTML.png?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig8_HTML.png" alt="figure8" loading="lazy" width="685" height="155" /></picture></a><p class="c-article-section__figure-credit text-right c-article-section__figure-credit-right" data-test="figure-credit">(Adapted from Bangor et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Bangor A, Kortum P, Miller J (2009) Determining what individual SUS scores mean: adding an adjective rating scale. J Usab Stud 4(3):114–123" href="/article/10.1007/s10055-018-0356-1#ref-CR2" id="ref-link-section-d14716e1445">2009</a>)</p></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Acceptability ranges for SUS scores.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec9">Visual, operation, and feedback evaluation (VOF evaluation)</h4><p>In the ensuing step, the user is asked to evaluate the MP with respect to its ability to simulate the real projector. The user evaluates the prototype with respect to 13 aspects, grouped into three categories: visual aspects, product operation, and haptic feedback, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig9">9</a>. VOF evaluation was developed by our own research group, based on the main aspects evaluated in other researches dealing with the development of MP (Park et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Park H, Son JS, Lee KH (2008) Design evaluation of digital consumer products using virtual reality-based functional behaviour simulation. J Eng Des 19(4):359–375" href="/article/10.1007/s10055-018-0356-1#ref-CR24" id="ref-link-section-d14716e1468">2008</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Park H, Moon HC, Lee J (2009) Tangible augmented prototyping of digital handheld products. Comput Ind J 60(2):114–125" href="/article/10.1007/s10055-018-0356-1#ref-CR25" id="ref-link-section-d14716e1471">2009</a>; Bordegoni et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Bordegoni M, Cugini U, Caruso G, Polistina S (2009) Mixed prototyping for product assessment: a reference framework. Int J Interact Des Manuf 3(3):177–187" href="/article/10.1007/s10055-018-0356-1#ref-CR5" id="ref-link-section-d14716e1474">2009</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Bordegoni M, Ferrise F, Covarrubias M, Antolini M (2011) Geodesic spline interface for haptic curve rendering. IEEE Trans Haptics 4(2):111–121" href="/article/10.1007/s10055-018-0356-1#ref-CR6" id="ref-link-section-d14716e1477">2011</a>; Lee et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Lee YG, Park H, Woo W, Ryu J, Kim HK, Baik SW et al (2010) Immersive modeling system (IMMS) for personal electronic products using a multi-modal interface. CAD 42(5):387–401" href="/article/10.1007/s10055-018-0356-1#ref-CR20" id="ref-link-section-d14716e1481">2010</a>; Verlinden and Horvath <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Verlinden J, Horvath I (2010) The enablers for interactive augmented prototyping. Int J Prod Dev 1(1):62–88" href="/article/10.1007/s10055-018-0356-1#ref-CR34" id="ref-link-section-d14716e1484">2010</a>; Barbieri et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Barbieri L, Angilica A, Bruno F (2013) Mixed prototyping with configurable physical archetype for usability evaluation of product interfaces. Comput Ind 64(3):310–323" href="/article/10.1007/s10055-018-0356-1#ref-CR3" id="ref-link-section-d14716e1487">2013</a>; Bruno et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Bruno F, Angilica A, Cosco F, Muzzupappa M (2013) Reliable behaviour simulation of product interface in mixed reality. Eng Comput 29(3):375–387" href="/article/10.1007/s10055-018-0356-1#ref-CR8" id="ref-link-section-d14716e1490">2013</a>; Ferrise et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Ferrise F, Bordegoni M, Graziosi S (2013) A method for designing users’ experience with industrial products based on a multimodal environment and mixed prototypes. Comput Aided Des Appl 10(3):461–474" href="/article/10.1007/s10055-018-0356-1#ref-CR13" id="ref-link-section-d14716e1493">2013</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Ferrise F, Graziosi S, Bordegoni M (2015) Prototyping strategies for multisensory product experience engineering. J Intell Manuf 28(7):1–13" href="/article/10.1007/s10055-018-0356-1#ref-CR14" id="ref-link-section-d14716e1496">2015</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig9_HTML.png?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig9_HTML.png" alt="figure9" loading="lazy" width="685" height="475" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>VOF evaluation questionnaires</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec10">Product personality assignment (PPA)</h4><p>The comparative evaluation of the user experience between the product and the MP begins with the application of the product personality assignment (PPA) questionnaire (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig10">10</a>), proposed by Jordan (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Jordan PW (2002) The personalities of products. In: Green WS, Jordan PW (eds) Pleasure with products: beyond usability. Taylor &amp; Francis, London, pp 17–46" href="/article/10.1007/s10055-018-0356-1#ref-CR16" id="ref-link-section-d14716e1528">2002</a>). After the experiments, each user evaluates the product and the MP, in relation to the 17 pairs of opposite adjectives: “product personality dimensions,” according to Jordan (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Jordan PW (2002) The personalities of products. In: Green WS, Jordan PW (eds) Pleasure with products: beyond usability. Taylor &amp; Francis, London, pp 17–46" href="/article/10.1007/s10055-018-0356-1#ref-CR16" id="ref-link-section-d14716e1531">2002</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig10_HTML.png?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig10_HTML.png" alt="figure10" loading="lazy" width="685" height="622" /></picture></a><p class="c-article-section__figure-credit text-right c-article-section__figure-credit-right" data-test="figure-credit">(Reproduce with permission from Jordan <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Jordan PW (2002) The personalities of products. In: Green WS, Jordan PW (eds) Pleasure with products: beyond usability. Taylor &amp; Francis, London, pp 17–46" href="/article/10.1007/s10055-018-0356-1#ref-CR16" id="ref-link-section-d14716e1548">2002</a>)</p></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Questionnaire for product personality assignment.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec11">Emotional response evaluation (ER evaluation)</h4><p>For the comparative evaluation of emotions that the product and its MP cause to users, we use expressive characters that represent a set of fourteen universal emotions, as proposed by Desmet (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Desmet PM (2003) Measuring emotions: development and application of an instrument to measure emotional responses to products. In: Blythe MA, Overbeeke K, Monk AF, Wright PC (eds) Funology: from usability to enjoyment. Springer, Berlin, pp 111–124" href="/article/10.1007/s10055-018-0356-1#ref-CR11" id="ref-link-section-d14716e1568">2003</a>). Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig11">11</a> shows these emotions as presented by Caicedo and Desmet (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Caicedo DG, Desmet PM (2009) Designing the new PrEmo: an empirical research on how to improve the emotion measuring tool. Delf University of Technology, Delf" href="/article/10.1007/s10055-018-0356-1#ref-CR9" id="ref-link-section-d14716e1574">2009</a>) and currently used in PrEmo<sup>®</sup> Instrument (a proprietary tool used to evaluate the user’s emotional response when interacting with a product or interface).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig11_HTML.png?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig11_HTML.png" alt="figure11" loading="lazy" width="685" height="248" /></picture></a><p class="c-article-section__figure-credit text-right c-article-section__figure-credit-right" data-test="figure-credit">(Reproduce with permission from Caicedo and Desmet <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Caicedo DG, Desmet PM (2009) Designing the new PrEmo: an empirical research on how to improve the emotion measuring tool. Delf University of Technology, Delf" href="/article/10.1007/s10055-018-0356-1#ref-CR9" id="ref-link-section-d14716e1593">2009</a>)</p></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Fourteen universal feelings.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>The expressive characters can be grouped into four emotional domains, identifying the emotions in their contexts as shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0356-1#Tab3">3</a>. These groupings sought new applications for these expressive characters beyond their use in evaluation of consumer products (Caicedo and Desmet <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Caicedo DG, Desmet PM (2009) Designing the new PrEmo: an empirical research on how to improve the emotion measuring tool. Delf University of Technology, Delf" href="/article/10.1007/s10055-018-0356-1#ref-CR9" id="ref-link-section-d14716e1611">2009</a>).</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Emotional domains for expressive characters.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0356-1/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>We use expressive characters to represent the user’s emotional response—and therefore the UX—in relation to: (a) the time taken to perform the tasks; (b) the ease of performing the tasks; and (c) the overall feeling after completing the tasks.</p><h3 class="c-article__sub-heading" id="Sec12">Experts evaluation</h3><p>Together with the experiments with users, we gather evaluations from experts in both product modeling and human factors. We invite four designers who have professional and teaching experience in industrial design (at least 5 years of experience). First the moderator introduces the layout for the experiments (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig4">4</a>) to each of these experts and talks about the context in which it had been developed. Then, he presents details of the experiments conducted with the users. They can in the sequence freely interact with the MP and the real projector, and also perform the tasks that had been requested of the users. After this experimentation stage, the experts are asked to subjectively evaluate, using a 5-point Likert scale, the adequacy of using mixed prototyping in the evaluation of the following aspects of a product under development: usability/UX (time, errors, issues, long- and short-term satisfaction), esthetics, physical and cognitive ergonomics, and function/operation. The moderator also collects from these experts suggestions for possible applications for MP technology.</p></div></div></section><section aria-labelledby="Sec13"><div class="c-article-section" id="Sec13-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec13">Results and discussion</h2><div class="c-article-section__content" id="Sec13-content"><h3 class="c-article__sub-heading" id="Sec14">Users’ evaluation</h3><p>Following the order in which the experiments and evaluations were carried out, we present and discuss the results of performance evaluations with users.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec15">Performance evaluation</h4><p>We used as metrics for comparative performance evaluation (actual projector versus mixed prototype): the number of users who correctly performed the tasks, those who failed, and those who gave up, as well as the time required to perform these tasks, as detailed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0356-1#Sec5">3.2</a>. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0356-1#Tab4">4</a> presents the results of the experiments in terms of the time (in seconds) it took to complete the task and the level of success (completed, fail, and withdrawal). Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig12">12</a> illustrates the results of Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0356-1#Tab4">4</a>, identifying each user.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 Representation of performance data for task accomplishment (users) for mixed reality prototype and real projector</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0356-1/tables/4"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig12_HTML.png?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig12_HTML.png" alt="figure12" loading="lazy" width="685" height="684" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Graphic representation of performance data for task accomplishment (users) for mixed reality prototype and real projector</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Initially, we can observe that for those tasks considered easy, all users were able to carry them out successfully. Errors and withdrawals began to appear in the medium- and high-difficulty tasks. Nevertheless, one cannot relate these errors and withdrawals to the use of the mixed prototype (MP). In tasks regarded as difficult, there was even a higher amount of successes in the use of MP compared to the use of the real projector. In addition, we observed only one withdrawal of all tasks with the MP and three withdrawals with the real projector.</p><p>From the results, and taking into account the impact of the small sample, we cannot state categorically that there is a significant difference between the time required to perform the tasks with the MP and with the actual product. We can observe, however, that there is some proportionality between the time required to accomplish the tasks and their respective level of difficulty. We also noticed that the number of errors and withdrawals tended to increase with the increase in the level of difficulty of the tasks. All this is consistent with the belief that the mixed prototyping technology can be used to assess improvements in developing interfaces, since the degree of difficulty encountered by the user in using the interface tended to be proportional to the time in carrying out the tasks as well as the number of errors and withdrawals.</p><p>Withdrawals and errors in the more difficult tasks were controversial. For the most part, when starting with the prototype, participants did not withdraw from the tasks; they actually exceeded the time spent trying to finish the activity. This can be because of the novelty of the technology or the participant’s profile.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec16">System usability scale (SUS)</h4><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0356-1#Tab5">5</a> presents the answers to SUS questionnaires given by the eight users who interacted with the MP. The table also presents the SUS score for each of the eight users, as well as the corresponding adjective rating, according to the scale shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig8">8</a>. It also displays the total time spent by users to perform the three tasks with MP. Lastly, it presents the averages and standard deviations of the values assigned by the eight members for each of the ten questions of SUS.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 SUS rates and scores for mixed reality prototype</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0356-1/tables/5"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Analyzing Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0356-1#Tab5">5</a>, we do not perceive a clear opinion from users about the usability of the developed MP. Three out of eight users assigned good or excellent usability; two users assigned regular usability; and three users assigned poor or very poor usability. We can see, however, some relationship between the total time to perform the three tasks with the prototype and the usability assigned to it. With the exception of user 3, individuals who took longer to complete the tasks tended to negatively evaluate the usability of the MP. Among the SUS questions, we highlight negatively the (positive) statement “I think the system was easy to use,” averaging 2.50; and also the statement, “I need to learn a lot of things before I could get going with this system,” averaging 2.75.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec17">Visual, operation, and feedback evaluation (VOF evaluation)</h4><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig13">13</a> presents the results of the posttest evaluation of the MP with respect to visual aspects, product operation, and haptic feedback, as described earlier.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-13"><figure><figcaption><b id="Fig13" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 13</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/13" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig13_HTML.png?as=webp"></source><img aria-describedby="figure-13-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig13_HTML.png" alt="figure13" loading="lazy" width="685" height="410" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-13-desc"><p>Results for visual, operation, and feedback evaluation for mixed reality prototype</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/13" data-track-dest="link:Figure13 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>The overall evaluation of the MP was positive (median equal to or greater than 4.0) for 8 out of 13 (61.5%) evaluated aspects. With respect to the visual aspects, although well evaluated for the realism of the image generated by AR and the legibility of the information, the prototype was not so well evaluated (median 3.5) for the legibility (ease of identification) of the keys and for the visual comfort in its use. The visual comfort may be affected by certain instability in the generation of AR. Factors such as ambient brightness and user’s skin color affected the quality of the image shown in the AR display. Also, the need for the user to look at two screens—one nearby, showing the AR, and another distant, showing the projection—may have negatively affected visual comfort. Regarding the aspects related to the simulation of product operation, users positively evaluated the ease of understanding the operation, the simulation of the configuration interface, and the ease of use of the prototype (medians 4.0). The ease of access to the prototype was the worst evaluated aspect (median 3.0), due to the physical configuration of the experiment that placed the display between the user and the physical model (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig3">3</a>). Also, not so well evaluated was the simulation of the communication interface (median 3.5). Lastly, with regard to aspects of haptic feedback, users evaluated positively (median 4.0) the simulation of the shape of the product and the representation of the size and the layout of the keys. Not as well evaluated was the click of the keys (median 3.5), possibly due to the response time (accelerated) of the electronic circuit on which these keys were mounted. Each key should be clicked crisply (i.e., tapped, but not held or pressed down) in order to prevent the related action to be repeated two or more times.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec18">Product personality assignment (PPA)</h4><p>The comparative analysis between the product personality and the MP personality, using the product personality dimensions of Jordan (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Jordan PW (2002) The personalities of products. In: Green WS, Jordan PW (eds) Pleasure with products: beyond usability. Taylor &amp; Francis, London, pp 17–46" href="/article/10.1007/s10055-018-0356-1#ref-CR16" id="ref-link-section-d14716e1987">2002</a>), showed congruence with the perceptions of the users in most pairs of opposite adjectives (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig14">14</a>). In 76.5% of the pairs of adjectives, the difference between the medians was less than or equal to 1 point. This congruence testifies to the potential of the MP to represent the product in relation to its personality. The largest difference occurred in the stable–unstable adjectives. The instability attributed to the MP might at first be related to the instability of the implemented AR, since whenever the user’s hand unintentionally hid the fiducial marker, the projector image disappeared from the screen. The analysis also drew attention to the fact that users considered the prototype inflexible, since this is one of the main arguments used in favor of mixed prototyping over traditional prototyping technologies (Barbieri et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Barbieri L, Angilica A, Bruno F (2013) Mixed prototyping with configurable physical archetype for usability evaluation of product interfaces. Comput Ind 64(3):310–323" href="/article/10.1007/s10055-018-0356-1#ref-CR3" id="ref-link-section-d14716e1993">2013</a>). Finally, the MP was considered simpler than the product, possibly because of the limited number of functionalities that were implemented, i.e., those related to the product configuration.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-14"><figure><figcaption><b id="Fig14" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 14</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/14" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig14_HTML.png?as=webp"></source><img aria-describedby="figure-14-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig14_HTML.png" alt="figure14" loading="lazy" width="685" height="593" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-14-desc"><p>Personality dimensions analysis for mixed reality prototype and real projector, according to Jordan (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Jordan PW (2002) The personalities of products. In: Green WS, Jordan PW (eds) Pleasure with products: beyond usability. Taylor &amp; Francis, London, pp 17–46" href="/article/10.1007/s10055-018-0356-1#ref-CR16" id="ref-link-section-d14716e2006">2002</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/14" data-track-dest="link:Figure14 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec19">Emotional response evaluation (ER evaluation)</h4><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig15">15</a> shows the results of applying ER evaluations to the users, regarding their emotional response in relation to: (a) the time taken to perform the tasks; (b) the ease in performing the tasks; and (c) the user’s overall feeling after completing the tasks.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-15"><figure><figcaption><b id="Fig15" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 15</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/15" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig15_HTML.png?as=webp"></source><img aria-describedby="figure-15-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig15_HTML.png" alt="figure15" loading="lazy" width="685" height="716" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-15-desc"><p>Expressive characters selected in emotional response evaluations for mixed reality prototype and real projector</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/15" data-track-dest="link:Figure15 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>In general, we notice that users reported more positive emotions than negative emotions, both for the product (in blue) and for the MP (in red). We may observe that one of the emotions that stood out in the users’ interaction with the MP was “fascination.” Just as an example, fascination was the selected emotion by three users regarding the “time taken to perform the tasks.” This fascination can be associated with the users’ own familiarity with AR technology, hitherto unknown by most of the users who took part in the experiments. Next, the emotion “admiration” appeared as one of the most selected with regard to the “ease of use” aspect. This admiration may reflect the contrast between the expected difficulty before using the AR technology and the difficulty actually found to use it. “Pride” is the emotion felt by most users after performing the task both with the MP and with the product. This is a natural feeling of individuals after performing a task successfully (or supposed success). Some users also reported “satisfaction” after completing the tasks with the product. In fact, the emotion “satisfaction” stood out in all the three evaluated aspects. This satisfaction reflects the good usability and UX offered by real projector.</p><h3 class="c-article__sub-heading" id="Sec20">Experts evaluation</h3><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-018-0356-1#Fig16">16</a> shows the median of the evaluations of the four experts that were invited to assess the MP with respect to its ability to represent and simulate the aspects of usability/UX, esthetics, ergonomics, and function/operation.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-16"><figure><figcaption><b id="Fig16" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 16</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/16" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig16_HTML.png?as=webp"></source><img aria-describedby="figure-16-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_Fig16_HTML.png" alt="figure16" loading="lazy" width="685" height="237" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-16-desc"><p>Median of evaluations from four experts for mixed reality prototype</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-018-0356-1/figures/16" data-track-dest="link:Figure16 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>In general, the experts evaluated the above-mentioned aspects positively: medians higher or equal to 3. They assessed the possibility of evaluating the performance aspects of usability (time and errors), particularly positively (medians 4.5). The possibility of evaluating esthetic aspects (median 3) and long-term satisfaction (median 3.5) were the worst evaluated aspects, these latter aspects more related to the user experience. Experts also evaluated positively (medians 4) the possibility of using the MP to discover problems in the product and to assess the short-term satisfaction in performing tasks (aspects related to the usability of the product); assess physical and cognitive ergonomics of the product; and simulate its operation or functionality.</p><p>Regarding the potential for application of mixed prototyping, the experts agreed that this technology could be used in prototyping household appliances (e.g., refrigerators, washing machines, dryers, and microwave ovens), information and communications devices (e.g., phones and smartphones), and in the automotive industry. Some experts have also mentioned electronic games and toys as possible products that could be prototyped with this technology. We can see that the classes of products mentioned by the experts include the products that, in fact, were prototyped in previously reviewed research, as shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-018-0356-1#Tab6">6</a>.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-6"><figure><figcaption class="c-article-table__figcaption"><b id="Tab6" data-test="table-caption">Table 6 Prototyped products in reviewed researches</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-018-0356-1/tables/6"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div></div></div></section><section aria-labelledby="Sec21"><div class="c-article-section" id="Sec21-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec21">Conclusion</h2><div class="c-article-section__content" id="Sec21-content"><p>This paper presented the development of a mixed prototype (MP) of an interactive electronic device and its evaluation by users and experts. Users assessed objective aspects of the MP, related to its performance and usability, and also subjective aspects, related to satisfaction and UX.</p><p>In regard to comparative performance evaluations (time to complete the tasks and number of errors), we cannot say that the MP is able to properly reproduce the results obtained with the product. Nevertheless, and more importantly, we can see that the time to perform the task and the number of errors show a clear positive relationship with the intrinsic difficulty of the task. Considering this difficulty is positively associated with the number of clicks required to complete the task which is negatively associated with its frequency of use. In this way, we can infer that mixed prototyping can be useful to monitor the evolution of usability of an interactive product under development, in terms of performance.</p><p>Still with regard to comparative evaluations, but those more subjective related to the user experience, the results for the projector and the prototype, using PPA and ER evaluation tools, showed to be congruent. In PPA tool, ¾ of the pairs of adjectives had differences between medians 0 or 1. In ER evaluation, positive emotions stood out both for the product (87.5%) and for its MP (83.3%), in the three evaluated aspects (time to complete the task; ease of use; and feeling after performing the task). However, when we analyze the emotions individually, we realize that emotions assigned to the MP were influenced by the “fascination” that AR technology arouses in individuals. We expect that with the more frequent use of mixed prototyping in design environments, emotions pointed at real products and their respective MP will become even closer.</p><p>Individually, using the VOF tool, the MP was positively evaluated: median equal to or greater than 4.0 for more than 60% of the aspects that were evaluated. Physical access to the keys of the prototype was the main negative, which is a question difficult to solve in this MP, as implemented. Regarding SUS evaluation of MP, the results were not conclusive. However, we perceived a certain (negative) relationship between time spent performing the tasks (i.e., difficulty in using the technology) and SUS score. This may indicate that this technology may be more suitable for slightly more technologically oriented users.</p><p>The experts considered the MP able to represent and simulate the product under various aspects. They highlighted the possibility of using mixed prototyping in the evaluation of product performance, physical and cognitive ergonomics, and product operation. Referring to the product classes for which mixed prototyping could be used, the experts’ suggestions coincided with the classes of products that have already been used in research and development in MP.</p><p>The preliminary results presented in this paper are in line with the results previously found by the research groups reviewed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-018-0356-1#Sec2">2</a> (Related Work). Our results reinforce the suitability of mixed prototypes (video see-through technology) for product evaluations, as presented by researchers from South Korea (Chosun University), particularly in ergonomic and usability aspects, as shown by researchers from the Polytechnic of Milan and from the University of Calabria, respectively. However, our results went a step further by pointing to the suitability of this technology for more subjective (or hedonic) aspects of the user–product interaction, i.e., for the user experience (UX).</p><p>From the results presented in this paper, we are evolving our research in the following directions: use of more immersive, and less intrusive, AR technologies; and exclusion of electronic components in the interaction of the user with the prototype (hand-tracking devices and gloves with contact sensors), providing greater flexibility for the reconfiguration of the interface; physically modeling only the region where the user actually interacts with the product interface, i.e., with the region where the controls are located.</p></div></div></section>
                        
                    

                    <section aria-labelledby="change-history"><div class="c-article-section" id="change-history-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="change-history">Change history</h2><div class="c-article-section__content" id="change-history-content"><ul class="c-article-change-list"><li class="c-article-change-list__item" id="chg1"><ins datetime="2018-07-30"><h3 class="c-article-change-list__heading u-h3">30 July 2018</h3><div class="c-article-change-list__details"><p>In the original publication of the article, the following corrections have to be noted down.</p></div></ins></li></ul></div></div></section><section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Aoyama, Y. Kimishima, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Aoyama H, Kimishima Y (2009) Mixed reality system for evaluating designability and operability of information " /><p class="c-article-references__text" id="ref-CR1">Aoyama H, Kimishima Y (2009) Mixed reality system for evaluating designability and operability of information appliances. Int J Interact Des Manuf 3(3):157–164</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs12008-009-0070-z" aria-label="View reference 1">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Mixed%20reality%20system%20for%20evaluating%20designability%20and%20operability%20of%20information%20appliances&amp;journal=Int%20J%20Interact%20Des%20Manuf&amp;volume=3&amp;issue=3&amp;pages=157-164&amp;publication_year=2009&amp;author=Aoyama%2CH&amp;author=Kimishima%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Bangor, P. Kortum, J. Miller, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Bangor A, Kortum P, Miller J (2009) Determining what individual SUS scores mean: adding an adjective rating sc" /><p class="c-article-references__text" id="ref-CR2">Bangor A, Kortum P, Miller J (2009) Determining what individual SUS scores mean: adding an adjective rating scale. J Usab Stud 4(3):114–123</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Determining%20what%20individual%20SUS%20scores%20mean%3A%20adding%20an%20adjective%20rating%20scale&amp;journal=J%20Usab%20Stud&amp;volume=4&amp;issue=3&amp;pages=114-123&amp;publication_year=2009&amp;author=Bangor%2CA&amp;author=Kortum%2CP&amp;author=Miller%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Barbieri, A. Angilica, F. Bruno, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Barbieri L, Angilica A, Bruno F (2013) Mixed prototyping with configurable physical archetype for usability ev" /><p class="c-article-references__text" id="ref-CR3">Barbieri L, Angilica A, Bruno F (2013) Mixed prototyping with configurable physical archetype for usability evaluation of product interfaces. Comput Ind 64(3):310–323</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.compind.2012.11.010" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Mixed%20prototyping%20with%20configurable%20physical%20archetype%20for%20usability%20evaluation%20of%20product%20interfaces&amp;journal=Comput%20Ind&amp;volume=64&amp;issue=3&amp;pages=310-323&amp;publication_year=2013&amp;author=Barbieri%2CL&amp;author=Angilica%2CA&amp;author=Bruno%2CF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Bordegoni, G. Caruso, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Bordegoni M, Caruso G (2012) Mixed reality distributed platform for collaborative design review of automotive " /><p class="c-article-references__text" id="ref-CR4">Bordegoni M, Caruso G (2012) Mixed reality distributed platform for collaborative design review of automotive interiors. Virtual Phys Prototyp 7(4):243–259</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F17452759.2012.721605" aria-label="View reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Mixed%20reality%20distributed%20platform%20for%20collaborative%20design%20review%20of%20automotive%20interiors&amp;journal=Virtual%20Phys%20Prototyp&amp;volume=7&amp;issue=4&amp;pages=243-259&amp;publication_year=2012&amp;author=Bordegoni%2CM&amp;author=Caruso%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Bordegoni, U. Cugini, G. Caruso, S. Polistina, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Bordegoni M, Cugini U, Caruso G, Polistina S (2009) Mixed prototyping for product assessment: a reference fram" /><p class="c-article-references__text" id="ref-CR5">Bordegoni M, Cugini U, Caruso G, Polistina S (2009) Mixed prototyping for product assessment: a reference framework. Int J Interact Des Manuf 3(3):177–187</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs12008-009-0073-9" aria-label="View reference 5">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Mixed%20prototyping%20for%20product%20assessment%3A%20a%20reference%20framework&amp;journal=Int%20J%20Interact%20Des%20Manuf&amp;volume=3&amp;issue=3&amp;pages=177-187&amp;publication_year=2009&amp;author=Bordegoni%2CM&amp;author=Cugini%2CU&amp;author=Caruso%2CG&amp;author=Polistina%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Bordegoni, F. Ferrise, M. Covarrubias, M. Antolini, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Bordegoni M, Ferrise F, Covarrubias M, Antolini M (2011) Geodesic spline interface for haptic curve rendering." /><p class="c-article-references__text" id="ref-CR6">Bordegoni M, Ferrise F, Covarrubias M, Antolini M (2011) Geodesic spline interface for haptic curve rendering. IEEE Trans Haptics 4(2):111–121</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTOH.2011.1" aria-label="View reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Geodesic%20spline%20interface%20for%20haptic%20curve%20rendering&amp;journal=IEEE%20Trans%20Haptics&amp;volume=4&amp;issue=2&amp;pages=111-121&amp;publication_year=2011&amp;author=Bordegoni%2CM&amp;author=Ferrise%2CF&amp;author=Covarrubias%2CM&amp;author=Antolini%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Brooke, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Brooke J (1996) SUS-A quick and dirty usability scale. Usab Eval Ind 189(194):4–7" /><p class="c-article-references__text" id="ref-CR7">Brooke J (1996) SUS-A quick and dirty usability scale. Usab Eval Ind 189(194):4–7</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=SUS-A%20quick%20and%20dirty%20usability%20scale&amp;journal=Usab%20Eval%20Ind&amp;volume=189&amp;issue=194&amp;pages=4-7&amp;publication_year=1996&amp;author=Brooke%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="F. Bruno, A. Angilica, F. Cosco, M. Muzzupappa, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Bruno F, Angilica A, Cosco F, Muzzupappa M (2013) Reliable behaviour simulation of product interface in mixed " /><p class="c-article-references__text" id="ref-CR8">Bruno F, Angilica A, Cosco F, Muzzupappa M (2013) Reliable behaviour simulation of product interface in mixed reality. Eng Comput 29(3):375–387</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs00366-012-0293-7" aria-label="View reference 8">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Reliable%20behaviour%20simulation%20of%20product%20interface%20in%20mixed%20reality&amp;journal=Eng%20Comput&amp;volume=29&amp;issue=3&amp;pages=375-387&amp;publication_year=2013&amp;author=Bruno%2CF&amp;author=Angilica%2CA&amp;author=Cosco%2CF&amp;author=Muzzupappa%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="DG. Caicedo, PM. Desmet, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Caicedo DG, Desmet PM (2009) Designing the new PrEmo: an empirical research on how to improve the emotion meas" /><p class="c-article-references__text" id="ref-CR9">Caicedo DG, Desmet PM (2009) Designing the new PrEmo: an empirical research on how to improve the emotion measuring tool. Delf University of Technology, Delf</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Designing%20the%20new%20PrEmo%3A%20an%20empirical%20research%20on%20how%20to%20improve%20the%20emotion%20measuring%20tool&amp;publication_year=2009&amp;author=Caicedo%2CDG&amp;author=Desmet%2CPM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="YM. Choi, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Choi YM (2015) Utilizing end user input in early product development. Procedia Manuf 3:2244–2250" /><p class="c-article-references__text" id="ref-CR10">Choi YM (2015) Utilizing end user input in early product development. Procedia Manuf 3:2244–2250</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.promfg.2015.07.368" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Utilizing%20end%20user%20input%20in%20early%20product%20development&amp;journal=Procedia%20Manuf&amp;volume=3&amp;pages=2244-2250&amp;publication_year=2015&amp;author=Choi%2CYM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="PM. Desmet, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Desmet PM (2003) Measuring emotions: development and application of an instrument to measure emotional respons" /><p class="c-article-references__text" id="ref-CR11">Desmet PM (2003) Measuring emotions: development and application of an instrument to measure emotional responses to products. In: Blythe MA, Overbeeke K, Monk AF, Wright PC (eds) Funology: from usability to enjoyment. Springer, Berlin, pp 111–124</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Funology%3A%20from%20usability%20to%20enjoyment&amp;pages=111-124&amp;publication_year=2003&amp;author=Desmet%2CPM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="FG. Faust, G. Roepke, T. Catecati, F. Araujo, MG. Gomes Ferreira, D. Albertazzi, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Faust FG, Roepke G, Catecati T, Araujo F, Gomes Ferreira MG, Albertazzi D (2012) Use of augmented reality in t" /><p class="c-article-references__text" id="ref-CR12">Faust FG, Roepke G, Catecati T, Araujo F, Gomes Ferreira MG, Albertazzi D (2012) Use of augmented reality in the usability evaluation of products. Work (Reading, Mass.) 41(1):1164–1167</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Use%20of%20augmented%20reality%20in%20the%20usability%20evaluation%20of%20products&amp;journal=Work%20%28Reading%2C%20Mass.%29&amp;volume=41&amp;issue=1&amp;pages=1164-1167&amp;publication_year=2012&amp;author=Faust%2CFG&amp;author=Roepke%2CG&amp;author=Catecati%2CT&amp;author=Araujo%2CF&amp;author=Gomes%20Ferreira%2CMG&amp;author=Albertazzi%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="F. Ferrise, M. Bordegoni, S. Graziosi, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Ferrise F, Bordegoni M, Graziosi S (2013) A method for designing users’ experience with industrial products ba" /><p class="c-article-references__text" id="ref-CR13">Ferrise F, Bordegoni M, Graziosi S (2013) A method for designing users’ experience with industrial products based on a multimodal environment and mixed prototypes. Comput Aided Des Appl 10(3):461–474</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.3722%2Fcadaps.2013.461-474" aria-label="View reference 13">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20method%20for%20designing%20users%E2%80%99%20experience%20with%20industrial%20products%20based%20on%20a%20multimodal%20environment%20and%20mixed%20prototypes&amp;journal=Comput%20Aided%20Des%20Appl&amp;volume=10&amp;issue=3&amp;pages=461-474&amp;publication_year=2013&amp;author=Ferrise%2CF&amp;author=Bordegoni%2CM&amp;author=Graziosi%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="F. Ferrise, S. Graziosi, M. Bordegoni, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Ferrise F, Graziosi S, Bordegoni M (2015) Prototyping strategies for multisensory product experience engineeri" /><p class="c-article-references__text" id="ref-CR14">Ferrise F, Graziosi S, Bordegoni M (2015) Prototyping strategies for multisensory product experience engineering. J Intell Manuf 28(7):1–13</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Prototyping%20strategies%20for%20multisensory%20product%20experience%20engineering&amp;journal=J%20Intell%20Manuf&amp;volume=28&amp;issue=7&amp;pages=1-13&amp;publication_year=2015&amp;author=Ferrise%2CF&amp;author=Graziosi%2CS&amp;author=Bordegoni%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DS. Jo, UY. Yang, WH. Son, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Jo DS, Yang UY, Son WH (2008) Design evaluation system with visualization and interaction of mobile devices ba" /><p class="c-article-references__text" id="ref-CR15">Jo DS, Yang UY, Son WH (2008) Design evaluation system with visualization and interaction of mobile devices based on virtual reality prototypes. ETRI J 30(6):757–764</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.4218%2Fetrij.08.0108.0209" aria-label="View reference 15">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Design%20evaluation%20system%20with%20visualization%20and%20interaction%20of%20mobile%20devices%20based%20on%20virtual%20reality%20prototypes&amp;journal=ETRI%20J&amp;volume=30&amp;issue=6&amp;pages=757-764&amp;publication_year=2008&amp;author=Jo%2CDS&amp;author=Yang%2CUY&amp;author=Son%2CWH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="PW. Jordan, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Jordan PW (2002) The personalities of products. In: Green WS, Jordan PW (eds) Pleasure with products: beyond u" /><p class="c-article-references__text" id="ref-CR16">Jordan PW (2002) The personalities of products. In: Green WS, Jordan PW (eds) Pleasure with products: beyond usability. Taylor &amp; Francis, London, pp 17–46</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Pleasure%20with%20products%3A%20beyond%20usability&amp;pages=17-46&amp;publication_year=2002&amp;author=Jordan%2CPW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Landa, D. Procházka, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Landa J, Procházka D (2013) Usage of Microsoft Kinect for augmented prototyping speed-up. Acta Univ Agric Silv" /><p class="c-article-references__text" id="ref-CR17">Landa J, Procházka D (2013) Usage of Microsoft Kinect for augmented prototyping speed-up. Acta Univ Agric Silvicult Mendel Brun 60(2):175–180</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.11118%2Factaun201260020175" aria-label="View reference 17">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Usage%20of%20Microsoft%20Kinect%20for%20augmented%20prototyping%20speed-up&amp;journal=Acta%20Univ%20Agric%20Silvicult%20Mendel%20Brun&amp;volume=60&amp;issue=2&amp;pages=175-180&amp;publication_year=2013&amp;author=Landa%2CJ&amp;author=Proch%C3%A1zka%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="G. Laurans, P. Desmet, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Laurans G, Desmet P (2012) Indroducing PREMO2: new directions for the non-verbal measurement of emotion in des" /><p class="c-article-references__text" id="ref-CR18">Laurans G, Desmet P (2012) Indroducing PREMO2: new directions for the non-verbal measurement of emotion in design. Central Saint Martins College Of Arts &amp; Design, London, p 13</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Indroducing%20PREMO2%3A%20new%20directions%20for%20the%20non-verbal%20measurement%20of%20emotion%20in%20design&amp;publication_year=2012&amp;author=Laurans%2CG&amp;author=Desmet%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JY. Lee, GW. Rhee, H. Park, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Lee JY, Rhee GW, Park H (2009) AR/RP-based tangible interactions for collaborative design evaluation of digita" /><p class="c-article-references__text" id="ref-CR19">Lee JY, Rhee GW, Park H (2009) AR/RP-based tangible interactions for collaborative design evaluation of digital products. Int J Adv Manuf Technol 45(7–8):649–665</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs00170-009-2012-0" aria-label="View reference 19">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=AR%2FRP-based%20tangible%20interactions%20for%20collaborative%20design%20evaluation%20of%20digital%20products&amp;journal=Int%20J%20Adv%20Manuf%20Technol&amp;volume=45&amp;issue=7%E2%80%938&amp;pages=649-665&amp;publication_year=2009&amp;author=Lee%2CJY&amp;author=Rhee%2CGW&amp;author=Park%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="YG. Lee, H. Park, W. Woo, J. Ryu, HK. Kim, SW. Baik, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Lee YG, Park H, Woo W, Ryu J, Kim HK, Baik SW et al (2010) Immersive modeling system (IMMS) for personal elect" /><p class="c-article-references__text" id="ref-CR20">Lee YG, Park H, Woo W, Ryu J, Kim HK, Baik SW et al (2010) Immersive modeling system (IMMS) for personal electronic products using a multi-modal interface. CAD 42(5):387–401</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Immersive%20modeling%20system%20%28IMMS%29%20for%20personal%20electronic%20products%20using%20a%20multi-modal%20interface&amp;journal=CAD&amp;volume=42&amp;issue=5&amp;pages=387-401&amp;publication_year=2010&amp;author=Lee%2CYG&amp;author=Park%2CH&amp;author=Woo%2CW&amp;author=Ryu%2CJ&amp;author=Kim%2CHK&amp;author=Baik%2CSW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SY. Lu, M. Shpitalni, R. Gadh, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Lu SY, Shpitalni M, Gadh R (1999) Virtual and augmented reality technologies for product realization. CIRP Ann" /><p class="c-article-references__text" id="ref-CR21">Lu SY, Shpitalni M, Gadh R (1999) Virtual and augmented reality technologies for product realization. CIRP Ann Manuf Technol 48(2):471–495</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0007-8506%2807%2963229-6" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20and%20augmented%20reality%20technologies%20for%20product%20realization&amp;journal=CIRP%20Ann%20Manuf%20Technol&amp;volume=48&amp;issue=2&amp;pages=471-495&amp;publication_year=1999&amp;author=Lu%2CSY&amp;author=Shpitalni%2CM&amp;author=Gadh%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Oikawa MA, de Souza Almeida I, Taketomi T, Yamamoto G, Miyazaki J, Kato H (2012) Augmented prototyping of 3D r" /><p class="c-article-references__text" id="ref-CR22">Oikawa MA, de Souza Almeida I, Taketomi T, Yamamoto G, Miyazaki J, Kato H (2012) Augmented prototyping of 3D rigid curved surfaces. In: Mixed and augmented reality (ISMAR), 2012 IEEE international symposium on mixed reality 2012, pp 307–308</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Park, HC. Moon, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Park H, Moon HC (2013) Design evaluation of information appliances using augmented reality-based tangible inte" /><p class="c-article-references__text" id="ref-CR23">Park H, Moon HC (2013) Design evaluation of information appliances using augmented reality-based tangible interaction. Comput Ind 64(7):854–868</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.compind.2013.05.006" aria-label="View reference 23">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Design%20evaluation%20of%20information%20appliances%20using%20augmented%20reality-based%20tangible%20interaction&amp;journal=Comput%20Ind&amp;volume=64&amp;issue=7&amp;pages=854-868&amp;publication_year=2013&amp;author=Park%2CH&amp;author=Moon%2CHC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Park, JS. Son, KH. Lee, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Park H, Son JS, Lee KH (2008) Design evaluation of digital consumer products using virtual reality-based funct" /><p class="c-article-references__text" id="ref-CR24">Park H, Son JS, Lee KH (2008) Design evaluation of digital consumer products using virtual reality-based functional behaviour simulation. J Eng Des 19(4):359–375</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F09544820701474129" aria-label="View reference 24">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Design%20evaluation%20of%20digital%20consumer%20products%20using%20virtual%20reality-based%20functional%20behaviour%20simulation&amp;journal=J%20Eng%20Des&amp;volume=19&amp;issue=4&amp;pages=359-375&amp;publication_year=2008&amp;author=Park%2CH&amp;author=Son%2CJS&amp;author=Lee%2CKH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Park, HC. Moon, J. Lee, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Park H, Moon HC, Lee J (2009) Tangible augmented prototyping of digital handheld products. Comput Ind J 60(2):" /><p class="c-article-references__text" id="ref-CR25">Park H, Moon HC, Lee J (2009) Tangible augmented prototyping of digital handheld products. Comput Ind J 60(2):114–125</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.compind.2008.09.001" aria-label="View reference 25">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Tangible%20augmented%20prototyping%20of%20digital%20handheld%20products&amp;journal=Comput%20Ind%20J&amp;volume=60&amp;issue=2&amp;pages=114-125&amp;publication_year=2009&amp;author=Park%2CH&amp;author=Moon%2CHC&amp;author=Lee%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Park, SJ. Park, HK. Jung, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Park H, Park SJ, Jung HK (2013) Note on tangible interaction using paper models for ar-based design evaluation" /><p class="c-article-references__text" id="ref-CR26">Park H, Park SJ, Jung HK (2013) Note on tangible interaction using paper models for ar-based design evaluation. J Adv Mech Des Syst Manuf 7(5):827–835</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1299%2Fjamdsm.7.827" aria-label="View reference 26">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Note%20on%20tangible%20interaction%20using%20paper%20models%20for%20ar-based%20design%20evaluation&amp;journal=J%20Adv%20Mech%20Des%20Syst%20Manuf&amp;volume=7&amp;issue=5&amp;pages=827-835&amp;publication_year=2013&amp;author=Park%2CH&amp;author=Park%2CSJ&amp;author=Jung%2CHK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Park, H-K. Jung, SJ. Park, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Park H, Jung H-K, Park SJ (2014) Tangible AR interaction based on fingertip touch using small-sized nonsquare " /><p class="c-article-references__text" id="ref-CR27">Park H, Jung H-K, Park SJ (2014) Tangible AR interaction based on fingertip touch using small-sized nonsquare markers. J Comput Des Eng 1(4):289–297</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Tangible%20AR%20interaction%20based%20on%20fingertip%20touch%20using%20small-sized%20nonsquare%20markers&amp;journal=J%20Comput%20Des%20Eng&amp;volume=1&amp;issue=4&amp;pages=289-297&amp;publication_year=2014&amp;author=Park%2CH&amp;author=Jung%2CH-K&amp;author=Park%2CSJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Park, K. Lim, M. Kook Seo, S. Jon, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Park M, Lim K, Kook Seo M, Jon S (2015) Spatial augmented reality for product appearance design evaluation. J " /><p class="c-article-references__text" id="ref-CR28">Park M, Lim K, Kook Seo M, Jon S (2015) Spatial augmented reality for product appearance design evaluation. J Comput Des Eng 2:38–46</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatial%20augmented%20reality%20for%20product%20appearance%20design%20evaluation&amp;journal=J%20Comput%20Des%20Eng&amp;volume=2&amp;pages=38-46&amp;publication_year=2015&amp;author=Park%2CM&amp;author=Lim%2CK&amp;author=Kook%20Seo%2CM&amp;author=Jon%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HT. Regenbrecht, M. Wagner, G. Baratoff, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Regenbrecht HT, Wagner M, Baratoff G (2002) Magicmeeting: a collaborative tangible augmented reality system. V" /><p class="c-article-references__text" id="ref-CR29">Regenbrecht HT, Wagner M, Baratoff G (2002) Magicmeeting: a collaborative tangible augmented reality system. Virtual Real 6(3):151–166</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs100550200016" aria-label="View reference 29">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Magicmeeting%3A%20a%20collaborative%20tangible%20augmented%20reality%20system&amp;journal=Virtual%20Real&amp;volume=6&amp;issue=3&amp;pages=151-166&amp;publication_year=2002&amp;author=Regenbrecht%2CHT&amp;author=Wagner%2CM&amp;author=Baratoff%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="J. Rubin, D. Chisnell, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Rubin J, Chisnell D (2008) Handbook of usability testing: How to plan, design, and conduct effective tests, 2n" /><p class="c-article-references__text" id="ref-CR30">Rubin J, Chisnell D (2008) Handbook of usability testing: How to plan, design, and conduct effective tests, 2nd edn. Wiley, Indianapolis</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Handbook%20of%20usability%20testing%3A%20How%20to%20plan%2C%20design%2C%20and%20conduct%20effective%20tests&amp;publication_year=2008&amp;author=Rubin%2CJ&amp;author=Chisnell%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Takahashi, T. Kawashima, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Takahashi H, Kawashima T (2010) Touch-sensitive augmented reality system for development of handheld informati" /><p class="c-article-references__text" id="ref-CR31">Takahashi H, Kawashima T (2010) Touch-sensitive augmented reality system for development of handheld information appliances. Int J Interact Des Manuf 4(1):25–33</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs12008-009-0083-7" aria-label="View reference 31">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Touch-sensitive%20augmented%20reality%20system%20for%20development%20of%20handheld%20information%20appliances&amp;journal=Int%20J%20Interact%20Des%20Manuf&amp;volume=4&amp;issue=1&amp;pages=25-33&amp;publication_year=2010&amp;author=Takahashi%2CH&amp;author=Kawashima%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="T. Tullis, B. Albert, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Tullis T, Albert B (2013) Measuring the user experience: collecting, analysing, and presenting usability matri" /><p class="c-article-references__text" id="ref-CR32">Tullis T, Albert B (2013) Measuring the user experience: collecting, analysing, and presenting usability matrics. MK Elsevier, London</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Measuring%20the%20user%20experience%3A%20collecting%2C%20analysing%2C%20and%20presenting%20usability%20matrics&amp;publication_year=2013&amp;author=Tullis%2CT&amp;author=Albert%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="R. Unger, C. Chandler, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Unger R, Chandler C (2009) A project guide to UX design: for user experience designers in the field or in the " /><p class="c-article-references__text" id="ref-CR33">Unger R, Chandler C (2009) A project guide to UX design: for user experience designers in the field or in the making. New Riders, Berkeley</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20project%20guide%20to%20UX%20design%3A%20for%20user%20experience%20designers%20in%20the%20field%20or%20in%20the%20making&amp;publication_year=2009&amp;author=Unger%2CR&amp;author=Chandler%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Verlinden, I. Horvath, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Verlinden J, Horvath I (2010) The enablers for interactive augmented prototyping. Int J Prod Dev 1(1):62–88" /><p class="c-article-references__text" id="ref-CR34">Verlinden J, Horvath I (2010) The enablers for interactive augmented prototyping. Int J Prod Dev 1(1):62–88</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1504%2FIJPD.2010.032990" aria-label="View reference 34">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20enablers%20for%20interactive%20augmented%20prototyping&amp;journal=Int%20J%20Prod%20Dev&amp;volume=1&amp;issue=1&amp;pages=62-88&amp;publication_year=2010&amp;author=Verlinden%2CJ&amp;author=Horvath%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Verlinden, I. Horváth, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Verlinden J, Horváth I (2008) Enabling interactive augmented prototyping by a portable hardware and a plug-in-" /><p class="c-article-references__text" id="ref-CR35">Verlinden J, Horváth I (2008) Enabling interactive augmented prototyping by a portable hardware and a plug-in-based software architecture. Strojniski Vestnik J Mech Eng 54(6):458–469</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Enabling%20interactive%20augmented%20prototyping%20by%20a%20portable%20hardware%20and%20a%20plug-in-based%20software%20architecture&amp;journal=Strojniski%20Vestnik%20J%20Mech%20Eng&amp;volume=54&amp;issue=6&amp;pages=458-469&amp;publication_year=2008&amp;author=Verlinden%2CJ&amp;author=Horv%C3%A1th%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Verlinden, I. Horváth, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Verlinden J, Horváth I (2009) Analyzing opportunities for using interactive augmented prototyping in design pr" /><p class="c-article-references__text" id="ref-CR36">Verlinden J, Horváth I (2009) Analyzing opportunities for using interactive augmented prototyping in design practice. Artif Intell Eng Des Anal Manuf 23:289–303</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1017%2FS0890060409000250" aria-label="View reference 36">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 36 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Analyzing%20opportunities%20for%20using%20interactive%20augmented%20prototyping%20in%20design%20practice&amp;journal=Artif%20Intell%20Eng%20Des%20Anal%20Manuf&amp;volume=23&amp;pages=289-303&amp;publication_year=2009&amp;author=Verlinden%2CJ&amp;author=Horv%C3%A1th%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JC. Verlinden, A. Smit, AW. Peeters, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Verlinden JC, de Smit A, Peeters AW (2003) Development of a flexible augmented prototyping system. J WSCG 11(3" /><p class="c-article-references__text" id="ref-CR37">Verlinden JC, de Smit A, Peeters AW (2003) Development of a flexible augmented prototyping system. J WSCG 11(3):496–503</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Development%20of%20a%20flexible%20augmented%20prototyping%20system&amp;journal=J%20WSCG&amp;volume=11&amp;issue=3&amp;pages=496-503&amp;publication_year=2003&amp;author=Verlinden%2CJC&amp;author=Smit%2CA&amp;author=Peeters%2CAW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Verlinden J, Horváth I, Edelenbos E (2006). Treatise of technologies for interactive augmented prototyping. In" /><p class="c-article-references__text" id="ref-CR38">Verlinden J, Horváth I, Edelenbos E (2006). Treatise of technologies for interactive augmented prototyping. In: Proceedings of tools and methods of competitive engineering (TMCE), pp 523–536</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Verlinden, I. Horváth, TJ. Nam, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Verlinden J, Horváth I, Nam TJ (2009) Recording augmented reality experiences to capture design reviews. Int J" /><p class="c-article-references__text" id="ref-CR39">Verlinden J, Horváth I, Nam TJ (2009) Recording augmented reality experiences to capture design reviews. Int J Interact Des Manuf (IJIDeM) 3(3):189–200</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs12008-009-0074-8" aria-label="View reference 39">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Recording%20augmented%20reality%20experiences%20to%20capture%20design%20reviews&amp;journal=Int%20J%20Interact%20Des%20Manuf%20%28IJIDeM%29&amp;volume=3&amp;issue=3&amp;pages=189-200&amp;publication_year=2009&amp;author=Verlinden%2CJ&amp;author=Horv%C3%A1th%2CI&amp;author=Nam%2CTJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Viganò, S. Mottura, L. Greci, M. Sacco, CR. Boër, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Viganò G, Mottura S, Greci L, Sacco M, Boër CR (2004) Virtual reality as a support tool in the shoe life cycle" /><p class="c-article-references__text" id="ref-CR40">Viganò G, Mottura S, Greci L, Sacco M, Boër CR (2004) Virtual reality as a support tool in the shoe life cycle. Int J Comput Integr Manuf 17(7):653–660</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1080%2F0951192042000273131" aria-label="View reference 40">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 40 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20as%20a%20support%20tool%20in%20the%20shoe%20life%20cycle&amp;journal=Int%20J%20Comput%20Integr%20Manuf&amp;volume=17&amp;issue=7&amp;pages=653-660&amp;publication_year=2004&amp;author=Vigan%C3%B2%2CG&amp;author=Mottura%2CS&amp;author=Greci%2CL&amp;author=Sacco%2CM&amp;author=Bo%C3%ABr%2CCR">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-018-0356-1-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>The authors would like to thank CNPq, CAPES, and FAPESC (Brazilian government agencies for scientific and technological development) for the financial support that makes this research possible.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Departamento de Engenharia de Produção e Sistemas, Universidade Federal de Santa Catarina, Campus Trindade, Florianópolis, Santa Catarina, Brazil</p><p class="c-article-author-affiliation__authors-list">Fernanda Gomes Faust &amp; Tiago Catecati</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Departamento de Design, Universidade do Estado de Santa Catarina, Av. Buriti, 680, ap. 705B, Itacorubi, Florianópolis, Santa Catarina, CEP 88.034-500, Brazil</p><p class="c-article-author-affiliation__authors-list">Isabella de Souza Sierra, Fernanda Steinbruch Araujo, Elton Moura Nickel &amp; Marcelo Gitirana Gomes Ferreira</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Departamento de Computação Aplicada, Universidade do Vale do Itajaí, Campus Itajaí, Florianópolis, Santa Catarina, Brazil</p><p class="c-article-author-affiliation__authors-list">Alejandro Rafael García Ramírez</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Fernanda_Gomes-Faust"><span class="c-article-authors-search__title u-h3 js-search-name">Fernanda Gomes Faust</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Fernanda Gomes+Faust&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Fernanda Gomes+Faust" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Fernanda Gomes+Faust%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Tiago-Catecati"><span class="c-article-authors-search__title u-h3 js-search-name">Tiago Catecati</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Tiago+Catecati&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Tiago+Catecati" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Tiago+Catecati%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Isabella-Souza_Sierra"><span class="c-article-authors-search__title u-h3 js-search-name">Isabella de Souza Sierra</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Isabella+de+Souza Sierra&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Isabella+de+Souza Sierra" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Isabella+de+Souza Sierra%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Fernanda_Steinbruch-Araujo"><span class="c-article-authors-search__title u-h3 js-search-name">Fernanda Steinbruch Araujo</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Fernanda Steinbruch+Araujo&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Fernanda Steinbruch+Araujo" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Fernanda Steinbruch+Araujo%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Alejandro_Rafael_Garc_a-Ram_rez"><span class="c-article-authors-search__title u-h3 js-search-name">Alejandro Rafael García Ramírez</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Alejandro Rafael Garc%C3%ADa+Ram%C3%ADrez&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Alejandro Rafael Garc%C3%ADa+Ram%C3%ADrez" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Alejandro Rafael Garc%C3%ADa+Ram%C3%ADrez%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Elton_Moura-Nickel"><span class="c-article-authors-search__title u-h3 js-search-name">Elton Moura Nickel</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Elton Moura+Nickel&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Elton Moura+Nickel" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Elton Moura+Nickel%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Marcelo_Gitirana-Gomes_Ferreira"><span class="c-article-authors-search__title u-h3 js-search-name">Marcelo Gitirana Gomes Ferreira</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Marcelo Gitirana+Gomes Ferreira&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Marcelo Gitirana+Gomes Ferreira" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Marcelo Gitirana+Gomes Ferreira%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-018-0356-1/email/correspondent/c1/new">Marcelo Gitirana Gomes Ferreira</a>.</p></div></div></section><section aria-labelledby="Sec22"><div class="c-article-section" id="Sec22-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec22">Electronic supplementary material</h2><div class="c-article-section__content" id="Sec22-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><p>Below is the link to the electronic supplementary material.

</p><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM1"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_MOESM1_ESM.docx" data-supp-info-image="">Supplementary material 1 (DOCX 36 kb)</a></h3></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM2"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1007%2Fs10055-018-0356-1/MediaObjects/10055_2018_356_MOESM2_ESM.docx" data-supp-info-image="">Supplementary material 2 (DOCX 519 kb)</a></h3></div></div></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Mixed%20prototypes%20for%20the%20evaluation%20of%20usability%20and%20user%20experience%3A%20simulating%20an%20interactive%20electronic%20device&amp;author=Fernanda%20Gomes%20Faust%20et%20al&amp;contentID=10.1007%2Fs10055-018-0356-1&amp;publication=1359-4338&amp;publicationDate=2018-07-13&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-018-0356-1" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-018-0356-1" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Faust, F.G., Catecati, T., de Souza Sierra, I. <i>et al.</i> Mixed prototypes for the evaluation of usability and user experience: simulating an interactive electronic device.
                    <i>Virtual Reality</i> <b>23, </b>197–211 (2019). https://doi.org/10.1007/s10055-018-0356-1</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-018-0356-1.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2017-07-12">12 July 2017</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-07-04">04 July 2018</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-07-13">13 July 2018</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2019-06-01">01 June 2019</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-018-0356-1" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-018-0356-1</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Product prototyping</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Augmented reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Mixed prototyping</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Usability</span></li><li class="c-article-subject-list__subject"><span itemprop="about">User experience</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-018-0356-1.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=356;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

