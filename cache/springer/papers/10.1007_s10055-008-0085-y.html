<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Synchronization between audiovisual and haptic feeling for constructin"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="Virtual reality (VR) technology has become more and more mature over the last decade. Development of a virtual environment for training purpose is considered to be one of the most practical..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/12/1.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Synchronization between audiovisual and haptic feeling for constructing edutainment systems"/>

    <meta name="dc.source" content="Virtual Reality 2008 12:1"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2008-03-05"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2008 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Virtual reality (VR) technology has become more and more mature over the last decade. Development of a virtual environment for training purpose is considered to be one of the most practical applications of the VR technology. Since the VR technology involves all kinds of sensors in exchanging information between the real world and the virtual environment, it is computationally intensive in terms of data processing at an individual sensor and information integration among all the sensors. In general, the information integration has to be well synchronized in order to meet the training needs. At the same time, real-time processing capability is also considered to be critical. Many more practical issues could be uncovered only when a virtual training environment is actually being developed. Based on this belief, this study experiments on the development of a virtual environment for training billiards players. The technical difficulties encountered and the corresponding resolutions are considered beneficial to the development of other practical virtual training environments. This paper summarizes the design and implementation details about our experimental virtual training environment for edutainment systems such as virtual billiard game, virtual air hockey game and virtual drum performance with the algorithms for the synchronization of the information from different sources."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2008-03-05"/>

    <meta name="prism.volume" content="12"/>

    <meta name="prism.number" content="1"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="27"/>

    <meta name="prism.endingPage" content="36"/>

    <meta name="prism.copyright" content="2008 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-008-0085-y"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-008-0085-y"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-008-0085-y.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-008-0085-y"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Synchronization between audiovisual and haptic feeling for constructing edutainment systems"/>

    <meta name="citation_volume" content="12"/>

    <meta name="citation_issue" content="1"/>

    <meta name="citation_publication_date" content="2008/03"/>

    <meta name="citation_online_date" content="2008/03/05"/>

    <meta name="citation_firstpage" content="27"/>

    <meta name="citation_lastpage" content="36"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-008-0085-y"/>

    <meta name="DOI" content="10.1007/s10055-008-0085-y"/>

    <meta name="citation_doi" content="10.1007/s10055-008-0085-y"/>

    <meta name="description" content="Virtual reality (VR) technology has become more and more mature over the last decade. Development of a virtual environment for training purpose is consider"/>

    <meta name="dc.creator" content="Yoshihiro Tabuchi"/>

    <meta name="dc.creator" content="Norihiro Abe"/>

    <meta name="dc.creator" content="Hirokazu Taki"/>

    <meta name="dc.creator" content="Shoujie He"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Dragovi&#8217;c V, Radnovi&#8217;c M (2006) Geometry of integrable billiards and pencils of quadrics. J Math Pures Appl 758&#8211;790"/>

    <meta name="citation_reference" content="Jebara T, Eyster C, Weaver J, Starner T, Pentland A (1997) Stochasticks: augmenting the billiards experience with probabilistic vision and wearable computers. Proc Int Symp Wearable Comput 138&#8211;145"/>

    <meta name="citation_reference" content="Matsuura H, Abe N, Tanaka K, Taki H, He S (2006) Virtual air hockey game allowing two players to fight thorough network. J Comput Inf Syst 583&#8211;591"/>

    <meta name="citation_reference" content="Pan Y, Abe N, Tanaka K, Taki H (2004) The virtual debugging system for developing embedded software using virtual machinery. In: Proceedings of embedded and ubiquitous computing, international conference (EUC 2004), pp 85&#8211;95, Aizu, Japan"/>

    <meta name="citation_reference" content="Takamura Y, Abe N, Tanaka K, Taki H, He S (2006) A virtual billiard game with visual auditory and haptic sensation. Lecture notes in artificial intelligence 1609, Foundations of Intelligent Systems, pp 700&#8211;705"/>

    <meta name="citation_reference" content="Tanaka K, Kaida M, Abe N, Taki H (2002) Synchronization of visual, haptic and auditory sense using a haptic display and a virtual sound source device. In: International society on virtual systems and multimedia (VSMM), pp 673&#8211;680"/>

    <meta name="citation_reference" content="Watanabe Y, Abe N, Tanaka K, Taki H, Yagi T (2005a) Multimodal communication system allowing man and avatar to use voice and beck. In: 3rd International conference on information technology and applications (ICITA&#8217;2005), pp 161&#8211;166"/>

    <meta name="citation_reference" content="Watanabe Y, Tokumochi D, Abe N, Tanaka K, Taki H, Kinoshita Y (2005b) Cutting virtual organ model with haptic feedback device. The first international conference on complex medical engineering&#8212;CME2005, pp 255&#8211;260"/>

    <meta name="citation_author" content="Yoshihiro Tabuchi"/>

    <meta name="citation_author_institution" content="Kyushu Institute of Technology, Iizuka, Japan"/>

    <meta name="citation_author" content="Norihiro Abe"/>

    <meta name="citation_author_email" content="abe@mse.kyutech.ac.jp"/>

    <meta name="citation_author_institution" content="Kyushu Institute of Technology, Iizuka, Japan"/>

    <meta name="citation_author" content="Hirokazu Taki"/>

    <meta name="citation_author_institution" content="Wakayama University, Wakayama, Japan"/>

    <meta name="citation_author" content="Shoujie He"/>

    <meta name="citation_author_institution" content="Eastman Kodak Company, Plano, USA"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-008-0085-y&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2008/03/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-008-0085-y"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Synchronization between audiovisual and haptic feeling for constructing edutainment systems"/>
        <meta property="og:description" content="Virtual reality (VR) technology has become more and more mature over the last decade. Development of a virtual environment for training purpose is considered to be one of the most practical applications of the VR technology. Since the VR technology involves all kinds of sensors in exchanging information between the real world and the virtual environment, it is computationally intensive in terms of data processing at an individual sensor and information integration among all the sensors. In general, the information integration has to be well synchronized in order to meet the training needs. At the same time, real-time processing capability is also considered to be critical. Many more practical issues could be uncovered only when a virtual training environment is actually being developed. Based on this belief, this study experiments on the development of a virtual environment for training billiards players. The technical difficulties encountered and the corresponding resolutions are considered beneficial to the development of other practical virtual training environments. This paper summarizes the design and implementation details about our experimental virtual training environment for edutainment systems such as virtual billiard game, virtual air hockey game and virtual drum performance with the algorithms for the synchronization of the information from different sources."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Synchronization between audiovisual and haptic feeling for constructing edutainment systems | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-008-0085-y","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Training system, Virtual reality, Synchronized real-time processing, Billiards game","kwrd":["Training_system","Virtual_reality","Synchronized_real-time_processing","Billiards_game"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-008-0085-y","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-008-0085-y","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=85;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-008-0085-y">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Synchronization between audiovisual and haptic feeling for constructing edutainment systems
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-008-0085-y.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-008-0085-y.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2008-03-05" itemprop="datePublished">05 March 2008</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Synchronization between audiovisual and haptic feeling for constructing edutainment systems</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Yoshihiro-Tabuchi" data-author-popup="auth-Yoshihiro-Tabuchi">Yoshihiro Tabuchi</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Kyushu Institute of Technology" /><meta itemprop="address" content="grid.258806.1, 0000000121101386, Kyushu Institute of Technology, 680-4 Kawazu, Iizuka, Fukuoka, 820-8502, Japan" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Norihiro-Abe" data-author-popup="auth-Norihiro-Abe" data-corresp-id="c1">Norihiro Abe<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Kyushu Institute of Technology" /><meta itemprop="address" content="grid.258806.1, 0000000121101386, Kyushu Institute of Technology, 680-4 Kawazu, Iizuka, Fukuoka, 820-8502, Japan" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Hirokazu-Taki" data-author-popup="auth-Hirokazu-Taki">Hirokazu Taki</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Wakayama University" /><meta itemprop="address" content="grid.413170.0, 0000000107109816, Wakayama University, 930 Sakaedani, Wakayama, Wakayama, 680-8510, Japan" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Shoujie-He" data-author-popup="auth-Shoujie-He">Shoujie He</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Eastman Kodak Company" /><meta itemprop="address" content="Eastman Kodak Company, Plano, TX, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 12</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">27</span>–<span itemprop="pageEnd">36</span>(<span data-test="article-publication-year">2008</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">109 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">2 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-008-0085-y/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Virtual reality (VR) technology has become more and more mature over the last decade. Development of a virtual environment for training purpose is considered to be one of the most practical applications of the VR technology. Since the VR technology involves all kinds of sensors in exchanging information between the real world and the virtual environment, it is computationally intensive in terms of data processing at an individual sensor and information integration among all the sensors. In general, the information integration has to be well synchronized in order to meet the training needs. At the same time, real-time processing capability is also considered to be critical. Many more practical issues could be uncovered only when a virtual training environment is actually being developed. Based on this belief, this study experiments on the development of a virtual environment for training billiards players. The technical difficulties encountered and the corresponding resolutions are considered beneficial to the development of other practical virtual training environments. This paper summarizes the design and implementation details about our experimental virtual training environment for edutainment systems such as virtual billiard game, virtual air hockey game and virtual drum performance with the algorithms for the synchronization of the information from different sources.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Ever since the computer was invented, a lot of things that used to be impossible have become possible and many imaginations have become reality. Constructing a 3D world inside a computer and interacting with it have been the goals that virtual reality (VR) technology is targeted at. Over the last decade, the VR technology has become more and more mature. These days, low cost and high performance computers and advanced sensor technologies have become the driving force for the VR technology to quickly find its real-world applications (Pan et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Pan Y, Abe N, Tanaka K, Taki H (2004) The virtual debugging system for developing embedded software using virtual machinery. In: Proceedings of embedded and ubiquitous computing, international conference (EUC 2004), pp 85–95, Aizu, Japan" href="/article/10.1007/s10055-008-0085-y#ref-CR4" id="ref-link-section-d25069e350">2004</a>). Development of a virtual environment for training purpose is considered to be one of the most practical applications of VR technology.</p><p>A high-quality virtual training environment is required to offer the trainee a real-world experience while interacting with virtual objects. This includes not only the high-quality 3D graphics representation of the virtual environment and virtual objects, but also the high-performance interactivity. The 3D graphics representations need to be dynamically and smoothly updated based upon the user interaction. The interactivity, on the other hand, requires well-synchronized real-time processing of the sensor data (Watanabe et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005a" title="Watanabe Y, Abe N, Tanaka K, Taki H, Yagi T (2005a) Multimodal communication system allowing man and avatar to use voice and beck. In: 3rd International conference on information technology and applications (ICITA’2005), pp 161–166" href="/article/10.1007/s10055-008-0085-y#ref-CR8" id="ref-link-section-d25069e356">2005a</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference b" title="Watanabe Y, Tokumochi D, Abe N, Tanaka K, Taki H, Kinoshita Y (2005b) Cutting virtual organ model with haptic feedback device. The first international conference on complex medical engineering—CME2005, pp 255–260" href="/article/10.1007/s10055-008-0085-y#ref-CR9" id="ref-link-section-d25069e359">b</a>). These are all computationally intensive. The limited resources and processing power on a single PC become very difficult and even impossible to meet the needs.</p><p>In this study, a virtual environment for training billiards players has been developed (Jebara et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Jebara T, Eyster C, Weaver J, Starner T, Pentland A (1997) Stochasticks: augmenting the billiards experience with probabilistic vision and wearable computers. Proc Int Symp Wearable Comput 138–145" href="/article/10.1007/s10055-008-0085-y#ref-CR2" id="ref-link-section-d25069e365">1997</a>, Dragovi’c et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Dragovi’c V, Radnovi’c M (2006) Geometry of integrable billiards and pencils of quadrics. J Math Pures Appl 758–790" href="/article/10.1007/s10055-008-0085-y#ref-CR1" id="ref-link-section-d25069e368">2006</a>). Behavior identification, 3D sound effects, and the force torque sensor feedback are identified as three essential components. The synchronization of the real-time processing of the sensor data is achieved through the SCRAM Net+.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">System organization</h2><div class="c-article-section__content" id="Sec2-content"><p>To construct a high-quality virtual training environment, it is a common recognition that there must be visual, auditory and haptic sensors, and the sensor data must be well synchronized. This study basically follows the same direction with the emphasis on the synchronization among the behavior generation using rigid object physics, 3D sound effects and haptic feedback. In order to do so, VORTEX, 3D-Sound Space and PHANToM are used in the construction of our experimental virtual environment.</p><p>Since it is impossible to have one PC to handle the processing of all the data, three PCs are used with each dedicated to a particular sensor or device. The three PCs are connected through SCRAM Net+. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig1">1</a> shows the system organization. The details are described as follows.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>System organization</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <h3 class="c-article__sub-heading" id="Sec3">PC for vision</h3>
                  <ol class="u-list-style-none">
                    <li>
                      <span class="u-custom-list-number">1.</span>
                      
                        <p>Graphic rendering and simulation</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">2.</span>
                      
                        <p>VORTEX—the rigid object physics engine.</p>
                      
                    </li>
                  </ol>
                <h3 class="c-article__sub-heading" id="Sec4">PC for auditory</h3><p>It generates stereophonic sound using Roland 3D Sound Space and RSS Data Stream Management system.</p><h3 class="c-article__sub-heading" id="Sec5">PC for haptic computation</h3><p>It is used as the user interface and returns haptic feedback through the GHOST and PHANToM.</p></div></div></section><section aria-labelledby="Sec6"><div class="c-article-section" id="Sec6-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec6">Parallel processing issues</h2><div class="c-article-section__content" id="Sec6-content"><p>With the nature of the system organization, the following parallel processing related issues have been identified.
</p><ul class="u-list-style-bullet">
                  <li>
                    <p>The transmission of position data</p>
                  </li>
                  <li>
                    <p>Presentation of haptic sensation</p>
                  </li>
                  <li>
                    <p>Synchronization of sound effects.</p>
                  </li>
                </ul>
                     <h3 class="c-article__sub-heading" id="Sec7">The transmission of position data</h3><p>The three PCs do their jobs cooperatively by sending their data through the shared memory of the SCRAM Net+. When a user starts interacting with the VR environment, for example, the interaction is communicated to the VR environment through PHANToM. The interaction event is then simulated by VORTEX. Based on the simulated results, RSS10 will play the sound effects and the PHANToM will react with haptic effects to the user whenever it is necessary.</p><p>The position data such as shift or rotation that are generated through the interaction with PHANToM is transmitted to VORTEX through the SCRAM Net+ with a delay of less than 1 ms. The results simulated by the VORTEX must be transmitted to the PC for a haptic reaction data computation and the PC for the processing of the 3D sound effects. All the data are written into the shared memory in the form of coordinates and a transformation matrix.</p><p>As soon as a simulation result is updated, the updated coordinates are written in the shared memory. However, since the updating of the simulation result is intermittent and non-linear, the receiver has to behave in the same way. There is the possibility that a moving virtual object passes through other virtual objects as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig2">2</a> and thus the unexpected simulation happens. The figure shows the case where a ball is colliding with a virtual object. But the same situation will occur in various cases, for example, when a drum is hit with a stick.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>A penetration problem</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>In the rigid object physics, the impulsive force occurring at the collision is generally calculated from the inertia tensor and relative velocity based on the shape data. As velocity information is indispensable while applying the rigid object physics to objects colliding with each other, instead of updating the coordinates, updating the velocity is considered to be necessary.</p><p>It is, however, impossible to correctly simulate the state of a virtual object because an error slowly accumulates if the state is updated based on the velocity. Therefore, both the current coordinates and the velocity of a virtual object are considered necessary while updating the shared memory. In this case, there is potentially a danger of error accumulation. For instance, right after both the coordinates and the velocity of a virtual object have been transmitted, the virtual object suddenly stops moving. In this case, its coordinates are invariant but in the PCs receiving the coordinates and velocity of the virtual object, the virtual object keeps moving.</p><p>This gives rise to inconsistent information between the two PCs with regard to the position of the virtual object. The slower the updating is, the more significant the error becomes. Because of the error, velocity is considered inadequate for the application that concerns the accuracy of locating virtual objects. In the regular cases, using the coordinates is recommended. It is suggested that velocity is taken into account as well only at the time when collision is going to happen.</p><p>As an example, let us consider a virtual billiard game in which a moving virtual object collides with some still virtual objects. In this game, a player hits a virtual billiard ball with PHANToM, which is a virtual billiard cue. GHOST detects the collision of the PHANToM with a virtual billiard ball. Since the coordinates of the virtual ball is not sent to the VORTEX yet at the moment when GHOST detects the collision, collision is does not happen in the VORTEX. At this moment, changing the control from the coordinates to the velocity makes it possible to apply the rigid object physics in the VORTEX (Takamura et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Takamura Y, Abe N, Tanaka K, Taki H, He S (2006) A virtual billiard game with visual auditory and haptic sensation. Lecture notes in artificial intelligence 1609, Foundations of Intelligent Systems, pp 700–705" href="/article/10.1007/s10055-008-0085-y#ref-CR6" id="ref-link-section-d25069e516">2006</a>).</p><p>It is necessary to transmit to the VORTEX the coordinates and velocity right before the collision occurs. This is because the collision has already occurred even when the coordinates at the collision were transmitted. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig3">3</a> illustrates how to change the control by velocity (the right) from that by coordinates (the left). Not the coordinates at the time of collision were detected, but the ones one step before (just before collision), and velocity are transmitted to the PC for VORTEX.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>How to change process</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>That inappropriate movement may happen due to the skipped coordinates update for one time interval is a concern. The experimental results show that the movement within one time interval is so tiny and the haptic simulation in GHOST is repeated 1,000 times per second and thus nothing unnatural is noticeable. This technique makes it possible to change control from that using coordinates to that using velocity at the best timing and vice versa. As a result, applying rigid object physics at collision becomes possible while keeping precise operation.</p><h3 class="c-article__sub-heading" id="Sec8">The presentation of haptic sensation</h3><p>When performing parallel computation in a real-time simulation, it is necessary to run simulation while maintaining synchronization between two PCs. Processor speed in two PCs are so different from each other that it is difficult to synchronize them as the time taken in each process is quite different.</p><p>VORTEX needs at most 60 Hz, but GHOST does 1,000 Hz. As long as the cue is used to hit a billiard ball, high frequency may not be required because GHOST has only return impulsive force. However during the game, the player is allowed to touch any objects except for billiard balls. If the cloth on the billiard board is touched with a cue, then smooth feeling must be returned to the player’s hand. The smooth presentation of touching sense is generally required at least from 200 to 300 Hz. If VORTEX were synchronized with GHOST, smooth touching sense is difficult to return. To ensure that GHOST gets enough velocity to return smooth haptic feeling, asynchronous execution of two PCs is proposed.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig4">4</a> illustrates how the data are exchanged through the shared memory system. It shows how VORTEX and GHOST access the shared memory along the time axis. Since GHOST runs at high processing speed, it writes data into the shared memory with high frequency, but reads data out from the shared memory only after VORTEX has finishing writing. Therefore, although it is parallel computation, accessing data asynchronously makes it possible to let the individual PC perform its own job without affecting others.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Operation from two PCs to a shared memory</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec9">Synchronization between sound generation and collision detection</h3><p>In a general sound revitalization instrument, when a sound is being generated, it is impossible to revitalize several sound effects simultaneously. Any new revitalization command is simply ignored until the current sound effect has been fully generated. Because of this limitation, when more than one sound effects are needed in a short period, such as the simulation of the repeated collision, none of the sound effects will be generated. In addition, when multiple objects collide with each other at the same time in the real world, a loud sound will be heard. With the current limitation, instead of a loud sound, a monotonous sound will be generated.</p><p>In the system, when virtual balls collide in an extremely short period, the sounds accompanying the collision are considered as a unified sound. When more than one virtual ball collide with each other, the sound effect is generated by recording in advance the real sound accompanying the collision of the real balls in the real world and then replaying the recording. Different levels of sounds are also recorded in advance according to the velocities of virtual balls. Each sound must be recorded as short as possible so that the recording could be repeatedly replayed as needed.</p></div></div></section><section aria-labelledby="Sec10"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Construction of VR space</h2><div class="c-article-section__content" id="Sec10-content"><p>In order to offer a real-world experience to the players, the virtual space must be made with high interactivity. In general, if a simulation is only for a simple scenario, it is sufficient to build only one VR space.</p><p>This system, however, is constructed with three PCs and each of the PCs handle visual, auditory and haptic sensations, respectively. Since each of them handle different type of tasks, the time spent is largely different. If we build only one VR space, which includes everything, in the case that a particular PC spends extra long time to finish its task, the other two PCs will have to be idle during that period of time. In this study, in order to speed up the overall processing, instead of one VR space, three VR spaces are constructed with each on one PC. Since each individual VR space handles one type of task (visual, auditory or haptic), only the data related to the particular sensor or device is held in memory and memory usage could be reduced substantially.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig5">5</a> illustrates the information needed for each of the VR spaces. The PC for vision space keeps track of the coordinates of virtual objects. The PC for sound space locates the existence of the player and also the sound sources so that the virtual sound could be generated to the best effect. The PC for haptic sensor has to keep track of all data of all the virtual objects including the cue, stand and balls, to detect the collision between the cue and virtual objects.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>
                                    <b>a</b> Vision space, <b>b</b> sound space, <b>c</b> haptic space</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Although there are three separate VR spaces, the player needs to feel like interacting with a single VR space. Otherwise, the player will not have the real-world experience. This requires synchronizing the three VR spaces seamlessly. This is achieved through the SCRAM Net+. When one VR space has changes, the updates will be written into the shared memory of the SCRAM Net+. The information in the shared memory will be read by the other VR spaces. By controlling each VR space separately, the visual, auditory and haptic sensations are eventually synchronized.</p></div></div></section><section aria-labelledby="Sec11"><div class="c-article-section" id="Sec11-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec11">Flow of process</h2><div class="c-article-section__content" id="Sec11-content"><p>Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig6">6</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig7">7</a> shows the outline flow of a system, </p><ol class="u-list-style-none">
                  <li>
                    <span class="u-custom-list-number">1.</span>
                    
                      <p>The visual, auditory and haptic simulation is started at each PC.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">2.</span>
                    
                      <p>Each VR space is constructed.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">3.</span>
                    
                      <p>When a user operates a cue, GHOST acquires the coordinates and posture of PHANToM through SCRAM Net+, and detects collision detection between a cue (PHANToM) and a ball, which is hit with the cue. Haptic feedback is returned to the user via PHANToM and the collision information is written into SCRAM Net+.</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">4.</span>
                    
                      <p>VORTEX reads coordinates of the object whose position is changed and updates simulation. As a result, as soon as the collision is detected, the result will be written on the SCRAM Net+. Finally, it visualizes the virtual world on a display. The same process is repeated (hereafter, this is regarded as one cycle).</p>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">5.</span>
                    
                      <p>RSS10 acquires the name, coordinates and velocity of a set of virtual objects, which collided from the SCRAM Net+ and then generates stereophonic sound and output the sound effects.</p>
                    
                  </li>
                </ol><p> VORTEX and GHOST at the acquisition of data do not have to wait for the other output in order to access the SCRAM Net+. This makes it possible for both of them to guarantee the updating frequency of simulation. The above, however, is a basic regular flow. The other special cases such as switching from coordinates to the velocity and other information exchange are performed only when needed.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>A flow of the system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig7_HTML.gif?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig7_HTML.gif" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>A flow of a vision system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <h3 class="c-article__sub-heading" id="Sec12">A flow of a vision system</h3>
                  <ol class="u-list-style-none">
                    <li>
                      <span class="u-custom-list-number">1.</span>
                      
                        <p>In addition to a transformation matrix of PHANToM, collision information is also collected. Whether there is a collision between PHANToM and a virtual object is detected by GHOST.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">2.</span>
                      
                        <p>If the collision is detected with GHOST, the control is switched to be velocity-based. The SCRAM Net+ is accessed again in order to get coordinates and velocity of PHANToM right before the collision.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">3.</span>
                      
                        <p>After setting the coordinates and velocity of PHANToM right before the collision with the object, the control that prevented PHANToM from updating coordinates must be canceled. It transmits information to make PHANToM write its coordinates thereafter.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">4.</span>
                      
                        <p>The simulation is updated again and in order to make collision between PHANToM and an object by all means happen at this step, once again control is changed back to the coordinates-based mode from the next step.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">5.</span>
                      
                        <p>Updated coordinates of all virtual objects and current cue coordinates are written on the SCRAM Net+.</p>
                      
                    </li>
                  </ol>
                <h3 class="c-article__sub-heading" id="Sec13">A flow of an auditory system</h3>
                  <ol class="u-list-style-none">
                    <li>
                      <span class="u-custom-list-number">1.</span>
                      
                        <p>Access the SCRAM Net+ and read all the updated information from VORTEX. The information includes the coordinates of all virtual objects and a position of PHANToM.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">2.</span>
                      
                        <p>Check if collision among virtual balls or with the frame of the billiards board is detected with VORTEX. Also check to see if a virtual ball has been hit with the cue.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">3.</span>
                      
                        <p>When collision is detected, the number of collision and information concerning pairs between objects colliding with each other is acquired in order to select the sound source for the generation of the sound effects.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">4.</span>
                      
                        <p>After a sound source is selected, sound generation command in MIDI is transmitted to Roland Sound Space (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig8">8</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig8_HTML.gif?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig8_HTML.gif" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>A flow of an auditory system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                                    
                      
                    </li>
                  </ol>
                <h3 class="c-article__sub-heading" id="Sec14">A flow of haptic system</h3>
                  <ol class="u-list-style-none">
                    <li>
                      <span class="u-custom-list-number">1.</span>
                      
                        <p>Once the haptic space is constructed, the coordinates of virtual objects will be transmitted into the haptic space. Note that the coordinates of the virtual objects are all simulated by VORTEX.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">2.</span>
                      
                        <p>Not only coordinates and the posture but also the velocity of PHANToM are acquired, and they are stored in memory to make it possible to use them when VORTEX switch the control from coordinates-based mode to the velocity-based one.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">3.</span>
                      
                        <p>If collision has been detected before, the transmission of the current PHANToM coordinates is restrained in order to make VORTEX shift to the velocity-based control mode. During that time, the SCRAM Net+ does not allow any data to be written until VORTEX finishes reading velocity information. Here, it is examined whether VORTEX has updated its state or not.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">4.</span>
                      
                        <p>In the case that it has not been examined yet after collision, the transmission of new coordinates will not be done. Only PHANToM coordinates are updated. Collision analysis among virtual objects will not be completed because there is the possibility of consecutive collisions.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">5.</span>
                      
                        <p>When it is not examined or when collision does not happen yet, collision detection is performed. If there is collision, collision information and the coordinates and velocity stored right before are transmitted (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig9">9</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig9_HTML.gif?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig9_HTML.gif" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>A flow of haptic system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                                    
                      
                    </li>
                  </ol>
                </div></div></section><section aria-labelledby="Sec15"><div class="c-article-section" id="Sec15-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec15">Virtual billiards game</h2><div class="c-article-section__content" id="Sec15-content"><p>A virtual billiards game is selected to evaluate the method proposed in this paper. The game board and a near view of a billiard ball, which is going to be hit with a cue are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig10">10</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig10_HTML.jpg?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig10_HTML.jpg" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Virtual billiard game</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig11">11</a> shows a cue controlled with PHANToM. Translating or rotating the interface instrument gives a virtual cue the same movement.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig11_HTML.jpg?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig11_HTML.jpg" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>User interface</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <h3 class="c-article__sub-heading" id="Sec16">Improving speed by parallel computation</h3><p>The processing speed of each PC is measured. The time taken to complete one cycle of process using each PC is measured 100 times and the maximum and the minimum of the results are recorded. Processing speed when a single PC manages three jobs was measured afterwards.</p><h3 class="c-article__sub-heading" id="Sec17">Experimental result</h3><p>It is understood that a large amount of processing time can be reduced by parallel computation. It seems that it is not impossible to perform three jobs with a single PC, but Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-008-0085-y#Tab1">1</a> shows that both haptic and auditory rendering is not fully realized. On the other hand, each PC exploiting parallel computation achieves enough iteration necessary for giving a user high reality.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Comparison between processing speed</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-008-0085-y/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec18">Evaluation of the system</h3><p>Ten subjects were asked to operate a virtual billiards game and to evaluate the validity of visual, auditory and haptic sensation and how much they are synchronized. Results are shown in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig12">12</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig13">13</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig14">14</a>. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig12">12</a> implies that good evaluation is obtained, concerning both auditory and haptic sensation. It can be considered that parallel computation succeeded in constructing VR space in which haptic sensation synchronizes with auditory one. But evaluation on visual sensation was not so good. Concerning the behavior of virtual objects, high reality is attained as simulation is performed based on rigid object physics. Rendering the system, which is provided with VORTEX, does not have enough functions which GL offers and cannot draw any shadows of virtual objects. It is still necessary to evaluate how close the current behavior is to the real billiards game. In terms of improvement, at the very least, friction factors need to be incorporated in the future. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig12_HTML.gif?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig12_HTML.gif" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Evaluation on visual, auditory and haptic sensation</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-13"><figure><figcaption><b id="Fig13" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 13</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/13" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig13_HTML.gif?as=webp"></source><img aria-describedby="figure-13-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig13_HTML.gif" alt="figure13" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-13-desc"><p>Evaluation of synchronization among three sensations</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/13" data-track-dest="link:Figure13 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-14"><figure><figcaption><b id="Fig14" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 14</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/14" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig14_HTML.jpg?as=webp"></source><img aria-describedby="figure-14-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig14_HTML.jpg" alt="figure14" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-14-desc"><p>Virtual air hockey game</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/14" data-track-dest="link:Figure14 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig13">13</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig14">14</a> show that enough synchronization among them is established. One of the goals of this study is to make the real-time processing possible while dealing with the different type of sensor data. In that sense, the experimental results are positive.</p></div></div></section><section aria-labelledby="Sec19"><div class="c-article-section" id="Sec19-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec19">Virtual air hockey game</h2><div class="c-article-section__content" id="Sec19-content"><p>This game is different from the billiard game in the point that two players hit a pack in turns through a network. Using two PHANToMs make it possible to give each of two players haptic feeling, but there is danger that intensive movement of a paddle may break down PHANToM. Instead of PHANToM, another possibility to use a mouse with oscillating function as a paddle is considered but it is turned out to be difficult to synchronize the oscillation with impulsive force occurring at the collision. As the result, a usual mouse is used as input device. Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig13">13</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig14">14</a> show the air hockey game and the configuration of it is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig15">15</a> (Matsuura et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Matsuura H, Abe N, Tanaka K, Taki H, He S (2006) Virtual air hockey game allowing two players to fight thorough network. J Comput Inf Syst 583–591" href="/article/10.1007/s10055-008-0085-y#ref-CR3" id="ref-link-section-d25069e1245">2006</a>). </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-15"><figure><figcaption><b id="Fig15" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 15</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/15" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig15_HTML.gif?as=webp"></source><img aria-describedby="figure-15-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig15_HTML.gif" alt="figure15" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-15-desc"><p>Configuration of air hockey game</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/15" data-track-dest="link:Figure15 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <h3 class="c-article__sub-heading" id="Sec20">Flow of processing of the entire system</h3><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig16">16</a> shows flow of processing of this system. The simulation is performed along the flow shown in the figure. First of all, when a player operates a mouse to hit a pack, the mouse coordinates are given to a paddle in the VR space described in VORTEX installed in each PC, and it is examined, which of a frame, goal or paddle collides with a pack. The simulation is updated based on the pack and paddle coordinates, and its information is written into SCRAM Net. On the other PC, necessary data are read from the net, and they are reflected in the simulation by VORTEX. As a result, synchronization between two PCs is attained. When collision among objects is detected, information on objects participating in this collision is sent to Roland Sound Space. Roland Sound Space system generates a 3D solid sound based on the location and velocity of the pack and the object that has just collided with the pack. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-16"><figure><figcaption><b id="Fig16" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 16</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/16" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig16_HTML.gif?as=webp"></source><img aria-describedby="figure-16-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig16_HTML.gif" alt="figure16" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-16-desc"><p>Flow of processing of the system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/16" data-track-dest="link:Figure16 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>As a result, a player at one terminal is allowed to play the game with a player at the other terminal through Scram Net. It was noted that the sound signal generated by a Roland Sound System installed in one PC is transmitted to other PC and successfully replayed in the system. This leads us to the possibility that the number of expensive physical simulators can be reduced.</p><p>Two VORTEXs are used in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig16">16</a>, but each VORTEX mealy calculates behavior of virtual objects on each side and it must read the necessary data from Scram Net before continuing the computation on its side. The system described so far does read data and calculates behavior on one side and then sends results to other side, but the new one calculates all necessary computation on one side and the other side receives the consequence and displays it as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig17">17</a>. That is, the server and client system is successfully adopted.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-17"><figure><figcaption><b id="Fig17" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 17</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/17" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig17_HTML.gif?as=webp"></source><img aria-describedby="figure-17-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig17_HTML.gif" alt="figure17" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-17-desc"><p>A new system using one VORTEX</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/17" data-track-dest="link:Figure17 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        </div></div></section><section aria-labelledby="Sec21"><div class="c-article-section" id="Sec21-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec21">Virtual drum performance</h2><div class="c-article-section__content" id="Sec21-content"><p>This system was constructed to examine the possibility of realizing virtual music instrument. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig18">18</a> shows the experimental drum set, which is hit with a virtual stick PHANToM.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-18"><figure><figcaption><b id="Fig18" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 18</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/18" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig18_HTML.jpg?as=webp"></source><img aria-describedby="figure-18-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig18_HTML.jpg" alt="figure18" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-18-desc"><p>Virtual drum performance</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/18" data-track-dest="link:Figure18 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>Recently, development of electronics makes it possible to produce electronic musical instruments that realize many kinds of real music instruments, but most of them only use a keyboard as a kind of electric switch. This method is not enough to realize percussion instrument because it cannot give a player the real sensation felt by hitting the instrument. An electric drum set allows a player to give the sensation as if he were performing a real drum set, the device used is, however, not virtual but real object. A drum is a virtual object, and it is so difficult to prevent a virtual stick from penetrating into it that PHANToM is used, which is used not only as a pointing device but also an output device to give haptic feeling.</p><p>This system consists of three drums and uses neither GHOST nor VORTEX because the location of the drums is fixed and there is no movable object other than a stick grasped by a player’s hand. The only method required to construct this application is to quickly detect collision between a stick and a drum itself including a frame or inside of the drum.</p><p>Purposely, the virtual space is divided into eight-sub volumes recursively, i.e., Oct-tree method is used (Tanaka et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Tanaka K, Kaida M, Abe N, Taki H (2002) Synchronization of visual, haptic and auditory sense using a haptic display and a virtual sound source device. In: International society on virtual systems and multimedia (VSMM), pp 673–680" href="/article/10.1007/s10055-008-0085-y#ref-CR7" id="ref-link-section-d25069e1360">2002</a>). A player is permitted to have a stick upside down and hit a drum as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig19">19</a>a, b. It is easy to add another stick but according to the subject test it turns out that no one can get the feeling as if a real drum were hit because it is not easy to hit a drum with PHANToM. Other reasons are that the face of the drum is not transformed when it is hit, and that only impulsive force is returned from the stick instead of oscillation along with reaction force. To solve the problem, rendering of shape deformation along with oscillating feedback force rendering are necessary, and the virtual system realizing them is under construction.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-19"><figure><figcaption><b id="Fig19" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 19</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/19" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig19_HTML.gif?as=webp"></source><img aria-describedby="figure-19-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig19_HTML.gif" alt="figure19" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-19-desc"><p>
                                    <b>a</b>, <b>b</b> Three drums and a stick</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/19" data-track-dest="link:Figure19 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     <p>The following does not solve the problem but we think it will a promising approach? That is, the method exploits both real sheet including flat circular surfaces as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0085-y#Fig20">20</a> and any objects of a cylinder shape as a stick. Really a keyboard drawn on a sheet is used instead of a real keyboard, but the array of keys is fixed. On the other hand, as the array and the number of drums are not fixed, although it may be not easy to permit a player to set the configuration of drums, image processing technique will help us realize such a system.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-20"><figure><figcaption><b id="Fig20" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 20</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/20" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig20_HTML.gif?as=webp"></source><img aria-describedby="figure-20-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0085-y/MediaObjects/10055_2008_85_Fig20_HTML.gif" alt="figure20" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-20-desc"><p>A promising virtual drum set</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0085-y/figures/20" data-track-dest="link:Figure20 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                     </div></div></section><section aria-labelledby="Sec22"><div class="c-article-section" id="Sec22-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec22">Conclusion</h2><div class="c-article-section__content" id="Sec22-content"><p>Game construction with high reality is obtained by integrating rigid object physics, haptic feedback and stereophonic sound system. For developing a system with much higher reality than that realized in this study, the operability which gives a user the feeling as if he were playing a real game is necessary. One of the promising ways is to build a mixed reality system permitting a user to hit a virtual ball with a real cue.</p><p>The system needs not only installing both position sensors on the body and impact generation device on the tip of the real cue, but also a technique realizing complete registration between real and virtual environment permitting a user to hit a virtual ball with a real cue.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dragovi’c V, Radnovi’c M (2006) Geometry of integrable billiards and pencils of quadrics. J Math Pures Appl 75" /><p class="c-article-references__text" id="ref-CR1">Dragovi’c V, Radnovi’c M (2006) Geometry of integrable billiards and pencils of quadrics. J Math Pures Appl 758–790</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Jebara T, Eyster C, Weaver J, Starner T, Pentland A (1997) Stochasticks: augmenting the billiards experience w" /><p class="c-article-references__text" id="ref-CR2">Jebara T, Eyster C, Weaver J, Starner T, Pentland A (1997) Stochasticks: augmenting the billiards experience with probabilistic vision and wearable computers. Proc Int Symp Wearable Comput 138–145</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Matsuura H, Abe N, Tanaka K, Taki H, He S (2006) Virtual air hockey game allowing two players to fight thoroug" /><p class="c-article-references__text" id="ref-CR3">Matsuura H, Abe N, Tanaka K, Taki H, He S (2006) Virtual air hockey game allowing two players to fight thorough network. J Comput Inf Syst 583–591</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pan Y, Abe N, Tanaka K, Taki H (2004) The virtual debugging system for developing embedded software using virt" /><p class="c-article-references__text" id="ref-CR4">Pan Y, Abe N, Tanaka K, Taki H (2004) The virtual debugging system for developing embedded software using virtual machinery. In: Proceedings of embedded and ubiquitous computing, international conference (EUC 2004), pp 85–95, Aizu, Japan</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Takamura Y, Abe N, Tanaka K, Taki H, He S (2006) A virtual billiard game with visual auditory and haptic sensa" /><p class="c-article-references__text" id="ref-CR6">Takamura Y, Abe N, Tanaka K, Taki H, He S (2006) A virtual billiard game with visual auditory and haptic sensation. Lecture notes in artificial intelligence 1609, Foundations of Intelligent Systems, pp 700–705</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Tanaka K, Kaida M, Abe N, Taki H (2002) Synchronization of visual, haptic and auditory sense using a haptic di" /><p class="c-article-references__text" id="ref-CR7">Tanaka K, Kaida M, Abe N, Taki H (2002) Synchronization of visual, haptic and auditory sense using a haptic display and a virtual sound source device. In: International society on virtual systems and multimedia (VSMM), pp 673–680</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Watanabe Y, Abe N, Tanaka K, Taki H, Yagi T (2005a) Multimodal communication system allowing man and avatar to" /><p class="c-article-references__text" id="ref-CR8">Watanabe Y, Abe N, Tanaka K, Taki H, Yagi T (2005a) Multimodal communication system allowing man and avatar to use voice and beck. In: 3rd International conference on information technology and applications (ICITA’2005), pp 161–166</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Watanabe Y, Tokumochi D, Abe N, Tanaka K, Taki H, Kinoshita Y (2005b) Cutting virtual organ model with haptic " /><p class="c-article-references__text" id="ref-CR9">Watanabe Y, Tokumochi D, Abe N, Tanaka K, Taki H, Kinoshita Y (2005b) Cutting virtual organ model with haptic feedback device. The first international conference on complex medical engineering—CME2005, pp 255–260</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-008-0085-y-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Kyushu Institute of Technology, 680-4 Kawazu, Iizuka, Fukuoka, 820-8502, Japan</p><p class="c-article-author-affiliation__authors-list">Yoshihiro Tabuchi &amp; Norihiro Abe</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Wakayama University, 930 Sakaedani, Wakayama, Wakayama, 680-8510, Japan</p><p class="c-article-author-affiliation__authors-list">Hirokazu Taki</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Eastman Kodak Company, Plano, TX, USA</p><p class="c-article-author-affiliation__authors-list">Shoujie He</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Yoshihiro-Tabuchi"><span class="c-article-authors-search__title u-h3 js-search-name">Yoshihiro Tabuchi</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Yoshihiro+Tabuchi&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Yoshihiro+Tabuchi" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Yoshihiro+Tabuchi%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Norihiro-Abe"><span class="c-article-authors-search__title u-h3 js-search-name">Norihiro Abe</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Norihiro+Abe&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Norihiro+Abe" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Norihiro+Abe%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Hirokazu-Taki"><span class="c-article-authors-search__title u-h3 js-search-name">Hirokazu Taki</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Hirokazu+Taki&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Hirokazu+Taki" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Hirokazu+Taki%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Shoujie-He"><span class="c-article-authors-search__title u-h3 js-search-name">Shoujie He</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Shoujie+He&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Shoujie+He" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Shoujie+He%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-008-0085-y/email/correspondent/c1/new">Norihiro Abe</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Synchronization%20between%20audiovisual%20and%20haptic%20feeling%20for%20constructing%20edutainment%20systems&amp;author=Yoshihiro%20Tabuchi%20et%20al&amp;contentID=10.1007%2Fs10055-008-0085-y&amp;publication=1359-4338&amp;publicationDate=2008-03-05&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Tabuchi, Y., Abe, N., Taki, H. <i>et al.</i> Synchronization between audiovisual and haptic feeling for constructing edutainment systems.
                    <i>Virtual Reality</i> <b>12, </b>27–36 (2008). https://doi.org/10.1007/s10055-008-0085-y</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-008-0085-y.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2006-05-14">14 May 2006</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2007-07-23">23 July 2007</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-03-05">05 March 2008</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-03">March 2008</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-008-0085-y" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-008-0085-y</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Training system</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Virtual reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Synchronized real-time processing</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Billiards game</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-008-0085-y.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=85;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

