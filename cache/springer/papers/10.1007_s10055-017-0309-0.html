<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Developing vibrotactile haptic stimuli based on measured human capabil"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="This paper describes an approach to design tactile haptic signals that help humans &#8220;visualize&#8221; an environment through the use of a vibrotactile haptic wristband that has four vibration..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/21/4.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Developing vibrotactile haptic stimuli based on measured human capabilities"/>

    <meta name="dc.source" content="Virtual Reality 2017 21:4"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2017-02-08"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2017 Springer-Verlag London"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="This paper describes an approach to design tactile haptic signals that help humans &#8220;visualize&#8221; an environment through the use of a vibrotactile haptic wristband that has four vibration motors. A human response map to tactile input while sitting was determined experimentally. It shows the zones where humans can classify signals with a high success rate based on minimum Duration of Stimulus (DOS) (&#8220;on&#8221; periods) and &#8220;off&#8221; periods of the haptic signals. It was also shown experimentally that a human&#8217;s ability to recognize tactile patterns depends on the level of engagement required by the activity. This paper provides an approach to predict a human response map for various activities. The map during sitting is used to design the signals to send information to a human. Two types of signals are developed: sequence stimuli and digital codes. Sequence stimuli create an on/off rhythm for the vibration motors that humans can sense directly without a decoding process. Experiments show that humans can recognize 10 levels of sequence stimuli with a success rate greater than 80%. This class of signals is useful for applications where information must be repeated frequently, e.g., range information sent to a human parking a car. The second class of signals is digital codes, similar to Morse code, where a sequence of long and short motor DOS represents each code. The meaning of the signal is associated with a specific code. From 27 digital codes, experiments showed a successful recognition rate of 78.7%. An application for the digital code method is to pick specific menu items, based on the codes, for fast food restaurants."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2017-02-08"/>

    <meta name="prism.volume" content="21"/>

    <meta name="prism.number" content="4"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="203"/>

    <meta name="prism.endingPage" content="212"/>

    <meta name="prism.copyright" content="2017 Springer-Verlag London"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-017-0309-0"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-017-0309-0"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-017-0309-0.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-017-0309-0"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer London"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Developing vibrotactile haptic stimuli based on measured human capabilities"/>

    <meta name="citation_volume" content="21"/>

    <meta name="citation_issue" content="4"/>

    <meta name="citation_publication_date" content="2017/11"/>

    <meta name="citation_online_date" content="2017/02/08"/>

    <meta name="citation_firstpage" content="203"/>

    <meta name="citation_lastpage" content="212"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-017-0309-0"/>

    <meta name="DOI" content="10.1007/s10055-017-0309-0"/>

    <meta name="citation_doi" content="10.1007/s10055-017-0309-0"/>

    <meta name="description" content="This paper describes an approach to design tactile haptic signals that help humans &#8220;visualize&#8221; an environment through the use of a vibrotactile"/>

    <meta name="dc.creator" content="Gridsada Phanomchoeng"/>

    <meta name="dc.creator" content="Ratchatin Chancharoen"/>

    <meta name="dc.creator" content="Ron Lumia"/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="Akita J, Ono T, Ito K, Okamoto M (2014) Touch at a distance: simple perception aid device with user&#8217;s explorer action. In: SIGGRAPH Asia 2014 Emerging Technologies. ACM"/>

    <meta name="citation_reference" content="citation_title=Gentleguide: an exploration of haptic output for indoors pedestrian guidance, human computer interaction with mobile devices and services; citation_publication_date=2003; citation_id=CR2; citation_author=S Bosman; citation_author=B Groenendaal; citation_author=JW Findlater; citation_author=T Visser; citation_author=M Graaf; citation_author=P Markopoulos; citation_publisher=Springer"/>

    <meta name="citation_reference" content="Brewster S, Brown LM (2004) Tactons: structured tactile messages for non-visual information display. In: Proceedings of the fifth conference on Australasian user interface, vol 28. Australian Computer Society, Inc., pp 15&#8211;23"/>

    <meta name="citation_reference" content="Chantranuwathana S, Sornumpol P (2005) One-DOF arm movement guidance using vibrotactile feedback. In: The 19th conference of mechanical engineering network of thailand, Phuket, Thailand"/>

    <meta name="citation_reference" content="Guo W, Wei N, Chen I-M, Ding ZQ, Yeo SH (2009) Intuitive vibro-tactile feedback for human body movement guidance. In: Proceeding of the 2009 IEEE international conference on robotics and biomimetics, Guilin, China, pp 135&#8211;140"/>

    <meta name="citation_reference" content="citation_journal_title=Percept Mot Skills; citation_title=Two-point tactual discrimination on the back: a signal-detection approach; citation_author=GW Guyot, FD Johnson, C Weaver; citation_volume=54; citation_issue=3c; citation_publication_date=1982; citation_pages=1289-1290; citation_doi=10.2466/pms.1982.54.3c.1289; citation_id=CR6"/>

    <meta name="citation_reference" content="Kohli L, Niwa M, Noma H, Susami K, Yanagida Y, Lindeman R W, Kume Y (2006) Towards effective information display using vibrotactile apparent motion. In: Haptic interfaces for virtual environment and teleoperator systems, 2006 14th Symposium on IEEE, pp 445&#8211;451"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Robot; citation_title=TIKL: development of a wearable vibrotactile feedback suit for improved human motor learning; citation_author=J Lieberman, C Breazeal; citation_volume=23; citation_issue=5; citation_publication_date=2007; citation_pages=919-926; citation_doi=10.1109/TRO.2007.907481; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=Wearable vibrotactile systems for virtual contact and information display; citation_author=RW Lindeman, Y Yanagida, H Noma, K Hosaka; citation_volume=9; citation_issue=2; citation_publication_date=2006; citation_pages=203-213; citation_doi=10.1007/s10055-005-0010-6; citation_id=CR9"/>

    <meta name="citation_reference" content="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1&#8211;8"/>

    <meta name="citation_reference" content="McDaniel T, Krishna S, Colbry D, Panchanathan S (2009) Using tactile rhythm to convey interpersonal distances to individuals who are blind. Im: CHI 2009, Boston, MA, USA, pp 4669&#8211;4674"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Veh Technol; citation_title=Directional sound for long distance auditory warnings from a highway construction work zone; citation_author=G Phanomchoeng, R Rajamani, J Hourdos; citation_volume=59; citation_issue=5; citation_publication_date=2010; citation_pages=2266-2276; citation_doi=10.1109/TVT.2010.2042090; citation_id=CR12"/>

    <meta name="citation_reference" content="citation_title=Ambient touch: designing tactile interfaces for handheld devices; citation_publication_date=2002; citation_id=CR13; citation_author=I Poupyrev; citation_author=S Maruyama; citation_author=J Rekimoto; citation_publisher=ACM"/>

    <meta name="citation_reference" content="citation_title=Haptic feedback for pen computing: directions and strategies; citation_publication_date=2004; citation_id=CR14; citation_author=I Poupyrev; citation_author=M Okabe; citation_author=S Maruyama; citation_publisher=ACM"/>

    <meta name="citation_reference" content="Rattanachotithavorn S, Sae-Ong P, Wannasuphoprasit W (2011) Experimental study of tactile stimulating system in back area for warning purpose. In: The 5th conference of TRS conference on robotics and industrial technology, Bangkok, Thailand"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Haptics; citation_title=Human-robot formation control via visual and vibrotactile haptic feedback; citation_author=S Scheggi, F Morbidi, D Prattichizzo; citation_volume=7; citation_issue=4; citation_publication_date=2014; citation_pages=499-511; citation_doi=10.1109/TOH.2014.2332173; citation_id=CR16"/>

    <meta name="citation_reference" content="Sergi F, Accoto D, Compolo D, Guglielmelli E (2008) Forearm orientation guidance with a vibrotactile feedback bracelet: on the directionality of tactile motor communication. In: Proceedings of the 2nd Biennial IEEE/RAS-EMBS international conference on biomedical robotics and biomechatronics, Scottsdale, AZ, USA, pp 433&#8211;438"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Haptics; citation_title=Evaluation of tactile feedback methods for wrist rotation guidance; citation_author=AA Stanley, KJ Kuchenbecker; citation_volume=5; citation_issue=3; citation_publication_date=2012; citation_pages=240-251; citation_doi=10.1109/TOH.2012.33; citation_id=CR18"/>

    <meta name="citation_reference" content="Szymczak D, Magnusson C, Rassmus-Grohn K (2012) Guiding tourists through haptic interaction: vibration feedback in the lund time machine. In: Isokoski P, Springare J (eds) EuroHaptics 2012, Part II. LNCS, vol 7283, pp 157&#8211;162"/>

    <meta name="citation_reference" content="citation_journal_title=Dyn Syst Control; citation_title=Human factors for the design of force-reflecting haptic interfaces; citation_author=HZ Tan, MA Srinivasan, B Eberman, B Cheng; citation_volume=55; citation_issue=1; citation_publication_date=1994; citation_pages=353-359; citation_id=CR20"/>

    <meta name="citation_reference" content="Tsukada K, Yasumura M (2004) Activebelt: belt-type wearable tactile display for directional navigation. In: International conference on ubiquitous computing. Lecture notes in computer science, vol 3205. Springer, Heidelberg, pp 384&#8211;399."/>

    <meta name="citation_reference" content="van Erp JBF (2001) Tactile navigation display, haptic human&#8211;computer interaction. Lecture notes in computer science, vol 2058, pp 165&#8211;173"/>

    <meta name="citation_reference" content="van Erp JBF (2002) Guideline for the use of vibro-tactile displays in human computer interaction. In: Proceedings of Eurohaptics, pp 18&#8211;22"/>

    <meta name="citation_reference" content="citation_journal_title=Transp Res Part F: Traffic Psychol Behav; citation_title=Vibrotactile in-vehicle navigation system; citation_author=JBF Erp, HAHC Veen; citation_volume=7; citation_issue=4; citation_publication_date=2004; citation_pages=247-256; citation_doi=10.1016/j.trf.2004.09.003; citation_id=CR24"/>

    <meta name="citation_reference" content="citation_journal_title=ACM Trans Appl Percept; citation_title=Waypoint navigation with a vibrotactile waist belt; citation_author=JBF Erp, HAHC Veen, C Jansen; citation_volume=2; citation_issue=2; citation_publication_date=2005; citation_pages=106-117; citation_doi=10.1145/1060581.1060585; citation_id=CR25"/>

    <meta name="citation_reference" content="Yang U, Jang Y, Kim GJ (2002) Designing a vibro-tactile wear for close range interaction for vr-based motion training. In: International conference on artificial reality and telexistence, pp 4&#8211;9"/>

    <meta name="citation_reference" content="Yano H, Miyamoto Y, Iwata H (2009) Haptic interface for perceiving remote object using a laser range finder. In: EuroHaptics conference, 2009 and symposium on haptic interfaces for virtual environment and teleoperator systems. World Haptics 2009. Third Joint IEEE, pp 196&#8211;201. IEEE"/>

    <meta name="citation_author" content="Gridsada Phanomchoeng"/>

    <meta name="citation_author_email" content="gridsada.phanomchoeng@gmail.com"/>

    <meta name="citation_author_institution" content="Department of Mechanical Engineering, Chulalongkorn University, Bangkok, Thailand"/>

    <meta name="citation_author" content="Ratchatin Chancharoen"/>

    <meta name="citation_author_email" content="ratchatin.c@chula.ac.th"/>

    <meta name="citation_author_institution" content="Department of Mechanical Engineering, Chulalongkorn University, Bangkok, Thailand"/>

    <meta name="citation_author" content="Ron Lumia"/>

    <meta name="citation_author_email" content="lumia@unm.edu"/>

    <meta name="citation_author_institution" content="Department of Mechanical Engineering, University of New Mexico, Albuquerque, USA"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-017-0309-0&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2017/11/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-017-0309-0"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Developing vibrotactile haptic stimuli based on measured human capabilities"/>
        <meta property="og:description" content="This paper describes an approach to design tactile haptic signals that help humans “visualize” an environment through the use of a vibrotactile haptic wristband that has four vibration motors. A human response map to tactile input while sitting was determined experimentally. It shows the zones where humans can classify signals with a high success rate based on minimum Duration of Stimulus (DOS) (“on” periods) and “off” periods of the haptic signals. It was also shown experimentally that a human’s ability to recognize tactile patterns depends on the level of engagement required by the activity. This paper provides an approach to predict a human response map for various activities. The map during sitting is used to design the signals to send information to a human. Two types of signals are developed: sequence stimuli and digital codes. Sequence stimuli create an on/off rhythm for the vibration motors that humans can sense directly without a decoding process. Experiments show that humans can recognize 10 levels of sequence stimuli with a success rate greater than 80%. This class of signals is useful for applications where information must be repeated frequently, e.g., range information sent to a human parking a car. The second class of signals is digital codes, similar to Morse code, where a sequence of long and short motor DOS represents each code. The meaning of the signal is associated with a specific code. From 27 digital codes, experiments showed a successful recognition rate of 78.7%. An application for the digital code method is to pick specific menu items, based on the codes, for fast food restaurants."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Developing vibrotactile haptic stimuli based on measured human capabilities | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-017-0309-0","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Vibrotactile, Haptic, Haptic wrist, Haptic belt, Tactile, Tactons, Human computer interaction","kwrd":["Vibrotactile","Haptic","Haptic_wrist","Haptic_belt","Tactile","Tactons","Human_computer_interaction"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-017-0309-0","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-017-0309-0","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=309;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-017-0309-0">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Developing vibrotactile haptic stimuli based on measured human capabilities
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-017-0309-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-017-0309-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2017-02-08" itemprop="datePublished">08 February 2017</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Developing vibrotactile haptic stimuli based on measured human capabilities</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Gridsada-Phanomchoeng" data-author-popup="auth-Gridsada-Phanomchoeng" data-corresp-id="c1">Gridsada Phanomchoeng<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Chulalongkorn University" /><meta itemprop="address" content="0000 0001 0244 7875, grid.7922.e, Department of Mechanical Engineering, Chulalongkorn University, Bangkok, 10330, Thailand" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Ratchatin-Chancharoen" data-author-popup="auth-Ratchatin-Chancharoen">Ratchatin Chancharoen</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Chulalongkorn University" /><meta itemprop="address" content="0000 0001 0244 7875, grid.7922.e, Department of Mechanical Engineering, Chulalongkorn University, Bangkok, 10330, Thailand" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Ron-Lumia" data-author-popup="auth-Ron-Lumia">Ron Lumia</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of New Mexico" /><meta itemprop="address" content="0000 0001 2188 8502, grid.266832.b, Department of Mechanical Engineering, University of New Mexico, Albuquerque, NM, 87131, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 21</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">203</span>–<span itemprop="pageEnd">212</span>(<span data-test="article-publication-year">2017</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">620 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">1 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-017-0309-0/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>This paper describes an approach to design tactile haptic signals that help humans “visualize” an environment through the use of a vibrotactile haptic wristband that has four vibration motors. A human response map to tactile input while sitting was determined experimentally. It shows the zones where humans can classify signals with a high success rate based on minimum Duration of Stimulus (DOS) (“on” periods) and “off” periods of the haptic signals. It was also shown experimentally that a human’s ability to recognize tactile patterns depends on the level of engagement required by the activity. This paper provides an approach to predict a human response map for various activities. The map during sitting is used to design the signals to send information to a human. Two types of signals are developed: sequence stimuli and digital codes. Sequence stimuli create an on/off rhythm for the vibration motors that humans can sense directly without a decoding process. Experiments show that humans can recognize 10 levels of sequence stimuli with a success rate greater than 80%. This class of signals is useful for applications where information must be repeated frequently, e.g., range information sent to a human parking a car. The second class of signals is digital codes, similar to Morse code, where a sequence of long and short motor DOS represents each code. The meaning of the signal is associated with a specific code. From 27 digital codes, experiments showed a successful recognition rate of 78.7%. An application for the digital code method is to pick specific menu items, based on the codes, for fast food restaurants.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Over the past decade, the amount of information available to humans has grown rapidly while the ability to obtain information remains the same. Humans obtain information through sight, hearing, taste, smell, and touch. For human–computer interaction, taste and smell present numerous challenges and have been explored in limited ways. Currently, sight, hearing, and touch are the sensing modalities used in most virtual reality applications. Consequently, three primary types of displays have evolved to deliver information to humans: visual displays, auditory displays, and tactile displays. Each has advantages and disadvantages (Lindeman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Lindeman RW, Yanagida Y, Noma H, Hosaka K (2006) Wearable vibrotactile systems for virtual contact and information display. Virtual Real 9(2):203–213" href="/article/10.1007/s10055-017-0309-0#ref-CR9" id="ref-link-section-d103047e354">2006</a>; Tsukada and Yasumura <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e357">2004</a>).</p><p>Humans can receive immense quantities of information from the sense of sight (Tsukada and Yasumura <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e363">2004</a>; van Erp <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e366">2001</a>). Developments in virtual reality (VR) technologies have focused on the visual display technologies that enhance this human sense. Many techniques have been developed to display information as iconic, text, pictograph, etc. Display devices, such as VR glasses, enhance the human sense of sight. However, one limitation of this approach is the need for humans to look at the visual stimulus, which for some activities is undesirable. Also, common vision problems such as near- and far-sightedness affect vision quality (Lindeman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Lindeman RW, Yanagida Y, Noma H, Hosaka K (2006) Wearable vibrotactile systems for virtual contact and information display. Virtual Real 9(2):203–213" href="/article/10.1007/s10055-017-0309-0#ref-CR9" id="ref-link-section-d103047e369">2006</a>; Tsukada and Yasumura <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e372">2004</a>).</p><p>Hearing techniques are also well developed. Humans can receive stimuli without facing a certain direction. Many technologies for producing audio have been used to enhance this human sense, e.g., directional speakers (Phanomchoeng et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e378">2010</a>). The limitation for hearing is that the auditory display may be masked by other sounds in the surrounding environment (Tsukada and Yasumura <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e381">2004</a>).</p><p>Humans can respond to touch, but touch is complex because it is not a single sense. Touch can be divided into kinesthetic and cutaneous sub-senses (Lindeman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Lindeman RW, Yanagida Y, Noma H, Hosaka K (2006) Wearable vibrotactile systems for virtual contact and information display. Virtual Real 9(2):203–213" href="/article/10.1007/s10055-017-0309-0#ref-CR9" id="ref-link-section-d103047e387">2006</a>). Clearly, humans can receive information through a tactile display. Many devices have been developed to generate tactile stimuli for the sense of touch (Brewster and Brown <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Brewster S, Brown LM (2004) Tactons: structured tactile messages for non-visual information display. In: Proceedings of the fifth conference on Australasian user interface, vol 28. Australian Computer Society, Inc., pp 15–23" href="/article/10.1007/s10055-017-0309-0#ref-CR3" id="ref-link-section-d103047e390">2004</a>). These devices do not limit the human’s use of other sensing modalities, but can provide additional information by displaying contact cues. This technology is still in its infancy. Tan et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e393">1994</a>) studied the human factors associated with haptic interfaces. This work provides insight into the design of specific haptics devices that respect the limitations imposed by the humans that interact with them. Vibration is studied in this work, but only as a disturbance that limits a human’s ability to perceive.</p><p>It is obvious that using only sight or hearing limits the information processing capability of humans (van Erp and van Veen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e400">2004</a>). There are situations where humans cannot interpret the environment using only sight or hearing. To address this problem, several types of tactile devices have been developed to help humans “visualize” a workspace through a haptic interface, i.e., create a spatial representation based on tactile input. For example, Yano et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e403">2009</a>) and Akita et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Akita J, Ono T, Ito K, Okamoto M (2014) Touch at a distance: simple perception aid device with user’s explorer action. In: SIGGRAPH Asia 2014 Emerging Technologies. ACM" href="/article/10.1007/s10055-017-0309-0#ref-CR1" id="ref-link-section-d103047e406">2014</a>) have developed similar devices where a distance measurement translates to a force for the user. The closer an object is to the user of this device, the more force is felt. By moving the device, a human can “feel” the shape of objects at a distance by holding and pointing it at objects. Both haptics devices turn a distance measurement into a force measurement that can be “visualized” through the user’s hand or fingers. van Erp and van Veen (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e409">2004</a>), as well as Rattanachotithavorn et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e412">2011</a>), have mounted multiple vibrating elements in a driver’s seat to send navigation and warning signals to a driver. Combining a visual and tactile display improves safety by reducing human response time by approximately 15% (van Erp and van Veen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e416">2004</a>). Many researchers (Bosman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Bosman S, Groenendaal B, Findlater JW, Visser T, de Graaf M, Markopoulos P (2003) Gentleguide: an exploration of haptic output for indoors pedestrian guidance, human computer interaction with mobile devices and services. Springer, Berlin, pp 358–362" href="/article/10.1007/s10055-017-0309-0#ref-CR2" id="ref-link-section-d103047e419">2003</a>; McDaniel et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e422">2009</a>; Szymczak et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e425">2012</a>; Tsukada and Yasumura <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e428">2004</a>; van Erp et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e431">2005</a>) have developed directional navigation devices, such as an active belt or wristband. The devices receive directional and range signals from a navigation system, such as GPS. Then, they generate tactile stimuli from multiple vibration motors inside a belt or wristband. Humans can “visualize” distance and direction through these haptic devices, i.e., it is possible to develop a spatial map that is normally created by vision. Work has been done (Chantranuwathana and Sornumpol <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Chantranuwathana S, Sornumpol P (2005) One-DOF arm movement guidance using vibrotactile feedback. In: The 19th conference of mechanical engineering network of thailand, Phuket, Thailand" href="/article/10.1007/s10055-017-0309-0#ref-CR4" id="ref-link-section-d103047e435">2005</a>; Guo et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Guo W, Wei N, Chen I-M, Ding ZQ, Yeo SH (2009) Intuitive vibro-tactile feedback for human body movement guidance. In: Proceeding of the 2009 IEEE international conference on robotics and biomimetics, Guilin, China, pp 135–140" href="/article/10.1007/s10055-017-0309-0#ref-CR5" id="ref-link-section-d103047e438">2009</a>; Lieberman and Breazeal <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Lieberman J, Breazeal C (2007) TIKL: development of a wearable vibrotactile feedback suit for improved human motor learning. IEEE Trans Robot 23(5):919–926" href="/article/10.1007/s10055-017-0309-0#ref-CR8" id="ref-link-section-d103047e441">2007</a>; Scheggi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e444">2014</a>; Sergi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e447">2008</a>; Stanley and Kuchenbecker <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e450">2012</a>; Yang et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e454">2002</a>) using tactile stimuli as a feedback signal for guiding movement or improving human motor learning. These researchers often used a body suit or wristband with vibration motors inside. When the devices detect movement from motion sensors, they generate vibration signals to humans as feedback that can be used to correct motion, change velocity, or control a vehicle.</p><p>Poupyrev et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e460">2002</a>) describe the problem of single bit tactile recognition, i.e., vibrotactile devices are often used to denote a single event, e.g., telephone call. Consequently they chose to use six tactile pulse sequences for their “TouchEngine” device that they interfaced with a handheld personal digital assistant. This work was extended to pen computing (Poupyrev et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e463">2004</a>) where a user “feels” the texture of objects on a screen through the pen itself.</p><p>For success with any tactile device, humans must perceive the signals with a high rate of recognition. In addition, it is desirable to send information more complex than 1 bit (on/off). There is no limit to the number of stimulus signals that can be sent to a human, and therefore choosing useful stimulus signals remains somewhat ad hoc even when respecting measured human limitations for recognizing signals. For instance, Bosman et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Bosman S, Groenendaal B, Findlater JW, Visser T, de Graaf M, Markopoulos P (2003) Gentleguide: an exploration of haptic output for indoors pedestrian guidance, human computer interaction with mobile devices and services. Springer, Berlin, pp 358–362" href="/article/10.1007/s10055-017-0309-0#ref-CR2" id="ref-link-section-d103047e469">2003</a>), McDaniel et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e472">2009</a>), Szymczak et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e475">2012</a>), Tsukada and Yasumura (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e478">2004</a>), and van Erp et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e481">2005</a>) used the position of the vibration motor inside the device to indicate direction and used different vibration frequencies to denote distance. However, human skin is sensitive to vibrations between 20 and 500 Hz (van Erp <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e485">2002</a>). Humans cannot distinguish the difference between vibration levels that differ by less than 20% (van Erp <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e488">2002</a>). To make matters worse, the differences between vibration levels need to increase when humans engage in vigorous activities (Matscheko et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e491">2010</a>; Scheggi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e494">2014</a>). As a result, only three or four distance levels can be presented with these devices. Additional levels only confuse humans (Szymczak et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e497">2012</a>). A similar result is shown by the devices employed in (Chantranuwathana and Sornumpol <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Chantranuwathana S, Sornumpol P (2005) One-DOF arm movement guidance using vibrotactile feedback. In: The 19th conference of mechanical engineering network of thailand, Phuket, Thailand" href="/article/10.1007/s10055-017-0309-0#ref-CR4" id="ref-link-section-d103047e500">2005</a>; Guo et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Guo W, Wei N, Chen I-M, Ding ZQ, Yeo SH (2009) Intuitive vibro-tactile feedback for human body movement guidance. In: Proceeding of the 2009 IEEE international conference on robotics and biomimetics, Guilin, China, pp 135–140" href="/article/10.1007/s10055-017-0309-0#ref-CR5" id="ref-link-section-d103047e504">2009</a>; Lieberman and Breazeal <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Lieberman J, Breazeal C (2007) TIKL: development of a wearable vibrotactile feedback suit for improved human motor learning. IEEE Trans Robot 23(5):919–926" href="/article/10.1007/s10055-017-0309-0#ref-CR8" id="ref-link-section-d103047e507">2007</a>; Scheggi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e510">2014</a>; Sergi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e513">2008</a>; Stanley and Kuchenbecker <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e516">2012</a>). They use vibration levels of each vibration motor to indicate motion error, i.e., a deviation from a desired motion. These devices show that it is difficult for users to recognize the amount of motion error using the native encoding scheme. This suggests that these tactile displays would benefit from the encoding schemes proposed in this paper.</p><p>To improve the use of tactile displays, Chantranuwathana and Sornumpol (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Chantranuwathana S, Sornumpol P (2005) One-DOF arm movement guidance using vibrotactile feedback. In: The 19th conference of mechanical engineering network of thailand, Phuket, Thailand" href="/article/10.1007/s10055-017-0309-0#ref-CR4" id="ref-link-section-d103047e522">2005</a>) developed a one-degree-of-freedom arm movement transfer function model. This model explains quantitatively the role of human sensing in the tactile display system. Then, van Erp (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e525">2002</a>) developed guidelines for the design of a visual display in human computer interaction. Matscheko et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e528">2010</a>) investigated a wristband with an array of four vibration motors inside. Their technique to deliver information used eight different vibration signals as a sequence of signal stimuli for each motor.</p><p>This paper focuses on human response to a set of vibration motors and the specific tactile stimuli that improve perception success rates. The proposed design method to create specific tactile stimuli is based on a human response map, which is described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-017-0309-0#Sec5">3</a>. Two examples of tactile stimuli are presented: sequence stimuli and digital codes.</p><p>The rest of the paper is organized as follows. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-017-0309-0#Sec2">2</a> describes the design and implementation of the vibrotactile wristband, a tactile display, as well as the experimental setup. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-017-0309-0#Sec5">3</a> describes the experiments that measure human response to a vibration motor. In Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-017-0309-0#Sec8">4</a>, a technique is proposed that creates sequence stimulus signals and experiments are performed to evaluate this approach. Then, a technique to develop digital code signals is presented and verified experimentally. Finally, conclusions are presented in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-017-0309-0#Sec12">5</a>.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Vibrotactile wristband</h2><div class="c-article-section__content" id="Sec2-content"><p>In this section, the concept and features of the vibrotactile wristband are presented. Then, the experimental setup and procedures are shown.</p><h3 class="c-article__sub-heading" id="Sec3">Description of the vibrotactile wristband</h3><p>Although there are many types of tactile displays such as a belt, vest, or suit, this paper uses a wristband for the experiments. This type of tactile display is appropriate because it has many applications, such as navigation, human motor learning, and information feedback (Bosman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Bosman S, Groenendaal B, Findlater JW, Visser T, de Graaf M, Markopoulos P (2003) Gentleguide: an exploration of haptic output for indoors pedestrian guidance, human computer interaction with mobile devices and services. Springer, Berlin, pp 358–362" href="/article/10.1007/s10055-017-0309-0#ref-CR2" id="ref-link-section-d103047e567">2003</a>; Chantranuwathana and Sornumpol <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Chantranuwathana S, Sornumpol P (2005) One-DOF arm movement guidance using vibrotactile feedback. In: The 19th conference of mechanical engineering network of thailand, Phuket, Thailand" href="/article/10.1007/s10055-017-0309-0#ref-CR4" id="ref-link-section-d103047e570">2005</a>; Guo et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Guo W, Wei N, Chen I-M, Ding ZQ, Yeo SH (2009) Intuitive vibro-tactile feedback for human body movement guidance. In: Proceeding of the 2009 IEEE international conference on robotics and biomimetics, Guilin, China, pp 135–140" href="/article/10.1007/s10055-017-0309-0#ref-CR5" id="ref-link-section-d103047e573">2009</a>; Kohli et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Kohli L, Niwa M, Noma H, Susami K, Yanagida Y, Lindeman R W, Kume Y (2006) Towards effective information display using vibrotactile apparent motion. In: Haptic interfaces for virtual environment and teleoperator systems, 2006 14th Symposium on IEEE, pp 445–451" href="/article/10.1007/s10055-017-0309-0#ref-CR7" id="ref-link-section-d103047e576">2006</a>; Lieberman and Breazeal <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Lieberman J, Breazeal C (2007) TIKL: development of a wearable vibrotactile feedback suit for improved human motor learning. IEEE Trans Robot 23(5):919–926" href="/article/10.1007/s10055-017-0309-0#ref-CR8" id="ref-link-section-d103047e579">2007</a>; Matscheko et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e583">2010</a>; Scheggi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e586">2014</a>; Sergi et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e589">2008</a>; Stanley and Kuchenbecker <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e592">2012</a>).</p><p>The device is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig1">1</a>. According to Matscheko et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e601">2010</a>), the position of vibration motors along the band (“wrist”) as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig1">1</a> is a good configuration because humans can distinguish the location of each vibration motor. The four vibration motors (Precision Microdrive 303-101) are mounted slotted plates and attached to an elastic wristband (the width of the wristband is about 20 mm and its length before stretching is about 180 mm). The position of the plates can be adjusted to simultaneously satisfy human perception capabilities and comfort. Two point discrimination (Guyot et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1982" title="Guyot GW, Johnson FD, Weaver C (1982) Two-point tactual discrimination on the back: a signal-detection approach. Percept Mot Skills 54(3c):1289–1290" href="/article/10.1007/s10055-017-0309-0#ref-CR6" id="ref-link-section-d103047e607">1982</a>; Matscheko et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e610">2010</a>), which defines the minimum distance (roughly 40 mm) between two stimuli that can be differentiated, has been satisfied. With this design, most people can easily adjust the location of the four vibration motors around the wristband.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Design of vibrotactile wristband</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Each vibration motor has a vibration frequency of approximately 200 Hz and 0.8 g acceleration when the input voltage to the motor is between 2.5 and 3.8 V. This amplitude and frequency are within the detectable stimulus range for humans (van Erp <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e635">2002</a>). The time delay from off to full on of the vibration motor is 65 ms and the time from on to full off of the vibration motor is 105 ms.</p><p>The controller for the vibrotactile wristband consists of a simple “on–off” power circuit using the National Instruments (NI) myRIO interface. The on–off power circuit is controlled by a signal from NI-myRIO and provides 0 or 3.8 V through a cable to each of the vibration motors. The NI-myRIO is programmed by LabView 2013 software with Real-Time and FPGA modules. There is an independent interface to each of the four vibration motors. The command update rate is 10,000 Hz. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig2">2</a> shows the vibrotactile wristband with controller and interface.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>
                                       <b>a</b> NI: myRIO and “on” off power circuit. <b>b</b> A vibrotactile wristband with its electronics and interface</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec4">Experimental setup</h3><p>There are two experiments in this paper. The first study explores the human response to a vibration motor while the second explores techniques to develop tactile signal stimuli that deliver information effectively. Both experiments were conducted at the mechanical engineering workspace hall at Chulalongkorn University. The experimental setup is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig3">3</a>. All test participants were recruited from third year undergraduate students in the Mechanical Engineering Department at Chulalongkorn University. Their ages were between 20 and 22 years, and all are healthy. Since all students shared the laboratory workspace, they were aware of experiments to evaluate the capabilities of the vibrotactile wristband. The experiments were performed as part of a required third year class, Experimentation and Laboratory II. The procedural details for the experiments are presented in Sects. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-017-0309-0#Sec5">3</a> and <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-017-0309-0#Sec8">4</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Top view shows the experiment space</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        </div></div></section><section aria-labelledby="Sec5"><div class="c-article-section" id="Sec5-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec5">Human response to a vibration motor</h2><div class="c-article-section__content" id="Sec5-content"><p>When a vibration motor is turned on, it vibrates with frequency of 200 Hz and 0.8 g acceleration. The amplitude of vibration for the particular vibration motors used in the wristband cannot be changed due to the limitations associated with the vibration motor hardware. Therefore, a human can feel only Duration of Stimulus (DOS) (“on” periods) or “off.” However, it is possible to vary the amount of time that that motor is on or off in order to encode many signals.</p><p>Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-017-0309-0#Sec6">3.1</a> describes a study of human response to a vibration motor. The vibration motor’s range of “on” and “off” periods along with the human’s ability to perceive the stimulus accurately is measured. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-017-0309-0#Sec7">3.2</a> shows the human response to a vibration motor during sitting, walking, and playing a game on a tablet.</p><h3 class="c-article__sub-heading" id="Sec6">Human response to a vibration motor</h3><p>Seven male students were subjects in this experiment. Each subject was asked to sit while an experimenter adjusted the wristband to the correct position. The position of the wristband is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig4">4</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Position of the wristband during experiments</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The experiment started by setting the on/off period of the vibration pulse as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig5">5</a>. The DOS (“on” periods) used in this experiment were 30, 35, 42, 50, 60, 80, and 130 ms. Each DOS period also pairs with “off” periods that were 120, 130, 142, 155, 170, 180, 200, and 250 ms. So, there were 56 combinations of vibration signals. The experiment consisted of sending between 2 and 5 pulses of a randomly chosen signal to vibration motor A. After sending the vibration pulses, the participant needed to respond with the number of vibration pulses felt within 5 s. Each type of vibration pulse was repeated three times. This procedure was repeated for all subjects.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Example of DOS and off period for a vibration motor</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig6">6</a> plots the DOS against the “off time” for the human response map, where the color indicates the success rate percentage. The minimum DOS and “off” periods (Red Cross) where humans distinguish the number of pulses received with a success rate greater than 90% were 65 and 155 ms, respectively. Zone A in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig6">6</a> depicts the region where subjects recognized successfully (greater than 90% success) the number of pulses received. Moreover, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig6">6</a> shows DOS and “off” periods are independent in Zone A. The minimum signal (Red Cross) takes 220 ms. One pattern of signal could be sent to subject in this amount of time. If one wants to send additional patterns, the signal must take additional time. Zone B shows the region where the subjects were unable to classify signals with a reasonable success rate.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Human response map</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>In Zone C of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig6">6</a>, the subjects achieved success primarily using the DOS, i.e., the success rate was independent of the “off” period. Conversely, Zone D is the region where the success rate depends on the “off” period. Interestingly, Zone E shows a linear relationship between DOS and “off” periods that affects the success rate. It should be noted that these results where obtained for subjects that were sitting. The level of activity affects the location of the minimum DOS and “off” periods of the signal.</p><h3 class="c-article__sub-heading" id="Sec7">Experiment of human response to a vibration motor during sitting, walking, and playing a game</h3><p>This section shows how the minimum DOS and “off” periods depend on the level of human activity. In these experiments, subjects either sit, play a game, or walk. The game that participants played is Fruit Ninja by Halfbrick Studios, which is installed on an IPad3. The game asks the player to cut fruit by drawing one’s finger across fruit. As the game progresses, the speed of fruit presentation increases, which increases the required level of attention from the user. For walking, the participants were asked to walk slowly around a table. Note that since the prototype of the wristband is tethered, users were required to stay within an area of 2.5 × 2.5 m, using the 3 m long cable of vibrotactile wristband.</p><p>Six males were subjects for this experiment, none of whom participated in Experiment 3.1. Each subject was asked to sit while an experimenter helped adjust the wristband to the correct position, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig4">4</a>.</p><p>To find the minimum “off” period, the DOS of the signal was set to 200 ms and “off” period was set to 5 ms. Then, a signal was sent to vibration motor A and the subject was asked if he could feel the “off” period. If he could not feel the “off” period, the “off” period was increased by 5 ms. The procedure terminated when the subject could feel the “off” period. Each subject experienced this procedure three times.</p><p>A similar approach was employed to find minimum DOS. The “off” period of signal was set to 200 ms and DOS was set to 5 ms, and increased until the subject felt the “on” signal.</p><p>The results are presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig7">7</a> and Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-017-0309-0#Tab1">1</a>. The minimum DOS and “off” periods are the times that every subject feels the “on” and “off” pulse signals. The minimum DOS and “off” periods during sitting differ slightly from experiment 3.1 because the procedure to find the minimum “off” period was different. In experiment 3.2, the experimenter only asked subjects if they could feel the “on” and “off” periods. However, experiment 3.1 asked the subject to count the number of pulses during the experiment. Thus, the minimum DOS and “off” periods from experiment 3.2 were smaller than those found in experiment 3.1.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig7_HTML.gif?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig7_HTML.gif" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Minimum DOS and “off” period that subject detects</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Comparison of minimum DOS and “off” period during verity activities</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-017-0309-0/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-017-0309-0#Tab1">1</a> shows that the minimum DOS and “off” periods depend upon the task performed. When a task requires the subject to pay more attention, the minimum DOS and “off” periods increase.</p><p>The minimum DOS and “off” periods found in experiment 3.2 can be mapped into the results from experiment 3.1 to predict where the subject will detect signals with a high success rate. The line <i>x</i>–<i>x</i> and <i>y</i>–<i>y</i> in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig6">6</a> corresponded with the minimum “off” period and the minimum DOS, respectively. Then, the human response map can be used to design signal stimuli that are suitable for high recognition rates.</p></div></div></section><section aria-labelledby="Sec8"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Signal stimuli for human response</h2><div class="c-article-section__content" id="Sec8-content"><p>For the vibration motors used in the experimental wristband, the amplitude of vibration cannot be changed. Consequently, humans can only detect whether a vibration motor is “on” or “off.” By varying the amount of time that the motor is on or off as well as changing the activation sequence associated with the four motors, one can create vibrotactile stimulus signals. There are many possible ways to create signals to send information to human.</p><p>Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-017-0309-0#Sec9">4.1</a> shows a technique to create what this paper calls the “sequence” stimuli. It is desirable to create signals that humans can recognize with a high success rate. Consequently, these signals are created based on the human response map of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig6">6</a>.</p><p>Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10055-017-0309-0#Sec10">4.2</a> presents the “digital” code stimuli. A period of 700 ms on the human response map is used to create the digital signals. The code is represented by the long and short DOS, and is therefore similar to Morse code.</p><h3 class="c-article__sub-heading" id="Sec9">Sequence stimuli</h3><p>The signals for this class of stimuli utilize the four vibration motors on the wristband to create a sequence of stimuli. There is no limit to the number of signals that can be created by varying the time delay between the vibration motors and DOS of motors. Based on the results shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig6">6</a>, however, the signals should be within Zone A to maximize the likelihood of a human’s understanding the haptic input.</p><p>The signals are designed by creating a sequence of turning on each vibration motor A, B, C, D, A, etc. For example, one can set a time delay [Stimulus onset Asynchrony (SOA)] between A–B, B–C, C–D, and D–A motors to 1000 ms. This means that the period for the signal is 4000 ms (1000 ms × Number of motors). It should be noted that if the time delay of the period is increased, it is possible to send additional information. Also, it takes time for a human to sense and interpret the stimulus. Although the period for the signal is arbitrary, there is an attempt to balance the amount of information that is possible to send with the time it takes to send that information.</p><p>Based on the period line of 4000 ms on the human response map in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig8">8</a>, the DOS is selected along the line. According to van Erp (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8" href="/article/10.1007/s10055-017-0309-0#ref-CR10" id="ref-link-section-d103047e1025">2002</a>), humans cannot distinguish the difference between the vibration levels that differ by less than 20%. It was also verified from pretests that humans had difficulty recognizing a linear increment of DOS. Consequently, four DOS values, i.e., 50, 100, 500, and 3000 ms, were selected. These signals are shown on the period line of 4000 ms on Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig8">8</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig8_HTML.gif?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig8_HTML.gif" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Sequence stimuli on the human response map</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig9">9</a> shows the example of the signal on the period line of 4000 ms.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig9_HTML.gif?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig9_HTML.gif" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Example of the signal on the period line of 4000 ms</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Two other signal periods were specified: 2000 and 800 ms, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig8">8</a>. It should be noted the distance between period lines differs by more than 50% to help human to distinguish the difference between these periods. For the period line of 2000 ms, Zone A is relatively short. Consequently, a DOS of 100 and 500 ms remains in Zone A. The shortest signal period of 800 ms has only one DOS at 50 ms, pushing the limits of Zone A.</p><p>All of the sequence stimuli are plotted on the human response map in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig8">8</a>. The sequences of these signals are shown in the second column of Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-017-0309-0#Tab2">2</a>. Since the signals utilize multiple vibration motors on the wristband to create a repeating sequence of vibration motors A, B, C, and D, it is possible to create clockwise (CW) sequences (A–B–C–D–A) and counter clockwise (CCW) sequences. Thus 14 levels of sequence stimuli are created.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Sequence stimuli</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10055-017-0309-0/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>In this experiment, seven males were subjects for this experiment, none of whom participated in Experiment 3.1 or 3.2. Each subject was asked to sit while an experimenter helped adjust the wristband to the correct position, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig4">4</a>.</p><p>The experiment started by training the subject with the sequence stimuli (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10055-017-0309-0#Tab2">2</a>) for 15 min. To help the subject become familiar with each sequence stimulus, each subject was taught to sense the time delay between A–B, B–C, C–D, and D–A motors. Next, the subject was asked to sense the DOS of each vibration motor for each level of time delay. After training, the experimenter turned on the device and randomly sent the signals to the subject. The experiment of sending the stimuli to the subject continued without stopping. For each stimulus, the subject needed to answer the level of the sequence stimuli (signal number) and direction of the sequence stimuli (CW/CCW) within 8 s after the experimenter changed the level. Each subject experienced all sequence stimuli and repeated this procedure three times.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig10">10</a> shows that humans recognize the level of the sequence stimuli quite well. The success rate of assigning the correct level is more than 70%. However, people could not distinguish the direction of all signals. In particular, there were problems distinguishing the direction of the signals for levels #1, #6 and #7. The success rate for these signals was lower than 70%. There were eight signals where people answered both level and direction with a success rate greater than 70%. Thus, one can conclude that humans can recognize 10 levels of analog signal with a success rate greater than 80%. (#1, #2 CW/CCW, #3 CW/CCW, #4 CW/CCW, #5 CW/CCW, #7).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig10_HTML.gif?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig10_HTML.gif" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Success rate of analog stimuli signals</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Note: 1. Interviewing the subjects after the experiments, it was found that they could recognize signal level #1 because they felt the “overlay” of the vibration. They could recognize signal level #7 because they could feel the sequence stimulus, but it was difficult to tell the direction.</p><p>2. There was one subject that was unable to train successful, i.e., he did not fully understand the signal after training. He usually gave incorrect answers for signal #6.</p><p>Analysis of the designed sequence stimuli showed that is difficult for people to determine the direction of signals #1 and #7. A plausible explanation for this phenomenon is that these signals are close to Zones C and D, i.e., at the limit of high recognition success rates. Experiment 3.1 shows that humans have a difficult time distinguishing signals in these zones. Also, the pattern of signal #1 had motor “on” times that overlapped. Thus, if signals #1 and #7 were re-designed, the number of levels that human could recognize may be increased. Naturally, if the subjects were given more time for training before the experiment, one would expect the success rate to increase.</p><h3 class="c-article__sub-heading" id="Sec10">Digital codes</h3><p>This section describes the design of digital vibrotactile stimulus codes. These codes are designed based on the human response map of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig8">8</a> where a single digital signal is sent during a chosen period of time. The digital codes are designed with a period of 700 ms. Note that when the period is short, relatively few different signals can be sent. When the period is long, there is sufficient time to send additional information. While there is no limit to the number of codes that can be created, there is a way to predict successful interpretation of the codes.</p><p>Two types of pulses are used to create digital codes. The first is the short pulse. The DOS for experiments used short pulses that are either 150 or 200 ms. The second is the long pulse. The DOS for long pulses was 400 ms. Then, the off period between pulses is 150 or 200 ms. Digital codes are created by combining one to four short pulses and 0–2 long pulses. Each pulse is separated by an off period. The digital codes of the experiment are shown in the second column of the table in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig11">11</a>. For example, digital signal number 18′s second column shows the code, “black dot, black dot, red dash.” This means the motors are turned on with the sequence: short pulse (motors B and D), off, short pulse (motors B and D), off, long pulse (motors A and C).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig11_HTML.gif?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-017-0309-0/MediaObjects/10055_2017_309_Fig11_HTML.gif" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Digital codes of the digital stimuli and the results. Total average success rate = 78.70%</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-017-0309-0/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig11">11</a>, the color of the digital codes corresponds to the position of vibration motors. For the digital codes 1–12, all codes are black, which corresponds to the vibration motors A, B, C, and D, as shown on the right side of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig11">11</a>. This means all vibration motors vibrate simultaneously with the same codes.</p><p>For signals 13–21, red corresponds to vibration motors A and C, and black corresponds to vibration motors B and D, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig11">11</a>. A similar approach applies to digital codes 22–27. Red corresponds to vibration motor C, and black corresponds to the vibration motors A, B, and D.</p><p>Nine males were subjects for this experiment, none of whom participated in Experiment 3.1, 3.2, or 4.1. Each subject was asked to sit while an experimenter helped adjust the wristband to the correct position, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig4">4</a>.</p><p>The experiment started by training the subject with codes for a total time of 15 min. To help the subject recall the codes, the subject was allowed to look at the table shown in the first two columns of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig11">11</a> during both training and experiment.</p><p>After the training, the experimenter randomly sent the signals to the subject without repeating them. Then, the subject responded with the number of the signal within 8 s after each transition. The experimenter randomly selected 12 signals to test for each subject.</p><p>The results of the experiment are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-017-0309-0#Fig11">11</a>. For the signal numbers 1–12, signal number 9 has a success rate of only 25%. This may be because the beat (short–long) seems too similar to signal numbers 2, 6, and 12. Still, the average success rate of these signals is 77.08%.</p><p>For signal numbers 13–21, the average success rate is 86.11%. The lowest success rate was achieved with signal number 21 because subjects confused the position between the motor A–C and motor B–D.</p><p>For signal numbers 22–23, the average success rate is 70.83%. In this case, the subjects confused the beat of signal numbers 23 and 26 since the number of pulses is the same.</p><p>There are 12 signals with a success rate of 100%. The average success rate for all signals is 78.70%. The average success rate of signal numbers 13–21 is 86.11%, which is highest. (If the subjects have more time to train, it is reasonable to expect that the success rate will increase.)</p><p>This section shows an example of sending information with digital codes (one datum per digital code). It is clear that there are many ways to code signals by combining a code with the DOS for specific vibration motors. To design the code, however, it is important to take into account how a human responds to tactile signals. If there are too many patterns in too short a time period, a human may not be able to recognize the code. The human response map should be used to inform the design of the codes. Also, the training is important for this case. Without training, humans could not effectively classify any of the codes. Similar to Morse code, memorization of the desired digital code during training improves the success rate.</p><h3 class="c-article__sub-heading" id="Sec11">Summary of signal stimuli</h3><p>Two techniques to create signal stimuli for sending information to a human are described in this paper. The first approach is the sequence stimuli, where multiple vibration motors on a wristband create continuous sequence stimuli. With a sequence stimulus, a human can directly sense the signal without decoding. This type of stimulus is useful for many applications. For example, when backing up a car, ultrasonic sensors of a modern car measure distance between an obstacle and rear bumper. This range information can be sent to the driver using sequence stimuli.</p><p>The second approach uses digital codes. One datum can be sent by one digital code. Additional information can be encoded through multiple digital codes. A human may need some time to understand these digital codes. However, it is possible to learn a large number of codes, similar to Morse code, with sufficient training. Digital codes may be suitable for sending information for picking items for shipments or selecting specific menu items in a restaurant.</p></div></div></section><section aria-labelledby="Sec12"><div class="c-article-section" id="Sec12-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec12">Conclusion</h2><div class="c-article-section__content" id="Sec12-content"><p>This paper proposes a new technique to design vibrotactile stimuli that allow humans to visualize haptic information through a wristband. The human response map for vibration motors during sitting was determined experimentally. The map shows the zones where humans can and cannot respond to vibrotactile stimuli with a reasonable success rate, i.e., it found the minimum DOS and “off” vibration motor periods for subjects. It was also determined that the size of the zones on the map depends on the level of engagement required by the activity. An approach to predict the human response map for various activities is shown. The map can inform the design of useful signals for effective vibrotactile information transfer to humans.</p><p>Two encoding techniques, sequence stimuli and digital codes, are used to create vibrotactile signal stimuli. These signals are created based on the human response map during sitting. Experiment 4.1 showed that humans can recognize 10 levels of sequence stimuli. Experiment 4.2 showed the 27 examples of digital codes. The average success rate to classify these codes is 78.70%. (Note that results are limited by the use of a homogenous set of nearly participants, i.e., healthy males 20–22 years old.)</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Akita J, Ono T, Ito K, Okamoto M (2014) Touch at a distance: simple perception aid device with user’s explorer" /><p class="c-article-references__text" id="ref-CR1">Akita J, Ono T, Ito K, Okamoto M (2014) Touch at a distance: simple perception aid device with user’s explorer action. In: SIGGRAPH Asia 2014 Emerging Technologies. ACM</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="S. Bosman, B. Groenendaal, JW. Findlater, T. Visser, M. Graaf, P. Markopoulos, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Bosman S, Groenendaal B, Findlater JW, Visser T, de Graaf M, Markopoulos P (2003) Gentleguide: an exploration " /><p class="c-article-references__text" id="ref-CR2">Bosman S, Groenendaal B, Findlater JW, Visser T, de Graaf M, Markopoulos P (2003) Gentleguide: an exploration of haptic output for indoors pedestrian guidance, human computer interaction with mobile devices and services. Springer, Berlin, pp 358–362</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Gentleguide%3A%20an%20exploration%20of%20haptic%20output%20for%20indoors%20pedestrian%20guidance%2C%20human%20computer%20interaction%20with%20mobile%20devices%20and%20services&amp;pages=358-362&amp;publication_year=2003&amp;author=Bosman%2CS&amp;author=Groenendaal%2CB&amp;author=Findlater%2CJW&amp;author=Visser%2CT&amp;author=Graaf%2CM&amp;author=Markopoulos%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Brewster S, Brown LM (2004) Tactons: structured tactile messages for non-visual information display. In: Proce" /><p class="c-article-references__text" id="ref-CR3">Brewster S, Brown LM (2004) Tactons: structured tactile messages for non-visual information display. In: Proceedings of the fifth conference on Australasian user interface, vol 28. Australian Computer Society, Inc., pp 15–23</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chantranuwathana S, Sornumpol P (2005) One-DOF arm movement guidance using vibrotactile feedback. In: The 19th" /><p class="c-article-references__text" id="ref-CR4">Chantranuwathana S, Sornumpol P (2005) One-DOF arm movement guidance using vibrotactile feedback. In: The 19th conference of mechanical engineering network of thailand, Phuket, Thailand</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Guo W, Wei N, Chen I-M, Ding ZQ, Yeo SH (2009) Intuitive vibro-tactile feedback for human body movement guidan" /><p class="c-article-references__text" id="ref-CR5">Guo W, Wei N, Chen I-M, Ding ZQ, Yeo SH (2009) Intuitive vibro-tactile feedback for human body movement guidance. In: Proceeding of the 2009 IEEE international conference on robotics and biomimetics, Guilin, China, pp 135–140</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="GW. Guyot, FD. Johnson, C. Weaver, " /><meta itemprop="datePublished" content="1982" /><meta itemprop="headline" content="Guyot GW, Johnson FD, Weaver C (1982) Two-point tactual discrimination on the back: a signal-detection approac" /><p class="c-article-references__text" id="ref-CR6">Guyot GW, Johnson FD, Weaver C (1982) Two-point tactual discrimination on the back: a signal-detection approach. Percept Mot Skills 54(3c):1289–1290</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.2466%2Fpms.1982.54.3c.1289" aria-label="View reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Two-point%20tactual%20discrimination%20on%20the%20back%3A%20a%20signal-detection%20approach&amp;journal=Percept%20Mot%20Skills&amp;volume=54&amp;issue=3c&amp;pages=1289-1290&amp;publication_year=1982&amp;author=Guyot%2CGW&amp;author=Johnson%2CFD&amp;author=Weaver%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kohli L, Niwa M, Noma H, Susami K, Yanagida Y, Lindeman R W, Kume Y (2006) Towards effective information displ" /><p class="c-article-references__text" id="ref-CR7">Kohli L, Niwa M, Noma H, Susami K, Yanagida Y, Lindeman R W, Kume Y (2006) Towards effective information display using vibrotactile apparent motion. In: Haptic interfaces for virtual environment and teleoperator systems, 2006 14th Symposium on IEEE, pp 445–451</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Lieberman, C. Breazeal, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Lieberman J, Breazeal C (2007) TIKL: development of a wearable vibrotactile feedback suit for improved human m" /><p class="c-article-references__text" id="ref-CR8">Lieberman J, Breazeal C (2007) TIKL: development of a wearable vibrotactile feedback suit for improved human motor learning. IEEE Trans Robot 23(5):919–926</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTRO.2007.907481" aria-label="View reference 8">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=TIKL%3A%20development%20of%20a%20wearable%20vibrotactile%20feedback%20suit%20for%20improved%20human%20motor%20learning&amp;journal=IEEE%20Trans%20Robot&amp;volume=23&amp;issue=5&amp;pages=919-926&amp;publication_year=2007&amp;author=Lieberman%2CJ&amp;author=Breazeal%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RW. Lindeman, Y. Yanagida, H. Noma, K. Hosaka, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Lindeman RW, Yanagida Y, Noma H, Hosaka K (2006) Wearable vibrotactile systems for virtual contact and informa" /><p class="c-article-references__text" id="ref-CR9">Lindeman RW, Yanagida Y, Noma H, Hosaka K (2006) Wearable vibrotactile systems for virtual contact and information display. Virtual Real 9(2):203–213</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10055-005-0010-6" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Wearable%20vibrotactile%20systems%20for%20virtual%20contact%20and%20information%20display&amp;journal=Virtual%20Real&amp;volume=9&amp;issue=2&amp;pages=203-213&amp;publication_year=2006&amp;author=Lindeman%2CRW&amp;author=Yanagida%2CY&amp;author=Noma%2CH&amp;author=Hosaka%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer " /><p class="c-article-references__text" id="ref-CR10">Matscheko M, Ferscha A, Riener A, Lehner M (2010) Tactor placement in wrist worn wearables, wearable computer (ISWC). In: 2010 International Symposium on IEEE, pp 1–8</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="McDaniel T, Krishna S, Colbry D, Panchanathan S (2009) Using tactile rhythm to convey interpersonal distances " /><p class="c-article-references__text" id="ref-CR11">McDaniel T, Krishna S, Colbry D, Panchanathan S (2009) Using tactile rhythm to convey interpersonal distances to individuals who are blind. Im: CHI 2009, Boston, MA, USA, pp 4669–4674</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Phanomchoeng, R. Rajamani, J. Hourdos, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Phanomchoeng G, Rajamani R, Hourdos J (2010) Directional sound for long distance auditory warnings from a high" /><p class="c-article-references__text" id="ref-CR12">Phanomchoeng G, Rajamani R, Hourdos J (2010) Directional sound for long distance auditory warnings from a highway construction work zone. IEEE Trans Veh Technol 59(5):2266–2276</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTVT.2010.2042090" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Directional%20sound%20for%20long%20distance%20auditory%20warnings%20from%20a%20highway%20construction%20work%20zone&amp;journal=IEEE%20Trans%20Veh%20Technol&amp;volume=59&amp;issue=5&amp;pages=2266-2276&amp;publication_year=2010&amp;author=Phanomchoeng%2CG&amp;author=Rajamani%2CR&amp;author=Hourdos%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="I. Poupyrev, S. Maruyama, J. Rekimoto, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Poupyrev I, Maruyama S, Rekimoto J (2002) Ambient touch: designing tactile interfaces for handheld devices. AC" /><p class="c-article-references__text" id="ref-CR13">Poupyrev I, Maruyama S, Rekimoto J (2002) Ambient touch: designing tactile interfaces for handheld devices. ACM, New York, pp 51–60</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Ambient%20touch%3A%20designing%20tactile%20interfaces%20for%20handheld%20devices&amp;pages=51-60&amp;publication_year=2002&amp;author=Poupyrev%2CI&amp;author=Maruyama%2CS&amp;author=Rekimoto%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="I. Poupyrev, M. Okabe, S. Maruyama, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Poupyrev I, Okabe M, Maruyama S (2004) Haptic feedback for pen computing: directions and strategies. ACM, New " /><p class="c-article-references__text" id="ref-CR14">Poupyrev I, Okabe M, Maruyama S (2004) Haptic feedback for pen computing: directions and strategies. ACM, New York, pp 1309–1312</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Haptic%20feedback%20for%20pen%20computing%3A%20directions%20and%20strategies&amp;pages=1309-1312&amp;publication_year=2004&amp;author=Poupyrev%2CI&amp;author=Okabe%2CM&amp;author=Maruyama%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rattanachotithavorn S, Sae-Ong P, Wannasuphoprasit W (2011) Experimental study of tactile stimulating system i" /><p class="c-article-references__text" id="ref-CR15">Rattanachotithavorn S, Sae-Ong P, Wannasuphoprasit W (2011) Experimental study of tactile stimulating system in back area for warning purpose. In: The 5th conference of TRS conference on robotics and industrial technology, Bangkok, Thailand</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Scheggi, F. Morbidi, D. Prattichizzo, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Scheggi S, Morbidi F, Prattichizzo D (2014) Human-robot formation control via visual and vibrotactile haptic f" /><p class="c-article-references__text" id="ref-CR16">Scheggi S, Morbidi F, Prattichizzo D (2014) Human-robot formation control via visual and vibrotactile haptic feedback. IEEE Trans Haptics 7(4):499–511</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTOH.2014.2332173" aria-label="View reference 16">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Human-robot%20formation%20control%20via%20visual%20and%20vibrotactile%20haptic%20feedback&amp;journal=IEEE%20Trans%20Haptics&amp;volume=7&amp;issue=4&amp;pages=499-511&amp;publication_year=2014&amp;author=Scheggi%2CS&amp;author=Morbidi%2CF&amp;author=Prattichizzo%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sergi F, Accoto D, Compolo D, Guglielmelli E (2008) Forearm orientation guidance with a vibrotactile feedback " /><p class="c-article-references__text" id="ref-CR17">Sergi F, Accoto D, Compolo D, Guglielmelli E (2008) Forearm orientation guidance with a vibrotactile feedback bracelet: on the directionality of tactile motor communication. In: Proceedings of the 2nd Biennial IEEE/RAS-EMBS international conference on biomedical robotics and biomechatronics, Scottsdale, AZ, USA, pp 433–438</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AA. Stanley, KJ. Kuchenbecker, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Stanley AA, Kuchenbecker KJ (2012) Evaluation of tactile feedback methods for wrist rotation guidance. IEEE Tr" /><p class="c-article-references__text" id="ref-CR18">Stanley AA, Kuchenbecker KJ (2012) Evaluation of tactile feedback methods for wrist rotation guidance. IEEE Trans Haptics 5(3):240–251</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTOH.2012.33" aria-label="View reference 18">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Evaluation%20of%20tactile%20feedback%20methods%20for%20wrist%20rotation%20guidance&amp;journal=IEEE%20Trans%20Haptics&amp;volume=5&amp;issue=3&amp;pages=240-251&amp;publication_year=2012&amp;author=Stanley%2CAA&amp;author=Kuchenbecker%2CKJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Szymczak D, Magnusson C, Rassmus-Grohn K (2012) Guiding tourists through haptic interaction: vibration feedbac" /><p class="c-article-references__text" id="ref-CR19">Szymczak D, Magnusson C, Rassmus-Grohn K (2012) Guiding tourists through haptic interaction: vibration feedback in the lund time machine. In: Isokoski P, Springare J (eds) EuroHaptics 2012, Part II. LNCS, vol 7283, pp 157–162</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HZ. Tan, MA. Srinivasan, B. Eberman, B. Cheng, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Tan HZ, Srinivasan MA, Eberman B, Cheng B (1994) Human factors for the design of force-reflecting haptic inter" /><p class="c-article-references__text" id="ref-CR20">Tan HZ, Srinivasan MA, Eberman B, Cheng B (1994) Human factors for the design of force-reflecting haptic interfaces. Dyn Syst Control 55(1):353–359</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20factors%20for%20the%20design%20of%20force-reflecting%20haptic%20interfaces&amp;journal=Dyn%20Syst%20Control&amp;volume=55&amp;issue=1&amp;pages=353-359&amp;publication_year=1994&amp;author=Tan%2CHZ&amp;author=Srinivasan%2CMA&amp;author=Eberman%2CB&amp;author=Cheng%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Tsukada K, Yasumura M (2004) Activebelt: belt-type wearable tactile display for directional navigation. In: In" /><p class="c-article-references__text" id="ref-CR21">Tsukada K, Yasumura M (2004) Activebelt: belt-type wearable tactile display for directional navigation. In: International conference on ubiquitous computing. Lecture notes in computer science, vol 3205. Springer, Heidelberg, pp 384–399.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="van Erp JBF (2001) Tactile navigation display, haptic human–computer interaction. Lecture notes in computer sc" /><p class="c-article-references__text" id="ref-CR22">van Erp JBF (2001) Tactile navigation display, haptic human–computer interaction. Lecture notes in computer science, vol 2058, pp 165–173</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="van Erp JBF (2002) Guideline for the use of vibro-tactile displays in human computer interaction. In: Proceedi" /><p class="c-article-references__text" id="ref-CR23">van Erp JBF (2002) Guideline for the use of vibro-tactile displays in human computer interaction. In: Proceedings of Eurohaptics, pp 18–22</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JBF. Erp, HAHC. Veen, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="van Erp JBF, van Veen HAHC (2004) Vibrotactile in-vehicle navigation system. Transp Res Part F: Traffic Psycho" /><p class="c-article-references__text" id="ref-CR24">van Erp JBF, van Veen HAHC (2004) Vibrotactile in-vehicle navigation system. Transp Res Part F: Traffic Psychol Behav 7(4):247–256. doi:<a href="https://doi.org/10.1016/j.trf.2004.09.003">10.1016/j.trf.2004.09.003</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.trf.2004.09.003" aria-label="View reference 24">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Vibrotactile%20in-vehicle%20navigation%20system&amp;journal=Transp%20Res%20Part%20F%3A%20Traffic%20Psychol%20Behav&amp;doi=10.1016%2Fj.trf.2004.09.003&amp;volume=7&amp;issue=4&amp;pages=247-256&amp;publication_year=2004&amp;author=Erp%2CJBF&amp;author=Veen%2CHAHC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JBF. Erp, HAHC. Veen, C. Jansen, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="van Erp JBF, van Veen HAHC, Jansen C (2005) Waypoint navigation with a vibrotactile waist belt. ACM Trans Appl" /><p class="c-article-references__text" id="ref-CR25">van Erp JBF, van Veen HAHC, Jansen C (2005) Waypoint navigation with a vibrotactile waist belt. ACM Trans Appl Percept 2(2):106–117</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F1060581.1060585" aria-label="View reference 25">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Waypoint%20navigation%20with%20a%20vibrotactile%20waist%20belt&amp;journal=ACM%20Trans%20Appl%20Percept&amp;volume=2&amp;issue=2&amp;pages=106-117&amp;publication_year=2005&amp;author=Erp%2CJBF&amp;author=Veen%2CHAHC&amp;author=Jansen%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Yang U, Jang Y, Kim GJ (2002) Designing a vibro-tactile wear for close range interaction for vr-based motion t" /><p class="c-article-references__text" id="ref-CR26">Yang U, Jang Y, Kim GJ (2002) Designing a vibro-tactile wear for close range interaction for vr-based motion training. In: International conference on artificial reality and telexistence, pp 4–9</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Yano H, Miyamoto Y, Iwata H (2009) Haptic interface for perceiving remote object using a laser range finder. I" /><p class="c-article-references__text" id="ref-CR27">Yano H, Miyamoto Y, Iwata H (2009) Haptic interface for perceiving remote object using a laser range finder. In: EuroHaptics conference, 2009 and symposium on haptic interfaces for virtual environment and teleoperator systems. World Haptics 2009. Third Joint IEEE, pp 196–201. IEEE</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-017-0309-0-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>This paper was supported by the Chulalongkorn University Strategic Research Grant CU-57-074-AS.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Department of Mechanical Engineering, Chulalongkorn University, Bangkok, 10330, Thailand</p><p class="c-article-author-affiliation__authors-list">Gridsada Phanomchoeng &amp; Ratchatin Chancharoen</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Department of Mechanical Engineering, University of New Mexico, Albuquerque, NM, 87131, USA</p><p class="c-article-author-affiliation__authors-list">Ron Lumia</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Gridsada-Phanomchoeng"><span class="c-article-authors-search__title u-h3 js-search-name">Gridsada Phanomchoeng</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Gridsada+Phanomchoeng&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Gridsada+Phanomchoeng" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Gridsada+Phanomchoeng%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Ratchatin-Chancharoen"><span class="c-article-authors-search__title u-h3 js-search-name">Ratchatin Chancharoen</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Ratchatin+Chancharoen&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Ratchatin+Chancharoen" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ratchatin+Chancharoen%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Ron-Lumia"><span class="c-article-authors-search__title u-h3 js-search-name">Ron Lumia</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Ron+Lumia&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Ron+Lumia" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ron+Lumia%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-017-0309-0/email/correspondent/c1/new">Gridsada Phanomchoeng</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Developing%20vibrotactile%20haptic%20stimuli%20based%20on%20measured%20human%20capabilities&amp;author=Gridsada%20Phanomchoeng%20et%20al&amp;contentID=10.1007%2Fs10055-017-0309-0&amp;publication=1359-4338&amp;publicationDate=2017-02-08&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10055-017-0309-0" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10055-017-0309-0" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Phanomchoeng, G., Chancharoen, R. &amp; Lumia, R. Developing vibrotactile haptic stimuli based on measured human capabilities.
                    <i>Virtual Reality</i> <b>21, </b>203–212 (2017). https://doi.org/10.1007/s10055-017-0309-0</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-017-0309-0.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-12-02">02 December 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2017-02-02">02 February 2017</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2017-02-08">08 February 2017</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2017-11">November 2017</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-017-0309-0" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-017-0309-0</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Vibrotactile</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Haptic</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Haptic wrist</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Haptic belt</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Tactile</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Tactons</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Human computer interaction</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-017-0309-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=309;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

