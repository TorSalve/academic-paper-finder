<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="Medical interface research at the HIT Lab"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="The Human Interface Technology Laboratory (HIT Lab) is a multi-disciplinary research and development lab whose work centers on novel approaches to human interface technology. Lab researchers..."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/10055/12/4.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10055"/>

    <meta name="dc.title" content="Medical interface research at the HIT Lab"/>

    <meta name="dc.source" content="Virtual Reality 2008 12:4"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2008-11-28"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2008 Springer-Verlag London Limited"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="The Human Interface Technology Laboratory (HIT Lab) is a multi-disciplinary research and development lab whose work centers on novel approaches to human interface technology. Lab researchers represent a wide range of disciplines from across the University of Washington campus, including engineering, medicine, education, social sciences, architecture, and the design arts. We describe here a representative sampling of past and current HIT Lab research and development activities related to medicine, including virtual reality and augmented/mixed reality applications for direct patient therapy, tools for basic medical education and procedure training, novel approaches to medical image acquisition and display, and new visualization methods in medical informatics."/>

    <meta name="prism.issn" content="1434-9957"/>

    <meta name="prism.publicationName" content="Virtual Reality"/>

    <meta name="prism.publicationDate" content="2008-11-28"/>

    <meta name="prism.volume" content="12"/>

    <meta name="prism.number" content="4"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="201"/>

    <meta name="prism.endingPage" content="214"/>

    <meta name="prism.copyright" content="2008 Springer-Verlag London Limited"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10055-008-0107-9"/>

    <meta name="prism.doi" content="doi:10.1007/s10055-008-0107-9"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10055-008-0107-9.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10055-008-0107-9"/>

    <meta name="citation_journal_title" content="Virtual Reality"/>

    <meta name="citation_journal_abbrev" content="Virtual Reality"/>

    <meta name="citation_publisher" content="Springer-Verlag"/>

    <meta name="citation_issn" content="1434-9957"/>

    <meta name="citation_title" content="Medical interface research at the HIT Lab"/>

    <meta name="citation_volume" content="12"/>

    <meta name="citation_issue" content="4"/>

    <meta name="citation_publication_date" content="2008/12"/>

    <meta name="citation_online_date" content="2008/11/28"/>

    <meta name="citation_firstpage" content="201"/>

    <meta name="citation_lastpage" content="214"/>

    <meta name="citation_article_type" content="Original Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10055-008-0107-9"/>

    <meta name="DOI" content="10.1007/s10055-008-0107-9"/>

    <meta name="citation_doi" content="10.1007/s10055-008-0107-9"/>

    <meta name="description" content="The Human Interface Technology Laboratory (HIT Lab) is a multi-disciplinary research and development lab whose work centers on novel approaches to human in"/>

    <meta name="dc.creator" content="Suzanne Weghorst"/>

    <meta name="dc.creator" content="Eric Seibel"/>

    <meta name="dc.creator" content="Peter Oppenheimer"/>

    <meta name="dc.creator" content="Hunter Hoffman"/>

    <meta name="dc.creator" content="Brian Schowengerdt"/>

    <meta name="dc.creator" content="Thomas A. Furness "/>

    <meta name="dc.subject" content="Computer Graphics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Image Processing and Computer Vision"/>

    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>

    <meta name="citation_reference" content="citation_journal_title=Physiotherapy; citation_title=The effect of visual cues on the gait of independently mobile Parkinson&#8217;s disease patients; citation_author=S Bagley, B Kelly, N Tunnicliffe, G Turnbull, JM Walker; citation_volume=77; citation_publication_date=1991; citation_pages=415-420; citation_doi=10.1016/S0031-9406(10)62035-4; citation_id=CR1"/>

    <meta name="citation_reference" content="Berg D, Raugi G, Gladstone H, Berkley J, Ganter M, Turkiyyah G (2001) Virtual reality simulators for dermatologic surgery: measuring their validity as a teaching tool. In: Proceedings of medicine meets virtual reality 2001, Newport Beach, CA"/>

    <meta name="citation_reference" content="citation_journal_title=Virtual Real; citation_title=Banded matrix approach to finite element modeling for soft tissue simulation; citation_author=J Berkley, S Weghorst, H Gladstone, G Raugi, D Berg, M Ganter; citation_volume=4; citation_publication_date=1999; citation_pages=203-212; citation_doi=10.1007/BF01418156; citation_id=CR3"/>

    <meta name="citation_reference" content="Berkley J, Oppenheimer P, Weghorst S, Berg D, Raugi G, Haynor D, Ganter M, Brooking C, Turkiyyah G (2000) Creating fast finite element models from medical images. In: Proceedings of medicine meets virtual reality 2000, Newport Beach, CA"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Vis Comput Graph; citation_title=Real-time finite element modeling for surgery simulation: an application to virtual suturing; citation_author=J Berkley, G Turkiyyah, D Berg, M Ganter, S Weghorst; citation_volume=10; citation_issue=3; citation_publication_date=2004; citation_pages=1-12; citation_doi=10.1109/TVCG.2004.1272730; citation_id=CR5"/>

    <meta name="citation_reference" content="Billinghurst M, Kato H (1999) Collaborative mixed reality. In: Proceedings of international symposium on mixed reality (ISMR &#8216;99). Mixed reality&#8212;merging real and virtual worlds. Yokohama, Japan, pp 261&#8211;284"/>

    <meta name="citation_reference" content="Billinghurst M, Kato H, Poupyrev I (2001) MagicBook: transitioning between reality and virtuality. Presented at CHI 2001, March 30&#8211;April 5, 2001, Seattle, WA"/>

    <meta name="citation_reference" content="citation_journal_title=J Soc Inf Disp; citation_title=Low-cost wearable low vision aid using a handmade retinal light scanning microdisplay; citation_author=R Bryant, EJ Seibel, CM Lee, KE Schroder; citation_volume=12; citation_issue=4; citation_publication_date=2004; citation_pages=397; citation_doi=10.1889/1.1847738; citation_id=CR8"/>

    <meta name="citation_reference" content="Campbell BD, Mete HO, Furness T, Weghorst S, Zabinsky Z (2008) Emergency response planning and training through interactive simulation and visualization with decision support. In: Proceedings of 2008 IEEE conference on technologies for homeland security. Boston, MA, pp 176&#8211;180"/>

    <meta name="citation_reference" content="citation_journal_title=Behav Res Ther; citation_title=Virtual reality and tactile augmentation in the treatment of spider phobia: a case study; citation_author=AS Carlin, HG Hoffman, S Weghorst; citation_volume=35; citation_publication_date=1997; citation_pages=153-158; citation_doi=10.1016/S0005-7967(96)00085-X; citation_id=CR10"/>

    <meta name="citation_reference" content="citation_journal_title=J Clin Psychiatry; citation_title=Virtual reality exposure therapy for the treatment of posttraumatic stress disorder following September 11, 2001; citation_author=J Difede, J Cukor, N Jayasinghe, I Patt, S Jedel, L Spielman, C Giosan, HG Hoffman; citation_volume=68; citation_publication_date=2007; citation_pages=1639-1647; citation_id=CR11"/>

    <meta name="citation_reference" content="citation_journal_title=Cyberpsychol Behav; citation_title=Virtual reality exposure therapy for World Trade Center post traumatic stress disorder: a case report; citation_author=J Difede, HG Hoffman; citation_volume=5; citation_publication_date=2002; citation_pages=529-536; citation_doi=10.1089/109493102321018169; citation_id=CR12"/>

    <meta name="citation_reference" content="citation_journal_title=Opt Express; citation_title=Three-dimensional imaging of single isolated cell nuclei using optical projection tomography; citation_author=M Fauver, EJ Seibel, JR Rahn, MG Meyer, FW Patten, T Neumann, AC Nelson; citation_volume=13; citation_issue=11; citation_publication_date=2005; citation_pages=4210-4223; citation_doi=10.1364/OPEX.13.004210; citation_id=CR13"/>

    <meta name="citation_reference" content="Furness TA (1986) The super cockpit and human factors challenges. In: Ung M (ed) Proceedings of human factors society 30th annual meeting. Dayton, OH, pp 48&#8211;52"/>

    <meta name="citation_reference" content="Furness T (1988) Harnessing virtual space. In: Proceedings of SID international symposium digest of technical papers. Playa del Rey, CA, pp 4&#8211;7"/>

    <meta name="citation_reference" content="citation_journal_title=Behav Res Ther; citation_title=Virtual reality in the treatment of spider phobia: a controlled study; citation_author=A Garcia-Palacios, HG Hoffman, C Carlin, TA Furness, C Botella-Arbona; citation_volume=40; citation_issue=9; citation_publication_date=2002; citation_pages=983-993; citation_doi=10.1016/S0005-7967(01)00068-7; citation_id=CR16"/>

    <meta name="citation_reference" content="Gillet A, Goodsell D, Sanner MF, Stoffler D, Weghorst S, Winn W, Olson AJ (2004) Computer-linked autofabricated 3D model for teaching structural biology. In: Proceedings of SIGGRAPH 2004, Los Angeles, CA"/>

    <meta name="citation_reference" content="citation_title=Physically touching virtual objects using tactile augmentation enhances the realism of virtual environments. In: Proceedings of the IEEE virtual reality annual international symposium &#8216;98, Atlanta, GA; citation_publication_date=1998; citation_id=CR19; citation_author=HG Hoffman; citation_publisher=IEEE Computer Society"/>

    <meta name="citation_reference" content="Hoffman H (2004) Virtual-reality therapy. Sci Am"/>

    <meta name="citation_reference" content="citation_journal_title=Pain; citation_title=Use of virtual reality for adjunctive treatment of adolescent burn pain during wound care: a case report; citation_author=HG Hoffman, JN Doctor, DR Patterson, GJ Carrougher, TA Furness; citation_volume=85; citation_publication_date=2000; citation_pages=305-309; citation_doi=10.1016/S0304-3959(99)00275-4; citation_id=CR21"/>

    <meta name="citation_reference" content="citation_journal_title=Clin J Pain; citation_title=The effectiveness of virtual reality based pain control with multiple treatments; citation_author=HG Hoffman, DR Patterson, GJ Carrougher, S Sharar; citation_volume=17; citation_publication_date=2001; citation_pages=229-235; citation_doi=10.1097/00002508-200109000-00007; citation_id=CR22"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Hum Comput Interact; citation_title=Interfaces that heal: coupling real and virtual objects to cure spider phobia; citation_author=HG Hoffman, A Garcia-Palacios, VA Carlin, J Furness, null Botella-Arbona; citation_volume=16; citation_publication_date=2003; citation_pages=283-300; citation_doi=10.1207/S15327590IJHC1602_08; citation_id=CR23"/>

    <meta name="citation_reference" content="citation_journal_title=Int J Hum Comput Interact; citation_title=Immersive virtual reality for reducing experimental ischemic pain; citation_author=HG Hoffman, A Garcia-Palacios, VA Kapa, J Beecher, SR Sharar; citation_volume=15; citation_publication_date=2003; citation_pages=469-486; citation_doi=10.1207/S15327590IJHC1503_10; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=Pain; citation_title=Manipulating presence influences the magnitude of virtual reality analgesia; citation_author=HG Hoffman, SR Sharar, B Coda, JJ Everett, M Ciol, T Richards, DR Patterson; citation_volume=111; citation_issue=1&#8211;2; citation_publication_date=2004; citation_pages=162-168; citation_doi=10.1016/j.pain.2004.06.013; citation_id=CR24"/>

    <meta name="citation_reference" content="citation_journal_title=J Clin Psychol; citation_title=Water-friendly virtual reality pain control during wound care; citation_author=HG Hoffman, DR Patterson, J Magula, GJ Carrougher, K Zeltzer, S Dagadakis, SR Sharar; citation_volume=60; citation_issue=2; citation_publication_date=2004; citation_pages=189-195; citation_doi=10.1002/jclp.10244; citation_id=CR25"/>

    <meta name="citation_reference" content="citation_journal_title=Cyberpsychol Behav; citation_title=A magnet-friendly virtual reality fiberoptic image delivery system; citation_author=HG Hoffman, TL Richards, J Magula, EJ Seibel, C Hayes, M Mathis, SR Sharar, K Maravilla; citation_volume=6; citation_publication_date=2004; citation_pages=645-648; citation_doi=10.1089/109493103322725423; citation_id=CR55"/>

    <meta name="citation_reference" content="citation_journal_title=Anesth Analg; citation_title=The analgesic effects of opioids and immersive virtual reality distraction: evidence from subjective and functional brain imaging assessments; citation_author=HG Hoffman, TL Richards, T Van Oostrom, BA Coda, MP Jensen, DK Blough, SR Sharar; citation_volume=105; citation_publication_date=2007; citation_pages=1776-1783; citation_doi=10.1213/01.ane.0000270205.45146.db; citation_id=CR56"/>

    <meta name="citation_reference" content="citation_journal_title=Anesth Analg; citation_title=Virtual reality pain control during burn wound debridement in the hydrotank; citation_author=HG Hoffman, DR Patterson, E Seibel, M Soltani, L Jewett-Leahy, SR Sharar; citation_volume=24; citation_issue=4; citation_publication_date=2008; citation_pages=299-304; citation_id=CR57"/>

    <meta name="citation_reference" content="citation_journal_title=Eur Neurol; citation_title=Clinicophysiological features of akinesia; citation_author=H Imai; citation_volume=36; citation_issue=Suppl 1; citation_publication_date=1996; citation_pages=9-12; citation_doi=10.1159/000118877; citation_id=CR26"/>

    <meta name="citation_reference" content="citation_journal_title=J Rehabil Res Dev; citation_title=Virtual cues and functional mobility of people with Parkinson&#8217;s disease: a single-subject pilot study; citation_author=TA Kaminsky, BJ Dudgeon, FF Billingsley, PH Mitchell, SJ Weghorst; citation_volume=44; citation_issue=3; citation_publication_date=2007; citation_pages=437-448; citation_doi=10.1682/JRRD.2006.09.0109; citation_id=CR27"/>

    <meta name="citation_reference" content="citation_journal_title=Stud Health Technol Inform; citation_title=New interface metaphors for complex information space visualization: an ECG monitor object prototype; citation_author=S Kaufman, I Poupyrev, E Miller, M Billinghurst, P Oppenheimer, S Weghorst; citation_volume=39; citation_publication_date=1997; citation_pages=131-140; citation_id=CR28"/>

    <meta name="citation_reference" content="citation_journal_title=Brain; citation_title=Stride length regulation in Parkinson&#8217;s disease: the use of extrinsic, visual cues; citation_author=GN Lewis, WD Byblow, SE Walt; citation_volume=123; citation_publication_date=2000; citation_pages=2077-2090; citation_doi=10.1093/brain/123.10.2077; citation_id=CR29"/>

    <meta name="citation_reference" content="Lindblad AJ, Turkiyyah GM, Weghorst SJ, Berg D (2006) Real-time finite element based virtual tissue cutting. Presented at MMVR 2006, 24&#8211;27 January 2006, Long Beach, CA"/>

    <meta name="citation_reference" content="citation_journal_title=J CyberTher Rehabil; citation_title=Pain control during wound care for combat-related burn injuries using custom articulated arm mounted virtual reality goggles; citation_author=C Maani, HG Hoffman, PA DeSocio, M Morrow, C Galin, J Magula, A Maiers, K Gaylord; citation_volume=1; citation_publication_date=2008; citation_pages=193-198; citation_id=CR31"/>

    <meta name="citation_reference" content="citation_title=Understanding biochemistry with augmented reality; citation_inbook_title=Proceedings of world conference on educational multimedia, hypermedia and telecommunications 2007; citation_publication_date=2007; citation_pages=4235-4239; citation_id=CR32; citation_author=E Medina; citation_author=Y Chen; citation_author=S Weghorst; citation_publisher=AACE"/>

    <meta name="citation_reference" content="Mete HO, Zabinsky ZB (2007) Preparing for disasters: medical supply location and distribution. In: Proceedings of the INFORMS conference, Seattle, WA, 2007"/>

    <meta name="citation_reference" content="citation_journal_title=Phys Ther; citation_title=Movement disorders in people with Parkinson&#8217;s disease: a model for physical therapy; citation_author=ME Morris; citation_volume=80; citation_publication_date=2000; citation_pages=578-597; citation_id=CR34"/>

    <meta name="citation_reference" content="Oppenheimer P, Gupta A, Weghorst S, Sweet R, Porter J (2001) The representation of blood flow in endourologic surgical simulations. In: Proceedings of medicine meets virtual reality 2001. Newport Beach, CA, pp 365&#8211;371"/>

    <meta name="citation_reference" content="Pryor HL, Furness TA, Viirre E (1998) The virtual retinal display: a new display technology using scanned laser light. In: Proceedings of human factors and ergonomics society, 42nd annual meeting. Santa Monica, CA, pp 1570&#8211;1574"/>

    <meta name="citation_reference" content="Riess T, Weghorst S (1995) Augmented reality in the treatment of Parkinson&#39;s disease. In: Proceedings of medicine meets virtual reality III, San Diego, CA, pp 298&#8211;302"/>

    <meta name="citation_reference" content="citation_title=Role of haptics in teaching structural molecular biology In: Proceedings of 11th international symposium on haptic interfaces for virtual environment and teleoperator systems, March 22&#8211;23, 2003; citation_publication_date=2003; citation_id=CR37; citation_author=G Sankaranarayanan; citation_author=S Weghorst; citation_author=MF Sanner; citation_author=A Gillet; citation_author=AJ Olson; citation_publisher=Los Angeles"/>

    <meta name="citation_reference" content="citation_journal_title=J Mol Graph Model; citation_title=Python: a programming language for software integration and development; citation_author=MF Sanner; citation_volume=17; citation_issue=1; citation_publication_date=1999; citation_pages=57-61; citation_id=CR38"/>

    <meta name="citation_reference" content="citation_journal_title=J Soc Inf Disp; citation_title=True 3D scanned voxel displays using single and multiple light sources; citation_author=BT Schowengerdt, EJ Seibel; citation_volume=14; citation_issue=2; citation_publication_date=2006; citation_pages=135-143; citation_doi=10.1889/1.2176115; citation_id=CR39"/>

    <meta name="citation_reference" content="citation_journal_title=Lasers Surg Med; citation_title=Unique features of optical scanning, single fiber endoscopy; citation_author=EJ Seibel, QYL Smithwick; citation_volume=30; citation_issue=3; citation_publication_date=2002; citation_pages=177-183; citation_doi=10.1002/lsm.10029; citation_id=CR40"/>

    <meta name="citation_reference" content="Seibel EJ, Smithwick QYJ, Brown CM, Reinhall PG (2001) Single fiber flexible endoscope: general design for small size, high resolution, and wide field of view. In: Proceedings of the SPIE, biomonitoring and endoscopy technologies, San Diego, CA, vol 4158, pp 29&#8211;39"/>

    <meta name="citation_reference" content="Seibel EJ, Johnston RS, Melville CD (2006) A full-color scanning fiber endoscope. In: Gannot I (ed) Optical fibers and sensors for medical diagnostics and treatment applications. Proceedings of SPIE, vol 6083, pp 9&#8211;16"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans Biomed Eng; citation_title=Tethered-capsule endoscopy, a low-cost and high-performance alternative technology for the screening of esophageal cancer and Barrett&#8217;s esophagus; citation_author=EJ Seibel, RE Carroll, JA Dominitz, RS Johnston, CD Melville, CM Lee , SM Seitz, MB Kimmey; citation_volume=55; citation_issue=3; citation_publication_date=2008; citation_pages=1032-1042; citation_doi=10.1109/TBME.2008.915680; citation_id=CR43"/>

    <meta name="citation_reference" content="citation_journal_title=Cyberpsychol Behav; citation_title=Virtual reality as a pediatric pain modulation technique: a case study; citation_author=E Steele, K Grimmer, B Thomas, B Mulley, I Fulton, H Hoffman; citation_volume=6; citation_publication_date=2003; citation_pages=633-638; citation_doi=10.1089/109493103322725405; citation_id=CR59"/>

    <meta name="citation_reference" content="citation_journal_title=J Endourol; citation_title=The simulation of bleeding in endoscopic procedures using virtual reality; citation_author=RM Sweet, P Oppenheimer, J Porter, D Hendrickson, A Gupta, S Weghorst; citation_volume=16; citation_issue=7; citation_publication_date=2002; citation_pages=451-455; citation_doi=10.1089/089277902760367395; citation_id=CR44"/>

    <meta name="citation_reference" content="citation_journal_title= J Urol; citation_title=Validation of the UW TURP simulator as an assessment and training tool; citation_author=RM Sweet, T Kowalewski, P Oppenheimer, J Berkley, R Satava, S Weghorst; citation_volume=172; citation_issue=5 Pt 1; citation_publication_date=2004; citation_pages=1953-1957; citation_doi=10.1097/01.ju.0000141298.06350.4c; citation_id=CR45"/>

    <meta name="citation_reference" content="Weghorst S (2001) Augmented reality approaches to sensory rehabilitation. Presented at HCI International, New Orleans, LA, August 2001"/>

    <meta name="citation_reference" content="citation_title=Virtual images in the treatment of Parkinson&#8217;s disease akinesia. In: Proceedings of medicine meets virtual reality II; citation_publication_date=1994; citation_id=CR46; citation_author=S Weghorst; citation_author=J Prothero; citation_author=TA Furness; citation_author=D Anson; citation_author=T Riess; citation_publisher=San Diego"/>

    <meta name="citation_reference" content="Weghorst S, Oppenheimer P, Kaufman S, Haynor D, Gifford J, Edmond C, Dunbar P, Billinghurst M, Poupyrev I, Miller E (1997) The LIMIT: a VR testbed for clinical interface design. In: Presented at Medicine Meets Virtual Reality, San Diego, CA, January 1997"/>

    <meta name="citation_reference" content="citation_journal_title=J Am Geriatr Soc; citation_title=Parkinson&#8217;s disease and nonpharmacologic treatment programs; citation_author=WJ Weiner, C Singer; citation_volume=37; citation_publication_date=1989; citation_pages=359-363; citation_id=CR48"/>

    <meta name="citation_reference" content="citation_journal_title=Urology; citation_title=Virtual reality as an adjunctive pain control during transurethral microwave thermotherapy; citation_author=JL Wright, HG Hoffman, RM Sweet; citation_volume=66; citation_publication_date=2005; citation_pages=1320; citation_id=CR61"/>

    <meta name="citation_author" content="Suzanne Weghorst"/>

    <meta name="citation_author_email" content="weghorst@u.washington.edu"/>

    <meta name="citation_author_institution" content="Human Interface Technology Laboratory, University of Washington, Seattle, USA"/>

    <meta name="citation_author" content="Eric Seibel"/>

    <meta name="citation_author_institution" content="Human Interface Technology Laboratory, University of Washington, Seattle, USA"/>

    <meta name="citation_author" content="Peter Oppenheimer"/>

    <meta name="citation_author_institution" content="Human Interface Technology Laboratory, University of Washington, Seattle, USA"/>

    <meta name="citation_author" content="Hunter Hoffman"/>

    <meta name="citation_author_institution" content="Human Interface Technology Laboratory, University of Washington, Seattle, USA"/>

    <meta name="citation_author" content="Brian Schowengerdt"/>

    <meta name="citation_author_institution" content="Human Interface Technology Laboratory, University of Washington, Seattle, USA"/>

    <meta name="citation_author" content="Thomas A. Furness "/>

    <meta name="citation_author_institution" content="Human Interface Technology Laboratory, University of Washington, Seattle, USA"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10055-008-0107-9&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2008/12/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10055-008-0107-9"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Virtual Reality"/>
        <meta property="og:title" content="Medical interface research at the HIT Lab"/>
        <meta property="og:description" content="The Human Interface Technology Laboratory (HIT Lab) is a multi-disciplinary research and development lab whose work centers on novel approaches to human interface technology. Lab researchers represent a wide range of disciplines from across the University of Washington campus, including engineering, medicine, education, social sciences, architecture, and the design arts. We describe here a representative sampling of past and current HIT Lab research and development activities related to medicine, including virtual reality and augmented/mixed reality applications for direct patient therapy, tools for basic medical education and procedure training, novel approaches to medical image acquisition and display, and new visualization methods in medical informatics."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10055.jpg"/>
    

    <title>Medical interface research at the HIT Lab | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b0cd12fb00.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-6aad73fdd0.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"DK","doi":"10.1007-s10055-008-0107-9","Journal Title":"Virtual Reality","Journal Id":10055,"Keywords":"Virtual reality, Mixed reality, Endoscopy, Medical informatics, Rehabilitation, Surgical simulation","kwrd":["Virtual_reality","Mixed_reality","Endoscopy","Medical_informatics","Rehabilitation","Surgical_simulation"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":["doNotAutoAssociate"],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"businessPartnerIDString":"1600006921|2000421697|3000092219|3000209025|3000236495"}},"Access Type":"subscription","Bpids":"1600006921, 2000421697, 3000092219, 3000209025, 3000236495","Bpnames":"Copenhagen University Library Royal Danish Library Copenhagen, DEFF Consortium Danish National Library Authority, Det Kongelige Bibliotek The Royal Library, DEFF Danish Agency for Culture, 1236 DEFF LNCS","BPID":["1600006921","2000421697","3000092219","3000209025","3000236495"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10055-008-0107-9","Full HTML":"Y","Subject Codes":["SCI","SCI22013","SCI21000","SCI22021","SCI18067"],"pmc":["I","I22013","I21000","I22021","I18067"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1434-9957","pissn":"1359-4338"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Graphics","2":"Artificial Intelligence","3":"Artificial Intelligence","4":"Image Processing and Computer Vision","5":"User Interfaces and Human Computer Interaction"},"secondarySubjectCodes":{"1":"I22013","2":"I21000","3":"I21000","4":"I22021","5":"I18067"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10055-008-0107-9","Page":"article","page":{"attributes":{"environment":"live"}}}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>





    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    (function(w, d) {
        window.config = window.config || {};
        window.config.mustardcut = false;

        var ctmLinkEl = d.getElementById('js-mustard');

        if (ctmLinkEl && w.matchMedia && w.matchMedia(ctmLinkEl.media).matches) {
            window.config.mustardcut = true;

            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                { 'src' : '/oscar-static/js/polyfill-es5-bundle-ab77bcf8ba.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es5-bundle-6b407673fa.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/airbrake-es6-bundle-e7bd4589ff.js', 'async': false, 'module': true}
            ];

            var bodyScripts = [
                { 'src' : '/oscar-static/js/app-es5-bundle-867d07d044.js', 'async': false, 'module': false},
                { 'src' : '/oscar-static/js/app-es6-bundle-8ebcb7376d.js', 'async': false, 'module': true}
                
                
                    , { 'src' : '/oscar-static/js/global-article-es5-bundle-12442a199c.js', 'async': false, 'module': false},
                    { 'src' : '/oscar-static/js/global-article-es6-bundle-7ae1776912.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i=0; i<headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i=0; i<bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        }
    })(window, document);
</script>

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=107;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10055-008-0107-9">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Medical interface research at the HIT Lab
                        </div>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-008-0107-9.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                    </div>
                </div>
            
            
            
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-008-0107-9.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Original Article</li>
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2008-11-28" itemprop="datePublished">28 November 2008</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Medical interface research at the HIT Lab</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Suzanne-Weghorst" data-author-popup="auth-Suzanne-Weghorst" data-corresp-id="c1">Suzanne Weghorst<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Washington" /><meta itemprop="address" content="grid.34477.33, 0000000122986657, Human Interface Technology Laboratory, University of Washington, Seattle, WA, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Eric-Seibel" data-author-popup="auth-Eric-Seibel">Eric Seibel</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Washington" /><meta itemprop="address" content="grid.34477.33, 0000000122986657, Human Interface Technology Laboratory, University of Washington, Seattle, WA, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Peter-Oppenheimer" data-author-popup="auth-Peter-Oppenheimer">Peter Oppenheimer</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Washington" /><meta itemprop="address" content="grid.34477.33, 0000000122986657, Human Interface Technology Laboratory, University of Washington, Seattle, WA, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Hunter-Hoffman" data-author-popup="auth-Hunter-Hoffman">Hunter Hoffman</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Washington" /><meta itemprop="address" content="grid.34477.33, 0000000122986657, Human Interface Technology Laboratory, University of Washington, Seattle, WA, USA" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Brian-Schowengerdt" data-author-popup="auth-Brian-Schowengerdt">Brian Schowengerdt</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Washington" /><meta itemprop="address" content="grid.34477.33, 0000000122986657, Human Interface Technology Laboratory, University of Washington, Seattle, WA, USA" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Thomas_A_-Furness_" data-author-popup="auth-Thomas_A_-Furness_">Thomas A. Furness  III</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Washington" /><meta itemprop="address" content="grid.34477.33, 0000000122986657, Human Interface Technology Laboratory, University of Washington, Seattle, WA, USA" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10055"><i data-test="journal-title">Virtual Reality</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 12</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">201</span>–<span itemprop="pageEnd">214</span>(<span data-test="article-publication-year">2008</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">199 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">0 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10055-008-0107-9/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                        </div>
                        
                        
                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>The Human Interface Technology Laboratory (HIT Lab) is a multi-disciplinary research and development lab whose work centers on novel approaches to human interface technology. Lab researchers represent a wide range of disciplines from across the University of Washington campus, including engineering, medicine, education, social sciences, architecture, and the design arts. We describe here a representative sampling of past and current HIT Lab research and development activities related to medicine, including virtual reality and augmented/mixed reality applications for direct patient therapy, tools for basic medical education and procedure training, novel approaches to medical image acquisition and display, and new visualization methods in medical informatics.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Since its founding by Tom Furness in 1989 the University of Washington’s Human Interface Technology Laboratory (HIT Lab) has taken a leadership role in developing technologies that have helped to bring virtual reality (VR) into mainstream university and industrial research. Drawing on the SurperCockpit concepts originally developed for simulating and improving fighter cockpit displays (Furness <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1986" title="Furness TA (1986) The super cockpit and human factors challenges. In: Ung M (ed) Proceedings of human factors society 30th annual meeting. Dayton, OH, pp 48–52" href="/article/10.1007/s10055-008-0107-9#ref-CR14" id="ref-link-section-d87028e341">1986</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Furness T (1988) Harnessing virtual space. In: Proceedings of SID international symposium digest of technical papers. Playa del Rey, CA, pp 4–7" href="/article/10.1007/s10055-008-0107-9#ref-CR15" id="ref-link-section-d87028e344">1988</a>), HIT Lab researchers have developed new software and hardware technologies to enable VR and other novel approaches to human–computer interface and computer-mediated communication.</p><p>Perhaps the most noteworthy of the lab’s accomplishments are the Virtual Retinal Display (VRD), which provides high-luminance, high-resolution images by projecting light directly onto the retina (Pryor et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Pryor HL, Furness TA, Viirre E (1998) The virtual retinal display: a new display technology using scanned laser light. In: Proceedings of human factors and ergonomics society, 42nd annual meeting. Santa Monica, CA, pp 1570–1574" href="/article/10.1007/s10055-008-0107-9#ref-CR36" id="ref-link-section-d87028e350">1998</a>), and the ARToolkit, a software suite for creating low-cost multi-user augmented reality (AR) applications (Billinghurst and Kato <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Billinghurst M, Kato H (1999) Collaborative mixed reality. In: Proceedings of international symposium on mixed reality (ISMR ‘99). Mixed reality—merging real and virtual worlds. Yokohama, Japan, pp 261–284" href="/article/10.1007/s10055-008-0107-9#ref-CR6" id="ref-link-section-d87028e353">1999</a>).</p><p>HIT Lab researchers have also explored a variety of domains for the application of VR and other novel interface approaches. Among the lab’s most fruitful VR application domains has been medicine. This paper presents a summary of some of the lab’s research and development efforts in the field of medicine, for which the HIT Lab was honored with the Satava Award in 2001.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Therapeutic applications</h2><div class="c-article-section__content" id="Sec2-content"><p>One of the most widespread and immediate application areas for VR/AR in medicine is in direct patient therapy. HIT Lab work in this domain has focused primarily on “prosthetic displays” for sensory and neurological disorders and on immersive VR applications in psychotherapy and cognitive psychology.</p><h3 class="c-article__sub-heading" id="Sec3">Assistive displays</h3><p>By providing methods for “perceptual enhancement” AR devices offer new options to patients suffering from sensory and neurological disorders. Two areas of focus by HIT Lab researchers in recent years are the development of interface technologies for (1) overcoming the debilitating effects of Parkinson’s disease (PD) on walking behavior, and (2) aids for assisting people with “low vision” conditions to better navigate through their physical environments.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec4">Facilitating walking in Parkinson’s disease akinesia</h4><p>Parkinson’s disease is a neurological disorder caused by the selective deterioration of dopaminergic neurons in the basal ganglia region of the brain. When these cells become damaged in PD, the balance between the neurotransmitters dopamine and acetylcholine becomes disrupted, resulting in the cardinal signs of the disease: tremor, rigidity, bradykinesia, and akinesia. Akinesia may appear in the later stages of PD, typically 10 years or more after onset (Imai <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Imai H (1996) Clinicophysiological features of akinesia. Eur Neurol 36(Suppl 1):9–12" href="/article/10.1007/s10055-008-0107-9#ref-CR26" id="ref-link-section-d87028e378">1996</a>). People with akinesia typically exhibit a gait pattern composed of a series of small, shuffling steps. These people also frequently present with freezing gait, when they report feeling as if their feet are glued to the floor and they are unable to move forward. This can occur at initiation of walking, during walking, and in doorways or narrow hallways, with or without the L-dopa medication typically used to treat PD.</p><p>Some akinetic patients exhibit <i>kinesia paradoxa</i>, a phenomenon that has been well documented in the literature and which may have implications for the treatment of akinesia (Morris <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Morris ME (2000) Movement disorders in people with Parkinson’s disease: a model for physical therapy. Phys Ther 80:578–597" href="/article/10.1007/s10055-008-0107-9#ref-CR34" id="ref-link-section-d87028e387">2000</a>). People with akinesia who demonstrate this phenomenon have been observed to walk over obstacles in their path, or up stairs, with a significant reduction in shuffling and freezing gait (Bagley et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Bagley S, Kelly B, Tunnicliffe N, Turnbull G, Walker JM (1991) The effect of visual cues on the gait of independently mobile Parkinson’s disease patients. Physiotherapy 77:415–420" href="/article/10.1007/s10055-008-0107-9#ref-CR1" id="ref-link-section-d87028e390">1991</a>; Lewis et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Lewis GN, Byblow WD, Walt SE (2000) Stride length regulation in Parkinson’s disease: the use of extrinsic, visual cues. Brain 123:2077–2090" href="/article/10.1007/s10055-008-0107-9#ref-CR29" id="ref-link-section-d87028e393">2000</a>; Weiner and Singer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1989" title="Weiner WJ, Singer C (1989) Parkinson’s disease and nonpharmacologic treatment programs. J Am Geriatr Soc 37:359–363" href="/article/10.1007/s10055-008-0107-9#ref-CR48" id="ref-link-section-d87028e396">1989</a>). The common feature of these situations is that they provide an environment with horizontal lines perpendicular to the walker’s path, typically spaced about one stride-length apart.</p><p>Until recently, the therapeutic applications of <i>kinesia paradoxa</i> have been limited to controlled physical environments. With the emergence of head-mounted AR displays HIT Lab researchers have been able to further explore this phenomenon and to develop functioning prototypes for commercial therapeutic devices (Weghorst et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Weghorst S, Prothero J, Furness TA III, Anson D, Riess T (1994) Virtual images in the treatment of Parkinson’s disease akinesia. In: Proceedings of medicine meets virtual reality II. San Diego, CA, pp 242–243" href="/article/10.1007/s10055-008-0107-9#ref-CR46" id="ref-link-section-d87028e405">1994</a>; Riess and Weghorst <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Riess T, Weghorst S (1995) Augmented reality in the treatment of Parkinson's disease. In: Proceedings of medicine meets virtual reality III, San Diego, CA, pp 298–302" href="/article/10.1007/s10055-008-0107-9#ref-CR58" id="ref-link-section-d87028e408">1995</a>). The most comprehensively tested device consists of an LED (light emitting diode) array mounted on one side of a pair of spectacles which, when activated sequentially, generates a series of horizontal lines that reflect off a lens and into the eye of the wearer (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig1">1</a>a). When looking at the ground, the lines appear to be stationary on the walking surface in front of the user, and can be used to simulate actual objects or lines in the environment (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig1">1</a>b). Tilt sensors detect when the head is raised slightly to initiate scrolling of the lines, and the light sequence is set at a pace that matches the average walking speed of the user.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig1_HTML.jpg" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p><b>a</b> Prototype visual cueing aid for Parkinson’s disease akinesia. <b>b</b> Optimal spacing of virtual cueing lines, adjusted for walking speed</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>With this “virtual cueing” device PD patients can produce a gait pattern of normal velocity, cadence, and stride length, thereby decreasing their risk for falls and allowing them more freedom and safety in the community. The efficacy of the device has been demonstrated both in controlled laboratory settings (Weghorst <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Weghorst S (2001) Augmented reality approaches to sensory rehabilitation. Presented at HCI International, New Orleans, LA, August 2001" href="/article/10.1007/s10055-008-0107-9#ref-CR60" id="ref-link-section-d87028e445">2001</a>) and in longitudinal studies in PD patients’ everyday environments (Kaminsky et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Kaminsky TA, Dudgeon BJ, Billingsley FF, Mitchell PH, Weghorst SJ (2007) Virtual cues and functional mobility of people with Parkinson’s disease: a single-subject pilot study. J Rehabil Res Dev 44(3):437–448" href="/article/10.1007/s10055-008-0107-9#ref-CR27" id="ref-link-section-d87028e448">2007</a>).</p><p>While the underlying physiological mechanism has yet to be determined, kinesia paradoxa provides an opportunity for the application of simple interactive AR displays. A more robust commercial version of this prototype is scheduled for production in 2008 by Enhanced Vision Systems, Inc.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec5">Wearable low vision aid</h4><p>“Low vision” denotes a class of visual disorders which are not correctable beyond an acuity level of 20/200 with conventional lenses. The visually impaired have great difficulty navigating and avoiding obstacles as they walk, even when using a cane or seeing eye dog, and especially under low light levels.</p><p>For some types of low vision disorder the retina is intact but vision is impaired by defects in the optical media (e.g., cataracts of the lens or corneal damage). For these cases the scanned light display approach pioneered by the VRD may be helpful. A research team led by Eric Seibel has developed a variant of the scanned light display that can be embedded in a head-worn device that senses objects in the user’s field of view and provides visual notification cues.</p><p>The Wearable Low Vision Aid (WLVA) is a portable system that uses machine vision to track potential walking hazards for the visually impaired (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig2">2</a>). The WLVA incorporates infrared illumination and efficient algorithms to identify potential walking hazards and a scanning fiber display to present bright icons to project an image onto the retina. The scanning fiber display couples a laser diode to a vibrating optical fiber that projects a virtual image onto the retina to display warning icons that the visually impaired can recognize. Initial low-vision subject testing has given promising results for this low-cost assistive device (Bryant et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Bryant R, Seibel EJ, Lee CM, Schroder KE (2004) Low-cost wearable low vision aid using a handmade retinal light scanning microdisplay. J Soc Inf Disp 12(4):397" href="/article/10.1007/s10055-008-0107-9#ref-CR8" id="ref-link-section-d87028e469">2004</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>A prototype wearable low vision aid, using head-mounted IR sensors and a scanned light display</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h3 class="c-article__sub-heading" id="Sec6">Cognitive VR therapy</h3><p>Immersive VR is rapidly becoming a viable treatment avenue for common psychological anxiety disorders. HIT Lab researcher Hunter Hoffman has led a research team in developing VR applications for the effective treatment of phobias (i.e., the irrational fear of certain objects or situations). VR is used to help phobics face their fears. Hoffman is also helping therapists to develop VR treatments for civilian and combat-related post-traumatic stress disorder (PTSD). VR is used to help PTSD patients become more comfortable thinking about their memories for traumatic events they previously avoided remembering.</p><p>In another HIT Lab medical application of immersive virtual reality, Hoffman and pain specialist Dave Patterson, from UW Harborview Burn Center, originated the use of immersive VR as a non-pharmacologic analgesic to help more successfully in controlling the perception of pain during aggressive wound treatment in burn patients. In this research, VR is used to help the patients to escape from the real world during painful medical procedures.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec7">VR therapy for spider phobia and PTSD</h4><p>Hoffman and colleagues have explored whether VR exposure therapy is effective in the treatment of spider phobia (e.g., Carlin et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Carlin AS, Hoffman HG, Weghorst S (1997) Virtual reality and tactile augmentation in the treatment of spider phobia: a case study. Behav Res Ther 35:153–158" href="/article/10.1007/s10055-008-0107-9#ref-CR10" id="ref-link-section-d87028e507">1997</a>; Garcia-Palacios et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Garcia-Palacios A, Hoffman HG, Carlin C, Furness TAIII, Botella-Arbona C (2002) Virtual reality in the treatment of spider phobia: a controlled study. Behav Res Ther 40(9):983–993" href="/article/10.1007/s10055-008-0107-9#ref-CR16" id="ref-link-section-d87028e510">2002</a>; Hoffman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003a" title="Hoffman HG, Garcia-Palacios A, Carlin C, Furness TA III, Botella-Arbona (2003a) Interfaces that heal: coupling real and virtual objects to cure spider phobia. Int J Hum Comput Interact 16:283–300" href="/article/10.1007/s10055-008-0107-9#ref-CR23" id="ref-link-section-d87028e513">2003a</a>). Garcia-Palacios et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Garcia-Palacios A, Hoffman HG, Carlin C, Furness TAIII, Botella-Arbona C (2002) Virtual reality in the treatment of spider phobia: a controlled study. Behav Res Ther 40(9):983–993" href="/article/10.1007/s10055-008-0107-9#ref-CR16" id="ref-link-section-d87028e516">2002</a>) compared a VR treatment condition with a “waiting list” condition in a between-group design study with 23 spider phobics. Participants in the VR treatment group received an average of four 1-h exposure therapy sessions which involved interacting with virtual spiders in a virtual kitchen named “SpiderWorld”. After mastering earlier levels, patients eventually picked up the plump furry body of a virtual Guyana bird-eating tarantula.</p><p>Virtual reality exposure was effective in treating spider phobia compared to the control condition, as measured by their fear-of-spiders questionnaire, a behavioral avoidance test (how close patients were willing to approach a live tarantula), and severity ratings by a clinician and an independent assessor. In total, 83% of patients in the VR treatment group showed clinically significant improvement compared with none in the waiting list group, and no patients dropping out, demonstrating that VR exposure can be effective in the treatment of phobias.</p><p>To make the VR spider more convincing, Hoffman has also used tactile augmentation to enhance the quality of the virtual world (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig3">3</a>a). With this technique, a fur-covered plastic spider is attached to a spatial tracker and used as a prop in the VR interaction (Hoffman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Hoffman HG (1998) Physically touching virtual objects using tactile augmentation enhances the realism of virtual environments. In: Proceedings of the IEEE virtual reality annual international symposium ‘98, Atlanta, GA. IEEE Computer Society, Los Alamitos, pp 59–63" href="/article/10.1007/s10055-008-0107-9#ref-CR19" id="ref-link-section-d87028e527">1998</a>). Tactile augmentation is used to elicit higher anxiety levels when needed and, in their study, the mixed reality technique doubled how close spider phobics could approach a live tarantula after completing therapy (Hoffman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003a" title="Hoffman HG, Garcia-Palacios A, Carlin C, Furness TA III, Botella-Arbona (2003a) Interfaces that heal: coupling real and virtual objects to cure spider phobia. Int J Hum Comput Interact 16:283–300" href="/article/10.1007/s10055-008-0107-9#ref-CR23" id="ref-link-section-d87028e530">2003a</a>). An immersive table mounted VR exhibit of SpiderWorld was part of a popular “Computers in Medicine” museum exhibition that toured Germany in 2006–2008. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig3_HTML.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig3_HTML.jpg" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p><b>a</b> Early VR spider phobia treatment session. <b>b</b> VR treatment environment for PTSD patients traumatized by the World Trade Center attacks</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Hoffman has also helped pioneer the use of virtual reality in cognitive behavioral therapy for civilian, as well as combat-related, post-traumatic stress disorder (PTSD). In collaboration with PTSD expert JoAnn Difede from Cornell Presbyterian Hospital in Manhattan, Hoffman’s group (Difede and Hoffman <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Difede J, Cukor J, Jayasinghe N, Patt I, Jedel S, Spielman L, Giosan C, Hoffman HG (2007) Virtual reality exposure therapy for the treatment of posttraumatic stress disorder following September 11, 2001. J Clin Psychiatry 68:1639–1647" href="/article/10.1007/s10055-008-0107-9#ref-CR11" id="ref-link-section-d87028e560">2002</a>; Difede et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Difede J, Hoffman HG (2002) Virtual reality exposure therapy for World Trade Center post traumatic stress disorder: a case report. Cyberpsychol Behav 5:529–536" href="/article/10.1007/s10055-008-0107-9#ref-CR12" id="ref-link-section-d87028e563">2007</a>) created a virtual world to successfully treat patients who had developed PTSD after 11 September 2001, World Trade Center attack (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig3">3</a>b). WTC world was programmed by Howard Abrams and included 3D models created by Duff Hendrickson.</p><p>More recently, PTSD experts Hoffman and Sarah Miyahira at the Pacific Telemedicine Hui at Tripler Army Medical Center have designed IraqWorld with input from Azucena Garcia-Palacios (HIT Lab affiliate from Spain), Ray Folen from Pacific Hui, and former HIT Lab researchers Ari Hollander and Howard Rose at <a href="http://www.imprintit.com">http://www.imprintit.com</a>. Worldbuilders Hollander and Rose created the IraqWorld VR environment using <a href="http://www.virtools.com">http://www.virtools.com</a> software. An initial study is now underway at Scholfield Barracks in Hawaii, exploring whether cognitive behavioral virtual reality exposure therapy can reduce combat-related PTSD (e.g., severe symptoms stemming from emotionally painful memories of hitting IED roadside bombs and experiencing or witnessing other types of deadly terrorist attacks on U.S. troops).</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec8">Burn pain control with VR</h4><p>Hoffman and pain researcher Dave Patterson, at Harborview Burn Center in Seattle, originated the use of immersive virtual reality for treating pain, and published the first data on this topic (Hoffman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Hoffman HG, Doctor JN, Patterson DR, Carrougher GJ, Furness TAIII (2000) Use of virtual reality for adjunctive treatment of adolescent burn pain during wound care: a case report. Pain 85:305–309" href="/article/10.1007/s10055-008-0107-9#ref-CR21" id="ref-link-section-d87028e595">2000</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Hoffman HG, Patterson DR, Carrougher GJ, Sharar S (2001) The effectiveness of virtual reality based pain control with multiple treatments. Clin J Pain 17:229–235" href="/article/10.1007/s10055-008-0107-9#ref-CR22" id="ref-link-section-d87028e598">2001</a>). This project is funded by the National Institutes of Health, Scandinavian Design, the Washington State Firefighters Fund, and the Paul Allen Family Foundation. So far, the University of Washington’s interdisciplinary VR analgesia research team has dominated this new field of research, but there are encouraging signs that independent teams at other burn centers in several countries are replicating and extending these findings that VR is effective for reducing excessive pain.</p><p>The original version of SnowWorld (completed in 2003) was developed by Hunter Hoffman with help from Jeff Bellinghausen and Chuck Walter from Multigen, Brian Stewart from SimWright Inc., Howard Abrams (freelance worldbuilder), and Duff Hendrickson from the UW HIT Lab. SnowWorld allows patients to shoot virtual snowballs at snowmen and other objects while flying through an icy canyon. Patients reported greatly a diminished perception of pain while immersed in this environment (Hoffman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Hoffman HG, Patterson DR, Seibel E, Soltani M, Jewett-Leahy L, Sharar SR (2008) Virtual reality pain control during burn wound debridement in the hydrotank. Clin J Pain 24(4):299–304" href="/article/10.1007/s10055-008-0107-9#ref-CR57" id="ref-link-section-d87028e604">2008</a>). Functional MRI (fMRI) studies show converging evidence that virtual reality reduces pain. People reported large reductions in pain during SnowWorld, and their fMRI brain scans showed corresponding large reductions in pain-related brain activity during VR (Hoffman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004c" title="Hoffman HG, Richards TL, Magula J, Seibel EJ, Hayes C, Mathis M, Sharar SR, Maravilla K (2004c) A magnet-friendly virtual reality fiberoptic image delivery system. Cyberpsychol Behav 6:645–648" href="/article/10.1007/s10055-008-0107-9#ref-CR55" id="ref-link-section-d87028e607">2004c</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Hoffman HG, Richards TL, Van Oostrom T, Coda BA, Jensen MP, Blough DK, Sharar SR (2007) The analgesic effects of opioids and immersive virtual reality distraction: evidence from subjective and functional brain imaging assessments. Anesth Analg 105:1776–1783" href="/article/10.1007/s10055-008-0107-9#ref-CR56" id="ref-link-section-d87028e610">2007</a>). A special wide field of view fiberoptic magnet-friendly VR helmet was developed at the HIT Lab by Hoffman, instrument maker Jeff Magula, optics engineer Janet Bosworth-Crossman, and Eric Seibel, Director of the Human Photonics Lab associated with the HIT Lab. The unique wide FOV magnet-friendly VR goggles made the immersive VR fMRI brain scan studies possible. One crucial role played by the HIT Lab in these projects was to help develop hardware and software that is not currently in existence, but is needed by the researchers.</p><p>Since many burn treatment procedures are conducted while the patient is immersed in water, Hoffman’s team has developed a “water-friendly”headmounted display (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig4">4</a>b). This fiber-optic VR helmet allows patients to go into virtual reality while undergoing wound care, debridement or bandagechanging in a hydro tank, partially submerged in water (Hoffman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004b" title="Hoffman HG, Patterson DR, Magula J, Carrougher GJ, Zeltzer K, Dagadakis S, Sharar SR (2004b) Water-friendly virtual reality pain control during wound care. J Clin Psychol 60(2):189–195" href="/article/10.1007/s10055-008-0107-9#ref-CR25" id="ref-link-section-d87028e619">2004b</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Hoffman HG, Patterson DR, Seibel E, Soltani M, Jewett-Leahy L, Sharar SR (2008) Virtual reality pain control during burn wound debridement in the hydrotank. Clin J Pain 24(4):299–304" href="/article/10.1007/s10055-008-0107-9#ref-CR57" id="ref-link-section-d87028e622">2008</a>). SnowWorld is now being used in VR analgesia research at a growing number of other regional burn centers, such as Shriners Childrens Burn Center in Galveston and the New York William Randolph Hearst Burn Center in Manhattan. Soldiers with combat-related burn injuries at the United States Army Institute of Surgical Research are also experiencing VR analgesia (Maani et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Maani C, Hoffman HG, DeSocio PA, Morrow M, Galin C, Magula J, Maiers A, Gaylord K (2008) Pain control during wound care for combat-related burn injuries using custom articulated arm mounted virtual reality goggles. J CyberTher Rehabil 1:193–198" href="/article/10.1007/s10055-008-0107-9#ref-CR31" id="ref-link-section-d87028e625">2008</a>). Hoffman and Patterson provide the SnowWorld software to eligible burn centers free of charge. </p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig4_HTML.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig4_HTML.jpg" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p><b>a</b> SnowWorld VR environment for pain reduction during burn wound treatment. <b>b</b> Water-friendly VR display developed for hydro tank wound cleaning procedures</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>The most recent build of SnowWorld (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig4">4</a>a), designed by Hoffman and created by worldbuilders at <a href="http://www.imprintit.com">http://www.imprintit.com</a>, was an interactive VR exhibit at the Smithsonian National Museum of Design Triennial in 2006–2008, and has also been exhibited at the Pacific Science Center in Seattle, using Hoffman and Magula’s custom table-mounted VR goggles.</p><p>Hoffman and colleagues have also found preliminary success using VR to reduce pain during urological endoscopies (Wright et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Wright JL, Hoffman HG, Sweet RM (2005) Virtual reality as an adjunctive pain control during transurethral microwave thermotherapy. Urology 66:1320" href="/article/10.1007/s10055-008-0107-9#ref-CR61" id="ref-link-section-d87028e669">2005</a>), during dental pain (Hoffman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003b" title="Hoffman HG, Garcia-Palacios A, Kapa VA, Beecher J, Sharar SR (2003b) Immersive virtual reality for reducing experimental ischemic pain. Int J Hum Comput Interact 15:469–486" href="/article/10.1007/s10055-008-0107-9#ref-CR18" id="ref-link-section-d87028e672">2003b</a>) and physical therapy with cerebral palsy patients (Steele et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Steele E, Grimmer K, Thomas B, Mulley B, Fulton I, Hoffman H (2003) Virtual reality as a pediatric pain modulation technique: a case study. Cyberpsychol Behav 6:633–638" href="/article/10.1007/s10055-008-0107-9#ref-CR59" id="ref-link-section-d87028e675">2003</a>).</p></div></div></section><section aria-labelledby="Sec9"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">Medical education and training</h2><div class="c-article-section__content" id="Sec9-content"><p>The traditional approach to medical education commonly known as “see one, do one, teach one” is fast giving way to VR simulation as an effective training modality. The advantages of VR training include reduced time required by attending physicians, the ability of residents to train to criteria at their own pace, and potentially a significant reduction in patient risk.</p><p>HIT Lab efforts in this area have focused on tissue modeling and surgical procedure simulation, in collaboration with physicians from a variety of medical specialties. A representative subset of those projects is discussed here.</p><p>In addition to these more advanced skills, VR has proven useful in teaching some of the basic sciences underlying modern medicine. HIT Lab researchers have focused on the use of tangible models augmented by graphical overlays to convey core concepts in molecular biology.</p><h3 class="c-article__sub-heading" id="Sec10">Surgical simulation</h3><p>Endoscopic procedures have become the normative treatment for a wide array of maladies in recent years, and the adoption of endoscopic monitors (as opposed to through-the-lens monitoring) has provided a natural platform for procedural simulation using interactive computer graphics. In close collaboration with colleagues at the UW Medical Center and other clinical research institutions, HIT Lab researchers have pursued an aggressive R&amp;D program in biological tissue modeling and surgical simulation.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec11">Fast finite element tissue modeling</h4><p>Finite element (FE) modeling is an accurate continuum mechanics-based methodology that has served as an industry standard for physical prototype testing and design. Bridges, cars, ships, airplanes, prosthetic devices, and mechanical parts represent only a small sample of products that have depended on the accuracy of FE modeling for development. While conventional FE formulations are not applicable to real-time rendering for graphics or haptics, FE modeling methodologies that utilize novel preprocessing techniques and alternative real-time solving methodologies are starting to emerge.</p><p>Many of the advances in real-time FE modeling have occurred as a result of the demand for realistic surgery simulation. For many medical procedures, there are no efficient means for training a medical student to perform surgery, and practice on real patients is often the only option. It is generally expected that simulation training will 1 day be as important to medicine as it is now to aviation. However, one of the reasons the medical community is currently reluctant to accept many of the commercial simulators available is that they do not provide sufficient realism. As a means of achieving more accurate deformation and haptic interaction, a number of real-time FE based approaches have been offered in context with surgery simulation.</p><p>Surgery on the skin ranges from simple suturing of lacerations to complex tissue movements such as flaps. Training in cutaneous surgery uses the traditional surgical apprenticeship model aided by tools such as suturing boards, pig’s foot training courses, and/or the use of live animals. For a variety of reasons, these methods are not ideal. HIT Lab researchers have been developing a suturing simulator based on FE modeling methods that allow for real-time haptic interaction and soft tissue deformation (Berkley et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Berkley J, Weghorst S, Gladstone H, Raugi G, Berg D, Ganter M (1999) Banded matrix approach to finite element modeling for soft tissue simulation. Virtual Real 4:203–212" href="/article/10.1007/s10055-008-0107-9#ref-CR3" id="ref-link-section-d87028e708">1999</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Berkley J, Oppenheimer P, Weghorst S, Berg D, Raugi G, Haynor D, Ganter M, Brooking C, Turkiyyah G (2000) Creating fast finite element models from medical images. In: Proceedings of medicine meets virtual reality 2000, Newport Beach, CA" href="/article/10.1007/s10055-008-0107-9#ref-CR4" id="ref-link-section-d87028e711">2000</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Berkley J, Turkiyyah G, Berg D, Ganter M, Weghorst S (2004) Real-time finite element modeling for surgery simulation: an application to virtual suturing. IEEE Trans Vis Comput Graph 10(3):1–12" href="/article/10.1007/s10055-008-0107-9#ref-CR5" id="ref-link-section-d87028e714">2004</a>; Berg et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Berg D, Raugi G, Gladstone H, Berkley J, Ganter M, Turkiyyah G (2001) Virtual reality simulators for dermatologic surgery: measuring their validity as a teaching tool. In: Proceedings of medicine meets virtual reality 2001, Newport Beach, CA" href="/article/10.1007/s10055-008-0107-9#ref-CR2" id="ref-link-section-d87028e717">2001</a>).</p><p>The requirements of suturing simulation have directly influenced the development of our real-time FE methodologies. Our approach to real-time FE modeling applies constraints to linear elastic models. The methodology emphasizes high model resolution, multipoint contact, rapid preprocessing and accommodates dynamically changing boundary conditions. Although this method could easily be adapted to dynamic analysis without requiring a lumped mass matrix, the inclusion of dynamic effects is generally unnecessary for simulating suturing. Suturing requires slow precise concentrated movements, so dynamic contributions are generally negligible.</p><p>Our Fast FE suturing simulator typically utilizes a model of a <i>hand</i> that has a laceration on the palm (as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig5">5</a>). This model was developed from MRI scans which were used to generate an implicit model. The bone surface is represented with fixed boundary nodes. The various soft tissue layers have not yet been segmented and are currently represented as one homogenous tissue. Material properties were roughly approximated using values from the literature, and nodal resolution is highest near the wound for greater modeling accuracy at the region of interest.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig5_HTML.jpg?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig5_HTML.jpg" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>The Fast FE suturing simulator. <b>a</b> An overlying mesh of a hand model with 863 nodes of which 624 nodes lie on the surface. Displacements are determined for the visible nodes and an additional 100 non-visible nodes that correspond to surface elements in order to allow real-time stress/strain visualization. Higher element resolution exists at the wound to provide greater accuracy at the region of interest. <b>b</b> The arm model during suture application with stress magnitude color mapping (shown here as <i>dark grey</i>). <b>c</b> A vector extending from the curved suturing needle can be used to help the user orient the needle perpendicular to the skin for proper needle insertion</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>There are various options for viewing the model in the Fast FE modeling software platform. One useful feature is real-time stress-strain visualization. Since it is important to minimize the stress inflicted on tissue during every surgical procedure, it is helpful to be able to visualize these stresses. Not only does stress–strain monitoring allow peak tissue stresses to be recorded for procedure assessment, but also the final results of a procedure can be evaluated through the color plots of stress and strain. Excessive tissue stress can lead to scarring and improper suture placement can be identified through the visualization of excessive stress concentrations (as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig5">5</a>b).</p><p>The Fast FE suturing simulator has recently been enhanced to support two-instrument haptic interaction with the virtual tissue (as is the norm in clinical practice), as well as tissue cutting under some constrained conditions (Lindblad et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Lindblad AJ, Turkiyyah GM, Weghorst SJ, Berg D (2006) Real-time finite element based virtual tissue cutting. Presented at MMVR 2006, 24–27 January 2006, Long Beach, CA" href="/article/10.1007/s10055-008-0107-9#ref-CR30" id="ref-link-section-d87028e772">2006</a>).</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec12">Procedural simulation</h4><p>Interactive computer graphics has provided a rich platform for the development of surgical training simulators. Over the years, HIT Lab researchers have participated in the development of several of these, most recently a comprehensive training simulator for trans-urethral resection of the prostate (TURP).</p><p>Trans-urethral resection of the prostate is the procedure of choice for treating the common problem of enlarged (non-cancerous) prostate, and its ubiquity and steep learning curve make it an ideal subject for VR-based simulation. Led by urologist Rob Sweet M.D. and graphics programmer Peter Oppenheimer, a HIT Lab team has developed and validated a TURP simulator that is now in commercial production by Medical Education Technologies, Inc (Sweet et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Sweet RM, Oppenheimer P, Porter J, Hendrickson D, Gupta A, Weghorst S (2002) The simulation of bleeding in endoscopic procedures using virtual reality. J Endourol 16(7):451–455" href="/article/10.1007/s10055-008-0107-9#ref-CR44" id="ref-link-section-d87028e785">2002</a>).</p><p>The TURP procedure consists of placing an endoscope in the urethra and resecting prostate tissue with loop electrocautery. During the resection process, bleeding vessels and sinuses in the prostate are exposed and the resulting blood flow is either stopped by applying the loop on the source and coagulating, or resecting it by cutting another prostate chip over the area. The operative area during this procedure is continuously irrigated with a clear fluid that flows from a source coaxial to the scope. The irrigation keeps the area of resection distended and free of blood and debris. This gives the surgeon visibility to resect the prostate adenoma and to coagulate bleeding vessels.</p><p>Because proper control of bleeding is essential to performing this procedure, we have developed an innovative approach to depicting blood flow within the surgeon’s endoscopic field (Oppenheimer et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Oppenheimer P, Gupta A, Weghorst S, Sweet R, Porter J (2001) The representation of blood flow in endourologic surgical simulations. In: Proceedings of medicine meets virtual reality 2001. Newport Beach, CA, pp 365–371" href="/article/10.1007/s10055-008-0107-9#ref-CR35" id="ref-link-section-d87028e793">2001</a>). While previous attempts have simulated bleeding over tissue surfaces or in blood vessels, our approach focused on the macroscopic visualization of bleeding in a fluid environment. Oppenheimer’s approach to the representation of blood flow consisted of capturing videos of bleeding vessels in vitro, processing them to separate the actual blood from the background anatomy, and organizing the movies into a parametric database. During the procedure simulation, resection of prostate tissue systematically triggers bleeding events and the playback of a blood flow movie. The blood flow movie is texture mapped onto a virtual surface that is positioned, oriented, morphed, composited, and looped into the virtual scene (as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig6">6</a>b).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig6_HTML.jpg?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig6_HTML.jpg" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p><b>a</b> Trans-urethral resection of the prostate (TURP) simulator, with instrumented resectoscope and foot pedals for applying cutting and cauterizing currents to the resecting “loop”, shown as the curved object in the virtual endoscopic monitor. <b>b</b> Scene from TURP simulation with superimposed blood flow video</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Validation studies with experienced urological surgeons have verified the realism of this approach, and predictive validity studies for the full training system are currently underway with surgical residents at several medical training centers (Sweet et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Sweet RM, Kowalewski T, Oppenheimer P, Berkley J, Satava R, Weghorst S (2004) Validation of the UW TURP simulator as an assessment and training tool. J Urol 172(5 Pt 1):1953–1957" href="/article/10.1007/s10055-008-0107-9#ref-CR45" id="ref-link-section-d87028e827">2004</a>).</p><h3 class="c-article__sub-heading" id="Sec13">Molecular biology education</h3><p>Molecular biology has come to play an ever increasing role in clinical medicine. Under the leadership of Art Olson of The Scripps Research Institute (TSRI), HIT Lab researchers have collaborated on the development of new tools for visualizing biochemical structure and function, for both education and research applications. This research combines PMV, TSRI’s python-based molecular viewer (Sanner <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Sanner MF (1999) Python: a programming language for software integration and development. J Mol Graph Model 17(1):57–61" href="/article/10.1007/s10055-008-0107-9#ref-CR38" id="ref-link-section-d87028e840">1999</a>), with the HIT Lab’s ARToolkit mixed reality rendering software (Billinghurst and Kato <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Billinghurst M, Kato H (1999) Collaborative mixed reality. In: Proceedings of international symposium on mixed reality (ISMR ‘99). Mixed reality—merging real and virtual worlds. Yokohama, Japan, pp 261–284" href="/article/10.1007/s10055-008-0107-9#ref-CR6" id="ref-link-section-d87028e843">1999</a>) and PMV-rendered physical prototypes to provide dynamic imagery registered with manipulable molecular models. PMV graphical renderings are also being used in the context of ARToolkit-mediated “magic books” for teaching basic principles in protein structure. Implementations of these technologies have been incorporated into experimental teaching curricula for both high school and college biochemistry courses.</p><h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec14">Augmented tangible molecular models</h4><p>Physical representations such as ball-and-stick models have long been used in teaching basic chemistry and structural molecular biology. As the size and complexity of known molecular structures increases, it is difficult (if not impossible) to show all of their features in a physical model alone. Recent advances in automated model fabrication technology now afford physical models of more complex molecular structures. In this multi-institutional collaborative project we are creating multi-modality enhancements of such tangible models by superimposing graphical (AR) information on top of the fabricated physical models (Gillet et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Gillet A, Goodsell D, Sanner MF, Stoffler D, Weghorst S, Winn W, Olson AJ (2004) Computer-linked autofabricated 3D model for teaching structural biology. In: Proceedings of SIGGRAPH 2004, Los Angeles, CA" href="/article/10.1007/s10055-008-0107-9#ref-CR17" id="ref-link-section-d87028e853">2004</a>), as illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig7">7</a>. By using several markers, the AR overlay can be maintained and appropriately occluded while being arbitrarily manipulated.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig7_HTML.jpg?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig7_HTML.jpg" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p><b>a</b> Physical model of <i>superoxide dismutase</i> (SOD) built with the Stratasys physical prototyping machine, and <b>b</b> augmented reality overlay showing the electrostatic field animated and a volume rendering of an electrostatic grid</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <p>Other research team members have incorporated support for voice commands and by haptic feedback (Sankaranarayanan et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Sankaranarayanan G, Weghorst S, Sanner MF, Gillet A, Olson AJ (2003) Role of haptics in teaching structural molecular biology. In: Proceedings of 11th international symposium on haptic interfaces for virtual environment and teleoperator systems, March 22–23, 2003. Los Angeles, CA, pp 363–266" href="/article/10.1007/s10055-008-0107-9#ref-CR37" id="ref-link-section-d87028e889">2003</a>). The user of such an interface can request a variety of overlay representations and can interact with these virtual enhancements with a haptic “probe” while manipulating the physical model. Since the underlying physical model is intimately related to and registered with both the graphical and haptic models, this approach provides a uniquely integrated tool for learning molecular biology. In addition, haptic cues provide a naturally intuitive method for representing interactions between molecules, based on their electrostatic fields.</p><p>Haptic interaction with an augmented tangible model is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig8">8</a>. In this scenario the user holds the superoxide free radical with the haptic device probe and, as it nears the charge field of the <i>superoxide dismutase</i> (SOD) model, strong forces pull the superoxide free radical toward the Cu and Zn ions at the active site of SOD. At the same time the user sees the secondary structure of the SOD enzyme as an AR overlay on top of the physical model.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig8_HTML.jpg?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig8_HTML.jpg" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>User interacting with SOD model using a head-mounted display and aPHANTom haptic device. Virtual overlay shows SOD secondary structure and electrostatic force fields</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small c-article__sub-heading--light" id="Sec15">Protein structure “magic book”</h4><p>PMV has also been used in conjunction with an ARToolkit application called the “magic book” (Billinghurst et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Billinghurst M, Kato H, Poupyrev I (2001) MagicBook: transitioning between reality and virtuality. Presented at CHI 2001, March 30–April 5, 2001, Seattle, WA" href="/article/10.1007/s10055-008-0107-9#ref-CR7" id="ref-link-section-d87028e927">2001</a>) to create an AR primer on the fundamentals of protein structure. Pages in the book guide the reader through chapters on amino acids, peptide bonds, primary protein structure (i.e., the amino acid sequence), secondary structure (i.e., folding into the elementary volumetric building blocks of <i>beta</i> sheets and <i>alpha</i> helices), tertiary structure (i.e., the complete folded peptide chain), and quaternary structure (i.e., molecular structures composed of multiple peptide chains, such as hemoglobin). Throughout the primer relevant PMV-mediated graphical renderings are registered with ARToolkit markers embedded within the text. The protein structure magic book has been demonstrated to enhance understanding of protein structure concepts in both undergraduate biochemistry students and biochemistry novices (Medina et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Medina E, Chen Y, Weghorst S (2007) Understanding biochemistry with augmented reality. In: Montgomerie C, Seale J (eds) Proceedings of world conference on educational multimedia, hypermedia and telecommunications 2007. AACE, Chesapeake, pp 4235–4239" href="/article/10.1007/s10055-008-0107-9#ref-CR32" id="ref-link-section-d87028e936">2007</a>).</p></div></div></section><section aria-labelledby="Sec16"><div class="c-article-section" id="Sec16-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec16">New instrumentation for medical practice</h2><div class="c-article-section__content" id="Sec16-content"><p>A large and active HIT Lab research group led by Eric Seibel has pioneered new advances in medical instrumentation, with specific focus on the early detection and treatment of cancer and pre-cancer, under the rubric of “human photonics” (optical scanning for image acquisition and display). By shepherding light in novel ways, Seibel’s team has developed new methods for endoscopy, cellular-level cancer detection, and revolutionary 3D display technologies for applications such as robotic surgery.</p><h3 class="c-article__sub-heading" id="Sec17">Scanning fiber endoscopy</h3><p>Remote optical imaging of human tissue in vivo has been the foundation for the growth of minimally invasive medicine. Under funding from a variety of sponsors, including NIH and the Pentax Corporation, Seibel has developed the core enabling technologies and prototypes of an ultrathin and flexible scanning fiber endoscope (SFE) that promises to aid in the early detection and treatment of cancers within the body (Seibel et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Seibel EJ, Smithwick QYJ, Brown CM, Reinhall PG (2001) Single fiber flexible endoscope: general design for small size, high resolution, and wide field of view. In: Proceedings of the SPIE, biomonitoring and endoscopy technologies, San Diego, CA, vol 4158, pp 29–39" href="/article/10.1007/s10055-008-0107-9#ref-CR41" id="ref-link-section-d87028e955">2001</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Seibel EJ, Johnston RS, Melville CD (2006) A full-color scanning fiber endoscope. In: Gannot I (ed) Optical fibers and sensors for medical diagnostics and treatment applications. Proceedings of SPIE, vol 6083, pp 9–16" href="/article/10.1007/s10055-008-0107-9#ref-CR42" id="ref-link-section-d87028e958">2006</a>). The goal of this project is to advance minimally invasive medical imaging by allowing access to regions of the body that were previously inaccessible. Once at a region of interest, imaging, diagnosis, therapy, and monitoring can be performed from the SFE with the goal of earlier and less-invasive treatment of cancers in hard to reach areas, such as the peripheral lung and the pancreas (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig9">9</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig9_HTML.gif?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig9_HTML.gif" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Scan method of the SFE. A piezoelectric tube is driven with a sinusoid where the <i>X</i>- and <i>Y</i>-axes are 90° out of phase while the signal amplitude is modulated. This results in a space-filling spiral scan. Backscattered light measured by the detector at each pixel location is assembled to form an image displayed on a screen. Between frames (<i>Asterisk</i>) the fiber scanner is brought to rest and a spectroscopic measurement can be made to diagnose tissue or high-power laser light can be turned on for laser therapy in a frame-sequential manner</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The main attributes of the SFE technology are (1) high-resolution imaging within an ultrathin size (&lt;2 mm in diameter); (2) integrated optical diagnoses and laser therapies with full-color imaging; (3) low-cost components that may lead to a disposable distal (in vivo) end; (4) a highly flexible and durable shaft that imparts less pressure on tissues; (5) efficient laser scanning imaging that allows 3D imaging for future surgeries; and (6) a computer-tracked guidance system for complex branching systems such as the lung (Seibel and Smithwick <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Seibel EJ, Smithwick QYL (2002) Unique features of optical scanning, single fiber endoscopy. Lasers Surg Med 30(3):177–183" href="/article/10.1007/s10055-008-0107-9#ref-CR40" id="ref-link-section-d87028e995">2002</a>).</p><p>The technology is based on a single optical fiber that is scanned at the distal tip of a flexible shaft to project red, green, and blue laser light onto tissue in a spiral pattern. The resulting images are high-quality color video (with high-resolution and wide-field of view) which is expected to produce future endoscopes that are able to directly integrate the many recent advances of laser diagnostics and therapies.</p><p>Seibel’s group has recently developed a tethered-capsule endoscope (TCE) aimed at improving early detection of esophageal cancer and pre-cancerous conditions by lowering the cost and increasing the performance of screening and surveillance (Seibel et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Seibel EJ, Carroll RE, Dominitz JA, Johnston RS, Melville CD, Lee CM, Seitz SM, Kimmey MB (2008) Tethered-capsule endoscopy, a low-cost and high-performance alternative technology for the screening of esophageal cancer and Barrett’s esophagus. IEEE Trans Biomed Eng 55(3):1032–1042" href="/article/10.1007/s10055-008-0107-9#ref-CR43" id="ref-link-section-d87028e1003">2008</a>). The TCE capsule is small in size, only 6.4 mm in diameter and 18 mm in length, matching the size of an easy to swallow capsule (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig10">10</a>). Within the capsule is a resonant fiber optic laser scanner which vibrates the single illumination optical fiber at over 10,000 cycles per second using a tubular piezoelectric actuator, creating 500-line images at 30 Hz. A 1.4-mm diameter tether carries the single mode illumination optical fiber that is connected to red, green and blue low-power and external laser sources, six collection optical fibers and several scanning signals at less than ±15 volts. Over 100° field-of-view images are recorded during image-guided diagnosis to monitor the health of the lower esophagus. As the capsule is slowly retracted by its tether, software has been developed to stitch these video images into a panoramic composite image of the lower esophagus to aid in disease recognition and measurement.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig10_HTML.jpg?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig10_HTML.jpg" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Tethered capsule endoscope, containing a resonant fiber optic laser scanner which vibrates a single illumination optical fiber at over 10,000 cycles per second using a tubular piezoelectric actuator, creating 500-line images at 30 Hz. The capsule is swallowed and then slowly retracted while video images are stitched into a panoramic composite image</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The TCE is designed to be used without any sedation, often the greatest cost in endoscopic procedures. All patients who have undergone testing of the TCE have found swallowing with sips of water to be tolerable. Additional advantages of the TCE over conventional endoscopy that uses diffuse illumination and camera-based video imaging are real-time magnification and enhanced spectral imaging. Because the image is scanned, the absolute number of pixels in the image is not fixed, and more imaging pixels can be added during stationary image analysis by reducing the imaging frame rate. To magnify the scanned image at the central region, a smaller region of tissue is scanned at the same high resolution display, which automatically zooms the resolution to the optical limit of the lens system. For an optical measurement of disease at the central pixel, the scanner can be held stationary and longer-duration spectroscopic measurements can be performed in a frame sequential manner to imaging. Finally, the laser illumination can be used for fluorescence biomarker imaging, and greater laser power can be used for laser-based therapies, such as photodynamic therapy. It is believed that the combination of such imaging and diagnostic techniques will assist in identifying and possibly treating precancerous conditions of esophageal cancer, while being delivered to the patient in a very cost-efficient package.</p><h3 class="c-article__sub-heading" id="Sec18">Optical projection tomography for cancer screening</h3><p>In most pathological and cytological analyses, tissue biopsies and cells are imaged in vitro (outside the body) using standard optical microscopes and absorption-based stains. Although cells and nuclei are 3D, this standard imaging technique is only 2D, with only one viewing perspective. The development of the optical projection tomography microscope (OPTM) has allowed 180° viewing of individual cells and nuclei at sub-micron spatial resolution that is isometric. Three-dimensional features are more easily recognized and quantitatively measured using the OPTM, such as the volume, 3D-shape, surface area, surface texture, and 3D features of nuclear invaginations can be used as more sensitive classifiers for earlier conditions of cancer and pre-cancer (Fauver et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Fauver M, Seibel EJ, Rahn JR, Meyer MG, Patten FW, Neumann T, Nelson AC (2005) Three-dimensional imaging of single isolated cell nuclei using optical projection tomography. Opt Express 13(11):4210–4223" href="/article/10.1007/s10055-008-0107-9#ref-CR13" id="ref-link-section-d87028e1038">2005</a>).</p><p>Once a cell sample is obtained from the body, earlier cancer diagnosis can be made with 3D microscopic analysis that provides isometric sub-micron spatial resolution by rotating the cells during image acquisition. The resulting volumetric images are analogous to a single cell CT image using optical tomography and absorptive hematoxylin stain. Cancer classifiers based on 3D feature sets are being developed for higher diagnostic sensitivity and specificity compared with standard, single perspective, 2D optical microscopy. This collaborative work with VisionGate Inc. was started by funding from the Washington Technology Center and subsequently the National Cancer Institute.</p><h3 class="c-article__sub-heading" id="Sec19">True 3D display</h3><p>Accurate 3D vision is critical to robotic surgery and some neurosurgical procedures. The human visual system makes use of multiple correlated depth cues when judging depth relationships between objects, including stereoscopic cues (binocular disparities between the retinal image in the left eye and that of the right eye), the oculomotor cues of vergence and accommodation (feedback from the muscles controlling the aiming of the eyes and the focusing of their lenses, respectively) and the changing retinal blur as the eye shifts its focus between objects. In addition, when shifting gaze from an object at one distance to an object at a different distance, multiple eye muscles must make simultaneous and matching adjustments to aim the eyes at the new object and focus the lenses of the eyes at the correct distance, and indeed these oculomotor movements are neurally cross-coupled, such that a shift in one triggers a matching shift in the other.</p><p>Conventional electronic 3D displays can correctly reproduce stereoscopic cues but create incorrect oculomotor and retinal blur cues. These displays use two flat screens (or one multiplexed screen) to present stereo pairs to the right and left eyes, but because all of the light is emitted from a two-dimensional plane at a single viewing distance, viewers must keep the lenses of their eyes focused at that distance or else the entire display will be blurred. In order to view an object that is rendered stereoscopically behind the surface of the screen, the viewer must try to aim the eyes behind the screen and focus its lenses at the screen, i.e., it must attempt to suppress the neural cross-coupling of vergence and accommodation and aim and focus their eyes at conflicting distances. This forced decoupling of reflexively linked processes fatigues the eyes, causes discomfort, compromises image quality, and may lead to pathologies in developing visual systems. Volumetric displays can overcome this conflict, but only for small objects placed within a limited range of viewing distances and accommodation levels, and do not render occlusion cues correctly.</p><p>The HIT Lab’s multi-planar True 3-D displays (Schowengerdt and Seibel <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Schowengerdt BT, Seibel EJ (2006) True 3D scanned voxel displays using single and multiple light sources. J Soc Inf Disp 14(2):135–143" href="/article/10.1007/s10055-008-0107-9#ref-CR39" id="ref-link-section-d87028e1055">2006</a>) scan voxels of light through a projected 3D volume to generate accommodation cues that match vergence and stereoscopic retinal disparity demands and can display images and objects at viewing distances throughout the full range of human accommodation (from 6.25 cm to infinity), better mimicking natural vision, providing more accurate depth cues, and minimizing eye fatigue. By more closely replicating the natural conditions of depth perception the True 3D display may thus allow a better match between surgeon and the surgical field.</p><p>More complicated robotic surgeries will require more time in the 3D display, and a mismatch using conventional stereoscopic display could cause faster fatigue and hence more procedural errors. Enabling accurate accommodation and vergence will provide a more realistic operating experience and may facilitate the development of more complicated procedures than are currently being performed.</p></div></div></section><section aria-labelledby="Sec20"><div class="c-article-section" id="Sec20-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec20">New directions in medical informatics</h2><div class="c-article-section__content" id="Sec20-content"><p>Interactive computer graphics provides new opportunities for integrating and displaying medical data. HIT Lab research teams have focused on methods for designing the medical data display of the future and the use of interactive computer graphics in emergency medical supply management.</p><h3 class="c-article__sub-heading" id="Sec21">Immersive simulation for mixed reality medical interface design</h3><p>The emergence of electronic medical records has enabled new avenues for accessing patient data, but also presents new challenges in displaying information that is most relevant to the clinical task at hand. Under sponsorship from the DARPA Advanced Biomedical Technologies initiative, researchers at the HIT Lab have constructed a VR testbed to explore methods for clinical use of anticipated AR and ubiquitous displays of the future.</p><p>The Virtual Emergency Room (Weghorst et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Weghorst S, Oppenheimer P, Kaufman S, Haynor D, Gifford J, Edmond C, Dunbar P, Billinghurst M, Poupyrev I, Miller E (1997) The LIMIT: a VR testbed for clinical interface design. In: Presented at Medicine Meets Virtual Reality, San Diego, CA, January 1997" href="/article/10.1007/s10055-008-0107-9#ref-CR47" id="ref-link-section-d87028e1077">1997</a>) was designed as a collaborative effort among HIT Lab researchers and representatives from a variety of medical specialties, including surgery, emergency medicine, radiology, cardiology, and nursing. The team’s objective was to envision the uses of emerging data display modalities, including AR and ubiquitous devices of various sorts, in realistic clinical environments.</p><p>As an aid to prototyping and evaluating display concepts, the team developed an immersive replica of an emergency room at the Harborview Medical Center (a Level 1 trauma center in Seattle), which served as a virtual brainstorming environment for the participating clinicians. The Virtual ER was then populated with a virtual patient and a host of clinical data objects specified by our clinical collaborators, including single radiology images, multi-image CT and MRI studies, live teleconsultant video streams, patient charts, lab data, and dynamic vital signs data streams. Each data object could be grabbed, resized, and repositioned by the immersed participants to explore the efficacy of various configurations (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig11">11</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig11_HTML.jpg?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig11_HTML.jpg" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Immersive VR simulation of AR and ubiquitous display of physician-specific clinical data in the Virtual Emergency Room</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The Virtual ER also provided a testbed for systematic empirical studies of candidate data representations. Among the studies conducted in the testbed was an evaluation of a novel electrocardiogram (EKG) representation, designed by cardiologist Stan Kaufman (Kaufman et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Kaufman S, Poupyrev I, Miller E, Billinghurst M, Oppenheimer P, Weghorst S (1997) New interface metaphors for complex information space visualization: an ECG monitor object prototype. Stud Health Technol Inform 39:131–140" href="/article/10.1007/s10055-008-0107-9#ref-CR28" id="ref-link-section-d87028e1107">1997</a>), which compared the ability of practicing cardiologists to decode both a dynamic 3D representation of heart electrical activity and a traditional EKG trace, using captured streaming data. While the traditional trace led to a more accurate diagnosis, the presence of an anomalous event was detected more quickly using the dynamic 3D model display, suggesting perhaps that the new representation could be better placed in the peripheral field of view and then transformed into a traditional trace when needed.</p><h3 class="c-article__sub-heading" id="Sec22">Geospatial optimization of medical resources</h3><p>Decisions to support preparedness and response activities for disaster management are challenging due to the uncertainties of events, the need to balance preparedness and risk, and complications due to partial information and data. Under the auspices of the UW’s Pacific Rim Visualization and Analytics Center (PARVAC), a regional visual analytics center sponsored by the Department of Homeland Security, HIT Lab researchers have developed analytical and visualization tools for emergency response and preparedness.</p><p>Working with emergency response planners at the UW Medical Center, the Geospatial Optimization of Strategic Resources (GOSR) team has developed new algorithms for determining the optimal distribution of emergency medical supply caches in the Seattle region, an area vulnerable to earthquakes.</p><p>Mete and Zabinsky (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Mete HO, Zabinsky ZB (2007) Preparing for disasters: medical supply location and distribution. In: Proceedings of the INFORMS conference, Seattle, WA, 2007" href="/article/10.1007/s10055-008-0107-9#ref-CR33" id="ref-link-section-d87028e1122">2007</a>) introduce stochastic optimization models to plan for the storage and distribution of medical supplies to be used in emergencies in the region. Their overall objective is to determine the optimal storage location and inventory levels for medical supply warehouses before an event occurs, to balance the risk of the warehouses themselves incurring earthquake damage, yet providing for fast distribution to hazardous areas. After the onset of a simulated disaster, their algorithms then optimize the delivery routes of medical supplies to hospitals to reduce travel time, using up-to-date information about where the needs are greatest, recognizing that roads and bridges may have sustained damage.</p><p>To evaluate these optimization models, the researchers then incorporated their algorithms into PARVAC’s RimSim architecture, a software platform for simulating emergency events in cities around the Pacific Rim (Campbell et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Campbell BD, Mete HO, Furness T, Weghorst S, Zabinsky Z (2008) Emergency response planning and training through interactive simulation and visualization with decision support. In: Proceedings of 2008 IEEE conference on technologies for homeland security. Boston, MA, pp 176–180" href="/article/10.1007/s10055-008-0107-9#ref-CR9" id="ref-link-section-d87028e1128">2008</a>). A sample RimSim visualization of the GOSR algorithms in action is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10055-008-0107-9#Fig12">12</a>. These generic geospatial optimization algorithms provide a robust decision support mechanism, which appears to be serviceable under the wide variety of possible disaster types and magnitudes.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig12_HTML.jpg?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10055-008-0107-9/MediaObjects/10055_2008_107_Fig12_HTML.jpg" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Geospatial optimization of medical supply caching and delivery within the RimSim emergency response simulation environment</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10055-008-0107-9/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        </div></div></section><section aria-labelledby="Sec23"><div class="c-article-section" id="Sec23-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec23">Summary and conclusions</h2><div class="c-article-section__content" id="Sec23-content"><p>HIT Lab researchers have ventured into a wide range of medical interface problem areas, developing solutions that span disciplines and offer advances in hardware, software, application development, and human factors research. Along the way we have observed some correlates of successful R&amp;D work in this area, and we offer them here as “lessons learned”:</p><ul class="u-list-style-dash">
                  <li>
                    <p><i>Interdisciplinary teams are essential for system design</i>. Conceptual and functional prototype development requires focused involvement by individuals with a wide variety of skills, knowledge, and interests.</p>
                  </li>
                  <li>
                    <p><i>Medical interface development is a two-way iterative bootstrapping process between technologists and medical practitioners</i>.</p>
                  </li>
                  <li>
                    <p><i>When researchers band together into larger laboratories they are better able to fine-tune their research teams</i> by splitting expertise across projects.</p>
                  </li>
                  <li>
                    <p><i>Technology and system demonstrations are critical tools for system development.</i> They can provide valuable proofs of concept, conceptual playgrounds, potential jumping-off points for further R&amp;D, in part a fortuitous result of the mutual bootstrapping process.</p>
                  </li>
                  <li>
                    <p><i>Virtual reality is alive and well in medicine</i>, and is rapidly integrating into common medical practice. Dialog about VR has become a mainstream topic at both integrated conferences such as Medicine Meets Virtual Reality and medical specialty meetings.</p>
                  </li>
                </ul>
                     <p>We look forward to continuing our efforts in discovering and developing linkages between VR (and associated technologies) and the ever-expanding domains of medicine.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Bagley, B. Kelly, N. Tunnicliffe, G. Turnbull, JM. Walker, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="Bagley S, Kelly B, Tunnicliffe N, Turnbull G, Walker JM (1991) The effect of visual cues on the gait of indepe" /><p class="c-article-references__text" id="ref-CR1">Bagley S, Kelly B, Tunnicliffe N, Turnbull G, Walker JM (1991) The effect of visual cues on the gait of independently mobile Parkinson’s disease patients. Physiotherapy 77:415–420</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0031-9406%2810%2962035-4" aria-label="View reference 1">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effect%20of%20visual%20cues%20on%20the%20gait%20of%20independently%20mobile%20Parkinson%E2%80%99s%20disease%20patients&amp;journal=Physiotherapy&amp;volume=77&amp;pages=415-420&amp;publication_year=1991&amp;author=Bagley%2CS&amp;author=Kelly%2CB&amp;author=Tunnicliffe%2CN&amp;author=Turnbull%2CG&amp;author=Walker%2CJM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Berg D, Raugi G, Gladstone H, Berkley J, Ganter M, Turkiyyah G (2001) Virtual reality simulators for dermatolo" /><p class="c-article-references__text" id="ref-CR2">Berg D, Raugi G, Gladstone H, Berkley J, Ganter M, Turkiyyah G (2001) Virtual reality simulators for dermatologic surgery: measuring their validity as a teaching tool. In: Proceedings of medicine meets virtual reality 2001, Newport Beach, CA</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Berkley, S. Weghorst, H. Gladstone, G. Raugi, D. Berg, M. Ganter, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Berkley J, Weghorst S, Gladstone H, Raugi G, Berg D, Ganter M (1999) Banded matrix approach to finite element " /><p class="c-article-references__text" id="ref-CR3">Berkley J, Weghorst S, Gladstone H, Raugi G, Berg D, Ganter M (1999) Banded matrix approach to finite element modeling for soft tissue simulation. Virtual Real 4:203–212</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2FBF01418156" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Banded%20matrix%20approach%20to%20finite%20element%20modeling%20for%20soft%20tissue%20simulation&amp;journal=Virtual%20Real&amp;volume=4&amp;pages=203-212&amp;publication_year=1999&amp;author=Berkley%2CJ&amp;author=Weghorst%2CS&amp;author=Gladstone%2CH&amp;author=Raugi%2CG&amp;author=Berg%2CD&amp;author=Ganter%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Berkley J, Oppenheimer P, Weghorst S, Berg D, Raugi G, Haynor D, Ganter M, Brooking C, Turkiyyah G (2000) Crea" /><p class="c-article-references__text" id="ref-CR4">Berkley J, Oppenheimer P, Weghorst S, Berg D, Raugi G, Haynor D, Ganter M, Brooking C, Turkiyyah G (2000) Creating fast finite element models from medical images. In: Proceedings of medicine meets virtual reality 2000, Newport Beach, CA</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Berkley, G. Turkiyyah, D. Berg, M. Ganter, S. Weghorst, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Berkley J, Turkiyyah G, Berg D, Ganter M, Weghorst S (2004) Real-time finite element modeling for surgery simu" /><p class="c-article-references__text" id="ref-CR5">Berkley J, Turkiyyah G, Berg D, Ganter M, Weghorst S (2004) Real-time finite element modeling for surgery simulation: an application to virtual suturing. IEEE Trans Vis Comput Graph 10(3):1–12</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTVCG.2004.1272730" aria-label="View reference 5">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Real-time%20finite%20element%20modeling%20for%20surgery%20simulation%3A%20an%20application%20to%20virtual%20suturing&amp;journal=IEEE%20Trans%20Vis%20Comput%20Graph&amp;volume=10&amp;issue=3&amp;pages=1-12&amp;publication_year=2004&amp;author=Berkley%2CJ&amp;author=Turkiyyah%2CG&amp;author=Berg%2CD&amp;author=Ganter%2CM&amp;author=Weghorst%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Billinghurst M, Kato H (1999) Collaborative mixed reality. In: Proceedings of international symposium on mixed" /><p class="c-article-references__text" id="ref-CR6">Billinghurst M, Kato H (1999) Collaborative mixed reality. In: Proceedings of international symposium on mixed reality (ISMR ‘99). Mixed reality—merging real and virtual worlds. Yokohama, Japan, pp 261–284</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Billinghurst M, Kato H, Poupyrev I (2001) MagicBook: transitioning between reality and virtuality. Presented a" /><p class="c-article-references__text" id="ref-CR7">Billinghurst M, Kato H, Poupyrev I (2001) MagicBook: transitioning between reality and virtuality. Presented at CHI 2001, March 30–April 5, 2001, Seattle, WA</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Bryant, EJ. Seibel, CM. Lee, KE. Schroder, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Bryant R, Seibel EJ, Lee CM, Schroder KE (2004) Low-cost wearable low vision aid using a handmade retinal ligh" /><p class="c-article-references__text" id="ref-CR8">Bryant R, Seibel EJ, Lee CM, Schroder KE (2004) Low-cost wearable low vision aid using a handmade retinal light scanning microdisplay. J Soc Inf Disp 12(4):397</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1889%2F1.1847738" aria-label="View reference 8">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Low-cost%20wearable%20low%20vision%20aid%20using%20a%20handmade%20retinal%20light%20scanning%20microdisplay&amp;journal=J%20Soc%20Inf%20Disp&amp;volume=12&amp;issue=4&amp;publication_year=2004&amp;author=Bryant%2CR&amp;author=Seibel%2CEJ&amp;author=Lee%2CCM&amp;author=Schroder%2CKE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Campbell BD, Mete HO, Furness T, Weghorst S, Zabinsky Z (2008) Emergency response planning and training throug" /><p class="c-article-references__text" id="ref-CR9">Campbell BD, Mete HO, Furness T, Weghorst S, Zabinsky Z (2008) Emergency response planning and training through interactive simulation and visualization with decision support. In: Proceedings of 2008 IEEE conference on technologies for homeland security. Boston, MA, pp 176–180</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AS. Carlin, HG. Hoffman, S. Weghorst, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Carlin AS, Hoffman HG, Weghorst S (1997) Virtual reality and tactile augmentation in the treatment of spider p" /><p class="c-article-references__text" id="ref-CR10">Carlin AS, Hoffman HG, Weghorst S (1997) Virtual reality and tactile augmentation in the treatment of spider phobia: a case study. Behav Res Ther 35:153–158</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0005-7967%2896%2900085-X" aria-label="View reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20and%20tactile%20augmentation%20in%20the%20treatment%20of%20spider%20phobia%3A%20a%20case%20study&amp;journal=Behav%20Res%20Ther&amp;volume=35&amp;pages=153-158&amp;publication_year=1997&amp;author=Carlin%2CAS&amp;author=Hoffman%2CHG&amp;author=Weghorst%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Difede, J. Cukor, N. Jayasinghe, I. Patt, S. Jedel, L. Spielman, C. Giosan, HG. Hoffman, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Difede J, Cukor J, Jayasinghe N, Patt I, Jedel S, Spielman L, Giosan C, Hoffman HG (2007) Virtual reality expo" /><p class="c-article-references__text" id="ref-CR11">Difede J, Cukor J, Jayasinghe N, Patt I, Jedel S, Spielman L, Giosan C, Hoffman HG (2007) Virtual reality exposure therapy for the treatment of posttraumatic stress disorder following September 11, 2001. J Clin Psychiatry 68:1639–1647</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20exposure%20therapy%20for%20the%20treatment%20of%20posttraumatic%20stress%20disorder%20following%20September%2011%2C%202001&amp;journal=J%20Clin%20Psychiatry&amp;volume=68&amp;pages=1639-1647&amp;publication_year=2007&amp;author=Difede%2CJ&amp;author=Cukor%2CJ&amp;author=Jayasinghe%2CN&amp;author=Patt%2CI&amp;author=Jedel%2CS&amp;author=Spielman%2CL&amp;author=Giosan%2CC&amp;author=Hoffman%2CHG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Difede, HG. Hoffman, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Difede J, Hoffman HG (2002) Virtual reality exposure therapy for World Trade Center post traumatic stress diso" /><p class="c-article-references__text" id="ref-CR12">Difede J, Hoffman HG (2002) Virtual reality exposure therapy for World Trade Center post traumatic stress disorder: a case report. Cyberpsychol Behav 5:529–536</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1089%2F109493102321018169" aria-label="View reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20exposure%20therapy%20for%20World%20Trade%20Center%20post%20traumatic%20stress%20disorder%3A%20a%20case%20report&amp;journal=Cyberpsychol%20Behav&amp;volume=5&amp;pages=529-536&amp;publication_year=2002&amp;author=Difede%2CJ&amp;author=Hoffman%2CHG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Fauver, EJ. Seibel, JR. Rahn, MG. Meyer, FW. Patten, T. Neumann, AC. Nelson, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Fauver M, Seibel EJ, Rahn JR, Meyer MG, Patten FW, Neumann T, Nelson AC (2005) Three-dimensional imaging of si" /><p class="c-article-references__text" id="ref-CR13">Fauver M, Seibel EJ, Rahn JR, Meyer MG, Patten FW, Neumann T, Nelson AC (2005) Three-dimensional imaging of single isolated cell nuclei using optical projection tomography. Opt Express 13(11):4210–4223</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1364%2FOPEX.13.004210" aria-label="View reference 13">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Three-dimensional%20imaging%20of%20single%20isolated%20cell%20nuclei%20using%20optical%20projection%20tomography&amp;journal=Opt%20Express&amp;volume=13&amp;issue=11&amp;pages=4210-4223&amp;publication_year=2005&amp;author=Fauver%2CM&amp;author=Seibel%2CEJ&amp;author=Rahn%2CJR&amp;author=Meyer%2CMG&amp;author=Patten%2CFW&amp;author=Neumann%2CT&amp;author=Nelson%2CAC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Furness TA (1986) The super cockpit and human factors challenges. In: Ung M (ed) Proceedings of human factors " /><p class="c-article-references__text" id="ref-CR14">Furness TA (1986) The super cockpit and human factors challenges. In: Ung M (ed) Proceedings of human factors society 30th annual meeting. Dayton, OH, pp 48–52</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Furness T (1988) Harnessing virtual space. In: Proceedings of SID international symposium digest of technical " /><p class="c-article-references__text" id="ref-CR15">Furness T (1988) Harnessing virtual space. In: Proceedings of SID international symposium digest of technical papers. Playa del Rey, CA, pp 4–7</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Garcia-Palacios, HG. Hoffman, C. Carlin, TA. Furness, C. Botella-Arbona, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Garcia-Palacios A, Hoffman HG, Carlin C, Furness TAIII, Botella-Arbona C (2002) Virtual reality in the treatme" /><p class="c-article-references__text" id="ref-CR16">Garcia-Palacios A, Hoffman HG, Carlin C, Furness TAIII, Botella-Arbona C (2002) Virtual reality in the treatment of spider phobia: a controlled study. Behav Res Ther 40(9):983–993</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0005-7967%2801%2900068-7" aria-label="View reference 16">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20in%20the%20treatment%20of%20spider%20phobia%3A%20a%20controlled%20study&amp;journal=Behav%20Res%20Ther&amp;volume=40&amp;issue=9&amp;pages=983-993&amp;publication_year=2002&amp;author=Garcia-Palacios%2CA&amp;author=Hoffman%2CHG&amp;author=Carlin%2CC&amp;author=Furness%2CTA&amp;author=Botella-Arbona%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gillet A, Goodsell D, Sanner MF, Stoffler D, Weghorst S, Winn W, Olson AJ (2004) Computer-linked autofabricate" /><p class="c-article-references__text" id="ref-CR17">Gillet A, Goodsell D, Sanner MF, Stoffler D, Weghorst S, Winn W, Olson AJ (2004) Computer-linked autofabricated 3D model for teaching structural biology. In: Proceedings of SIGGRAPH 2004, Los Angeles, CA</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="HG. Hoffman, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Hoffman HG (1998) Physically touching virtual objects using tactile augmentation enhances the realism of virtu" /><p class="c-article-references__text" id="ref-CR19">Hoffman HG (1998) Physically touching virtual objects using tactile augmentation enhances the realism of virtual environments. In: Proceedings of the IEEE virtual reality annual international symposium ‘98, Atlanta, GA. IEEE Computer Society, Los Alamitos, pp 59–63</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Physically%20touching%20virtual%20objects%20using%20tactile%20augmentation%20enhances%20the%20realism%20of%20virtual%20environments.%20In%3A%20Proceedings%20of%20the%20IEEE%20virtual%20reality%20annual%20international%20symposium%20%E2%80%9898%2C%20Atlanta%2C%20GA&amp;pages=59-63&amp;publication_year=1998&amp;author=Hoffman%2CHG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hoffman H (2004) Virtual-reality therapy. Sci Am" /><p class="c-article-references__text" id="ref-CR20">Hoffman H (2004) Virtual-reality therapy. Sci Am</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HG. Hoffman, JN. Doctor, DR. Patterson, GJ. Carrougher, TA. Furness, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Hoffman HG, Doctor JN, Patterson DR, Carrougher GJ, Furness TAIII (2000) Use of virtual reality for adjunctive" /><p class="c-article-references__text" id="ref-CR21">Hoffman HG, Doctor JN, Patterson DR, Carrougher GJ, Furness TAIII (2000) Use of virtual reality for adjunctive treatment of adolescent burn pain during wound care: a case report. Pain 85:305–309</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0304-3959%2899%2900275-4" aria-label="View reference 20">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Use%20of%20virtual%20reality%20for%20adjunctive%20treatment%20of%20adolescent%20burn%20pain%20during%20wound%20care%3A%20a%20case%20report&amp;journal=Pain&amp;volume=85&amp;pages=305-309&amp;publication_year=2000&amp;author=Hoffman%2CHG&amp;author=Doctor%2CJN&amp;author=Patterson%2CDR&amp;author=Carrougher%2CGJ&amp;author=Furness%2CTA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HG. Hoffman, DR. Patterson, GJ. Carrougher, S. Sharar, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Hoffman HG, Patterson DR, Carrougher GJ, Sharar S (2001) The effectiveness of virtual reality based pain contr" /><p class="c-article-references__text" id="ref-CR22">Hoffman HG, Patterson DR, Carrougher GJ, Sharar S (2001) The effectiveness of virtual reality based pain control with multiple treatments. Clin J Pain 17:229–235</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1097%2F00002508-200109000-00007" aria-label="View reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effectiveness%20of%20virtual%20reality%20based%20pain%20control%20with%20multiple%20treatments&amp;journal=Clin%20J%20Pain&amp;volume=17&amp;pages=229-235&amp;publication_year=2001&amp;author=Hoffman%2CHG&amp;author=Patterson%2CDR&amp;author=Carrougher%2CGJ&amp;author=Sharar%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HG. Hoffman, A. Garcia-Palacios, VA. Carlin, J. Furness, . Botella-Arbona, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Hoffman HG, Garcia-Palacios A, Carlin C, Furness TA III, Botella-Arbona (2003a) Interfaces that heal: coupling" /><p class="c-article-references__text" id="ref-CR23">Hoffman HG, Garcia-Palacios A, Carlin C, Furness TA III, Botella-Arbona (2003a) Interfaces that heal: coupling real and virtual objects to cure spider phobia. Int J Hum Comput Interact 16:283–300</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1207%2FS15327590IJHC1602_08" aria-label="View reference 22">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Interfaces%20that%20heal%3A%20coupling%20real%20and%20virtual%20objects%20to%20cure%20spider%20phobia&amp;journal=Int%20J%20Hum%20Comput%20Interact&amp;volume=16&amp;pages=283-300&amp;publication_year=2003&amp;author=Hoffman%2CHG&amp;author=Garcia-Palacios%2CA&amp;author=Carlin%2CVA&amp;author=Furness%2CJ&amp;author=Botella-Arbona%2C">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HG. Hoffman, A. Garcia-Palacios, VA. Kapa, J. Beecher, SR. Sharar, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Hoffman HG, Garcia-Palacios A, Kapa VA, Beecher J, Sharar SR (2003b) Immersive virtual reality for reducing ex" /><p class="c-article-references__text" id="ref-CR18">Hoffman HG, Garcia-Palacios A, Kapa VA, Beecher J, Sharar SR (2003b) Immersive virtual reality for reducing experimental ischemic pain. Int J Hum Comput Interact 15:469–486</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1207%2FS15327590IJHC1503_10" aria-label="View reference 23">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Immersive%20virtual%20reality%20for%20reducing%20experimental%20ischemic%20pain&amp;journal=Int%20J%20Hum%20Comput%20Interact&amp;volume=15&amp;pages=469-486&amp;publication_year=2003&amp;author=Hoffman%2CHG&amp;author=Garcia-Palacios%2CA&amp;author=Kapa%2CVA&amp;author=Beecher%2CJ&amp;author=Sharar%2CSR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HG. Hoffman, SR. Sharar, B. Coda, JJ. Everett, M. Ciol, T. Richards, DR. Patterson, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Hoffman HG, Sharar SR, Coda B, Everett JJ, Ciol M, Richards T, Patterson DR (2004a) Manipulating presence infl" /><p class="c-article-references__text" id="ref-CR24">Hoffman HG, Sharar SR, Coda B, Everett JJ, Ciol M, Richards T, Patterson DR (2004a) Manipulating presence influences the magnitude of virtual reality analgesia. Pain 111(1–2):162–168</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.pain.2004.06.013" aria-label="View reference 24">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Manipulating%20presence%20influences%20the%20magnitude%20of%20virtual%20reality%20analgesia&amp;journal=Pain&amp;volume=111&amp;issue=1%E2%80%932&amp;pages=162-168&amp;publication_year=2004&amp;author=Hoffman%2CHG&amp;author=Sharar%2CSR&amp;author=Coda%2CB&amp;author=Everett%2CJJ&amp;author=Ciol%2CM&amp;author=Richards%2CT&amp;author=Patterson%2CDR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HG. Hoffman, DR. Patterson, J. Magula, GJ. Carrougher, K. Zeltzer, S. Dagadakis, SR. Sharar, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Hoffman HG, Patterson DR, Magula J, Carrougher GJ, Zeltzer K, Dagadakis S, Sharar SR (2004b) Water-friendly vi" /><p class="c-article-references__text" id="ref-CR25">Hoffman HG, Patterson DR, Magula J, Carrougher GJ, Zeltzer K, Dagadakis S, Sharar SR (2004b) Water-friendly virtual reality pain control during wound care. J Clin Psychol 60(2):189–195</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2Fjclp.10244" aria-label="View reference 25">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Water-friendly%20virtual%20reality%20pain%20control%20during%20wound%20care&amp;journal=J%20Clin%20Psychol&amp;volume=60&amp;issue=2&amp;pages=189-195&amp;publication_year=2004&amp;author=Hoffman%2CHG&amp;author=Patterson%2CDR&amp;author=Magula%2CJ&amp;author=Carrougher%2CGJ&amp;author=Zeltzer%2CK&amp;author=Dagadakis%2CS&amp;author=Sharar%2CSR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HG. Hoffman, TL. Richards, J. Magula, EJ. Seibel, C. Hayes, M. Mathis, SR. Sharar, K. Maravilla, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Hoffman HG, Richards TL, Magula J, Seibel EJ, Hayes C, Mathis M, Sharar SR, Maravilla K (2004c) A magnet-frien" /><p class="c-article-references__text" id="ref-CR55">Hoffman HG, Richards TL, Magula J, Seibel EJ, Hayes C, Mathis M, Sharar SR, Maravilla K (2004c) A magnet-friendly virtual reality fiberoptic image delivery system. Cyberpsychol Behav 6:645–648</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1089%2F109493103322725423" aria-label="View reference 26">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20magnet-friendly%20virtual%20reality%20fiberoptic%20image%20delivery%20system&amp;journal=Cyberpsychol%20Behav&amp;volume=6&amp;pages=645-648&amp;publication_year=2004&amp;author=Hoffman%2CHG&amp;author=Richards%2CTL&amp;author=Magula%2CJ&amp;author=Seibel%2CEJ&amp;author=Hayes%2CC&amp;author=Mathis%2CM&amp;author=Sharar%2CSR&amp;author=Maravilla%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HG. Hoffman, TL. Richards, T. Van Oostrom, BA. Coda, MP. Jensen, DK. Blough, SR. Sharar, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Hoffman HG, Richards TL, Van Oostrom T, Coda BA, Jensen MP, Blough DK, Sharar SR (2007) The analgesic effects " /><p class="c-article-references__text" id="ref-CR56">Hoffman HG, Richards TL, Van Oostrom T, Coda BA, Jensen MP, Blough DK, Sharar SR (2007) The analgesic effects of opioids and immersive virtual reality distraction: evidence from subjective and functional brain imaging assessments. Anesth Analg 105:1776–1783</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1213%2F01.ane.0000270205.45146.db" aria-label="View reference 27">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20analgesic%20effects%20of%20opioids%20and%20immersive%20virtual%20reality%20distraction%3A%20evidence%20from%20subjective%20and%20functional%20brain%20imaging%20assessments&amp;journal=Anesth%20Analg&amp;volume=105&amp;pages=1776-1783&amp;publication_year=2007&amp;author=Hoffman%2CHG&amp;author=Richards%2CTL&amp;author=Van%20Oostrom%2CT&amp;author=Coda%2CBA&amp;author=Jensen%2CMP&amp;author=Blough%2CDK&amp;author=Sharar%2CSR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HG. Hoffman, DR. Patterson, E. Seibel, M. Soltani, L. Jewett-Leahy, SR. Sharar, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Hoffman HG, Patterson DR, Seibel E, Soltani M, Jewett-Leahy L, Sharar SR (2008) Virtual reality pain control d" /><p class="c-article-references__text" id="ref-CR57">Hoffman HG, Patterson DR, Seibel E, Soltani M, Jewett-Leahy L, Sharar SR (2008) Virtual reality pain control during burn wound debridement in the hydrotank. Clin J Pain 24(4):299–304</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20pain%20control%20during%20burn%20wound%20debridement%20in%20the%20hydrotank&amp;journal=Anesth%20Analg&amp;volume=24&amp;issue=4&amp;pages=299-304&amp;publication_year=2008&amp;author=Hoffman%2CHG&amp;author=Patterson%2CDR&amp;author=Seibel%2CE&amp;author=Soltani%2CM&amp;author=Jewett-Leahy%2CL&amp;author=Sharar%2CSR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Imai, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Imai H (1996) Clinicophysiological features of akinesia. Eur Neurol 36(Suppl 1):9–12" /><p class="c-article-references__text" id="ref-CR26">Imai H (1996) Clinicophysiological features of akinesia. Eur Neurol 36(Suppl 1):9–12</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1159%2F000118877" aria-label="View reference 29">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Clinicophysiological%20features%20of%20akinesia&amp;journal=Eur%20Neurol&amp;volume=36&amp;issue=Suppl%201&amp;pages=9-12&amp;publication_year=1996&amp;author=Imai%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="TA. Kaminsky, BJ. Dudgeon, FF. Billingsley, PH. Mitchell, SJ. Weghorst, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Kaminsky TA, Dudgeon BJ, Billingsley FF, Mitchell PH, Weghorst SJ (2007) Virtual cues and functional mobility " /><p class="c-article-references__text" id="ref-CR27">Kaminsky TA, Dudgeon BJ, Billingsley FF, Mitchell PH, Weghorst SJ (2007) Virtual cues and functional mobility of people with Parkinson’s disease: a single-subject pilot study. J Rehabil Res Dev 44(3):437–448</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1682%2FJRRD.2006.09.0109" aria-label="View reference 30">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20cues%20and%20functional%20mobility%20of%20people%20with%20Parkinson%E2%80%99s%20disease%3A%20a%20single-subject%20pilot%20study&amp;journal=J%20Rehabil%20Res%20Dev&amp;volume=44&amp;issue=3&amp;pages=437-448&amp;publication_year=2007&amp;author=Kaminsky%2CTA&amp;author=Dudgeon%2CBJ&amp;author=Billingsley%2CFF&amp;author=Mitchell%2CPH&amp;author=Weghorst%2CSJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Kaufman, I. Poupyrev, E. Miller, M. Billinghurst, P. Oppenheimer, S. Weghorst, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Kaufman S, Poupyrev I, Miller E, Billinghurst M, Oppenheimer P, Weghorst S (1997) New interface metaphors for " /><p class="c-article-references__text" id="ref-CR28">Kaufman S, Poupyrev I, Miller E, Billinghurst M, Oppenheimer P, Weghorst S (1997) New interface metaphors for complex information space visualization: an ECG monitor object prototype. Stud Health Technol Inform 39:131–140</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=New%20interface%20metaphors%20for%20complex%20information%20space%20visualization%3A%20an%20ECG%20monitor%20object%20prototype&amp;journal=Stud%20Health%20Technol%20Inform&amp;volume=39&amp;pages=131-140&amp;publication_year=1997&amp;author=Kaufman%2CS&amp;author=Poupyrev%2CI&amp;author=Miller%2CE&amp;author=Billinghurst%2CM&amp;author=Oppenheimer%2CP&amp;author=Weghorst%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="GN. Lewis, WD. Byblow, SE. Walt, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Lewis GN, Byblow WD, Walt SE (2000) Stride length regulation in Parkinson’s disease: the use of extrinsic, vis" /><p class="c-article-references__text" id="ref-CR29">Lewis GN, Byblow WD, Walt SE (2000) Stride length regulation in Parkinson’s disease: the use of extrinsic, visual cues. Brain 123:2077–2090</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1093%2Fbrain%2F123.10.2077" aria-label="View reference 32">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Stride%20length%20regulation%20in%20Parkinson%E2%80%99s%20disease%3A%20the%20use%20of%20extrinsic%2C%20visual%20cues&amp;journal=Brain&amp;volume=123&amp;pages=2077-2090&amp;publication_year=2000&amp;author=Lewis%2CGN&amp;author=Byblow%2CWD&amp;author=Walt%2CSE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lindblad AJ, Turkiyyah GM, Weghorst SJ, Berg D (2006) Real-time finite element based virtual tissue cutting. P" /><p class="c-article-references__text" id="ref-CR30">Lindblad AJ, Turkiyyah GM, Weghorst SJ, Berg D (2006) Real-time finite element based virtual tissue cutting. Presented at MMVR 2006, 24–27 January 2006, Long Beach, CA</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Maani, HG. Hoffman, PA. DeSocio, M. Morrow, C. Galin, J. Magula, A. Maiers, K. Gaylord, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Maani C, Hoffman HG, DeSocio PA, Morrow M, Galin C, Magula J, Maiers A, Gaylord K (2008) Pain control during w" /><p class="c-article-references__text" id="ref-CR31">Maani C, Hoffman HG, DeSocio PA, Morrow M, Galin C, Magula J, Maiers A, Gaylord K (2008) Pain control during wound care for combat-related burn injuries using custom articulated arm mounted virtual reality goggles. J CyberTher Rehabil 1:193–198</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Pain%20control%20during%20wound%20care%20for%20combat-related%20burn%20injuries%20using%20custom%20articulated%20arm%20mounted%20virtual%20reality%20goggles&amp;journal=J%20CyberTher%20Rehabil&amp;volume=1&amp;pages=193-198&amp;publication_year=2008&amp;author=Maani%2CC&amp;author=Hoffman%2CHG&amp;author=DeSocio%2CPA&amp;author=Morrow%2CM&amp;author=Galin%2CC&amp;author=Magula%2CJ&amp;author=Maiers%2CA&amp;author=Gaylord%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="E. Medina, Y. Chen, S. Weghorst, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Medina E, Chen Y, Weghorst S (2007) Understanding biochemistry with augmented reality. In: Montgomerie C, Seal" /><p class="c-article-references__text" id="ref-CR32">Medina E, Chen Y, Weghorst S (2007) Understanding biochemistry with augmented reality. In: Montgomerie C, Seale J (eds) Proceedings of world conference on educational multimedia, hypermedia and telecommunications 2007. AACE, Chesapeake, pp 4235–4239</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proceedings%20of%20world%20conference%20on%20educational%20multimedia%2C%20hypermedia%20and%20telecommunications%202007&amp;pages=4235-4239&amp;publication_year=2007&amp;author=Medina%2CE&amp;author=Chen%2CY&amp;author=Weghorst%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mete HO, Zabinsky ZB (2007) Preparing for disasters: medical supply location and distribution. In: Proceedings" /><p class="c-article-references__text" id="ref-CR33">Mete HO, Zabinsky ZB (2007) Preparing for disasters: medical supply location and distribution. In: Proceedings of the INFORMS conference, Seattle, WA, 2007</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="ME. Morris, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Morris ME (2000) Movement disorders in people with Parkinson’s disease: a model for physical therapy. Phys The" /><p class="c-article-references__text" id="ref-CR34">Morris ME (2000) Movement disorders in people with Parkinson’s disease: a model for physical therapy. Phys Ther 80:578–597</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Movement%20disorders%20in%20people%20with%20Parkinson%E2%80%99s%20disease%3A%20a%20model%20for%20physical%20therapy&amp;journal=Phys%20Ther&amp;volume=80&amp;pages=578-597&amp;publication_year=2000&amp;author=Morris%2CME">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Oppenheimer P, Gupta A, Weghorst S, Sweet R, Porter J (2001) The representation of blood flow in endourologic " /><p class="c-article-references__text" id="ref-CR35">Oppenheimer P, Gupta A, Weghorst S, Sweet R, Porter J (2001) The representation of blood flow in endourologic surgical simulations. In: Proceedings of medicine meets virtual reality 2001. Newport Beach, CA, pp 365–371</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pryor HL, Furness TA, Viirre E (1998) The virtual retinal display: a new display technology using scanned lase" /><p class="c-article-references__text" id="ref-CR36">Pryor HL, Furness TA, Viirre E (1998) The virtual retinal display: a new display technology using scanned laser light. In: Proceedings of human factors and ergonomics society, 42nd annual meeting. Santa Monica, CA, pp 1570–1574</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Riess T, Weghorst S (1995) Augmented reality in the treatment of Parkinson's disease. In: Proceedings of medic" /><p class="c-article-references__text" id="ref-CR58">Riess T, Weghorst S (1995) Augmented reality in the treatment of Parkinson's disease. In: Proceedings of medicine meets virtual reality III, San Diego, CA, pp 298–302</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="G. Sankaranarayanan, S. Weghorst, MF. Sanner, A. Gillet, AJ. Olson, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Sankaranarayanan G, Weghorst S, Sanner MF, Gillet A, Olson AJ (2003) Role of haptics in teaching structural mo" /><p class="c-article-references__text" id="ref-CR37">Sankaranarayanan G, Weghorst S, Sanner MF, Gillet A, Olson AJ (2003) Role of haptics in teaching structural molecular biology<i>.</i> In: Proceedings of 11th international symposium on haptic interfaces for virtual environment and teleoperator systems, March 22–23, 2003. Los Angeles, CA, pp 363–266</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 41 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Role%20of%20haptics%20in%20teaching%20structural%20molecular%20biology.%20In%3A%20Proceedings%20of%2011th%20international%20symposium%20on%20haptic%20interfaces%20for%20virtual%20environment%20and%20teleoperator%20systems%2C%20March%2022%E2%80%9323%2C%202003&amp;pages=363-266&amp;publication_year=2003&amp;author=Sankaranarayanan%2CG&amp;author=Weghorst%2CS&amp;author=Sanner%2CMF&amp;author=Gillet%2CA&amp;author=Olson%2CAJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MF. Sanner, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Sanner MF (1999) Python: a programming language for software integration and development. J Mol Graph Model 17" /><p class="c-article-references__text" id="ref-CR38">Sanner MF (1999) Python: a programming language for software integration and development. J Mol Graph Model 17(1):57–61</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 42 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Python%3A%20a%20programming%20language%20for%20software%20integration%20and%20development&amp;journal=J%20Mol%20Graph%20Model&amp;volume=17&amp;issue=1&amp;pages=57-61&amp;publication_year=1999&amp;author=Sanner%2CMF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="BT. Schowengerdt, EJ. Seibel, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Schowengerdt BT, Seibel EJ (2006) True 3D scanned voxel displays using single and multiple light sources. J So" /><p class="c-article-references__text" id="ref-CR39">Schowengerdt BT, Seibel EJ (2006) True 3D scanned voxel displays using single and multiple light sources. J Soc Inf Disp 14(2):135–143</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1889%2F1.2176115" aria-label="View reference 43">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 43 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=True%203D%20scanned%20voxel%20displays%20using%20single%20and%20multiple%20light%20sources&amp;journal=J%20Soc%20Inf%20Disp&amp;volume=14&amp;issue=2&amp;pages=135-143&amp;publication_year=2006&amp;author=Schowengerdt%2CBT&amp;author=Seibel%2CEJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EJ. Seibel, QYL. Smithwick, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Seibel EJ, Smithwick QYL (2002) Unique features of optical scanning, single fiber endoscopy. Lasers Surg Med 3" /><p class="c-article-references__text" id="ref-CR40">Seibel EJ, Smithwick QYL (2002) Unique features of optical scanning, single fiber endoscopy. Lasers Surg Med 30(3):177–183</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1002%2Flsm.10029" aria-label="View reference 44">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 44 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Unique%20features%20of%20optical%20scanning%2C%20single%20fiber%20endoscopy&amp;journal=Lasers%20Surg%20Med&amp;volume=30&amp;issue=3&amp;pages=177-183&amp;publication_year=2002&amp;author=Seibel%2CEJ&amp;author=Smithwick%2CQYL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Seibel EJ, Smithwick QYJ, Brown CM, Reinhall PG (2001) Single fiber flexible endoscope: general design for sma" /><p class="c-article-references__text" id="ref-CR41">Seibel EJ, Smithwick QYJ, Brown CM, Reinhall PG (2001) Single fiber flexible endoscope: general design for small size, high resolution, and wide field of view. In: Proceedings of the SPIE, biomonitoring and endoscopy technologies, San Diego, CA, vol 4158, pp 29–39</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Seibel EJ, Johnston RS, Melville CD (2006) A full-color scanning fiber endoscope. In: Gannot I (ed) Optical fi" /><p class="c-article-references__text" id="ref-CR42">Seibel EJ, Johnston RS, Melville CD (2006) A full-color scanning fiber endoscope. In: Gannot I (ed) Optical fibers and sensors for medical diagnostics and treatment applications. Proceedings of SPIE, vol 6083, pp 9–16</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EJ. Seibel, RE. Carroll, JA. Dominitz, RS. Johnston, CD. Melville, CM. Lee, SM. Seitz, MB. Kimmey, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Seibel EJ, Carroll RE, Dominitz JA, Johnston RS, Melville CD, Lee CM, Seitz SM, Kimmey MB (2008) Tethered-caps" /><p class="c-article-references__text" id="ref-CR43">Seibel EJ, Carroll RE, Dominitz JA, Johnston RS, Melville CD, Lee CM, Seitz SM, Kimmey MB (2008) Tethered-capsule endoscopy, a low-cost and high-performance alternative technology for the screening of esophageal cancer and Barrett’s esophagus. IEEE Trans Biomed Eng 55(3):1032–1042</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTBME.2008.915680" aria-label="View reference 47">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 47 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Tethered-capsule%20endoscopy%2C%20a%20low-cost%20and%20high-performance%20alternative%20technology%20for%20the%20screening%20of%20esophageal%20cancer%20and%20Barrett%E2%80%99s%20esophagus&amp;journal=IEEE%20Trans%20Biomed%20Eng&amp;volume=55&amp;issue=3&amp;pages=1032-1042&amp;publication_year=2008&amp;author=Seibel%2CEJ&amp;author=Carroll%2CRE&amp;author=Dominitz%2CJA&amp;author=Johnston%2CRS&amp;author=Melville%2CCD&amp;author=Lee%2CCM&amp;author=Seitz%2CSM&amp;author=Kimmey%2CMB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="E. Steele, K. Grimmer, B. Thomas, B. Mulley, I. Fulton, H. Hoffman, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Steele E, Grimmer K, Thomas B, Mulley B, Fulton I, Hoffman H (2003) Virtual reality as a pediatric pain modula" /><p class="c-article-references__text" id="ref-CR59">Steele E, Grimmer K, Thomas B, Mulley B, Fulton I, Hoffman H (2003) Virtual reality as a pediatric pain modulation technique: a case study. Cyberpsychol Behav 6:633–638</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1089%2F109493103322725405" aria-label="View reference 48">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 48 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20as%20a%20pediatric%20pain%20modulation%20technique%3A%20a%20case%20study&amp;journal=Cyberpsychol%20Behav&amp;volume=6&amp;pages=633-638&amp;publication_year=2003&amp;author=Steele%2CE&amp;author=Grimmer%2CK&amp;author=Thomas%2CB&amp;author=Mulley%2CB&amp;author=Fulton%2CI&amp;author=Hoffman%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RM. Sweet, P. Oppenheimer, J. Porter, D. Hendrickson, A. Gupta, S. Weghorst, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Sweet RM, Oppenheimer P, Porter J, Hendrickson D, Gupta A, Weghorst S (2002) The simulation of bleeding in end" /><p class="c-article-references__text" id="ref-CR44">Sweet RM, Oppenheimer P, Porter J, Hendrickson D, Gupta A, Weghorst S (2002) The simulation of bleeding in endoscopic procedures using virtual reality. J Endourol 16(7):451–455</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1089%2F089277902760367395" aria-label="View reference 49">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 49 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20simulation%20of%20bleeding%20in%20endoscopic%20procedures%20using%20virtual%20reality&amp;journal=J%20Endourol&amp;volume=16&amp;issue=7&amp;pages=451-455&amp;publication_year=2002&amp;author=Sweet%2CRM&amp;author=Oppenheimer%2CP&amp;author=Porter%2CJ&amp;author=Hendrickson%2CD&amp;author=Gupta%2CA&amp;author=Weghorst%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RM. Sweet, T. Kowalewski, P. Oppenheimer, J. Berkley, R. Satava, S. Weghorst, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Sweet RM, Kowalewski T, Oppenheimer P, Berkley J, Satava R, Weghorst S (2004) Validation of the UW TURP simula" /><p class="c-article-references__text" id="ref-CR45">Sweet RM, Kowalewski T, Oppenheimer P, Berkley J, Satava R, Weghorst S (2004) Validation of the UW TURP simulator as an assessment and training tool. J Urol 172(5 Pt 1):1953–1957</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1097%2F01.ju.0000141298.06350.4c" aria-label="View reference 50">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 50 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Validation%20of%20the%20UW%20TURP%20simulator%20as%20an%20assessment%20and%20training%20tool&amp;journal=J%20Urol&amp;volume=172&amp;issue=5%20Pt%201&amp;pages=1953-1957&amp;publication_year=2004&amp;author=Sweet%2CRM&amp;author=Kowalewski%2CT&amp;author=Oppenheimer%2CP&amp;author=Berkley%2CJ&amp;author=Satava%2CR&amp;author=Weghorst%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Weghorst S (2001) Augmented reality approaches to sensory rehabilitation. Presented at HCI International, New " /><p class="c-article-references__text" id="ref-CR60">Weghorst S (2001) Augmented reality approaches to sensory rehabilitation. Presented at HCI International, New Orleans, LA, August 2001</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="S. Weghorst, J. Prothero, TA. Furness, D. Anson, T. Riess, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Weghorst S, Prothero J, Furness TA III, Anson D, Riess T (1994) Virtual images in the treatment of Parkinson’s" /><p class="c-article-references__text" id="ref-CR46">Weghorst S, Prothero J, Furness TA III, Anson D, Riess T (1994) Virtual images in the treatment of Parkinson’s disease akinesia. In: Proceedings of medicine meets virtual reality II. San Diego, CA, pp 242–243</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 52 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20images%20in%20the%20treatment%20of%20Parkinson%E2%80%99s%20disease%20akinesia.%20In%3A%20Proceedings%20of%20medicine%20meets%20virtual%20reality%20II&amp;pages=242-243&amp;publication_year=1994&amp;author=Weghorst%2CS&amp;author=Prothero%2CJ&amp;author=Furness%2CTA&amp;author=Anson%2CD&amp;author=Riess%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Weghorst S, Oppenheimer P, Kaufman S, Haynor D, Gifford J, Edmond C, Dunbar P, Billinghurst M, Poupyrev I, Mil" /><p class="c-article-references__text" id="ref-CR47">Weghorst S, Oppenheimer P, Kaufman S, Haynor D, Gifford J, Edmond C, Dunbar P, Billinghurst M, Poupyrev I, Miller E (1997) The LIMIT: a VR testbed for clinical interface design. In: Presented at Medicine Meets Virtual Reality, San Diego, CA, January 1997</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="WJ. Weiner, C. Singer, " /><meta itemprop="datePublished" content="1989" /><meta itemprop="headline" content="Weiner WJ, Singer C (1989) Parkinson’s disease and nonpharmacologic treatment programs. J Am Geriatr Soc 37:35" /><p class="c-article-references__text" id="ref-CR48">Weiner WJ, Singer C (1989) Parkinson’s disease and nonpharmacologic treatment programs. J Am Geriatr Soc 37:359–363</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 54 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Parkinson%E2%80%99s%20disease%20and%20nonpharmacologic%20treatment%20programs&amp;journal=J%20Am%20Geriatr%20Soc&amp;volume=37&amp;pages=359-363&amp;publication_year=1989&amp;author=Weiner%2CWJ&amp;author=Singer%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JL. Wright, HG. Hoffman, RM. Sweet, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Wright JL, Hoffman HG, Sweet RM (2005) Virtual reality as an adjunctive pain control during transurethral micr" /><p class="c-article-references__text" id="ref-CR61">Wright JL, Hoffman HG, Sweet RM (2005) Virtual reality as an adjunctive pain control during transurethral microwave thermotherapy. Urology 66:1320</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 55 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20reality%20as%20an%20adjunctive%20pain%20control%20during%20transurethral%20microwave%20thermotherapy&amp;journal=Urology&amp;volume=66&amp;publication_year=2005&amp;author=Wright%2CJL&amp;author=Hoffman%2CHG&amp;author=Sweet%2CRM">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10055-008-0107-9-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Human Interface Technology Laboratory, University of Washington, Seattle, WA, USA</p><p class="c-article-author-affiliation__authors-list">Suzanne Weghorst, Eric Seibel, Peter Oppenheimer, Hunter Hoffman, Brian Schowengerdt &amp; Thomas A. Furness  III</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Suzanne-Weghorst"><span class="c-article-authors-search__title u-h3 js-search-name">Suzanne Weghorst</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Suzanne+Weghorst&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Suzanne+Weghorst" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Suzanne+Weghorst%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Eric-Seibel"><span class="c-article-authors-search__title u-h3 js-search-name">Eric Seibel</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Eric+Seibel&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Eric+Seibel" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Eric+Seibel%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Peter-Oppenheimer"><span class="c-article-authors-search__title u-h3 js-search-name">Peter Oppenheimer</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Peter+Oppenheimer&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Peter+Oppenheimer" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Peter+Oppenheimer%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Hunter-Hoffman"><span class="c-article-authors-search__title u-h3 js-search-name">Hunter Hoffman</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Hunter+Hoffman&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Hunter+Hoffman" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Hunter+Hoffman%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Brian-Schowengerdt"><span class="c-article-authors-search__title u-h3 js-search-name">Brian Schowengerdt</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Brian+Schowengerdt&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Brian+Schowengerdt" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Brian+Schowengerdt%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Thomas_A_-Furness_"><span class="c-article-authors-search__title u-h3 js-search-name">Thomas A. Furness  III</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Thomas A.+Furness &#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Thomas A.+Furness " data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Thomas A.+Furness %22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10055-008-0107-9/email/correspondent/c1/new">Suzanne Weghorst</a>.</p></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Medical%20interface%20research%20at%20the%20HIT%20Lab&amp;author=Suzanne%20Weghorst%20et%20al&amp;contentID=10.1007%2Fs10055-008-0107-9&amp;publication=1359-4338&amp;publicationDate=2008-11-28&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Weghorst, S., Seibel, E., Oppenheimer, P. <i>et al.</i> Medical interface research at the HIT Lab.
                    <i>Virtual Reality</i> <b>12, </b>201–214 (2008). https://doi.org/10.1007/s10055-008-0107-9</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10055-008-0107-9.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-09-08">08 September 2008</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-10-15">15 October 2008</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-11-28">28 November 2008</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2008-12">December 2008</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10055-008-0107-9" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10055-008-0107-9</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Virtual reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Mixed reality</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Endoscopy</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Medical informatics</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Rehabilitation</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Surgical simulation</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10055-008-0107-9.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button">
            
                <span>Download PDF</span>
                <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>
    

                </div>

                <div data-test="collections">
                    
                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10055/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=107;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 130.225.98.201</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Copenhagen University Library Royal Danish Library Copenhagen (1600006921)  - DEFF Consortium Danish National Library Authority (2000421697)  - Det Kongelige Bibliotek The Royal Library (3000092219)  - DEFF Danish Agency for Culture (3000209025)  - 1236 DEFF LNCS (3000236495) 
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

