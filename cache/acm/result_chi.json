{"papers": [{"title": "Selection-based Text Entry in Virtual Reality", "authors": ["Marco Speicher", "Anna Maria Feit", "Pascal Ziegler", "Antonio Kr\u00fcger"], "abstract": "In recent years, Virtual Reality (VR) and 3D User Interfaces (3DUI) have seen a drastic increase in popularity, especially in terms of consumer-ready hardware and software. While the technology for input as well as output devices is market ready, only a few solutions for text input exist, and empirical knowledge about performance and user preferences is lacking. In this paper, we study text entry in VR by selecting characters on a virtual keyboard. We discuss the design space for assessing selection-based text entry in VR. Then, we implement six methods that span different parts of the design space and evaluate their performance and user preferences. Our results show that pointing using tracked hand-held controllers outperforms all other methods. Other methods such as head pointing can be viable alternatives depending on available resources. We summarize our findings by formulating guidelines for choosing optimal virtual keyboard text entry methods in VR.                     References                 Jaewoo Ahn and Kyungha Min. 2006. VirtualPhonepad: a text input tool for virtual environments. Advances in Artificial Reality and Tele-Existence (2006), 58--64.  Google ScholarIan G Angus and Henry A Sowizral. 1995. Embedding the 2D interaction metaphor in a real 3D virtual environment. In IS&amp;T/SPIE's Symposium on Electronic Imaging: Science &amp; Technology. International Society for Optics and Photonics, 282--293.Google ScholarShiri Azenkot and Shumin Zhai. 2012. Touch Behavior with Different Postures on Soft Smartphone Keyboards. In Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services (MobileHCI '12). ACM, New York, NY, USA, 251--260.  Google ScholarMyroslav Bachynskyi, Gregorio Palmas, Antti Oulasvirta, and Tino Weinkauf. 2015. Informing the Design of Novel Input Methods with Muscle Coactivation Clustering. ACM Trans. Comput.-Hum. Interact. 21, 6, Article 30 (Jan. 2015), 25 pages.  Google ScholarThomas Baudel and Michel Beaudouin-Lafon. 1993. Charade: Remote Control of Objects Using Free-hand Gestures. Commun. ACM 36, 7 (July 1993), 28--35.  Google ScholarNikolaus Bee and Elisabeth Andr\u00b4 e. 2008. Writing with your eye: A dwell time free writing system adapted to the nature of human eye gaze. In International Tutorial and Research Workshop on Perception and Interactive Technologies for Speech-Based Systems. Springer, 111--122.  Google ScholarDoug Bowman, Ernst Kruijff, Joseph J LaViola Jr, and Ivan P Poupyrev. 2004. 3D User Interfaces: Theory and Practice, CourseSmart eTextbook. Addison-Wesley. Google ScholarDoug A. Bowman, Ryan P. McMahan, and Eric D. Ragan. 2012. Questioning Naturalism in 3D User Interfaces. Commun. ACM 55, 9 (Sept. 2012), 78--88.  Google ScholarDoug A. Bowman, Christopher J. Rhoton, and Marcio S. Pinho. 2002. Text Input Techniques for Immersive Virtual Environments: An Empirical Comparison. Proceedings of the Human Factors and Ergonomics Society Annual Meeting 46, 26 (2002), 2154--2158.Google ScholarWei Ding, Ping Chen, Hisham Al-Mubaid, and Marc Pomplun. 2009. A Gaze-Controlled Interface to Virtual Reality Applications for Motor-and Speech-Impaired Users. HCI International, San Diego, CA (2009).Google ScholarAugust Dvorak, Nellie L Merrick, William L Dealey, and Gertrude C Ford. 1936. Typewriting behavior. New York: American Book Company 1, 6 (1936).Google ScholarPeter J Gianaros, Eric R Muth, J Toby Mordkoff, Max E Levine, and Robert M Stern. 2001. A questionnaire for the assessment of the multiple dimensions of motion sickness. Aviation, Space, and Environmental Medicine 72, 2 (2001), 115.Google ScholarYulia Gizatdinova, Oleg \u0160pakov, and Veikko Surakka. 2012. Comparison of Video-based Pointing and Selection Techniques for Hands-free Text Entry. In Proceedings of the International Working Conference on Advanced Visual Interfaces (AVI '12). ACM, New York, NY, USA, 132--139.  Google ScholarGabriel Gonz\u00b4 alez, Jos\u00b4 e P Molina, Arturo S Garc\u00b4\u00eca, Diego Mart\u00b4nez, and Pascual Gonz\u00b4 alez. 2009. Evaluation of text input techniques in immersive virtual environments. In New Trends on Human-Computer Interaction. Springer, 109--118.Google ScholarJan Gugenheimer, David Dobbelstein, Christian Winkler, Gabriel Haas, and Enrico Rukzio. 2016. FaceTouch: Enabling Touch Interaction in Display Fixed UIs for Mobile Virtual Reality. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST '16). ACM, New York, NY, USA, 49--60.  Google ScholarSean Gustafson, Daniel Bierwirth, and Patrick Baudisch. 2010. Imaginary Interfaces: Spatial Interaction with Empty Hands and Without Visual Feedback. In Proceedings of the 23Nd Annual ACM Symposium on User Interface Software and Technology (UIST '10). ACM, New York, NY, USA, 3--12.  Google ScholarS. G. Hart and L. E. Stavenland. 1988. Development of NASA-TLX (Task Load Index): Results of empirical and theoretical research. In Human Mental Workload, P. A. Hancock and N. Meshkati (Eds.). Elsevier, Chapter 7, 139--183. http://ntrs.nasa.gov/archive/nasa/casi.ntrs. nasa.gov/20000004342_1999205624.pdfGoogle ScholarKen Hinckley, Mary Czerwinski, and Mike Sinclair. 1998. Interaction and Modeling Techniques for Desktop Two-handed Input. In Proceedings of the 11th Annual ACM Symposium on User Interface Software and Technology (UIST '98). ACM, New York, NY, USA, 49--58.  Google ScholarLode Hoste, Bruno Dumas, and Beat Signer. 2012. SpeeG: A Multimodal Speech- and Gesture-based Text Input Solution. In Proceedings of the International Working Conference on Advanced Visual Interfaces (AVI '12). ACM, New York, NY, USA, 156--163.  Google ScholarJason Jerald. 2015. The VR book: human-centered design for virtual reality. (2015). Google ScholarRobin Kinkead. 1975. Typing Speed, Keying Rates, and Optimal Keyboard Layouts. Proceedings of the Human Factors Society Annual Meeting 19, 2 (1975), 159--161.Google ScholarRegis Kopper, Doug A. Bowman, Mara G. Silva, and Ryan P. McMahan. 2010. A human motor behavior model for distal pointing tasks. International Journal of Human-Computer Studies 68, 10 (2010), 603 -- 615.  Google ScholarPer Ola Kristensson and Keith Vertanen. 2012. Performance Comparisons of Phrase Sets and Presentation Styles for Text Entry Evaluations. In Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces (IUI '12). ACM, New York, NY, USA, 29--32.  Google ScholarBettina Laugwitz, Theo Held, and Martin Schrepp. 2008. Construction and evaluation of a user experience questionnaire. In Symposium of the Austrian HCI and Usability Engineering Group. Springer, 63--76.  Google ScholarAnatole Lecuyer. 2009. Simulating Haptic Feedback Using Vision: A Survey of Research and Applications of Pseudo-Haptic Feedback. Presence: Teleoperators and Virtual Environments 18, 1 (2009), 39--53.  Google ScholarKun Chang Lee and Namho Chung. 2008. Empirical analysis of consumer reaction to the virtual reality shopping mall. Computers in Human Behavior 24, 1 (2008), 88 -- 104.  Google ScholarVladimir I Levenshtein. 1966. Binary codes capable of correcting deletions, insertions, and reversals. In Soviet physics doklady, Vol. 10. 707--710.Google ScholarJia-Wei Lin, Ping-Hsuan Han, Jiun-Yu Lee, Yang-Sheng Chen, Ting-Wei Chang, Kuan-Wen Chen, and Yi-Ping Hung. 2017. Visualizing the Keyboard in Virtual Reality for Enhancing Immersive Experience. In ACM SIGGRAPH 2017 Posters (SIGGRAPH '17). ACM, New York, NY, USA, Article 35, 2 pages.  Google ScholarKent Lyons, Thad Starner, Daniel Plaisted, James Fusia, Amanda Lyons, Aaron Drew, and E. W. Looney. 2004. Twiddler Typing: One-handed Chording Text Entry for Mobile Phones. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '04). ACM, New York, NY, USA, 671--678.  Google ScholarI. Scott MacKenzie. 2002. KSPC (Keystrokes per Character) as a Characteristic of Text Entry Techniques. Springer Berlin Heidelberg, Berlin, Heidelberg, 195--210.Google ScholarI. Scott MacKenzie and Kumiko Tanaka-Ishii. 2007. Text Entry Systems: Mobility, Accessibility, Universality. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA. Google ScholarI. Scott MacKenzie and Shawn X. Zhang. 1999. The Design and Evaluation of a High-performance Soft Keyboard. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '99). ACM, New York, NY, USA, 25--31.  Google ScholarAllan MacLean, Richard M. Young, Victoria M. E. Bellotti, and Thomas P. Moran. 1991. Questions, Options, and Criteria: Elements of Design Space Analysis. Hum.-Comput. Interact. 6, 3 (Sept. 1991), 201--250.  Google ScholarP\u00a8 aivi Majaranta and Kari-Jouko R\u00a8 aih\u00a8 a. 2007. Text entry by gaze: Utilizing eye-tracking. Text entry systems: Mobility, accessibility, universality (2007), 175--187. http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1. 1.102.5479Google ScholarAnders Markussen, Mikkel R Jakobsen, and Kasper Hornb\u00e6k. 2013. Selection-based mid-air text entry on large displays. In IFIP Conference on Human-Computer Interaction. Springer, 401--418.Google ScholarMark McGill, Daniel Boland, Roderick Murray-Smith, and Stephen Brewster. 2015. A Dose of Reality: Overcoming Usability Challenges in VR Head-Mounted Displays. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). ACM, New York, NY, USA, 2143--2152.  Google ScholarMathieu Nancel, Julie Wagner, Emmanuel Pietriga, Olivier Chapuis, and Wendy Mackay. 2011. Mid-air Pan-and-zoom on Wall-sized Displays. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11). ACM, New York, NY, USA, 177--186.  Google ScholarJan Noyes. 1983. The QWERTY keyboard: A review. International Journal of Man-Machine Studies 18, 3 (1983), 265--281.Google ScholarGang Ren and Eamonn O'Neill. 2013. Freehand Gestural Text Entry for Interactive TV. In Proceedings of the 11th European Conference on Interactive TV and Video (EuroITV '13). ACM, New York, NY, USA, 121--130.  Google ScholarGarth Shoemaker, Leah Findlater, Jessica Q. Dawson, and Kellogg S. Booth. 2009. Mid-air Text Input Techniques for Very Large Wall Displays. In Proceedings of Graphics Interface 2009 (GI '09). Canadian Information Processing Society, Toronto, Ont., Canada, Canada, 231--238. http://dl.acm.org/citation.cfm?id=1555880.1555931 Google ScholarSrinath Sridhar, Anna Maria Feit, Christian Theobalt, and Antti Oulasvirta. 2015. Investigating the Dexterity of Multi-Finger Input for Mid-Air Text Entry. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). ACM, New York, NY, USA, 3643--3652.  Google ScholarKeith Vertanen and Per Ola Kristensson. 2011. A Versatile Dataset for Text Entry Evaluations Based on Genuine Mobile Emails. In Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services (MobileHCI '11). ACM, New York, NY, USA, 295--298.  Google ScholarJames Walker, Bochao Li, Keith Vertanen, and Scott Kuhl. 2017. Efficient Typing on a Visually Occluded Physical Keyboard. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI '17). ACM, New York, NY, USA, 5457--5461.  Google ScholarFrank Weichert, Daniel Bachmann, Bartholomus Rudak, and Denis Fisseler. 2013. Analysis of the Accuracy and Robustness of the Leap Motion Controller. Sensors 13, 5 (2013), 6380--6393.Google ScholarAndrew D. Wilson and Maneesh Agrawala. 2006. Text Entry Using a Dual Joystick Game Controller. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '06). ACM, New York, NY, USA, 475--478.  Google ScholarJacob O Wobbrock. 2007. Measures of text entry performance. San Francisco: Morgan Kaufmann.Google ScholarJacob O. Wobbrock, Duen Horng Chau, and Brad A. Myers. 2007. An Alternative to Push, Press, and Tap-tap-tap: Gesturing on an Isometric Joystick for Mobile Phone Text Entry. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '07). ACM, New York, NY, USA, 667--676.  Google ScholarChun Yu, Yizheng Gu, Zhican Yang, Xin Yi, Hengliang Luo, and Yuanchun Shi. 2017. Tap, Dwell or Gesture?: Exploring Head-Based Text Entry Techniques for HMDs. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI '17). ACM, New York, NY, USA, 4479--4488.  Google ScholarShumin Zhai. 1995. Human Performance in Six Degree of Freedom Input Control. (1995).Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3173574.3174221/6e7d0292-2df8-4a8a-822a-b253e42d68be/pn4876-file3.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee06e0e0927f1e11a21c84ce9c058849e8aa6c6105a816da2fe8db75c2d0c174321709c3e0b122eeff1ccb9a6b9627c8aff7ae7d628ef5d86629ca2740395a0a2fd099fa639dea37c1application/x-mpegurlmp418.4 MB", "keywords": ["user experience", "virtual reality", "task performance", "mid-air", "text entry", "pointing"], "published_in": "CHI '18: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems", "publication_date": "21 April 2018", "citations": "14", "isbn": "9781450356206", "doi": "10.1145/3173574", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3173574.3174221", "paper_url": "https://dl.acm.org/doi/10.1145/3173574.3174221"}, {"title": "Exploring Interaction Fidelity in Virtual Reality: Object Manipulation and Whole-Body Movements", "authors": ["Katja Rogers", "Jana Funke", "Julian Frommel", "Sven Stamm", "Michael Weber"], "abstract": "High degrees of interaction fidelity (IF) in virtual reality (VR) are said to improve user experience and immersion, but there is also evidence of low IF providing comparable experiences. VR games are now increasingly prevalent, yet we still do not fully understand the trade-off between realism and abstraction in this context. We conducted a lab study comparing high and low IF for object manipulation tasks in a VR game. In a second study, we investigated players' experiences of IF for whole-body movements in a VR game that allowed players to crawl underneath virtual boulders and \"dangle'' along monkey bars. Our findings show that high IF is preferred for object manipulation, but for whole-body movements, moderate IF can suffice, as there is a trade-off with usability and social factors. We provide guidelines for the development of VR games based on our results.", "keywords": ["virtual objects", "virtual reality", "whole body interaction", "games", "interaction fidelity", "player experience"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "7", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300644", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300644"}, {"title": "Crossing-Based Selection with Virtual Reality Head-Mounted Displays", "authors": ["Huawei Tu", "Susu Huang", "Jiabin Yuan", "Xiangshi Ren", "Feng Tian"], "abstract": "This paper presents the first investigation into using the goal-crossing paradigm for object selection with virtual reality (VR) head-mounted displays. Two experiments were carried out to evaluate ray-casting crossing tasks with target discs in 3D space and goal lines on 2D plane respectively in comparison to ray-casting pointing tasks. Five factors, i.e. task difficulty, the direction of movement constraint (collinear vs. orthogonal), the nature of the task (discrete vs. continuous), field of view of VR devices and target depth, were considered in both experiments. Our findings are: (1) crossing generally had shorter or no longer time, and higher or similar accuracy than pointing, indicating crossing can complement or substitute pointing; (2) crossing tasks can be well modelled with Fitts' Law; (3) crossing performance depended on target depth; (4) crossing target discs in 3D space differed from crossing goal lines on 2D plane in many aspects such as time and error performance, the effects of target depth and the parameters of Fitts' models. Based on these findings, we formulate a number of design recommendations for crossing-based interaction in VR.                     References                 Johnny Accot and Shumin Zhai. 1997. Beyond Fitts' Law: Models for Trajectory-based HCI Tasks. In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems (CHI'97). ACM, New York, NY, USA, 295--302.  Google ScholarDigital LibraryJohnny Accot and Shumin Zhai. 2002. More Than Dotting the I's - Foundations for Crossing-based Interfaces. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'02). ACM, New York, NY, USA, 73--80.  Google ScholarDigital LibraryGeorg Apitz and Fran\u00e7ois Guimbreti\u00e8re. 2004. CrossY: A Crossingbased Drawing Application. In Proceedings of the 17th Annual ACM Symposium on User Interface Software and Technology (UIST'04). ACM, New York, NY, USA, 3--12.  Google ScholarDigital LibraryGeorg Apitz, Fran\u00e7ois Guimbreti\u00e8re, and Shumin Zhai. 2008. Foundations for Designing and Evaluating User Interfaces Based on the Crossing Paradigm. ACM Trans. Comput.-Hum. Interact. 17, 2, Article 9 (May 2008), 42 pages.  Google ScholarDigital LibraryFerran Argelaguet and Carlos Andujar. 2009. Efficient 3D pointing selection in cluttered virtual environments. IEEE Computer Graphics and Applications 29, 6 (2009), 34--43.Google ScholarDigital LibraryFerran Argelaguet and Carlos Andujar. 2013. A survey of 3D object selection techniques for virtual environments. Computers &amp; Graphics 37, 3 (2013), 121--136.  Google ScholarDigital LibraryXiaojun Bi, Yang Li, and Shumin Zhai. 2013. FFitts Law: Modeling Finger Touch with Fitts' Law. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '13). ACM, New York, NY, USA, 1363--1372.  Google ScholarDigital LibraryBinocular visual field of humans 2018. Peripheral vision - Wikipedia. https://en.wikipedia.org/wiki/Peripheral_vision, note = Accessed: Auguest 2018,.Google ScholarDoug Bowman, Chadwick Wingrave, Joshua Campbell, and Vinh Ly. 2001. Using pinch gloves (tm) for both natural and abstract interaction techniques in virtual environments. Technical Report TR-01--23, Computer Science, Virginia Tech. (2001).Google ScholarDoug A Bowman, Donald B Johnson, and Larry F Hodges. 2001. Testbed evaluation of virtual environment interaction techniques. Presence: Teleoperators &amp; Virtual Environments 10, 1 (2001), 75--95.  Google ScholarDigital LibraryDoug A Bowman and Chadwick A Wingrave. 2001. Design and evaluation of menu systems for immersive virtual environments. In Proceedings of Virtual Reality. IEEE, 149--156. Google ScholarDigital LibraryNathan Cournia, John D. Smith, and Andrew T. Duchowski. 2003. Gazevs. Hand-based Pointing in Virtual Environments. In CHI '03 Extended Abstracts on Human Factors in Computing Systems (CHI EA '03). ACM, New York, NY, USA, 772--773.  Google ScholarDigital LibraryRaimund Dachselt and Anett H\u00fcbner. 2007. Three-dimensional menus: A survey and taxonomy. Computers &amp; Graphics 31, 1 (2007), 53--65.  Google ScholarDigital LibraryKaushik Das and Christoph W Borst. 2010. An evaluation of menu properties and pointing techniques in a projection-based VR environment. In 3D User Interfaces (3DUI), 2010 IEEE Symposium on. IEEE, 47--50.  Google ScholarDigital LibraryMorgan Dixon, Fran\u00e7ois Guimbreti\u00e8re, and Nicholas Chen. 2008. Optimal Parameters for Efficient Crossing-based Dialog Boxes. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'08). ACM, New York, NY, USA, 1623--1632.  Google ScholarDigital LibrarySarah A. Douglas, Arthur E. Kirkpatrick, and I. Scott MacKenzie. 1999. Testing Pointing Device Performance and User Assessment with the ISO 9241, Part 9 Standard. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'99). ACM, New York, NY, USA, 215--222.  Google ScholarDigital LibraryPierre Dragicevic. 2004. Combining Crossing-based and Paper-based Interaction Paradigms for Dragging and Dropping Between Overlapping Windows. In Proceedings of the 17th Annual ACM Symposium on User Interface Software and Technology (UIST'04). ACM, New York, NY, USA, 193--196.  Google ScholarDigital LibraryPaul M Fitts. 1954. The information capacity of the human motor system in controlling the amplitude of movement. Journal of experimental psychology 47, 6 (1954), 381.Google ScholarCross RefClifton Forlines and Ravin Balakrishnan. 2008. Evaluating Tactile Feedback and Direct vs. Indirect Stylus Input in Pointing and Crossing Selection Tasks. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'08). ACM, New York, NY, USA, 1563--1572.  Google ScholarDigital LibraryAndrew Forsberg, Kenneth Herndon, and Robert Zeleznik. 1996. Aperture Based Selection for Immersive Virtual Environments. In Proceedings of the 9th Annual ACM Symposium on User Interface Software and Technology (UIST'96). ACM, New York, NY, USA, 95--96.  Google ScholarDigital LibraryTovi Grossman and Ravin Balakrishnan. 2004. Pointing at Trivariate Targets in 3D Environments. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'04). ACM, New York, NY, USA, 447--454.  Google ScholarDigital LibraryTovi Grossman and Ravin Balakrishnan. 2006. The Design and Evaluation of Selection Techniques for 3D Volumetric Displays. In Proceedings of the 19th Annual ACM Symposium on User Interface Software and Technology (UIST'06). ACM, New York, NY, USA, 3--12.  Google ScholarDigital LibraryGerwin Haan, Michal Koutek, and Frits H Post. 2005. IntenSelect: Using Dynamic Object Rating for Assisting 3D Object Selection. In IPT/EGVE. Citeseer, 201--209. Google ScholarDigital LibraryKenneth P. Herndon, Andries van Dam, and Michael Gleicher. 1994. The Challenges of 3D Interaction: A CHI '94 Workshop. SIGCHI Bull. CHI 2019, May 4--9, 2019, Glasgow, Scotland UK H. Tu et al. 26, 4 (Oct. 1994), 36--43.  Google ScholarDigital LibraryRichard H Jacoby and Stephen R Ellis. 1992. Using virtual menus in a virtual environment. In Visual Data Interpretation, Vol. 1668. International Society for Optics and Photonics, 39--49.Google ScholarCross RefJ Adam Jones, J Edward Swan, and Mark Bolas. 2013. Peripheral stimulation and its effect on perceived spatial scale in virtual environments. IEEE Transactions on Visualization &amp; Computer Graphics 4 (2013), 701--710.  Google ScholarDigital LibraryKreylos, O. 2018. Optical Properties of Current VR HMDs. http://doc-ok.org/?p=1414, note = Accessed: Auguest 2018,.Google ScholarJJ-W Lin, Henry Been-Lirn Duh, Donald E Parker, Habib Abi-Rached, and Thomas A Furness. 2002. Effects of field of view on presence, enjoyment, memory, and simulator sickness in a virtual environment. In Virtual Reality, 2002. Proceedings. IEEE. IEEE, 164--171. Google ScholarDigital LibraryYuexing Luo and Daniel Vogel. 2014. Crossing-based Selection with Direct Touch Input. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'14). ACM, New York, NY, USA, 2627--2636.  Google ScholarDigital LibraryYuexing Luo and Daniel Vogel. 2015. Pin-and-Cross: A Unimanual Multitouch Technique Combining Static Touches with Crossing Selection. In Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology (UIST'15). ACM, New York, NY, USA, 323--332.  Google ScholarDigital LibraryI Scott MacKenzie. 1992. Fitts' law as a research and design tool in human-computer interaction. Human-computer interaction 7, 1 (1992), 91--139.  Google ScholarDigital LibraryI. Scott MacKenzie and William Buxton. 1992. Extending Fitts' Law to Two-dimensional Tasks. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'92). ACM, New York, NY, USA, 219--226.  Google ScholarDigital LibraryMark R. Mine. 1995. Virtual Environment Interaction Techniques. Technical Report. Chapel Hill, NC, USA. Google ScholarDigital LibraryPeter Mitchell and Brett Wilkinson. 2016. Periphery Triggered Menus for Head Mounted Menu Interface Interactions. In Proceedings of the 28th Australian Conference on Computer-Human Interaction (OzCHI'16). ACM, New York, NY, USA, 30--33.  Google ScholarDigital LibraryAbdeldjallil Naceri, Ryad Chellali, and Thierry Hoinville. 2011. Depth perception within peripersonal space using head-mounted display. Presence: Teleoperators and Virtual Environments 20, 3 (2011), 254--272.  Google ScholarDigital LibraryTakashi Nakamura, Shin Takahashi, and Jiro Tanaka. 2008. DoubleCrossing: A New Interaction Technique for Hand Gesture Interfaces. In Proceedings of the 8th Asia-Pacific Conference on Computer-Human Interaction (APCHI'08). Springer-Verlag, Berlin, Heidelberg, 292--300.  Google ScholarDigital LibraryOculus Rift CV1 2018. Oculus Rift - Wikipedia. https://en.wikipedia. org/wiki/Oculus_Rift, note = Accessed: Auguest 2018,.Google ScholarJeffrey S. Pierce, Andrew S. Forsberg, Matthew J. Conway, Seung Hong, Robert C. Zeleznik, and Mark R. Mine. 1997. Image Plane Interaction Techniques in 3D Immersive Environments. In Proceedings of the 1997 Symposium on Interactive 3D Graphics (I3D '97). ACM, New York, NY, USA, 39--43.  Google ScholarDigital LibraryIvan Poupyrev, Mark Billinghurst, Suzanne Weghorst, and Tadao Ichikawa. 1996. The Go-go Interaction Technique: Non-linear Mapping for Direct Manipulation in VR. In Proceedings of the 9th Annual ACM Symposium on User Interface Software and Technology (UIST '96). ACM, New York, NY, USA, 79--80.  Google ScholarDigital LibraryAdrian Ramcharitar and Robert J. Teather. 2018. EZCursorVR: 2D Selection with Virtual Reality Head-Mounted Displays. In Proceedings of the Graphics Interface Conference 2018 (GI'18). ACM.Google ScholarRebekka S. Renner, Boris M. Velichkovsky, and Jens R. Helmert. 2013. The Perception of Egocentric Distances in Virtual Environments - A Review. ACM Comput. Surv. 46, 2, Article 23 (Dec. 2013), 40 pages.  Google ScholarDigital LibraryFrank Steinicke, Timo Ropinski, and Klaus Hinrichs. 2006. Object selection in virtual environments using an improved virtual pointer metaphor. In Computer Vision and Graphics. Springer, 320--326.Google ScholarWolfgang Stuerzlinger and Robert J. Teather. 2014. Considerations for Targets in 3D Pointing Experiments. In Proceedings of HCI Korea (HCIK '15). Hanbit Media, Inc., South Korea, 162--168. Google ScholarDigital LibraryAhmed N. Sulaiman and Patrick Olivier. 2008. Attribute Gates. In Proceedings of the 21st Annual ACM Symposium on User Interface Software and Technology (UIST '08). ACM, New York, NY, USA, 57--66.  Google ScholarDigital LibraryRobert J Teather and Wolfgang Stuerzlinger. 2011. Pointing at 3D targets in a stereo head-tracked virtual environment. In 3D User Interfaces (3DUI), 2011 IEEE Symposium on. IEEE, 87--94. Google ScholarDigital LibraryRobert J. Teather and Wolfgang Stuerzlinger. 2013. Pointing at 3D Target Projections with One-eyed and Stereo Cursors. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '13). ACM, New York, NY, USA, 159--168.  Google ScholarDigital LibraryLode Vanacken, Tovi Grossman, and Karin Coninx. 2007. Exploring the effects of environment density and target visibility on object selection in 3D virtual environments. In IEEE Symposium on 3D User Interfaces. IEEE, 115--122.Google ScholarCross RefColin Ware and Kathy Lowther. 1997. Selection Using a One-eyed Cursor in a Fish Tank VR Environment. ACM Trans. Comput.-Hum. Interact. 4, 4 (Dec. 1997), 309--322.  Google ScholarDigital LibraryChristopher D Wickens. 1991. Processing resources and attention. Multiple-task performance 1991 (1991), 3--34.Google ScholarC Wingrave and D Bowman. 2005. Baseline factors for raycasting selection. In Proceedings of HCI International. Citeseer.Google ScholarJacob O. Wobbrock and Krzysztof Z. Gajos. 2008. Goal Crossing with Mice and Trackballs for People with Motor Impairments: Performance, Submovements, and Design Directions. ACM Trans. Access. Comput. 1, 1, Article 4 (May 2008), 37 pages.  Google ScholarDigital LibraryRobert Xiao and Hrvoje Benko. 2016. Augmenting the Field-of-View of Head-Mounted Displays with Sparse Peripheral Displays. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI'16). ACM, New York, NY, USA, 1221--1232.  Google ScholarDigital LibraryRichard Yao, Tom Heath, Aaron Davies, Tom Forsyth, Nate Mitchell, and Perry Hoberman. 2014. Oculus vr best practices guide. Oculus VR 4 (2014).Google ScholarTakuto Yoshikawa, Buntarou Shizuki, and Jiro Tanaka. 2012. HandyWidgets: Local Widgets Pulled-out from Hands. In Proceedings of the 2012 ACM International Conference on Interactive Tabletops and Surfaces (ITS'12). ACM, New York, NY, USA, 197--200.  Google ScholarDigital LibraryShumin Zhai, William Buxton, and Paul Milgram. 1994. The \"Silk Cursor\": Investigating Transparency for 3D Target Acquisition. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'94). ACM, New York, NY, USA, 459--464.  Google ScholarDigital LibrarySupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3290605.3300848/d5065111-0994-4a85-9b80-8aef91940297/paper618p.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee05eee35a4ac3e15fa134b9cf2a159e61fc5f20bdeaf7c76a6bd7ccf71461a561d5ce68357cc1a34eace68daa986acda359eb21299cd2d2bcb9997e62f3cd8355fe9dc60d71d3ef9dapplication/x-mpegurlmp4723.2 KB", "keywords": ["virtual reality head-mounted displays", "crossing", "pointing", "ray-casting selection", "fitts' law"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "9", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300848", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300848"}, {"title": "VirtualBricks: Exploring a Scalable, Modular Toolkit for Enabling Physical Manipulation in VR", "authors": ["Jatin Arora", "Aryan Saini", "Nirmita Mehra", "Varnit Jain", "Shwetank Shrey", "Aman Parnami"], "abstract": "Often Virtual Reality (VR) experiences are limited by the design of standard controllers. This work aims to liberate a VR developer from these limitations in the physical realm to provide an expressive match to the limitless possibilities in the virtual realm. VirtualBricks is a LEGO based toolkit that enables construction of a variety of physical-manipulation enabled controllers for VR, by offering a set of feature bricks that emulate as well as extend the capabilities of default controllers. Based on the LEGO platform, the toolkit provides a modular, scalable solution for enabling passive haptics in VR. We demonstrate the versatility of our designs through a rich set of applications including re-implementations of artifacts from recent research. We share a VR Integration package for integration with Unity VR IDE, the CAD models for the feature bricks, for easy deployment of VirtualBricks within the community.                     References                 2017. Racket Sports Set with VIVE Tracker. (2017). https://www.vive. com/us/VR-racket-sports-set-with-tracker/Google Scholar2018. PlayStation VR aim controller. (2018). https://www.playstation. com/en-in/explore/accessories/playstation-vr-aim-controller/Google ScholarM. Abdullah, M. Kim, W. Hassan, Y. Kuroda, and S. Jeon. 2018. HapticDrone: An encountered-type kinesthetic haptic interface with controllable force feedback: Example of stifness and weight rendering. In 2018 IEEE Haptics Symposium (HAPTICS). 334--339.Google ScholarM. Achibet, A. Girard, A. Talvas, M. Marchal, and A. L\u00e9cuyer. 2015. Elastic-Arm: Human-scale passive haptic feedback for augmenting interaction and perception in virtual environments. In 2015 IEEE Virtual Reality (VR). 63--68.Google ScholarLaurent Aguerreche, Thierry Duval, and Anatole L\u00e9cuyer. 2010. Reconfgurable tangible devices for 3D virtual object manipulation by single or multiple users. In Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology. ACM Press, 227.  Google ScholarDigital LibraryBruno Araujo, Ricardo Jota, Varun Perumal, Jia Xian Yao, Karan Singh, and Daniel Wigdor. 2016. Snake Charmer: Physically Enabling Virtual Objects. In Proceedings of the TEI '16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction (TEI '16). ACM Press, 218--226.  Google ScholarDigital LibraryM. Bouzit, G. Burdea, G. Popescu, and R. Boian. 2002. The Rutgers Master II-ND force feedback glove. IEEE/ASME Transactions on Mechatronics 7, 2 (2002), 256--263.Google ScholarCross RefJack Shen-Kuen Chang, Georgina Yeboah, Alison Doucette, Paul Clifton, Michael Nitsche, Timothy Welsh, and Ali Mazalek. 2017. TASC: Combining Virtual Reality with Tangible and Embodied Interactions to Support Spatial Cognition. In Proceedings of the 2017 Conference on Designing Interactive Systems. ACM Press, 1239--1251.  Google ScholarDigital LibraryLung-Pan Cheng, Li Chang, Sebastian Marwecki, and Patrick Baudisch. 2018. iTurk: Turning Passive Haptics into Active Haptics by Making Users Reconfgure Props in Virtual Reality. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM Press, 1--10.  Google ScholarDigital LibraryLung-Pan Cheng, Thijs Roumen, Hannes Rantzsch, Sven K\u00f6hler, Patrick Schmidt, Robert Kovacs, Johannes Jasper, Jonas Kemper, and Patrick Baudisch. 2015. TurkDeck: Physical Virtual Reality Based on People. In Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology - UIST '15. ACM Press, Daegu, Kyungpook, Republic of Korea, 417--426.  Google ScholarDigital LibraryArtem Dementyev, Hsin-Liu (Cindy) Kao, and Joseph A. Paradiso. 2015. SensorTape: Modular and Programmable 3D-Aware Dense Sensor Network on a Tape. In Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology (UIST '15). ACM, New York, NY, USA, 649--658.  Google ScholarDigital LibraryDavid Gauntlett. 2014. The LEGO System as a tool for thinking, creativity, and changing the world. (2014), 16.Google ScholarCarles Gomez, Joaquim Oller, and Josep Paradells. 2012. Overview and Evaluation of Bluetooth Low Energy: An Emerging Low-Power Wireless Technology. Sensors 12, 9 (Sept. 2012), 11734--11753.Google ScholarCross RefAnuruddha Hettiarachchi and Daniel Wigdor. 2016. Annexing Reality: Enabling Opportunistic Use of Everyday Objects as Tangible Proxies in Augmented Reality. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM Press, 1957--1967.  Google ScholarDigital LibraryKen Hinckley, Randy Pausch, John C. Goble, and Neal F. Kassell. 1994. Passive Real-world Interface Props for Neurosurgical Visualization. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '94). ACM, New York, NY, USA, 452--458.  Google ScholarDigital LibraryBrent Edward Insko. 2001. Passive Haptics Signifcantly Enhances Virtual Environments. Ph.D. Dissertation. Advisor(s) Brooks,Jr., Frederick P. AAI3007820.Google ScholarMajeed Kazemitabaar, Jason McPeak, Alexander Jiao, Liang He, Thomas Outing, and Jon E. Froehlich. 2017. MakerWear: A Tangible Approach to Interactive Wearable Creation for Children. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI '17). ACM, New York, NY, USA, 133--145.  Google ScholarDigital LibraryLuv Kohli, Eric Burns, Dorian Miller, and Henry Fuchs. 2005. Combining passive haptics with redirected walking. In Proceedings of the 2005 International Conference on Augmented Tele-existence. ACM Press, 253.  Google ScholarDigital LibraryDavid Ledo, Steven Houben, Jo Vermeulen, Nicolai Marquardt, Lora Oehlberg, and Saul Greenberg. 2018. Evaluation Strategies for HCI Toolkit Research. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, NY, USA, 36:1--36:17.  Google ScholarDigital LibraryPedro Lopes, Sijing You, Lung-Pan Cheng, Sebastian Marwecki, and Patrick Baudisch. 2017. Providing Haptics to Walls &amp; Heavy Objects in Virtual Reality by Means of Electrical Muscle Stimulation. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI '17). ACM, New York, NY, USA, 1471--1482.  Google ScholarDigital LibraryThomas H. Massie and J. K. Salisbury. 1994a. The PHANToM haptic interface: A device for probing virtual objects. In Proceedings of the ASME Dynamic Systems and Control Division. 295--301.Google ScholarThomas H. Massie and J. K. Salisbury. 1994b. The PHANToM haptic interface: A device for probing virtual objects. (1994), 295--301.Google ScholarJohn C. McClelland, Robert J. Teather, and Audrey Girouard. 2017. Haptobend: shape-changing passive haptic feedback in virtual reality. In Proceedings of the 5th Symposium on Spatial User Interaction. ACM Press, 82--90.  Google ScholarDigital LibraryW. A. McNeely. 1993. Robotic graphics: a new approach to force feedback for virtual reality. In Proceedings of IEEE Virtual Reality Annual International Symposium. 336--341.  Google ScholarDigital LibraryJun Murayama, Laroussi Bougrila, Yanlinluo Katsuhito Akahane, Shoichi Hasegawa, B\u00e9at Hirsbrunner, and Makoto Sato. 2004. SPIDAR G &amp; G: A two-handed haptic interface for bimanual VR interaction. In Proceedings of EuroHaptics 2004. 138--146.Google ScholarKen Nakagaki, Artem Dementyev, Sean Follmer, Joseph A. Paradiso, and Hiroshi Ishii. 2016. ChainFORM: A Linear Integrated Modular Hardware System for Shape Changing Interfaces. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST '16). ACM, New York, NY, USA, 87--96.  Google ScholarDigital LibraryAlexa F. Siu, Eric J. Gonzalez, Shenli Yuan, Jason Ginsberg, Allen Zhao, and Sean Follmer. 2017. shapeShift: A Mobile Tabletop Shape Display for Tangible and Haptic Interaction. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM Press, 77--79.  Google ScholarDigital LibraryHaruhisa Kawasaki Takahiro Endo and Yasutoshi Doi Tetsuya Mouri. Five-fngered haptic interface robot: HIRO III. In World Haptics 2009 Third Joint EuroHaptics conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. https://ieeexplore. CHI 2019, May 4--9, 2019, Glasgow, Scotland Uk Arora et al. ieee.org/document/4810812/Google ScholarRyoichi Watanabe, Yuichi Itoh, Masatsugu Asai, Yoshifumi Kitamura, Yoshifumi Kitamura, Fumio Kishino, and Hideo Kikuchi. 2004. The Soul of ActiveCube: Implementing a Flexible, Multimodal, Threedimensional Spatial Tangible Interface. Comput. Entertain. 2, 4 (Oct. 2004), 15--15.  Google ScholarDigital LibraryEric Whitmire, Hrvoje Benko, Christian Holz, Eyal Ofek, and Mike Sinclair. 2018. Haptic Revolver: Touch, Shear, Texture, and Shape Rendering on a Reconfgurable Virtual Reality Controller. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM Press, 1--12.  Google ScholarDigital LibraryNobuhisa Hanamitsu Yukari Konishi, Ayahiko Sato Kouta Minamizawa, and Benjamin Outram Tetsuya Mizuguchi. 2011. Synesthesia Suit : the full body immersive experience. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11). https: //dl.acm.org/citation.cfm?id=2932629  Google ScholarDigital LibraryAndre Zenner and Antonio Kruger. 2017. Shifty: A Weight-Shifting Dynamic Passive Haptic Proxy to Enhance Object Perception in Virtual Reality. IEEE Transactions on Visualization and Computer Graphics 23, 4 (April 2017), 1285--1294.  Google ScholarDigital LibraryYiwei Zhao, Lawrence H. Kim, Ye Wang, Mathieu Le Goc, and Sean Follmer. 2017. Robotic Assembly of Haptic Proxy Objects for Tangible Interaction and Virtual Reality. In Proceedings of the 2017 ACM International Conference on Interactive Surfaces and Spaces (ISS '17). ACM, New York, NY, USA, 82--91.  Google ScholarDigital LibrarySupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3290605.3300286/c80f9d35-0d54-4459-a30f-89c835a8731b/paper056.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee05eee35a4ac3e15fa134b9c5261b9e66f15f7030d866fc89794873a290b1e8eff3d4b9d62be111486077256eb07a4bbd7d3a00e785df078cca2ddda89fdb7dafe50389aab91e5ddbapplication/x-mpegurlmp4276.3 MB", "keywords": ["construction toolkit", "physical manipulation", "passive haptics"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "1", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300286", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300286"}, {"title": "A handle bar metaphor for virtual object manipulation with mid-air interaction", "authors": ["Peng Song", "Wooi Boon Goh", "William Hutama", "Chi-Wing Fu", "Xiaopei Liu"], "abstract": "Commercial 3D scene acquisition systems such as the Microsoft Kinect sensor can reduce the cost barrier of realizing mid-air interaction. However, since it can only sense hand position but not hand orientation robustly, current mid-air interaction methods for 3D virtual object manipulation often require contextual and mode switching to perform translation, rotation, and scaling, thus preventing natural continuous gestural interactions. A novel handle bar metaphor is proposed as an effective visual control metaphor between the user's hand gestures and the corresponding virtual object manipulation operations. It mimics a familiar situation of handling objects that are skewered with a bimanual handle bar. The use of relative 3D motion of the two hands to design the mid-air interaction allows us to provide precise controllability despite the Kinect sensor's low image resolution. A comprehensive repertoire of 3D manipulation operations is proposed to manipulate single objects, perform fast constrained rotation, and pack/align multiple objects along a line. Three user studies were devised to demonstrate the efficacy and intuitiveness of the proposed interaction techniques on different virtual manipulation scenarios.", "keywords": ["user interaction", "3d manipulation", "bimanual gestures"], "published_in": "CHI '12: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "5 May 2012", "citations": "84", "isbn": "9781450310154", "doi": "10.1145/2207676", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2207676.2208585", "paper_url": "https://dl.acm.org/doi/10.1145/2207676.2208585"}, {"title": "Object Manipulation in Virtual Reality Under Increasing Levels of Translational Gain", "authors": ["Graham Wilson", "Mark Mcgill", "Matthew Jamieson", "Julie R. Williamson", "Stephen A. Brewster"], "abstract": "Room-scale Virtual Reality (VR) has become an affordable consumer reality, with applications ranging from entertainment to productivity. However, the limited physical space available for room-scale VR in the typical home or office environment poses a significant problem. To solve this, physical spaces can be extended by amplifying the mapping of physical to virtual movement (translational gain). Although amplified movement has been used since the earliest days of VR, little is known about how it influences reach-based interactions with virtual objects, now a standard feature of consumer VR. Consequently, this paper explores the picking and placing of virtual objects in VR for the first time, with translational gains of between 1x (a one-to-one mapping of a 3.5m*3.5m virtual space to the same sized physical space) and 3x (10.5m*10.5m virtual mapped to 3.5m*3.5m physical). Results show that reaching accuracy is maintained for up to 2x gain, however going beyond this diminishes accuracy and increases simulator sickness and perceived workload. We suggest gain levels of 1.5x to 1.75x can be utilized without compromising the usability of a VR task, significantly expanding the bounds of interactive room-scale VR.                     References                 Mahdi Azmandian, Timofey Grechkin, Mark Bolas, and Evan Suma. 2016. The redirected walking toolkit: a unified development platform for exploring large virtual environments. 2016 IEEE 2nd Workshop on Everyday Virtual Reality (WEVR): 9-- 14.Google ScholarMahdi Azmandian, Timofey Grechkin, and Evan Suma Rosenberg. 2017. An evaluation of strategies for two-user redirected walking in shared physical spaces. Proceedings - IEEE Virtual Reality: 91--98.Google ScholarMahdi Azmandian, Mark Hancock, Hrvoje Benko, Eyal Ofek, and Andrew D. Wilson. 2016. Haptic Retargeting: Dynamic Repurposing of Passive Haptics for Enhanced Virtual Reality Experiences. Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems - CHI '16: 1968-- 1979.  Google ScholarT Banton, J Stefanucci, F Durgin, a Fass, and D Proffitt. 2005. The Perception of Walking Speed in a Virtual Environment. Presence 14, 4: 394--406.  Google ScholarDoug A. Bowman and Larry F. Hodges. 1997. An evaluation of techniques for grabbing and manipulating remote objects in immersive virtual environments. Proceedings of the 1997 symposium on Interactive 3D graphics - SI3D '97: 35-.  Google ScholarEvren Bozgeyikli, Andrew Raij, Srinivas Katkoori, and Rajiv Dubey. 2016. Point and Teleport Locomotion Technique for Virtual Reality. In Proceedings of the 2016 Annual Symposium on Computer-Human Interaction in Play - CHI PLAY '16, 205--216.  Google ScholarF.P. Brooks. 1999. What's Real About Virtual Reality? Proceedings IEEE Virtual Reality (Cat. No. 99CB36316), December: 2--3. Google ScholarGerd Bruder, Frank Steinicke, Benjamin Bolte, Phil Wieland, Harald Frenz, and Markus Lappe. 2013. Exploiting perceptual limitations and illusions to support walking through virtual environments in confined physical spaces. Displays 34, 2: 132--141.Google ScholarGerd Bruder, Frank Steinicke, and Phil Wieland. 2011. Self-motion illusions in immersive virtual reality environments. 2011 IEEE Virtual Reality Conference: 39--46.  Google ScholarHaiwei Chen and Henry Fuchs. 2017. Supporting free walking in a large virtual environment. Proceedings of the Computer Graphics International Conference on - CGI '17: 1--6.  Google ScholarGabriel Cirio, Maud Marchal, Tony Regia-Corte, and Anatole L\u00e9cuyer. 2009. The magic barrier tape: a novel metaphor for infinite navigation in virtual worlds with a restricted walking workspace. Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology - VRST '09 1, 212: 155.  Google ScholarRudolph P. Darken, William R. Cockayne, and David Carmein. 1997. The omni-directional treadmill: A Locomotion Device for Virtual Worlds. Proceedings of the 10th annual ACM symposium on User interface software and technology - UIST '97: 213--221.  Google ScholarAjoy S. Fernandes and Steven K. Feiner. 2016. Combating VR sickness through subtle dynamic field-of-view modification. In 2016 IEEE Symposium on 3D User Interfaces, 3DUI 2016 Proceedings, 201--210.Google ScholarHarald Frenz, Markus Lappe, Marina Kolesnik, and Thomas B\u00fchrmann. 2007. Estimation of travel distance from visual motion in virtual environments. ACM Transactions on Applied Perception 4, 1: 3--es.  Google ScholarTimofey Grechkin, Jerald Thomas, Mahdi Azmandian, Mark Bolas, and Evan Suma. 2016. Revisiting detection thresholds for redirected walking. Proceedings of the ACM Symposium on Applied Perception - SAP '16: 113--120.  Google ScholarSG Hart and LE Staveland. 1988. Development of NASA-TLX (Task Load Index): Results of empirical and theoretical research. In Human mental workload. Retrieved June 17, 2013 from http://humanfactors.arc.nasa.gov/groups/TLX/down loads/NASA-TLXChapter.pdfGoogle ScholarJL Hintze and RD Nelson. 1998. Violin plots: a box plot-density trace synergism. The American Statistician. Retrieved November 26, 2015 fromGoogle ScholarEric Hodgson and Eric Bachmann. 2013. Comparing four approaches to generalized redirected walking: simulation and live user data. IEEE transactions on visualization and computer graphics 19, 4: 634--43.  Google ScholarEric Hodgson, Eric Bachmann, and David Waller. 2011. Redirected walking to explore virtual environments. ACM Transactions on Applied Perception 8, 4: 1--22.  Google ScholarHTC. HTC Vive. Retrieved September 18, 2017 from http://www.htcvr.com/Google ScholarVictoria Interrante, Brian Ries, and Lee Anderson. 2007. Seven league boots: A new metaphor for augmented locomotion through moderately large scale immersive virtual environments. IEEE Symposium on 3D User Interfaces 2007 Proceedings, 3DUI 2007: 167--170.Google ScholarP. M. Jaekl, M. R. Jenkin, and Laurence R. Harris. 2005. Perceiving a stable world during active rotational and translational head movements. Experimental Brain Research 163, 3: 389--399.Google ScholarOmar Janeh, Eike Langbehn, Frank Steinicke, Gerd Bruder, Alessandro Gulberti, Monika Poetter, O Janeh, E Langbehn, and F Steinicke. 2017. Walking in Virtual Reality: Effects of Manipulated Visual Self-Motion on Walking Biomechanics. ACM Trans. Appl. Percept. ACM Transactions on Applied Perception 14, 12: 1--15.  Google ScholarRobert S. Kennedy, Norman E. Lane, Kevin S. Berbaum, and Michael G. Lilienthal. 1993. Simulator Sickness Questionnaire: An Enhanced Method for Quantifying Simulator Sickness. The International Journal of Aviation Psychology 3, 3: 203--220.Google ScholarBehrang Keshavarz, Bernhard E Riecke, Lawrence J Hettinger, and Jennifer L Campos. 2015. Vection and visually induced motion sickness: how are they related? Frontiers in psychology 6: 472.Google ScholarMartin Krzywinski and Naomi Altman. 2014. Points of Significance: Visualizing samples with box plots. Nature Methods 11, 2: 119--120.Google ScholarAndreas Kunz, Markus Zank, Morten Fjeld, and Thomas Nescher. 2016. Real walking in virtual environments for factory planning and evaluation. Procedia CIRP 44: 257--262.Google ScholarEike Langbehn, Paul Lubos, Gerd Bruder, and Frank Steinicke. 2017. Bending the Curve: Sensitivity to Bending of Curved Paths and Application in RoomScale VR. IEEE Transactions on Visualization and Computer Graphics 23, 4: 1349--1358.  Google ScholarEike Langbehn, Paul Lubos, Gerd Bruder, and Frank Steinicke. 2017. Application of redirected walking in room-scale VR. Proceedings - IEEE Virtual Reality 2: 449--450.Google ScholarLeap Motion. 2018. Hand tracking VR platform. leapmotion.com. Retrieved January 4, 2018 from https://www.leapmotion.com/product/vrGoogle ScholarRV Lenth. Least-squares means: the R package lsmeans. jstatsoft.org. Retrieved September 13, 2017 from https://www.jstatsoft.org/article/view/v069i01/v69i 01.pdfGoogle ScholarKeigo Matsumoto, Yuki Ban, Takuji Narumi, Yohei Yanase, Tomohiro Tanikawa, and Michitaka Hirose. 2016. Unlimited corridor: redirected walking techniques using visuo haptic interaction. ACM SIGGRAPH 2016 Emerging Technologies on SIGGRAPH '16: 1--2.  Google ScholarKeigo Matsumoto, Takuji Narumi, Yuki Ban, Tomohiro Tanikawa, and Michitaka Hirose. 2017. Turn physically curved paths into virtual curved paths. Proceedings - IEEE Virtual Reality: 247--248.Google ScholarMark Mcgill, Alexander Ng, and Stephen Brewster. 2017. I Am The Passenger: How Visual Motion Cues Can Influence Sickness For In-Car VR. Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems - CHI '17: 5655--5668.  Google ScholarThomas Nescher and Andreas Kunz. 2013. Using Head Tracking Data for Robust Short Term Path Prediction of Human Locomotion.. Springer, Berlin, Heidelberg, 172--191.Google ScholarNguyen Thi Anh Ngoc, Yannick Rothacher, Peter Brugger, Bigna Lenggenhager, and Andreas Kunz. 2016. Estimation of individual redirected walking thresholds using standard perception tests. In Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology - VRST '16, 329-- 330.  Google ScholarAnh Nguyen, Federico Cervellati, and Andreas Kunz. 2017. Gain Compensation in Redirected Walking. 4.Google ScholarAnders Paludan, Jacob Elbaek, Mathias Mortensen, Morten Zobbe, Niels Christian Nilsson, Rolf Nordahl, Lars Reng, and Stefania Serafin. 2016. Disguising rotational gain for redirected walking in virtual reality: Effect of visual density. Proceedings - IEEE Virtual Reality 2016--July: 259--260.Google ScholarTabitha C. Peck, Henry Fuchs, and Mary C. Whitton. 2012. The design and evaluation of a large-scale real-walking locomotion interface. IEEE Transactions on Visualization and Computer Graphics 18, 7: 1053--1067.  Google ScholarDavid Regan, K I Beverley, and Max Cynader. 1979. The visual perception of motion in depth. Scientific American 241, 1: 136--51.Google ScholarBibiana Da Silva. 2017. The average dimensions of a living room. ehow.co.uk. Retrieved September 18, 2017 from http://www.ehow.co.uk/info_8574543_averagedimensions-living-room.htmlGoogle ScholarF Steinicke, G Bruder, J Jerald, H Frenz, and M Lappe. 2010. Estimation of Detection Thresholds for Redirected Walking Thechniques. IEEE Transactions on Visualization and Computer Graphics 16, 1: 17--27.  Google ScholarFrank Steinicke, Gerd Bruder, Jason Jerald, Harald Frenz, Markus Lappe, and Harald Frenz. 2008. Analyses of Human Sensitivity to Redirected Walking. Vrst 146, 3: 149--156.  Google ScholarFrank Steinicke, Gerd Bruder, Timo Ropinski, and Klaus Hinrichs. 2008. Moving Towards Generally Applicable Redirected Walking. Proceedings of the 10th Virtual Reality International Conference (VRIC 2008): 15--24.Google ScholarEvan A. Suma, Mahdi Azmandian, Timofey Grechkin, Thai Phan, and Mark Bolas. 2015. Making small spaces feel large: infinite walking in virtual reality. In ACM SIGGRAPH 2015 Emerging Technologies on - SIGGRAPH '15, 1--1.  Google ScholarEvan A. Suma, Seth Clark, David Krum, Samantha Finkelstein, Mark Bolas, and Zachary Warte. 2011. Leveraging Change Blindness for Rediection in Virtual Environments. In Proceedings - IEEE Virtual Reality, 159--166.  Google ScholarEvan A. Suma, Zachary Lipps, Samantha Finkelstein, David M. Krum, and Mark Bolas. 2012. Impossible spaces: Maximizing natural walking in virtual environments with self-overlapping architecture. IEEE Transactions on Visualization and Computer Graphics 18, 4: 555--564.  Google ScholarSam Tregillus, Majed Al Zayer, and Eelke Folmer. 2017. Handsfree Omnidirectional VR Navigation using Head Tilt. Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems - CHI '17: 4063--4068.  Google ScholarTriangular Pixels. 2017. Unseen Diplomacy: a VR obstacle course. triangularpixels.net. Retrieved December 30, 2017 from http://www.triangularpixels.net/cms/games/unseendiplomacy/Google ScholarMartin Usoh, Kevin Arthur, Mary C Whitton, Rui Bastos, Anthony Steed, Mel Slater, and Frederick P Brooks. 1999. Walking &amp;gt; walking-in-place &amp;gt; flying, in virtual environments. Proceedings of the 26th annual conference on Computer graphics and interactive techniques - SIGGRAPH '99: 359--364.  Google ScholarKhrystyna Vasylevska and Hannes Kaufmann. 2017. Towards efficient spatial compression in selfoverlapping virtual environments. 2017 IEEE Symposium on 3D User Interfaces, 3DUI 2017 Proceedings: 12--21.Google ScholarKhrystyna Vasylevska, Hannes Kaufmann, Mark Bolas, and Evan A. Suma. 2013. Flexible spaces: Dynamic layout generation for infinite walking in virtual environments. IEEE Symposium on 3D User Interface 2013, 3DUI 2013 - Proceedings: 39--42.Google ScholarKhrystyna Vasylevska, Iana Podkosova, and Hannes Kaufmann. 2015. Walking in Virtual Reality: Flexible Spaces and Other Techniques. In The Visual Language of Technique, L. Cocchiarella (ed.). Springer, 81--97.Google ScholarWiki. 2017. Locomotion - Virtual Reality and Augmented Reality Wiki - VR and AR Wiki. XinReality. Retrieved September 13, 2017 from https://xinreality.com/wiki/LocomotionGoogle ScholarPreston Tunnell Wilson, William Kalescky, and Ansel Maclaughlin. 2015. VR Locomotion?: Walking &amp;gt; Walking in Place &amp;gt; Arm Swinging. 243-- 249.Google ScholarJacob O. Wobbrock, Leah Findlater, Darren Gergle, and James J. Higgins. 2011. The aligned rank transform for nonparametric factorial analyses using only anova procedures. In Proceedings of the 2011 annual conference on Human factors in computing systems - CHI '11, 143.  Google ScholarXianshi Xie, Qiufeng Lin, Haojie Wu, Gayathri Narasimham, Timothy P. McNamara, Thomas H. Carr, John Rieser, and Bobby Bodenheimer. 2010. A System for Exploring Large Virtual Environments That Combines Scaled Translational Gain and Interventions. Symposium on Applied Perception in Graphics and Visualization 1, 212: 65--72.  Google ScholarCatherine Zanbaka, Benjamin Lok, Sabarish Babu, Dan Xiao, Amy Ulinski, and Larry F. Hodges. 2004. Effects of travel technique on cognition in virtual environments. Proceedings - Virtual Reality Annual International Symposium: 149--156.  Google ScholarRuimin Zhang, Bochao Li, and Scott A Kuhl. 2014. Human Sensitivity to Dynamic Translational Gains in Head-Mounted Displays. In Proceedings of SUI 2014, 62--65.  Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3173574.3173673/2c5f128b-b1bd-468a-9065-8af67327978a/pn1671-file5.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee06e0e0927f1e11a21c84c9577a2a912c46bd41e57ea0672470c335cc416786682be9bd4d78cfc54acfca0b0aa7af7c2a85e85e8b30c0328683b0e9fe25edc8966eec11478ac70759application/x-mpegurlmp48.1 MB", "keywords": ["translational gain", "virtual reality", "redirected walking", "object manipulation", "amplified movement"], "published_in": "CHI '18: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems", "publication_date": "19 April 2018", "citations": "10", "isbn": "9781450356206", "doi": "10.1145/3173574", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3173574.3173673", "paper_url": "https://dl.acm.org/doi/10.1145/3173574.3173673"}, {"title": "Pseudo-Haptic Weight: Changing the Perceived Weight of Virtual Objects By Manipulating Control-Display Ratio", "authors": ["Majed Samad", "Elia Gatti", "Anne Hermes", "Hrvoje Benko", "Cesare Parise"], "abstract": "In virtual reality, the lack of kinesthetic feedback often prevents users from experiencing the weight of virtual objects. Control-to-display (C/D) ratio manipulation has been proposed as a method to induce weight perception without kinesthetic feedback. Based on the fact that lighter (heavier) objects are easier (harder) to move, this method induces an illusory perception of weight by manipulating the rendered position of users' hands---increasing or decreasing their displayed movements. In a series of experiments we demonstrate that C/D-ratio induces a genuine perception of weight, while preserving ownership over the virtual hand. This means that such a manipulation can be easily introduced in current VR experiences without disrupting the sense of presence. We discuss these findings in terms of estimation of physical work needed to lift an object. Our findings provide the first quantification of the range of C/D-ratio that can be used to simulate weight in virtual reality.", "keywords": ["pseudo-haptics", "virtual weight", "multisensory integration"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "14", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300550", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300550"}, {"title": "RealityCheck: Blending Virtual Environments with Situated Physical Reality", "authors": ["Jeremy Hartmann", "Christian Holz", "Eyal Ofek", "Andrew D. Wilson"], "abstract": "Today's virtual reality (VR) systems offer chaperone rendering techniques that prevent the user from colliding with physical objects. Without a detailed geometric model of the physical world, these techniques offer limited possibility for more advanced compositing between the real world and the virtual. We explore this using a realtime 3D reconstruction of the real world that can be combined with a virtual environment. RealityCheck allows users to freely move, manipulate, observe, and communicate with people and objects situated in their physical space without losing the sense of immersion or presence inside their virtual world. We demonstrate RealityCheck with seven existing VR titles, and describe compositing approaches that address the potential conflicts when rendering the real world and a virtual environment together. A study with frequent VR users demonstrate the affordances provided by our system and how it can be used to enhance current VR experiences.                     References                 Mahdi Azmandian, Mark Hancock, Hrvoje Benko, Eyal Ofek, and Andrew D. Wilson. 2016. Haptic Retargeting: Dynamic Repurposing of Passive Haptics for Enhanced Virtual Reality Experiences. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems - CHI '16. ACM Press, New York, New York, USA, 1968--1979.  Google ScholarDigital LibraryYoav Benjamini and Yosef Hochberg. 1995. Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing. Journal of the Royal Statistical Society. Series B (Methodological) 57, 1 (1995), 289--300. http://www.jstor.org/stable/2346101Google ScholarCross RefLung-Pan Cheng, Thijs Roumen, Hannes Rantzsch, Sven K\u00f6hler, Patrick Schmidt, Robert Kovacs, Johannes Jasper, Jonas Kemper, and Patrick Baudisch. 2015. TurkDeck: Physical Virtual Reality Based on People. Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology - UIST '15 (2015), 417--426.  Google ScholarDigital LibraryMingsong Dou, Jonathan Taylor, Pushmeet Kohli, Vladimir Tankovich, Shahram Izadi, Sameh Khamis, Yury Degtyarev, Philip Davidson, Sean Ryan Fanello, Adarsh Kowdle, Sergio Orts Escolano, Christoph Rhemann, and David Kim. 2016. Fusion4D: Real-time Performance Capture of Challenging Scenes. ACM Transactions on Graphics 35, 4 (jul 2016), 1--13.  Google ScholarDigital LibraryRuofei Du, Ming Chuang, Wayne Chang, Hugues Hoppe, and Amitabh Varshney. 2018. Montage4D: Interactive Seamless Fusion of Multiview Video Textures. In Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games - I3D '18, Vol. 11. ACM Press, New York, New York, USA, 1--11.  Google ScholarDigital LibraryKeinosuke Fukunaga and L. Hostetler. 1975. The estimation of the gradient of a density function, with applications in pattern recognition. IEEE Transactions on Information Theory 21, 1 (jan 1975), 32--40.  Google ScholarDigital LibraryRan Gal, Lior Shapira, Eyal Ofek, and Pushmeet Kohli. 2014. FLARE: Fast layout for augmented reality applications. In 2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR). IEEE, 207--212.Google ScholarCross RefJan Gugenheimer, Evgeny Stemasov, Julian Frommel, and Enrico Rukzio. 2017. ShareVR: Enabling Co-Located Experiences for Virtual Reality between HMD and Non-HMD Users. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems CHI '17. ACM Press, New York, New York, USA, 4021--4033.  Google ScholarDigital LibraryAnuruddha Hettiarachchi and Daniel Wigdor. 2016. Annexing Reality: Enabling Opportunistic Use of Everyday Objects as Tangible Proxies in Augmented Reality. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems - CHI '16. ACM Press, New York, New York, USA, 1957--1967.  Google ScholarDigital LibraryGalen Hunt and Doug Brubacher. 1999. Detours: Binary Interception of Win32 Functions. In Proceedings of the 3rd Conference on USENIX Windows NT Symposium - Volume 3 (WINSYM'99). USENIX Association, Berkeley, CA, USA, 14--14. http://dl.acm.org/citation.cfm?id=1268427. Google ScholarDigital LibrarySeokhee Jeon and Seungmoon Choi. 2009. Haptic Augmented Reality: Taxonomy and an Example of Stiffness Modulation. Presence: Teleoperators and Virtual Environments 18, 5 (oct 2009), 387--408.  Google ScholarDigital LibraryBrett Jones, Lior Shapira, Rajinder Sodhi, Michael Murdock, Ravish Mehra, Hrvoje Benko, Andrew Wilson, Eyal Ofek, Blair MacIntyre, and Nikunj Raghuvanshi. 2014. RoomAlive: Magical Experiences Enabled by Scalable, Adaptive Projector-camera Units. Proceedings of the 27th annual ACM symposium on User interface software and technology UIST '14 (2014), 637--644.  Google ScholarDigital LibraryBrett R. Jones, Hrvoje Benko, Eyal Ofek, and Andrew D. Wilson. 2013. IllumiRoom. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13. ACM Press, New York, New York, USA, 869.Google ScholarTakeo Kanade, Peter Rander, and PJ Narayanan. 1997. Virtualized reality: Constructing virtual worlds from real scenes. IEEE multimedia 4, 1 (1997), 34--47.  Google ScholarDigital LibraryPascal Knierim, Valentin Schwind, Anna Maria Feit, Florian Nieuwenhuizen, and Niels Henze. 2018. Physical Keyboards in Virtual Reality: Analysis of Typing Performance and Effects of Avatar Hands. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI '18. ACM Press, New York, New York, USA, 1--9.  Google ScholarDigital LibraryRyohei Komiyama, Takashi Miyaki, and Jun Rekimoto. 2017. JackIn Space: Designing a Seamless Transition Between First and Third Person View for Effective Telepresence Collaborations Ryohei. In Proceedings of the 8th Augmented Human International Conference on - AH '17. ACM Press, New York, New York, USA, 1--9.  Google ScholarDigital LibraryJ\u00e9r\u00e9my Lacoche, Nico Pallamin, Thomas Boggini, and J\u00e9r\u00f4me Royan. 2017. Improved Redirection with Distractors: A large-scale-realwalking locomotion interface and its effect on navigation in virtual environments. In Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology - VRST '17. ACM Press, New York, New York, USA, 1--9.Google ScholarDavid Lindlbauer and Andy D Wilson. 2018. Remixed Reality: Manipulating Space and Time in Augmented Reality. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI '18. ACM Press, New York, New York, USA, 1--13.  Google ScholarDigital LibraryChristian Mai, Mariam Hassib, and Ceenu George. 2017. Like Elephants Do: Sensing Bystanders During HMD Usage. Technical Report. https://pdfs.semanticscholar.org/5513/ 8687c17ad46747c95ab33fa9c4851ee2d26e.pdf?Google ScholarSteve Mann. 1999. Mediated Reality. Linux J. 1999, 59es, Article 5 (March 1999). http://dl.acm.org/citation.cfm?id=327697.327702 Google ScholarDigital LibrarySebastian Marwecki, Maximilian Brehm, Lukas Wagner, Lung-Pan Cheng, Florian 'Floyd' Mueller, and Patrick Baudisch. 2018. VirtualSpace - Overloading Physical Space with Multiple Virtual Reality Users. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI '18. ACM Press, New York, New York, USA, 1--10.  Google ScholarDigital LibraryJohn C. McClelland, Robert J Teather, and Audrey Girouard. 2017. Haptobend: Shape-Changing Passive Haptic Feedback in Virtual Reality. In Proceedings of the 5th Symposium on Spatial User Interaction - SUI '17. ACM Press, New York, New York, USA, 82--90.  Google ScholarDigital LibraryMark McGill, Daniel Boland, Roderick Murray-Smith, and Stephen Brewster. 2015. A dose of reality: overcoming usability challenges in vr head-mounted displays. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems - CHI '15. ACM Press, New York, New York, USA, 2143--2152.  Google ScholarDigital LibraryPaul Milgram and Herman Colquhoun. 1999. A taxonomy of real and virtual world display integration. Mixed reality: Merging real and virtual worlds 1 (1999), 1--26.Google ScholarPaul Milgram and Fumio Kishino. 1994. A Taxonomy of Mixed Reality Visual Displays Augmented Reality. Technical Report 12. http://vered. rose.utoronto.ca/people/paulGoogle ScholarRaul Mur-Artal and Juan D. Tardos. 2017. ORB-SLAM2: An OpenSource SLAM System for Monocular, Stereo, and RGB-D Cameras. IEEE Transactions on Robotics 33, 5 (oct 2017), 1255--1262. arXiv:1610.06475Google ScholarCross RefTabitha C. Peck, Henry Fuchs, and Mary C. Whitton. 2010. Improved Redirection with Distractors: A large-scale-real-walking locomotion interface and its effect on navigation in virtual environments. In 2010 IEEE Virtual Reality Conference (VR). IEEE, 35--38.  Google ScholarDigital LibraryJulian Petford, Miguel A Nacenta, Carl Gutwin, Joseph Eremondi, and Cody Ede. 2016. The ASPECTA Toolkit: Affordable Full Coverage Displays. In Proceedings of the 5th ACM International Symposium on Pervasive Displays - PerDis '16. ACM Press, New York, New York, USA, 87--105.  Google ScholarDigital LibraryJoseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. 2016. You Only Look Once: Unified, Real-Time Object Detection. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, 779--788. arXiv:1506.02640Google ScholarCross RefErik Reinhard, M. Adhikhmin, Bruce Gooch, and Peter Shirley. 2001. Color transfer between images. IEEE Computer Graphics and Applications 21, 4 (2001), 34--41.  Google ScholarDigital LibraryJeffrey M. Richter. 1999. Programming Applications for Microsoft Windows with Cdrom (4th ed.). Microsoft Press, Redmond, WA, USA. Google ScholarDigital LibraryJoan Sol Roo and Martin Hachet. 2017. One Reality. In Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology - UIST '17. ACM Press, New York, New York, USA, 787--795.Google ScholarLior Shapira and Daniel Freedman. 2016. Reality Skins: Creating Immersive and Tactile Virtual Environments. In 2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR). IEEE, 115--124.Google ScholarAdalberto L Simeone. 2015. Substitutional reality: Towards a research agenda. In 2015 IEEE 1st Workshop on Everyday Virtual Reality (WEVR). IEEE, 19--22.Google ScholarCross RefShuran Song, Fisher Yu, Andy Zeng, Angel X. Chang, Manolis Savva, and Thomas Funkhouser. 2017. Semantic Scene Completion from a Single Depth Image. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, 190--198. arXiv:1611.08974Google ScholarCross RefMisha Sra, Sergio Garrido-Jurado, and Chris Schmandt. 2016. Procedurally generated virtual reality from 3D reconstructed physical space. In Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology - VRST '16. ACM Press, New York, New York, USA, 191--200.  Google ScholarDigital LibraryWilliam Steptoe, Simon Julier, and Anthony Steed. 2014. Presence and discernability in conventional and non-photorealistic immersive augmented reality. In 2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR). IEEE, 213--218.Google ScholarCross RefQi Sun, Arie Kaufman, Anjul Patney, Li-Yi Wei, Omer Shapira, Jingwan Lu, Paul Asente, Suwen Zhu, Morgan Mcguire, and David Luebke. 2018. Towards Virtual Reality Infinite Walking: Dynamic Saccadic Redirection. ACM Transactions on Graphics 37, 4 (jul 2018), 1--13.  Google ScholarDigital LibraryQi Sun, Li-Yi Wei, and Arie Kaufman. 2016. Mapping virtual and physical reality. ACM Transactions on Graphics 35, 4 (jul 2016), 1--12.  Google ScholarDigital LibrarySungjoon Choi, Qian-Yi Zhou, and Vladlen Koltun. 2015. Robust reconstruction of indoor scenes. In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, 5556--5565.Google ScholarCross RefMartin Usoh, Ernest Catena, Sima Arman, and Mel Slater. 2000. Using Presence Questionnaires in Reality. Presence: Teleoperators and Virtual Environments 9, 5 (oct 2000), 497--503.  Google ScholarDigital LibraryAndrew Wilson. 2017. Fast Lossless Depth Image Compression. In Proceedings of the Interactive Surfaces and Spaces on ZZZ - ISS '17. ACM Press, New York, New York, USA, 100--105.  Google ScholarDigital LibraryAndrew D Wilson and Hrvoje Benko. 2016. Projected Augmented Reality with the RoomAlive Toolkit. In Proceedings of the 2016 ACM on Interactive Surfaces and Spaces. ACM, 517--520.  Google ScholarDigital LibraryJacob O Wobbrock, Leah Findlater, Darren Gergle, and James J Higgins. 2011. The aligned rank transform for nonparametric factorial analyses using only anova procedures. In Proceedings of the 2011 annual conference on Human factors in computing systems - CHI '11. ACM Press, New York, New York, USA, 143.  Google ScholarDigital LibraryYiwei Zhao and Sean Follmer. 2018. A Functional Optimization Based Approach for Continuous 3D Retargeted Touch of Arbitrary, Complex Boundaries in Haptic Virtual Reality. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI '18. ACM Press, New York, New York, USA, 1--12.  Google ScholarDigital LibrarySupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3290605.3300577/3d173162-7419-4d12-bc14-a6ff265931b2/paper347p.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee05eee35a4ac3e15fa134b9c2291a9e36ad5e21dfb2c346e2f3fecccc3455aa3d501ff857f21e0d5e58deb8f8b1ac755ae615b9a9dc0c65547a640c70ea63fa8ace6b4cea1e64dc9aapplication/x-mpegurlmp46.6 MB", "keywords": ["depth cameras", "3d compositing", "virtual reality"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "4", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300577", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300577"}, {"title": "FRVRIT: A Tool for Full Body Virtual Reality Game Evaluation", "authors": ["Daniel Maccormick", "Alain Sangalang", "Jackson Rushing", "Ravnik Singh Jagpal", "Pejman Mirza-Babaei", "Loutfouz Zaman"], "abstract": "Virtual reality (VR) games continue to grow in popularity with the advancement of commercial VR capabilities such as the inclusion of full body tracking. This means game developers can design for novel interactions involving a player's full body rather than solely relying on controller input. However, existing research on evaluating player interaction in VR games primarily focuses on game content and inputs from game controllers or player hands. Current approaches for evaluating player full body interactions are limited to simple qualitative observation which makes evaluation difficult and time-consuming. We present a Full Room Virtual Reality Investigation Tool (FRVRIT) which combines data recording and visualization to provide a quantitative solution for evaluating player movement and interaction in VR games. The tool facilitates objective data observation through multiple visualization methods that can be manipulated, allowing developers to better observe and record player movements in the VR space to improve and iterate on the desired interactions in their games.                     References                 2005. Learning C# and coding in Unity for beginners. (2005). https://unity3d.com/learning-c-sharp-in-unity-for-beginnersGoogle Scholar2014. Kinect - Windows app development. (2014). https://developer.microsoft.com/en-us/windows/kinectGoogle Scholar2016. Job Simulator: the 2050 Archives | Owlchemy Labs. (2016). https://jobsimulatorgame.com/Google Scholar2016. Oculus Rift: VR Headset for VR Ready PCs | Oculus. (2016). https://www.oculus.com/rift/#oui-csl-rift-games=robo-recallGoogle Scholar2016. PaintLab on Steam. (2016). https://store.steampowered.com/app/455160/PaintLab/Google Scholar2016. VIVE Canada | Discover Virtual Reality Beyond Imagination. (2016). https://www.vive.com/ca/Google Scholar2017. How to Get Raw (Positional) Data from HTC Vive - CodeProject. (2017). https://www.codeproject.com/Articles/ 1171122/How-to-Get-Raw-Positional-Data-from-HTC-ViveGoogle Scholar2017. Simple File Browser - Asset Store. (2017). https://assetstore.unity.com/packages/tools/input-management/ simple-file-browser-98451Google Scholar2018. Beat Saber. (2018). http://beatsaber.com/Google Scholar2018. Global augmented/virtual reality market size 2016--2022 | Statistic. (2018). https://www.statista.com/statistics/ 591181/global-augmented-virtual-reality-market-size/Google Scholar2018. MATLAB - MathWorks. (2018). https://www.mathworks.com/products/matlab.htmlGoogle ScholarDimitrios S. Alexiadis, Philip Kelly, Petros Daras, Noel E. O'Connor, Tamy Boubekeur, and Maher Ben Moussa. Evaluating a dancer's performance using kinect-based skeleton tracking. In Proceedings of the 19th ACM international conference on Multimedia - MM '11 (2011). ACM Press, 659.  Google ScholarBrandon Drenikow and Pejman Mirza-Babaei. Vixen: interactive visualization of gameplay experiences. In Proceedings of the International Conference on the Foundations of Digital Games - FDG '17 (2017). ACM Press, 1--10.  Google ScholarSimone Kriglstein, Gnter Wallner, and Margit Pohl. 2014. A user study of different gameplay visualizations. ACM, 361--370.  Google ScholarNorman Sally Jane, Lawson Sian E.M., Olivier Patrick, Watson Paul, Chan Anita M.-A., Dade-Robertson Martyn, Dunphy Paul, Green Dave, Hiden Hugo, Hook Jonathan, and Jackson Daniel G. 2009. AMUC: Associated Motion capture User Categories. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 367, 1898 (July 2009), 2771--2780.Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3290607.3312825/f93e8e49-8c62-4962-8366-7fa72aafcee6/lbw1710p.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee05eee35a4ac1e15fa135bbdbad36e8784b170bee76904e874bb0da50dd8a513802eba80101f7c5a803cbeb60ad20a06bc492b020ad180e2fe44c44382eea4206b1214f953dfc2fb1application/x-mpegurlmp42.5 MB", "keywords": ["full body", "analytics", "visualization", "tool", "GUR", "virtual reality", "full room"], "published_in": "CHI EA '19: Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "0", "isbn": "9781450359719", "doi": "10.1145/3290607", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290607.3312825", "paper_url": "https://dl.acm.org/doi/10.1145/3290607.3312825"}, {"title": "A Dose of Reality: Overcoming Usability Challenges in VR Head-Mounted Displays", "authors": ["Mark Mcgill", "Daniel Boland", "Roderick Murray-Smith", "Stephen Brewster"], "abstract": "We identify usability challenges facing consumers adopting Virtual Reality (VR) head-mounted displays (HMDs) in a survey of 108 VR HMD users. Users reported significant issues in interacting with, and being aware of their real-world context when using a HMD. Building upon existing work on blending real and virtual environments, we performed three design studies to address these usability concerns. In a typing study, we show that augmenting VR with a view of reality significantly corrected the performance impairment of typing in VR. We then investigated how much reality should be incorporated and when, so as to preserve users' sense of presence in VR. For interaction with objects and peripherals, we found that selectively presenting reality as users engaged with it was optimal in terms of performance and users' sense of presence. Finally, we investigated how this selective, engagement-dependent approach could be applied in social environments, to support the user's awareness of the proximity and presence of others.                     References                 Barrett, J., and Krueger, H. Performance effects of reduced proprioceptive feedback on touch typists and casual users in a typing task. Behaviour &amp; Information Technology 13, 6 (1994), 373--381.Google ScholarCross RefBenford, S., et al. Understanding and constructing shared spaces with mixed-reality boundaries. ACM TOCHI 5, 3 (1998), 185--223.  Google ScholarDigital LibraryBillinghurst, M., and Kato, H. Collaborative mixed reality. In Proc. ISMR '99, ACM (1999), 261--284.Google ScholarCross RefBruder, G., and et al. Augmented virtual studio for architectural exploration, 2010.Google ScholarCarvalho, F. G., et al. Toward the design of transitional interfaces: an exploratory study on a semi-immersive hybrid user interface. Virtual Reality 16, 4 (2012).Google ScholarDigital LibraryDavis, L., et al. Enabling a continuum of virtual environment experiences. IEEE Comput. Graph. Appl. 23, 2 (Mar. 2003), 10--12.  Google ScholarDigital LibraryGonzalez, G., et al. Evaluation of text input techniques in immersive virtual environments. In New Trends on HumanComputer Interaction, J. A. Macas et al., Eds. Springer London, 2009, 109--118.Google ScholarGrasset, R., Lamb, P., and Billinghurst, M. Evaluation of mixed-space collaboration. In Proc. ISMAR '05, IEEE (2005), 90--99.  Google ScholarDigital LibraryHutchison, A. Back to the holodeck: New life for virtual reality? In Proc. DIMEA '07, ACM (2007), 98--104.  Google ScholarDigital LibraryKaber, D. B., and Zhang, T. Human factors in virtual reality system design for mobility and haptic task performance. Reviews of Human Factors and Ergonomics 7, 1 (2011), 323--366.Google ScholarCross RefKristensson, P. O., and Vertanen, K. Performance comparisons of phrase sets and presentation styles for text entry evaluations. In Proc. IUI '12, ACM (2012).  Google ScholarDigital LibraryLombard, M., et al. Measuring presence: the temple presence inventory. In Proc. ISPR '09 (2009).Google ScholarMetzger, P. Adding reality to the virtual. In Proc. VR '93, IEEE (1993), 7--13.  Google ScholarDigital LibraryMilgram, P., and Colquhoun, H. A taxonomy of real and virtual world display integration. Mixed reality: Merging real and virtual worlds (1999), 5--30.Google ScholarMilgram, P., and Kishino, F. A Taxonomy Of Mixed Reality Visual Displays. IEICE Transactions on Information and Systems 77, 12 (1994), 1321--1329.Google ScholarPohl, H., and Murray-Smith, R. Focused and casual interactions: Allowing users to vary their level of engagement. In Proc. CHI 2013, ACM (2013).  Google ScholarDigital LibraryRekimoto, J., and Nagao, K. The world through the computer: Computer augmented interaction with real world environments. In Proc. UIST '95, ACM (1995).  Google ScholarDigital LibrarySchubert, T., Friedmann, F., and Regenbrecht, H. The experience of presence: Factor analytic insights. Presence: Teleoperators and virtual environments 10, 3 (2001), 266--281.  Google ScholarDigital LibrarySlater, M. Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments. Phil. Trans. R. Soc. Lond. B: Biological Sciences 364, 1535 (2009), 3549--3557.Google ScholarCross RefSoukoreff, R. W., and MacKenzie, I. S. Metrics for text entry research. In Proc. CHI '03, ACM (2003), 113--120.  Google ScholarDigital LibrarySteinicke, F., et al. A virtual body for augmented virtuality by chroma-keying of egocentric videos. In 3DUI 2009, IEEE (2009), 125--126.  Google ScholarDigital LibraryTecchia, F., et al. I'M in VR!: Using Your Own Hands in a Fully Immersive MR System. In Proc. VRST '14, ACM (2014), 73--76.  Google ScholarDigital LibraryThomas, B. H. A survey of visual, mixed, and augmented reality gaming. Computers in Entertainment 10, 3 (2012), 3:1--3:33.  Google ScholarDigital LibraryVan Baren, J., and IJsselsteijn, W. Measuring presence: A guide to current measurement approaches. OmniPres project (2004).Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/2702123.2702382/016798ac-d94f-46ea-b9d0-7915add2e2f9/p2143-mcgill.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ef00e7e19e8ead7e09dfbd941213e5ab4dc3dd5414365fa3661c54fbed188f74a44af550c25ab26f45414de4e91c6607fbd0741c87d783102c31d2ca5f28799caefad07e2cdf2bea9bapplication/x-mpegurlmp4109.4 MB", "keywords": ["augmented virtuality", "virtual reality", "engagement"], "published_in": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems", "publication_date": "18 April 2015", "citations": "51", "isbn": "9781450331456", "doi": "10.1145/2702123", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2702123.2702382", "paper_url": "https://dl.acm.org/doi/10.1145/2702123.2702382"}, {"title": "Beyond Horror and Fear: Exploring Player Experience Invoked by Emotional Challenge in VR Games", "authors": ["Xiaolan Peng", "Jin Huang", "Linghan Li", "Chen Gao", "Hui Chen", "Feng Tian", "Hongan Wang"], "abstract": "Digital gameplay experience depends not only on the type of challenge that the game provides, but also on how the challenge be presented. With the introduction of a novel type of emotional challenge and the increasing popularity of virtual reality (VR), there is a need to explore player experience invoked by emotional challenge in VR games. We selected two games that provides emotional challenge and conducted a 24-subject experiment to compare the impact of a VR and monitor-display version of each game on multiple player experiences. Preliminary results show that many positive emotional experiences have been enhanced significantly with VR while negative emotional experiences such as horror and fear have less been influenced; participants' perceived immersion and presence were higher when using VR than using monitor-display. Our finding of VR's expressive capability in emotional experiences may encourage more design and research with regard to emotional challenge in VR games.", "keywords": ["games", "virtual reality", "emotion", "emotional challenge", "player experience"], "published_in": "CHI EA '19: Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "3", "isbn": "9781450359719", "doi": "10.1145/3290607", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290607.3312832", "paper_url": "https://dl.acm.org/doi/10.1145/3290607.3312832"}, {"title": "Emotional Beasts: Visually Expressing Emotions through Avatars in VR", "authors": ["Guillermo Bernal", "Pattie Maes"], "abstract": "With the advances in Virtual Reality (VR) and physiological sensing technology, even more immersive computer-mediated communication through life-like characteristics is now possible. In response to the current lack of culture, expression and emotions in VR avatars, we propose a two-fold solution. First, integration of bio-signal sensors into the HMD and techniques to detect aspects of the emotional state of the user. Second, the use of this data to generate expressive avatars which we refer to as Emotional Beasts. The creation of Emotional Beasts will allow us to experiment with the manipulation of a user's self-expression in VR space and as well as the perception of others in it, providing some valuable tools to evoke a desired emotional reaction. As this medium moves forward, this and other tools are what will help the field of virtual reality expand from a medium of surface-level experience to one of deep, emotionally compelling human-to-human connection.", "keywords": ["social virtual reality", "bio-signals", "affective computing", "self-expression", "avatars"], "published_in": "CHI EA '17: Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "publication_date": "6 May 2017", "citations": "6", "isbn": "9781450346566", "doi": "10.1145/3027063", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3027063.3053207", "paper_url": "https://dl.acm.org/doi/10.1145/3027063.3053207"}, {"title": "Vremiere: In-Headset Virtual Reality Video Editing", "authors": ["Cuong Nguyen", "Stephen Diverdi", "Aaron Hertzmann", "Feng Liu"], "abstract": "Creative professionals are creating Virtual Reality (VR) experiences today by capturing spherical videos, but video editing is still done primarily in traditional 2D desktop GUI applications such as Premiere. These interfaces provide limited capabilities for previewing content in a VR headset or for directly manipulating the spherical video in an intuitive way. As a result, editors must alternate between editing on the desktop and previewing in the headset, which is tedious and interrupts the creative process. We demonstrate an application that enables a user to directly edit spherical video while fully immersed in a VR headset. We first interviewed professional VR filmmakers to understand current practice and derived a suitable workflow for in-headset VR video editing. We then developed a prototype system implementing this new workflow. Our system is built upon a familiar timeline design, but is enhanced with custom widgets to enable intuitive editing of spherical video inside the headset. We conducted an expert review study and found that with our prototype, experts were able to edit videos entirely within the headset. Experts also found our interface and widgets useful, providing intuitive controls for their editing needs.                     References                 Natalia Bogdan, Tovi Grossman, and George Fitzmaurice. 2014. HybridSpace: Integrating 3D freehand input and stereo viewing into traditional desktop applications. In 2014 IEEE Symposium on 3D User Interfaces (3DUI). IEEE, 51--58.Google ScholarWutthigrai Boonsuk, Stephen Gilbert, and Jonathan Kelly. 2012. The impact of three interfaces for 360-degree video on spatial cognition. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems CHI '12. ACM Press, New York, New York, USA, 2579.  Google ScholarJessica Brillhart. 2016a. In the Blink of a Mind - Attention. (2016). https://medium.com/the-language-of-vr/in-the-blink-of-a-mind-attention-1fdff60fa045Google ScholarJessica Brillhart. 2016b. In the Blink of a Mind - Prologue. (2016). https://medium.com/the-language-of-vr/in-the-blink-of-a-mind-prologue-7864c0474a29Google ScholarKai-Yin Cheng, Sheng-Jie Luo, Bing-Yu Chen, and Hao-Hua Chu. 2009. SmartPlayer: User-Centric Video Fast-Forwarding. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems CHI '09. ACM Press, New York, New York, USA, 789.  Google ScholarAndy Cockburn, Amy Karlson, and Benjamin B. Bederson. 2008. A review of overview+detail, zooming, and focus+context interfaces. Comput. Surveys 41, 1 (dec 2008), 1--31.  Google ScholarKevin Fan, Liwei Chan, Daiya Kato, Kouta Minamizawa, and Masahiko Inami. 2016. VR Planet: Interface for Meta-View and Feet Interaction of VR Contents. In ACM SIGGRAPH 2016 VR Village on SIGGRAPH '16. ACM Press, New York, New York, USA, 1--2.  Google ScholarAjoy S. Fernandes and Steven K. Feiner. 2016. Combating VR sickness through subtle dynamic field-of-view modification. In 2016 IEEE Symposium on 3D User Interfaces (3DUI). IEEE, 201--210.Google ScholarDustin E. R. Freeman, Stephanie Santosa, Fanny Chevalier, Ravin Balakrishnan, and Karan Singh. 2014. LACES: Live Authoring through Compositing and Editing of Streaming Video. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems CHI '14. ACM Press, New York, New York, USA, 1207--1216.  Google ScholarEdwin L. Hutchins, James D. Hollan, and Donald A. Norman. 1985. Direct Manipulation Interfaces. Human-Computer Interaction 1, 4 (dec 1985), 311--338.  Google ScholarShunichi Kasahara and Jun Rekimoto. 2015. JackIn Head: Immersive Visual Telepresence System with Omnidirectional Wearable Camera for Remote Collaboration. In Proceedings of the 21st ACM Symposium on Virtual Reality Software and Technology VRST '15. ACM Press, New York, New York, USA, 217--225.  Google ScholarRobert S. Kennedy, Norman E. Lane, Kevin S. Berbaum, and Michael G. Lilienthal. 1993. Simulator sickness questionnaire: An enhanced method for quantifying simulator sickness. The international journal of aviation psychology 3, 3 (1993), 203--220.Google ScholarDon Kimber, Jonathan Foote, and Surapong Lertsithichai. 2001. FlyAbout: Spatially Indexed Panoramic Video. In Proceedings of the ninth ACM international conference on Multimedia - MULTIMEDIA '01. ACM Press, New York, New York, USA, 339.  Google ScholarEugenia M. Kolasinski. 1995. Simulator Sickness in Virtual Environments. Technical Report. DTIC Document.Google ScholarJohannes Kopf. 2016. 360 video stabilization: A new algorithm for smoother 360 video viewing. (2016). https://code.facebook.com/posts/697469023742261/360-video-stabilization-a-new-algorithm-for-smoother-360-video-viewing/Google ScholarOh-Hyun Kwon, Chris Muelder, Kyungwon Lee, and Kwan-Liu Ma. 2016. A Study of Layout, Rendering, and Interaction Methods for Immersive Graph Visualization. IEEE Transactions on Visualization and Computer Graphics 22, 7 (2016), 1802--1815.Google ScholarBruce D. Lucas and Takeo Kanade. 1981. An Iterative Image Registration Technique with an Application to Stereo Vision. In Proceedings of the 7th International Joint Conference on Artificial Intelligence - Volume 2 (IJCAI'81). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 674--679. http://dl.acm.org/citation.cfm?id=1623264.1623280 Google ScholarAlessandro Mulloni, Hartmut Seichter, Andreas D\u00fcnser, Patrick Baudisch, and Dieter Schmalstieg. 2012. 360\u00b0 panoramic overviews for location-based services. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems CHI '12. ACM Press, New York, New York, USA, 2565.  Google ScholarLu\u00eds a. R. Neng and Teresa Chambel. 2010. Get around 360\u00b0 hypervideo. In Proceedings of the 14th International Academic MindTrek Conference on Envisioning Future Media Environments - MindTrek '10. ACM Press, New York, New York, USA, 119.Google ScholarBenjamin Petry and Jochen Huber. 2015. Towards effective interaction with omnidirectional videos using immersive virtual reality headsets. In Proceedings of the 6th Augmented Human International Conference on - AH '15. ACM Press, New York, New York, USA, 217--218.  Google ScholarSuporn Pongnumkul, Jue Wang, and Michael Cohen. 2008. Creating map-based storyboards for browsing tour videos. In Proceedings of the 21st annual ACM symposium on User interface software and technology UIST '08. ACM, New York, NY, USA, 13--22.  Google ScholarGustavo Alberto Rovelo Ruiz, Davy Vanacken, Kris Luyten, Francisco Abad, and Emilio Camahort. 2014. Multi-viewer gesture-based interaction for omni-directional video. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems CHI '14. ACM Press, New York, New York, USA, 4077--4086.  Google ScholarJonas Schild, Liane B\u00f6licke, Joseph J. LaViola Jr., and Maic Masuch. 2013. Creating and analyzing stereoscopic 3D graphical user interfaces in digital games. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems CHI '13. ACM Press, New York, New York, USA, 169.  Google ScholarKlaus Schoeffmann, Marco A Hudelist, and Jochen Huber. 2015. Video Interaction Tools: A Survey of Recent Work. Comput. Surveys 48, 1 (sep 2015), 1--34.  Google ScholarHaijun Xia, Bruno Araujo, Tovi Grossman, and Daniel Wigdor. 2016. Object-Oriented Drawing. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems CHI '16. ACM Press, New York, New York, USA, 4610--4621.  Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3025453.3025675/66d7c5cf-973b-4fc1-88e4-8360ef668b14/pn2133p.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee07e5e64ad2301e1e02b6a6c2891a42e09fcc6c1c5943378b5c0db880f3cfa799fc5d967be12bd5f18c67e30e893abcd37e74897f5eb589019a39549141c4cf07513687e6424398ccapplication/x-mpegurlmp412.3 MB", "keywords": ["video editing", "virtual reality"], "published_in": "CHI '17: Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2017", "citations": "15", "isbn": "9781450346559", "doi": "10.1145/3025453", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3025453.3025675", "paper_url": "https://dl.acm.org/doi/10.1145/3025453.3025675"}, {"title": "SeeingVR: A Set of Tools to Make Virtual Reality More Accessible to People with Low Vision", "authors": ["Yuhang Zhao", "Edward Cutrell", "Christian Holz", "Meredith Ringel Morris", "Eyal Ofek", "Andrew D. Wilson"], "abstract": "Current virtual reality applications do not support people who have low vision, i.e., vision loss that falls short of complete blindness but is not correctable by glasses. We present SeeingVR, a set of 14 tools that enhance a VR application for people with low vision by providing visual and audio augmentations. A user can select, adjust, and combine different tools based on their preferences. Nine of our tools modify an existing VR application post hoc via a plugin without developer effort. The rest require simple inputs from developers using a Unity toolkit we created that allows integrating all 14 of our low vision support tools during development. Our evaluation with 11 participants with low vision showed that SeeingVR enabled users to better enjoy VR and complete tasks more quickly and accurately. Developers also found our Unity toolkit easy and convenient to use.                     References                 PF Adams and PM Barnes. 2006. Summary health statistics for the US population: National Health Interview Survey, 2004. National Center for Health Statistics 10, 229 (2006), 1--104.Google ScholarAndroid. 2018. Make apps more accessible | Android Developers. https://developer.android.com/guide/topics/ui/accessibility/apps Last accessed 21 December 2018.Google ScholarAmerican Optometric Association (AOA). 2018. Common Types of Low Vision. https://www.aoa.org/patients-and-public/ caring-for-your-vision/low-vision/common-types-of-low-vision last accessed 7 July 2015.Google ScholarApple. 2018. Vision Accessibility - iPhone. https://www.apple.com/ accessibility/iphone/vision/ Last accessed 21 December 2018.Google ScholarJoseph Bates. 1992. Virtual reality, art, and entertainment. Presence: Teleoperators &amp; Virtual Environments 1, 1 (1992), 133--138.Google ScholarDigital LibraryJeffrey P Bigham, Chandrika Jayant, Hanjie Ji, Greg Little, Andrew Miller, Robert C Miller, Robin Miller, Aubrey Tatarowicz, Brandyn White, Samual White, et al. 2010. VizWiz: nearly real-time answers to visual questions. In Proceedings of the 23nd annual ACM symposium on User interface software and technology. ACM, 333--342.  Google ScholarDigital LibraryJeffrey P Bigham, Ryan S Kaminsky, Richard E Ladner, Oscar M Danielsson, and Gordon L Hempton. 2006. WebInSight:: making web images accessible. In Proceedings of the 8th international ACM SIGACCESS conference on Computers and accessibility. ACM, 181--188.  Google ScholarDigital LibraryJeffrey P Bigham, Craig M Prince, and Richard E Ladner. 2008. WebAnywhere: a screen reader on-the-go. In Proceedings of the 2008 international cross-disciplinary conference on Web accessibility (W4A). ACM, 73--82.  Google ScholarDigital LibraryChetz Colwell, Helen Petrie, Diana Kornbrot, Andrew Hardwick, and Stephen Furner. 1998. Haptic virtual reality for blind computer users. In Proceedings of the third international ACM conference on Assistive technologies. ACM, 92--99.  Google ScholarDigital LibraryeSight. 2018. eSight Electronic Glasses. https://www.esighteyewear. com/homex last accessed 21 December 2018.Google ScholarEusth.2016. IllusionPluginArchitecture. https://github.com/Eusth/IPA Last accessed 21 December 2018.Google ScholarMR Everingham, BT Thomas, T Troscianko, et al. 1999. Head-mounted mobility aid for low vision using scene classification techniques. The International Journal of Virtual Reality 3, 4 (1999), 3.Google ScholarAmerican Foundation for the Blind (AFB). 2018. Screen Readers and Screen Magnifiers: An Introduction to Computer Accessibility Software. http://suo.im/5rv11hGoogle ScholarGearVR. 2018. GearVR Framework. http://www.gearvrf.org/ Last accessed 21 December 2018.Google ScholarJos\u00e9 Luis Gonz\u00e1lez-Mora, A Rodriguez-Hernandez, Enrique Burunat, F Martin, and Miguel A Castellano. 2006. Seeing the world by hearing: Virtual Acoustic Space (VAS) a new space perception system for blind people.. In Information and Communication Technologies, 2006. ICTTA'06. 2nd, Vol. 1. IEEE, 837--842.Google ScholarCross RefGoogle. 2018. Android accessibility overview - Android Accessibility Help. https://support.google.com/accessibility/android/answer/ 6006564?hl=en last accessed 21 December 2018.Google ScholarAnhong Guo, Jeeeun Kim, Xiang'Anthony' Chen, Tom Yeh, Scott E Hudson, Jennifer Mankoff, and Jeffrey P Bigham. 2017. Facade: Auto-generating tactile interfaces to appliances. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 5826--5838.  Google ScholarDigital LibraryStephen L Hicks, Iain Wilson, Louwai Muhammed, John Worsfold, Susan M Downes, and Christopher Kennard. 2013. A depth-based head-mounted visual display to aid navigation in partially sighted individuals. PloS one 8, 7 (2013), e67695.Google ScholarCross RefBill Holton. 2014. A Review of iOS Access for All: Your Comprehensive Guide to Accessibility for iPad, iPhone, and iPod Touch, by Shelly Brisbin. AccessWorld Magazine 15, 7 (2014), aw150706.Google ScholarAmy Hurst, Scott E Hudson, and Jennifer Mankoff. 2010. Automatically identifying targets users interact with during real world tasks. In Proceedings of the 15th international conference on Intelligent user interfaces. ACM, 11--20.  Google ScholarDigital LibraryChuck Huss and Anne Corn. 2004. Low Vision Driving with Bioptics: An Overview. Journal of Visual Impairment and Blindness 98, 10 (2004), 641--653.Google ScholarCross RefAlex D Hwang and Eli Peli. 2014. An augmented-reality edge enhancement application for Google Glass. Optometry and vision science: official publication of the American Academy of Optometry 91, 8 (2014), 1021.Google ScholarGunnar Jansson, H Petrie, C Colwell, D Kornbrot, J F\u00e4nger, H K\u00f6nig, K Billberger, Andrew Hardwick, and Stephen Furner. 1999. Haptic virtual environments for blind people: Exploratory experiments with two devices. International journal of virtual reality 4, 1 (1999), 10--20.Google ScholarKaterina Kalyvioti and Tassos A Mikropoulos. 2014. Virtual Environments and Dyslexia: A literature review. Procedia Computer Science 27 (2014), 138--147.Google ScholarCross RefShaun K Kane, Meredith Ringel Morris, and Jacob O Wobbrock. 2013. Touchplates: low-cost tactile overlays for visually impaired touch screen users. In Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility. ACM, 22.  Google ScholarDigital LibraryRichard L Kline and Ephraim P Glinert. 1995. Improving GUI accessibility for people with low vision. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM Press/Addison-Wesley Publishing Co., 114--121.  Google ScholarDigital LibraryAndreas Kunz, Klaus Miesenberger, Limin Zeng, and Gerhard Weber. 2018. Virtual Navigation Environment for Blind and Low Vision People. In International Conference on Computers Helping People with Special Needs. Springer, 114--122.Google ScholarOrly Lahav, Hadas Gedalevitz, Steven Battersby, David Brown, Lindsay Evett, and Patrick Merritt. 2018. Virtual environment navigation with look-around mode to explore new real spaces by people who are blind. Disability and rehabilitation 40, 9 (2018), 1072--1084.Google ScholarOrly Lahav and David Mioduser. 2001. Multisensory virtual environment for supporting blind persons' acquisition of spatial cognitive mapping--a case study. In EdMedia: World Conference on Educational Media and Technology. Association for the Advancement of Computing in Education (AACE), 1046--1051.Google ScholarBen Lang. 2018. Vive Pro Gets AR Capabilities Thanks to HTC's New Tools for Front-facing Cameras. http://suo.im/4PYzCi/. Last accessed 21 December 2018.Google ScholarMary Leach. 2013. Researchers Show Peripheral Prism Glasses to be a Simple, Inexpensive Rehabilitation Tool. https://www.masseyeandear. org/news/press-releases/2013/11/2013-prism-glasses last accessed 21 December 2018.Google ScholarAnatole L\u00e9cuyer, Pascal Mobuchon, Christine M\u00e9gard, J\u00e9r\u00f4me Perret, Claude Andriot, and J-P Colinot. 2003. HOMERE: a multimodal system for visually impaired people to explore virtual environments. In Virtual Reality, 2003. Proceedings. IEEE. IEEE, 251--258. Google ScholarDigital Librarylucassa3. 2018. EscapeVR-HarryPotter. https://github.com/lucassa3/ EscapeVR-HarryPotter Last accessed 21 December 2018.Google ScholarGang Luo and Eli Peli. 2006. Use of an augmented-vision device for visual search by patients with tunnel vision. Investigative ophthalmology &amp; visual science 47, 9 (2006), 4152--4159.Google ScholarMAGic. 2018. The best screen magnifier - MAGic. https: //www.freedomscientific.com/Products/LowVision/MAGic last accessed 21 December 2018.Google ScholarShachar Maidenbaum, Shelly Levy-Tzedek, Daniel-Robert Chebat, and Amir Amedi. 2013. Increasing accessibility to the blind of virtual environments, using a virtual mobility aid based on the\" EyeCane\": Feasibility study. PloS one 8, 8 (2013), e72555.Google ScholarCross RefJ Stephen Mansfield, Gordon E Legge, and Mark C Bane. 1996. Psychophysics of reading. XV: Font effects in normal and low vision. Investigative Ophthalmology &amp; Visual Science 37, 8 (1996), 1492--1501.Google ScholarTom H Margrain. 2000. Helping blind and partially sighted people to read: the effectiveness of low vision aids. British Journal of Ophthalmology 84, 8 (2000), 919--921.Google ScholarCross RefRobert W Massof and Douglas L Rickman. 1992. Obstacles encountered in the development of the low vision enhancement system. Optometry and vision science: official publication of the American Academy of Optometry 69, 1 (1992), 32--41.Google ScholarDavidMaulsby,SaulGreenberg,andRichardMander.1993. Prototyping an intelligent agent through Wizard of Oz. In Proceedings of the INTERACT'93 and CHI'93 conference on Human factors in computing systems. ACM, 277--284.  Google ScholarDigital LibraryZahira Merchant, Ernest T Goetz, Lauren Cifuentes, Wendy Keeney-Kennicutt, and Trina J Davis. 2014. Effectiveness of virtual reality-based instruction on students' learning outcomes in K-12 and higher education: A meta-analysis. Computers &amp; Education 70 (2014), 29--40.Google ScholarDigital LibraryMicrosoft. 2018. Cognitive Services | Microsoft Azure. https: //azure.microsoft.com/en-us/services/cognitive-services/?v=18.44b Last accessed 21 December 2018.Google ScholarMicrosoft. 2018. Hear text read aloud with Narrator. https://support. microsoft.com/en-us/help/17173/windows-10-hear-text-read-aloud Last accessed 21 December 2018.Google ScholarMicrosoft. 2018. Seeing AI | Talking camera app for those with a visual impairment. https://www.microsoft.com/en-us/seeing-ai last accessed 21 December 2018.Google ScholarPhil Parette and Marcia Scherer. 2004. Assistive technology use and stigma. Education and Training in Developmental Disabilities (2004), 217--226.Google ScholarEli Peli. 2001. Vision multiplexing: an engineering approach to vision rehabilitation device development. Optometry and Vision Science 78, 5 (2001), 304--315.Google ScholarCross RefLorenzo Picinali, Amandine Afonso, Michel Denis, and Brian FG Katz. 2014. Exploration of architectural spaces by blind people using auditory virtual reality for the construction of spatial knowledge. International Journal of Human-Computer Studies 72, 4 (2014), 393--407.  Google ScholarDigital LibrarySara Reardon. 2011. Playing by ear.Google ScholarMarti L Riemer-Reiss and Robbyn R Wacker. 2000. Factors associated with assistive technology discontinuance among individuals with disabilities. Journal of Rehabilitation 66, 3 (2000).Google ScholarJaime S\u00e1nchez and Mauricio Lumbreras. 1999. Virtual environment interaction through 3D audio by blind children. CyberPsychology &amp; Behavior 2, 2 (1999), 101--111.Google ScholarCross RefJH S\u00e1nchez and MA S\u00e1enz. 2006. Assisting the mobilization through subway networks by users with visual disabilities. In Proc. 6th Intl Conf. Disability, Virtual Reality &amp; Assoc. Tech., Esbjerg, Denmark. 183--190.Google ScholarDavid W Schloerb, Orly Lahav, Joseph G Desloge, and Mandayam A Srinivasan. 2010. BlindAid: Virtual environment system for self-reliant trip planning and orientation and mobility training. In Haptics Symposium, 2010 IEEE. IEEE, 363--370.  Google ScholarDigital LibraryLiz Segre. 2018. Low Vision Aids For Reading. https: //www.allaboutvision.com/lowvision/reading.htm Last accessed 21 December 2018.Google ScholarYoshikazu Seki and Tetsuji Sato. 2011. A training system of orientation and mobility for blind people using acoustic virtual reality. IEEE Transactions on neural systems and rehabilitation engineering 19, 1 (2011), 95--104.Google ScholarCross RefSK Semwal. 2001. MoVE: Mobiltiy training in haptic virtual environment. piglet. uccs. edu/? semwal/NSF2001PS. pdf (2001).Google ScholarKristen Shinohara and Jacob O Wobbrock. 2011. In the shadow of misperception: assistive technology use and social interactions. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 705--714.  Google ScholarDigital Librarysteamspy. 2018. SteamSpy - All the data and stats about Steam games. https://steamspy.com/tag/VR+Only Last accessed 21 December 2018.Google ScholarSarit Szpiro, Yuhang Zhao, and Shiri Azenkot. 2016. Finding a store, searching for a product: a study of daily challenges of low vision people. In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing. ACM, 61--72.  Google ScholarDigital LibrarySarit Felicia Anais Szpiro, Shafeka Hashash, Yuhang Zhao, and Shiri Azenkot. 2016. How people with low vision access computing devices: Understanding challenges and opportunities. In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility. ACM, 171--180.  Google ScholarDigital LibraryHironobu Takagi and Chieko Asakawa. 2000. Transcoding proxy for nonvisual web access. In Proceedings of the fourth international ACM conference on Assistive technologies. ACM, 164--171.  Google ScholarDigital LibraryMauro Te\u00f3filo, Vicente F Lucena, Josiane Nascimento, Taynah Miyagawa, and Francimar Maciel. 2018. Evaluating accessibility features designed for virtual reality context. In Consumer Electronics (ICCE), 2018 IEEE International Conference on. IEEE, 1--6.Google ScholarCross RefVirgil Tiponut, Zoltan Haraszy, Daniel Ianchis, and Ioan Lie. 2008. Acoustic virtual reality performing man-machine interfacing of the blind. In WSEAS International Conference. Proceedings. Mathematics and Computers in Science and Engineering. WSEAS. Google ScholarDigital LibraryMA Torres-Gil, O Casanova-Gonzalez, and Jos\u00e9 Luis Gonz\u00e1lez-Mora. 2010. Applications of virtual reality for visually impaired people. WSEAS transactions on computers 9, 2 (2010), 184--193. Google ScholarDigital LibraryShari Trewin, Vicki L Hanson, Mark R Laff, and Anna Cavender. 2008. PowerUp: an accessible virtual world. In Proceedings of the 10th international ACM SIGACCESS conference on Computers and accessibility. ACM, 177--184.  Google ScholarDigital LibraryShari Trewin, Mark Laff, Vicki Hanson, and Anna Cavender. 2009. Exploring visual and motor accessibility in navigating a virtual world. ACM Transactions on Accessible Computing (TACCESS) 2, 2 (2009), 11.  Google ScholarDigital LibraryDimitrios Tzovaras, Konstantinos Moustakas, Georgios Nikolakis, and Michael G Strintzis. 2009. Interactive mixed reality white cane simulation for the training of the blind and the visually impaired. Personal and Ubiquitous Computing 13, 1 (2009), 51--58.  Google ScholarDigital LibraryDimitrios Tzovaras, Georgios Nikolakis, George Fergadis, Stratos Malasiotis, and Modestos Stavrakis. 2002. Design and implementation of virtual environments training of the visually impaire. In Proceedings of the fifth international ACM conference on Assistive technologies. ACM, 41--48.  Google ScholarDigital LibraryUnity. 2016. Edge Detection - Unity. https://docs.unity3d.com/540/ Documentation/Manual/script-EdgeDetectEffect.html Last accessed 21 December 2018.Google ScholarUnity. 2018. Game Objects and Components - Unity. https://unity3d.com/learn/tutorials/topics/interface-essentials/ game-objects-and-components Last accessed 21 December 2018.Google ScholarFernando Vargas-Mart\u00edn and Eli Peli. 2001. P-16: Augmented View for Tunnel Vision: Device Testing by Patients in Real Environments. In SID Symposium Digest of Technical Papers, Vol. 32. Wiley Online Library, 602--605.Google ScholarCross RefVENTUREBEAT. 2017. 59% of VR Developers Use Unity, But Devs Make More Money With Unreal. https://uploadvr.com/ vr-developers-unity-unreal/ Last accessed 21 December 2018.Google ScholarMaria Virvou and George Katsionis. 2008. On the usability and likeability of virtual reality games for education: The case of VR-ENGAGE. Computers &amp; Education 50, 1 (2008), 154--178.  Google ScholarDigital LibraryW3C. 2018. Contrast (Minimum): Understanding Success Criterion 1.4.3. https://www.w3.org/TR/UNDERSTANDING-WCAG20/ visual-audio-contrast-contrast.html Last accessed 21 December 2018.Google ScholarW3C. 2018. Web Content Accessibility Guidelines (WCAG) Overview. https://www.w3.org/WAI/standards-guidelines/wcag/ Last accessed 21 December 2018.Google ScholarWebAIM. 2017. Designing for Screen Reader Compatibility. https:// webaim.org/techniques/screenreader/ Last accessed 21 December 2018.Google ScholarJason Weimann. 2016. Using the Valves - Lab Renderer for VR. https://unity3d.college/2016/08/02/using-valves-lab-renderer-vr/ Last accessed 21 December 2018.Google ScholarWorld Health Organization (WHO). 2018. Blindness and Vision Impairment. https://www.who.int/news-room/fact-sheets/detail/ blindness-and-visual-impairment Last accessed 21 December 2018.Google ScholarPaul N Wilson, Nigel Foreman, and Dana\u00eb Stanton. 1997. Virtual reality, disability and rehabilitation. Disability and rehabilitation 19, 6 (1997), 213--220.Google ScholarJames S Wolffsohn and Rachael C Peterson. 2003. A review of current knowledge on Electronic Vision Enhancement Systems for the visually impaired. Ophthalmic and Physiological Optics 23, 1 (2003), 35--42.Google ScholarCross RefAlice Wong, Hannah Gillis, and Ben Peck. 2018. VR Accessibility Survey: Survey for People with Disabilities. https://drive.google.com/ file/d/0B0VwTVwReMqLMFIzdzVVaVdaTFk/view Last accessed 21 December 2018.Google ScholarXiaoyi Zhang, Anne Spencer Ross, Anat Caspi, James Fogarty, and Jacob O Wobbrock. 2017. Interaction Proxies for Runtime Repair and Enhancement of Mobile Application Accessibility. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 6024--6037.  Google ScholarDigital LibraryXiaoyi Zhang, Tracy Tran, Yuqian Sun, Ian Culhane, Shobhit Jain, James Fogarty, and Jennifer Mankoff. 2018. Interactiles: 3D Printed Tactile Interfaces to Enhance Mobile Touchscreen Accessibility. In Proceedings of the 20th International ACM SIGACCESS Conference on Computers and Accessibility. ACM, 131--142.  Google ScholarDigital LibraryYuhang Zhao, Cynthia L Bennett, Hrvoje Benko, Edward Cutrell, Christian Holz, Meredith Ringel Morris, and Mike Sinclair. 2018. Enabling People with Visual Impairments to Navigate Virtual Reality with a Haptic and Auditory Cane Simulation. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 116.  Google ScholarDigital LibraryYuhang Zhao, Michele Hu, Shafeka Hashash, and Shiri Azenkot. 2017. Understanding Low Vision People's Visual Perception on Commercial Augmented Reality Glasses. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 4170--4181.  Google ScholarDigital LibraryYuhang Zhao, Sarit Szpiro, and Shiri Azenkot. 2015. Foresee: A customizable head-mounted vision enhancement system for people withlowvision.InProceedingsofthe17thInternationalACMSIGACCESS Conference on Computers &amp; Accessibility. ACM, 239--249.  Google ScholarDigital LibraryYuhang Zhao, Sarit Szpiro, Jonathan Knighten, and Shiri Azenkot. 2016. CueSee: exploring visual cues for people with low vision to facilitate a visual search task. In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing. ACM, 73--84.  Google ScholarDigital LibraryFeng Zhou, Henry Been-Lirn Duh, and Mark Billinghurst. 2008. Trends in augmented reality tracking, interaction and display: A review of ten years of ISMAR. In Proceedings of the 7th IEEE/ACM International Symposium on Mixed and Augmented Reality. IEEE Computer Society, 193--202.  Google ScholarDigital LibraryMichael Zyda. 2005. From visual simulation to virtual reality to games. Computer 38, 9 (2005), 25--32.  Google ScholarDigital LibrarySupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3290605.3300341/7c18b50d-30ef-42f7-9706-cacfe7e3b2ba/paper111.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee05eee35a4ac3e15fa134b9c42a1c9e32aa5e2ed32eca1ef897f37a8038975507c36d479d51eff0084921a545efa8b6760fe60e0c785597acd5f5039cc0afcdc1399e8d92d45dd153application/x-mpegurlmp484.3 MB", "keywords": ["unity", "accessibility", "low vision", "virtual reality"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "10", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300341", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300341"}, {"title": "Assessing the Accuracy of Point &amp; Teleport Locomotion with Orientation Indication for Virtual Reality using Curved Trajectories", "authors": ["Markus Funk", "Florian M\u00fcller", "Marco Fendrich", "Megan Shene", "Moritz Kolvenbach", "Niclas Dobbertin", "Sebastian G\u00fcnther", "Max M\u00fchlh\u00e4user"], "abstract": "Room-scale Virtual Reality (VR) systems have arrived in users' homes where tracked environments are set up in limited physical spaces. As most Virtual Environments (VEs) are larger than the tracked physical space, locomotion techniques are used to navigate in VEs. Currently, in recent VR games, point &amp; teleport is the most popular locomotion technique. However, it only allows users to select the position of the teleportation and not the orientation that the user is facing after the teleport. This results in users having to manually correct their orientation after teleporting and possibly getting entangled by the cable of the headset. In this paper, we introduce and evaluate three different point &amp; teleport techniques that enable users to specify the target orientation while teleporting. The results show that, although the three teleportation techniques with orientation indication increase the average teleportation time, they lead to a decreased need for correcting the orientation after teleportation.                     References                 Jonas Auda, Max Pascher, and Stefan Schneegass. 2019. Around the (Virtual) World: Infinite Walking in Virtual Reality Using Electrical Muscle Stimulation. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM.  Google ScholarDigital LibraryMahdi Azmandian, Mark Hancock, Hrvoje Benko, Eyal Ofek, and Andrew D Wilson. 2016. Haptic retargeting: Dynamic repurposing of passive haptics for enhanced virtual reality experiences. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM, 1968--1979.  Google ScholarDigital LibraryNiels H Bakker, Peter O Passenier, and Peter J Werkhoven. 2003. Effects of head-slaved navigation and the use of teleports on spatial orientation in virtual environments. Human factors 45, 1 (2003), 160--169.Google ScholarLaurenz Berger and Katrin Wolf. 2018. WIM: Fast Locomotion in Virtual Reality with Spatial Orientation Gain &amp; without Motion Sickness. In Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia. ACM, 19--24.  Google ScholarDigital LibraryJiwan Bhandari, Paul MacNeilage, and Eelke Folmer. 2018. Teleportation without Spatial Disorientation Using Optical Flow Cues. In Proceedings of Graphics Interface 2018 (GI 2018). Canadian HumanComputer Communications Society / Soci\u00e9t\u00e9 canadienne du dialogue humain-machine, 162 -- 167.Google ScholarFrank Biocca, Arthur Tang, Charles Owen, and Fan Xiao. 2006. Attention funnel: omnidirectional 3D cursor for mobile augmented reality platforms. In Proceedings of the SIGCHI conference on Human Factors in computing systems. ACM, 1115--1122.  Google ScholarDigital LibraryCostas Boletsis. 2017. The New Era of Virtual Reality Locomotion: A Systematic Literature Review of Techniques and a Proposed Typology. Multimodal Technologies and Interaction 1, 4 (2017), 24.Google ScholarCross RefBenjamin Bolte, Frank Steinicke, and Gerd Bruder. 2011. The jumper metaphor: an effective navigation technique for immersive display setups. In Proceedings of Virtual Reality International Conference.Google ScholarLaroussi Bouguila, Florian Evequoz, Michele Courant, and Beat Hirsbrunner. 2004. Walking-pad: a step-in-place locomotion interface for virtual environments. In Proceedings of the 6th international conference on Multimodal interfaces. ACM, 77--81.  Google ScholarDigital LibraryDoug A Bowman, David Koller, and Larry F Hodges. 1997. Travel in immersive virtual environments: An evaluation of viewpoint motion control techniques. In Virtual Reality Annual International Symposium, 1997., IEEE 1997. IEEE, 45--52. Google ScholarDigital LibraryEvren Bozgeyikli, Andrew Raij, Srinivas Katkoori, and Rajiv Dubey. 2016. Point &amp; teleport locomotion technique for virtual reality. In Proceedings of the 2016 Annual Symposium on Computer-Human Interaction in Play. ACM, 205--216. Point &amp; Teleport with Orientation Indication CHI 2019, May 4--9, 2019, Glasgow, Scotland Uk  Google ScholarDigital LibraryCarmine Elvezio, Mengu Sukan, Steven Feiner, and Barbara Tversky. 2017. Travel in large-scale head-worn vr: Pre-oriented teleportation with wims and previews. In 2017 IEEE Virtual Reality (VR). IEEE, 475-- 476.Google ScholarSebastian Freitag, Dominik Rausch, and Torsten Kuhlen. 2014. Reorientation in virtual environments using interactive portals. In 3D User Interfaces (3DUI), 2014 IEEE Symposium on. IEEE, 119--122.Google ScholarJulian Frommel, Sven Sonntag, and Michael Weber. 2017. Effects of controller-based locomotion on player experience in a virtual reality exploration game. In Proceedings of the 12th International Conference on the Foundations of Digital Games. ACM, 30.  Google ScholarDigital LibrarySandra G Hart and Lowell E Staveland. 1988. Development of NASATLX (Task Load Index): Results of empirical and theoretical research. In Advances in psychology. Vol. 52. Elsevier, 139--183.Google ScholarAnuruddha Hettiarachchi and Daniel Wigdor. 2016. Annexing reality: Enabling opportunistic use of everyday objects as tangible proxies in augmented reality. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM, 1957--1967.  Google ScholarDigital LibraryJohn M Hollerbach. 2002. Locomotion interfaces. Handbook of virtual environments: Design, implementation, and applications (2002), 239-- 254.Google ScholarHiroo Iwata. 1999. Walking about virtual environments on an infinite floor. In Virtual Reality, 1999. Proceedings., IEEE. IEEE, 286--293. Google ScholarDigital LibraryHiroo Iwata, Hiroaki Yano, Hiroyuki Fukushima, and Haruo Noma. 2005. Circulafloor {locomotion interface}. IEEE Computer Graphics and Applications 25, 1 (2005), 64--67.  Google ScholarDigital LibraryHiroo Iwata, Hiroaki Yano, and Hiroshi Tomioka. 2006. Powered shoes. In ACM SIGGRAPH 2006 Emerging technologies. ACM, 28.  Google ScholarDigital LibraryBeverly K Jaeger and Ronald R Mourant. 2001. Comparison of simulator sickness using static and dynamic walking simulators. In Proceedings of the Human Factors and Ergonomics Society Annual Meeting, Vol. 45. SAGE Publications Sage CA: Los Angeles, CA, 1896--1900.Google ScholarCross RefJi-Sun Kim, Denis Gracanin, Kresimir Matkovic, and Francis Quek. 2008. Finger walking in place (FWIP): A traveling technique in virtual environments. In International Symposium on Smart Graphics. Springer, 58--69.  Google ScholarDigital LibraryAlexandra Kitson, Abraham M Hashemian, Ekaterina R Stepanova, Ernst Kruijff, and Bernhard E Riecke. 2017. Comparing leaning-based motion cueing interfaces for virtual reality locomotion. In 3D User Interfaces (3DUI), 2017 IEEE Symposium on. IEEE, 73--82.Google ScholarEike Langbehn, Paul Lubos, Gerd Bruder, and Frank Steinicke. 2017. Bending the curve: Sensitivity to bending of curved paths and application in room-scale vr. IEEE transactions on visualization and computer graphics 23, 4 (2017), 1389--1398.  Google ScholarDigital LibraryJoseph J LaViola Jr. 2000. A discussion of cybersickness in virtual environments. ACM SIGCHI Bulletin 32, 1 (2000), 47--56.  Google ScholarDigital LibraryJames Liu, Hirav Parekh, Majed Al-Zayer, and Eelke Folmer. 2018. Increasing Walking in VR using Redirected Teleportation. In Proceedings of the 31th Annual ACM Symposium on User Interface Software and Technology (UIST '18).  Google ScholarDigital LibraryGerard Llorach, Alun Evans, and Josep Blat. 2014. Simulator sickness and presence using HMDs: comparing use of a game controller and a position estimation system. In Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology. ACM, 137--140.  Google ScholarDigital LibraryThomas Nescher, Ying-Yin Huang, and Andreas Kunz. 2014. Planning redirection techniques for optimal free walking experience using model predictive control. In 3D User Interfaces (3DUI), 2014 IEEE Symposium on. IEEE, 111--118.Google ScholarNiels Christian Nilsson, Tabitha Peck, Gerd Bruder, Eri Hodgson, Stefania Serafin, Mary Whitton, Frank Steinicke, and Evan Suma Rosenberg. 2018. 15 Years of Research on Redirected Walking in Immersive Virtual Environments. IEEE computer graphics and applications 38, 2 (2018), 44--56.  Google ScholarDigital LibraryNiels C Nilsson, Stefania Serafin, Morten H Laursen, Kasper S Pedersen, Erik Sikstrom, and Rolf Nordahl. 2013. Tapping-in-place: Increasing the naturalness of immersive walking-in-place locomotion through novel gestural input. In 2013 IEEE Symposium on 3D User Interfaces (3DUI). IEEE, 31--38.Google ScholarCross RefSharif Razzaque, Zachariah Kohn, and Mary C Whitton. 2001. Redirected walking. In Proceedings of EUROGRAPHICS, Vol. 9. 105--106.Google ScholarBhuvaneswari Sarupuri, Miriam Luque Chipana, and Robert W Lindeman. 2017. Trigger walking: A low-fatigue travel technique for immersive virtual reality. In 3D User Interfaces (3DUI), 2017 IEEE Symposium on. IEEE, 227--228.Google ScholarMel Slater, Martin Usoh, and Anthony Steed. 1995. Taking steps: the influence of a walking technique on presence in virtual reality. ACM Transactions on Computer-Human Interaction (TOCHI) 2, 3 (1995), 201--219.  Google ScholarDigital LibraryFrank Steinicke, Gerd Bruder, Jason Jerald, Harald Frenz, and Markus Lappe. 2010. Estimation of detection thresholds for redirected walking techniques. IEEE transactions on visualization and computer graphics 16, 1 (2010), 17--27.  Google ScholarDigital LibraryFrank Steinicke, Yon Visell, Jennifer Campos, and Anatole L\u00e9cuyer. 2013. Human walking in virtual environments. Springer. Google ScholarDigital LibraryRichard Stoakley, Matthew J Conway, and Randy Pausch. 1995. Virtual reality on a WIM: interactive worlds in miniature. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM Press/Addison-Wesley Publishing Co., 265--272.  Google ScholarDigital LibraryEvan A Suma, Mahdi Azmandian, Timofey Grechkin, Thai Phan, and Mark Bolas. 2015. Making small spaces feel large: infinite walking in virtual reality. In ACM SIGGRAPH 2015 Emerging Technologies. ACM, 16.  Google ScholarDigital LibraryEvan A Suma, Zachary Lipps, Samantha Finkelstein, David M Krum, and Mark Bolas. 2012. Impossible spaces: Maximizing natural walking in virtual environments with self-overlapping architecture. IEEE Transactions on Visualization and Computer Graphics 18, 4 (2012), 555--564.  Google ScholarDigital LibraryJames N Templeman, Patricia S Denbrook, and Linda E Sibert. 1999. Virtual locomotion: Walking in place through virtual environments. Presence 8, 6 (1999), 598--617.  Google ScholarDigital LibraryMartin Usoh, Kevin Arthur, Mary C Whitton, Rui Bastos, Anthony Steed, Mel Slater, and Frederick P Brooks Jr. 1999. Walking&amp;gt; walkingin-place&amp;gt; flying, in virtual environments. In Proceedings of the 26th annual conference on Computer graphics and interactive techniques. ACM Press/Addison-Wesley Publishing Co., 359--364.  Google ScholarDigital LibraryKhrystyna Vasylevska, Hannes Kaufmann, Mark Bolas, and Evan A Suma. 2013. Flexible spaces: Dynamic layout generation for infinite walking in virtual environments. In 3D user interfaces (3DUI), 2013 IEEE Symposium on. IEEE, 39--42. CHI 2019, May 4--9, 2019, Glasgow, Scotland Uk Funk et al.Google ScholarMary C Whitton, Joseph V Cohn, Jeff Feasel, Paul Zimmons, Sharif Razzaque, Sarah J Poulton, Brandi McLeod, and Frederick P Brooks. 2005. Comparing VE locomotion interfaces. In Virtual Reality, 2005. Proceedings. VR 2005. IEEE. IEEE, 123--130.  Google ScholarDigital LibraryBetsy Williams, Gayathri Narasimham, Bjoern Rump, Timothy P McNamara, Thomas H Carr, John Rieser, and Bobby Bodenheimer. 2007. Exploring large virtual environments with an HMD when physical space is limited. In Proceedings of the 4th symposium on Applied perception in graphics and visualization. ACM, 41--48.  Google ScholarDigital LibraryGraham Wilson, Mark McGill, Matthew Jamieson, Julie R Williamson, and Stephen A Brewster. 2018. Object Manipulation in Virtual Reality Under Increasing Levels of Translational Gain. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 99.  Google ScholarDigital LibraryChadwick A Wingrave, Yonca Haciahmetoglu, and Doug A Bowman. 2006. Overcoming world in miniature limitations by a scaled and scrolling WIM. In 3D User Interfaces, 2006. 3DUI 2006. IEEE Symposium on. IEEE, 11--16.  Google ScholarDigital LibraryMengxin Xu, Mar\u00eda Murcia-L\u00f3pez, and Anthony Steed. 2017. Object location memory error in virtual and real environments. In Virtual Reality (VR), 2017 IEEE. IEEE, 315--316.Google ScholarZhixin Yan, Robert W Lindeman, and Arindam Dey. 2016. Let your fingers do the walking: A unified approach for efficient short-, medium, and long-distance travel in VR. In 3D User Interfaces (3DUI), 2016 IEEE Symposium on. IEEE, 27--30.Google ScholarRun Yu, Wallace S Lages, Mahdi Nabiyouni, Brandon Ray, Navyaram Kondur, Vikram Chandrashekar, and Doug A Bowman. 2017. Bookshelf and Bird: Enabling real walking in large VR spaces. In 3D User Interfaces (3DUI), 2017 IEEE Symposium on. IEEE, 116--119.Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3290605.3300377/09125230-104e-4876-a494-2ceeb0609767/paper147.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee05eee35a4ac3e15fa134b9c4291a9e35f05e24cac1d4b92f4ea74f242d1bd9dee1610e6a9bb83d5b207e2fc62e723e9f19b9900d2ce9f9387a255c4263314390db8972bacc8417bbapplication/x-mpegurlmp476.2 MB", "keywords": ["orientation indication", "locomotion", "teleportation", "point & teleport", "virtual environments", "virtual reality"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "6", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300377", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300377"}, {"title": "TORC: A Virtual Reality Controller for In-Hand High-Dexterity Finger Interaction", "authors": ["Jaeyeon Lee", "Mike Sinclair", "Mar Gonzalez-Franco", "Eyal Ofek", "Christian Holz"], "abstract": "Recent hand-held controllers have explored a variety of haptic feedback sensations for users in virtual reality by producing both kinesthetic and cutaneous feedback from virtual objects. These controllers are grounded to the user's hand and can only manipulate objects through arm and wrist motions, not using the dexterity of their fingers as they would in real life. In this paper, we present TORC, a rigid haptic controller that renders virtual object characteristics and behaviors such as texture and compliance. Users hold and squeeze TORC using their thumb and two fingers and interact with virtual objects by sliding their thumb on TORC's trackpad. During the interaction, vibrotactile motors produce sensations to each finger that represent the haptic feel of squeezing, shearing or turning an object. Our evaluation showed that using TORC, participants could manipulate virtual objects more precisely (e.g., position and rotate objects in 3D) than when using a conventional VR controller.                     References                 Parastoo Abtahi and Sean Follmer. 2018. Visuo-Haptic Illusions for Improving the Perceived Performance of Shape Displays. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI '18. ACM Press, New York, New York, USA, 1--13.  Google ScholarDigital LibraryMerwan Achibet, Maud Marchal, Ferran Argelaguet, and Anatole Lecuyer. 2014. The Virtual Mitten: A novel interaction paradigm for visuo-haptic manipulation of objects using grip force. In 2014 IEEE Symposium on 3D User Interfaces (3DUI). IEEE, 59--66.Google ScholarCross RefMichael J Adams, Simon A Johnson, Philippe Lef\u00e8vre, Vincent L\u00e9vesque, Vincent Hayward, Thibaut Andr\u00e9, and Jean-Louis Thonnard. 2013. Finger pad friction and its role in grip and touch. Journal of The Royal Society Interface 10, 80 (3 2013).Google ScholarCross RefFerran Argelaguet, David Antonio G\u00c3mez J\u00e1uregui, Maud Marchal, and Anatole L\u00e9cuyer. 2013. Elastic images: Perceiving local elasticity of images through a novel pseudo-haptic deformation effect. ACM Transactions on Applied Perception (TAP) 10, 3 (2013), 17.  Google ScholarDigital LibraryHrvoje Benko, Christian Holz, Mike Sinclair, and Eyal Ofek. 2016. NormalTouch and TextureTouch: High-fidelity 3D Haptic Shape Rendering on Handheld Virtual Reality Controllers. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST '16). ACM, New York, 717--728.  Google ScholarDigital LibraryChristopher C Berger and Mar Gonzalez-Franco. 2018. Expanding the Sense of Touch Outside the Body. In Proceedings of the 15th ACM Symposium on Applied Perception, Vol. SAP '18. ACM, Vancouver, 10:1-- 10:9.  Google ScholarDigital LibraryChristopher C Berger, Mar Gonzalez-Franco, Eyal Ofek, and Ken Hinckley. 2018. The uncanny valley of haptics. Science Robotics 3, 17 (4 2018).Google ScholarRay Bittner and Mike Sinclair. 2009. VersaPatch: A Low Cost 2.5D Capacitive Touch Sensor. Springer, Berlin, Heidelberg, 407--416.Google ScholarConrad Bullion and Hakan Gurocak. 2009. Haptic Glove with MR Brakes for Distributed Finger Force Feedback. Presence: Teleoperators and Virtual Environments 18, 6 (12 2009), 421--433.  Google ScholarDigital LibraryFrancesco Chinello, Claudio Pacchierotti, Monica Malvezzi, and Domenico Prattichizzo. 2018. A Three Revolute-Revolute-Spherical Wearable Fingertip Cutaneous Device for Stiffness Rendering. IEEE Transactions on Haptics 11, 1 (1 2018), 39--50.Google ScholarCross RefInrak Choi, Heather Culbertson, Mark R. Miller, Alex Olwal, and Sean Follmer. 2017. Grabity: A Wearable Haptic Interface for Simulating Weight and Grasping in Virtual Reality. In Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology (UIST '17). ACM, New York, 119--130.  Google ScholarDigital LibraryInrak Choi, Elliot W. Hawkes, David L. Christensen, Christopher J. Ploch, and Sean Follmer. 2016. Wolverine: A wearable haptic interface for grasping in virtual reality. In 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 986--993.Google ScholarCross RefInrak Choi, Eyal Ofek, Hrvoje Benko, Mike Sinclair, and Christian Holz. 2018. CLAW: A Multifunctional Handheld Haptic Controller for Grasping, Touching, and Triggering in Virtual Reality. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI '18. ACM Press, New York, New York, USA, 1--13.  Google ScholarDigital LibraryH. Culbertson and K. J. Kuchenbecker. 2015. Should haptic texture vibrations respond to user force and speed?. In 2015 IEEE World Haptics Conference (WHC). 106--112.Google ScholarH. Culbertson, J. Unwin, and K. J. Kuchenbecker. 2014. Modeling and Rendering Realistic Textures from Unconstrained Tool-Surface Interactions. IEEE Transactions on Haptics 7, 3 (7 2014), 381--393.Google ScholarCross RefMark R Cutkosky. 1989. On grasp choice, grasp models, and the design of hands for manufacturing tasks. IEEE Transactions on robotics and automation 5, 3 (1989), 269--279.Google ScholarCross RefRavin de Souza, Sahar El-Khoury, Jos Santos-Victor, and Aude Billard. 2015. Recognizing the grasp intention from human demonstration. Robotics and Autonomous Systems 74, PA (12 2015), 108--121.  Google ScholarDigital LibraryBrian Dellon and Yoky Matsuoka. 2007. Prosthetics, exoskeletons, and rehabilitation {grand challenges of robotics}. IEEE robotics &amp; automation magazine 14, 1 (2007), 30--34.Google ScholarL. Dominjon, A. Lecuyer, J. Burkhardt, P. Richard, and S. Richir. 2005. Influence of control/display ratio on the perception of mass of manipulated objects in virtual environments. In IEEE Proceedings. VR 2005. Virtual Reality, 2005. IEEE, 19--318.  Google ScholarDigital LibraryThomas Feix, Javier Romero, Heinz-Bodo Schmiedmayer, Aaron M. Dollar, and Danica Kragic. 2016. The GRASP Taxonomy of Human Grasp Types. IEEE Transactions on Human-Machine Systems 46, 1 (2 2016), 66--77.Google ScholarCross RefMar Gonzalez-Franco and Jaron Lanier. 2017. Model of Illusions and Virtual Reality., 1125 pages.Google ScholarMar Gonzalez-Franco, Antonella Maselli, DInei Florencio, Nikolai Smolyanskiy, and Zhengyou Zhang. 2017. Concurrent talking in immersive virtual reality: On the dominance of visual speech cues. Scientific Reports (2017).Google ScholarMar Gonzalez-Franco and Tabitha C. Peck. 2018. Avatar Embodiment. Towards a Standardized Questionnaire. Frontiers in Robotics and AI 5 (6 2018), 74.Google ScholarXiaochi Gu, Yifei Zhang, Weize Sun, Yuanzhe Bian, Dao Zhou, and Per Ola Kristensson. 2016. Dexmo: An Inexpensive and Lightweight Mechanical Exoskeleton for Motion Capture and Force Feedback in VR. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI '16). ACM, New York, 1991-1995.  Google ScholarDigital LibrarySeongkook Heo and Geehyuk Lee. 2017. Vibrotactile Compliance Feedback for Tangential Force Interaction. IEEE Transactions on Haptics 10, 3 (7 2017), 444--455.Google ScholarCross RefRonan Hinchet, Velko Vechev, Herbert Shea, and Otmar Hilliges. 2018. DextrES. In The 31st Annual ACM Symposium on User Interface Software and Technology - UIST '18. ACM Press, New York, New York, USA, 901-- 912.  Google ScholarDigital LibraryHyunKi In, Kyu-Jin Cho, KyuRi Kim, and BumSuk Lee. 2011. Jointless structure and under-actuation mechanism for compact hand exoskeleton. In 2011 IEEE International Conference on Rehabilitation Robotics. IEEE, 1--6.Google ScholarHyunki In, Brian Byunghyun Kang, MinKi Sin, and Kyu-Jin Cho. 2015. Exo-Glove: A Wearable Robot for the Hand with a Soft Tendon Routing System. IEEE Robotics &amp; Automation Magazine 22, 1 (3 2015), 97--105.Google ScholarCross RefJohan Kildal. 2011. Tangible 3D Haptics on Touch Surfaces: Virtual Compliance. In CHI '11 Extended Abstracts on Human Factors in Computing Systems (CHI EA '11). ACM, New York, 1123--1128.  Google ScholarDigital LibraryJohan Kildal. 2012. Kooboh: Variable Tangible Properties in a Handheld Haptic-Illusion Box. Springer, Berlin, Heidelberg, 191--194.  Google ScholarDigital LibraryHwan Kim, HyeonBeom Yi, Hyein Lee, and Woohun Lee. 2018. HapCube: A Wearable Tactile Device to Provide Tangential and Normal Pseudo-Force Feedback on a Fingertip. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, 1--501.  Google ScholarDigital LibrarySunjun Kim and Geehyuk Lee. 2013. Haptic feedback design for a virtual button along force-displacement curves. In Proceedings of the 26th annual ACM symposium on User interface software and technology - UIST '13. ACM Press, New York, New York, USA, 91--96.  Google ScholarDigital LibrarySeung-Chan Kim, Chong Hui Kim, Tae-Hon Yang, Gi-Hun Yang, SungChul Kang, and Dong-Soo Kwon. 2008. SaLT: Small and lightweight tactile display using ultrasonic actuators. In RO-MAN 2008 - The 17th IEEE International Symposium on Robot and Human Interactive Communication. IEEE, 430--435.Google ScholarYeongmi Kim, Ian Oakley, and Jeha Ryu. 2014. Combining Point Force Haptic and Pneumatic Tactile Displays LAMS: Location Aware Multimedia Storytelling View project YouGrabber View project Combining Point Force Haptic and Pneumatic Tactile Displays. Technical Report. https://www.researchgate.net/publication/252603525Google ScholarRoberta L. Klatzky and Susan Lederman. 1990. Intelligent Exploration by the Human Hand. In Dextrous Robot Hands. Springer New York, New York, NY, 66--81. Google ScholarDigital LibraryInwook Koo, Brian Byunghyun Kang, and Kyu-Jin Cho. 2013. Development of Hand Exoskeleton using Pneumatic Artificial Muscle Combined with Linkage. Journal of the Korean Society for Precision Engineering 30, 11 (11 2013), 1217--1224.Google ScholarCross RefAnatole L\u00e9cuyer. 2009. Simulating Haptic Feedback Using Vision: A Survey of Research and Applications of Pseudo-Haptic Feedback. Presence: Teleoperators and Virtual Environments 18, 1 (2 2009), 39--53.  Google ScholarDigital LibraryAnatole Lecuyer. 2017. Playing with Senses in VR: Alternate Perceptions Combining Vision and Touch. IEEE Computer Graphics and Applications 37, 1 (2017), 20--26.Google ScholarDigital LibraryAnatole L\u00e9cuyer, Jean-Marie Burkhardt, and Laurent Etienne. 2004. Feeling bumps and holes without a haptic interface. In Proceedings of the 2004 conference on Human factors in computing systems - CHI '04. ACM Press, New York, New York, USA, 239--246.  Google ScholarDigital LibraryA. Lecuyer, S. Coquillart, A. Kheddar, P. Richard, and P. Coiffet. 2000. Pseudo-haptic feedback: can isometric input devices simulate force feedback?. In Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048). IEEE Comput. Soc, 83--90. Google ScholarDigital LibrarySusan J. Lederman and Lynette A. Jones. 2011. Tactile and Haptic Illusions. IEEE Transactions on Haptics 4, 4 (10 2011), 273--294.  Google ScholarDigital LibraryChristine L MacKenzie and Thea Iberall. 1994. The grasping hand. Vol. 104. Elsevier.Google ScholarKouta Minamizawa, Souichiro Fukamachi, Hiroyuki Kajimoto, Naoki Kawakami, and Susumu Tachi. 2007. Gravity grabber: wearable haptic display to present virtual mass sensation. ACM SIGGRAPH 2007 emerging technologies (2007), 8.  Google ScholarDigital LibraryA.M. Okamura, N. Smaby, and M.R. Cutkosky. 2000. An overview of dexterous manipulation. In Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), Vol. 1. IEEE, 255--262.Google ScholarCross RefGeorge L Peterson and Thomas C Brown. 1998. Economic Valuation by the Method of Paired Comparison, with Emphasis on Evaluation of the Transitivity Axiom. Land Economics 74(2), May (1998), 240--261.Google ScholarCross RefWilliam R. Provancher, Mark R. Cutkosky, Katherine J. Kuchenbecker, and Gijnter Niemeyer. 2005. Contact Location Display for Haptic Perception of Curvature and Object Motion. The International Journal of Robotics Research 24, 9 (9 2005), 691--702.  Google ScholarDigital LibraryJun Rekimoto. 2013. Traxion. In Proceedings of the 26th annual ACM symposium on User interface software and technology - UIST '13. ACM Press, New York, New York, USA, 427--432.  Google ScholarDigital LibraryI. Sarakoglou, N. Tsagarakis, and D.G. Caldwell. 2005. A Portable Fingertip Tactile Feedback Array Transmission System Reliability and Modelling. In First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. IEEE, 547--548.  Google ScholarDigital LibrarySamuel B. Schorr and Allison M. Okamura. 2017. Fingertip Tactile Devices for Virtual Object Manipulation and Exploration. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems - CHI '17. ACM Press, New York, New York, USA, 3115--3119.  Google ScholarDigital LibraryEvan Strasnick, Christian Holz, Eyal Ofek, Mike Sinclair, and Hrvoje Benko. 2018. Haptic Links: Bimanual Haptics for Virtual Reality Using Variable Stiffness Actuation. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, 1--644.  Google ScholarDigital LibraryJacob Thorn, Rodrigo Pizarro, Bernhard Spanlang, Pablo BermellGarcia, and Mar Gonzalez-Franco. 2016. Assessing 3D Scan Quality Through Paired-comparisons Psychophysics. In Proceedings of the 2016 ACM on Multimedia Conference - MM '16. ACM Press, New York, New York, USA, 147--151.  Google ScholarDigital LibraryKrist Vaesen. 2012. The cognitive bases of human tool use. Behavioral and Brain Sciences 35, 4 (2012), 203--218.Google ScholarCross RefYon Visell, Bruno L. Giordano, Guillaume Millet, and Jeremy R. Cooperstock. 2011. Vibration Influences Haptic Perception of Surface Compliance During Walking. PLoS ONE 6, 3 (3 2011), e17697.Google ScholarEric Whitmire, Hrvoje Benko, Christian Holz, Eyal Ofek, and Mike Sinclair. 2018. Haptic Revolver: Touch, Shear, Texture, and Shape Rendering on a Reconfigurable Virtual Reality Controller. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, 86:1--86:12.  Google ScholarDigital LibraryVibol Yem, Ryuta Okazaki, and Hiroyuki Kajimoto. 2016. FinGAR. In ACM SIGGRAPH 2016 Emerging Technologies on - SIGGRAPH '16. ACM Press, New York, New York, USA, 1--2.  Google ScholarDigital LibraryVibol Yem, Kevin Vu, Yuki Kon, and Hiroyuki Kajimoto. 2018. Effect of Electrical Stimulation Haptic Feedback on Perceptions of SoftnessHardness and Stickiness While Touching a Virtual Object. In 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR). IEEE, 89--96.Google ScholarT. Yoshioka, S. J. Bensma\u00efa, J. C. Craig, and S. S. Hsiao. 2007. Texture perception through direct and indirect touch: An analysis of perceptual space for tactile textures in two modes of exploration. Somatosensory &amp; Motor Research 24, 1--2 (1 2007), 53--70.Google ScholarCross RefSung-Sik Yun, Brian Byunghyun Kang, and Kyu-Jin Cho. 2017. ExoGlove PM: An Easily Customizable Modularized Pneumatic Assistive Glove. IEEE Robotics and Automation Letters 2, 3 (7 2017), 1725--1732.Google ScholarCross RefAndre Zenner and Antonio Kruger. 2017. Shifty: A Weight-Shifting Dynamic Passive Haptic Proxy to Enhance Object Perception in Virtual Reality. IEEE Transactions on Visualization and Computer Graphics 23, 4 (4 2017), 1285--1294.  Google ScholarDigital LibrarySupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3290605.3300301/2dd3c78e-be66-4f63-a58c-d4b2200a0f81/paper071.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee05eee35a4ac3e15fa134b9c42e1c9e37ad0b253abc3f1220fb1bb6b13b2b63bcf97cc7a61d05706e8a804d754f15f6e873b622a4b279745bdff01ac7f353fc984f0cf97741cbd722application/x-mpegurlmp4266.4 MB", "keywords": ["vr object manipulation", "haptic texture", "haptics", "haptic compliance"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "18", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300301", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300301"}, {"title": "WatchVR: Exploring the Usage of a Smartwatch for Interaction in Mobile Virtual Reality", "authors": ["Teresa Hirzle", "Jan Rixen", "Jan Gugenheimer", "Enrico Rukzio"], "abstract": "Mobile virtual reality (VR) head-mounted displays (HMDs) are steadily becoming part of people's everyday life. Most current interaction approaches rely either on additional hardware (e.g. Daydream Controller) or offer only a liMassachusetts Institute of Technologyed interaction concept (e.g. Google Cardboard). We explore a solution where a conventional smartwatch, a device users already carry around with them, is used to enable short interactions but also allows for longer complex interactions with mobile VR. To explore the possibilities of a smartwatch for interaction, we conducted a user study in which we compared two variables with regard to user performance: interaction method (touchscreen vs inertial sensors) and wearing method (hand-held vs wrist-worn). We found that selection time and error rate were lowest when holding the smartwatch in one hand using its inertial sensors for interaction (hand-held).", "keywords": ["nomadic virtual reality", "mobile virtual reality", "3d pointing", "smartwatch"], "published_in": "CHI EA '18: Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems", "publication_date": "20 April 2018", "citations": "8", "isbn": "9781450356213", "doi": "10.1145/3170427", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3170427.3188629", "paper_url": "https://dl.acm.org/doi/10.1145/3170427.3188629"}, {"title": "Experimental Analysis of Barehand Mid-air Mode-Switching Techniques in Virtual Reality", "authors": ["Hemant Bhaskar Surale", "Fabrice Matulic", "Daniel Vogel"], "abstract": "We present an empirical comparison of eleven bare hand, mid-air mode-switching techniques suitable for virtual reality in two experiments. The first evaluates seven techniques spanning dominant and non-dominant hand actions. Techniques represent common classes of actions selected by a methodical examination of 56 examples of prior art. The standard \"subtraction method\" protocol is adapted for 3D interfaces, with two baseline selection methods, bare hand pinch and device controller button. A second experiment with four techniques explores more subtle dominant-hand techniques and the effect of using a dominant hand device for selection. Results provide guidance to practitioners when choosing bare hand, mid-air mode-switching techniques, and for researchers when designing new mode-switching methods in VR.", "keywords": ["controlled experiment", "interaction techniques"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "7", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300426", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300426"}, {"title": "A Dose of Reality: Overcoming Usability Challenges in VR Head-Mounted Displays", "authors": ["Mark Mcgill", "Roderick Murray-Smith", "Daniel Boland", "Stephen A. Brewster"], "abstract": "This video presents insights into the usability challenges present in consumer VR Head-Mounted Displays regarding a users' capability to interact with and be aware of reality. We demonstrate how these issues can be overcome through selectively incorporating necessary elements of reality into VR, as a user engages with reality. We term this approach Engagement-Dependent Augmented Virtuality.", "keywords": ["virtual reality", "augmented virtuality", "engagement"], "published_in": "CHI EA '15: Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems", "publication_date": "18 April 2015", "citations": "1", "isbn": "9781450331463", "doi": "10.1145/2702613", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2702613.2732491", "paper_url": "https://dl.acm.org/doi/10.1145/2702613.2732491"}, {"title": "\"When the Elephant Trumps\": A Comparative Study on Spatial Audio for Orientation in 360&#xba; Videos", "authors": ["Paulo Bala", "Raul Masu", "Valentina Nisi", "Nuno Nunes"], "abstract": "Orientation is an emerging issue in cinematic Virtual Reality (VR), as viewers may fail in locating points of interest. Recent strategies to tackle this research problem have investigated the role of cues, specifically diegetic sound effects. In this paper, we examine the use of sound spatialization for orientation purposes, namely by studying different spatialization conditions (\"none\", \"partial\", and \"full\" spatial manipulation) of multitrack soundtracks. We performed a between-subject mixed-methods study with 36 participants, aided by Cue Control, a tool we developed for dynamic spatial sound editing and data collection/analysis. Based on existing literature on orientation cues in 360\u00ba and theories on human listening, we discuss situations in which the spatialization was more effective (namely, \"full\" spatial manipulation both when using only music and when combining music and diegetic effects), and how this can be used by creators of 360\u00ba videos.", "keywords": ["cinematic virtual reality", "virtual audio spaces", "spatial audio", "360\u00ba video", "orientation"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "1", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300925", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300925"}, {"title": "ARPen: Mid-Air Object Manipulation Techniques for a Bimanual AR System with Pen &amp; Smartphone", "authors": ["Philipp Wacker", "Oliver Nowak", "Simon Voelker", "Jan Borchers"], "abstract": "Modeling in Augmented Reality (AR) lets users create and manipulate virtual objects in mid-air that are aligned to their real environment. We present ARPen, a bimanual input technique for AR modeling that combines a standard smartphone with a 3D-printed pen. Users sketch with the pen in mid-air, while holding their smartphone in the other hand to see the virtual pen traces in the live camera image. ARPen combines the pen's higher 3D input precision with the rich interactive capabilities of the smartphone touchscreen. We studied subjective preferences for this bimanual input technique, such as how people hold the smartphone while drawing, and analyzed the performance of different bimanual techniques for selecting and moving virtual objects. Users preferred a bimanual technique casting a ray through the pen tip for both selection and translation. We provide initial design guidelines for this new class of bimanual AR modeling systems.                     References                 Rahul Arora, Rubaiat Habib Kazi, Tovi Grossman, George Fitzmaurice, and Karan Singh. 2018. SymbiosisSketch: Combining 2D &amp; 3D Sketching for Designing Detailed 3D Objects in Situ. In Proc CHI '18. ACM, 185:1--185:15.  Google ScholarDigital LibraryRahul Arora, Rubaiat Habib Kazi, Fraser Anderson, Tovi Grossman, Karan Singh, and George Fitzmaurice. 2017. Experimental Evaluation of Sketching on Surfaces in VR. In Proc CHI '17. ACM, 5643--5654.  Google ScholarDigital LibraryTeo Babic, Harald Reiterer, and Michael Haller. 2018. Pocket6: A 6DoF Controller Based On A Simple Smartphone Application. In Proceedings of the Symposium on Spatial User Interaction (SUI '18). ACM, New York, NY, USA, 2--10.  Google ScholarDigital LibrarySeok-Hyung Bae, Ravin Balakrishnan, and Karan Singh. 2008. ILoveSketch: as-natural-as-possible sketching system for creating 3d curve models. In Proceedings of the 21st annual ACM symposium on User interface software and technology - UIST '08. ACM Press.  Google ScholarDigital LibraryHuidong Bai, Gun A. Lee, and Mark Billinghurst. 2012. Freeze View Touch and Finger Gesture Based Interaction Methods for Handheld Augmented Reality Interfaces. In Proceedings of the 27th Conference on Image and Vision Computing New Zealand (IVCNZ '12). ACM, New York, NY, USA, 126--131.  Google ScholarDigital LibraryHuidong Bai, Gun A. Lee, Mukundan Ramakrishnan, and Mark Billinghurst. 2014. 3D Gesture Interaction for Handheld Augmented Reality. In SIGGRAPH Asia 2014 Mobile Graphics and Interactive Applications (SA '14). ACM, New York, NY, USA, Article 7, 6 pages.  Google ScholarDigital LibraryOriel Bergig, Nate Hagbi, Jihad El-Sana, and Mark Billinghurst. 2009. In-place 3D Sketching for Authoring and Augmenting Mechanical Systems. In Proceedings of the 2009 8th IEEE International Symposium on Mixed and Augmented Reality (ISMAR '09). IEEE Computer Society, Washington, DC, USA, 87--94.  Google ScholarDigital LibraryMark Billinghurst, Tham Piumsomboon, and Huidong Bai. 2014. Hands in Space: Gesture Interaction with Augmented-Reality Interfaces. IEEE Computer Graphics and Applications 34, 1 (Jan 2014), 77--80.Google ScholarCross RefDoug A. Bowman, Ernst Kruijff, Joseph J. LaViola, and Ivan Poupyrev. 2004. 3D User Interfaces: Theory and Practice. Addison Wesley Longman Publishing Co., Inc., Redwood City, CA, USA. Google ScholarDigital LibraryBill Buxton and George W. Fitzmaurice. 1998. HMDs, Caves &amp; Chameleon: A Human-centric Analysis of Interaction in Virtual Space. SIGGRAPH Comput. Graph. 32, 4 (Nov. 1998), 69--74.  Google ScholarDigital LibraryArindam Dey, Graeme Jarvis, Christian Sandor, and Gerhard Reitmayr. 2012. Tablet versus phone: Depth perception in handheld augmented reality. In 2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR). 187--196.  Google ScholarDigital LibraryLeo Gombac, Klen Copic Pucihar, Matjaz Kljun, Paul Coulton, and Jan Grbac. 2016. 3D Virtual Tracing and Depth Perception Problem on Mobile AR. In Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI EA '16). ACM, New York, NY, USA, 1849--1856.  Google ScholarDigital LibraryNate Hagbi, Raphaet Grasset, Oriel Bergig, Mark Billinghurst, and Jihad El-Sana. 2010. In-Place Sketching for Content Authoring in Augmented Reality Games. In Proceedings of the 2010 IEEE Virtual Reality Conference (VR '10). IEEE Computer Society, Washington, DC, USA, 91--94.  Google ScholarDigital LibraryAnders Henrysson, Mark Billinghurst, and Mark Ollila. 2005. Virtual Object Manipulation Using a Mobile Phone. In Proceedings of the 2005 International Conference on Augmented Tele-existence (ICAT '05). ACM, New York, NY, USA, 164--171.  Google ScholarDigital LibraryKe Huo, Vinayak, and Karthik Ramani. 2017. Window-Shaping: 3D Design Ideation by Creating on, Borrowing from, and Looking at the Physical World. In Proceedings of the Eleventh International Conference on Tangible, Embedded, and Embodied Interaction (TEI '17). ACM, New York, NY, USA, 37--45.  Google ScholarDigital LibraryWolfgang H\u00fcrst, Ronald Poppe, and Jerry van Angeren. 2015. Drawing outside the lines: Tracking-based gesture interaction in mobile augmented entertainment. In 2015 7th International Conference on Intelligent Technologies for Interactive Entertainment (INTETAIN). 79--87. Google ScholarDigital LibraryWolfgang H\u00fcrst and Casper van Wezel. 2013. Gesture-based interaction via finger tracking for mobile augmented reality. Multimedia Tools and Applications 62, 1 (Jan 2013), 233--258.Google ScholarCross RefTakeo Igarashi, Satoshi Matsuoka, and Hidehiko Tanaka. 1999. Teddy: a sketching interface for 3D freeform design. In Proceedings of the 26th annual conference on Computer graphics and interactive techniques SIGGRAPH '99. ACM Press.  Google ScholarDigital LibraryPaul Issartel, Florimond Gu\u00e9niat, and Mehdi Ammi. 2014. Slicing techniques for handheld augmented reality. In 2014 IEEE Symposium on 3D User Interfaces (3DUI). 39--42.Google ScholarCross RefBret Jackson and Daniel F. Keefe. 2016. Lift-Off: Using Reference Imagery and Freehand Sketching to Create 3D Models in VR. IEEE Transactions on Visualization and Computer Graphics 22, 4 (April 2016), 1442--1451.  Google ScholarDigital LibraryErnst Kruijff, J. Edward Swan, and Steven Feiner. 2010. Perceptual issues in augmented reality revisited. In 2010 IEEE International Symposium on Mixed and Augmented Reality. 3--12.Google ScholarCross RefDavid Lakatos, Matthew Blackshaw, Alex Olwal, Zachary Barryte, Ken Perlin, and Hiroshi Ishii. 2014. T(Ether): Spatially-aware Handhelds, Gestures and Proprioception for Multi-user 3D Modeling and Animation. In Proceedings of the 2Nd ACM Symposium on Spatial User Interaction (SUI '14). ACM, New York, NY, USA, 90--93.  Google ScholarDigital LibraryGun A. Lee, Ungyeon Yang, Yongwan Kim, Dongsik Jo, Ki-Hong Kim, Jae Ha Kim, and Jin Sung Choi. 2009. Freeze-Set-Go Interaction Method for Handheld Mobile Augmented Reality Environments. In Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology (VRST '09). ACM, New York, NY, USA, 143--146.  Google ScholarDigital LibraryJoon Hyub Lee, Sang-Gyun An, Yongkwan Kim, and Seok-Hyung Bae. 2018. Projective Windows: Bringing Windows in Space to the Fingertip. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, NY, USA, Article 218, 8 pages.  Google ScholarDigital LibraryAsier Marzo, Beno\u00eet Bossavit, and Martin Hachet. 2014. Combining Multi-touch Input and Device Movement for 3D Manipulations in Mobile Augmented Reality Environments. In Proceedings of the 2Nd ACM Symposium on Spatial User Interaction (SUI '14). ACM, New York, NY, USA, 13--16.  Google ScholarDigital LibraryPaul Milgram and Fumio Kishino. 1994. A Taxonomy of Mixed Reality Visual Displays. IEICE Transactions on Information Systems E77-D (1994). http://vered.rose.utoronto.ca/people/paul_dir/IEICE94/ieice. htmlGoogle ScholarBojan Milosevic, Flavio Bertini, Elisabetta Farella, and Serena Morigi. 2016. A SmartPen for 3D interaction and sketch-based surface modeling. The International Journal of Advanced Manufacturing Technology 84, 5 (01 May 2016), 1625--1645.Google ScholarAnnette Mossel, Benjamin Venditti, and Hannes Kaufmann. 2013. 3DTouch and HOMER-S: Intuitive Manipulation Techniques for Onehanded Handheld Augmented Reality. In Proceedings of the Virtual Reality International Conference: Laval Virtual (VRIC '13). ACM, New York, NY, USA, Article 12, 10 pages.  Google ScholarDigital LibraryAnnette Mossel, Benjamin Venditti, and Hannes Kaufmann. 2013. DrillSample: Precise Selection in Dense Handheld Augmented Reality Environments. In Proceedings of the Virtual Reality International Conference: Laval Virtual (VRIC '13). ACM, New York, NY, USA, Article 10, 10 pages.  Google ScholarDigital LibraryJon Peddie. 2017. Augmented Reality - Where We Will All Live. Springer. Google ScholarDigital LibraryHuaishu Peng, Jimmy Briggs, Cheng-Yao Wang, Kevin Guo, Joseph Kider, Stefanie Mueller, Patrick Baudisch, and Fran\u00e7ois Guimbreti\u00e8re. 2018. RoMA: Interactive Fabrication with Augmented Reality and a Robotic 3D Printer. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, NY, USA, Article 579, 12 pages.  Google ScholarDigital LibraryJarkko Polvi, Takafumi Taketomi, Goshiro Yamamoto, Arindam Dey, Christian Sandor, and Hirokazu Kato. 2016. SlidAR: A 3D positioning method for SLAM-based handheld augmented reality. Computers &amp; Graphics 55 (2016), 33 -- 43.  Google ScholarDigital LibraryEmanuel Sachs, Andrew Roberts, and David Stoops. 1991. 3-Draw: a tool for designing 3D shapes. IEEE Computer Graphics and Applications 11, 6 (Nov 1991), 18--26.  Google ScholarDigital LibraryHartmut Seichter. 2003. Sketchand+ a Collaborative Augmented Reality Sketching Application. In Proceedings of the 8th International Conference on Computer Aided Architectural Design Research in Asia (CAADRIA '03). 209--222.Google ScholarIris Seidinger and Jens Grubert. 2016. 3D Character Customization for Non-Professional Users in Handheld Augmented Reality. In 2016 IEEE International Symposium on Mixed and Augmented Reality (ISMARAdjunct). 129--134.Google ScholarCross RefMichael Tsang, George W. Fitzmaurice, Gordon Kurtenbach, Azam Khan, and Bill Buxton. 2003. Boom Chameleon: Simultaneous Capture of 3D Viewpoint, Voice and Gesture Annotations on a Spatially-aware Display. In ACM SIGGRAPH 2003 Papers (SIGGRAPH '03). ACM, New York, NY, USA, 698--698.  Google ScholarDigital LibraryKlen Copic Pucihar, Paul Coulton, and Jason Alexander. 2013. Evaluating Dual-view Perceptual Issues in Handheld Augmented Reality: Device vs. User Perspective Rendering. In Proceedings of the 15th ACM on International Conference on Multimodal Interaction (ICMI '13). ACM, New York, NY, USA, 381--388.  Google ScholarDigital LibraryThomas Vincent, Laurence Nigay, and Takeshi Kurata. 2013. Precise Pointing Techniques for Handheld Augmented Reality. In HumanComputer Interaction -- INTERACT 2013. Springer Berlin Heidelberg, Berlin, Heidelberg, 122--139.Google ScholarPhilipp Wacker, Adrian Wagner, Simon Voelker, and Jan Borchers. 2018. Physical Guides: An Analysis of 3D Sketching Performance on Physical Objects in Augmented Reality. In Proceedings of the Symposium on Spatial User Interaction (SUI '18). ACM, New York, NY, USA, 25--35.  Google ScholarDigital LibraryPo-Chen Wu, Robert Wang, Kenrick Kin, Christopher Twigg, Shangchen Han, Ming-Hsuan Yang, and Shao-Yi Chien. 2017. DodecaPen: Accurate 6DoF Tracking of a Passive Stylus. In Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology (UIST '17). ACM, New York, NY, USA, 365--374.  Google ScholarDigital LibraryMin Xin, Ehud Sharlin, and Mario Costa Sousa. 2008. Napkin sketch: handheld mixed reality 3D sketching. In Proceedings of the 2008 ACM symposium on Virtual reality software and technology - VRST '08. ACM Press.  Google ScholarDigital LibraryBrandon Yee, Yuan Ning, and Hod Lipson. 2009. Augmented Reality In-situ 3D Sketching of Physical Objects. In Intelligent UI workshop on sketch recognition (IUI '09).Google ScholarSang Ho Yoon, Ke Huo, and Karthik Ramani. 2016. TMotion: Embedded 3D Mobile Input Using Magnetic Sensing Technique. In Proceedings of the TEI '16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction (TEI '16). ACM, New York, NY, USA, 21--29.  Google ScholarDigital LibraryYa-Ting Yue, Xiaolong Zhang, Yongliang Yang, Gang Ren, Yi-King Choi, and Wenping Wang. 2017. WireDraw: 3D Wire Sculpturing Guided with Mixed Reality. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems - CHI '17. ACM Press.  Google ScholarDigital Librarypaper619pvc.zipPreview video captionsSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3290605.3300849/5cc56df0-da56-456b-b9b9-64c672ad454f/paper619p.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee05eee35a4ac3e15fa134b9cf2a149e30aa0c23101160f8ba89377819c1efe63358514d8f5dfeeae5ebfbbd572b484819e29ec5a296490dccadced036f23f103da2e54a985f7054beapplication/x-mpegurlmp44.7 MB", "keywords": ["translation", "smartphone ar", "selection", "mid-air interaction", "immersive modeling", "pen", "bimanual interaction", "augmented reality"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "7", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300849", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300849"}, {"title": "Select ahead: efficient object selection technique using the tendency of recent cursor movements", "authors": ["Soonchan Park", "Seokyeol Kim", "Jinah Park"], "abstract": "Virtual hand is one of the most intuitive metaphors for object selection in the virtual environment because of its natural mapping between the user action input and the cursor. However, it has a limitation of lengthy cursor manipulation for object selection task which is directly related to the level of workload of the user in performing object selection. In this paper, we propose 'Select Ahead' as a new object selection technique that improves efficiency by reducing the physical workload. Select Ahead guides the user to select the distant object along the estimated tendency of the recent cursor movements. We evaluate the relative performance of Select Ahead through the experiments in the 3D virtual environment with various object densities. The results show that Select Ahead significantly reduces the length of the cursor movements compared to those of the 3D point cursor and the 3D bubble cursor regardless of the object density. In the aspect of the total duration time for selection, Select Ahead outperforms the 3D point cursor and has no significant difference compared to that of the 3D bubble cursor.", "keywords": ["3d interaction", "virtual hand", "object selection", "virtual reality", "3d cursor"], "published_in": "APCHI '12: Proceedings of the 10th asia pacific conference on Computer human interaction", "publication_date": "28 August 2012", "citations": "2", "isbn": "9781450314961", "doi": "10.1145/2350046", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2350046.2350060", "paper_url": "https://dl.acm.org/doi/10.1145/2350046.2350060"}, {"title": "Virtual Hubs: Understanding Relational Aspects and Remediating Incubation", "authors": ["Jandy Luik", "Jenna Ng", "Jonathan Hook"], "abstract": "We have recently seen the emergence of new platforms that aim to provide remotely located entrepreneurs and startup companies with support analogous to that found within traditional incubation or acceleration spaces. This paper offers an understanding of these 'virtual hubs', and the inherently socio-technical interactions that occur between their members. Our study analyzes a sample of existing virtual hubs in two stages. First, we contribute broader insight into the current landscape of virtual hubs by documenting and categorizing 25 hubs regarding their form, support offered and a selection of further qualities. Second, we contribute detailed insight into the operation and experience of such hubs, from an analysis of 10 semi-structured interviews with organizers and participants of virtual hubs. We conclude by analyzing our findings in terms of relational aspects of non-virtual hubs from the literature and remediation theory, and propose opportunities for advancing the design of such platforms.", "keywords": ["incubators and accelerators", "virtual hubs", "relational aspects", "digital incubation", "remediation"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "0", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300471", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300471"}, {"title": "shapeShift: 2D Spatial Manipulation and Self-Actuation of Tabletop Shape Displays for Tangible and Haptic Interaction", "authors": ["Alexa F. Siu", "Eric J. Gonzalez", "Shenli Yuan", "Jason B. Ginsberg", "Sean Follmer"], "abstract": "We explore interactions enabled by 2D spatial manipulation and self-actuation of a tabletop shape display. To explore these interactions, we developed shapeShift, a compact, high-resolution (7 mm pitch), mobile tabletop shape display. shapeShift can be mounted on passive rollers allowing for bimanual interaction where the user can freely manipulate the system while it renders spatially relevant content. shapeShift can also be mounted on an omnidirectional-robot to provide both vertical and lateral kinesthetic feedback, display moving objects, or act as an encountered-type haptic device for VR. We present a study on haptic search tasks comparing spatial manipulation of a shape display for egocentric exploration of a map versus exploration using a fixed display and a touch pad. Results show a 30% decrease in navigation path lengths, 24% decrease in task time, 15% decrease in mental demand and 29% decrease in frustration in favor of egocentric navigation.                     References                 Johnny Accot and Shumin Zhai. 1999. Performance evaluation of input devices in trajectory-based tasks: an application of the steering law. In Proceedings of the SIGCHI conference on Human Factors in Computing Systems. ACM, 466--472.  Google ScholarBruno Araujo, Ricardo Jota, Varun Perumal, Jia Xian Yao, Karan Singh, and Daniel Wigdor. 2016. Snake Charmer: Physically Enabling Virtual Objects. In Proceedings of the TEI'16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction. ACM, 218--226.  Google ScholarRobert A Bjork and William B Whitten. 1974. Recency-sensitive retrieval processes in long-term free recall. Cognitive Psychology 6, 2 (1974), 173--189.Google ScholarMatthew Blackshaw, Anthony DeVincenzi, David Lakatos, Daniel Leithinger, and Hiroshi Ishii. 2011. Recompose: direct and gestural interaction with an actuated surface. In CHI'11 Extended Abstracts on Human Factors in Computing Systems. ACM, 1237--1242.  Google ScholarPatrick Bruns, Carlos J. Camargo, Humberto Campanella, Jaume Esteve, Hubert R. Dinse, and Brigitte R\u00c3uder. 2014. Tactile Acuity Charts: A Reliable Measure of Spatial Acuity. PLOS ONE 9, 2 (02 2014), 1--11.Google ScholarW Buxton. 1995. Touch, Gesture &amp; Marking. Chapter 7 in RM Baecker, J. Grudin, W. Buxton and S. Greenberg, S.(Eds.). Readings in Human Computer Interaction: Toward the Year 2000. (1995).Google ScholarEmanuele Coluccia, Irene C Mammarella, Rossana De Beni, Miriam Ittyerah, and Cesare Cornoldi. 2016. Remembering Object Position in the Absence of Vision: Egocentric, Allocentric, and Egocentric Decentred Frames of Reference. Perception 36, 6 (June 2016), 850--864.Google ScholarBrian D Ehret. 2002. Learning where to look: Location learning in graphical user interfaces. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, 211--218.  Google ScholarKatherine M Everitt, Scott R Klemmer, Robert Lee, and James A Landay. 2003. Two worlds apart: bridging the gap between physical and virtual media for distributed design collaboration. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, 553--560.  Google ScholarGeorge W Fitzmaurice. 1993. Situated information spaces and spatially aware palmtop computers. Commun. ACM 36, 7 (1993), 39--49.  Google ScholarSean Follmer, Daniel Leithinger, Alex Olwal, Akimitsu Hogge, and Hiroshi Ishii. 2013. inFORM: Dynamic Physical Affordances and Constraints Through Shape and Object Actuation. In Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology (UIST '13). ACM, 417--426.  Google ScholarKen Hinckley, Randy Pausch, and Dennis Proffitt. 1997a. Attention and visual feedback: the bimanual frame of reference. ACM, New York, New York, USA.Google ScholarKen Hinckley, Randy Pausch, Dennis Proffitt, James Patten, and Neal Kassell. 1997b. Cooperative bimanual action. In the SIGCHI conference. ACM Press, New York, New York, USA, 27--34.  Google ScholarKoichi Hirota and Michitaka Hirose. 1995. Simulation and presentation of curved surface in virtual reality environment through surface display. In Virtual Reality Annual International Symposium, 1995. Proceedings. IEEE, 211--216. Google ScholarHiroo Iwata, Hiroaki Yano, Fumitaka Nakaizumi, and Ryo Kawamura. 2001. Project FEELEX: adding haptic surface to graphics. In Proceedings of the 28th annual conference on Computer graphics and interactive techniques. ACM, 469--476.  Google ScholarGarrett JW. 1971. The adult human hand: some anthropometric and biomechanical considerations. Human Factors 13, 2 (April 1971), 117--131.Google ScholarVictor Kaptelinin. 1993. Item recognition in menu selection: the effect of practice. In INTERACT'93 and CHI'93 conference companion on Human factors in computing systems. ACM, 183--184.  Google ScholarFrederic Kerber, Antonio Kr\u00fcger, and Markus L\u00f6chtefeld. 2014. Investigating the effectiveness of peephole interaction for smartwatches in a map navigation task. In Proceedings of the 16th international conference on Human-computer interaction with mobile devices &amp; services. ACM, 291--294.  Google ScholarR L Klatzky and S J Lederman. How well can we encode spatial layout from sparse kinesthetic contact?. In 11th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. IEEE Comput. Soc, 179--186. Google ScholarJonathan Konieczny, Clement Shimizu, Gary Meyer, and D'nardo Colucci. 2005. A handheld flexible display system. In Visualization, 2005. VIS 05. IEEE. IEEE, 591--597.Google ScholarJames R Lackner and Barbara Shenker. 1985. Proprioceptive influences on auditory and visual spatial localization. Journal of Neuroscience 5, 3 (1985), 579--583.Google ScholarMathieu Le Goc, Lawrence H. Kim, Ali Parsaei, Jean-Daniel Fekete, Pierre Dragicevic, and Sean Follmer. 2016. Zooids: Building Blocks for Swarm User Interfaces. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST '16). ACM, 97--109.  Google ScholarSusan J Lederman, Roberta L Klatzky, April Collins, and Jackie Wardell. 1987. Exploring environments by hand or foot: Time-based heuristics for encoding distance in movement space. Journal of Experimental Psychology: Learning, Memory, and Cognition 13, 4 (1987), 606.Google ScholarEric Lee and James Macgregor. 2016. Minimizing User Search Time in Menu Retrieval Systems. Human Factors 27, 2 (Nov. 2016), 157--162.Google ScholarDaniel Leithinger. 2015. Grasping information and collaborating through shape displays. Ph.D. Dissertation. Massachusetts Institute of Technology.Google ScholarDaniel Leithinger and Sean Follmer. 2010. Relief: a scalable actuated shape display. ACM, New York, New York, USA.Google ScholarDaniel Leithinger, Sean Follmer, Alex Olwal, and Hiroshi Ishii. 2014. Physical telepresence: shape capture and display for embodied, computer-mediated remote collaboration. In Proceedings of the 27th annual ACM symposium on User interface software and technology. ACM, 461--470.  Google ScholarWilliam A McNeely. 1993. Robotic graphics: a new approach to force feedback for virtual reality. In Virtual Reality Annual International Symposium, 1993., 1993 IEEE. IEEE, 336--341.  Google ScholarSumit Mehra, Peter Werkhoven, and Marcel Worring. 2006. Navigating on handheld displays: Dynamic versus static peephole navigation. ACM Transactions on Computer-Human Interaction (TOCHI) 13, 4 (2006), 448--457.  Google ScholarK E Overvliet, J B J Smeets, and E Brenner. 2008. The use of proprioception and tactile information in haptic search. Acta Psychologica 129, 1 (Sept. 2008), 83--90.Google ScholarGian Pangaro, Dan Maynes-Aminzade, and Hiroshi Ishii. 2002. The actuated workbench: computer-controlled actuation in tabletop tangible interfaces. In Proceedings of the 15th annual ACM symposium on User interface software and technology. ACM, 181--190.  Google ScholarStephen Pheasant and Christine M Haslegrave. 2016. Bodyspace: Anthropometry, ergonomics and the design of work. CRC Press.Google ScholarMyrthe A Plaisier, Astrid ML Kappers, Wouter M Bergmann Tiest, and Marc O Ernst. 2010. Visually Guided Haptic Search. Haptics, IEEE Transactions on 3, 1 (2010), 63--72.  Google ScholarIvan Poupyrev, Tatsushi Nashida, Shigeaki Maruyama, Jun Rekimoto, and Yasufumi Yamaji. 2004. Lumen: interactive visual and shape display for calm computing. In ACM SIGGRAPH 2004 Emerging technologies. ACM, 17.  Google ScholarRoman R\u00e4dle, Hans-Christian Jetter, Simon Butscher, and Harald Reiterer. 2013. The effect of egocentric body movements on users' navigation performance and spatial memory in zoomable user interfaces. In Proceedings of the 2013 ACM international conference on Interactive tabletops and surfaces. ACM, 23--32.  Google ScholarR R\u00e4dle, H C Jetter, J M\u00fcller, and H Reiterer. 2014. Bigger is not always better: display size, performance, and task load during peephole map navigation. In Proceedings of the 32nd ....Google ScholarMajken K Rasmussen, Esben W Pedersen, Marianne G Petersen, and Kasper Hornb\u00e6k. 2012. Shape-changing interfaces: a review of the design space and open research questions. ACM.Google ScholarJan Richter, Bruce H Thomas, Maki Sugimoto, and Masahiko Inami. 2007. Remote active tangible interactions. In Proceedings of the 1st international conference on Tangible and embedded interaction. ACM, 39--42.  Google ScholarEckard Riedenklau, Thomas Hermann, and Helge Ritter. 2012. An integrated multi-modal actuated tangible user interface for distributed collaborative planning. In Proceedings of the Sixth International Conference on Tangible, Embedded and Embodied Interaction. ACM, 169--174.  Google ScholarMichael Rohs, Johannes Sch\u00f6ning, Martin Raubal, Georg Essl, and Antonio Kr\u00fcger. 2007. Map navigation with mobile devices: virtual versus physical movement with and without visual context. In Proceedings of the 9th international conference on Multimodal interfaces. ACM, 146--153.  Google ScholarMark S Sanders and Ernest James McCormick. 1993. Human factors in engineering and design. McGraw-Hill book company.Google ScholarJulian Seifert, Sebastian Boring, Christian Winkler, Florian Schaub, Fabian Schwab, Steffen Herrdum, Fabian Maier, Daniel Mayer, and Enrico Rukzio. 2014. Hover Pad: interacting with autonomous and self-actuated displays in space. In Proceedings of the 27th annual ACM symposium on User interface software and technology. ACM, 139--147.  Google ScholarMakoto Shimojo, Masami Shinohara, and Yukio Fukui. 1999. Human shape recognition performance for 3D tactile display. IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans 29, 6 (1999), 637--644.  Google ScholarMike Sinclair, Michel Pahud, and Hrvoje Benko. 2013. TouchMover: actuated 3D touchscreen with haptic feedback. In Proceedings of the 2013 ACM international conference on Interactive tabletops and surfaces. ACM, 287--296.  Google ScholarJacqueline C Snow, Rafal M Skiba, Taylor L Coleman, and Marian E Berryhill. 2014. Real-world objects are more memorable than photographs of objects. Frontiers in human neuroscience 8 (2014).Google ScholarJ\u00fcrgen Steimle, Andreas Jordt, and Pattie Maes. 2013. Flexpad: highly flexible bending interactions for projected handheld displays. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 237--246.  Google ScholarBrygg Ullmer and Hiroshi Ishii. 1997. The metaDESK: models and prototypes for tangible user interfaces. In Proceedings of the 10th annual ACM symposium on User interface software and technology. ACM, 223--232.  Google ScholarChristopher R Wagner, Susan J Lederman, and Robert D Howe. 2002. A tactile shape display using RC servomotors. In Haptic Interfaces for Virtual Environment and Teleoperator Systems, 2002. HAPTICS 2002. Proceedings. 10th Symposium on. IEEE, 354--355. Google ScholarMalte Weiss, Florian Schwarz, Simon Jakubowski, and Jan Borchers. 2010. Madgets: actuating widgets on interactive tabletops. In Proceedings of the 23nd annual ACM symposium on User interface software and technology. ACM, 293--302.  Google ScholarYasuyoshi Yokokohji, Ralph L Hollis, and Takeo Kanade. 1996. What you can see is what you can feel-development of a visual/haptic interface to virtual environment. In Virtual Reality Annual International Symposium, 1996., Proceedings of the IEEE 1996. IEEE, 46--53. Google ScholarYiwei Zhao, Lawrence H Kim, Ye Wang, Mathieu Le Goc, and Sean Follmer. 2017. Robotic Assembly of Haptic Proxy Objects for Tangible Interaction and Virtual Reality. In Proceedings of the 2017 ACM on Interactive Surfaces and Spaces. ACM.  Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3173574.3173865/882740ab-52fe-412f-b2c3-1b8f833a336b/pn2806-file3.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee06e0e0927f1e11a21c84c9597b2c91261dba10d178c158a50ff7e4cdca86eff5ab911d3c5418ce669478e407a5fd8fcdb57de1176bd2a3232f050152df1062df1b876ce3e5723031application/x-mpegurlmp427.6 MB", "keywords": ["shape-changing user interfaces", "shape displays", "actuated tangibles"], "published_in": "CHI '18: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems", "publication_date": "21 April 2018", "citations": "23", "isbn": "9781450356206", "doi": "10.1145/3173574", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3173574.3173865", "paper_url": "https://dl.acm.org/doi/10.1145/3173574.3173865"}, {"title": "Mailing Archived Emails as Postcards: Probing the Value of Virtual Collections", "authors": ["David B. Gerritsen", "Dan Tasse", "Jennifer K. Olsen", "Tatiana A. Vlahovic", "Rebecca Gulotta", "William Odom", "Jason Wiese", "John Zimmerman"], "abstract": "People accumulate huge assortments of virtual possessions, but it is not yet clear how systems and system designers can help people make meaning from these large archives. Early research in HCI has suggested that people generally appear to value their virtual things less than their material things, but theory on material possessions does not entirely explain this difference. To investigate if changes to the form and behavior of virtual things may surface valued elements of a virtual archive, we designed a technology probe that selected snippets from old emails and mailed them as physical postcards to participating households. The probe uncovered features of emails that trigger meaningful reflection, and how contextual information can help people engage in reminiscence. Our study revealed insights about how materializing virtual possessions influences factors shaping how people draw on, understand, and value those possessions. We conclude with implication and strategies for aimed at supporting people in having more meaningful interactions and experiences with their virtual possessions.", "keywords": ["revisitation", "virtual possessions", "design", "technology probes", "self-reflection"], "published_in": "CHI '16: Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems", "publication_date": "7 May 2016", "citations": "7", "isbn": "9781450333627", "doi": "10.1145/2858036", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2858036.2858541", "paper_url": "https://dl.acm.org/doi/10.1145/2858036.2858541"}, {"title": "Haptic Retargeting: Dynamic Repurposing of Passive Haptics for Enhanced Virtual Reality Experiences", "authors": ["Mahdi Azmandian", "Mark Hancock", "Hrvoje Benko", "Eyal Ofek", "Andrew D. Wilson"], "abstract": "Manipulating a virtual object with appropriate passive haptic cues provides a satisfying sense of presence in virtual reality. However, scaling such experiences to support multiple virtual objects is a challenge as each one needs to be accompanied with a precisely-located haptic proxy object. We propose a solution that overcomes this limitation by hacking human perception. We have created a framework for repurposing passive haptics, called haptic retargeting, that leverages the dominance of vision when our senses conflict. With haptic retargeting, a single physical prop can provide passive haptics for multiple virtual objects. We introduce three approaches for dynamically aligning physical and virtual objects: world manipulation, body manipulation and a hybrid technique which combines both world and body manipulation. Our study results indicate that all our haptic retargeting techniques improve the sense of presence when compared to typical wand-based 3D control of virtual objects. Furthermore, our hybrid haptic retargeting achieved the highest satisfaction and presence scores while limiting the visible side-effects during interaction.                     References                 Merwan Achibet, Adrien Girard, Anthony Talvas, Maud Marchal, and Anatole Lecuyer. 2015. ElasticArm: Human-scale passive haptic feedback for augmenting interaction and perception in virtual environments. Virtual Reality (VR), 2015 IEEE, 63--68.Google ScholarCross RefYuki Ban, Takashi Kajinami, Takuji Narumi, Tomohiro Tanikawa, and Michitaka Hirose. 2012. Modifying an identified angle of edged shapes using pseudo-haptic effects. Haptics: Perception, Devices, Mobility, and Communication. Springer Berlin Heidelberg, 2012. 25--36.. http://doi.org/10.1007/978--3642--31401--8_3  Google ScholarDigital LibraryPatrick Baudisch, Edward Cutrell, Dan Robbins, et al. 2003. Drag-and-pop and drag-and-pick: Techniques for accessing remote screen content on touch-and penoperated systems. Proceedings of INTERACT, 57--64.Google ScholarKristopher J. Blom, Jorge Arroyo-Palacios, and Mel Slater. 2014. The effects of rotating the self out of the body in the full virtual body ownership illusion. Perception 43, 4: 275--294. http://doi.org/10.1068/p7618Google ScholarCross RefEric Burns, Sharif Razzaque, Mary C. Whitton, and Frederick P. Brooks. 2007. MACBETH: The avatar which I see before me and its movement toward my hand. Proceedings IEEE Virtual Reality: 295--296. http://doi.org/10.1109/VR.2007.352509Google ScholarFran\u00e7ois Conti and Oussama Khatib. 2005. Spanning large workspaces using small haptic devices. Eurohaptics Conference, 2005 and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, 2005. World Haptics 2005. First Joint: 183--188. http://doi.org/10.1109/WHC.2005.118  Google ScholarDigital LibraryChristian Corsten, Ignacio Avellino, Max M\u00f6llers, and Jan Borchers. 2013. Instant User Interfaces: Repurposing Everyday Objects as Input Devices. Proceedings of the 2013 ACM international conference on Interactive tabletops and surfaces ITS '13, 71--80. http://doi.org/10.1145/2512349.2512799  Google ScholarDigital LibraryGeorge W. Fitzmaurice, Hiroshi Ishii, and William A.S. Buxton. 1995. Bricks: laying the foundations for graspable user interfaces. Proceedings of the SIGCHI conference on Human factors in computing systems: 442--449. http://doi.org/10.1145/223904.223964  Google ScholarDigital LibraryBernd Frohlich and John Plate. 2000. The cubic mouse: a new device for three-dimensional input. Conference on Human Factors in Computing Systems: Proceedings of the SIGCHI conference on Human factors in computing systems 1, 06: 526--531. http://doi.org/10.1145/332040.332491  Google ScholarDigital LibraryJames J. Gibson. 1933. Adaptation, after-effect and contrast in the perception of curved lines. Journal of Experimental Psychology 16, 1: 1--31. http://doi.org/10.1037/h0074626Google ScholarCross RefJohn C. Goble, Ken Hinckley, Randy Pausch, John W. Snell, and Neal P. Kassell. 1995. Two-handed spatial interface tools for neurosurgical planning. Computer 28, 7: 20--26. http://doi.org/10.1109/2.391037  Google ScholarDigital LibraryRoland Guay. 1977. Purdue Spatial Visualization Test Visualization of Views. Purdue Research Foundation, West Lafayette, IN.Google ScholarHannah B. Helbig and Marc O. Ernst. 2007. Optimal integration of shape information from vision and touch. Experimental Brain Research 179, 4: 595--606. http://doi.org/10.1007/s00221-006-0814-yGoogle ScholarCross RefSteven J Henderson and Steven Feiner. 2008. Opportunistic Controls: Leveraging Natural Affordances as Tangible User Interfaces for Augmented Reality. Proceedings of the 2008 ACM symposium on Virtual reality software and technology VRST '08, 211--218. http://doi.org/10.1145/1450579.1450625  Google ScholarDigital LibraryKen Hinckley, Randy Pausch, John C Goble, and Neal F Kassell. 1994. Passive Real-world Interface Props for Neurosurgical Visualization. Proceedings of the SIGCHI conference on Human factors in computing systems celebrating interdependence CHI '94, 452--458. http://doi.org/10.1145/191666.191821  Google ScholarDigital LibraryRalph L. Hollis, Septimiu E. Salcudean, and A. Peter Allan. 1991. A six-degree-of-freedom magnetically levitated variable compliance fine-motion wrist: Design, modeling, and control. IEEE Transactions on Robotics and Automation 7, 3: 320--332. http://doi.org/10.1109/70.88141Google ScholarCross RefBrent E. Insko. 2001. Passive haptics significantly enhances virtual environments. Computer: 100.Google ScholarKonstantina Kilteni, Jean Marie Normand, Maria V. Sanchez-Vives, and Mel Slater. 2012. Extending body space in immersive virtual reality: A very long arm illusion. PLoS ONE 7, 7. http://doi.org/10.1371/journal.pone.0040867Google ScholarCross RefKonstantina Kilteni. 2015. Over my fake body: body ownership illusions for studying the multisensory basis of own-body perception. Frontiers in Human Neuroscience 9, March. http://doi.org/10.3389/fnhum.2015.00141Google ScholarItaru Kitahara, Morio Nakahara, and Yuichi Ohta. 2010. Sensory Properties in Fusion of Visual / Haptic Stimuli Using Mixed Reality. In Advances in Haptics. InTech. 565--583.Google ScholarRoberta L. Klatzky, Jack M. Loomis, Andrew C. Beall, Sarah S. Chance, and Reginald G. Golledge. 1998. Spatial Updating of Self-Position and Orientation During Real, Imagined, and Virtual Locomotion. Psychological Science 9, 4: 293--298. http://doi.org/10.1111/1467--9280.00058Google ScholarCross RefLuv Kohli, Eric Burns, Dorian Miller, and Henry Fuchs. 2005. Combining passive haptics with redirected walking. Proceedings of the 2005 International Conference on Augmented Teleexistence 57, 4: 253--254. http://doi.org/10.1145/1152399.1152451  Google ScholarDigital LibraryLuv Kohli, Mary C. Whitton, and Frederick P. Brooks. 2012. Redirected touching: The effect of warping space on task performance. IEEE Symposium on 3D User Interfaces 2012, 3DUI 2012 - Proceedings: 105--112. http://doi.org/10.1109/3DUI.2012.6184193Google ScholarCross RefLuv Kohli, Mary C. Whitton, and Frederick P. Brooks. 2013. Redirected Touching: Training and adaptation in warped virtual spaces. IEEE Symposium on 3D User Interface 2013, 3DUI 2013 - Proceedings: 79--86. http://doi.org/10.1109/3DUI.2013.6550201Google ScholarCross RefLuv Kohli. 2010. Redirected touching: Warping space to remap passive haptics. 3DUI 2010 IEEE Symposium on 3D User Interfaces 2010, Proceedings: 129--130. http://doi.org/10.1109/3DUI.2010.5444703  Google ScholarDigital LibraryAnatole L\u00e9cuyer, Sabine Coquillart, Aberrahmane Kheddar, Paul Richard, and Phillipe Coiffet. 2000. Pseudo-haptic feedback: can isometric input devices simulate force feedback? Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048). http://doi.org/10.1109/VR.2000.840369 Google ScholarDigital LibraryRensis Likert. 1932. A technique for the measurement of attitudes. Archives of Psychology 22 140: 55. http://doi.org/2731047Google ScholarWilliam A. McNeely. 1993. Robotic graphics: a new approach to force feedback for virtual reality. Proceedings of IEEE Virtual Reality Annual International Symposium. http://doi.org/10.1109/VRAIS.1993.380761  Google ScholarDigital LibraryWalter R Miles. 1930. Ocular dominance in human adults. Journal of General Psychology 3: 412--430.Google ScholarCross RefSharif Razzaque, Zachariah Kohn, and Mary C Whitton. 2001. Redirected Walking. Proceedings of EUROGRAPHICS: 289--294.Google ScholarIrvin Rock and Jack Victor. 1964. Vision and Touch: An Experimentally Created Conflict Between The Two Senses. Science (NY, N.Y.) 143: 594--596. http://doi.org/10.1126/science.143.3606.594Google ScholarAdalberto L Simeone, Eduardo Velloso, and Hans Gellersen. 2015. Substitutional Reality. Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems CHI '15, 3307--3316. http://doi.org/10.1145/2702123.2702389  Google ScholarDigital LibraryBernhard Spanlang, Jean-Marie Normand, David Borland, et al. 2014. How to Build an Embodiment Lab: Achieving Body Representation Illusions in Virtual Reality. Frontiers in Robotics and AI 1: 1--22. http://doi.org/10.3389/frobt.2014.00009Google ScholarCross RefFrank Steinicke, Gerd Bruder, Jason Jerald, Harald Frenz, and Markus Lappe. 2010. Estimation of Detection Thresholds for Redirected Walking Techniques. IEEE Transactions on Visualization and Computer Graphics 16, 1: 17--27. http://doi.org/10.1109/TVCG.2009.62  Google ScholarDigital LibrarySusumu Tachi, Taro Maeda, Ryokichi Hirata, and Hiroshi Hoshino. 1994. A Construction Method of Virtual Haptic Space. Proceedings of the 4th International Conference on Artificial Reality and Tele-Existence (ICAT'94).Google ScholarColin Ware and Jeff Rose. 1999. Rotating virtual objects with real handles. ACM Transactions on Computer-Human Interaction 6, 162--180. http://doi.org/10.1145/319091.319102  Google ScholarDigital LibraryBob G. Witmer and Michael J. Singer. 1998. Measuring Presence in Virtual Environments: A Presence Questionnaire. Presence: Teleoperators and Virtual Environments 7, 3: 225--240. http://doi.org/10.1162/105474698565686  Google ScholarDigital Librarypn1050-file4.zipCaptions file for the video.Supplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/2858036.2858226/f1d965e7-5efb-48d1-9bd3-50575ddd0841/pn1050.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ef0fe2eb2ee9941421545250ec1cc143d20f9928b71d50fc9db0e8f3a41613bcda0f6bd9f5d3d49917546dcb98ec5c4566ca329f2a29635e3dc21d43310edc33bd47c33a1f05762122application/x-mpegurlmp449.8 MB", "keywords": ["perception", "haptics", "virtual reality"], "published_in": "CHI '16: Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems", "publication_date": "7 May 2016", "citations": "114", "isbn": "9781450333627", "doi": "10.1145/2858036", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2858036.2858226", "paper_url": "https://dl.acm.org/doi/10.1145/2858036.2858226"}, {"title": "pCubee: a perspective-corrected handheld cubic display", "authors": ["Ian Stavness", "Billy Lam", "Sidney Fels"], "abstract": "In this paper, we describe the design of a personal cubic display that offers novel interaction techniques for static and dynamic 3D content. We extended one-screen Fish Tank VR by arranging five small LCD panels into a box shape that is light and compact enough to be handheld. The display uses head-coupled perspective rendering and a real-time physics simulation engine to establish an interaction metaphor of having real objects inside a physical box that a user can hold and manipulate. We evaluated our prototype as a visualization tool and as an input device by comparing it with a conventional LCD display and mouse for a 3D tree-tracing task. We found that bimanual interaction with pCubee and a mouse offered the best performance and was most preferred by users. pCubee has potential in 3D visualization and interactive applications such as games, storytelling and education, as well as viewing 3D maps, medical and architectural data.", "keywords": ["handheld device", "physical interaction", "user interface", "multi-screen display", "user evaluation", "fish tank vr", "3d visualization"], "published_in": "CHI '10: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "10 April 2010", "citations": "52", "isbn": "9781605589299", "doi": "10.1145/1753326", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1753326.1753535", "paper_url": "https://dl.acm.org/doi/10.1145/1753326.1753535"}, {"title": "Extending the Body for Interaction with Reality", "authors": ["Tiare Feuchtner", "J\u00f6rg M\u00fcller"], "abstract": "In this paper, we explore how users can control remote devices with a virtual long arm, while preserving the perception that the artificial arm is actually part of their own body. Instead of using pointing, speech, or a remote control, the users' arm is extended in augmented reality, allowing access to devices that are out of reach. Thus, we allow users to directly manipulate real-world objects from a distance using their bare hands. A core difficulty we focus on is how to maintain ownership for the unnaturally long virtual arm, which is the strong feeling that one's limbs are actually part of the own body. Fortunately, what the human brain experiences as being part of the own body is very malleable and we find that during interaction the user's virtual arm can be stretched to more than twice its real length, without breaking the user's sense of ownership for the virtual limb.                     References                 Abednego, M., Lee, J.-H., Moon, W., and Park, J.-H. I-grabber: Expanding physical reach in a large-display tabletop environment through the use of a virtual grabber. In Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces, ITS '09, ACM (New York, NY, USA, 2009), 61--64.  Google ScholarDigital LibraryArgelaguet, F., and Andujar, C. A survey of 3d object selection techniques for virtual environments. Computers &amp; Graphics 37, 3 (2013), 121--136.  Google ScholarDigital LibraryArgelaguet, F., Hoyet, L., Trico, M., and L\u00e9cuyer, A. The role of interaction in virtual embodiment: Effects of the virtual hand representation. In Virtual Reality (VR), 2016 IEEE, IEEE (2016), 3--10.Google ScholarAzmandian, M., Hancock, M., Benko, H., Ofek, E., and Wilson, A. D. Haptic retargeting: Dynamic repurposing of passive haptics for enhanced virtual reality experiences. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, ACM (2016), 1968--1979.  Google ScholarDigital LibraryBanakou, D., Groten, R., and Slater, M. Illusory ownership of a virtual child body causes overestimation of object sizes and implicit attitude changes. Proceedings of the National Academy of Sciences 110, 31 (2013), 12846--12851.Google ScholarCross RefBeaudouin-Lafon, M. Instrumental interaction: an interaction model for designing post-wimp user interfaces. In Proceedings of the SIGCHI conference on Human Factors in Computing Systems, ACM (2000), 446--453.  Google ScholarDigital LibraryBotvinick, M., and Cohen, J. Rubber hands 'feel' touch that eyes see. Nature 391, 6669 (1998), 756--756.Google ScholarCross RefBowman, D. A., Coquillart, S., Froehlich, B., Hirose, M., Kitamura, Y., Kiyokawa, K., and Stuerzlinger, W. 3d user interfaces: New directions and perspectives. IEEE computer graphics and applications, 6 (2008), 20--36.  Google ScholarDigital LibraryBraun, N., Thorne, J. D., Hildebrandt, H., and Debener, S. Interplay of agency and ownership: The intentional binding and rubber hand illusion paradigm combined. PloS one 9, 11 (2014), e111967.Google ScholarBuchmann, V., Violich, S., Billinghurst, M., and Cockburn, A. Fingartips: gesture based direct manipulation in augmented reality. In Proceedings of the 2nd international conference on Computer graphics and interactive techniques in Australasia and South East Asia, ACM (2004), 212--221.  Google ScholarDigital LibraryCalvert, G., Spence, C., and Stein, B. E. The handbook of multisensory processes. MIT press, 2004.Google ScholarCasiez, G., Vogel, D., Balakrishnan, R., and Cockburn, A. The impact of control-display gain on user performance in pointing tasks. Human-Computer Interaction 23, 3 (2008), 215--250.Google ScholarCross RefCaspar, E. A., Cleeremans, A., and Haggard, P. The relationship between human agency and embodiment. Consciousness and cognition 33 (2015), 226--236.Google ScholarCostantini, M., and Haggard, P. The rubber hand illusion: sensitivity and reference frame for body ownership. Consciousness and cognition 16, 2 (2007), 229--240.Google ScholarDummer, T., Picot-Annand, A., Neal, T., and Moore, C. Movement and the rubber hand illusion. Perception 38, 2 (2009), 271.Google ScholarCross RefEhrsson, H. The concept of body ownership and its relation to multisensory integration. The New Handbook of Multisensory Processes - B. E. Stein (Ed.) (2012), 775--792. MIT Press (Cambridge).Google ScholarEhrsson, H. H., Holmes, N. P., and Passingham, R. E. Touching a rubber hand: feeling of body ownership is associated with activity in multisensory brain areas. The Journal of Neuroscience 25, 45 (2005), 10564--10573.Google ScholarCross RefEhrsson, H. H., Spence, C., and Passingham, R. E. That's my hand! activity in premotor cortex reflects feeling of ownership of a limb. Science 305, 5685 (2004), 875--877.Google ScholarCross RefFranck, N., Farrer, C., Georgieff, N., Marie-Cardine, M., Dal\u00e9ry, J., d'Amato, T., and Jeannerod, M. Defective recognition of one's own actions in patients with schizophrenia. American Journal of Psychiatry 158, 3 (2001), 454--459.Google ScholarCross RefFraser, M., Benford, S., Hindmarsh, J., and Heath, C. Supporting awareness and interaction through collaborative virtual interfaces. In Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology, UIST '99, ACM (New York, NY, USA, 1999), 27--36.  Google ScholarDigital LibraryFrees, S., Kessler, G. D., and Kay, E. Prism interaction for enhancing control in immersive virtual environments. ACM Transactions on Computer-Human Interaction (TOCHI) 14, 1 (2007), 2.  Google ScholarDigital LibraryGallo, L., Ciampi, M., and Minutolo, A. Smoothed pointing: a user-friendly technique for precision enhanced remote pointing. In Complex, Intelligent and Software Intensive Systems (CISIS), 2010 International Conference on, IEEE (2010), 712--717.  Google ScholarDigital LibraryGuterstam, A., Petkova, V. I., and Ehrsson, H. H. The illusion of owning a third arm. PloS one 6, 2 (2011), e17208.Google ScholarHilliges, O., Kim, D., Izadi, S., Weiss, M., and Wilson, A. Holodesk: direct 3d interactions with a situated see-through display. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, ACM (2012), 2421--2430.  Google ScholarDigital LibraryHindmarsh, J., Fraser, M., Heath, C., Benford, S., and Greenhalgh, C. Object-focused interaction in collaborative virtual environments. ACM Trans. Comput.-Hum. Interact. 7, 4 (Dec. 2000), 477--509.  Google ScholarDigital LibraryHolz, C., Grossman, T., Fitzmaurice, G., and Agur, A. Implanted user interfaces. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, ACM (2012), 503--512.  Google ScholarDigital LibraryHutchins, E. L., Hollan, J. D., and Norman, D. A. Direct manipulation interfaces. Human-Computer Interaction 1, 4 (1985), 311--338.  Google ScholarDigital LibraryIjsselsteijn, W., de Kort, Y., and Haans, A. Is this my hand i see before me? the rubber hand illusion in reality, virtual reality, and mixed reality. Presence 15, 4 (2006), 455--464.  Google ScholarDigital LibraryIshii, H., Lakatos, D., Bonanni, L., and Labrune, J.-B. Radical atoms: Beyond tangible bits, toward transformable materials. interactions 19, 1 (Jan. 2012), 38--51.  Google ScholarDigital LibraryJenkinson, P. M., and Preston, C. New reflections on agency and body ownership: The moving rubber hand illusion in the mirror. Consciousness and cognition 33 (2015), 432--442.Google ScholarKalckert, A., and Ehrsson, H. H. The moving rubber hand illusion revisited: Comparing movements and visuotactile stimulation to induce illusory ownership. Consciousness and cognition 26 (2014), 117--132.Google ScholarKalckert, A., and Ehrsson, H. H. The spatial distance rule in the moving and classical rubber hand illusions. Consciousness and cognition 30 (2014), 118--132.Google ScholarKilteni, K., Bergstrom, I., and Slater, M. Drumming in immersive virtual reality: the body shapes the way we play. Visualization and Computer Graphics, IEEE Transactions on 19, 4 (2013), 597--605.  Google ScholarDigital LibraryKilteni, K., Maselli, A., Kording, K. P., and Slater, M. Over my fake body: body ownership illusions for studying the multisensory basis of own-body perception. Frontiers in human neuroscience 9 (2015).Google ScholarKilteni, K., Normand, J.-M., Sanchez-Vives, M. V., and Slater, M. Extending body space in immersive virtual reality: a very long arm illusion. PloS one 7, 7 (2012), e40867.Google ScholarKokkinara, E., and Slater, M. Measuring the effects through time of the influence of visuomotor and visuotactile synchronous stimulation on a virtual body ownership illusion. Perception 43, 1 (2014), 43--58.Google ScholarCross RefK\u00f6nig, W. A., Gerken, J., Dierdorf, S., and Reiterer, H. Adaptive pointing: implicit gain adaptation for absolute pointing devices. In CHI'09 Extended Abstracts on Human Factors in Computing Systems, ACM (2009), 4171--4176.  Google ScholarDigital LibraryLin, L., and J\u00f6rg, S. Need a hand? How appearance affects the virtual hand illusion. In Proceedings of the ACM Symposium on Applied Perception, SAP '16, ACM (New York, NY, USA, 2016), 69--76.  Google ScholarDigital LibraryMaravita, A., Spence, C., and Driver, J. Multisensory integration and the body schema: close to hand and within reach. Current Biology 13, 13 (2003), R531--R539.Google ScholarCross RefMaselli, A., and Slater, M. The building blocks of the full body ownership illusion. Frontiers in human neuroscience 7 (2013).Google ScholarNancel, M., Pietriga, E., Chapuis, O., and Beaudouin-Lafon, M. Mid-air pointing on ultra-walls. ACM Transactions on Computer-Human Interaction (TOCHI) 22, 5 (2015), 21.  Google ScholarDigital LibraryParker, J. K., Mandryk, R. L., and Inkpen, K. M. Tractorbeam: Seamless integration of local and remote pointing for tabletop displays. In Proceedings of Graphics Interface 2005, GI '05, Canadian Human-Computer Communications Society (School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada, 2005), 33--40. Google ScholarDigital LibraryPetkova, V. I., and Ehrsson, H. H. If i were you: perceptual illusion of body swapping. PloS one 3, 12 (2008), e3832.Google ScholarPoupyrev, I., Billinghurst, M., Weghorst, S., and Ichikawa, T. The go-go interaction technique: non-linear mapping for direct manipulation in vr. In Proceedings of the 9th annual ACM symposium on User interface software and technology, ACM (1996), 79--80.  Google ScholarDigital LibraryRiemer, M., Fuchs, X., Bublatzky, F., Kleinb\u00f6hl, D., H\u00fclzl, R., and Trojan, J. The rubber hand illusion depends on a congruent mapping between real and artificial fingers. Acta psychologica 152 (2014), 34--41.Google ScholarShimada, S., Fukuda, K., and Hiraki, K. Rubber hand illusion under delayed visual feedback. PloS one 4, 7 (2009), e6185.Google ScholarShneiderman, B. Direct manipulation: a step beyond programming languages. Sparks of innovation in human-computer interaction 17 (1983).  Google ScholarDigital LibrarySlater, M., Perez-Marcos, D., Ehrsson, H. H., and Sanchez-Vives, M. V. Towards a digital body: the virtual arm illusion. Frontiers in human neuroscience 2 (2008).Google ScholarSlater, M., Perez-Marcos, D., Ehrsson, H. H., and Sanchez-Vives, M. V. Inducing illusory ownership of a virtual body. Frontiers in neuroscience 3, 2 (2009), 214.Google ScholarSlater, M., Spanlang, B., Sanchez-Vives, M. V., and Blanke, O. First person experience of body transfer in virtual reality. PloS one 5, 5 (2010), e10564.Google ScholarSteptoe, W., Steed, A., and Slater, M. Human tails: ownership and control of extended humanoid avatars. Visualization and Computer Graphics, IEEE Transactions on 19, 4 (2013), 583--590.  Google ScholarDigital LibraryTelea, A. An image inpainting technique based on the fast marching method. Journal of graphics tools 9, 1 (2004), 23--34.Google ScholarTieri, G., Tidoni, E., Pavone, E., and Aglioti, S. Mere observation of body discontinuity affects perceived ownership and vicarious agency over a virtual hand. Experimental brain research 233, 4 (2015), 1247--1259.Google ScholarTsakiris, M., Carpenter, L., James, D., and Fotopoulou, A. Hands only illusion: multisensory integration elicits sense of ownership for body parts but not for non-corporeal objects. Experimental Brain Research 204, 3 (2010), 343--352.Google ScholarCross RefTsakiris, M., Prabhu, G., and Haggard, P. Having a body versus moving your body: How agency structures body-ownership. Consciousness and cognition 15, 2 (2006), 423--432.Google Scholarvan der Hoort, B., and Ehrsson, H. H. Body ownership affects visual perception of object size by rescaling the visual representation of external space. Attention, Perception, &amp; Psychophysics 76, 5 (2014), 1414--1428.Google ScholarVogel, D., and Balakrishnan, R. Distant freehand pointing and clicking on very large, high resolution displays. In Proceedings of the 18th Annual ACM Symposium on User Interface Software and Technology, UIST '05, ACM (New York, NY, USA, 2005), 33--42.  Google ScholarDigital LibraryWalsh, L. D., Moseley, G. L., Taylor, J. L., and Gandevia, S. C. Proprioceptive signals contribute to the sense of body ownership. The Journal of physiology 589, 12 (2011), 3009--3021.Google ScholarZhang, J., Chen, W., Li, H., Hommel, B., and Yuan, T. Disentangling the sense of agency and the sense of ownership in the virtual hand illusion paradigm. Tech. rep., PeerJ PrePrints, 2014.Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3025453.3025689/c3394632-dd26-40cb-bc10-e3e6ab094ec5/pn2199p.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee07e5e64ad2301e1e02b6a6c2861642b59a9b62fe4346f371b790cf18099fc5424951bfc9c09a665a49cc998af4c26130f28e934e6528c98704c6f1a78c9a78c98140badb5ad2bd63application/x-mpegurlmp43.9 MB", "keywords": ["virtual hand illusion", "ubiquitous computing", "ownership", "augmented reality"], "published_in": "CHI '17: Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2017", "citations": "12", "isbn": "9781450346559", "doi": "10.1145/3025453", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3025453.3025689", "paper_url": "https://dl.acm.org/doi/10.1145/3025453.3025689"}, {"title": "Direct Finger Manipulation of 3D Object Image with Ultrasound Haptic Feedback", "authors": ["Atsushi Matsubayashi", "Yasutoshi Makino", "Hiroyuki Shinoda"], "abstract": "In this study, we prototype and examine a system that allows a user to manipulate a 3D virtual object with multiple fingers without wearing any device. An autostereoscopic display produces a 3D image and a depth sensor measures the movement of the fingers. When a user touches a virtual object, haptic feedback is provided by ultrasound phased arrays. By estimating the cross section of the finger in contact with the virtual object and by creating a force pattern around it, it is possible for the user to recognize the position of the surface relative to the finger. To evaluate our system, we conducted two experiments to show that the proposed feedback method is effective in recognizing the object surface and thereby enables the user to grasp the object quickly without seeing it.", "keywords": ["touch/haptic/pointing/gesture", "virtual/augmented reality"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "3", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300317", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300317"}, {"title": "Quantitative measurement of virtual vs. physical object embodiment through kinesthetic figural after effects", "authors": ["Ayman Alzayat", "Mark Hancock", "Miguel Nacenta"], "abstract": "Over the past decade, multi-touch surfaces have become commonplace, with many researchers and practitioners describing the benefits of their natural, physical-like interactions. We present a pair of studies that empirically investigates the psychophysical effects of direct interaction with both physical and virtual artefacts. We use the phenomenon of Kinesthetic Figural After Effects-a change in understanding of the physical size of an object after a period of exposure to an object of different size. Our studies show that, while this effect is robustly reproducible when using physical artefacts, this same effect does not manifest when manipulating virtual artefacts on a direct, multi-touch tabletop display. We contribute quantitative evidence suggesting a psychophysical difference in our response to physical vs. virtual objects, and discuss future research directions to explore measurable phenomena to evaluate the presence of physical-like changes from virtual on-screen objects.                     References                 Arzy, S., Thut, G., Mohr, C., Michel, C.M., and Blanke, O. Neural basis of embodiment: distinct contributions of temporoparietal junction and extrastriate body area. Journal of Neuroscience 26, 31 (2006), 8074--8081.Google ScholarCross RefBenford, S., Browers, J., Fahlen, E.L., Greenhalgh, C., Snowdon, D. User embodiment in collaborative virtual environments. In Proc. CHI, ACM Press (1995), 242249.  Google ScholarDigital LibraryBenko, H., Harrison, C., Wilson, A.D. OmniTouch: Wearable Multitouch Interaction Everywhere. In Proc. UIST, ACM Press (2011), 441--450.  Google ScholarDigital LibraryBotvinick, M. &amp; Cohen, J. Rubber hands 'feel' touch that eyes see. Nature 391, 6669 (1998), 756.Google ScholarBrozzoli, C., Cardinali L., Pavani F., and Farn\u00e8 A. Action-specific remapping of peripersonal space. Neuropsychologia 48, 3 (2010), 796--802.Google ScholarCross RefBuxton, B., Multi-touch Systems that I Have Known and Loved. http://www.billbuxton.com/multitouchOverview.html. Original: 2007. Last retrieved: Jan 2014.Google ScholarCardinali, L., Frassinetti, F., Brozzoli, C., Urquizar, C., Roy, A. C., Farn\u00e8, A. Tool-use induces morphological updating of the body schema. Current Biology 19, 12 (2009), R478--R479.Google ScholarCross RefChurchill, A.V. Quantitative Tactual-Kinesthetic Judgment. Perceptual and Motor Skills 20 (1965), 1147--1148.Google ScholarCross RefCoyle, D., Moore, J. Kristensson, P.O., Fletcher, P.C., Blackwell, A.F. I did that! Measuring Users-Experience of Agency in their own Actions. In Proc. CHI'12.  Google ScholarDigital LibraryDourish, P. Where the Action Is: The Foundations of Embodied Interaction. MIT Press, 2001. Google ScholarDigital LibraryDurgin, F.H., Evans, L., Dunphy, N., Klostermann, S., Simmons, K. Rubber hands feel the touch of light. Psychological Science 18, 2 (2007), 152--157.Google ScholarCross RefGibson, J. J. The visual perception of objective motion and subjective movement. Psychol. Rev 61 (1954), 304--314.Google ScholarGibson, J. J., &amp; Backlund, F. An aftereffect in haptic space perception. Quart. J. Exp. Psychol, (1963).Google ScholarGibson, J. J. The perception of visual surfaces. Amer. J. Psychol, 43 (1950), 367--384.Google ScholarCross RefHancock, M., Cate, T.T., and Carpendale, S. Sticky tools: Full 6DOF force-based interaction for multi-touch tables. In Proc. ITS, ACM Press (2009), 133--140.  Google ScholarDigital LibraryHeinemann, E.G. Figural after effects in kinesthesis: Effects of object width and repeated presentations. Journal of Experimental Psychology 61, 1 (1961), 51--56.Google ScholarCross RefHolmes, N.P. and Spence, C. Beyond the body schema: Visual, prosthetic, and technological contributions tobodily perception and awareness. Human body perception from the inside out, (2006), 15--64.Google ScholarIshii, H., Lakatos, D., Bonanni, L., Labrune, J.B. Radical atoms: beyond tangible bits, toward transformable materials. Interactions 19 (2012), 38--51.  Google ScholarDigital LibraryJord\u00e0, S., Geiger, G. Alonso, M., Kaltenbrunner, M., The reacTable: exploring the synergy between live music performance and tabletop tangible interfaces. In Proc. TEI, ACM Press (2007), 139--146.  Google ScholarDigital LibraryKelvin, R. P. Discrimination of size by sight and touch. Quart. J. exp. Psychol 69, 6 (1954), 23--34.Google ScholarKidd, A.H., Beere, D.B. Relationship between kinaesthetic figural aftereffect and certain personality variables. Perceptual and Motor Skills 26 (1968) 577--587.Google ScholarCross RefKohler, W., and Dinnerstein, D. Figural after-effects in kinaesthesis. Miscellanea psychologica Albert Michotte. Louvain: Editions de 1'Institut Superieur de Philosophie, (1949), 196--220.Google ScholarLeap Motion. http://www.leapmotion.com. Last retrieved: Jan 2014.Google ScholarMaravita, A. and Iriki, A. Tools for the body (schema). TRENDS in Cognitive Sciences 8, 2 (2004), 79--86.Google ScholarCross RefMarino, B., Stucchi, N., Nava, E., Haggard, P., and Maravita, A. Distorting the visual size of the hand affects hand pre-shaping during grasping. Experimental Brain Research 202, 2 (2010), 499--505.Google ScholarCross RefMcDonnell, P.M., Scott, R.N., Dickison, J., Theriault, R.A., Wood, B. Do artificial limbs become part of the user? New evidence. Journal of Rehabilitation Research and Development 26, 2 (1989), 17--24.Google ScholarNacenta, M.A., Pinelle, D., Gutwin, C., Mandryk, R. Individual and group support in tabletop interaction techniques. In Tabletops -- Horizontal Interactive Displays, C. M\u00fcller-Tomfelde, Ed. Springer (2010), 303--333.Google ScholarPatel, H. and Morreale, P. 2014. Education and learning: electronic books or traditional printed books? J. Comput. Sci. Coll. 29, 3 (2014), 21--28. Google ScholarDigital LibraryPetrie, A. Individuality in pain and suffering (2nd ed.). U. Chicago Press, 1978, 107--127.Google ScholarPhelan J.G, Brooks R., Brashears G.C. Relationship of kinesthetic figural aftereffect to masculinity-femininity and expectation for internal versus external control of reinforcement. Perceptual and Motor Skills 31 (1970), 863--866.Google ScholarCross RefPlatt, D., Holzman, P.S., Larson, D. Individual consistencies in kinesthetic figural aftereffects. Perceptual and Motor Skills 32 (1971), 787--795.Google ScholarCross RefPolanyi, M. The tacit dimension. Anchor Books, Garden City, N.Y, 1966.Google ScholarProcessing. http://processing.org. Last retrieved: Jan 2014.Google ScholarReactable Systems S.L., Reactable Mobile. http://reactable.com/products/mobile/. Last retrieved: Jan 2014.Google ScholarSheridan, T.B. Further musings on the psychophysics of presence. Systems, Man, and Cybernetics 2 (1994), 1073--1077.Google ScholarTang, A., Neustaedter, C., Greenberg, S. VideoArms: Embodiments for mixed presence groupware. In People and Computers XX -- Engage, N. Bryann-Kinns, A. Blanford, P. Curzon, L. Nigay, Eds., Springer (2010), 85--102.Google ScholarUllmer, B., Ishii, H. Emerging frameworks for tangible user interfaces. IBM Systems Journal 39 (2000), 915--931.  Google ScholarDigital Libraryde Vignemont, F. Embodiment, ownership and disownership. Consciousness and Cognition 20 (2010), 82--93.Google ScholarCross RefWelch, R.B. and Warren, D.H. Immediate perceptual response to intersensory discrepancy. Psychological Bulletin 88, 3 (1980), 638--667.Google ScholarCross Ref                                                                                                Index Terms                 Quantitative measurement of virtual vs. physical object embodiment through kinesthetic figural after effectsHuman-centered computing", "keywords": ["embodied interaction", "tabletop displays", "multi-touch", "tangible user interfaces", "physical interaction"], "published_in": "CHI '14: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "26 April 2014", "citations": "5", "isbn": "9781450324731", "doi": "10.1145/2556288", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2556288.2557282", "paper_url": "https://dl.acm.org/doi/10.1145/2556288.2557282"}, {"title": "On the Shoulder of the Giant: A Multi-Scale Mixed Reality Collaboration with 360 Video Sharing and Tangible Interaction", "authors": ["Thammathip Piumsomboon", "Gun A. Lee", "Andrew Irlitti", "Barrett Ens", "Bruce H. Thomas", "Mark Billinghurst"], "abstract": "We propose a multi-scale Mixed Reality (MR) collaboration between the Giant, a local Augmented Reality user, and the Miniature, a remote Virtual Reality user, in Giant-Miniature Collaboration (GMC). The Miniature is immersed in a 360-video shared by the Giant who can physically manipulate the Miniature through a tangible interface, a combined 360-camera with a 6 DOF tracker. We implemented a prototype system as a proof of concept and conducted a user study (n=24) comprising of four parts comparing: A) two types of virtual representations, B) three levels of Miniature control, C) three levels of 360-video view dependencies, and D) four 360-camera placement positions on the Giant. The results show users prefer a shoulder mounted camera view, while a view frustum with a complimentary avatar is a good visualization for the Miniature virtual representation. From the results, we give design recommendations and demonstrate an example Giant-Miniature Interaction.                     References                 Sigurdur O Adalgeirsson and Cynthia Breazeal. 2010. MeBot: a robotic platform for socially embodied presence. in Proceedings of the 5th ACM/IEEE international conference on Human-robot interaction, IEEE Press, 15--22. Google ScholarDigital LibraryJudith Amores, Xavier Benavides and Pattie Maes. 2015. Showme: A remote collaboration system that supports immersive gestural communication. in Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems, ACM, 1343--1348.  Google ScholarDigital LibrarySathya Barathan, Gun A. Lee, Mark Billinghurst and Robert W. Lindeman. 2017. Sharing Gaze for Remote Instruction ICAT-EGVE 2017 - International Conference on Artificial Reality and Telexistence and Eurographics Symposium on Virtual Environments, The Eurographics Association. Google ScholarDigital LibraryStephan Beck, Andre Kunert, Alexander Kulik and Bernd Froehlich. 2013. Immersive group-to-group telepresence. IEEE Transactions on Visualization and Computer Graphics, 19 (4). 616--625.  Google ScholarDigital LibraryMark Billinghurst, Hirokazu Kato and Ivan Poupyrev. 2001. The MagicBook: a transitional AR interface. Computers &amp; Graphics, 25 (5). 745--753.Google ScholarCross RefMark Billinghurst, Alaeddin Nassani and Carolin Reichherzer. 2014. Social panoramas: using wearable computers to share experiences. in SIGGRAPH Asia 2014 Mobile Graphics and Interactive Applications, ACM, 25.  Google ScholarDigital LibraryScott Brave, Hiroshi Ishii and Andrew Dahley. 1998. Tangible interfaces for remote collaboration and communication Proceedings of the 1998 ACM conference on Computer supported cooperative work, ACM, Seattle, Washington, USA, 169--178.  Google ScholarDigital LibraryMinghao Cai, Soh Masuko and Jiro Tanaka. 2018. Gesture-based Mobile Communication System Providing Side-by-side Shopping Feeling. in Proceedings of the 23rd International Conference on Intelligent User Interfaces Companion, ACM, 2.  Google ScholarDigital LibraryKatherine M. Everitt, Scott R. Klemmer, Robert Lee and James A. Landay. 2003. Two worlds apart: bridging the gap between physical and virtual media for distributed design collaboration Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, ACM, Ft. Lauderdale, Florida, USA, 553--560.  Google ScholarDigital LibraryFaro. FOCUS-M 70. Retrieved January 1, 2019 from https://www.faro.com/en-sg/products/construction-bim/faro-laserscanner-focus/.Google ScholarC\u00e9dric Fleury, Alain Chauffaut, Thierry Duval, Val\u00e9rie Gouranton and Bruno Arnaldi. 2010. A Generic Model for Embedding Users' Physical Workspaces into Multi-Scale Collaborative Virtual Environments. in ICAT 2010 (20th International Conference on Artificial Reality and Telexistence), Adelaide, Australia.Google ScholarSusan R Fussell, Leslie D Setlock and Robert E Kraut. 2003. Effects of head-mounted and scene-oriented video systems on remote collaboration on physical tasks. in Proceedings of the SIGCHI conference on Human factors in computing systems, ACM, 513--520.  Google ScholarDigital LibrarySusan R Fussell, Leslie D Setlock, Jie Yang, Jiazhi Ou, Elizabeth Mauer and Adam DI Kramer. 2004. Gestures over video streams to support remote collaboration on physical tasks. Human-Computer Interaction, 19 (3). 273--309.  Google ScholarDigital LibraryLei Gao, Huidong Bai, Gun Lee and Mark Billinghurst. 2016. An oriented point-cloud view for MR remote collaboration. in SIGGRAPH ASIA 2016 Mobile Graphics and Interactive Applications, ACM, 8.  Google ScholarDigital LibraryLei Gao, Huidong Bai, Thammathip Piumsomboon, G Lee, Robert W Lindeman and Mark Billinghurst. 2017. Real-time Visual Representations for Mixed Reality Remote Collaboration.Google ScholarGarmin. VIRB 360. Retrieved January 1, 2019 from https://buy.garmin.com/en-AU/AU/p/562010.Google ScholarSteffen Gauglitz, Cha Lee, Matthew Turk and Tobias H\u00f6llerer. 2012. Integrating the physical environment into mobile remote collaboration. in Proceedings of the 14th international conference on Human-computer interaction with mobile devices and services, ACM, 241--250.  Google ScholarDigital LibrarySteffen Gauglitz, Benjamin Nuernberger, Matthew Turk and Tobias H\u00f6llerer. 2014. In touch with the remote world: Remote collaboration with augmented reality drawings and virtual navigation. in Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology, ACM, 197--205.  Google ScholarDigital LibrarySteffen Gauglitz, Benjamin Nuernberger, Matthew Turk and Tobias H\u00f6llerer. 2014. World-stabilized annotations and virtual scene navigation for remote collaboration. in Proceedings of the 27th annual ACM symposium on User interface software and technology, ACM, 449--459.  Google ScholarDigital LibraryJan Gugenheimer, Evgeny Stemasov, Julian Frommel and Enrico Rukzio. 2017. ShareVR: Enabling Co-Located Experiences for Virtual Reality between HMD and Non-HMD Users Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, ACM, Denver, Colorado, USA, 4021--4033.  Google ScholarDigital LibraryKunal Gupta, Gun A Lee and Mark Billinghurst. 2016. Do You See What I See? The Effect of Gaze Tracking on Task Space Remote Collaboration. IEEE Transactions on Visualization and Computer Graphics, 22 (11). 2413--2422.Google ScholarCross RefChad Harms and Frank Biocca. 2004. Internal consistency and reliability of the networked minds measure of social presence In M. Alcaniz &amp; B. Rey (Eds.), Seventh Annual International Workshop: Presence 2004, Valencia: Universidad Politecnica de Valencia.Google ScholarKeita Higuchi, Katsuya Fujii and Jun Rekimoto. 2013. Flying head: A head-synchronization mechanism for flying telepresence. in 2013 23rd International Conference on Artificial Reality and Telexistence (ICAT), 28--34.Google ScholarCross RefKeita Higuchi, Ryo Yonetani and Yoichi Sato. 2016. Can Eye Help You?: Effects of Visualizing Eye Fixations on Remote Collaboration Scenarios for Physical Tasks. in Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, ACM, 51805190.  Google ScholarDigital LibraryHTC. Vive. Retrieved January 1, 2019 from https://www.vive.com/au/product/.Google ScholarHTC. Vive Pro, Retrieved January 1, 2019 from https://www.vive.com/au/product/vive-pro/.Google ScholarHTC. Vive SRWorks SDK. Retrieved January 1, 2019 from https://developer.vive.com/resources/knowledgebase/intro-vivesrworks-sdk/.Google ScholarHTC. Vive Tracker. Retrieved January 1, 2019 from https://www.vive.com/au/vive-tracker/.Google ScholarHiroshi Ishii. 2008. The tangible user interface and its evolution. Communications of the ACM, 51 (6). 32--36.  Google ScholarDigital LibraryShunichi Kasahara, Shohei Nagai and Jun Rekimoto. 2017. JackIn Head: Immersive Visual Telepresence System with Omnidirectional Wearable Camera. IEEE Transactions on Visualization and Computer Graphics, 23 (3). 1222--1234.  Google ScholarDigital LibraryRobert S Kennedy, Norman E Lane, Kevin S Berbaum and Michael G Lilienthal. 1993. Simulator sickness questionnaire: An enhanced method for quantifying simulator sickness. The international journal of aviation psychology, 3 (3). 203--220.Google ScholarSeungwon Kim, Mark Billinghurst and Gun Lee. 2018. The Effect of Collaboration Styles and View Independence on Video-Mediated Remote Collaboration. Computer Supported Cooperative Work (CSCW). 1--39.  Google ScholarDigital LibrarySeungwon Kim, Gun A Lee, Nobuchika Sakata, Andreas Dunser, Elina Vartiainen and Mark Billinghurst. 2013. Study of augmented gesture communication cues and view sharing in remote collaboration. in Mixed and Augmented Reality (ISMAR), 2013 IEEE International Symposium on, IEEE, 261--262.Google ScholarCross RefSeungwon Kim, Gun Lee, Nobuchika Sakata and Mark Billinghurst. 2014. Improving co-presence with augmented visual communication cues for sharing experience through video conference. in Mixed and Augmented Reality (ISMAR), 2014 IEEE International Symposium on, IEEE, 83--92.Google ScholarCross RefKiyoshi Kiyokawa, Haruo Takemura and Naokazu Yokoya. 1999. A collaboration support technique by integrating a shared virtual reality and a shared augmented reality. in Systems, Man, and Cybernetics, 1999. IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on, IEEE, 48--53.Google ScholarScott R. Klemmer, Mark W. Newman, Ryan Farrell, Mark Bilezikjian and James A. Landay. 2001. The designers' outpost: a tangible interface for collaborative web site Proceedings of the 14th annual ACM symposium on User interface software and technology, ACM, Orlando, Florida, 1--10.  Google ScholarDigital LibraryRegis Kopper, Tao Ni, Doug A Bowman and Marcio Pinho. 2006. Design and evaluation of navigation techniques for multiscale virtual environments. in Virtual Reality Conference, 2006, Ieee, 175182.  Google ScholarDigital LibraryTakeshi Kurata, Nobuchika Sakata, Masakatsu Kourogi, Hideaki Kuzuoka and Mark Billinghurst. 2004. Remote collaboration using a shoulder-worn active camera/laser. in Eighth International Symposium on Wearable Computers, 62--69.  Google ScholarDigital LibraryHideaki Kuzuoka, Shinya Oyama, Keiichi Yamazaki, Kenji Suzuki and Mamoru Mitsuishi. 2000. GestureMan: a mobile robot that embodies a remote instructor's actions Proceedings of the 2000 ACM conference on Computer supported cooperative work, ACM, Philadelphia, Pennsylvania, USA, 155--162.  Google ScholarDigital LibraryJoel Lanir, Ran Stone, Benjamin Cohen and Pavel Gurevich. 2013. Ownership and control of point of view in remote assistance Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, ACM, Paris, France, 2243--2252.  Google ScholarDigital LibraryMorgan Le Ch\u00e9n\u00e9chal, Thierry Duval, Val\u00e9rie Gouranton, J\u00e9r\u00f4me Royan and Bruno Arnaldi. 2016. Vishnu: virtual immersive support for HelpiNg users an interaction paradigm for collaborative remote guiding in mixed reality. in Collaborative Virtual Environments (3DCVE), 2016 IEEE Third VR International Workshop on, IEEE, 9--12.Google ScholarMorgan Le Ch\u00e9n\u00e9chal, J\u00e9r\u00e9my Lacoche, J\u00e9r\u00f4me Royan, Thierry Duval, Val\u00e9rie Gouranton and Bruno Arnaldi. 2016. When the giant meets the ant an asymmetric approach for collaborative and concurrent object manipulation in a multi-scale environment. in Collaborative Virtual Environments (3DCVE), 2016 IEEE Third VR International Workshop on, IEEE, 18--22.Google ScholarGun A Lee, Seungwon Kim, Youngho Lee, Arindam Dey, Thammathip Piumsomboon, Mitchell Norman and Mark Billinghurst. 2017. Improving Collaboration in Augmented Video Conference using Mutually Shared Gaze.Google ScholarGun A Lee, Theophilus Teo, Seungwon Kim and Mark Billinghurst. 2017. Mixed reality collaboration through sharing a live panorama. in SIGGRAPH Asia 2017 Mobile Graphics &amp; Interactive Applications, ACM, 14.  Google ScholarDigital LibraryGun A Lee, Theophilus Teo, Seungwon Kim and Mark Billinghurst. 2018. A User Study on MR Remote Collaboration using Live 360 Video 2018 IEEE International Symposium on Mixed and Augmented Reality (ISMAR '18)., 153--164Google ScholarDaniel Leithinger, Sean Follmer, Alex Olwal and Hiroshi Ishii. 2014. Physical telepresence: shape capture and display for embodied, computer-mediated remote collaboration Proceedings of On the Shoulder of the Giant CHI'19, May 4--9, 2019, Glasgow, Scotland UK the 27th annual ACM symposium on User interface software and technology, ACM, Honolulu, Hawaii, USA, 461--470.  Google ScholarDigital LibraryTamotsu Machino, Satoshi Iwaki, Hiroaki Kawata, Yoshimasa Yanagihara, Yoshito Nanjo and Kenichiro Shimokura. 2006. Remote-collaboration system using mobile robot with camera and projector. in Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006., 4063--4068.Google ScholarCross RefAkira Matsuda, Takashi Miyaki and Jun Rekimoto. 2017. ScalableBody: a telepresence robot that supports face position matching using a vertical actuator Proceedings of the 8th Augmented Human International Conference, ACM, Silicon Valley, California, USA, 1--9.  Google ScholarDigital LibraryPaul Milgram and Fumio Kishino. 1994. A taxonomy of mixed reality visual displays. IEICE TRANSACTIONS on Information and Systems, 77 (12). 1321--1329.Google ScholarJ\u00f6rg M\u00fcller, Tobias Langlotz and Holger Regenbrecht. 2016. PanoVC: Pervasive telepresence using mobile phones. in Pervasive Computing and Communications (PerCom), 2016 IEEE International Conference on, IEEE, 1--10.Google ScholarCross RefBenjamin Nuernberger, Kuo-Chin Lien, Tobias H\u00f6llerer and Matthew Turk. 2016. Interpreting 2d gesture annotations in 3d augmented reality. in 3D User Interfaces (3DUI), 2016 IEEE Symposium on, IEEE, 149--158.Google ScholarBenjamin Nuernberger, Matthew Turk and Tobias H\u00f6llerer. 2017. Evaluating snapping-to-photos virtual travel interfaces for 3D reconstructed visual reality. in Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology, ACM, 22.  Google ScholarDigital LibraryOhan Oda, Carmine Elvezio, Mengu Sukan, Steven Feiner and Barbara Tversky. 2015. Virtual replicas for remote assistance in virtual and augmented reality. in Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology, ACM, 405--415.  Google ScholarDigital LibraryCorey Pittman and Joseph J LaViola Jr. 2014. Exploring head tracked head mounted displays for first person robot teleoperation. in Proceedings of the 19th international conference on Intelligent User Interfaces, ACM, 323--328.  Google ScholarDigital LibraryThammathip Piumsomboon, Gun A Lee, Barrett Ens, Bruce H Thomas and Mark Billinghurst. 2018. Superman vs Giant: A Study on Spatial Perception for a Multi-Scale Mixed Reality Flying Telepresence Interface. IEEE Transactions on Visualization and Computer Graphics. 1--1.Google ScholarCross RefThammathip Piumsomboon, Arindam Day, Barrett Ens, Youngho Lee, Gun Lee and Mark Billinghurst. 2017. Exploring enhancements for remote mixed reality collaboration SIGGRAPH Asia 2017 Mobile Graphics &amp; Interactive Applications, ACM, Bangkok, Thailand, 1--5.  Google ScholarDigital LibraryThammathip Piumsomboon, Gun A Lee and Mark Billinghurst. 2018. Snow Dome: A Multi-Scale Interaction in Mixed Reality Remote Collaboration. in Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems, ACM, D115.  Google ScholarDigital LibraryThammathip Piumsomboon, Gun A Lee, Jonathon D Hart, Barrett Ens, Robert W Lindeman, Bruce H Thomas and Mark Billinghurst. 2018. Mini-Me: An Adaptive Avatar for Mixed Reality Remote Collaboration. in Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, ACM, 46.  Google ScholarDigital LibraryVR QuickTime. 1995. An Image-Based Approach to Virtual Environment Navigation, Shenchang Eric Chen, Apple Computer, Inc. in Siggraph, Computer Graphics Proceedings, Annual Conference Series, 29--38.  Google ScholarDigital LibraryAbhishek Ranjan, Jeremy P. Birnholtz and Ravin Balakrishnan. 2007. Dynamic shared visual spaces: experimenting with automatic camera control in a remote repair task Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, ACM, San Jose, California, USA, 1177--1186.  Google ScholarDigital LibraryPeter Robinson and Philip Tuddenham. 2007. Distributed Tabletops: Supporting Remote and Mixed-Presence Tabletop Collaboration. in Second Annual IEEE International Workshop on Horizontal Interactive Human-Computer Systems (TABLETOP'07), 1926.Google ScholarBektur Ryskeldiev, Michael Cohen and Jens Herder. 2017. Applying rotational tracking and photospherical imagery to immersive mobile telepresence and live video streaming groupware. in SIGGRAPH Asia 2017 Mobile Graphics &amp; Interactive Applications, ACM, 5.  Google ScholarDigital LibraryNobuchika Sakata, Takeshi Kurata, Takekazu Kato, Masakatsu Kourogi and Hideaki Kuzuoka. 2003. WACL: Supporting telecommunications using wearable active camera with laser pointer. in null, IEEE, 53. Google ScholarDigital LibraryMHD Yamen Saraiji, Tomoya Sasaki, Reo Matsumura, Kouta Minamizawa and Masahiko Inami. 2018. Fusion: full body surrogacy for collaborative communication ACM SIGGRAPH 2018 Emerging Technologies, ACM, Vancouver, British Columbia, Canada, 1--2.  Google ScholarDigital LibraryJeff Sauro and Joseph S Dumas. 2009. Comparison of three onequestion, post-task usability questionnaires. in Proceedings of the SIGCHI conference on human factors in computing systems, ACM, 1599--1608.  Google ScholarDigital LibraryRajinder S. Sodhi, Brett R. Jones, David Forsyth, Brian P. Bailey and Giuliano Maciocci. 2013. BeThere: 3D mobile collaboration with spatial input Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, ACM, Paris, France, 179--188.  Google ScholarDigital LibraryOpen Broadcaster Software. OBS Studio. Retrieved January 1, 2019 from https://obsproject.com/.Google ScholarMatthew Tait and Mark Billinghurst. 2015. The Effect of View Independence in a Collaborative AR System. Comput. Supported Coop. Work, 24 (6). 563--589.  Google ScholarDigital LibraryAnthony Tang, Omid Fakourfar, Carman Neustaedter and Scott Bateman. 2017. Collaboration in 360 Videochat: Challenges and Opportunities, University of Calgary.Google ScholarFranco Tecchia, Leila Alem and Weidong Huang. 2012. 3D helping hands: a gesture based MR system for remote collaboration. in Proceedings of the 11th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry, ACM, 323--328.  Google ScholarDigital LibraryUnity3D. Unity3D Game Engine. Retrieved January 1, 2019 from https://unity3d.com.Google ScholarValve Corp. SteamVR Plugin for Unity. Retrieved January 1, 2019 from https://assetstore.unity.com/packages/templates/systems/steamvrplugin-32647.Google ScholarPeter Vorderer, Werner Wirth, Feliz Ribeiro Gouveia, Frank Biocca, Timo Saari, Lutz J\u00e4ncke, Saskia B\u00f6cking, Holger Schramm, Andre Gysbers and Tilo Hartmann. 2004. MEC Spatial Presence Questionnaire. Retrieved Sept, 18. 2015.Google ScholarJacob O Wobbrock, Leah Findlater, Darren Gergle and James J Higgins. 2011. The aligned rank transform for nonparametric factorial analyses using only anova procedures. in Proceedings of the SIGCHI conference on human factors in computing systems, ACM, 143--146.  Google ScholarDigital LibraryCatherine Zanbaka, Paula Goolkasian and Larry Hodges. 2006. Can a virtual cat persuade you?: the role of gender and realism in speaker persuasiveness. in Proceedings of the SIGCHI conference on Human Factors in computing systems, ACM, 1153--1162.  Google ScholarDigital LibraryXiaolong Zhang and George W Furnas. 2005. mCVEs: Using crossscale collaboration to support user interaction with multiscale structures. Presence: Teleoperators &amp; Virtual Environments, 14 (1). 31--46.  Google ScholarDigital LibrarySupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3290605.3300458/104ae155-32c3-44d5-ba0d-a8af286645ad/paper228.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee05eee35a4ac3e15fa134b9c32b159e34f95b7741acbfe77fb7fd67962f2edff7439d010f34c3e708f602b965432215f4be23ccd90255a32e703a31bdee13a69cd08fee92bbc7a54aapplication/x-mpegurlmp443.1 MB", "keywords": ["tangible user interface", "remote collaboration", "mixed reality", "wearable interface", "live panorama sharing", "multi-scale"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "15", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300458", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300458"}, {"title": "Imperceptible depth shifts for touch interaction with stereoscopic objects", "authors": ["Dimitar Valkov", "Alexander Giesler", "Klaus H. Hinrichs"], "abstract": "While touch technology has proven its usability for 2D interaction and has already become a standard input modality for many devices, the challenges to exploit its applicability with stereoscopically rendered content have barely been studied. In this paper we exploit the properties of the visual perception to allow users to touch stereoscopically displayed objects when the input is constrained to a 2D surface. Therefore, we have extended and generalized recent evaluations on the user's ability to discriminate small induced object shifts while reaching out to touch a virtual object, and we propose a practical interaction technique, the attracting shift technique, suitable for numerous application scenarios where shallow depth interaction is sufficient. In addition, our results indicate that slight object shifts during touch interaction make the virtual scene appear perceptually more stable compared to a static scene. As a consequence, applications have to manipulate the virtual objects to make them appear static for the user.                     References                 Benko, H., and Feiner, S. Balloon selection: A multi-finger technique for accurate low-fatigue 3d selection. In IEEE 3DUI (2007), 79--86.Google ScholarBenko, H., Wilson, A. D., and Baudisch, P. Precise selection techniques for multi-touch screens. In ACM CHI (2006), 1263--1272.  Google ScholarDigital LibraryBruder, G., Steinicke, F., and Stuerzlinger, W. Touching the void revisited: Analyses of touch behavior on and above tabletop surfaces. In IFIP TC13 INTERACT (2013).Google ScholarBurns, E., Razzaque, S., Panter, A. T., Whitton, M., McCallus, M., and Brooks, F. The Hand is Slower than the Eye: A Quantitative Exploration of Visual Dominance over Proprioception. In IEEE VR (2005), 3--10.  Google ScholarDigital LibraryChan, L.-W., Kao, H.-S., Chen, M. Y., Lee, M.-S., Hsu, J., and Hung, Y.-P. Touching the void: direct-touch interaction for intangible displays. In ACM CHI (2010), 2625--2634.  Google ScholarDigital LibraryGoodale, M. A., and Milner, A. D. Separate visual pathways for perception and action. Trends in Neurosciences (1992), 20--25.Google ScholarHachet, M., Bossavit, B., Coh\u00e9, A., and de la Rivi'ere, J.-B. Toucheo: Multitouch and stereo combined in a seamless workspace. In ACM UIST (2011), 587--592.  Google ScholarDigital LibraryHancock, M., Carpendale, S., and Cockburn, A. Shallow-depth 3d interaction: design and evaluation of one-, two- and three-touch techniques. In ACM CHI (2007), 1147--1156.  Google ScholarDigital Library9. Johansson, R. S., Westling, G., Bckstrm1, A., and Flanagan, J. R. Eye-Hand Coordination in Object Manipulation. Journal of Neuroscience 21, 17 (2001), 6917--6932.Google ScholarCross RefKohli, L. Redirected touching: Warping space to remap passive haptics. IEEE 3DUI (2010), 129--130.  Google ScholarDigital LibraryKooi, F. L., and Toet, A. Visual comfort of binocular and 3d displays. Displays 25, 23 (2004), 99--108.Google ScholarCross RefLiu, G., Chua, R., and Enns, J. T. Attention for perception and action: task interference for action planning, but not for online control. Experimental Brain Research 185 (2008), 709--717.Google ScholarCross RefMartinet, A., Casiez, G., and Grisoni, G. The design and evaluation of 3d positioning techniques for multi-touch displays. In IEEE 3DUI (2010).  Google ScholarDigital LibraryMather, G. Foundations of Sensation and Perception. Psychology Press, 2009.Google ScholarNickel, K., and Stiefelhagen, R. Pointing gesture recognition based on 3d-tracking of face, hands and head orientation. In ACM ICMI (2003), 140--146.  Google ScholarDigital LibraryOh, J.-Y., and Stuerzlinger, W. Moving objects with 2d input devices in cad systems and desktop virtual environments. In Graphics Interface 2005 (2005), 195--202. Google ScholarDigital LibrarySchmalstieg, D., Encarnac\u00b8 ao, L. M., and Szalav\u00e1ri, Z. Using transparent props for interaction with the virtual table. In ACM I3D (1999), 147--153.  Google ScholarDigital LibrarySch\u00f6ning, J., Steinicke, F., Valkov, D., Kr\u00fcger, A., and Hinrichs, K. H. Bimanual interaction with interscopic multi-touch surfaces. In IFIP TC13 INTERACT (2009), 40--53.  Google ScholarDigital LibraryShibata, T., Kurihara, S., Kawai, T., Takahashi, T., Shimizu, T., Kawada, R., Ito, A., Hkkinen, J., Takatalo, J., and Nyman, G. Evaluation of stereoscopic image quality for mobile devices using interpretation based quality methodology. In SPIE 7237, 72371E (2009).Google ScholarSpindler, M., Tominski, C., Schumann, H., and Dachselt, R. Tangible views for information visualization. In ACM ITS (2010), 157--166.  Google ScholarDigital LibrarySteinicke, F., Ropinski, T., Hinrichs, K., and Mensmann, J. Urban City Planning in Semi-immersive Virtual Reality. In INSTICC GRAPP (2006), 192--199.Google ScholarStellmach, S., and Dachselt, R. Look &amp; touch: gaze-supported target acquisition. In ACM CHI (2012), 2981--2990.  Google ScholarDigital LibraryStrothoff, S., Valkov, D., and Hinrichs, K. H. Triangle cursor: Interactions with objects above the tabletop. In ACM ITS (2011), 111--119.  Google ScholarDigital LibraryTeather, R. J., and Stuerzlinger, W. Guidelines for 3d positioning techniques. In ACM Future Play (2007), 61--68.  Google ScholarDigital LibraryTeather, R. J., and Stuerzlinger, W. Pointing at 3d target projections with one-eyed and stereo cursors. In ACM CHI (2013), 159--168.  Google ScholarDigital LibraryUngerleiger, L. G., and Miskin, M. Two cortical visual systems. Analysis of Visual Behavior (1982), 549--586.Google ScholarValkov, D., Giesler, A., and Hinrichs, K. Evaluation of depth perception for touch interaction with stereoscopic rendered objects. In ACM ITS (2012).  Google ScholarDigital LibraryValkov, D., Steinicke, F., Bruder, G., and Hinrichs, K. 2d touching of 3d stereoscopic objects. In ACM CHI (2011), 1353--1362.  Google ScholarDigital Librarysuppl.movSupplemental videoSupplemental MaterialAvailable for Downloadpdfp227-valkov.pdf (6.4 MB)", "keywords": ["human factors", "experimentation"], "published_in": "CHI '14: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "26 April 2014", "citations": "7", "isbn": "9781450324731", "doi": "10.1145/2556288", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2556288.2557134", "paper_url": "https://dl.acm.org/doi/10.1145/2556288.2557134"}, {"title": "Uvmode: usability verification mixed reality system for mobile devices", "authors": ["Ungyeon Yang", "Dongsik Jo", "Wooho Son"], "abstract": "UVMODE is a mixed reality based usability evaluation system for mobile information device development. The system contributes to increasing efficiency of the usability evaluation process by replacing real products with virtual models. With our system, users can change the design of a virtual product easily, and investigate how it affects its usability. While users can review and test the virtual product by manipulating it with MR interfaces, the system also provides evaluation tools for measuring objective usability measures, including estimated design quality and users' hand load. In this paper, we present the system design and implementation details of our system, and discuss how it could improve the current usability evaluation processes held in mobile information device industry.", "keywords": ["usability test", "design reviewing", "product-life-cycle", "operation simulation", "mixed reality", "tangible interface", "affective engineering", "photo-realistic rendering"], "published_in": "CHI EA '08: CHI '08 Extended Abstracts on Human Factors in Computing Systems", "publication_date": "5 April 2008", "citations": "6", "isbn": "9781605580128", "doi": "10.1145/1358628", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1358628.1358893", "paper_url": "https://dl.acm.org/doi/10.1145/1358628.1358893"}, {"title": "Annexing Reality: Enabling Opportunistic Use of Everyday Objects as Tangible Proxies in Augmented Reality", "authors": ["Anuruddha Hettiarachchi", "Daniel Wigdor"], "abstract": "Advances in display and tracking technologies hold the promise of increasingly immersive augmented-reality experiences. Unfortunately, the on-demand generation of haptic experiences is lagging behind these advances in other feedback channels. We present Annexing Reality; a system that opportunistically annexes physical objects from a user's current physical environment to provide the best-available haptic sensation for virtual objects. It allows content creators to a priori specify haptic experiences that adapt to the user's current setting. The system continuously scans user's surrounding, selects physical objects that are similar to given virtual objects, and overlays the virtual models on to selected physical ones reducing the visual-haptic mismatch. We describe the developer's experience with the Annexing Reality system and the techniques utilized in realizing it. We also present results of a developer study that validates the usability and utility of our method of defining haptic experiences.                     References                 Merwan Achibet, Maud Marchal, Ferran Argelaguet, and Anatole Lecuyer. 2014. The Virtual Mitten: A novel interaction paradigm for visuo-haptic manipulation of objects using grip force. 2014 IEEE Symposium on 3D User Interfaces (3DUI), IEEE, 59--66. http://doi.org/10.1109/3DUI.2014.6798843Google ScholarCross RefMarco Agus, Andrea Giachetti, Enrico Gobbetti, Gianluigi Zanetti, and Antonio Zorcolo. 2014. A multiprocessor decoupled system for the simulation of temporal bone surgery. Computing and Visualization in Science 5, 1: 35--43. http://doi.org/10.1007/s00791002-0085--5Google ScholarDigital LibraryMarc Alexa, Johannes Behr, Daniel Cohen-Or, Shachar Fleishman, David Levin, and Claudio T. Silva. 2003. Computing and rendering point set surfaces. IEEE Transactions on Visualization and Computer Graphics 9, 1: 3--15. http://doi.org/10.1109/TVCG.2003.1175093  Google ScholarDigital LibraryYuki Ban, Takashi Kajinami, Takuji Narumi, Tomohiro Tanikawa, and Michitaka Hirose. 2012. Modifying an identified angle of edged shapes using pseudo-haptic effects. Haptics: Perception, Devices, Mobility, and Communication: 25--36. Retrieved September 23, 2015 from http://link.springer.com/chapter/10.1007/978-3-64231401-8_3  Google ScholarDigital LibraryYuki Ban, Takashi Kajinami, Takuji Narumi, Tomohiro Tanikawa, and Michitaka Hirose. 2012. Modifying an identified curved surface shape using pseudo-haptic effect. 2012 IEEE Haptics Symposium (HAPTICS), IEEE, 211--216. http://doi.org/10.1109/HAPTIC.2012.6183793  Google ScholarDigital LibraryYuki Ban, Takuji Narumi, Tomohiro Tanikawa, and Michitaka Hirose. 2012. Modifying an identified position of edged shapes using pseudo-haptic effects. Proceedings of the 18th ACM symposium on Virtual reality software and technology - VRST '12, ACM Press, 93--96. http://doi.org/10.1145/2407336.2407353  Google ScholarDigital LibraryPaul J. Besl and Neil D. McKay. 1992. A method for registration of 3-D shapes. IEEE Transactions on Pattern Analysis and Machine Intelligence 14, 2: 239--256. http://doi.org/10.1109/34.121791  Google ScholarDigital LibraryAnders G. Buch, Dirk Kraft, Joni-Kristian Kamarainen, Henrik G. Petersen, and Norbert Kruger. 2013. Pose estimation using local structure-specific shape and appearance context. 2013 IEEE International Conference on Robotics and Automation, IEEE, 2080--2087. http://doi.org/10.1109/ICRA.2013.6630856Google ScholarCross RefAlbert S. Carlin, Hunter G. Hoffman, and Suzanne Weghorst. 1997. Virtual reality and tactile augmentation in the treatment of spider phobia: a case report. Behaviour Research and Therapy 35, 2: 153--158. http://doi.org/10.1016/S0005-7967(96)00085-XGoogle ScholarCross RefKai-Yin Cheng, Rong-Hao Liang, Bing-Yu Chen, Rung-Huei Laing, and Sy-Yen Kuo. 2010. iCon: utilizing everyday objects as additional, auxiliary and instant tabletop controllers. Proceedings of the 28th international conference on Human factors in computing systems CHI '10, ACM Press, 1155--1164. http://doi.org/10.1145/1753326.1753499  Google ScholarDigital LibraryChristian Corsten, Ignacio Avellino, Max M\u00f6llers, and Jan Borchers. 2013. Instant user interfaces. Proceedings of the 2013 ACM international conference on Interactive tabletops and surfaces ITS '13, ACM Press, 71--80. http://doi.org/10.1145/2512349.2512799  Google ScholarDigital LibraryMichael Csongei, Liem Hoang, Ulrich Eck, and Christian Sandor. 2012. ClonAR: Rapid redesign of real-world objects. 2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), IEEE, 277--278. http://doi.org/10.1109/ISMAR.2012.6402572  Google ScholarDigital LibraryLisa M. Di Diodato, Richard Mraz, Nicole S. Baker, and Simon J. Graham. 2007. A haptic force feedback device for virtual reality-fMRI experiments. IEEE transactions on neural systems and rehabilitation engineering?: a publication of the IEEE Engineering in Medicine and Biology Society 15, 4: 570--576. http://doi.org/10.1109/TNSRE.2007.906962Google ScholarMarkus Funk, Oliver Korn, and Albrecht Schmidt. 2014. An augmented workplace for enabling userdefined tangibles. Proceedings of the extended abstracts of the 32nd annual ACM conference on Human factors in computing systems CHI EA '14, ACM Press, 1285--1290. http://doi.org/10.1145/2559206.2581142  Google ScholarDigital LibrarySidhant Gupta, Dan Morris, Shwetak N. Patel, and Desney Tan. 2013. AirWave: non-contact haptic feedback using air vortex rings. Proceedings of the 2013 ACM international joint conference on Pervasive and ubiquitous computing - UbiComp '13, ACM Press, 419--428. http://doi.org/10.1145/2493432.2493463  Google ScholarDigital LibrarySteven J. Henderson and Steven Feiner. 2008. Opportunistic controls: leveraging natural affordances as tangible user interfaces for augmented reality. Proceedings of the 2008 ACM symposium on Virtual reality software and technology - VRST '08, ACM Press, 211--218. http://doi.org/10.1145/1450579.1450625  Google ScholarDigital LibraryValentin Heun, Shunichi Kasahara, and Pattie Maes. 2013. Smarter objects: using AR technology to program physical objects and their interactions. CHI '13 Extended Abstracts on Human Factors in Computing Systems on CHI EA '13, ACM Press, 961--966. http://doi.org/10.1145/2468356.2468528  Google ScholarDigital LibraryKen Hinckley, Randy Pausch, John C. Goble, and Neal F. Kassell. 1994. Passive real-world interface props for neurosurgical visualization. Proceedings of the SIGCHI conference on Human factors in computing systems celebrating interdependence CHI '94, ACM Press, 452--458. http://doi.org/10.1145/191666.191821  Google ScholarDigital LibraryKoichi Hirota and Michitaka Hirose. 1995. Providing force feedback in virtual environments. IEEE Computer Graphics and Applications 15, 5: 22--30. http://doi.org/10.1109/38.403824  Google ScholarDigital LibraryHunter G. Hoffman. 1998. Physically touching virtual objects using tactile augmentation enhances the realism of virtual environments. Proceedings. IEEE 1998 Virtual Reality Annual International Symposium (Cat. No.98CB36180), IEEE Comput. Soc, 59--63. http://doi.org/10.1109/VRAIS.1998.658423 Google ScholarDigital LibraryHiroshi Ishii and Brygg Ullmer. 1997. Tangible bits. Proceedings of the SIGCHI conference on Human factors in computing systems CHI '97, ACM Press, 234--241. http://doi.org/10.1145/258549.258715  Google ScholarDigital LibraryHiroo Iwata, Hiroaki Yano, Fumitaka Nakaizumi, and Ryo Kawamura. 2001. Project FEELEX: adding haptic surface to graphics. Proceedings of the 28th annual conference on Computer graphics and interactive techniques SIGGRAPH '01, ACM Press, 469--476. http://doi.org/10.1145/383259.383314  Google ScholarDigital LibraryBenjamin Knoerlein, G\u00e1bor Sz\u00e9kely, and Matthias Harders. 2007. Visuo-haptic collaborative augmented reality ping-pong. Proceedings of the international conference on Advances in computer entertainment technology - ACE '07, ACM Press, 91--94. http://doi.org/10.1145/1255047.1255065  Google ScholarDigital LibraryAaron Kotranza and Benjamin Lok. 2008. Virtual Human + Tangible Interface = Mixed Reality Human An Initial Exploration with a Virtual Breast Exam Patient. 2008 IEEE Virtual Reality Conference, IEEE, 99--106. http://doi.org/10.1109/VR.2008.4480757Google ScholarCross RefHarold W. Kuhn. 1955. The Hungarian method for the assignment problem. Naval Research Logistics Quarterly 2, 1--2: 83--97. http://doi.org/10.1002/nav.3800020109Google ScholarCross RefEun Kwon, Gerard J. Kim, and Sangyoon Lee. 2009. Effects of sizes and shapes of props in tangible augmented reality. 2009 8th IEEE International Symposium on Mixed and Augmented Reality, IEEE, 201--202. http://doi.org/10.1109/ISMAR.2009.5336463  Google ScholarDigital LibraryDaniel Leithinger, Sean Follmer, Alex Olwal, et al. 2013. Sublimate: state-changing virtual and physical rendering to augment interaction with shape displays. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems CHI '13, ACM Press, 1441--1450. http://doi.org/10.1145/2470654.2466191  Google ScholarDigital LibraryThomas H. Massie and Kenneth J. Salisbury. 1994. The phantom haptic interface: A device for probing virtual objects. Proceedings of the ASME winter annual meeting, symposium on haptic interfaces for virtual environment and teleoperator systems, 295-- 300.Google ScholarPaul Milgram and Fumio Kishino. 1994. A Taxonomy of Mixed Reality Visual Displays. IEICE TRANSACTIONS on Information and Systems E77-D, 1321--1329.Google ScholarYoichi Ochiai, Kota Kumagai, Takayuki Hoshi, Jun Rekimoto, Satoshi Hasegawa, and Yoshio Hayasaki. 2015. Fairy lights in femtoseconds. ACM SIGGRAPH 2015 Posters on SIGGRAPH '15, ACM Press, 1--1. http://doi.org/10.1145/2787626.2792630Google ScholarDigital LibraryOhan Oda, Levi J. Lister, Sean White, and Steven Feiner. 2008. Developing an augmented reality racing game. 2. Retrieved September 21, 2015 from http://dl.acm.org/citation.cfm?id=1363200.1363203Google ScholarCross RefBernhard Pflesser, Andreas Petersik, Ulf Tiede, Karl Heinz H\u00f6hne, and Rudolf Leuwer. 2002. Volume cutting for virtual petrous bone surgery. Computer aided surgery?: official journal of the International Society for Computer Aided Surgery 7, 2: 74--83. http://doi.org/10.1002/igs.10036Google ScholarJun Rekimoto. 2014. Traxion: a tactile interaction device with virtual force sensation. ACM SIGGRAPH 2014 Emerging Technologies on SIGGRAPH '14, ACM Press, 1--1. http://doi.org/10.1145/2614066.2614079  Google ScholarDigital LibraryRadu B. Rusu, Nico Blodow, and Michael Beetz. 2009. Fast Point Feature Histograms (FPFH) for 3D registration. 2009 IEEE International Conference on Robotics and Automation, IEEE, 3212--3217. http://doi.org/10.1109/ROBOT.2009.5152473 Google ScholarDigital LibraryRadu B. Rusu. 2010. Semantic 3D Object Maps for Everyday Manipulation in Human Living Environments. KI - K\u00fcnstliche Intelligenz 24, 4: 345--348. http://doi.org/10.1007/s13218-010-0059-6Google ScholarCross RefSatoshi Saga and Ramesh Raskar. 2012. Feel through window. SIGGRAPH Asia 2012 Emerging Technologies on SA '12, ACM Press, 1--3. http://doi.org/10.1145/2407707.2407715Google ScholarDigital LibraryMakoto Sato. 2002. SPIDAR and virtual reality. Proceedings of the 5th Biannual World Automation Congress, TSI Press, 17--23. http://doi.org/10.1109/WAC.2002.1049515Google ScholarCross RefRuwen Schnabel, Roland Wahl, and Reinhard Klein. 2007. Efficient RANSAC for Point-Cloud Shape Detection. Computer Graphics Forum 26, 2: 214--226. http://doi.org/10.1111/j.1467-8659.2007.01016.xGoogle ScholarCross RefAdalberto L. Simeone, Eduardo Velloso, and Hans Gellersen. 2015. Substitutional Reality. Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems CHI '15, ACM Press, 3307--3316. http://doi.org/10.1145/2702123.2702389  Google ScholarDigital LibraryRajinder Sodhi, Ivan Poupyrev, Matthew Glisson, and Ali Israr. 2013. AIREAL: interactive tactile experiences in free air. ACM Transactions on Graphics 32, 4: 134. http://doi.org/10.1145/2461912.2462007  Google ScholarDigital LibraryYuriko Suzuki and Minoru Kobayashi. 2005. Air jet driven force feedback in virtual reality. IEEE Computer Graphics and Applications 25, 1: 44--47. http://doi.org/10.1109/MCG.2005.1  Google ScholarDigital LibraryJames Vallino and Christopher Brown. 1999. Haptics in augmented reality. Proceedings IEEE International Conference on Multimedia Computing and Systems, IEEE Comput. Soc, 195--200. http://doi.org/10.1109/MMCS.1999.779146  Google ScholarDigital LibraryPeter Weir, Christian Sandor, Matt Swoboda, Ulrich Eck, Gerhard Reitmayr, and Arindam Dey. 2012. BurnAR: Feel the heat. 2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), IEEE, 331--332. http://doi.org/10.1109/ISMAR.2012.6402599  Google ScholarDigital LibraryMicrosoft HoloLens. Retrieved September 21, 2015 from https://www.microsoft.com/microsofthololens/en-usGoogle ScholarKinect for Xbox One. Retrieved September 21, 2015 from http://www.xbox.com/en-ca/xboxone/accessories/kinect-for-xbox-oneGoogle ScholarATOMIC Authoring Tool. Retrieved September 21, 2015 from http://www.sologicolibre.org/projects/atomic/en/Google ScholarbuildAR. Retrieved September 21, 2015 from https://buildar.com/startGoogle ScholarVuforia Augmented Reality for 3D Mobile Content. Retrieved September 21, 2015 from https://www.qualcomm.com/products/vuforiaGoogle Scholarmetaio. Retrieved September 22, 2015 from https://www.metaio.com/Google Scholardlib C++ Library - Optimization. Retrieved September 21, 2015 from http://dlib.net/optimization.htmlGoogle ScholarMeta Augmented Reality. Retrieved September 23, 2015 from https://www.getameta.com/Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/2858036.2858134/8e7e0cdc-c2e7-4d7e-a395-404e0772380e/pn0634-file3.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ef0fe2eb2ee9941421545250ef1dc3438c5bca7421d7a2ea6aa8bd4b4fe6204a39e1c05214648b5822147014608b68bec148627bb73e7f185f01e742cfccb5b05c208990d01405e24fapplication/x-mpegurlmp454.4 MB", "keywords": ["augmented reality", "opportunistic tangible interfaces", "augmented reality content authoring"], "published_in": "CHI '16: Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems", "publication_date": "7 May 2016", "citations": "52", "isbn": "9781450333627", "doi": "10.1145/2858036", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2858036.2858134", "paper_url": "https://dl.acm.org/doi/10.1145/2858036.2858134"}, {"title": "BeThere: 3D mobile collaboration with spatial input", "authors": ["Rajinder S. Sodhi", "Brett R. Jones", "David Forsyth", "Brian P. Bailey", "Giuliano Maciocci"], "abstract": "We present BeThere, a proof-of-concept system designed to explore 3D input for mobile collaborative interactions. With BeThere, we explore 3D gestures and spatial input which allow remote users to perform a variety of virtual interactions in a local user's physical environment. Our system is completely self-contained and uses depth sensors to track the location of a user's fingers as well as to capture the 3D shape of objects in front of the sensor. We illustrate the unique capabilities of our system through a series of interactions that allow users to control and manipulate 3D virtual content. We also provide qualitative feedback from a preliminary user study which confirmed that users can complete a shared collaborative task using our system.                     References                 Bauer, M., and Kortuem, G. Where Are You Pointing At? A Study of Remote Collaboration in a Wearable Videoconference System. In Wearable Computers. (1999), 151--161. Google ScholarDigital LibraryBenko, H., Jota, R., Wilson, A. D., and Inesc-id, V. MirageTable: Freehand Interaction on a Projected Augmented Reality Tabletop. In Proc. of CHI (2012), 199--208.  Google ScholarDigital LibraryB\u00e9rard, F., Ip, J., Benovoy, M., El-Shimy, D., Blum, J., and Cooperstock, J. Did minority report get it wrong? superiority of the mouse over 3d input devices in a 3d placement task. In Proc. of INTERACT (2009), 400--414.  Google ScholarDigital LibraryBillinghurst, M., Cheok, A., Kato, H., and Prince, S. Real World Teleconferencing. In Proc. of CHI (1999), 194--195.  Google ScholarDigital LibraryButler, A., and Izadi, S. SideSight: multi-touch interaction around small devices. In Proc. of UIST (2008), 3--6.  Google ScholarDigital LibraryEns, B., Ahlstr\u00f6m, D., Cockburn, A., and Irani, P. Characterizing user performance with assisted direct off-screen pointing. In Proc. of MobileHCI (2011), 485--494.  Google ScholarDigital LibraryFitzmaurice, G. W., Zhai, S., and Chignell, M. H. Virtual reality for palmtop computers. In Trans. on Info. Sys., vol. 11 (1993), 197--218.  Google ScholarDigital LibraryFriedrich, D. W. ARVIKA: Augmented Reality for Development, Production and Service. In Proc. of ISMAR (2002), 1--2. Google ScholarDigital LibraryFussell, S., Setlock, L., Yang, J., Ou, J., and Mauer, E. Gestures Over Video Streams to Support Remote Collaboration on Physical Tasks. In Hum.-Comput. Interact. 19 (Sept. 2004), 273--309.  Google ScholarDigital LibraryGauglitz, S., Lee, C., Turk, M., and Hollerer, T. Integrating the Physical Environment into Mobile Remote Collaboration. In Proc. of Mobile HCI (2012), 241--250.  Google ScholarDigital LibraryGergle, D., and Clark, A. T. See What I m Saying? Using Dyadic Mobile Eye Tracking to Study Collaborative Reference. In Proc. CSCW (2011), 435--444.  Google ScholarDigital LibraryGurevich, P., Lanir, J., Cohen, B., and Stone, R. TeleAdvisor: a versatile augmented reality tool for remote assistance. In Proc. of CHI (2012), 619--622.  Google ScholarDigital LibraryGustafson, S., and Bierwirth, D. Imaginary interfaces: spatial interaction with empty hands and without visual feedback. In Proc. of UIST (2010), 3--12.  Google ScholarDigital LibraryGutwin, C., and Penner, R. Improving interpretation of remote gestures with telepointer traces. Proc. of CSCW (2002), 49.  Google ScholarDigital LibraryHackenberg, G. Lightweight Palm and Finger Tracking for Real-Time 3D Gesture Control. Building, March 2010 (2011), 19--26.  Google ScholarDigital LibraryHancock, M., ten Cate, T., and Carpendale, S. Sticky tools: full 6dof force-based interaction for multi-touch tables. In Proc. of ITS, ITS '09 (2009), 133--140.  Google ScholarDigital LibraryHarrison, C., Benko, H., Wilson, A. D., and Way, O. M. OmniTouch: Wearable multitouch interaction everywhere. In Proc. UIST (2011), 441--450.  Google ScholarDigital LibraryHarrison, C., and Hudson, S. Abracadabra: wireless, high-precision, and unpowered finger input for very small mobile devices. In Proc. UIST (2009), 121--124.  Google ScholarDigital LibraryHilliges, O., Kim, D., Izadi, S., Weiss, M., and Wilson, A. Holodesk: direct 3d interactions with a situated see-through display. In Proc. of CHI (2012), 2421--2430.  Google ScholarDigital LibraryIzadi, S. KinectFusion: Real-time 3D Reconstruction and Interaction Using a Moving Depth Camera. In Proc. of UIST (2011), 559--568.  Google ScholarDigital LibraryJones, B., Sodhi, R., Bailey, B., Maciocci, G., and Forsyth, D. Depth-based Around Device Interaction for Multiscale Navigation. In Proc. MobileHCI (2012), 83--92.  Google ScholarDigital LibraryKratz, S., and Rohs, M. HoverFlow: Expanding the Design Space of Around-Device Interaction. In MobileHCI (2009), 1--8.  Google ScholarDigital LibraryKratz, S., and Rohs, M. PalmSpace: Continuous Around-Device Gestures vs. Multitouch for 3D Rotation Tasks on Mobile Devices Categories and Subject Descriptors Interaction on Mobile Devices. In Proc. of AVI (2012), 181--188.  Google ScholarDigital LibraryLi, W., Agrawala, M., Curless, B., and Salesin, D. Automated Generation of Interactive 3D Exploded View Diagrams. In Proc. of SIGGRAPH (2008), 101--107.  Google ScholarDigital LibraryLincoln, P., Welch, G., Nashel, A., Ilie, A., State, A., and Fuchs, H. Animatronic Shader Lamps Avatars. In Proc. of ISMAR, Ieee (Oct. 2009), 27--33.  Google ScholarDigital LibraryMaimone, A. A First Look at a Telepresence System with Room-Sized Real-Time 3D Capture. In Proc. ICAT (2011), 4--9.Google ScholarMartinet, A., Casiez, G., and Grisoni, L. Integrality and separability of multitouch interaction techniques in 3d manipulation tasks. Trans. on Vis. and CG 18, 3 (Mar. 2012), 369--380.  Google ScholarDigital LibraryNancel, M., Wagner, J., Pietriga, E., Chapuis, O., Mackay, W., Orsay, F., and Orsay, F. Mid-air Pan-and-Zoom on Wall-sized Displays. In Proc of CHI, no. May (2011), 177--186.  Google ScholarDigital LibraryNeill, J. O., Castellani, S., Roulland, F., and Hairon, N. From Ethnographic Study to Mixed Reality: A Remote Collaborative Troubleshooting System. Proc. of CSCW (2011), 225--234.  Google ScholarDigital LibraryOikonomidis, I., Kyriazis, N., and Argyros, A. Efficient model-based 3D tracking of hand articulations using Kinect. Proc of the BMVC (2011), 101.1--101.11.Google ScholarCross RefRanjan, A., Birnholtz, J. P., and Balakrishnan, R. Dynamic Shared Visual Spaces: Experimenting with Automatic Camera Control in a Remote Repair Task. In Proc. of CHI (2007), 1177--1186.  Google ScholarDigital LibraryRaskar, R., Welch, G., Cutts, M., Lake, A., Stesin, L., and Fuchs, H. The office of the future. In Proc. SIGGRAPH (1998), 179--188.  Google ScholarDigital LibraryReisman, J. L., Davidson, P. L., and Han, J. Y. A screen-space formulation for 2d and 3d direct manipulation. In Proc. of UIST, UIST'09 (2009), 69--78.  Google ScholarDigital LibraryRing, M.-t. F., Ashbrook, D., Baudisch, P., White, S., Str, P.-d.-h., and Potsdam, D. Nenya: Subtle and Eyes-Free Mobile Input with a. In Proc. CHI (2011), 2043--2046.  Google ScholarDigital LibrarySakong, K. Supporting telepresence by visual and physical cues in distributed 3D collaborative design environments. In Proc. CHI (2006), 1283--1288.  Google ScholarDigital LibraryStafford, A. Piekarski, W., and Thomas, B. Implementation of god-like interaction techniques. In Proc. of ISMAR (2006) (2006), 165--172.  Google ScholarDigital LibraryTang, J., and Minneman, S. VideoDraw: A Video Interface for Collaborative Drawing. In ACM Trans. Inf. Syst. 9 (1991), 170--184.  Google ScholarDigital LibraryWigdor, D., Forlines, C., Baudisch, P., Barnwell, J., and Shen, C. Lucid touch: a see-through mobile device. In Proc. of UIST, ACM (2007), 269--278.  Google ScholarDigital LibraryWilson, A., and Robbins, D. Playtogether: Playing games across multiple interactive tabletops. In Proc. of IUI (2006).Google ScholarWilson, A. D. Robust Computer Vision-Based Detection of Pinching for One and Two-Handed Gesture Input. In Proc of UIST (2006), 255--258.  Google ScholarDigital Library                                                                                                Index Terms                 BeThereHuman-centered computing", "keywords": ["around device interaction", "augmented reality", "collaboration", "depth sensors"], "published_in": "CHI '13: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "27 April 2013", "citations": "81", "isbn": "9781450318990", "doi": "10.1145/2470654", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2470654.2470679", "paper_url": "https://dl.acm.org/doi/10.1145/2470654.2470679"}, {"title": "Sparse Haptic Proxy: Touch Feedback in Virtual Environments Using a General Passive Prop", "authors": ["Lung-Pan Cheng", "Eyal Ofek", "Christian Holz", "Hrvoje Benko", "Andrew D. Wilson"], "abstract": "We propose a class of passive haptics that we call Sparse Haptic Proxy: a set of geometric primitives that simulate touch feedback in elaborate virtual reality scenes. Unlike previous passive haptics that replicate the virtual environment in physical space, a Sparse Haptic Proxy simulates a scene's detailed geometry by redirecting the user's hand to a matching primitive of the proxy. To bridge the divergence of the scene from the proxy, we augment an existing Haptic Retargeting technique with an on-the-fly target remapping: We predict users' intentions during interaction in the virtual space by analyzing their gaze and hand motions, and consequently redirect their hand to a matching part of the proxy. We conducted three user studies on haptic retargeting technique and implemented a system from three main results: 1) The maximum angle participants found acceptable for retargeting their hand is 40\u00b0, with an average rating of 4.6 out of 5. 2) Tracking participants' eye gaze reliably predicts their touch intentions (97.5%), even while simultaneously manipulating the user's hand-eye coordination for retargeting. 3) Participants preferred minimized retargeting distances over better-matching surfaces of our Sparse Haptic Proxy when receiving haptic feedback for single-finger touch input. We demonstrate our system with two virtual scenes: a flight cockpit and a room quest game. While their scene geometries differ substantially, both use the same sparse haptic proxy to provide haptic feedback to the user during task completion.                     References                 Azmandian, M., Hancock, M., Benko, H., Ofek, E., and Wilson, A. 2016. Haptic Retargeting: Dynamic Repurposing of Passive Haptics for Enhanced Virtual Reality Experiences. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI '16). ACM, NY, NY, USA, 1968--1979. DOI: http://dx.doi.org/10.1145/2858036.2858226  Google ScholarDigital LibraryBan, Y., Kajinami, T., Narumi, T., Tanikawa, T., and Hirose, M. (2012). Modifying an identified angle of edged shapes using pseudo-haptic effects. In Proceedings of the International Conference on Haptics: Perception, Devices, Mobility, and Communication, 25 of  Google ScholarDigital LibraryBergamasco M., Allotta B., Bosio L., Ferretti L., Parrini G., Prisco G.M., Salsedo F., Sartini G.. 1994. An arm exoskeleton system for teleoperation and virtual environments applications. In Proceedings of IEEE International Conference on Robotics and Automation. 2, 1449--1454. http://doi.org/10.1109/ROBOT.1994.351286 Google ScholarCross RefBinsted, G., Chua, R., Helsen, W., and Elliott, D. Eyehand coordination in goal-directed aiming. Human Movement Science 20, 4--5 (2001), 563--585.Google ScholarBurns, E., Razzaque, S., Whitton, M.C., and Brooks, F.P. 2007. MACBETH: The avatar which I see before me and its movement toward my hand. In Proceedings of IEEE Virtual Reality Conference, 295--296. Google ScholarCross RefFrederick P. Brooks, Jr., Ming Ouh-Young, James J. Batter, and P. Jerome Kilpatrick. 1990. Project GROPEHaptic displays for scientific visualization. SIGGRAPH Comput. Graph. 24, 4 (September 1990), 177--185. DOI=http://dx.doi.org/10.1145/97880.97899  Google ScholarDigital LibraryLung-Pan Cheng, Thijs Roumen, Hannes Rantzsch, Sven K\u00f6hler, Patrick Schmidt, Robert Kovacs, Johannes Jasper, Jonas Kemper, and Patrick Baudisch. 2015. TurkDeck: Physical Virtual Reality Based on People. In Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology (UIST '15). ACM, NY, NY, USA, 417--426. DOI: http://dx.doi.org/10.1145/2807442.2807463  Google ScholarDigital LibraryConti, F. and Khatib, O. 2005. Spanning large workspaces using small haptic devices. In Proceedings of First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, 183--188.  Google ScholarDigital LibraryChristian Corsten, Ignacio Avellino, Max M\u00f6llers, and Jan Borchers. 2013. Instant user interfaces: repurposing everyday objects as input devices. In Proceedings of the 2013 ACM international conference on Interactive tabletops and surfaces (ITS '13). ACM, NY, NY, USA, 71--80. DOI=http://dx.doi.org/10.1145/2512349.2512799  Google ScholarDigital LibraryGeorge W. Fitzmaurice, Hiroshi Ishii, and William A. S. Buxton. 1995. Bricks: laying the foundations for graspable user interfaces. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '95), Irvin R. Katz, Robert Mack, Linn Marks, Mary Beth Rosson, and Jakob Nielsen (Eds.). ACM Press/Addison-Wesley Publishing Co., NY, NY, USA, 442--449. DOI: http://dx.doi.org/10.1145/223904.223964  Google ScholarDigital LibraryGoertz, R. and Thompson, R. 1954. Electronically controlled manipulator. Nucleonics, 12, 11, 46--47.Google ScholarSteven J. Henderson and Steven Feiner. 2008. Opportunistic controls: leveraging natural affordances as tangible user interfaces for augmented reality. In Proceedings of the 2008 ACM symposium on Virtual reality software and technology (VRST '08). ACM, NY, NY, USA, 211--218. DOI=http://dx.doi.org/10.1145/1450579.1450625  Google ScholarDigital LibraryAnuruddha Hettiarachchi and Daniel Wigdor. 2016. Annexing Reality: Enabling Opportunistic Use of Everyday Objects as Tangible Proxies in Augmented Reality. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI '16). ACM, NY, NY, USA, 1957--1967. DOI: http://dx.doi.org/10.1145/2858036.2858134  Google ScholarDigital LibraryKen Hinckley, Randy Pausch, John C. Goble, and Neal F. Kassell. 1994. Passive real-world interface props for neurosurgical visualization. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '94), Beth Adelson, Susan Dumais, and Judith Olson (Eds.). ACM, NY, NY, USA, 452458. DOI=http://dx.doi.org/10.1145/191666.191821  Google ScholarDigital LibraryHughes, C.E., Stapleton, C.B., Hughes, D.E., Smith, E.M. 2005. Mixed reality in education, entertainment, and training. Computer Graphics and Applications, 25, 6, 24--30.  Google ScholarDigital LibraryHiroo Iwata, Hiroaki Yano, Fumitaka Nakaizumi, and Ryo Kawamura. 2001. Project FEELEX: adding haptic surface to graphics. In Proceedings of the 28th annual conference on Computer graphics and interactive techniques (SIGGRAPH '01). ACM, NY, NY, USA, 469--476. DOI=http://dx.doi.org/10.1145/383259.383314  Google ScholarDigital LibraryIvan E. Sutherland. 1965. The ultimate display. In Proceedings of the Congress of the International Federation of Information Processing (IFIP), 506--508. http://doi.org/10.1109/MC.2005.274  Google ScholarDigital LibraryKohli, L. 2010. Redirected touching: Warping space to remap passive haptics. In Proceedings of IEEE Symposium on 3D User Interfaces (3DUI), 2010, 129--130. http://doi.org/10.1109/3DUI.2010.5444703Google ScholarCross RefKohli, L., Burns, E., Miller, D., and Fuchs, H. 2005. Combining Passive Haptics with Redirected Walking. In Proceedings of the 2005 International Conference on Augmented Tele-existence, 253--254.  Google ScholarDigital LibraryKohli, L., Whitton, M.C., and Brooks, F.P. 2012. Redirected touching: The effect of warping space on task performance. IEEE Symposium on 3D User Interfaces (3DUI), 105--112.Google ScholarKohli, L., Whitton, M.C., and Brooks, F.P. 2013. Redirected Touching: Training and adaptation in warped virtual spaces. IEEE Symposium on 3D User Interfaces (3DUI), 79--86.Google ScholarKok-Lim Low, Greg Welch, Anselmo Lastra, and Henry Fuchs. 2001. Life-sized projector-based dioramas. In Proceedings of the ACM symposium on Virtual reality software and technology (VRST '01). ACM, NY, NY, USA, 93--101. DOI=http://dx.doi.org/10.1145/505008.505026  Google ScholarDigital LibraryMassie, T.H. and Salisbury, J.K. 1994. The PHANTOM Haptic Interface: A Device for Probing Virtual Objects Three Enabling Observations Three Necessary Criteria for an Effective Interface. In Proceedings HAPTICS '94, 55, 1, 295--300.Google ScholarMatsuoka, Y., Allin, S. J., &amp; Klatzky, R. L. (2002). The tolerance for visual feedback distortions in a virtual environment. Physiology &amp; behavior, 77(4), 651655. Google ScholarCross RefPatrick, N. 1990. Design, Construction, and Testing of a Fingertip Tactile Display for Interaction with Virtual and Remote Environments, Masters Thesis, Dept. of Mechanical Engineering, MIT, Boston, MA.Google ScholarPair, J., Neumann, U., Piepol, D., and Swartout, W.R. FlatWorld: Combining Hollywood Set-Design Techniques with VR. IEEE Computer Graphics and Applications 23, 1 (2003), 12--15.  Google ScholarDigital LibraryIvan Poupyrev, Mark Billinghurst, Suzanne Weghorst, and Tadao Ichikawa. 1996. The go-go interaction technique: non-linear mapping for direct manipulation in VR. In Proceedings of the 9th annual ACM symposium on User interface software and technology (UIST '96). ACM, NY, NY, USA, 79--80. DOI=http://dx.doi.org/10.1145/237091.237102  Google ScholarDigital LibraryRazzaque, S., Kohn, Z., and Whitton, M.C. 2001. Redirected Walking. In Proceedings of EUROGRAPHICS, 289--294.Google ScholarJia Sheng, Ravin Balakrishnan, and Karan Singh. 2006. An interface for virtual 3D sculpting via physical proxy. In Proceedings of the 4th international conference on Computer graphics and interactive techniques in Australasia and Southeast Asia (GRAPHITE '06). ACM, NY, NY, USA, 213--220. DOI=http://dx.doi.org/10.1145/1174429.1174467  Google ScholarDigital LibraryAdalberto L. Simeone, Eduardo Velloso, and Hans Gellersen. 2015. Substitutional Reality: Using the Physical Environment to Design Virtual Reality Experiences. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). ACM, NY, NY, USA, 3307--3316. DOI: http://dx.doi.org/10.1145/2702123.2702389  Google ScholarDigital LibraryBarton A. Smith, Janet Ho, Wendy Ark, and Shumin Zhai. 2000. Hand eye coordination patterns in target selection. In Proceedings of the 2000 symposium on Eye tracking research &amp; applications (ETRA '00). ACM, NY, NY, USA, 117--122. DOI=http://dx.doi.org/10.1145/355017.355041  Google ScholarDigital LibrarySpillmann, J., Tuchschmid, S., and Harders, M. (2013). Adaptive space warping to enhance passive haptics in an arthroscopy surgical simulator. IEEE Transactions on Visualization and Computer Graphics, 19(4):626-- 633.  Google ScholarDigital LibrarySteinicke, F., Bruder, G., Jerald, J., Frenz, H., and Lappe, M. 2010. Estimation of Detection Thresholds for Redirected Walking Techniques. IEEE Transactions on Visualization and Computer Graphics 16, 1, 17--27.  Google ScholarDigital LibrarySzalav\u00e1ri, Z. and Gervautz, M. 2008. The Personal Interaction Panel - a Two-Handed Interface for Augmented Reality. Computer Graphics Forum 16, 3, 335-- 346. Google ScholarCross RefTachi, S., Maeda, T., Hirata, R., and Hoshino, H. A. 1994. Construction Method of Virtual Haptic Space. In Proceedings of the 4th International Conference on Artificial Reality and Tele-Existence, 131--138.Google ScholarWilliam A. McNeely. 1993. Robotic graphics: a new approach to force feedback for virtual reality. In Proceedings of IEEE Virtual Reality Annual International Symposium, 1993, 336--341. http://doi.org/10.1109/VRAIS.1993.380761  Google ScholarDigital LibrarySupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3025453.3025753/a1d99a2e-c662-4699-9f1b-23ee261575e4/pn2491p.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee07e5e64ad2301e1e02b6a6c38b1c42b798cc62ffbc71dfc673c12a15e771456966bff78c07fb72287356d0a5dbccddaa15998e01c2d570c2671ae670f0b59bea8d3a3a56151d2067application/x-mpegurlmp43.8 MB", "keywords": ["virtual reality", "passive haptics", "retargeting", "perception"], "published_in": "CHI '17: Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2017", "citations": "40", "isbn": "9781450346559", "doi": "10.1145/3025453", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3025453.3025753", "paper_url": "https://dl.acm.org/doi/10.1145/3025453.3025753"}, {"title": "The Object Inside: Assessing 3D Examination with a Spherical Handheld Perspective-Corrected Display", "authors": ["Francois Berard", "Thibault Louis"], "abstract": "Handheld Perspective Corrected Displays (HPCDs) can create the feeling of holding a virtual 3D object. They offer a direct interaction that is isomorphic to the manipulation of physical objects. This illusion depends on the ability to provide a natural visuomotor coupling. High performances systems are thus required to evaluate the fundamental merits of HPCDs. We built a spherical HPCD using external projection. The system offers a lightweight wireless seamless display with head-coupled stereo, robust tracking, and low latency. We compared users' performances with this HPCD and two other interactions that used a fixed planar display and either a touchpad or the spherical display as an indirect input. The task involved the inspection of complex virtual 3D puzzles. Physical puzzles were also tested as references. Contrary to expectations, all virtual interactions were found to be more efficient than a more \"natural\" physical puzzle. The HPCD yielded lower performances than the touchpad. This study indicates that the object examination task did not benefit from the accurate and precise rotations offered by the HPCD, but benefited from the high C/D gain of the touchpad.                     References                 Kevin W. Arthur, Kellogg S. Booth, and Colin Ware. 1993. Evaluating 3D task performance for fish tank virtual worlds. ACM Transactions on Information Systems 11, 3 (1993), 239--265.  Google ScholarDigital LibraryRagnar Bade, Felix Ritter, and Bernhard Preim. 2005. Usability comparison of mouse-based interaction techniques for predictable 3d rotation, In Proceedings of the 5th international conference on Smart Graphics. SG (2005), 138--150.  Google ScholarDigital LibraryElie Cattan, Am\u00e9lie Rochet-Capellan, and Fran\u00e7ois B\u00e9rard. 2015. A Predictive Approach for an End-to-End Touch-Latency Measurement, In ACM Interactive Tabletops and Surfaces. ITS (2015).  Google ScholarDigital LibraryGeorge W. Fitzmaurice. 1993. Situated Information Spaces and Spatially Aware Palmtop Computers. Commun. ACM 36, 7 (1993), 39--49.  Google ScholarDigital LibraryBernd Froehlich, Jan Hochstrate, Verena Skuk, and Anke Huckauf. 2006. The GlobeFish and the GlobeMouse: two new six degree of freedom input devices for graphics applications, In ACM Conference on Human Factors in Computing Systems. CHI (2006), 191--199.  Google ScholarDigital LibraryTovi Grossman and Ravin Balakrishnan. 2006. An evaluation of depth perception on volumetric displays, In ACM Conference on Advanced Visual Interfaces. AVI (2006), 193--200.  Google ScholarDigital LibraryMark Hancock, Thomas ten Cate, and Sheelagh Carpendale. 2009. Sticky tools: full 6DOF force-based interaction for multi-touch tables, In ACM International Conference on Interactive Tabletops and Surfaces. ITS (2009), 133--140.  Google ScholarDigital LibraryKarin L. Harman, G. Keith Humphrey, and Melvyn A. Goodale. 1999. Active manual control of object views facilitates visual recognition. Current Biology 9, 22 (2016/08/30 1999), 1315--1318.Google ScholarOtmar Hilliges, David Kim, Shahram Izadi, Malte Weiss, and Andrew Wilson. 2012. HoloDesk: Direct 3D Interactions with a Situated See-through Display, In ACM Conference on Human Factors in Computing Systems. CHI (2012), 2421--2430.  Google ScholarDigital LibraryKen Hinckley, Randy Pausch, John C. Goble, and Neal F. Kassell. 1994. Passive real-world interface props for neurosurgical visualization, In ACM Conference on Human Factors in Computing Systems. CHI (1994), 452--458.  Google ScholarDigital LibraryKen Hinckley, Joe Tullio, Randy Pausch, Dennis Proffitt, and Neal Kassell. 1997. Usability analysis of 3D rotation techniques, In ACM Symposium on User Interface Software and Technology. UIST (1997), 1--10.  Google ScholarDigital LibraryYvonne Jansen, Pierre Dragicevic, and Jean-Daniel Fekete. 2013. Evaluating the Efficiency of Physical Visualizations, In ACM Conference on Human Factors in Computing Systems. CHI (2013), 2593--2602.  Google ScholarDigital LibraryFrank Meijer and Rob H.J. Van der Lubbe. 2011. Active exploration improves perceptual sensitivity for virtual 3D objects in visual recognition tasks. Vision Research 51, 23--24 (2011), 2431--2439.Google ScholarCross RefIvan Poupyrev, Suzanne Weghorst, and Sidney Fels. 2000. Non-isomorphic 3D Rotational Techniques, In ACM Conference on Human Factors in Computing Systems. CHI (2000), 540--547.  Google ScholarDigital LibraryMartin Spindler, Wolfgang B\u00fcschel, and Raimund Dachselt. 2012. Use your head: tangible windows for 3D information spaces in a tabletop environment, In ACM International Conference on Interactive Tabletops and Surfaces. ITS (2012), 245--254.  Google ScholarDigital LibraryIan Stavness, Billy Lam, and Sidney Fels. 2010. pCubee: A Perspective-corrected Handheld Cubic Display, In ACM Conference on Human Factors in Computing Systems. CHI (2010), 1381--1390.  Google ScholarDigital LibraryColin Ware and Roland Arsenault. 2004. Frames of Reference in Virtual Object Rotation, In ACM Symposium on Applied Perception in Graphics and Visualization. APGV (2004), 135--141.  Google ScholarDigital LibraryColin Ware and Glenn Franck. 1996. Evaluating stereo and motion cues for visualizing information nets in three dimensions. ACM Trans. Graph. 15, 2 (1996), 121--140.  Google ScholarDigital LibraryColin Ware and Peter Mitchell. 2005. Reevaluating Stereo and Motion Cues for Visualizing Graphs in Three Dimensions, In Proceedings of the 2Nd Symposium on Applied Perception in Graphics and Visualization. APGV (2005), 51--58.  Google ScholarDigital LibraryColin Ware and Jeff Rose. 1999. Rotating Virtual Objects with Real Handles. ACM Trans. Comput.-Hum. Interact. 6, 2 (June 1999), 162--180.  Google ScholarDigital LibrarySupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3025453.3025806/20a768e5-e82f-4462-9e00-5f0d9b6340b0/pn2758p.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee07e5e64ad2301e1e02b6a6cc8e1942e499c96ce8027d5cbd4aaff4aa89c28b2824202864d5b69bf295b67ea1d39ed35abcad3510c94b1f6c5b0045e3c217100f942c48bcb8336f4bapplication/x-mpegurlmp44.6 MB", "keywords": ["handheld perspective corrected display (hpcd)", "depth perception", "isomorphic rotation", "object examination", "3d display", "evaluation"], "published_in": "CHI '17: Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2017", "citations": "9", "isbn": "9781450346559", "doi": "10.1145/3025453", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3025453.3025806", "paper_url": "https://dl.acm.org/doi/10.1145/3025453.3025806"}, {"title": "Prospective motor control on tabletops: planning grasp for multitouch interaction", "authors": ["Halla B. Olafsdottir", "Theophanis Tsandilas", "Caroline Appert"], "abstract": "Substantial amount of research in Psychology has studied how people manipulate objects in the physical world. This work has unveiled that people show strong signs of prospective motor planning, i.e., they choose initial grasps that avoid uncomfortable end postures and facilitate object manipulation. Interactive tabletops allow their users great flexibility in the manipulation of virtual objects but to our knowledge previous work has never examined whether prospective motor control takes place in this context. To test this, we ran three experiments. We systematically studied how users adapt their grasp when asked to translate and rotate virtual objects on a multitouch tabletop. Our results demonstrate that target position and orientation significantly affect the orientation of finger placement on the object. We analyze our results in the light of the most recent model of planning for manipulating physical objects and identify their implications for the design of tabletop interfaces. \\                     References                 Cohen, R. G., and Rosenbaum, D. A. Prospective and retrospective effects in hulman motor control: planning grasps for object rotation and translation. Psychological Research 75, 4 (2011), 341--349.Google ScholarCross RefCumming, G., and Finch, S. Inference by eye: confidence intervals and how to read pictures of data. American Psychologist 60, 2 (2005), 170--180.Google ScholarCross RefFitzmaurice, G. W., and Buxton, W. An empirical evaluation of graspable user interfaces: towards specialized, space-multiplexed input. In Proc. CHI '97, ACM (1997), 43--50.  Google ScholarDigital LibraryHancock, M. S., and Booth, K. S. Improving menu placement strategies for pen input. In Proc. GI '04, Canadian Human-Computer Communications Society (2004), 221--230. Google ScholarDigital LibraryHancock, M. S., Carpendale, S., Vernier, F. D., Wigdor, D., and Shen, C. Rotation and translation mechanisms for tabletop interaction. In Proc. TABLETOP '06, IEEE Computer Society (2006), 79--88.  Google ScholarDigital LibraryHerbort, O. Optimal versus heuristic planning of object manipulations: A review and a computational model of the continuous end-state comfort effect. New Ideas in Psychology (2013), 1--11.Google ScholarHerbort, O., and Butz, M. The continuous end-state comfort effect: weighted integration of multiple biases. Psychological Research 76, 3 (2012), 345--363.Google ScholarCross RefHinrichs, U., and Carpendale, S. Gestures in the wild: studying multi-touch gesture sequences on interactive tabletop exhibits. In Proc. CHI '11, ACM (2011), 3023--3032.  Google ScholarDigital LibraryHoggan, E., Williamson, J., Oulasvirta, A., Nacenta, M., Kristensson, P. O., and Lehtio, A. Multi-touch rotation gestures: Performance and ergonomics. Proceedings of CHI 2013 (2013), 3047--3050.  Google ScholarDigital LibraryHornecker, E., Marshall, P., Dalton, N. S., and Rogers, Y. Collaboration and interference: awareness with mice or touch input. In Proc. CSCW '08, ACM (2008), 167--176.  Google ScholarDigital LibraryJeannerod, M. The timing of natural prehension movements. Journal of motor behavior 16, 3 (1984), 235--254.Google ScholarKruger, R., Carpendale, S., Scott, S. D., and Tang, A. Fluid integration of rotation and translation. In Proc. CHI '05, ACM (2005), 601--610.  Google ScholarDigital LibraryLozano, C., Jindrich, D., and Kahol, K. The impact on musculoskeletal system during multitouch tablet interactions. In Proc. CHI '11, ACM (2011), 825--828.  Google ScholarDigital LibraryMarteniuk, R. G., MacKenzie, C., Jeannerod, M., Athenes, S., and Dugas, C. Constraints on human arm movement trajectories. Canadian Journal of Psychology 41, 3 (1987), 365--378.Google ScholarCross Ref15. M\u00f6llers, M., Dumont, N., Ladwig, S., and Borchers, J. Improving touch accuracy on large tabletops using predecessor and successor. In Proc. CHI '13, ACM (2013), 755--758.  Google ScholarDigital LibraryMorris, M. R., Wobbrock, J. O., and Wilson, A. D. Understanding users' preferences for surface gestures. In Proc. GI '10, Canadian Information Processing Society (2010), 261--268. Google ScholarDigital LibraryMoscovich, T., and Hughes, J. F. Multi--nger cursor techniques. In Proc. GI '06, Canadian Information Processing Society (2006), 1--7. Google ScholarDigital LibraryRosenbaum, D. A., Chapman, K. M., Weigelt, M., Weiss, D. J., and van der Wel, R. Cognition, action, and object manipulation. Psychological Bulletin 138, 5 (2012), 924--946.Google ScholarCross RefRosenbaum, D. A., Marchak, F., Barnes, H. J., Vaughan, J., Slotta, J., and Jorgensen, M. Constraints for action selection: overhand versus underhand grips. In Attention and Performance XIII, M. Jannerod, Ed. Erlbaum, Hillsdale, NJ, 1990, 321--342.Google ScholarRosenbaum, D. A., van Heugten, C. M., and Caldwell, G. E. From cognition to biomechanics and back: The end-state comfort effect and the middle-is-faster effect. Acta Psychologica 94, 1 (1996), 59--85.Google ScholarCross RefRosenbaum, D. A., Vaughan, J., Barnes, H. J., and Jorgensen, M. J. Time course of movement planning: Selection of handgrips for object manipulation. Journal of Experimental Psychology: Learning, Memory, and Cognition 18, 5 (1992), 1058--1073.Google ScholarSantello, M. Kinematic synergies for the control of hand shape. Archives Iteliennes de Biologie 140 (2002), 221--228.Google ScholarShort, M. W., and Cauraugh, J. H. Precision hypothesis and the end-state comfort effect. Acta Psychologica 100, 3 (1999), 243--252.Google ScholarCross RefTuddenham, P., Kirk, D., and Izadi, S. Graspables revisited: multi-touch vs. tangible input for tabletop displays in acquisition and manipulation tasks. In Proc. CHI '10, ACM (2010), 2223--2232.  Google ScholarDigital LibraryVogel, D., and Casiez, G. Hand occlusion on a multi-touch tabletop. In Proc. CHI '12, ACM (2012), 2307--2316.  Google ScholarDigital LibraryWagner, J., Huot, S., and Mackay, W. Bitouch and bipad: designing bimanual interaction for hand-held tablets. In Proc. CHI '12, ACM (2012), 2317--2326.  Google ScholarDigital LibraryWobbrock, J. O., Morris, M. R., and Wilson, A. D. User-defined gestures for surface computing. In Proc. CHI '09, ACM (2009), 1083--1092.  Google ScholarDigital LibraryWu, M., and Balakrishnan, R. Multi--nger and whole hand gestural interaction techniques for multi-user tabletop displays. In Proc. UIST '03, ACM (2003), 193--202.  Google ScholarDigital LibrarySupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/2556288.2557029/a79489af-e28d-47b7-8ac4-533c96dd38f9/pn0426-file3.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ef02e2e52e2faf54fffd7dafb0c787709aa98d8b97a97c300f7b93608b0860682bdf6ab76f91e3f8ec5b56db52a26eabd6d944caad068e20ee47b82a31359dd68009e0c858a5ee8eeeapplication/x-mpegurlmp412.1 MB", "keywords": ["multitouch", "acquisition and manipulation", "tabletops", "movement planning", "end-state comfort effect", "range of motion"], "published_in": "CHI '14: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "26 April 2014", "citations": "9", "isbn": "9781450324731", "doi": "10.1145/2556288", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2556288.2557029", "paper_url": "https://dl.acm.org/doi/10.1145/2556288.2557029"}, {"title": "The Effect of Offset Correction and Cursor on Mid-Air Pointing in Real and Virtual Environments", "authors": ["Sven Mayer", "Valentin Schwind", "Robin Schweigert", "Niels Henze"], "abstract": "Pointing at remote objects to direct others' attention is a fundamental human ability. Previous work explored methods for remote pointing to select targets. Absolute pointing techniques that cast a ray from the user to a target are affected by humans' limited pointing accuracy. Recent work suggests that accuracy can be improved by compensating systematic offsets between targets a user aims at and rays cast from the user to the target. In this paper, we investigate mid-air pointing in the real world and virtual reality. Through a pointing study, we model the offsets to improve pointing accuracy and show that being in a virtual environment affects how users point at targets. In the second study, we validate the developed model and analyze the effect of compensating systematic offsets. We show that the provided model can significantly improve pointing accuracy when no cursor is provided. We further show that a cursor improves pointing accuracy but also increases the selection time.                     References                 Deepak Akkil and Poika Isokoski. 2016. Accuracy of Interpreting Pointing Gestures in Egocentric View. In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp '16). ACM, New York, NY, USA, 262--273.  Google ScholarFerran Argelaguet and Carlos Andujar. 2013. A survey of 3D object selection techniques for virtual environments. Computers &amp; Graphics 37, 3 (2013), 121--136.  Google ScholarFerran Argelaguet, Carlos Andujar, and Ramon Trueba. 2008. Overcoming Eye-hand Visibility Mismatch in 3D Pointing Selection. In Proceedings of the 2008 ACM Symposium on Virtual Reality Software and Technology (VRST '08). ACM, New York, NY, USA, 43--46.  Google ScholarFerran Argelaguet, Ludovic Hoyet, Micha\u00ebl Trico, and Anatole L\u00e9cuyer. 2016. The role of interaction in virtual embodiment: Effects of the virtual hand representation. In Proceedings of the 2016 IEEE Virtual Reality Conference (IEEE/VR '16). Greenville, SC, USA, 3--10.Google ScholarTiziana Aureli, Maria Spinelli, Mirco Fasolo, Maria Concetta Garito, Paola Perucchini, and Laura D'Odorico. 2017. The Pointing-Vocal Coupling Progression in the First Half of the Second Year of Life. Infancy (2017), 18.Google ScholarJohn V. Basmajian and Carlo J. De Luca. 1985. Muscles alive: their functions revealed by electromyography. Williams &amp; Wilkins, Baltimore, London, Sydney. http://books.google.de/books?id=H9pqAAAAMAAJGoogle ScholarScott Bateman, Regan L. Mandryk, Carl Gutwin, and Robert Xiao. 2013. Analysis and comparison of target assistance techniques for relative ray-cast pointing. International Journal of Human-Computer Studies 71, 5 (2013), 511--532.  Google ScholarElizabeth Bates. 1979. The Emergence of Symbols: Cognition and Communication in Infancy. Academic Press. 404 pages. https://books.google.de/books?id=_45-AAAAMAAJGoogle ScholarHrvoje Benko, Andrew D. Wilson, and Federico Zannier. 2014. Dyadic Projected Spatial Augmented Reality. In Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology (UIST '14). ACM, New York, NY, USA, 645--655.  Google ScholarRichard A. Bolt. 1980. Put-that-there: Voice and gesture at the graphics interface. In Proceedings of the 7th annual conference on Computer graphics and interactive techniques (SIGGRAPH '80). ACM, New York, NY, USA, 262--270.  Google ScholarJerome S. Bruner. 1975. The ontogenesis of speech acts. Journal of Child Language 2, 1 (1975), 1--19.Google ScholarLuigia Camaioni, Paola Perucchini, Francesca Bellagamba, and Cristina Colonnesi. 2004. The Role of Declarative Pointing in Developing a Theory of Mind. Infancy 5, 3 (2004), 291--308.Google ScholarC. N. Christakos and S. Lal. 1980. Lumped and population stochastic models of skeletal muscle: Implications and predictions. Biological Cybernetics 36, 2 (01 Feb 1980), 73--85.Google ScholarAndy Cockburn, Philip Quinn, Carl Gutwin, Gonzalo Ramos, and Julian Looser. 2011. Air pointing: Design and evaluation of spatial target acquisition with and without visual feedback. International Journal of Human-Computer Studies 69, 6 (2011), 401--414.  Google ScholarAndrea Corradini and Philip R. Cohen. 2002. Multimodal speech-gesture interface for handfree painting on a virtual paper using partial recurrent neural networks as gesture recognizer. (2002).Google ScholarGiambattista Della Porta. 1593. De refractione Optices Parte: Libri Novem... Ex officina Horatii Salviani, apud Jo. Jacobum Carlinum, &amp; Antonium Pacem.Google ScholarH. Henrik Ehrsson, Charles Spence, and Richard E. Passingham. 2004. That's My Hand! Activity in Premotor Cortex Reflects Feeling of Ownership of a Limb. Science 305, 5685 (2004), 875--877.Google ScholarRodger J. Elble and William C. Koller. 1990. Tremor. Johns Hopkins University Press, Baltimore. https://google.com/books?id=-LdrAAAAMAAJGoogle ScholarJ. M. Foley and Richard Held. 1972. Visually directed pointing as a function of target distance, direction, and available cues. Perception &amp; Psychophysics 12, 3 (01 May 1972), 263--268.Google ScholarEdward G. Freedman and David L. Sparks. 2000. Coordination of the eyes and head: movement kinematics. Experimental Brain Research 131, 1 (01 Mar 2000), 22--32.Google ScholarMichael Steven Anthony Graziano. 1999. Where is my arm? The relative role of vision and proprioception in the neuronal representation of limb position. Proceedings of the National Academy of Sciences 96, 18 (1999), 10418--10421.Google ScholarMichael S. A. Graziano, Dylan F. Cooke, and Charlotte S. R. Taylor. 2000. Coding the Location of the Arm by Sight. Science 290 (2000), 1782--1786. http://www.jstor.org/stable/3081775Google ScholarJan Gugenheimer, Pascal Knierim, Christian Winkler, Julian Seifert, and Enrico Rukzio. 2015. UbiBeam: Exploring the Interaction Space for Home Deployed Projector-Camera Systems. In IFIP TC 13 International Conference on Human-Computer Interaction (INTERACT 2015). Springer International Publishing, Cham, 350--366.  Google ScholarSandra G. Hart. 2006. NASA-Task Load Index (NASA-TLX); 20 years later. In Proceedings of the Human Factors and Ergonomic Society annual meeting, Vol. 50. SAGE Publications, SAGE Publications, Los Angeles, CA, USA, 904--908.Google ScholarJohn B. Haviland. 2003. How to point in Zinacant\u00e1n. Psychology Press, Mahwah, New Jersey, USA, 139--169.Google ScholarHao Jiang, Eyal Ofek, Neema Moraveji, and Yuanchun Shi. 2006. Direct Pointer: Direct Manipulation for Large-display Interaction Using Handheld Cameras. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '06). ACM, New York, NY, USA, 1107--1110.  Google ScholarRicardo Jota, Miguel A. Nacenta, Joaquim A. Jorge, Sheelagh Carpendale, and Saul Greenberg. 2010. A Comparison of Ray Pointing Techniques for Very Large Displays. In Proceedings of Graphics Interface 2010 (GI '10). Canadian Information Processing Society, Toronto, Ont., Canada, Canada, 269--276. http://dl.acm.org/citation.cfm?id=1839214.1839261 Google ScholarAdam Kendon. 2004. Gesture: Visible Action as Utterance. Cambridge University Press, Cambridge. IX, 400 S. pages. https://books.google.de/books?id=WY2bBQAAQBAJGoogle ScholarAarlenne Z. Khan and J. Douglas Crawford. 2003. Coordinating one hand with two eyes: optimizing for field of view in a pointing task. Vision Research 43, 4 (2003), 409--417.Google ScholarPascal Knierim, Valentin Schwind, Anna Feit, Florian Nieuwenhuizen, and Niels Henze. 2018. Physical Keyboards in Virtual Reality: Analysis of Typing Performance and Effects of Avatar Hands. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, NY, USA.  Google ScholarRegis Kopper, Doug A. Bowman, Mara G. Silva, and Ryan P. McMahan. 2010. A Human Motor Behavior Model for Distal Pointing Tasks. International Journal of Human-Computer Studies 68, 10 (Oct. 2010), 603--615.  Google ScholarAlfred Kranstedt, Andy L\u00fccking, Thies Pfeiffer, Hannes Rieser, and Marc Staudacher. 2006. Measuring and Reconstructing Pointing in Visual Contexts. In Proceedings of the 10th Workshop on the Semantics and Pragmatics of Dialogue (brandial'06). Universit\u00e4tsverlag Potsdam, Potsdam, 82--89. http://opus.kobv.de/ubp/ volltexte/2006/1048/pdf/brandial06_proceedings.pdfGoogle ScholarLorraine Lin and Sophie J\u00f6rg. 2016. Need a hand? How Appearance Affects the Virtual Hand Illusion. In Proceedings of the ACM Symposium on Applied Perception (SAP '16). ACM Press, New York, New York, USA, 69--76.  Google ScholarLars Lischke, Pascal Knierim, and Hermann Klinke. 2015. Mid-Air Gestures for Window Management on Large Displays. In Mensch und Computer 2015 Tagungsband. De Gruyter Oldenbourg, Berlin, 439--442.Google ScholarLars Lischke, Valentin Schwind, Kai Friedrich, Albrecht Schmidt, and Niels Henze. 2016. MAGIC-Pointing on Large High-Resolution Displays. In Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI EA '16). ACM, New York, NY, USA, 1706--1712.  Google ScholarI. Scott MacKenzie and Shaidah Jusoh. 2001. An Evaluation of Two Input Devices for Remote Pointing. In Engineering for Human-Computer Interaction: 8th IFIP International Conference (EHCI'01). Springer Berlin Heidelberg, Berlin, Heidelberg, 235--250. Google ScholarVille M\u00e4kel\u00e4, Tomi Heimonen, Matti Luhtala, and Markku Turunen. 2014. Information Wall: Evaluation of a Gesture-controlled Public Display. In Proceedings of the 13th International Conference on Mobile and Ubiquitous Multimedia (MUM '14). ACM, New York, NY, USA, 228--231.  Google ScholarAnders Markussen, Sebastian Boring, Mikkel R. Jakobsen, and Kasper Hornb\u00e6k. 2016. Off-Limits: Interacting Beyond the Boundaries of Large Displays. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI '16). ACM, New York, NY, USA, 5862--5873.  Google ScholarAnders Markussen, Mikkel R\u00f8nne Jakobsen, and Kasper Hornb\u00e6k. 2014. Vulture: A Mid-air Word-gesture Keyboard. In Proceedings of the 32Nd Annual ACM Conference on Human Factors in Computing Systems (CHI '14). ACM, New York, NY, USA, 1073--1082.  Google ScholarSven Mayer, Katrin Wolf, Stefan Schneegass, and Niels Henze. 2015. Modeling Distant Pointing for Compensating Systematic Displacements. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). ACM, New York, NY, USA, 4165--4168.  Google ScholarVictoria McArthur, Steven J. Castellucci, and I. Scott MacKenzie. 2009. An Empirical Comparison of \"Wiimote\" Gun Attachments for Pointing Tasks. In Proceedings of the 1st ACM SIGCHI Symposium on Engineering Interactive Computing Systems (EICS '09). ACM, New York, NY, USA, 203--208.  Google ScholarSamuel Navas Medrano, Max Pfeiffer, and Christian Kray. 2017. Enabling Remote Deictic Communication with Mobile Devices: An Elicitation Study. In Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI '17). ACM, New York, NY, USA, Article 19, 13 pages.  Google ScholarWalter R. Miles. 1930. Ocular Dominance in Human Adults. The journal of general psychology 3, 3 (1930), 412--430.Google ScholarPaul Milgram and Fumio Kishino. 1994. A taxonomy of mixed reality visual displays. IEICE Transactions on Information and Systems 77, 12 (1994), 1321--1329. http://ci.nii.ac.jp/naid/110003209335/en/Google ScholarMark R. Mine. 1995. Virtual Environment Interaction Techniques. Technical Report. University of North Carolina at Chapel Hill, Chapel Hill, NC, USA. http://www.cs.unc.edu/techreports/95-018.pdf Google ScholarMark R. Mine, Frederick P. Brooks Jr., and Carlo H. Sequin. 1997. Moving Objects in Space: Exploiting Proprioception in Virtual-environment Interaction. In Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH '97). ACM Press/Addison-Wesley Publishing Co., New York, NY, USA, 19--26.  Google ScholarSteven Morrison and J. Keogh. 2001. Changes in the dynamics of tremor during goal-directed pointing. Human Movement Science 20, 4 (2001), 675--693.Google ScholarMathieu Nancel, Emmanuel Pietriga, Olivier Chapuis, and Michel Beaudouin-Lafon. 2015. Mid-Air Pointing on Ultra-Walls. ACM Trans. Comput.-Hum. Interact. 22, 5, Article 21 (Aug. 2015), 62 pages.  Google ScholarKai Nickel and Rainer Stiefelhagen. 2003. Pointing Gesture Recognition Based on 3D-tracking of Face, Hands and Head Orientation. In Proceedings of the 5th International Conference on Multimodal Interfaces (ICMI '03). ACM, New York, NY, USA, 140--146.  Google ScholarDan R. Olsen, Jr. and Travis Nielsen. 2001. Laser Pointer Interaction. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '01). ACM, New York, NY, USA, 17--22.  Google ScholarJeni Paay, Dimitrios Raptis, Jesper Kjeldskov, Mikael B. Skov, Eric V. Ruder, and Bjarke M. Lauridsen. 2017. Investigating Cross-Device Interaction Between a Handheld Device and a Large Display. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI '17). ACM, New York, NY, USA, 6608--6619.  Google ScholarJeffrey S. Pierce, Andrew S. Forsberg, Matthew J. Conway, Seung Hong, Robert C. Zeleznik, and Mark R. Mine. 1997. Image Plane Interaction Techniques in 3D Immersive Environments. In Proceedings of the 1997 Symposium on Interactive 3D Graphics (I3D '97). ACM, New York, NY, USA, 39--ff.  Google ScholarKatrin Plaumann, Matthias Weing, Christian Winkler, Michael M\u00fcller, and Enrico Rukzio. 2017. Towards accurate cursorless pointing: the effects of ocular dominance and handedness. Personal and Ubiquitous Computing (07 Dec 2017).Google ScholarCameron N. Riviere, R. Scott Rader, and Pradeep K. Khosla. 1997. Characteristics of hand motion of eye surgeons. In Proceedings of the 19th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (IEEE/EMBS '97), Vol. 4. IEEE, Chicago, IL, USA, USA, 1690--1693.Google ScholarValentin Schwind, Pascal Knierim, Cagri Tasci, Patrick Franczak, Nico Haas, and Niels Henze. 2017. \"These Are Not My Hands!\": Effect of Gender on the Perception of Avatar Hands in Virtual Reality. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI '17). ACM, New York, NY, USA, 1577--1582.  Google ScholarMel Slater, Daniel Perez-marcos, and H. Henrik Ehrsson. 2009. Inducing illusory ownership of a virtual body. Frontiers in neuroscience 3, 2 (Sep 2009), 214--220.Google ScholarR. William Soukoreff and I. Scott MacKenzie. 2004. Towards a standard for pointing device evaluation, perspectives on 27 years of Fitts' law research in HCI. International Journal of Human-Computer Studies 61, 6 (2004), 751--789.  Google ScholarJohn S. Stahl. 1999. Amplitude of human head movements associated with horizontal saccades. Experimental Brain Research 126, 1 (01 Apr 1999), 41--54.Google ScholarDaniel Vogel and Ravin Balakrishnan. 2004. Interactive Public Ambient Displays: Transitioning from Implicit to Explicit, Public to Personal, Interaction with Multiple Users. In Proceedings of the 17th Annual ACM Symposium on User Interface Software and Technology (UIST '04). ACM, New York, NY, USA, 137--146.  Google ScholarDaniel Vogel and Ravin Balakrishnan. 2005. Distant Freehand Pointing and Clicking on Very Large, High Resolution Displays. In Proceedings of the 18th Annual ACM Symposium on User Interface Software and Technology (UIST '05). ACM, New York, NY, USA, 33--42.  Google ScholarChristian Winkler, Ken Pfeuffer, and Enrico Rukzio. 2012. Investigating Mid-air Pointing Interaction for Projector Phones. In Proceedings of the 2012 ACM International Conference on Interactive Tabletops and Surfaces (ITS '12). ACM, New York, NY, USA, 85--94.  Google ScholarNelson Wong and Carl Gutwin. 2014. Support for Deictic Pointing in CVEs: Still Fragmented After All These Years'. In Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing (CSCW '14). ACM, New York, NY, USA, 1377--1387.  Google ScholarShumin Zhai. 1998. User Performance in Relation to 3D Input Device Design. ACM SIGGRAPH Computer Graphics 32, 4 (Nov. 1998), 50--54.  Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3173574.3174227/9c0caf7a-ffde-4851-a664-5a47dd30e761/pn4903-file5.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee06e0e0927f1e11a21c84ce9c058e49e7ac6b66fdacad3330594241a5412680612a23e32fc44f5fd434793dd2b69e6224ef9b278e4d949887001ce46d6f194ade728a1261a8b3f57fapplication/x-mpegurlmp411.2 MB", "keywords": ["modeling", "virtual environment", "offset correction", "cursor", "mid-air pointing", "ray casting"], "published_in": "CHI '18: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems", "publication_date": "21 April 2018", "citations": "15", "isbn": "9781450356206", "doi": "10.1145/3173574", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3173574.3174227", "paper_url": "https://dl.acm.org/doi/10.1145/3173574.3174227"}, {"title": "Design and Evaluation of a Handheld-based 3D User Interface for Collaborative Object Manipulation", "authors": ["Jer\u00f4nimo Gustavo Grandi", "Henrique Galvan Debarba", "Luciana Nedel", "Anderson Maciel"], "abstract": "Object manipulation in 3D virtual environments demands a combined coordination of rotations, translations and scales, as well as the camera control to change the user's viewpoint. Then, for many manipulation tasks, it would be advantageous to share the interaction complexity among team members. In this paper we propose a novel 3D manipulation interface based on a collaborative action coordination approach. Our technique explores a smartphone -- the touchscreen and inertial sensors -- as input interface, enabling several users to collaboratively manipulate the same virtual object with their own devices. We first assessed our interface design on a docking and an obstacle crossing tasks with teams of two users. Then, we conducted a study with 60 users to understand the influence of group size in collaborative 3D manipulation. We evaluated teams in combinations of one, two, three and four participants. Experimental results show that teamwork increases accuracy when compared with a single user. The accuracy increase is correlated with the number of individuals in the team and their work division strategy.", "keywords": ["3D user interfaces", "collaborative manipulation", "user studies"], "published_in": "CHI '17: Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2017", "citations": "11", "isbn": "9781450346559", "doi": "10.1145/3025453", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3025453.3025935", "paper_url": "https://dl.acm.org/doi/10.1145/3025453.3025935"}, {"title": "Eden: a professional multitouch tool for constructing virtual organic environments", "authors": ["Kenrick Kin", "Tom Miller", "Bj\u00f6rn Bollensdorff", "Tony Derose", "Bj\u00f6rn Hartmann", "Maneesh Agrawala"], "abstract": "Set construction is the process of selecting and positioning virtual geometric objects to create a virtual environment used in a computer-animated film. Set construction artists often have a clear mental image of the set composition, but find it tedious to build their intended sets with current mouse and keyboard interfaces. We investigate whether multitouch input can ease the process of set construction. Working with a professional set construction artist at Pixar Animation Studios, we designed and developed Eden, a fully functional multitouch set construction application. In this paper, we describe our design process and how we balanced the advantages and disadvantages of multitouch input to develop usable gestures for set construction. Based on our design process and the user experiences of two set construction artists, we present a general set of lessons we learned regarding the design of a multitouch interface.", "keywords": ["Eden", "camera control", "object manipulation", "gestures", "set construction", "multitouch", "gesture design"], "published_in": "CHI '11: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "7 May 2011", "citations": "31", "isbn": "9781450302289", "doi": "10.1145/1978942", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1978942.1979141", "paper_url": "https://dl.acm.org/doi/10.1145/1978942.1979141"}, {"title": "The Effect of Stereo Display Deficiencies on Virtual Hand Pointing", "authors": ["Mayra Donaji Barrera Machuca", "Wolfgang Stuerzlinger"], "abstract": "The limitations of stereo display systems affect depth perception, e.g., due to the vergence-accommodation conflict or diplopia. We performed three studies to understand how stereo display deficiencies impact 3D pointing for targets in front of a screen and close to the user, i.e., in peripersonal space. Our first two experiments compare movements with and without a change in visual depth for virtual respectively physical targets. Results indicate that selecting targets along the depth axis is slower and has less throughput for virtual targets, while physical pointing demonstrates the opposite result. We then propose a new 3D extension for Fitts' law that models the effect of stereo display deficiencies. Next, our third experiment verifies the model and measures more broadly how the change in visual depth between targets affects pointing performance in peripersonal space and confirms significant effects on time and throughput. Finally, we discuss implications for 3D user interface design.                     References                 Hirotugu A. 1974. A new look at the statistical model identification. IEEE Trans. Automat. Control 19, 6 (1974), 716--723.Google ScholarCross RefJohnny Accot and Shumin Zhai. 2003. Refining Fitts' law models for bivariate pointing. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '03). ACM Press, New York, New York, USA, 193--200.  Google ScholarDigital LibraryNicholas T. Antony and Peter J. Keir. 2010. Effects of posture, movement and hand load on shoulder muscle activity. Journal of Electromyography and Kinesiology 20, 2 (Apr 2010), 191--198.Google ScholarCross RefFerran Argelaguet and Carlos Andujar. 2013. A survey of 3D object selection techniques for virtual environments. Computers &amp; Graphics 37, 3 (May 2013), 121--136.  Google ScholarDigital LibraryMayra Donaji Barrera Machuca and Wolfgang Stuerzlinger. 2018. Do Stereo Display Deficiencies Affect 3D Pointing? Extended abstracts of the SIGCHI conference on Human Factors in Computing Systems (CHI '18) (2018), 1--6.  Google ScholarDigital LibraryGeoffrey P. Bingham, Arthur Bradley, Michael Bailey, and Roy Vinner. 2001. Accommodation, occlusion, and disparity matching are used to guide reaching: A comparison of actual versus virtual environments. Journal of Experimental Psychology: Human Perception and Performance 27, 6 (2001), 1314--1334.Google ScholarCross RefJames Boritz and Kellogg S. Booth. 1997. A study of interactive 3D point location in a computer simulated virtual environment. In Proceedings of the ACM Symposium on Virtual Reality Software and Technology (VRST '97). ACM Press, New York, New York, USA, 181--187.  Google ScholarDigital LibraryDoug A. Bowman and Larry F. Hodges. 1997. An evaluation of techniques for grabbing and manipulating remote objects in immersive virtual environments. Proceedings of the Symposium on Interactive 3D Graphics (SI3D'97) (1997), 35--ff.  Google ScholarDigital LibraryDoug A. Bowman, Ernst Kruijff, Joseph J. LaViola Jr., and Ivan Poupyrev. 2004. 3D User Interfaces: Theory and Practice (1st ed.). Addison-Wesley. 512 pages. Google ScholarDigital LibraryJames M. Brown and Naomi Weisstein. 1988. A spatial frequency effect on perceived depth. Perception &amp; Psychophysics 44, 2 (Mar 1988), 157--166.Google ScholarCross RefGerd Bruder, Frank Steinicke, and Wolfgang Stuerzlinger. 2013. Effects of visual conflicts on 3D selection task performance in stereoscopic display environments. In Proceedings of the IEEE Symposium on 3D User Interfaces (3DUI'13). 115--118.Google ScholarCross RefK.P. Burnham and D.R. Anderson. 2002. Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach (2nd ed). Vol. 172. 488 pages. arXiv:arXiv:1011.1669v3Google ScholarYeonjoo Cha and Rohae Myung. 2013. Extended Fitts' law for 3D pointing tasks using 3D target arrangements. International Journal of Industrial Ergonomics 43, 4 (Jul 2013), 350--355.Google ScholarCross RefJames E. Cutting and Peter M. Vishton. 1995. Perceiving Layout and Knowing Distances: The Integration, Relative Potency and Contextual Use of Different Information about Depth. In Handbook of perception and cognition, Vol 5; Perception of space and motion. Academic Press, San Diego, California, USA, 69--117.Google ScholarHeiko Drewes. 2010. Only one Fitts' law formula please!. In Extended abstracts of the SIGCHI conference on Human Factors in Computing Systems (CHI '10). ACM Press, New York, New York, USA, 2813.  Google ScholarDigital LibraryFrank H. Durgin, Dennis R. Proffitt, Thomas J. Olson, and Karen S. Reinke. 1995. Comparing depth from motion with depth from binocular disparity. Journal of Experimental Psychology: Human Perception and Performance 21, 3 (1995), 679--699.Google ScholarCross RefG. N. Dutton, A. Saaed, B. Fahad, R. Fraser, G. McDaid, J. McDade, A. Mackintosh, T. Rane, and K. Spowart. 2004. Association of binocular lower visual field impairment, impaired simultaneous perception, disordered visually guided motion and inaccurate saccades in children with cerebral visual dysfunction-a retrospective observational study. Eye 18, 1 (Jan 2004), 27--34.Google ScholarCross RefPaul M. Fitts. 1954. The Information Capacity of the Human Motor System in Controlling the Amplitude of Movements. Journal of Experimental Psychology 47, 3 (1954), 381--391.Google ScholarCross RefPaul M. Fitts and James R. Peterson. 1964. Information capacity of discrete motor responses. Journal of Experimental Psychology 67, 2 The Effect of Stereo Display Deficiencies on Virtual Hand Pointing CHI 2019, May 4--9, 2019, Glasgow, Scotland UK (1964), 103--112.Google ScholarCross RefEvan D. Graham and Christine L. MacKenzie. 1996. Physical versus virtual pointing. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '96). ACM Press, New York, New York, USA, 292--299.  Google ScholarDigital LibraryTovi Grossman and Ravin Balakrishnan. 2004. Pointing at trivariate targets in 3D environments. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '04). ACM Press, New York, New York, USA, 447--454.  Google ScholarDigital LibraryTovi Grossman and Ravin Balakrishnan. 2005. A probabilistic approach to modeling two-dimensional pointing. ACM Transactions on Computer- Human Interaction 12, 3 (Sep 2005), 435--459.  Google ScholarDigital LibraryTaejin Ha and Woontack Woo. 2010. An empirical evaluation of virtual hand techniques for 3D object manipulation in a tangible augmented reality environment. In Proceedings of the IEEE Symposium on 3D User Interfaces (3DUI'10). IEEE, 91--98.  Google ScholarDigital LibraryRobert F. Hess, Long To, Jiawei Zhou, Guangyu Wang, and Jeremy R. Cooperstock. 2015. Stereo Vision: The Haves and HaveNots. i-Perception 6, 3 (Jun 2015), 1--5.Google ScholarDavid M. Hoffman, Ahna R. Girshick, Kurt Akeley, and Martin S. Banks. 2008. Vergence-accommodation conflicts hinder visual performance and cause visual fatigue. Journal of Vision 8, 3 (Mar 2008), 33.1--30.Google ScholarCross RefHyungki Hong and Seok Hyon Kang. 2015. Measurement of the lens accommodation in viewing stereoscopic displays. Journal of the Society for Information Display 23, 1 (Jan 2015), 19--26.Google ScholarCross RefHTC. 2016. VIVE. (2016). https://www.vive.com/ca/Google ScholarISO. 2015. ISO 9241--400:2007 Ergonomics of human--system interaction -- Part 400: Principles and requirements for physical input devices. (2015).Google ScholarIzabelle Janzen, Vasanth K. Rajendran, and Kellogg S. Booth. 2016. The Impact of Target Depth on Pointing Performance. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '16). ACM Press, New York, New York, USA, 188--199.  Google ScholarDigital LibraryRobert V. Kenyon and Stephen R. Ellis. 2014. Vision, Perception, and Object Manipulation in Virtual Environments. In Virtual Reality for Physical and Motor Rehabilitation, Patrice L. Weiss, Emily A. Keshner, and Mindy F. Levin (Eds.). Springer New York, New York, NY, 47--70.Google ScholarRegis Kopper, Doug A. Bowman, Mara G. Silva, and Ryan P. McMahan. 2010. A human motor behavior model for distal pointing tasks. International Journal of Human - Computer Studies 68, 10 (Oct 2010), 603--615.  Google ScholarDigital LibraryGeorgios Kouroupetroglou, Alexandros Pino, Athanasios Balmpakakis, Dimitrios Chalastanis, Vasileios Golematis, Nikolaos Ioannou, and Ioannis Koutsoumpas. 2012. Using Wiimote for 2D and 3D Pointing Tasks: Gesture Performance Evaluation. In Proceedings of the International Conference on Gesture and Sign Language in Human-Computer Interaction and Embodied Communication. Lecture Notes in Computer Science, Vol. 7206. Springer Berlin Heidelberg, Berlin, Heidelberg, 13-- 23.  Google ScholarDigital LibraryLeap Motion. 2016. Orion. (2016). https://www.leapmotion.com/Google ScholarChiuhsiang J. Lin and Bereket H. Woldegiorgis. 2015. Interaction and visual performance in stereoscopic displays: A review. Journal of the Society for Information Display 23, 7 (Jul 2015), 319--332.Google ScholarCross RefChiuhsiang J. Lin and Bereket H. Woldegiorgis. 2017. Egocentric distance perception and performance of direct pointing in stereoscopic displays. Applied Ergonomics 64 (Oct 2017), 66--74.Google ScholarPaul Lubos, Gerd Bruder, and Frank Steinicke. 2014. Analysis of direct selection in head-mounted display environments. Proceedings of the IEEE Symposium on 3D User Interfaces (3DUI'14) (2014), 11--18.Google ScholarCross RefI. Scott MacKenzie. 2015. Fitts' Throughput and the Remarkable Case of Touch-Based Target Selection. In Proceedings of the International Conference on Human-Computer Interaction (HCII'15) (Lecture Notes in Computer Science), Masaaki Kurosu (Ed.), Vol. LNCS 9170. Springer International Publishing, Switzerland, 238--249.Google ScholarCross RefGuido Maiello, Miyoung Kwon, and Peter J Bex. 2018. Threedimensional binocular eye hand coordination in normal vision and with simulated visual impairment. Experimental Brain Research 236, 3 (Mar 2018), 691--709.Google ScholarCross RefAlison McDonald, Bryan R. Picco, Alicia L. Belbeck, Amy Y. Chow, and Clark R. Dickerson. 2012. Spatial dependency of shoulder muscle demands in horizontal pushing and pulling. Applied Ergonomics 43, 6 (Nov 2012), 971--978.Google ScholarCross RefJohn P. McIntire, Paul R. Havig, and Eric E. Geiselman. 2014. Stereoscopic 3D displays and human performance: A comprehensive review. Displays 35, 1 (Jan 2014), 18--26.Google ScholarCross RefMetaVision. 2012. MetaVision desktop. (2012). http://www.metavision. com/Google ScholarAtsuo Murata and Hirokazu Iwase. 2001. Extending Fitts' law to a three-dimensional pointing task. Human Movement Science 20, 6 (Dec 2001), 791--805.Google ScholarCross RefKephart Newell C. 1962. The Slow Learner in the Classroom. C. E. Merrill Books, Columbus. 292 pages.Google ScholarKarin Nieuwenhuizen, Jean-Bernard Martens, Lei Liu, and Robert van Liere. 2009. Insights from Dividing 3D Goal-Directed Movements into Meaningful Phases. IEEE Computer Graphics and Applications 29, 6 (Nov 2009), 44--53.Google ScholarCross RefOculus. 2016. Rift. (2016). https://www.oculus.com/Google ScholarRobert Patterson. 2007. Human Factors of 3-D Displays. Journal of the Society for Information Display 15, 11 (2007), 861--871.Google ScholarCross RefRobert Patterson and Wayne L. Martin. 1992. Human stereopsis. Human Factors: The Journal of the Human Factors and Ergonomics Society 34, 6 (Dec 1992), 669--92.Google ScholarCross RefMax Pfeiffer and Wolfgang Stuerzlinger. 2015. 3D virtual hand pointing with EMS and vibration feedback. In Proceedings of the IEEE Symposium on 3D User Interfaces (3DUI'15). IEEE, New York, New York, USA, 117-- 120.Google ScholarCross RefAlexandros Pino, Evangelos Tzemis, Nikolaos Ioannou, and Georgios Kouroupetroglou. 2013. Using Kinect for 2D and 3D Pointing Tasks: Performance Evaluation. In Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). Vol. 8007 LNCS. Springer-Verlag Berlin Heidelberg, 358--367.  Google ScholarDigital LibraryIvan Poupyrev, T. Ichikawa, S. Weghorst, and Mark Billinghurst. 1998. Egocentric Object Manipulation in Virtual Environments: Empirical Evaluation of Interaction Techniques. Computer Graphics Forum 17, 3 (Aug 1998), 41--52.Google ScholarCross RefRebekka S. Renner, Boris M. Velichkovsky, and Jens R. Helmert. 2013. The perception of egocentric distances in virtual environments - A review. Comput. Surveys 46, 2 (Nov 2013), 1--40. arXiv:arXiv:1502.07526v1 CHI 2019, May 4--9, 2019, Glasgow, Scotland UK Barrera &amp; Stuerzlinger  Google ScholarDigital LibraryW. N. Schofield. 1976. Do children find movements which cross the body midline difficult? Quarterly Journal of Experimental Psychology 28, 4 (1976), 571--582.Google ScholarCross RefGarth B. D. Shoemaker, Takayuki Tsukitani, Yoshifumi Kitamura, and Kellogg S. Booth. 2012. Two-Part Models Capture the Impact of Gain on Pointing Performance. ACM Transactions on Computer- Human Interaction 19, 4 (Dec 2012), 1--34.  Google ScholarDigital LibraryR. William Soukoreff and I. Scott MacKenzie. 2004. Towards a standard for pointing device evaluation, perspectives on 27 years of Fitts' law research in HCI. International Journal of Human - Computer Studies 61, 6 (Dec 2004), 751--789.  Google ScholarDigital LibraryHelmut Strasser and Karl-Werner M\u00fcller. 1999. Favorable movements of the hand-arm system in the horizontal plane assessed by electromyographic investigations and subjective rating. International Journal of Industrial Ergonomics 23, 4 (Mar 1999), 339--347.Google ScholarCross RefRajaraman Suryakumar, Jason P. Meyers, Elizabeth L. Irving, and William R. Bobier. 2007. Vergence accommodation and monocular closed loop blur accommodation have similar dynamic characteristics. Vision Research 47, 3 (2007), 327--337.Google ScholarCross RefJ. Edward Swan, Gurjot Singh, and Stephen R. Ellis. 2015. Matching and Reaching Depth Judgments with Real and Augmented Reality Targets. IEEE Transactions on Visualization and Computer Graphics 21, 11 (Nov 2015), 1289--1298.  Google ScholarDigital LibraryRobert J. Teather and Wolfgang Stuerzlinger. 2011. Pointing at 3D targets in a stereo head-tracked virtual environment. In Proceedings of the IEEE Symposium on 3D User Interfaces (3DUI'11). IEEE, 87--94. Google ScholarDigital LibraryRobert J. Teather and Wolfgang Stuerzlinger. 2013. Pointing at 3d target projections with one-eyed and stereo cursors. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '13). ACM Press, New York, New York, USA, 159.  Google ScholarDigital LibraryJulian J. Tramper and Stan Gielen. 2011. Visuomotor coordination is different for different directions in three-dimensional space. The Journal of Neuroscience 31, 21 (2011), 7857--7866.Google ScholarCross RefJean-Luc Velay, Virginie Daffaure, Nathalie Raphael, and Simone Benoit-Dubrocard. 2001. Hemispheric Asymmetry and Interhemispheric Transfer in Pointing Depend on the Spatial Components of the Movement. Cortex 37, 1 (Jan 2001), 75--90.Google ScholarCross RefJacob O. Wobbrock, Leah Findlater, Darren Gergle, and James J. Higgins. 2011. The aligned rank transform for nonparametric factorial analyses using only anova procedures. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11). 143.  Google ScholarDigital LibraryCharles M. Zaroff, Magosha Knutelska, and Thomas E. Frumkes. 2003. Variation in Stereoacuity: Normative Description, Fixation Disparity, and the Roles of Aging and Gender. Investigative Ophthalmology &amp; Visual Science 44, 2 (Feb 2003), 891.Google ScholarCross RefSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3290605.3300437/268221eb-c631-4814-a30d-02ee9c06c0cf/paper207.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee05eee35a4ac3e15fa134b9c32d1a9e37ff5724531fc475a06372029f066ae41405bda3d91c30eea71b1d7e2f39aa7e9a8c69e42c2ba5d9bf2e657997c5dbb997b73b78a9be11a2a5application/x-mpegurlmp4189.9 MB", "keywords": ["fitt's law", "selection", "3d pointing", "cursor"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "12", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300437", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300437"}, {"title": "RayCursor: A 3D Pointing Facilitation Technique based on Raycasting", "authors": ["Marc Baloup", "Thomas Pietrzak", "G\u00e9ry Casiez"], "abstract": "Raycasting is the most common target pointing technique in virtual reality environments. However, performance on small and distant targets is impacted by the accuracy of the pointing device and the user's motor skills. Current pointing facilitation techniques are currently only applied in the context of the virtual hand, i.e. for targets within reach. We propose enhancements to Raycasting: filtering the ray, and adding a controllable cursor on the ray to select the nearest target. We describe a series of studies for the design of the visual feedforward, filtering technique, as well as a comparative study between different 3D pointing techniques. Our results show that highlighting the nearest target is one of the most efficient visual feedforward technique. We also show that filtering the ray reduces error rate in a drastic way. Finally we show the benefits of RayCursor compared to Raycasting and another technique from the literature.                     References                 Ferran Argelaguet and Carlos Andujar. 2013. A survey of 3D object selection techniques for virtual environments. Computers and Graphics 37, 3 (2013), 121 -- 136. RayCursor CHI 2019, May 4--9, 2019, Glasgow, Scotland Uk  Google ScholarDigital LibraryMarc Baloup, Veis Oudjail, Thomas Pietrzak, and G\u00e9ry Casiez. 2018. Pointing Techniques for Distant Targets in Virtual Reality. In Proceedings of the AFIHM Conf\u00e9rence Francophone sur l'interaction HommeMachine (IHM 2018) (Articles Scientifiques). Brest, France, 8. https: //hal.archives-ouvertes.fr/hal-01899061  Google ScholarDigital LibraryRenaud Blanch, Yves Guiard, and Michel Beaudouin-Lafon. 2004. Semantic Pointing: Improving Target Acquisition with Control-display Ratio Adaptation. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '04). ACM, New York, NY, USA, 519--526.  Google ScholarDigital LibraryDoug A. Bowman, Ernst Kruijff, Joseph J. LaViola, and Ivan Poupyrev. 2004. 3D User Interfaces: Theory and Practice. Addison Wesley Longman Publishing Co., Inc., Redwood City, CA, USA. Google ScholarDigital LibraryGeorge EP Box and David R Cox. 1964. An analysis of transformations. Journal of the Royal Statistical Society. Series B (Methodological) (1964), 211--252.Google ScholarJeffrey Cashion, Chadwick Wingrave, and Joseph J LaViola Jr. 2012. Dense and dynamic 3d selection for game-based virtual environments. IEEE transactions on visualization and computer graphics 18, 4 (2012), 634--642.  Google ScholarDigital LibraryG\u00e9ry Casiez and Nicolas Roussel. 2011. No More Bricolage!: Methods and Tools to Characterize, Replicate and Compare Pointing Transfer Functions. In Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology (UIST '11). ACM, New York, NY, USA, 603--614.  Google ScholarDigital LibraryG\u00e9ry Casiez, Nicolas Roussel, Romuald Vanbelleghem, and Fr\u00e9d\u00e9ric Giraud. 2011. Surfpad: Riding Towards Targets on a Squeeze Film Effect. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11). ACM, New York, NY, USA, 2491--2500.  Google ScholarDigital LibraryG\u00e9ry Casiez, Nicolas Roussel, and Daniel Vogel. 2012. 1e Filter: A Simple Speed-based Low-pass Filter for Noisy Input in Interactive Systems. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '12). ACM, New York, NY, USA, 2527--2530.  Google ScholarDigital LibraryGerwin de Haan, Michal Koutek, and Frits H. Post. 2005. IntenSelect: Using Dynamic Object Rating for Assisting 3D Object Selection. In Proceedings of the 11th Eurographics Conference on Virtual Environments (EGVE'05). Eurographics Association, Aire-la-Ville, Switzerland, Switzerland, 201--209. Google ScholarDigital LibraryWilliam Delamare, C\u00e9line Coutrix, and Laurence Nigay. 2013. Mobile Pointing Task in the Physical World: Balancing Focus and Performance While Disambiguating. In Proceedings of the 15th International Conference on Human-computer Interaction with Mobile Devices and Services (MobileHCI '13). ACM, New York, NY, USA, 89--98.  Google ScholarDigital LibraryNiklas Elmqvist and Jean-Daniel Fekete. 2008. Semantic Pointing for Object Picking in Complex 3D Environments. In Proceedings of Graphics Interface 2008 (GI '08). Canadian Information Processing Society, Toronto, Ont., Canada, 243--250. http://dl.acm.org/citation. cfm?id=1375714.1375755 Google ScholarDigital LibraryTovi Grossman and Ravin Balakrishnan. 2005. The Bubble Cursor: Enhancing Target Acquisition by Dynamic Resizing of the Cursor's Activation Area. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '05). ACM, New York, NY, USA, 281--290.  Google ScholarDigital LibraryTovi Grossman and Ravin Balakrishnan. 2006. The Design and Evaluation of Selection Techniques for 3D Volumetric Displays. In Proceedings of the 19th Annual ACM Symposium on User Interface Software and Technology (UIST '06). ACM, New York, NY, USA, 3--12.  Google ScholarDigital LibraryYves Guiard, Renaud Blanch, and Michel Beaudouin-Lafon. 2004. Object Pointing: A Complement to Bitmap Pointing in GUIs. In Proceedings of Graphics Interface 2004 (GI '04). Canadian Human-Computer Communications Society, School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada, 9--16. http://dl.acm.org/citation. cfm?id=1006058.1006060 Google ScholarDigital LibraryMaxime Guillon, Fran\u00e7ois Leitner, and Laurence Nigay. 2014. Static Voronoi-Based Target Expansion Technique for Distant Pointing. In Proceedings of the International Working Conference on Advanced Visual Interfaces (AVI 2014), Franca Garzotto, Paolo Paolini, Antonella De Angeli, Giulio Jacucci, Alessio Malizia, Maristella Matera, and Rosa Lanzilotti (Eds.). ACM, Como, Italy, 41--48.  Google ScholarDigital LibraryMaxime Guillon, Fran\u00e7ois Leitner, and Laurence Nigay. 2015. Investigating Visual Feedforward for Target Expansion Techniques. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). ACM, New York, NY, USA, 2777--2786.  Google ScholarDigital LibraryAakar Gupta, Thomas Pietrzak, Cleon Yau, Nicolas Roussel, and Ravin Balakrishnan. 2017. Summon and Select: Rapid Interaction with Interface Controls in Mid-air. In Proceedings of the 2017 ACM International Conference on Interactive Surfaces and Spaces (ISS '17). ACM, New York, NY, USA, 52--61.  Google ScholarDigital LibraryKen Hinckley, Randy Pausch, John C. Goble, and Neal F. Kassell. 1994. A Survey of Design Issues in Spatial Input. In Proceedings of the 7th Annual ACM Symposium on User Interface Software and Technology (UIST '94). ACM, New York, NY, USA, 213--222.  Google ScholarDigital LibraryRegis Kopper, Felipe Bacim, and Doug A Bowman. 2011. Rapid and accurate 3D selection by progressive refinement. In 2011 IEEE Symposium on 3D User Interfaces (3DUI). IEEE, IEEE Computer Society, Washington, DC, USA, 67--74. Google ScholarDigital LibraryMikko Kyt\u00f6, Barrett Ens, Thammathip Piumsomboon, Gun A. Lee, and Mark Billinghurst. 2018. Pinpointing: Precise Head- and Eye-Based Target Selection for Augmented Reality. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, NY, USA, Article 81, 14 pages.  Google ScholarDigital LibraryJiandong Liang and Mark Green. 1994. JDCAD: A highly interactive 3D modeling system. Computers &amp; Graphics 18, 4 (1994), 499 -- 506.Google ScholarCross RefMark R Mine. 1995. Virtual environment interaction techniques. Technical Report. University of North Carolina, Chapel Hill, NC, USA. Google ScholarDigital LibraryMathieu Nancel, Olivier Chapuis, Emmanuel Pietriga, Xing-Dong Yang, Pourang P Irani, and Michel Beaudouin-Lafon. 2013. Highprecision pointing on large wall displays using small handheld devices. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '13). ACM, New York, NY, USA, 831--840.  Google ScholarDigital LibraryGang Ren and Eamonn O'Neill. 2013. 3D selection with freehand gesture. Computers &amp; Graphics 37, 3 (May 2013), 101--120.  Google ScholarDigital LibraryHyocheol Ro, Seungho Chae, Inhwan Kim, Junghyun Byun, Yoonsik Yang, Yoonjung Park, and Tackdon Han. 2017. A dynamic depthvariable ray-casting interface for object manipulation in ar environments. In 2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC). IEEE Systems, Man, and Cybernetics Society, 2873-- 2878. CHI 2019, May 4--9, 2019, Glasgow, Scotland Uk M. Baloup et al.Google ScholarGreg Schmidt, Yohan Baillot, Dennis G. Brown, Erik B. Tomlin, and J. Edward II Swan. 2006. Toward Disambiguating Multiple Selections for Frustum-Based Pointing. In Proceedings of the 3D User Interfaces (3DUI '06). IEEE Computer Society, Washington, DC, USA, 87--94.  Google ScholarDigital LibraryFrank Steinicke, Timo Ropinski, and Klaus Hinrichs. 2004. Object selection in virtual environments with an improved virtual pointer metaphor. In Computer Vision and Graphics: International Conference, ICCVG 2004. Springer Netherlands, Warsaw, Poland, 320--326.Google ScholarLode Vanacken, Tovi Grossman, and Karin Coninx. 2007. Exploring the Effects of Environment Density and Target Visibility on Object Selection in 3D Virtual Environments. In 2007 IEEE Symposium on 3D User Interfaces. IEEE Computer Society, Washington, DC, USA.Google ScholarCross RefDonald Lee Vickers. 1972. Sorcerer's Apprentice: Head-mounted Display and Wand. Ph.D. Dissertation.Google ScholarVive. 2019. HTC Vive VR headset. https://www.vive.com/us/product/ vive-virtual-reality-system/, retrieved January 7th, 2019.Google ScholarDaniel Vogel and Ravin Balakrishnan. 2005. Distant Freehand Pointing and Clicking on Very Large, High Resolution Displays. In Proceedings of the 18th Annual ACM Symposium on User Interface Software and Technology (UIST '05). ACM, New York, NY, USA, 33--42.  Google ScholarDigital LibraryJacob O. Wobbrock, Leah Findlater, Darren Gergle, and James J. Higgins. 2011. The Aligned Rank Transform for Nonparametric Factorial Analyses Using Only Anova Procedures. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11). ACM, New York, NY, USA, 143--146.  Google ScholarDigital Librarypaper101vc.zipVideo figure captionsSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3290605.3300331/e0443c2a-e054-43e9-9773-895973f46178/paper101p.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee05eee35a4ac3e15fa134b9c42d1c9e60f95b22c1328b94f7b9be4bda9793a3a0e678ca6ac0ba044b4328bfb436af4d4d264c01951916c1954c0eb7c557189b0a0296541f9bf6b06dapplication/x-mpegurlmp41.8 MB", "keywords": ["virtual reality", "pointing technique", "visual feedforward"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "12", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300331", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300331"}, {"title": "Designing effective gaze mechanisms for virtual agents", "authors": ["Sean Andrist", "Tomislav Pejsa", "Bilge Mutlu", "Michael Gleicher"], "abstract": "Virtual agents hold great promise in human-computer interaction with their ability to afford embodied interaction using nonverbal human communicative cues. Gaze cues are particularly important to achieve significant high-level outcomes such as improved learning and feelings of rapport. Our goal is to explore how agents might achieve such outcomes through seemingly subtle changes in gaze behavior and what design variables for gaze might lead to such positive outcomes. Drawing on research in human physiology, we developed a model of gaze behavior to capture these key design variables. In a user study, we investigated how manipulations in these variables might improve affiliation with the agent and learning. The results showed that an agent using affiliative gaze elicited more positive feelings of connection, while an agent using referential gaze improved participants' learning. Our model and findings offer guidelines for the design of effective gaze behaviors for virtual agents.", "keywords": ["gaze", "nonverbal behavior", "affiliation", "learning", "virtual agents"], "published_in": "CHI '12: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "5 May 2012", "citations": "31", "isbn": "9781450310154", "doi": "10.1145/2207676", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2207676.2207777", "paper_url": "https://dl.acm.org/doi/10.1145/2207676.2207777"}, {"title": "TouchTools: leveraging familiarity and skill with physical tools to augment touch interaction", "authors": ["Chris Harrison", "Robert Xiao", "Julia Schwarz", "Scott E. Hudson"], "abstract": "The average person can skillfully manipulate a plethora of tools, from hammers to tweezers. However, despite this remarkable dexterity, gestures on today's touch devices are simplistic, relying primarily on the chording of fingers: one-finger pan, two-finger pinch, four-finger swipe and similar. We propose that touch gesture design be inspired by the manipulation of physical tools from the real world. In this way, we can leverage user familiarity and fluency with such tools to build a rich set of gestures for touch interaction. With only a few minutes of training on a proof-of-concept system, users were able to summon a variety of virtual tools by replicating their corresponding real-world grasps.                     References                 Apple Computer, Inc. Multi-touch gesture dictionary (2008). US Patent 20070177803.Google ScholarBartindale, T. Harrison, C., Olivier, P. L., and Hudson, S. SurfaceMouse: Supplementing Multi-Touch Interaction with a Virtual Mouse. In Proc. TEI '11. 293--296.  Google ScholarDigital LibraryBaudel, T., and Beaudouin-Lafon, M. Charade: remote control of objects using free-hand gestures. Comm. ACM, 36(7). 28--35.  Google ScholarDigital LibraryCao, X., A. Wilson, R. Balakrishnan, K. Hinckley, S. Hudson. ShapeTouch: Leveraging contact shape on interactive surfaces. In Proc. ITS '08. 129--136.Google ScholarEpps, J., Lichman, S. and Wu, M. A study of hand shape use in tabletop gesture interaction. In CHI EA '06. 748--753.  Google ScholarDigital LibraryErol, A., Bebis, G., Nicolescu, M., Boyle, R., and Twombly, X. Vision-based hand pose estimation: A review. Computer Vision and Image Understanding, 108(1), 2007, 52--73.  Google ScholarDigital LibraryEwerling, P., Kulik, A., and Froehlich, B. Finger and hand detection for multi-touch interfaces based on maximally stable extremal regions. In Proc. ITS '12. 173--182.  Google ScholarDigital LibraryFreeman, D., Benko, H., Morris, M. and Wigdor, D. ShadowGuides: Visualizations for in-situ learning of multi-touch and whole-hand gestures. In Proc. ITS '09. 165--172.  Google ScholarDigital LibraryHinckley, K., Yatani, K., Pahud, M., Coddington, N., Rodenhouse, D., Wilson, A., Benko, H. and Buxton, B. Pen + touch = new tools. In Proc. UIST '10. 27--36.  Google ScholarDigital LibraryHolz, C. and Baudisch, P. The generalized perceived input point model and how to double touch accuracy by extracting fingerprints. In Proc. CHI '10. 581--590.  Google ScholarDigital LibraryKratz, S., Rohs, M., Guse, D., M\u00fcller, J., Bailly, G. and Nischt, M. PalmSpace: continuous around-device gestures vs. multitouch for 3D rotation tasks on mobile devices. In Proc. AVI '12. 181--188.  Google ScholarDigital LibraryMacKenzie, C. L., and Iberall, T. (1994). The Grasping Hand. Advances in Psychology, Vol. 104. North Holland, Elsevier Science B.V. Amsterdam, The Netherlands.Google ScholarMarquardt, N., Kiemer, J., Ledo, D., Boring, S. and Greenberg, S. Designing user-, hand-, and handpart-aware tabletop interactions with the TouchID toolkit. In Proc. ITS '11. 21--30.  Google ScholarDigital LibraryMurugappan, S., Vinayak, Elmqvist, N. and Ramani, K. Extended multitouch: recovering touch posture and differentiating users using a depth camera. In Proc. UIST '12. 487--496.  Google ScholarDigital LibraryPatkin, M. (1981). Ergonomics and the Surgeon. Clinical Science for Surgeons. Butterworth. London, UK.Google ScholarPoupyrev, I., Weghorst, S., Billinghurst, M., Ichikawa, T., A framework and testbed for studying manipulation techniques for immersive VR. In Proc. VRST '97. 21--28.  Google ScholarDigital LibraryRekimoto, J. SmartSkin: An infrastructure for free-hand manipulation on interactive surfaces. In Proc. CHI '02. 113--120.  Google ScholarDigital LibraryRogers, S., Williamson, J., Stewart, C., and Murray-Smith, R. FingerCloud: uncertainty and autonomy handover in capacitive sensing. In Proc. CHI '10. 577--580.  Google ScholarDigital LibrarySchmidt, D., Chong, M.K. and Gellersen, H. HandsDown: hand-contour-based user identification for interactive surfaces. In Proc. NordiCHI '10. 432--441.  Google ScholarDigital LibraryWeiss, M., Wagner, J., Jansen, Y., Jennings, R., Khoshabeh, R., Hollan, J.D. and Borchers, J. SLAP widgets: bridging the gap between virtual and physical controls on tabletops. In Proc. CHI '09. 481--490.  Google ScholarDigital LibraryWigdor, D., Benko, H., Pella, J., Lombardo, J. and Williams, S. Rock &amp; rails: extending multi-touch interactions with shape gestures to enable precise spatial manipulations. In Proc. CHI '11. 1581--1590.  Google ScholarDigital LibraryWilson, A. Simulating grasping behavior on an imaging interactive surface. In Proc. ITS '09. 125--132.  Google ScholarDigital LibraryWilson, A., Izadi, S., Hilliges, O., Garcia-Mendoza, A. and Kirk, D. Bringing physics to the surface. In Proc. UIST '08. 67--76.  Google ScholarDigital LibraryWilson, F. (1998). The Hand: How Its Use Shapes the Brain, Language, and Human Culture. Pantheon Books, New York.Google ScholarWobbrock, J., Morris, M., and Wilson, A. User-defined gestures for surface computing. In Proc. CHI '09. 1083--1092.  Google ScholarDigital LibraryWu, M. and Balakrishnan, R. Multi-finger and whole hand gestural interaction techniques for multi-user tabletop displays. In Proc. UIST '03. 193--202.  Google ScholarDigital LibraryWu, M., Shen C., Ryall, K., Forlines, C. and Balakrishna, R. Gesture Registration, Relaxation, and Reuse for Multi-Point Direct-Touch Surfaces, In Proc. Tabletop '06. 185--192.  Google ScholarDigital LibraryWynn-Parry, C. B. (1981). Rehabilitation of the Hand. Butterworths, London, UK.Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/2556288.2557012/c336d7bb-f113-47ed-abcd-0a178d0438d0/pn0343-file3.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ef02e2e52e2faf54fffd7dafb0c48c7098ad878961594b8e7d6ef567617b113e92db340abe9f6c0ba6c6d130154e33118f5f530d1ab2975bb9b0a662ba10b96abb0a23d3b4e3cebad7application/x-mpegurlmp476.4 MB", "keywords": ["surface computing", "gesture design", "multitouch", "tangible computing", "capacitive sensing", "touchscreen"], "published_in": "CHI '14: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "26 April 2014", "citations": "21", "isbn": "9781450324731", "doi": "10.1145/2556288", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2556288.2557012", "paper_url": "https://dl.acm.org/doi/10.1145/2556288.2557012"}, {"title": "Haptic-Enabled Handheld Mobile Robots: Design and Analysis", "authors": ["Ayberk \u00d6zg\u00fcr", "Wafa Johal", "Francesco Mondada", "Pierre Dillenbourg"], "abstract": "The Cellulo robots are small tangible robots that are designed to represent virtual interactive point-like objects that reside on a plane within carefully designed learning activities. In the context of these activities, our robots not only display autonomous motion and act as tangible interfaces, but are also usable as haptic devices in order to exploit, for instance, kinesthetic learning. In this article, we present the design and analysis of the haptic interaction module of the Cellulo robots. We first detail our hardware and controller design that is low-cost and versatile. Then, we describe the task-based experimental procedure to evaluate the robot's haptic abilities. We show that our robot is usable in most of the tested tasks and extract perceptive and manipulative guidelines for the design of haptic elements to be integrated in future learning activities. We conclude with limitations of the system and future work.", "keywords": ["handheld robots", "haptic interaction", "mobile robots"], "published_in": "CHI '17: Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2017", "citations": "9", "isbn": "9781450346559", "doi": "10.1145/3025453", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3025453.3025994", "paper_url": "https://dl.acm.org/doi/10.1145/3025453.3025994"}, {"title": "Interaction with magic lenses: real-world validation of a Fitts' Law model", "authors": ["Michael Rohs", "Antti Oulasvirta", "Tiia Suomalainen"], "abstract": "Rohs and Oulasvirta (2008) proposed a two-component Fitts' law model for target acquisition with magic lenses in mobile augmented reality (AR) with 1) a physical pointing phase, in which the target can be directly observed on the background surface, and 2) a virtual pointing phase, in which the target can only be observed through the device display. The model provides a good fit (R2=0.88) with laboratory data, but it is not known if it generalizes to real-world AR tasks. In the present outdoor study, subjects (N=12) did building-selection tasks in an urban area. The differences in task characteristics to the laboratory study are drastic: targets are three-dimensional and they vary in shape, size, z-distance, and visual context. Nevertheless, the model yielded an R2 of 0.80, and when using effective target width an R2 of 0.88 was achieved.", "keywords": ["Fitt's Law", "human-performance modeling", "augmented reality", "magic lens pointing", "field experiment", "target acquisition"], "published_in": "CHI '11: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "7 May 2011", "citations": "20", "isbn": "9781450302289", "doi": "10.1145/1978942", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1978942.1979343", "paper_url": "https://dl.acm.org/doi/10.1145/1978942.1979343"}, {"title": "Modeling Error Rates in Spatiotemporal Moving Target Selection", "authors": ["Jin Huang", "Byungjoo Lee"], "abstract": "When we try to acquire a moving target such as hitting a virtual tennis in a computer game, we must hit the target instantly when it flies over our hitting range. In other words, we have to acquire the target in spatial and temporal domains simultaneously. We call this type of task spatiotemporal moving target selection, which we find is common yet less studied in HCI. This paper presents a tentative model for predicting the error rates in spatiotemporal moving target selection. Our model integrates two latest models, the Ternary-Gaussian model and the Temporal Pointing model, to explain the influence of spatial and temporal constraints on pointing errors. In a 12-subject pointing experiment with a computer mouse, our model shows high fitting results with 0.904 R2. We discuss future research directions on this topic and how it could potentially help the design in dynamical user interfaces.", "keywords": ["moving target selection", "error rates", "spatial pointing", "temporal pointing"], "published_in": "CHI EA '19: Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "1", "isbn": "9781450359719", "doi": "10.1145/3290607", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290607.3313077", "paper_url": "https://dl.acm.org/doi/10.1145/3290607.3313077"}, {"title": "ForceRay: Extending Thumb Reach via Force Input Stabilizes Device Grip for Mobile Touch Input", "authors": ["Christian Corsten", "Marcel Lahaye", "Jan Borchers", "Simon Voelker"], "abstract": "Smartphones are used predominantly one-handed, using the thumb for input. Many smartphones, however, have grown beyond 5\". Users cannot tap everywhere on these screens without destabilizing their grip. ForceRay (FR) lets users aim at an out-of-reach target by applying a force touch at a comfortable thumb location, casting a virtual ray towards the target. Varying pressure moves a cursor along the ray. When reaching the target, quickly lifting the thumb selects it. In a first study, FR was 195 ms slower and had a 3% higher selection error than the best existing technique, BezelCursor (BC), but FR caused significantly less device movement than all other techniques, letting users maintain a steady grip and removing their concerns about device drops. A second study showed that an hour of training speeds up both BC and FR, and that both are equally fast for targets at the screen border.                     References                 Axel Antoine, Sylvain Malacria, and G\u00e9ry Casiez. 2017. ForceEdge: Controlling Autoscroll on Both Desktop and Mobile Computers Using the Force. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI '17). ACM, New York, NY, USA, 3281--3292.  Google ScholarDigital LibraryJoanna Bergstrom-Lehtovirta and Antti Oulasvirta. 2014. Modeling the Functional Area of the Thumb on Mobile Touchscreen Surfaces. In Proceedings of the 32nd Annual ACM Conference on Human Factors in Computing Systems (CHI '14). ACM, New York, NY, USA, 1991--2000.  Google ScholarDigital LibrarySebastian Boring, David Ledo, Xiang 'Anthony' Chen, Nicolai Marquardt, Anthony Tang, and Saul Greenberg. 2012. The Fat Thumb: Using the Thumb's Contact Size for Single-Handed Mobile Interaction. In Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI '12). ACM, New York, NY, USA, 39--48.  Google ScholarDigital LibraryStephen A. Brewster and Michael Hughes. 2009. Pressure-Based Text Entry for Mobile Devices. In Proceedings of the 11th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI '09). ACM, New York, NY, USA, Article 9, 4 pages.  Google ScholarDigital LibraryG\u00e9ry Casiez, Nicolas Roussel, and Daniel Vogel. 2012. 1 Filter: A Simple Speed-Based Low-Pass Filter for Noisy Input in Interactive Systems. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '12). ACM, New York, NY, USA, 2527--2530.  Google ScholarDigital LibraryJared Cechanowicz, Pourang Irani, and Sriram Subramanian. 2007. Augmenting the Mouse with Pressure Sensitive Input. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '07). ACM, New York, NY, USA, 1385--1394.  Google ScholarDigital LibraryYouli Chang, Sehi L'Yi, Kyle Koh, and Jinwook Seo. 2015. Understanding Users' Touch Behavior on Large Mobile Touch-Screens and Assisted Targeting by Tilting Gesture. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). ACM, New York, NY, USA, 1499--1508.  Google ScholarDigital LibraryOlivier Chapuis, Jean-Baptiste Labrune, and Emmanuel Pietriga. 2009. DynaSpot: Speed-dependent Area Cursor. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '09). ACM, New York, NY, USA, 1391--1400.  Google ScholarDigital LibraryChristian Corsten, Bjoern Daehlmann, Simon Voelker, and Jan Borchers. 2017. BackXPress: Using Back-of-Device Finger Pressure to Augment Touchscreen Input on Smartphones. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI '17). ACM, New York, NY, USA, 4654--4666.  Google ScholarDigital LibraryChristian Corsten, Simon Voelker, and Jan Borchers. 2017. Release, Don't Wait! Reliable Force Input Confrmation with Quick Release. In Proceedings of the 2017 ACM International Conference on Interactive Surfaces and Spaces (ISS '17). ACM, New York, NY, USA, 246--251.  Google ScholarDigital LibraryChristian Corsten, Simon Voelker, Andreas Link, and Jan Borchers. 2018. Use the ForcePicker, Luke: Space-Efcient Value Input on ForceSensitive Mobile Touchscreens. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, NY, USA, 12.  Google ScholarDigital LibraryPhilip L. Davidson and Jeferson Y. Han. 2008. Extending 2D Object Arrangement with Pressure-Sensitive Layering Cues. In Proceedings of the 21st Annual ACM Symposium on User Interface Software and Technology (UIST '08). ACM, New York, NY, USA, 87--90.  Google ScholarDigital LibraryRachel Eardley, Anne Roudaut, Steve Gill, and Stephen J. Thompson. 2017. Understanding Grip Shifts: How Form Factors Impact Hand Movements on Mobile Phones. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI '17). ACM, New York, NY, USA, 4680--4691.  Google ScholarDigital LibraryRachel Eardley, Anne Roudaut, Steve Gill, and Stephen J. Thompson. 2018. Designing for Multiple Hand Grips and Body Postures Within the UX of a Moving Smartphone. In Proceedings of the 2018 Designing Interactive Systems Conference (DIS '18). ACM, New York, NY, USA, 611--621.  Google ScholarDigital LibraryRachel Eardley, Anne Roudaut, Steve Gill, and Stephen J. Thompson. 2018. Investigating How Smartphone Movement is Afected by Body Posture. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, NY, USA, Article 202, 8 pages.  Google ScholarDigital LibraryJon Fingas. 2012. Shocker: Smartphone Users Like Bigger Screebs, Market Share May Respond Accordingly. http://engadget.com/2012/09/ 03/shocker-smartphone-users-like-bigger-screens/. {Online; accessed Sept 20, 2018}.Google ScholarMayank Goel, Jacob Wobbrock, and Shwetak Patel. 2012. GripSense: Using Built-in Sensors to Detect Hand Posture and Pressure on Commodity Mobile Phones. In Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology (UIST '12). ACM, New York, NY, USA, 545--554.  Google ScholarDigital LibraryTovi Grossman and Ravin Balakrishnan. 2005. The Bubble Cursor: Enhancing Target Acquisition by Dynamic Resizing of the Cursor's Activation Area. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '05). ACM, New York, NY, USA, 281--290.  Google ScholarDigital LibraryKhalad Hasan, Junhyeok Kim, David Ahlstr\u00f6m, and Pourang Irani. 2016. Thumbs-Up: 3D Spatial Thumb-Reachable Space for One-Handed Thumb Interaction on Smartphones. In Proceedings of the 2016 Symposium on Spatial User Interaction (SUI '16). ACM, New York, NY, USA, 103--106.  Google ScholarDigital LibraryNambu Hirotaka. 2003. Reassessing Current Cell Phone Designs: Using Thumb Input Efectively. In CHI '03 Extended Abstracts on Human Factors in Computing Systems (CHI EA '03). ACM, New York, NY, USA, 938--939.  Google ScholarDigital LibraryApple Inc. 2018. iOS 11 UIKit API Reference. https://developer.apple. com/reference/uikit/uitouch. {Online; accessed Sept 20, 2018}.Google ScholarApple Inc. 2018. Taking Advantage of 3D Touch. https://developer. apple.com/ios/3d-touch/. {Online; accessed Sept 20, 2018}.Google ScholarAmy K Karlson and Benjamin B Bederson. 2007. ThumbSpace: Generalized One-Handed Input for Touchscreen-Based Mobile Devices. In Human-Computer Interaction -- INTERACT 2007. Springer, Berlin, Heidelberg, Berlin, Heidelberg, 324--338. Google ScholarDigital LibraryAmy K. Karlson and Benjamin B. Bederson. 2008. One-Handed Touchscreen Input for Legacy Applications. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '08). ACM, New York, NY, USA, 1399--1408.  Google ScholarDigital LibraryAmy K Karlson, Benjamin B Bederson, and Jose L Contreras-Vidal. 2008. Understanding One-Handed Use of Mobile Devices. In Handbook of Research on User Interface Design and Evaluation for Mobile Technology. IGI Global, 86--101.Google ScholarSunjun Kim, Jihyun Yu, and Geehyuk Lee. 2012. Interaction Techniques for Unreachable Objects on the Touchscreen. In Proceedings of the 24th Australian Computer-Human Interaction Conference (OzCHI '12). ACM, New York, NY, USA, 295--298.  Google ScholarDigital LibraryJ. Lai and D. Zhang. 2015. ExtendedThumb: A Target Acquisition Approach for One-Handed Interaction With Touch-Screen Mobile Phones. IEEE Transactions on Human-Machine Systems 45, 3 (June 2015), 362--370.Google ScholarCross RefHuy Viet Le, Patrick Bader, Thomas Kosch, and Niels Henze. 2016. Investigating Screen Shifting Techniques to Improve One-Handed Smartphone Usage. In Proceedings of the 9th Nordic Conference on Human-Computer Interaction (NordiCHI '16). ACM, New York, NY, USA, Article 27, 10 pages.  Google ScholarDigital LibraryWing Ho Andy Li, Hongbo Fu, and Kening Zhu. 1. BezelCursor: BezelInitiated Cursor for One-Handed Target Acquisition on Mobile Touch Screens. International Journal of Mobile Human Computer Interaction (IJMHCI) 8, 1 (Jan. 1), 1--22.  Google ScholarDigital LibraryMarkus L\u00f6chtefeld, Christoph Hirtz, and Sven Gehring. 2013. Evaluation of Hybrid Front- and Back-of-Device Interaction on Mobile Devices. In Proceedings of the 12th International Conference on Mobile and Ubiquitous Multimedia (MUM '13). ACM, New York, NY, USA, Article 17, 4 pages.  Google ScholarDigital LibraryMarkus L\u00f6chtefeld, Phillip Schardt, Antonio Kr\u00fcger, and Sebastian Boring. 2015. Detecting Users Handedness for Ergonomic Adaptation of Mobile User Interfaces. In Proceedings of the 14th International Conference on Mobile and Ubiquitous Multimedia (MUM '15). ACM, New York, NY, USA, 245--249.  Google ScholarDigital LibraryRoss McLachlan, Daniel Boland, and Stephen Brewster. 2014. Transient and Transitional States: Pressure As an Auxiliary Input Modality for Bimanual Interaction. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '14). ACM, New York, NY, USA, 401--410.  Google ScholarDigital LibrarySachi Mizobuchi, Shinya Terasaki, Turo Keski-Jaskari, Jari Nousiainen, Matti Ryynanen, and Miika Silfverberg. 2005. Making an Impression: Force-Controlled Pen Input for Handheld Devices. In CHI '05 Extended Abstracts on Human Factors in Computing Systems (CHI EA '05). ACM, New York, NY, USA, 1661--1664.  Google ScholarDigital LibraryR. Kevin Nelson. 2015. Exploring Apple's 3D Touch. https://medium. com/. {Online; accessed Sept 20, 2018}.Google ScholarSiyuan Qiu, Lu Wang, and Laikuan Wong. 2016. Pressure-Based Touch Positioning Techniques for 3D Objects. In Proceedings of the 20th ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D '16). ACM, New York, NY, USA, 199--200.  Google ScholarDigital LibraryGonzalo Ramos, Matthew Boulos, and Ravin Balakrishnan. 2004. Pressure Widgets. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '04). ACM, New York, NY, USA, 487--494.  Google ScholarDigital LibraryJef Raskin. 2000. The Humane Interface: New Directions for Designing Interactive Systems. ACM Press/Addison-Wesley Publishing Co., New York, NY, USA. Google ScholarDigital LibrarySimon Rogers, John Williamson, Craig Stewart, and Roderick MurraySmith. 2011. AnglePose: Robust, Precise Capacitive Touch Tracking via 3D Orientation Estimation. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11). ACM, New York, NY, USA, 2575--2584.  Google ScholarDigital LibraryAnne Roudaut, St\u00e9phane Huot, and Eric Lecolinet. 2008. TapTap and MagStick: Improving One-Handed Target Acquisition on Small Touch-Screens. In Proceedings of the Working Conference on Advanced Visual Interfaces (AVI '08). ACM, New York, NY, USA, 146--153.  Google ScholarDigital LibraryKatie A. Siek, Yvonne Rogers, and Kay H. Connelly. 2005. Fat Finger Worries: How Older and Younger Users Physically Interact with PDAs. In Proceedings of the 2005 IFIP TC13 International Conference on Human-Computer Interaction (INTERACT'05). Springer-Verlag, Berlin, Heidelberg, 267--280.  Google ScholarDigital LibraryDaniel Spelmezan, Caroline Appert, Olivier Chapuis, and Emmanuel Pietriga. 2013. Controlling Widgets with One Power-Up Button. In Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology (UIST '13). ACM, New York, NY, USA, 71--74.  Google ScholarDigital LibraryDaniel Spelmezan, Caroline Appert, Olivier Chapuis, and Emmanuel Pietriga. 2013. Side Pressure for Bidirectional Navigation on Small Devices. In Proceedings of the 15th International Conference on Humancomputer Interaction with Mobile Devices and Services (MobileHCI '13). ACM, New York, NY, USA, 11--20.  Google ScholarDigital LibraryCraig Stewart, Michael Rohs, Sven Kratz, and Georg Essl. 2010. Characteristics of Pressure-Based Input for Mobile Devices. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '10). ACM, New York, NY, USA, 801--810.  Google ScholarDigital LibraryQingkun Su, Oscar Kin-Chung Au, Pengfei Xu, Hongbo Fu, and ChiewLan Tai. 2016. 2D-Dragger: Unifed Touch-Based Target Acquisition with Constant Efective Width. In Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI '16). ACM, New York, NY, USA, 170--179.  Google ScholarDigital LibraryHsin-Ruey Tsai, Da-Yuan Huang, Chen-Hsin Hsieh, Lee-Ting Huang, and Yi-Ping Hung. 2016. MovingScreen: Selecting Hard-to-Reach Targets with Automatic Comfort Zone Calibration on Mobile Devices. In Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct (MobileHCI '16). ACM, New York, NY, USA, 651--658.  Google ScholarDigital LibraryGraham Wilson, Stephen Brewster, and Martin Halvey. 2013. Towards Utilising One-Handed Multi-Digit Pressure Input. In CHI '13 Extended Abstracts on Human Factors in Computing Systems (CHI EA '13). ACM, New York, NY, USA, 1317--1322.  Google ScholarDigital LibraryGraham Wilson, Stephen A. Brewster, Martin Halvey, Andrew Crossan, and Craig Stewart. 2011. The Efects of Walking, Feedback and Control Method on Pressure-Based Interaction. In Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services (MobileHCI '11). ACM, New York, NY, USA, 147-- 156.  Google ScholarDigital LibraryGraham Wilson, Craig Stewart, and Stephen A. Brewster. 2010. Pressure-Based Menu Selection for Mobile Devices. In Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services (MobileHCI '10). ACM, New York, NY, USA, 181--190.  Google ScholarDigital LibraryXing-Dong Yang, Edward Mak, Pourang Irani, and Walter F. Bischof. 2009. Dual-Surface Input: Augmenting One-Handed Interaction with Coordinated Front and Behind-the-Screen Input. In Proceedings of the 11th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI '09). ACM, New York, NY, USA, Article 5, 10 pages.  Google ScholarDigital LibraryHyunjin Yoo, Jungwon Yoon, and Hyunsoo Ji. 2015. Index Finger Zone: Study on Touchable Area Expandability Using Thumb and Index Finger. In Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct (MobileHCI '15). ACM, New York, NY, USA, 803--810.  Google ScholarDigital LibraryNeng-Hao Yu, Da-Yuan Huang, Jia-Jyun Hsu, and Yi-Ping Hung. 2013. Rapid Selection of Hard-to-Access Targets by Thumb on Mobile TouchScreens. In Proceedings of the 15th International Conference on Humancomputer Interaction with Mobile Devices and Services (MobileHCI '13). ACM, New York, NY, USA, 400--403.  Google ScholarDigital LibraryMingyuan Zhong, Chun Yu, Qian Wang, Xuhai Xu, and Yuanchun Shi. 2018. ForceBoard: Subtle Text Entry Leveraging Pressure. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, NY, USA, Article 528, 10 pages.  Google ScholarDigital Librarypn4509vc.zipVideo figure captionspaper212pvc.zipPreview video captionsSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3290605.3300442/947b2e68-1e9f-4043-8356-4cd67ed715b9/paper212p.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee05eee35a4ac3e15fa134b9c32a1f9e3cfd587429fb93750ad6f2677a69b71b27722884e6bd0c91e7146558b382c4b20c5bcf449a204b387cb0835588f8cddb09ca6939bef2eb87b4application/x-mpegurlmp44.3 MB", "keywords": ["touch", "mobile", "force", "one-handed", "pressure", "reachability"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "5", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300442", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300442"}, {"title": "Hybrid-Brailler: Combining Physical and Gestural Interaction for Mobile Braille Input and Editing", "authors": ["Daniel Trindade", "Andr\u00e9 Rodrigues", "Tiago Guerreiro", "Hugo Nicolau"], "abstract": "Braille input enables fast nonvisual entry speeds on mobile touchscreen devices. Yet, the lack of tactile cues commonly results in typing errors, which are hard to correct. We propose Hybrid-Brailler, an input solution that combines physical and gestural interaction to provide fast and accurate Braille input. We use the back of the device for physical chorded input while freeing the touchscreen for gestural interaction. Gestures are used in editing operations, such as caret movement, text selection, and clipboard control, enhancing the overall text entry experience. We conducted two user studies to assess both input and editing performance. Results show that Hybrid-Brailler supports fast entry rates as its virtual counterpart, while significantly increasing input accuracy. Regarding editing performance, when compared with the mainstream technique, Hybrid-Brailler shows performance benefits of 21% in speed and increased editing accuracy. We finish with lessons learned for designing future nonvisual input and editing techniques.                     References                 Shiri Azenkot and Nicole B. Lee. 2013. Exploring the use of speech input by blind people on mobile devices. In Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility - ASSETS '13, 1--8.  Google ScholarShiri Azenkot, Jacob O. Wobbrock, Sanjana Prasain, and Richard E. Ladner. 2012. Input finger detection for nonvisual touch screen text entry in Perkinput. In Proceedings of Graphics Interface, 121--129. https://doi.org/2305276.2305297 Google ScholarMatthew N. Bonner, Jeremy T. Brudvik, Gregory D. Abowd, and W. Keith Edwards. 2010. No-look notes: Accessible eyes-free multi-touch text entry. Lecture Notes in Computer Science 6030 LNCS: 409--426.  Google ScholarMaria Claudia Buzzi, Marina Buzzi, Barbara Leporini, and Amaury Trujillo. 2014. Designing a text entry multimodal keypad for blind users of touchscreen mobile phones. In Proceedings of the 16th international ACM SIGACCESS conference on Computers &amp; accessibility (ASSETS '14), 131--136.  Google ScholarChen Chen, Simon T Perrault, Shengdong Zhao, and Wei Tsang Ooi. 2014. BezelCopy: an efficient crossapplication copy-paste technique for touchscreen smartphones. In Proceedings of the 2014 International Working Conference on Advanced Visual Interfaces, 185--192.  Google ScholarMark D Dunlop and Andrew Crossan. 2000. Predictive text entry methods for mobile phones. Personal Technologies 4, 2: 134--143.Google ScholarVittorio Fuccella, Poika Isokoski, and Benoit Martin. 2013. Gestures and Widgets: Performance in Text Editing on Multi-touch Capable Mobile Devices. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '13), 2785--2794.  Google ScholarWilliam Grussenmeyer and Eelke Folmer. 2017. Accessible Touchscreen Technology for People with Visual Impairments: A Survey. ACM Transactions on Accessible Computing (TACCESS) 9, 2: 6:1--6:31.  Google ScholarT Guerreiro, P Lago\u00e1, H Nicolau, D Gon\u00e7alves, and J A Jorge. 2008. From tapping to touching: Making touch screens accessible to blind users. IEEE MultiMedia: 48--50.  Google ScholarShaun K Kane, Jacob O Wobbrock, and Richard E Ladner. 2011. Usable Gestures for Blind People: Understanding Preference and Performance. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11), 413--422.  Google ScholarR C Littell, P R Henry, and C B Ammerman. 1998. Statistical analysis of repeated measures data using SAS procedures. Journal of animal science 76, 4: 1216--1231.Google ScholarKent Lyons, Thad Starner, Daniel Plaisted, James Fusia, Amanda Lyons, Aaron Drew, and E W Looney. 2004. Twiddler Typing: One-handed Chording Text Entry for Mobile Phones. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 671--678.  Google ScholarI S MacKenzie and R W Soukoreff. 2002. Text entry for mobile computing: Models and methods, theory and practice. Human-Computer Interaction 17, 2: 147-- 198.Google ScholarI S MacKenzie and R W Soukoreff. 2003. Phrase sets for evaluating text entry techniques. In Extended abstracts of the SIGCHI Conference on Human Factors in Computing Systems, 754--755.  Google ScholarDigital LibrarySergio Mascetti, Cristian Bernareggi, and Matteo Belotti. 2011. TypeInBraille: A Braille-based Typing Application for Touchscreen Devices. In Proceedings of the 13th International ACM SIGACCESS Conference on Computers and Accessibility, 295.  Google ScholarKyle Montague, Hugo Nicolau, and Vicki Hanson. 2014. Motor-Impaired Touchscreen Interactions in the Wild. In 16th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS).  Google ScholarHugo Nicolau, Kyle Montague, Tiago Guerreiro, Jo\u00e3o Guerreiro, and Vicki L Hanson. 2014. B#: Chord-based Correction for Multitouch Braille Input. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'14), 1705--1708.  Google ScholarHugo Nicolau, Kyle Montague, Tiago Guerreiro, Andr\u00e9 Rodrigues, and Vicki L Hanson. 2015. Typing Performance of Blind Users: An Analysis of Touch Behaviors, Learning Effect, and In-Situ Usage. In ACM SIGACCESS Conference on Computers and Accessibility.  Google ScholarHugo Nicolau, Kyle Montague, Tiago Guerreiro, Andr\u00e9 Rodrigues, and Vicki L Hanson. 2017. Investigating Laboratory and Everyday Typing Performance of Blind Users. ACM Transactions on Accessible Computing (TACCESS) 10, 1: 4:1--4:26.  Google ScholarJo\u00e3o Oliveira, Tiago Guerreiro, Hugo Nicolau, Joaquim Jorge, and Daniel Gon\u00e7alves. 2011. Blind people and mobile touch-based text-entry: Acknowledging the Need for Different Flavors. In The proceedings of the 13th international ACM SIGACCESS conference on Computers and accessibility - ASSETS '11, 179.  Google ScholarJo\u00e3o Oliveira, Tiago Guerreiro, Hugo Nicolau, Joaquim Jorge, and Daniel Gon\u00e7alves. 2011. BrailleType: unleashing braille over touch screen mobile phones. Lecture Notes in Computer Science 6946 LNCS, PART 1: 100--107.Google ScholarJean-baptiste Scheibel, Cyril Pierson, Beno\u00eet Martin, Nathan Godard, Vittorio Fuccella, and Poika Isokoski. 2013. Virtual Stick in Caret Positioning on Touch Screens. In Proceedings of the 25th Conference on L'Interaction Homme-Machine (IHM '13), 107:107--107:114.  Google ScholarKristen Shinohara and Jacob O Wobbrock. 2016. Selfconscious or self-confident? A diary study conceptualizing the social accessibility of assistive technology. ACM Transactions on Accessible Computing (TACCESS) 8, 2: 5.  Google ScholarR William Soukoreff and I Scott MacKenzie. 2003. Metrics for text entry research: an evaluation of MSD and KSPC, and a new unified error metric. In Proceedings of the SIGCHI conference on Human factors in computing systems, 113--120.  Google ScholarCaleb Southern, James Clawson, Brian Frey, Gregory Abowd, and Mario Romero. 2012. An Evaluation of BrailleTouch: Mobile Touchscreen Text Entry for the Visually Impaired. In Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services (MobileHCI '12), 317--326.  Google ScholarKenji Suzuki, Kazumasa Okabe, Ryuuki Sakamoto, and Daisuke Sakamoto. 2015. Fix and Slide: Caret Navigation with Movable Background. In Adjunct Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology, 79--80.  Google ScholarJacob O Wobbrock, Leah Findlater, Darren Gergle, and James J Higgins. 2011. The aligned rank transform for nonparametric factorial analyses using only anova procedures. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 143--146.  Google ScholarJacob O Wobbrock and Brad A Myers. 2006. Analyzing the input stream for character- level errors in unconstrained text entry evaluations. ACM Trans. Comput.-Hum. Interact. 13, 4: 458--489.  Google ScholarGeorgios Yfantidis and Grigori Evreinov. 2004. Adaptive blind interaction technique for touchscreens. Universal Access in the Information Society 4, 4: 344-- 353.  Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3173574.3173601/7b7c8388-ae4e-42b9-8f9b-a69e951c949b/pn1173.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee06e0e0927f1e11a21c84c9577d28912947bf44aa96b6d3d13a0a87ca8499ae2fb4c0cbac30a31082b9a7fbfbd7312d7b16f45028affdb8c9d74000f35fcdb60823261c7564f581edapplication/x-mpegurlmp4311.7 MB", "keywords": ["blind", "mobile", "text entry", "touchscreen", "braille", "editing"], "published_in": "CHI '18: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems", "publication_date": "19 April 2018", "citations": "4", "isbn": "9781450356206", "doi": "10.1145/3173574", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3173574.3173601", "paper_url": "https://dl.acm.org/doi/10.1145/3173574.3173601"}, {"title": "DMove: Directional Motion-based Interaction for Augmented Reality Head-Mounted Displays", "authors": ["Wenge Xu", "Hai-Ning Liang", "Yuxuan Zhao", "Difeng Yu", "Diego Monteiro"], "abstract": "We present DMove, directional motion-based interaction for Augmented Reality (AR) Head-Mounted Displays (HMDs) that is both hands- and device-free. It uses directional walk-ing as a way to interact with virtual objects. To use DMove, a user needs to perform directional motions such as mov-ing one foot forward or backward. In this research, we first investigate the recognition accuracy of the motion direc-tions of our method and the social acceptance of this type of interactions together with users' comfort rating for each direction. We then optimize its design and conduct a sec-ond study to compare DMove in task performance and user preferences (workload, motion sickness, user experience), with two approaches-Hand interaction (Meta 2-like) and Head+Hand interaction (HoloLens-like) for menu selection tasks. Based on the results of these two studies, we provide a set of guidelines for DMove and further demonstrate two applications that utilize directional motions.", "keywords": ["augmented reality", "motion direction", "head-mounted display", "menu selection"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "4", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300674", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300674"}, {"title": "Spring: a solution for managing the third DOF with tactile interface", "authors": ["Robin Vivian", "J\u00e9r\u00f4me Dinet", "David Bertolo"], "abstract": "Tablets with touch-screens are one of the most widely used interfaces for three main reasons: the effectiveness and efficiency and fun side interactions. Associated with significant increases in power, the multi-touch touchscreen terminals are able to manipulate real-time application of virtual worlds for entertainment or learning. This raises a question that was already current with conventional interfaces (mouse for example) how to define, with 2D input interface, designation, orientation and move actions (simply and intuitively) on objects in 3D space that require at least 6 degrees of freedom (6 DOF for the object and sometimes six other for the camera)? Our study provides a way of managing the depth dimension with the principle of universal interaction: to screw / unscrew. The first part of this paper presents the theoretical framework based on prior studies and the second part describes the formalization of a grammar of gesture allowing the intuitive interaction management of depth component.", "keywords": ["interactions", "tactile device", "gestural grammar", "tablets touch-screen", "graphical user interfaces", "3dof", "grammar of gesture"], "published_in": "APCHI '12: Proceedings of the 10th asia pacific conference on Computer human interaction", "publication_date": "28 August 2012", "citations": "3", "isbn": "9781450314961", "doi": "10.1145/2350046", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2350046.2350097", "paper_url": "https://dl.acm.org/doi/10.1145/2350046.2350097"}, {"title": "An interaction system using mixed hand gestures", "authors": ["Zhong Yang", "Yi Li", "Yang Zheng", "Weidong Chen", "Xiaoxiang Zheng"], "abstract": "This paper presents a mixed hand gesture interaction system in virtual environment, in which \"mixed\" means static and dynamic hand gestures are combined for both navigation and object manipulation. Firstly, a simple average background model and skin color are used for hand area segmentation. Then a state-based spotting algorithm is employed to automatically identify two types of hand gestures. A voting-based method is used for quick classification of static gestures. And we use the hidden Markov model (HMM) to recognize dynamic gestures. Since the training of HMM requires the consistency of the training data, outputted by the feature extraction, a data aligning algorithm is raised. Through our mixed hand gesture system, users can perform complicated operating commands in a natural way. The experimental results demonstrate that our methods are effective and accurate.", "keywords": ["hand gesture recognition", "data aligning", "hidden markov model (hmm)", "mixed hand gesture", "spotting algorithm"], "published_in": "APCHI '12: Proceedings of the 10th asia pacific conference on Computer human interaction", "publication_date": "28 August 2012", "citations": "4", "isbn": "9781450314961", "doi": "10.1145/2350046", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2350046.2350074", "paper_url": "https://dl.acm.org/doi/10.1145/2350046.2350074"}, {"title": "COMPASS: Rotational Keyboard on Non-Touch Smartwatches", "authors": ["Xin Yi", "Chun Yu", "Weijie Xu", "Xiaojun Bi", "Yuanchun Shi"], "abstract": "Entering text is very challenging on smartwatches, especially on non-touch smartwatches where virtual keyboards are unavailable. In this paper, we designed and implemented COMPASS, a non-touch bezel-based text entry technique. COMPASS positions multiple cursors on a circular keyboard, with the location of each cursor dynamically optimized during typing to minimize rotational distance. To enter text, a user rotates the bezel to select keys with any nearby cursors. The design of COMPASS was justified by an iterative design process and user studies. Our evaluation showed that participants achieved a pick-up speed around 10 WPM and reached 12.5 WPM after 90-minute practice. COMPASS allows users to enter text on non-touch smartwatches, and also serves as an alternative for entering text on touch smartwatches when touch is unavailable (e.g., wearing gloves).                     References                 2016. A note on calculating text entry speed. (2016). http://www.yorku.ca/mack/RN-TextEntrySpeed.html.Google Scholar2016. American National Corpus. (2016). http://www.americannationalcorpus.org/OANC/index.html.Google Scholar2016. Apple Watch. (2016). http://www.apple.com/watch/.Google Scholar2016. BMW iDrive. (2016). http://www.bmw.com/com/en/insights/technology/ technology_guide/articles/controller.html.Google Scholar2016. Moto 360. (2016). https://www.motorola.com/us/products/moto-360.Google Scholar2016. Pebble Watch. (2016). https://www.pebble.com/.Google Scholar2016. Wrist Gestures. (2016). https://support.google.com/androidwear/answer/6312406.Google ScholarShaikh Shawon Arefin Shimon, Courtney Lutton, Zichun Xu, Sarah Morrison-Smith, Christina Boucher, and Jaime Ruiz. 2016. Exploring Non-touchscreen Gestures for Smartwatches. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI '16). ACM, New York, NY, USA, 3822--3833. DOI: http://dx.doi.org/10.1145/2858036.2858385  Google ScholarDigital LibraryXiaojun Bi, Tom Ouyang, and Shumin Zhai. 2014. Both Complete and Correct?: Multi-objective Optimization of Touchscreen Keyboard. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '14). ACM, New York, NY, USA, 2297--2306. DOI: http://dx.doi.org/10.1145/2556288.2557414  Google ScholarDigital LibraryRenaud Blanch and Micha\u00ebl Ortega. 2009. Rake Cursor: Improving Pointing Performance with Concurrent Input Channels. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '09). ACM, New York, NY, USA, 1415--1418. DOI: http://dx.doi.org/10.1145/1518701.1518914  Google ScholarDigital LibraryJared Cechanowicz, Steven Dawson, Matt Victor, and Sriram Subramanian. 2006. Stylus Based Text Input Using Expanding CIRRIN. In Proceedings of the Working Conference on Advanced Visual Interfaces (AVI '06). ACM, New York, NY, USA, 163--166. DOI: http://dx.doi.org/10.1145/1133265.1133299  Google ScholarDigital LibraryXiang 'Anthony' Chen, Tovi Grossman, and George Fitzmaurice. 2014. Swipeboard: A Text Entry Technique for Ultra-small Interfaces That Supports Novice to Expert Transitions. In Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology (UIST '14). ACM, New York, NY, USA, 615--620. DOI: http://dx.doi.org/10.1145/2642918.2647354  Google ScholarDigital LibraryLeah Findlater and Jacob Wobbrock. 2012. Personalized Input: Improving Ten-finger Touchscreen Typing Through Automatic Adaptation. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '12). ACM, New York, NY, USA, 815--824. DOI:http://dx.doi.org/10.1145/2207676.2208520  Google ScholarDigital LibraryMarkus Funk, Alireza Sahami, Niels Henze, and Albrecht Schmidt. 2014. Using a Touch-sensitive Wristband for Text Entry on Smart Watches. In CHI '14 Extended Abstracts on Human Factors in Computing Systems (CHI EA '14). ACM, New York, NY, USA, 2305--2310. DOI: http://dx.doi.org/10.1145/2559206.2581143  Google ScholarDigital LibraryJoshua Goodman, Gina Venolia, Keith Steury, and Chauncey Parker. 2002. Language Modeling for Soft Keyboards. In Proceedings of the 7th International Conference on Intelligent User Interfaces (IUI '02). ACM, New York, NY, USA, 194--195. DOI: http://dx.doi.org/10.1145/502716.502753  Google ScholarDigital LibraryMitchell Gordon, Tom Ouyang, and Shumin Zhai. 2016. WatchWriter: Tap and Gesture Typing on a Smartwatch Miniature Keyboard with Statistical Decoding. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI '16). ACM, New York, NY, USA, 3817--3821. DOI: http://dx.doi.org/10.1145/2858036.2858242  Google ScholarDigital LibraryChris Harrison and Scott E. Hudson. 2009. Abracadabra: Wireless, High-precision, and Unpowered Finger Input for Very Small Mobile Devices. In Proceedings of the 22Nd Annual ACM Symposium on User Interface Software and Technology (UIST '09). ACM, New York, NY, USA, 121--124. DOI: http://dx.doi.org/10.1145/1622176.1622199  Google ScholarDigital LibraryUta Hinrichs, Holly Schmidt, Tobias Isenberg, Mark S Hancock, and Sheelagh Carpendale. 2008. Bubbletype: Enabling text entry within a walk-up tabletop installation. (2008).Google ScholarJonggi Hong, Seongkook Heo, Poika Isokoski, and Geehyuk Lee. 2015. SplitBoard: A Simple Split Soft Keyboard for Wristwatch-sized Touch Screens. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). ACM, New York, NY, USA, 1233--1236. DOI: http://dx.doi.org/10.1145/2702123.2702273  Google ScholarDigital LibraryFrederic Kerber, Tobias Kiefer, and Markus L\u00f6chtefeld. 2016. Investigating Interaction Techniques for State-of-the-Art Smartwatches. In Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI EA '16). ACM, New York, NY, USA, 2540--2547. DOI: http://dx.doi.org/10.1145/2851581.2892302  Google ScholarDigital LibraryMasatomo Kobayashi and Takeo Igarashi. 2008. Ninja Cursors: Using Multiple Cursors to Assist Target Acquisition on Large Screens. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '08). ACM, New York, NY, USA, 949--958. DOI:http://dx.doi.org/10.1145/1357054.1357201  Google ScholarDigital LibraryLuis A. Leiva, Alireza Sahami, Alejandro Catala, Niels Henze, and Albrecht Schmidt. 2015. Text Entry on Tiny QWERTY Soft Keyboards. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). ACM, New York, NY, USA, 669--678. DOI: http://dx.doi.org/10.1145/2702123.2702388  Google ScholarDigital LibraryI. Scott MacKenzie and R. William Soukoreff. 2002. A Character-level Error Analysis Technique for Evaluating Text Entry Methods. In Proceedings of the Second Nordic Conference on Human-computer Interaction (NordiCHI '02). ACM, New York, NY, USA, 243--246. DOI: http://dx.doi.org/10.1145/572020.572056  Google ScholarDigital LibraryI. Scott MacKenzie and R. William Soukoreff. 2003. Phrase Sets for Evaluating Text Entry Techniques. In CHI '03 Extended Abstracts on Human Factors in Computing Systems (CHI EA '03). ACM, New York, NY, USA, 754--755. DOI:http://dx.doi.org/10.1145/765891.765971  Google ScholarDigital LibraryJennifer Mankoff and Gregory D. Abowd. 1998. Cirrin: A Word-level Unistroke Keyboard for Pen Input. In Proceedings of the 11th Annual ACM Symposium on User Interface Software and Technology (UIST '98). ACM, New York, NY, USA, 213--214. DOI: http://dx.doi.org/10.1145/288392.288611  Google ScholarDigital LibraryPaul Nation and Robert Waring. 1997. Vocabulary size, text coverage and word lists. Vocabulary: Description, acquisition and pedagogy 14 (1997), 6--19.Google ScholarStephen Oney, Chris Harrison, Amy Ogan, and Jason Wiese. 2013. ZoomBoard: A Diminutive Qwerty Soft Keyboard Using Iterative Zooming for Ultra-small Devices. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '13). ACM, New York, NY, USA, 2799--2802. DOI: http://dx.doi.org/10.1145/2470654.2481387  Google ScholarDigital LibraryKatrin Plaumann, Michael M\u00fcller, and Enrico Rukzio. 2016. CircularSelection: Optimizing List Selection for Smartwatches. In Proceedings of the 2016 ACM International Symposium on Wearable Computers (ISWC '16). ACM, New York, NY, USA, 128--135. DOI: http://dx.doi.org/10.1145/2971763.2971766  Google ScholarDigital LibraryMorten Proschowsky, Nette Schultz, and Niels Ebbe Jacobsen. 2006. An Intuitive Text Input Method for Touch Wheels. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '06). ACM, New York, NY, USA, 467--470. DOI: http://dx.doi.org/10.1145/1124772.1124842  Google ScholarDigital LibraryPhilip Quinn, Andy Cockburn, and J\u00e9r\u00f4me Delamarche. 2013. Examining the costs of multiple trajectory pointing techniques. International Journal of Human-Computer Studies 71, 4 (2013), 492--509.  Google ScholarDigital LibraryKari-Jouko R\u00e4ih\u00e4 and Oleg \u0160pakov. 2009. Disambiguating Ninja Cursors with Eye Gaze. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '09). ACM, New York, NY, USA, 1411--1414. DOI: http://dx.doi.org/10.1145/1518701.1518913  Google ScholarDigital LibraryGarth Shoemaker, Leah Findlater, Jessica Q Dawson, and Kellogg S Booth. 2009. Mid-air text input techniques for very large wall displays. In Proc. GI'09. Canadian Information Processing Society, 231--238.Google ScholarDigital LibraryR. William Soukoreff and I. Scott MacKenzie. 2003. Metrics for Text Entry Research: An Evaluation of MSD and KSPC, and a New Unified Error Metric. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '03). ACM, New York, NY, USA, 113--120. DOI: http://dx.doi.org/10.1145/642611.642632  Google ScholarDigital LibraryKeith Vertanen, Haythem Memmi, Justin Emge, Shyam Reyal, and Per Ola Kristensson. 2015. VelociTap: Investigating Fast Mobile Text Entry Using Sentence-Based Decoding of Touchscreen Keyboard Input. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). ACM, New York, NY, USA, 659--668. DOI: http://dx.doi.org/10.1145/2702123.2702135  Google ScholarDigital LibraryHongyi Wen, Julian Ramos Rojas, and Anind K. Dey. 2016. Serendipity: Finger Gesture Recognition Using an Off-the-Shelf Smartwatch. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI '16). ACM, New York, NY, USA, 3847--3851. DOI: http://dx.doi.org/10.1145/2858036.2858466  Google ScholarDigital LibraryChun Yu, Yuanchun Shi, Ravin Balakrishnan, Xiangliang Meng, Yue Suo, Mingming Fan, and Yongqiang Qin. 2010. The Satellite Cursor: Achieving MAGIC Pointing Without Gaze Tracking Using Multiple Cursors. In Proceedings of the 23Nd Annual ACM Symposium on User Interface Software and Technology (UIST '10). ACM, New York, NY, USA, 163--172. DOI: http://dx.doi.org/10.1145/1866029.1866056  Google ScholarDigital LibrarySupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3025453.3025454/6f275a2f-b217-4100-bf38-c6ca34ce5923/p705-yi.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee07e5e64ad2301e1e02b6a6c08b1b42e0cf9a6c05c03d5908483d5e9b345079bd03bed555eb8a4a08b03c18f93d902c6822f67314af6a4034e7478d81dedb0a8ed3ca9dc7e62cde81application/x-mpegurlmp4212.7 MB", "keywords": ["circular keyboard", "text entry", "smartwatch", "non-touch", "multiple cursors"], "published_in": "CHI '17: Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2017", "citations": "21", "isbn": "9781450346559", "doi": "10.1145/3025453", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3025453.3025454", "paper_url": "https://dl.acm.org/doi/10.1145/3025453.3025454"}, {"title": "Mouse, Tactile, and Tangible Input for 3D Manipulation", "authors": ["Lonni Besan\u00e7on", "Paul Issartel", "Mehdi Ammi", "Tobias Isenberg"], "abstract": "We evaluate the performance and usability of mouse-based, touch-based, and tangible interaction for manipulating objects in a 3D virtual environment. This comparison is a step toward a better understanding of the limitations and benefits of these existing interaction techniques, with the ultimate goal of facilitating an easy transition between the different 3D data exploration environments. For this purpose we analyze participants' performance in 3D manipulation using a docking task. We measured completion times, docking accuracy, as well as subjective criteria such as fatigue, workload, and preference. Our results show that the three input modalities provide similar levels of precision but require different completion times. We also discuss our qualitative observations as well as people's preferences and put our findings into context of the application domain of 3D data analysis environments.                     References                 Par-Anders Albinsson and Shumin Zhai. 2003. High precision touch screen interaction. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 105--112.  Google ScholarDigital LibraryAlissa N. Antle, Milena Droumeva, and Daniel Ha. 2009. Hands on what? Comparing children's mouse-based and tangible-based interaction. In Proceedings of the International Conference on Interaction Design and Children. ACM, New York, 80--88.  Google ScholarDigital LibraryRagnar Bade, Felix Ritter, and Bernhard Preim. 2005. Usability comparison of mouse-based interaction techniques for predictable 3D rotation. In Proceedings of the International Symposium on Smart Graphics. Springer, Berlin/Heidelberg, 138--150.  Google ScholarDigital LibraryThom Baguley. 2009. Standardized or simple effect size: What should be reported? British Journal of Psychology 100, 3 (Aug. 2009), 603--617.Google ScholarCross RefMonya Baker. 2015. Statisticians issue warning over misuse of P values. Nature 531, 7593 (March 2015), 151.Google ScholarGavin Bell. 1988. Bell's trackball. Source code, formerly at http://www.dispersoid.net/code/trackball.c, available through the Internet Archive's copy of July 17, 2007. (1988). http://web.archive.org/web/20070717090837/http://www.dispersoid.net/code/trackball.cGoogle ScholarLonni Besanc\u00b8on, Paul Issartel, Mehdi Ammi, and Tobias Isenberg. 2017. Hybrid tactile/tangible interaction for 3D data exploration. IEEE Transactions on Visualization and Computer Graphics 23, 1 (Jan. 2017), 881--890.  Google ScholarDigital LibraryWilliam Buxton. 1986. Chunking and phrasing and the design of human-computer Dialogues. In Proceedings of the IFIP World Computer Congress. 475--480. http://www. dgp.toronto.edu/OTP/papers/bill.buxton/chunking.htmlGoogle ScholarGery Casiez, Nicolas Roussel, and Daniel Vogel. 2012. 1 -- filter: A simple speed-based low-pass filter for noisy input in interactive systems. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 2527--2530.  Google ScholarDigital LibraryLi-Wei Chan, Hui-Shan Kao, Mike Y Chen, Ming-Sui Lee, Jane Hsu, and Yi-Ping Hung. 2010. Touching the void: Direct-touch interaction for intangible displays. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 2625--2634.  Google ScholarDigital LibraryMichael Chen, S. Joy Mountford, and Abigail Sellen. 1988. A study in interactive 3-D rotation using 2-D control devices. ACM SIGGRAPH Computer Graphics 22, 4 (Aug. 1988), 121--129.  Google ScholarDigital LibraryRobert Coe. 2002. It's the effect size, stupid: What effect size is and why it is important. In Proceedings of the Annual Conference of the British Educational Research Association. http://www.leeds.ac.uk/educol/documents/00002182.htmGoogle ScholarDane Coffey, Nicholas Malbraaten, Trung Le, Iman Borazjani, Fotis Sotiropoulos, Arthur G. Erdman, and Daniel F. Keefe. 2012. Interactive slice WIM: Navigating and interrogating volume datasets using a multi-surface, multi-touch VR interface. IEEE Transactions on Visualization and Computer Graphics 18, 10 (Oct. 2012), 1614--1626.  Google ScholarDigital LibraryGeoff Cumming. 2014. The new statistics: Why and how. Psychological Science 25, 1 (Jan. 2014), 7--29.Google ScholarCross RefNicola Dell, Vidya Vaidyanathan, Indrani Medhi, Edward Cutrell, and William Thies. 2012. \"Yours is better!\" Participant response bias in HCI. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 1321--1330.  Google ScholarDigital LibraryPierre Dragicevic. 2016. Fair statistical communication in HCI. In Modern Statistical Methods for HCI, Judy Robertson and Maurits Kaptein (Eds.). Springer International Publishing, Cham, Switzerland, Chapter 13, 291--330.Google ScholarPierre Dragicevic, Fanny Chevalier, and Stephane Huot. 2014. Running an HCI experiment in multiple parallel universes. In Extended Abstracts on Human Factors in Computing Systems. ACM, New York, 607--618.  Google ScholarDigital LibraryYuan Du, Haoyi Ren, Gang Pan, and Shjian Li. 2011. Tilt &amp; touch: Mobile phone for 3D interaction. In Proceedings of the International Conference on Ubiquitous Computing. ACM, New York, 485--486.  Google ScholarDigital LibraryAugusto Esteves and Ian Oakley. 2011. Informing design by recording tangible interaction. In Extended Abstracts on Human Factors in Computing Systems. ACM, New York, 2077--2082.  Google ScholarDigital LibraryClifton Forlines, Daniel Wigdor, Chia Shen, and Ravin Balakrishnan. 2007. Direct-touch vs. mouse input for tabletop displays. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 647--656.  Google ScholarDigital LibraryBernd Froehlich, Jan Hochstrate, Verena Skuk, and Anke Huckauf. 2006. The GlobeFish and the GlobeMouse. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 191--199.  Google ScholarDigital LibraryDavid Glesser, Franc\u00b8ois B\u00e9rard, and Jeremy R. Cooperstock. 2013. Overcoming limitations of the trackpad for 3D docking operations. In Extended Abstracts on Human Factors in Computing Systems. ACM, New York, 1239--1244.  Google ScholarDigital LibraryMorris Goodman and Arthur Teicher. 1988. To touch or not to touch. Psychotherapy: Theory, Research, Practice, Training 25, 4 (1988), 44--64.Google ScholarMark Hancock, Sheelagh Carpendale, and Andy Cockburn. 2007. Shallow-depth 3D interaction. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 1147--1156.  Google ScholarDigital LibraryMark Hancock, Thomas ten Cate, and Sheelagh Carpendale. 2009. Sticky tools: Full 6DOF force-based interaction for multi-touch tables. In Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces. ACM, New York, 133--140.  Google ScholarDigital LibrarySandra G. Hart. 2006. NASA-task load index (NASA-TLX); 20 years later. Proceedings of the Human Factors and Ergonomics Society Annual Meeting 50, 9 (Oct. 2006), 904--908.Google ScholarCross RefKen Hinckley, Randy Pausch, John C Goble, and Neal F Kassell. 1994. Passive real-world interface props for neurosurgical visualization. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 452--458.  Google ScholarDigital LibraryKen Hinckley, Joe Tullio, Randy Pausch, Dennis Proffitt, and Neal Kassell. 1997. Usability analysis of 3D rotation techniques. In Proceedings of the Annual ACM Symposium on User Interface Software and Technology. ACM, New York, 1--10.  Google ScholarDigital LibraryMichael S Horn, R Jordan Crouser, and Marina U Bers. 2012. Tangible interaction and learning: The case for a hybrid approach. Personal and Ubiquitous Computing 16, 4 (2012), 379--389.  Google ScholarDigital LibraryTobias Isenberg. 2016. Interactive exploration of 3D scientific visualizations on large display surfaces. In Collaboration Meets Interactive Surfaces and Spaces: Theory and Practice, Craig Anslow, Pedro Campos, and Joaquim Jorge (Eds.). Springer, Berlin. To appear.Google ScholarHiroshi Ishii. 2008. The tangible user interface and its evolution. Communications of the ACM 51, 6 (June 2008), 32--36.  Google ScholarDigital LibraryBret Jackson, Tung Yuen Lau, David Schroeder, Kimani C. Toussaint Jr., and Daniel F. Keefe. 2013. A lightweight tangible 3D interface for interactive visualization of thin fiber structures. IEEE Transactions on Visualization and Computer Graphics 19, 12 (Dec. 2013), 2802--2809.  Google ScholarDigital LibraryRobert JK Jacob, Linda E Sibert, Daniel C McFarlane, and M Preston Mullen Jr. 1994. Integrality and separability of input devices. ACM Transactions on Computer-Human Interaction 1, 1 (1994), 3--26.  Google ScholarDigital LibraryYvonne Jansen, Pierre Dragicevic, and Jean-Daniel Fekete. 2012. Tangible remote controllers for wall-size displays. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 2865--2874.  Google ScholarDigital LibraryMartin Kaltenbrunner, Till Bovermann, Ross Bencina, and Enrico Costanza. 2005. TUIO: A protocol for table-top tangible user interfaces. In Proceedings of the International Workshop on Gesture in Human-Computer Interaction and Simulation. Vannes, France. http://opensoundcontrol.org/tuio-protocol-table-top-tangible-user-interfacesGoogle ScholarNicholas Katzakis, Kiyoshi Kiyokawa, and Haruo Takemura. 2013. Plane-casting: 3D cursor control with a smartphone. In Proceedings of the Asia Pacific Conference on Computer Human Interaction. ACM, New York, 199--200.  Google ScholarDigital LibraryDaniel F. Keefe. 2010. Integrating visualization and interaction research to improve scientific workflows. IEEE Computer Graphics and Applications 30, 2 (March/April 2010), 8--13.  Google ScholarDigital LibraryDaniel F. Keefe and Tobias Isenberg. 2013. Reimagining the scientific visualization interaction paradigm. IEEE Computer 46, 5 (May 2013), 51--57.  Google ScholarDigital LibraryKenrick Kin, Maneesh Agrawala, and Tony DeRose. 2009. Determining the benefits of direct-touch, bimanual, and multifinger input on a multitouch workstation. In Proceedings of Graphics Interface. CIPS, Toronto, 119--124. Google ScholarDigital LibraryTijmen Klein, Florimond Gueniat, Luc Pastur, Frederic Vernier, and Tobias Isenberg. 2012. A design study of direct-touch interaction for exploratory 3D scientific visualization. Computer Graphics Forum 31, 3 (June 2012), 1225--1234.  Google ScholarDigital LibrarySebastian Knoedel and Martin Hachet. 2011. Multi-touch RST in 2D and 3D spaces: Studying the impact of directness on user performance. In Proceedings of the IEEE Symposium on 3D User Interfaces. IEEE Computer Society, Los Alamitos, 75--78. Google ScholarDigital LibraryVincent Levesque, Louise Oram, Karon MacLean, Andy Cockburn, Nicholas D. Marchuk, Dan Johnson, J. Edward Colgate, and Michael A. Peshkin. 2011. Enhancing physicality in touch interaction with programmable friction. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 2481--2490.  Google ScholarDigital LibraryHai-Ning Liang, Cary Williams, Myron Semegen, Wolfgang Stuerzlinger, and Pourang Irani. 2013. An investigation of suitable interactions for 3D manipulation of distant objects through a mobile device. International Journal of Innovative Computing, Information and Control 9, 12 (2013), 4737--4752. http://www.ijicic.org/apchi12--291.pdfGoogle ScholarAurelien Lucchi, Patrick Jermann, Guillaume Zufferey, and Pierre Dillenbourg. 2010. An empirical evaluation of touch and tangible interfaces for tabletop displays. In Proceedings of the International Conference on Tangible, Embedded, and Embodied Interaction. ACM, New York, 177--184.  Google ScholarDigital LibraryPaul Marshall, Rowanne Fleck, Amanda Harris, Jochen Rick, Eva Hornecker, Yvonne Rogers, Nicola Yuill, and Nick Sheep Dalton. 2009. Fighting for control: Children's embodied interactions when using physical and digital representations. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 2149--2152.  Google ScholarDigital LibraryAnthony Martinet, Gery Casiez, and Laurent Grisoni. 2010. The effect of DOF separation in 3D manipulation tasks with multi-touch displays. In Proceedings of the ACM Symposium on Virtual Reality Software and Technology. ACM, New York, 111--118.  Google ScholarDigital LibraryShawna Meyer, Oryx Cohen, and Erik Nilsen. 1994. Device comparisons for goal-directed drawing tasks. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 251--252.  Google ScholarDigital LibraryTamara Munzner, Chris Johnson, Robert Moorhead, Hanspeter Pfister, Penny Rheingans, and Terry S. Yoo. 2006. NIH-NSF visualization research challenges report summary. Computer Graphics and Applications, IEEE 26, 2 (March 2006), 20--24.  Google ScholarDigital LibraryJakob Nielsen. 1993. Usability Engineering. Morgan Kaufmann, San Francisco.Google ScholarIzabel C. Olson, Zeina Atrash Leong, Uri Wilensky, and Mike S. Horn. 2011. \"It's just a toolbar!\" Using tangibles to help children manage conflict around a multi-touch tabletop. In Proceedings of the International Conference on Tangible, Embedded, and Embodied Interaction. ACM, New York, 29--36.  Google ScholarDigital LibraryIvan Poupyrev and Shigeaki Maruyama. 2003. Tactile interfaces for small touch screens. In Proceedings of the Annual ACM Symposium on User Interface Software and Technology. ACM, New York, 217--220.  Google ScholarDigital LibrarySara Price, Yvonne Rogers, Mike Scaife, Danae Stanton, and Helen Neale. 2003. Using \"tangibles\" to promote novel forms of playful learning. Interacting with Computers 15, 2 (April 2003), 169--185.Google ScholarCross RefMathieu Raynal, Guillaume Gauffre, Cedric Bach, Benedicte Schmitt, and Emmanuel Dubois. 2010. Tactile camera vs. tangible camera: Taking advantage of small physical artefacts to navigate into large data collection. In Proceedings of the Nordic Conference on Human-Computer Interaction. ACM, New York, 373--382.  Google ScholarDigital LibraryFarzan Sasangohar, I. Scott MacKenzie, and Stacey Scott. 2009. Evaluation of mouse and touch input for a tabletop display using Fitts' reciprocal tapping task. Proceedings of the Human Factors and Ergonomics Society Annual Meeting 53, 12 (Oct. 2009), 839--843.Google ScholarCross RefJeff Sauro and James R. Lewis. 2010. Average task times in usability tests: What to report?. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 2347--2350.  Google ScholarDigital LibraryDominik Schmidt, Florian Block, and Hans Gellersen. 2009. A comparison of direct and indirect multi-touch input for large surfaces. In Proceedings of Human-Computer Interaction -- INTERACT. Springer, Berlin, Heidelberg, 582--594.  Google ScholarDigital LibraryAndrew Sears and Ben Shneiderman. 1991. High precision touchscreens: Design strategies and comparisons with a mouse. International Journal of Man-Machine Studies 34, 4 (1991), 593--613.  Google ScholarDigital LibraryAbigail J. Sellen, Gordon P. Kurtenbach, and William A. S. Buxton. 1992. The prevention of mode errors through sensory feedback. Human Computer Interaction 7, 2 (June 1992), 141--164.  Google ScholarDigital LibraryOrit Shaer and Eva Hornecker. 2010. Tangible user interfaces: Past, present, and future directions. Foundations and Trends in Human-Computer Interaction 3, 1--2 (2010), 1--137.  Google ScholarDigital LibraryChristopher D. Shaw. 1998. Pain and fatigue in desktop VR: Initial results. In Proceedings of Graphics Interface. CIPS, Toronto, 185--192.Google ScholarBen Shneiderman. 1991. Touch screens now offer compelling uses. IEEE Software 8, 2 (March 1991), 93--94.  Google ScholarDigital LibraryKen Shoemake. 1992. ARCBALL: A user interface for specifying three-dimensional orientation using a mouse. In Proceedings of Graphics Interface. CIPS, Toronto, 151--156. Google ScholarDigital LibraryAdalberto L. Simeone and Hans Gellerseny. 2015. Comparing indirect and direct touch in a stereoscopic interaction task. In Proceedings of the IEEE Symposium on 3D User Interfaces. IEEE Computer Society, Los Alamitos, 105--108.Google ScholarPeng Song, Wooi Boon Goh, Chi-Wing Fu, Qiang Meng, and Pheng-Ann Heng. 2011. WYSIWYF: Exploring and annotating volume data with a tangible handheld device. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 1333--1342.  Google ScholarDigital LibraryNicole Sultanum, Sowmya Somanath, Ehud Sharlin, and Mario Costa Sousa. 2011. \"Point it, split it, peel it, view it\": Techniques for interactive reservoir visualization on tabletops. In Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces. ACM, New York, 192--201.  Google ScholarDigital LibraryLucia Terrenghi, David Kirk, Abigail Sellen, and Shahram Izadi. 2007. Affordances for manipulation of physical versus digital media on interactive surfaces. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 1157--1166.  Google ScholarDigital LibraryPhilip Tuddenham, David Kirk, and Shahram Izadi. 2010. Graspables revisited: Multi-touch vs. tangible input for tabletop displays in acquisition and manipulation tasks. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 2223--2232.  Google ScholarDigital LibraryBrygg Ullmer and Hiroshi Ishii. 2000. Emerging frameworks for tangible user interfaces. IBM Systems Journal 39, 3.4 (2000), 915--931.  Google ScholarDigital LibraryDimitar Valkov, Frank Steinicke, Gerd Bruder, and Klaus Hinrichs. 2011. 2D touching of 3D stereoscopic objects. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 1353--1362.  Google ScholarDigital LibraryGary R. VandenBos (Ed.). 2009. Publication Manual of the American Psychological Association (6th ed.). American Psychological Association, Washington, DC. http://www.apastyle.org/manual/Google ScholarVanessa Vuibert, Wolfgang Stuerzlinger, and Jeremy R Cooperstock. 2015. Evaluation of docking task performance using mid-air interaction techniques. In Proceedings of the ACM Symposium on Spatial User Interaction. ACM, New York, 44--52.  Google ScholarDigital LibrarySijie Wang. 2010. Comparing tangible and multi-touch interfaces for a spatial problem solving task. Master's thesis. Simon Fraser University, Canada. http://summit.sfu.ca/item/11500Google ScholarDiane Watson, Mark Hancock, Regan L. Mandryk, and Max Birk. 2013. Deconstructing the touch experience. In Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces. ACM, New York, 199--208.  Google ScholarDigital LibraryDaniel Wigdor and Dennis Wixon. 2011. Brave NUI World: Designing Natural User Interfaces for Touch and Gesture. Morgan Kaufmann Publishers Inc., San Francisco. Google ScholarDigital LibraryLesley Xie, Alissa N. Antle, and Nima Motamedi. 2008. Are tangibles more fun? Comparing children's enjoyment and engagement using physical, graphical and tangible user interfaces. In Proceedings of the International Conference on Tangible, Embedded, and Embodied Interaction. ACM, New York, 191--198.  Google ScholarDigital LibraryLingyun Yu, Pjotr Svetachov, Petra Isenberg, Maarten H. Everts, and Tobias Isenberg. 2010. FI3D: Direct-touch interaction for the exploration of 3D scientific visualization spaces. IEEE Transactions on Visualization and Computer Graphics 16, 6 (Nov./Dec. 2010), 1613--1622.  Google ScholarDigital LibraryShumin Zhai and Paul Milgram. 1998. Quantifying coordination in multiple DOF movement and its application to evaluating 6 DOF input devices. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, 320--327.  Google ScholarDigital LibrarySupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3025453.3025863/25110baf-baab-4faf-976a-43e0df6ec9ac/pn3094p.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee07e5e64ad2301e1e02b6a6cc881c42e49c996a1c968d77ebe8c7a41cdc0ef0c87ccdf4c62945fed68e914b673485f8647363d2888c1b63cc422b56fe4cce85439733b75bee7fa2faapplication/x-mpegurlmp41.1 MB", "keywords": ["mouse", "usability study", "3D interaction", "tactile interaction", "TUI", "tangible interaction"], "published_in": "CHI '17: Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2017", "citations": "20", "isbn": "9781450346559", "doi": "10.1145/3025453", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3025453.3025863", "paper_url": "https://dl.acm.org/doi/10.1145/3025453.3025863"}, {"title": "Handsaw: tangible exploration of volumetric data by direct cut-plane projection", "authors": ["Leonardo Bonanni", "Jason Alonso", "Neil Chao", "Greg Vargas", "Hiroshi Ishii"], "abstract": "Tangible User Interfaces are well-suited to handling three-dimensional data sets by direct manipulation of real objects in space, but current interfaces can make it difficult to look inside dense volumes of information. This paper presents the Handsaw, a system that detects a virtual cut-plane projected by an outstretched hand or laser-line directly on an object or space and reveals sectional data on an adjacent display. By leaving the hands free and using a remote display, these techniques can be shared between multiple users and integrated into everyday practice. The Handsaw has been prototyped for scientific visualizations in medicine, engineering and urban design. User evaluations suggest that using a hand is more intuitive while projected light is more precise than keyboard and mouse control, and the Handsaw system has the potential to be used effectively by novices and in groups.", "keywords": ["product design", "scientific visualization", "volumetric data", "tangible user interface", "cross-section", "interior design", "medical visualization"], "published_in": "CHI '08: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "6 April 2008", "citations": "7", "isbn": "9781605580111", "doi": "10.1145/1357054", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1357054.1357098", "paper_url": "https://dl.acm.org/doi/10.1145/1357054.1357098"}, {"title": "Robots, Pancakes, and Computer Games: Designing Serious Games for Robot Imitation Learning", "authors": ["Benjamin Walther-Franks", "Jan Smeddinck", "Peter Szmidt", "Andrei Haidu", "Michael Beetz", "Rainer Malaka"], "abstract": "Autonomous manipulation robots can be valuable aids as interactive agents in the home, yet it has proven extremely difficult to program their behavior. Imitation learning uses data on human demonstrations to build behavioral models for robots. In order to cover a wide range of action strategies, data from many individuals is needed. Acquiring such large amounts of data can be a challenge. Tools for data capturing in this domain must thus implement a good user experience. We propose to use human computation games in order to gather data on human manual behavior. We demonstrate the idea with a strategy game that is operated via a natural user interface. A comparison between using the game for action execution and demonstrating actions in a virtual environment shows that people interact longer and have a better experience when playing the game.                     References                 Aras, H., Krause, M., Haller, A., &amp; Malaka, R. (2010). Webpardy: Harvesting QA by HC. In Proc. HCOMP 2010, (pp. 49--52). ACM.  Google ScholarDigital LibraryArgall, B. D., Chernova, S., Veloso, M., &amp; Browning, B. (2009). A survey of robot learning from demonstration. Robotics and Autonomous Systems, 57(5), 469--483.  Google ScholarDigital LibraryBeetz, M., Klank, U., Kresse, I., Maldonado, A., Mosenlechner, L., Pangercic, D., Ruhr, T., &amp; Tenorth, M. (2011). Robotic roommates making pancakes. In Proc. Humanoids 2011, (pp. 529--536). IEEE.Google ScholarCross RefBillard, A., Calinon, S., Dillmann, R., &amp; Schaal, S. (2008). Robot programming by demonstration. In B. Siciliano, &amp; O. Khatib (Eds.) Springer Handbook of Robotics, chap. 60, (pp. 1371--1394). Springer.Google ScholarBollini, M., Tellex, S., Thompson, T., Roy, N., &amp; Rus, D. (2013). Interpreting and executing recipes with a cooking robot. In J. P. Desai, G. Dudek, O. Khatib, &amp; V. Kumar (Eds.) Experimental Robotics, vol. 88 of Springer Tracts in Advanced Robotics, (pp. 481--495). Springer.Google ScholarBonetta, L. (2009). New citizens for the life sciences. Cell, 138(6), 1043--1045.Google ScholarCross RefBowman, D. A., Kruijff, E., LaViola, J. J., &amp; Poupyrev, I. (2004). 3D User Interfaces: Theory and Practice. Addison-Wesley. Google ScholarDigital LibraryDeterding, S., Dixon, D., Khaled, R., &amp; Nacke, L. (2011). From game design elements to gamefulness: Defining \"gamification\". In Proc MindTrek 2011, (pp. 9--15). New York, NY, USA: ACM.  Google ScholarDigital LibraryFlatla, D. R., Gutwin, C., Nacke, L. E., Bateman, S., &amp; Mandryk, R. L. (2011). Calibration games: Making calibration tasks enjoyable by adding motivating game elements. In Proc. UIST 2011, (pp. 403--412). ACM.  Google ScholarDigital LibraryForbes, M., Chung, M. J., Cakmak, M., &amp; Rao, R. P. N. (2014). Robot programming by demonstration with crowdsourced action fixes. In Proc. HCOMP 2014, (pp. 67--76). AAAI Press.Google ScholarHaidu, A., Kohlsdorf, D., &amp; Beetz, M. (2014). Learning task outcome prediction for robot control from interactive environments. In Proc. Intelligent Robots and Systems. IEEE/RSJ.Google ScholarCross RefHunicke, R., LeBlanc, M., &amp; Zubek, R. (2004). MDA: A formal approach to game design and game research. In D. Fu, S. Henke, &amp; J. Orkin (Eds.) AAAI Workshop Challenges in Game Artificial Intelligence. AAAI Press.Google ScholarKanda, T., Ishiguro, H., Imai, M., &amp; Ono, T. (2004). Development and evaluation of interactive humanoid robots. Proceedings of the IEEE, 92(11), 1839--1850.Google ScholarCross RefKrause, M., &amp; Smeddinck, J. (2012). Human Computation: A New Aspect of Serious Games., (pp. 1027--1047). In Handbook of Research on Serious Games as Educational, Business and Research Tools: Development and Design. IGI Global.Google ScholarKrause, M., Takhtamysheva, A., Wittstock, M., &amp; Malaka, R. (2010). Frontiers of a paradigm: Exploring human computation with digital games. In Proc HCOMP 10, (pp. 22--25). ACM.  Google ScholarDigital LibraryKunze, L., Haidu, A., &amp; Beetz, M. (2013). Acquiring task models for imitation learning through games with a purpose. In Proc. IROS, 2013, (pp. 102--107). IEEE.Google ScholarCross RefLeap Motion, Inc. http://leapmotion.com (last visited on 2015-01-07).Google ScholarMatyas, S., Matyas, C., Schlieder, C., Kiefer, P., Mitarai, H., &amp; Kamata, M. (2008). Designing locationbased mobile games with a purpose: Collecting geospatial data with CityExplorer. In Proc. ACE 2008, (pp. 244--247). ACM.  Google ScholarDigital LibraryMcCarthy, J. (1968). Programs with common sense. In Semantic Information Processing, vol. 1, (pp. 403--418).Google ScholarPollard, N. S., Hodgins, J. K., Riley, M. J., &amp; Atkeson, C. G. (2002). Adapting human motion for the control of a humanoid robot. In Proc. ICRA 2002, vol. 2, (pp. 1390--1397). IEEE.Google ScholarCross RefQuinn, A. J., &amp; Bederson, B. B. (2011). Human computation: A survey and taxonomy of a growing field. In Proc. CHI 2011, (pp. 1403--1412). ACM.  Google ScholarDigital LibraryRyan, R. M., Rigby, C. S., &amp; Przybylski, A. (2006). The motivational pull of video games: A Self-Determination theory approach. Motivation and Emotion, 30(4), 344--360.Google ScholarCross RefSchaal, S. (1999). Is imitation learning the route to humanoid robots? Trends in Cognitive Sciences, 3(6), 233--242.Google ScholarCross RefShamsuddin, S., Ismail, L. I., Yussof, H., Ismarrubie Zahari, N., Bahari, S., Hashim, H., &amp; Jaffar, A. (2011). Humanoid robot NAO: Review of control and motion exploration. In Proc. ICCSCE, (pp. 511--516). IEEE.Google ScholarCross RefToris, R., Kent, D., &amp; Chernova, S. (2014). The robot management system: A framework for conducting Human-Robot interaction studies through crowdsourcing. Journal of Human-Robot Interaction, 3(2), 25+.Google ScholarCross RefTuite, K., Snavely, N., Hsiao, D. Y., Smith, A. M., &amp; Popovi\u0107, Z. (2010). Reconstructing the world in 3D: Bringing games with a purpose outdoors. In Proc. FDG 2010, (pp. 232--239). ACM.  Google ScholarDigital Libraryvon Ahn, L., &amp; Dabbish, L. (2008). Designing games with a purpose. Commun. ACM, 51(8), 58--67.  Google ScholarDigital LibraryYuen, M.-C., Chen, L.-J., &amp; King, I. (2009). A survey of human computation systems. In Proc. CSE, vol. 4, (pp. 723--728). Los Alamitos, CA, USA: IEEE.  Google ScholarDigital LibrarySupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/2702123.2702552/501e6abf-ac2c-487a-b2b2-35a6f41c8367/pn2328-file3.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ef00e7e19e8ead7e09dfbd94141ee5ab48c2da06d1026f60901dd392274ef315d38921510a5f9053651348d2d152b6f5ff6793d585fb5aa8619b127d50d23881201968e9e7d56b229aapplication/x-mpegurlmp427.2 MB", "keywords": ["human computation games", "programming by demonstration"], "published_in": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems", "publication_date": "18 April 2015", "citations": "4", "isbn": "9781450331456", "doi": "10.1145/2702123", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2702123.2702552", "paper_url": "https://dl.acm.org/doi/10.1145/2702123.2702552"}, {"title": "iGYM: A Wheelchair-Accessible Interactive Floor Projection System for Co-located Physical Play", "authors": ["Roland Graf", "Sun Young Park", "Emma Shpiz", "Hun Seok Kim"], "abstract": "Physical play opportunities for people with motor disabilities typically do not include co-located play with peers without disabilities in traditional sport settings. In this paper, we present a prototype of a wheelchair-accessible interactive floor projection system, iGYM, designed to enable people with motor disabilities to compete on par with, and in the same environment as, peers without disabilities. iGYM provides two key system features-peripersonal circle interaction and adjustable game mechanic (physics)-that enable individualized game calibration and wheelchair-accessible manipulation of virtual targets on the floor. Preliminary findings from our pilot study with people with motor disabilities using power wheelchairs, manual wheelchairs, and people without disabilities showed that the prototype system was accessible for all participants at higher than anticipated target speeds. Our work has implications for designing novel, physical play opportunities in inclusive traditional sport settings.                     References                 M. Biggio, A. Bisio, L. Avanzino, P. Ruggeri, &amp; M. Bove. 2017. This racket is not mine: The influence of the tool-use on peripersonal space. Neuropsychologia, 103, 54--58.Google ScholarPatrick Carrington, Amy Hurst, and Shaun K. Kane. 2014 . Wearables and chairables: inclusive design of mobile input and output techniques for power wheelchair users. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '14). ACM, New York, NY, USA, 3103--3112.  Google ScholarFranceli L. Cibrian, Monica Tentori &amp; Ana I. Mart\u00ednez-Garc\u00eda. 2016. Hunting Relics: A Persuasive Exergame to Promote Collective Exercise in Young Children. In International Journal of Human--Computer Interaction, 32:3, 277--294Google ScholarJamal K. Edey, Katie Seaborn, Carmen Branje, Deborah I. Fels. 2014. Powered to Play: A mixed reality game for people driving powered chairs. IEE 978--1--4799--7546--4/14/Google ScholarGiulia Galli, Jean Paul Noel, Elisa Canzoneri, Olaf Blanke, Andrea Serino. 2015. The wheelchair as a full-body tool extending the peripersonal space. In Frontiers in Psychology, 6, 639.Google ScholarKathrin Gerling, Kieran Hicks, Michael Kalyn, Adam Evans, and Conor Linehan. 2016. Designing Movement-based Play With Young People Using Powered Wheelchairs. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI '16). ACM, New York, NY, USA, 4447--4458.  Google ScholarKathrin Maria Gerling, Matthew Miller, Regan L. Mandryk, Max Valentin Birk, and Jan David Smeddinck. 2014. Effects of balancing for physical abilities on player performance, experience and self-esteem in exergames. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '14). ACM, New York, NY, USA, 2201--2210. DOI: https://dl.acm.org/citation.cfm?doid=2556288.2556963  Google ScholarRoland Graf and Surat Kwanmuang. 2015. Solar Pink Pong: Street Video Game. In Proceedings of the Ninth International Conference on Tangible, Embedded, and Embodied Interaction (TEI '15). ACM, New York, NY, USA, 417--418.  Google ScholarMichael S. Jeffress, William J. Brown. 2017. Opportunities and Benefits for Powerchair Users Through Power Soccer. In Adapted Physical Activity Quarterly, 2017, 34, 235--255.Google ScholarGillian King, Theresa Petrenchik, Mary Law &amp; Patricia Hurley. 2009. The Enjoyment of Formal and Informal Recreation and Leisure Activities: A comparison of school-aged children with and without physical disabilities. In International Journal of Disability, Development and Education, 56:2, 109--130.Google ScholarAdrian Lees, Lee Nolan. 1998. The biomechanics of soccer: A review. In Journal of Sports Sciences, 16:3, 211--234.Google ScholarCheryl Missiuna, Nancy Pollock. 1991. Play Deprivation in Children With Physical Disabilities: The Role of the Occupational Therapist in Preventing Secondary Disability. In American Journal of Occupational Therapy, 1991; Vol 45(10):882--888.Google ScholarFlorian 'Floyd' Mueller, Darren Edge, Frank Vetere, Martin R. Gibbs, Stefan Agamanolis, Bert Bongers, and Jennifer G. Sheridan. 2011. Designing sports: a framework for exertion games. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11). ACM, New York, NY, USA, 2651--2660.  Google ScholarRimmer, James H., Jennifer L. Rowland, and Kiyoshi Yamaki. 2007. Obesity and secondary conditions in adolescents with disabilities: addressing the needs of an underserved population. In Journal of Adolescent Health 41, no. 3 (2007): 224--229.Google ScholarElena Marquez Segura, Katherine Isbister. 2015. Enabling Co-Located Physical Social Play: A Framework for Design and Evaluation. In: Bernhaupt R. (eds) Game User Experience Evaluation. Human--Computer Interaction Series. Springer, ChamGoogle ScholarElena Marquez Segura, Katherine Isbister. 2015. Enabling Co-Located Physical Social Play: A Framework for Design and Evaluation. In: Bernhaupt R. (eds) Game User Experience Evaluation. Human--Computer Interaction Series. Springer, ChamGoogle ScholarIssey Takahashi, Mika Oki, Baptiste Bourreau, Itaru Kitahara, Kenji Suzuki. 2018. FUTUREGYM: A gymnasium with interactive floor projection for children with special needs. In International Journal of Child-Computer Interaction, Vol 5, 2018, 37--47.Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3290607.3312792/a05a09e9-0422-4cbf-952c-4847111aa3df/lbw1615p.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee05eee35a4ac1e15fa135bbd4a631e87f42110f72c2b06b8980880eff9e2dd10861e70cd46c9f3cef84b9e0da805d6a80022da2cd08b9ac0c22229d2fcf951a9304100f7215f270daapplication/x-mpegurlmp43 MB", "keywords": ["interactive floor", "game accessibility", "co-located play", "adaptive sport", "peripersonal space"], "published_in": "CHI EA '19: Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "2", "isbn": "9781450359719", "doi": "10.1145/3290607", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290607.3312792", "paper_url": "https://dl.acm.org/doi/10.1145/3290607.3312792"}, {"title": "Crowdsourcing Interface Feature Design with Bayesian Optimization", "authors": ["John J. Dudley", "Jason T. Jacques", "Per Ola Kristensson"], "abstract": "Designing novel interfaces is challenging. Designers typically rely on experience or subjective judgment in the absence of analytical or objective means for selecting interface parameters. We demonstrate Bayesian optimization as an efficient tool for objective interface feature refinement. Specifically, we show that crowdsourcing paired with Bayesian optimization can rapidly and effectively assist interface design across diverse deployment environments. Experiment 1 evaluates the approach on a familiar 2D interface design problem: a map search and review use case. Adding a degree of complexity, Experiment 2 extends Experiment 1 by switching the deployment environment to mobile-based virtual reality. The approach is then demonstrated as a case study for a fundamentally new and unfamiliar interaction design problem: web-based augmented reality. Finally, we show how the model generated as an outcome of the refinement process can be used for user simulation and queried to deliver various design insights.", "keywords": ["optimization", "interface design", "crowdsourcing"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "0", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300482", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300482"}, {"title": "Augmented Reality Views for Occluded Interaction", "authors": ["Klemen Lilija", "Henning Pohl", "Sebastian Boring", "Kasper Hornb\u00e6k"], "abstract": "We rely on our sight when manipulating objects. When objects are occluded, manipulation becomes difficult. Such occluded objects can be shown via augmented reality to re-enable visual guidance. However, it is unclear how to do so to best support object manipulation. We compare four views of occluded objects and their effect on performance and satisfaction across a set of everyday manipulation tasks of varying complexity. The best performing views were a see-through view and a displaced 3D view. The former enabled participants to observe the manipulated object through the occluder, while the latter showed the 3D view of the manipulated object offset from the object's real location. The worst performing view showed remote imagery from a simulated hand-mounted camera. Our results suggest that alignment of virtual objects with their real-world location is less important than an appropriate point-of-view and view stability.                     References                 Roland Arsenault and Colin Ware. 2000. Eye-Hand Co-Ordination with Force Feedback. In Proceedings of the SIGCHI conference on Human factors in computing systems - CHI '00. ACM Press, New York, New York, USA, 408--414.  Google ScholarDigital LibraryP. Barnum, Y. Sheikh, A. Datta, and T. Kanade. 2009. Dynamic seethroughs: Synthesizing hidden views of moving objects. In 2009 8th IEEE International Symposium on Mixed and Augmented Reality. 111--114.  Google ScholarDigital LibraryChristoph Bichlmeier, Sandro Michael Heining, Marco Feuerstein, and Nassir Navab. 2009. The virtual mirror: a new interaction paradigm for augmented reality environments. IEEE Transactions on Medical Imaging 28, 9 (2009), 1498--1510.Google ScholarCross RefIan M Bullock and Aaron M Dollar. 2011. Classifying human manipulation behavior. In Rehabilitation Robotics (ICORR), 2011 IEEE International Conference on. IEEE, 1--6.Google ScholarCross RefAshleyColley,OlliKoskenranta,JaniV\u00e4yrynen,LeenaVent\u00e4-Olkkonen, and Jonna H\u00e4kkil\u00e4. 2014. Windows to other places: exploring solutions for seeing through walls using handheld projection. In Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational. ACM, 127--136.  Google ScholarDigital LibraryMustafa Tolga Eren and Selim Balcisoy. 2018. Evaluation of X-ray visualization techniques for vertical depth judgments in underground exploration. The Visual Computer 34, 3 (2018), 405--416.  Google ScholarDigital LibraryThomas Feix, Ian M Bullock, and Aaron M Dollar. 2014. Analysis of human grasping behavior: Object characteristics and grasp type. IEEE transactions on haptics 7, 3 (2014), 311--323.Google ScholarRichard Held, Aglaia Efstathiou, and Martha Greene. 1966. Adaptation to displaced and delayed visual feedback from the hand. Journal of Experimental Psychology 72, 6 (1966), 887.Google ScholarCross RefSamantha Horvath, John Galeotti, Bing Wu, Roberta Klatzky, Mel Siegel, and George Stetten. 2014. FingerSight: Fingertip Haptic Sensing of the Visual Environment. IEEE Journal of Translational Engineering in Health and Medicine 2 (2014), 1--9.Google ScholarCross RefDaisuke Iwai and Kosuke Sato. 2011. Document search support by making physical documents transparent in projection-based mixed reality. Virtual reality 15, 2--3 (2011), 147--160.Google ScholarLS Jakobson and Melvyn A Goodale. 1989. Trajectories of reaches to prismatically-displaced targets: evidence for \"automatic\" visuomotor recalibration. Experimental Brain Research 78, 3 (1989), 575--587.Google ScholarCross RefBernhard Kainz, Stefan Hauswiesner, Gerhard Reitmayr, Markus Steinberger, Raphael Grasset, Lukas Gruber, Eduardo Veas, Denis Kalkofen, Hartmut Seichter, and Dieter Schmalstieg. 2012. OmniKinect: Real-time Dense Volumetric Data Acquisition and Applications. In Proceedings of the 18th ACM Symposium on Virtual Reality Software and Technology (VRST '12). ACM, New York, NY, USA, 25--32.  Google ScholarDigital LibraryDavid Kim, Otmar Hilliges, Shahram Izadi, Alex D. Butler, Jiawen Chen, Iason Oikonomidis, and Patrick Olivier. 2012. Digits: Freehand 3D Interactions Anywhere Using a Wrist-worn Gloveless Sensor. In Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology (UIST '12). ACM, New York, NY, USA, 167--176.  Google ScholarDigital LibraryRobert Krempien, Harald Hoppe, L\u00fcder Kahrs, Sascha Daeuber, Oliver Schorr, Georg Eggers, Marc Bischof, Marc W. Munter, Juergen Debus, and Wolfgang Harms. 2008. Projector-Based Augmented Reality for Intuitive Intraoperative Guidance in ImageGuided 3D Interstitial Brachytherapy. International Journal of Radiation Oncology*Biology*Physics 70, 3 (mar 2008), 944--952.Google ScholarTakeshi Kurata, Nobuchika Sakata, Masakatsu Kourogi, Hideaki Kuzuoka, and Mark Billinghurst. 2004. Remote collaboration using a shoulder-worn active camera/laser. In Wearable Computers, 2004. ISWC 2004. Eighth International Symposium on, Vol. 1. IEEE, 62--69.  Google ScholarDigital LibraryDavid Lindlbauer and Andy D. Wilson. 2018. Remixed Reality: Manipulating Space and Time in Augmented Reality. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI '18. ACM Press, New York, New York, USA, 129:1--129:13.  Google ScholarDigital LibraryFei Liu and Stefan Seipel. 2018. Precision study on augmented realitybased visual guidance for facility management tasks. Automation in Construction 90 (2018), 79--90.Google ScholarCross RefJ. Liu, F. Feng, Y. C. Nakamura, and N. S. Pollard. 2014. A taxonomy of everyday grasps in action. (Nov 2014), 573--580.Google ScholarWalterio W Mayol-Cuevas, Ben J Tordoff, and David W Murray. 2009. On the choice and placement of wearable vision sensors. IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans 39, 2 (2009), 414--425.  Google ScholarDigital LibraryJames Mccrae, Niloy J Mitra, and Karan Singh. 2013. Surface perception of planar abstractions. ACM Transactions on Applied Perception (TAP) 10, 3 (2013), 14.  Google ScholarDigital LibraryShohei Mori, Sei Ikeda, and Hideo Saito. 2017. A survey of diminished reality: Techniques for visually concealing, eliminating, and seeing through real objects. IPSJ Transactions on Computer Vision and Applications 9, 1 (dec 2017), 17.Google ScholarCross RefShohei Mori, Momoko Maezawa, and Hideo Saito. 2017. A work area visualization by multi-view camera-based diminished reality. Multimodal Technologies and Interaction 1, 3 (2017), 18.Google ScholarCross RefNassir Navab, Joerg Traub, Tobias Sielhorst, Marco Feuerstein, and Christoph Bichlmeier. 2007. Action-and workflow-driven augmented reality for computer-aided medical procedures. IEEE Computer Graphics and Applications 27, 5 (2007), 10--14.  Google ScholarDigital LibraryTomislav Pejsa, Julian Kantor, Hrvoje Benko, Eyal Ofek, and Andrew D Wilson. 2016. Room2Room: Enabling Life-Size Telepresence in a Projected Augmented Reality Environment. In Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing - CSCW '16. ACM Press, New York, New York, USA, 1714--1723.  Google ScholarDigital LibraryRob Reilink, Gart de Bruin, Michel Franken, Massimo A Mariani, Sarthak Misra, and Stefano Stramigioli. 2010. Endoscopic camera control by head movements for thoracic surgery. In Biomedical Robotics and Biomechatronics (BioRob), 2010 3rd IEEE RAS and EMBS International Conference on. IEEE, 510--515.Google ScholarCross RefAlberto Romay, Stefan Kohlbrecher, David C Conner, and Oskar Von Stryk. 2015. Achieving versatile manipulation tasks with unknown objects by supervised humanoid robots based on object templates.. In Humanoids. 249--255.Google ScholarYves Rossetti, Kazuo Koga, and Tadaaki Mano. 1993. Prismatic displacement of vision induces transient changes in the timing of eye-hand coordination. Perception &amp; Psychophysics 54, 3 (1993), 355--364.Google ScholarCross RefKaoru Sekiyama, Satoru Miyauchi, Toshihide Imaruoka, Hiroyuki Egusa, and Takara Tashiro. 2000. Body Image as a Visuomotor Transformation Device Revealed in Adaptation to Reversed Vision. Nature 407, 6802 (sep 2000), 374--377.Google ScholarCross RefRoy Shilkrot, Jochen Huber, J\u00fcrgen Steimle, Suranga Nanayakkara, and Pattie Maes. 2015. Digital Digits: A Comprehensive Survey of Finger Augmentation Devices. ACM Comput. Surv. 48, 2, Article 30 (Nov. 2015), 29 pages.  Google ScholarDigital LibraryLee Stearns, Victor DeSouza, Jessica Yin, Leah Findlater, and Jon E. Froehlich. 2017. Augmented Reality Magnification for Low Vision Users with the Microsoft Hololens and a Finger-Worn Camera. In Proceedings of the 19th International ACM SIGACCESS Conference on Computers and Accessibility - ASSETS '17. ACM Press, New York, New York, USA, 361--362.  Google ScholarDigital LibraryKazuya Sugimoto, Hiromitsu Fujii, Atsushi Yamashita, and Hajime Asama. 2014. Half-diminished reality image using three rgb-d sensors for remote control robots. In Safety, Security, and Rescue Robotics (SSRR), 2014 IEEE International Symposium on. IEEE, 1--6.Google ScholarRobert J. Teather and Wolfgang Stuerzlinger. 2008. Exaggerated Head Motions for Game Viewpoint Control. In Proceedings of the 2008 Conference on Future Play: Research, Play, Share (Future Play '08). ACM, New York, NY, USA, 240--243.  Google ScholarDigital LibraryKlen Copic Pucihar, Paul Coulton, and Jason Alexander. 2013. Evaluating Dual-view Perceptual Issues in Handheld Augmented Reality: Device vs. User Perspective Rendering. In Proceedings of the 15th ACM on International Conference on Multimodal Interaction (ICMI '13). ACM, New York, NY, USA, 381--388.  Google ScholarDigital LibraryColin Ware and Jeff Rose. 1999. Rotating virtual objects with real handles. ACM Transactions on Computer-Human Interaction (TOCHI) 6, 2 (1999), 162--180.  Google ScholarDigital LibraryRobert B Welch and Gerald Goldstein. 1972. Prism adaptation and brain damage. Neuropsychologia 10, 4 (1972), 387--394.Google ScholarCross RefMark Wentink, Paul Breedveld, Dirk W Meijer, and Henk G Stassen. 2000. Endoscopic camera rotation: a conceptual solution to improve hand-eye coordination in minimally-invasive surgery. Minimally Invasive Therapy &amp; Allied Technologies 9, 2 (2000), 125--131.Google ScholarCross RefXing-Dong Yang, Tovi Grossman, Daniel Wigdor, and George Fitzmaurice. 2012. Magic Finger: Always-available Input Through Finger Instrumentation. In Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology (UIST '12). ACM, New York, NY, USA, 147--156.  Google ScholarDigital LibraryTsuneo Yoshikawa. 2000. Force control of robot manipulators. 1 (2000), 220--226.Google ScholarStefanie Zollmann, Raphael Grasset, Gerhard Reitmayr, and Tobias Langlotz. 2014. Image-based X-ray visualization techniques for spatial understanding in Outdoor Augmented Reality. In Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design. ACM, 194--203.  Google ScholarDigital Librarypn4779.zipThe auxiliary material contains a PDF file with a figure showing participants ratings for every combination of object and visualization.Supplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3290605.3300676/543eeae5-c482-498b-ba17-36a7d52c15e9/paper446p.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee05eee35a4ac3e15fa134b9c1291b9e30fd5c731486fe2b911b87c64cf96598f71d181f751a0926047d4252ae0e8c3dcd7772befeadd7083ff30e159566b5b048f7f7c44c05fdaea6application/x-mpegurlmp41.9 MB", "keywords": ["augmented reality", "finger-camera", "manipulation task"], "published_in": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "2", "isbn": "9781450359702", "doi": "10.1145/3290605", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290605.3300676", "paper_url": "https://dl.acm.org/doi/10.1145/3290605.3300676"}, {"title": "SIG: Spatiality of Augmented Reality User Interfaces", "authors": ["Alla Vovk", "Danilo Gasques Rodrigues", "Fridolin Wild", "Nadir Weibel"], "abstract": "Augmented reality and spatial information manipulation is being increasingly used as part of environ- ment integrated form factors and wearable device such as head-mounted displays. The integration of this exciting technology in many aspects of peoples' lives is transforming the way we understand computing, pushing the boundaries of Spatial Interfaces into virtual but embedded environments. We think that the time is ripe for a renewed discussion about the role of Augmented Reality within Spatial Interfaces. With this SIG we want to expand the discussion related to Spatial Interfaces and the way they impact interaction with the world in two areas. First, we aim to critically discuss the definition of Spatial Interfaces and outline the common components that build such interfaces in today's world. Second, we would like the community to reflect on the path ahead and focus on the potential of what kind of experiences can Spatial Interfaces achieve today", "keywords": ["spatial computing", "spatial interface", "augmented reality", "interaction"], "published_in": "CHI EA '19: Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "0", "isbn": "9781450359719", "doi": "10.1145/3290607", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290607.3311756", "paper_url": "https://dl.acm.org/doi/10.1145/3290607.3311756"}, {"title": "Remixed Reality: Manipulating Space and Time in Augmented Reality", "authors": ["David Lindlbauer", "Andy D. Wilson"], "abstract": "We present Remixed Reality, a novel form of mixed reality. In contrast to classical mixed reality approaches where users see a direct view or video feed of their environment, with Remixed Reality they see a live 3D reconstruction, gathered from multiple external depth cameras. This approach enables changing the environment as easily as geometry can be changed in virtual reality, while allowing users to view and interact with the actual physical world as they would in augmented reality. We characterize a taxonomy of manipulations that are possible with Remixed Reality: spatial changes such as erasing objects; appearance changes such as changing textures; temporal changes such as pausing time; and viewpoint changes that allow users to see the world from different points without changing their physical location. We contribute a method that uses an underlying voxel grid holding information like visibility and transformations, which is applied to live geometry in real time.                     References                 Mahdi Azmandian, Mark Hancock, Hrvoje Benko, Eyal Ofek, and Andrew D. Wilson. 2016. Haptic Retargeting: Dynamic Repurposing of Passive Haptics for Enhanced Virtual Reality Experiences. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI '16). ACM, New York, NY, USA, 19681979.  Google ScholarHrvoje Benko, Andrew D. Wilson, and Federico Zannier. 2014. Dyadic Projected Spatial Augmented Reality. In Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '14). ACM, New York, NY, USA, 645--655.  Google ScholarPaul J. Besl and Neil D. McKay. 1992. A Method for Registration of 3-D Shapes. IEEE Trans. Pattern Anal. Mach. Intell. 14, 2 (February 1992), 239--256.  Google ScholarMark Billinghurst, Adrian Clark, and Gun Lee. 2015. A Survey of Augmented Reality. Found. Trends Hum.Comput. Interact. 8, 2--3, 73--272.  Google ScholarOliver Bimber and Ramesh Raskar. 2005. Spatial Augmented Reality: Merging Real and Virtual Worlds. A. K. Peters, Ltd., Natick, MA, USA. Google ScholarGerd Bruder, Frank Steinicke, Klaus H. Hinrichs. 2009. Arch-Explore: A natural user interface for immersive architectural walkthroughs. In Proceedings of the IEEE Symposium on 3D User Interfaces (3DUI'09). 75--82.  Google ScholarKai B\u00fcrger, Jens Kr\u00fcger and R\u00fcdiger Westermann. Direct Volume Editing. 2008. In IEEE Transactions on Visualization and Computer Graphics, 14 / 6, 13881395.  Google ScholarMingsong Dou, Sameh Khamis, Yury Degtyarev, Philip Davidson, Sean Ryan Fanello, Adarsh Kowdle, Sergio Orts Escolano, Christoph Rhemann, David Kim, Jonathan Taylor, Pushmeet Kohli, Vladimir Tankovich, and Shahram Izadi. 2016. Fusion4D: real-time performance capture of challenging scenes. In ACM Trans. Graph. 35/4.  Google ScholarSteven Feiner, Blair MacIntyre, Marcus Haupt, and Eliot Solomon. 1993. Windows on the world: 2D windows for 3D augmented reality. In Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '93). ACM, New York, NY, USA, 145--155.  Google ScholarSebastian Freitag, Dominik Rausch, Torsten Kuhlen. 2014 Reorientation in virtual environments using interactive portals. In Proceedings of the IEEE Symposium on 3D User Interfaces (3DUI'14). 119--122.Google ScholarJan Herling and Wolfgang Broll. 2012. PixMix: A realtime approach to high-quality Diminished Reality. In Proceedings of the IEEE International Symposium on Mixed and Augmented Reality (ISMAR '12). IEEE Computer Society, Washington, DC, USA, 141--150.  Google ScholarAnuruddha Hettiarachchi and Daniel Wigdor. 2016. Annexing Reality: Enabling Opportunistic Use of Everyday Objects As Tangible Proxies in Augmented Reality. In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '16). ACM, New York, NY, USA, 1957--1967.  Google ScholarMatthias Innmann, Michael Zollh\u00f6fer, Matthias Nie\u00dfner, Christian Theobalt, and Marc Stamminger. (2016) VolumeDeform: Real-Time Volumetric Nonrigid Reconstruction. In Proceedings of the European Conference on Computer Vision (ECCV '16). 362--379.Google ScholarShahram Izadi, David Kim, Otmar Hilliges, David Molyneaux, Richard Newcombe, Pushmeet Kohli, Jamie Shotton, Steve Hodges, Dustin Freeman, Andrew Davison, and Andrew Fitzgibbon. 2011. KinectFusion: real-time 3D reconstruction and interaction using a moving depth camera. In Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '11). ACM, New York, NY, USA, 559--568.  Google ScholarBrett R. Jones, Hrvoje Benko, Eyal Ofek, and Andrew D. Wilson. 2013. IllumiRoom: Peripheral Projected Illusions for Interactive Experiences. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '13). ACM, New York, NY, USA, 869-- 878.  Google ScholarBrett R. Jones, Rajinder Sodhi, Michael Murdock, Ravish Mehra, Hrvoje Benko, Andrew D. Wilson, Eyal Ofek, Blair MacIntyre, Nikunj Raghuvanshi, and Lior Shapira. 2014. RoomAlive: magical experiences enabled by scalable, adaptive projector-camera units. In Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '14). ACM, New York, NY, USA, 637--644.  Google ScholarAndr\u00e9 Kunert, Alexander Kulik, Stephan Beck, and Bernd Froehlich. 2014. Photoportals: shared references in space and time. In Proceedings of the ACM conference on Computer supported cooperative work &amp; social computing (CSCW '14). ACM, New York, NY, USA, 1388--1399.  Google ScholarJoshua Lifton, and Joseph A. Paradiso. 2010. Dual Reality: Merging the Real and Virtual. In Facets of Virtual Environments (FaVE '09). Springer, Berlin, Heidelberg.Google ScholarYung-Ta Lin, Yi-Chi Liao, Shan-Yuan Teng, Yi-Ju Chung, Liwei Chan, and Bing-Yu Chen. 2017. OutsideIn: Visualizing Out-of-Sight Regions-of-Interest in a 360 Video Using Spatial Picture-in-Picture Previews. In Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '17). ACM, New York, NY, USA.  Google ScholarDavid Lindlbauer, J\u00f6rg M\u00fcller, and Marc Alexa. 2016. Changing the Appearance of Physical Interfaces Through Controlled Transparency. In Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '16). ACM, New York, NY, USA.  Google ScholarDavid Lindlbauer, J\u00f6rg M\u00fcller, and Marc Alexa. 2017. Changing the Appearance of Real-World Objects By Modifying Their Surroundings. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI '17). ACM, New York, NY, USA, 39543965.  Google ScholarSang-won Leigh and Pattie Maes. 2015. AfterMath: Visualizing Consequences of Actions through Augmented Reality. In Proceedings of the Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems (CHI EA '15). ACM, New York, NY, USA, 941--946.  Google ScholarSteve Mann. Mediated reality. Technical Report MITML Percom TR-260, University of Toronto, 1994.Google ScholarSteve Mann and James Fung. 2001. Videoorbits on eye tap devices for deliberately diminished reality or altering the visual perception of rigid planar patches of a real world scene. In Proceedings of the International Symposium on Mixed Reality (ISMR'01). 48--55.Google ScholarSteve Mann and James Fung. 2002. EyeTap devices for augmented, deliberately diminished, or otherwise altered visual perception of rigid planar patches of realworld scenes. In Presence: Teleoperators and Virtual Environments 11, 2 158--175.  Google ScholarMark McGill, Daniel Boland, Roderick Murray-Smith, and Stephen Brewster. 2015. A Dose of Reality: Overcoming Usability Challenges in VR Head-Mounted Displays. In Proceedings of the Annual ACM Conference on Human Factors in Computing Systems (CHI '15). ACM, New York, NY, USA, 2143--2152.  Google ScholarPaul Milgram and Fumio Kishino. A taxonomy of mixed reality visual displays. In IIEICE Transactions on Information Systems, Vol E77-D, No.12 December 1994.Google ScholarTakashi Miyaki and Jun Rekimoto. 2016. LiDARMAN: reprogramming reality with egocentric laser depth scanning. In ACM SIGGRAPH 2016 Emerging Technologies (SIGGRAPH '16). ACM, New York, NY, USA, Article 15.  Google ScholarMathias M\u00f6hring, Christian Lessig, and Oliver Bimber, Video see-through AR on consumer cell-phones. 2004 In Proceedings of the IEEE and ACM International Symposium on Mixed and Augmented Reality, (ISMAR '04). 252--253.  Google ScholarSimon Olberding, Michael Wessely, and J\u00fcrgen Steimle. 2014. PrintScreen: Fabricating Highly Customizable Thin-film Touch-displays. In Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '14). ACM, New York, NY, USA, 281-- 290.  Google ScholarSergio Orts-Escolano, Christoph Rhemann, Sean Fanello, Wayne Chang, Adarsh Kowdle, Yury Degtyarev, David Kim, Philip L. Davidson, Sameh Khamis, Mingsong Dou, Vladimir Tankovich, Charles Loop, Qin Cai, Philip A. Chou, Sarah Mennicken, Julien Valentin, Vivek Pradeep, Shenlong Wang, Sing Bing Kang, Pushmeet Kohli, Yuliya Lutchyn, Cem Keskin, and Shahram Izadi. 2016. Holoportation: Virtual 3D Teleportation in Real-time. In Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '16). ACM, New York, NY, USA, 741--754.  Google ScholarShigeru Owada, Frank Nielsen, and Takeo Igarashi. 2005. Volume catcher. In Proceedings of the Symposium on interactive 3D graphics and games (I3D '05). ACM, New York, NY, USA, 111--116.  Google ScholarIvan Poupyrev, Mark Billinghurst, Suzanne Weghorst, and Tadao Ichikawa. 1996. The go-go interaction technique: non-linear mapping for direct manipulation in VR. In Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '96). ACM, New York, NY, USA, 79--80.  Google ScholarRamesh Raskar, Greg Welch, Matt Cutts, Adam Lake, Lev Stesin, and Henry Fuchs. 1998. The Office of the Future: A Unified Approach to Image-based Modeling and Spatially Immersive Displays. In Proceedings of the Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH '98). ACM, New York, NY, USA, 179--188.  Google ScholarRamesh Raskar, Greg Welch, Kok-Lim Low, and Deepak Bandyopadhyay. 2001. Shader lamps: animating real objects with image-based illumination. In Proceedings of the Eurographics conference on Rendering (EGWR'01). Eurographics Association, Aire-la-Ville, Switzerland, Switzerland, 89--101.  Google ScholarMajken K. Rasmussen, Esben W. Pedersen, Marianne G. Petersen, and Kasper Hornb\u00e6k. 2012. Shape-changing Interfaces: A Review of the Design Space and Open Research Questions. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '12). ACM, New York, NY, USA, 735--744.  Google ScholarSharif Razzaque, Zachariah Kohn, and Mary C. Whitton. 2001. Redirected Walking. In Proceedings of Eurographics (EG '01), 289--294.Google ScholarJun Rekimoto and Katashi Nagao. 1995. The world through the computer: computer augmented interaction with real world environments. In Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '95). ACM, New York, NY, USA, 29--36.  Google ScholarJoan Sol Roo, Martin Hachet. Towards a Hybrid Space Combining Spatial Augmented Reality and Virtual Reality. In Proceedings of the 2017 IEEE Symposium on 3D User Interfaces (3DUI '17), Los Angeles, CA, USA, 195--198.Google ScholarJoan Sol Roo, Martin Hachet. One Reality: Augmenting How the Physical World is Experienced by combining Multiple Mixed Reality Modalities. In Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '17). ACM, New York, NY, USA.  Google ScholarClaus Scheiblauer, Michael Wimmer, Out-of-core selection and editing of huge point clouds. 2011. Computers &amp; Graphics, Volume 35, Issue 2, Pages 342--351, ISSN 0097--8493.  Google ScholarIan Stavness, Billy Lam, and Sidney Fels. 2010. pCubee: A Perspective-corrected Handheld Cubic Display. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '10). ACM, New York, NY, USA, 1381--1390.  Google ScholarVikas Singh, Deborah Silver and Nicu D. Cornea. 2003. Real-time volume manipulation. In Proceedings of the Eurographics/IEEE TVCG Workshop on Volume graphics (VG '03). ACM, New York, NY, USA, 45--51.  Google ScholarAdriana De Souza E Silva. 2009. Hybrid Reality and Location-Based Gaming: Redefining Mobility and Game Spaces in Urban Environments. Simul. Gaming 40, 3 (June 2009), 404--424.  Google ScholarMisha Sra, Sergio Garrido-Jurado, Chris Schmandt, and Pattie Maes. 2016. Procedurally generated virtual reality from 3D reconstructed physical space. In Proceedings of the ACM Conference on Virtual Reality Software and Technology (VRST '16). ACM, New York, NY, USA, 191--200.  Google ScholarRichard Stoakley, Matthew J. Conway, and Randy Pausch. 1995. Virtual reality on a WIM: interactive worlds in miniature. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '95). ACM, New York, NY, USA, 265--272.  Google ScholarJohn Underkoffler and Hiroshi Ishii. 1998. Illuminating Light: An Optical Design Tool with a Luminous-tangible Interface. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '98). ACM, New York, NY, USA, 542--549.  Google ScholarJohn Underkoffler and Hiroshi Ishii. 1999. Urp: A Luminous-tangible Workbench for Urban Planning and Design. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '99). ACM, New York, NY, USA, 386--393.  Google ScholarJulien Valentin, Vibhav Vineet, Ming-Ming Cheng, David Kim, Jamie Shotton, Pushmeet Kohli, Matthias Nie\u00dfner, Antonio Criminisi, Shahram Izadi, and Philip Torr. 2015. SemanticPaint: Interactive 3D Labeling and Learning at Your Fingertips. ACM Trans. Graph. 34, 5, Article 154.  Google ScholarJohn Viega, Matthew J. Conway, George Williams, and Randy Pausch. 1996. 3D magic lenses. In Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '96). ACM, New York, NY, USA, 51--58.  Google ScholarAndrew D. Wilson. 2017. Fast lossless depth image compression. In Proceedings of ACM Interactive Surfaces and Spaces (ISS '17). ACM, New York, NY, USA.  Google ScholarYa-Ting Yue, Yong-Liang Yang, Gang Ren, and Wenping Wang. 2017. SceneCtrl: Mixed Reality Enhancement via Efficient Scene Editing. In Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '17). ACM, New York, NY, USA.  Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3173574.3173703/0904d942-5483-4a00-9dc7-e8cbe6fc620a/pn1866-file3.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee06e0e0927f1e11a21c84c9567d2a912e1cb813c1b4a3c7fb59989bec3f3cdd22ddea1d60d870bad98114a75a366eaee0177b9c6b6df03c86d349b7997c7637939649d10c2b0a73ebapplication/x-mpegurlmp439.8 MB", "keywords": ["remixed reality", "augmented reality", "virtual reality"], "published_in": "CHI '18: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems", "publication_date": "19 April 2018", "citations": "14", "isbn": "9781450356206", "doi": "10.1145/3173574", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3173574.3173703", "paper_url": "https://dl.acm.org/doi/10.1145/3173574.3173703"}, {"title": "High-precision pointing on large wall displays using small handheld devices", "authors": ["Mathieu Nancel", "Olivier Chapuis", "Emmanuel Pietriga", "Xing-Dong Yang", "Pourang P. Irani", "Michel Beaudouin-Lafon"], "abstract": "Rich interaction with high-resolution wall displays is not limited to remotely pointing at targets. Other relevant types of interaction include virtual navigation, text entry, and direct manipulation of control widgets. However, most techniques for remotely acquiring targets with high precision have studied remote pointing in isolation, focusing on pointing efficiency and ignoring the need to support these other types of interaction. We investigate high-precision pointing techniques capable of acquiring targets as small as 4 millimeters on a 5.5 meters wide display while leaving up to 93 % of a typical tablet device's screen space available for task-specific widgets. We compare these techniques to state-of-the-art distant pointing techniques and show that two of our techniques, a purely relative one and one that uses head orientation, perform as well or better than the best pointing-only input techniques while using a fraction of the interaction resources.                     References                 Ashdown, M., Oka, K., and Sato, Y. Combining head tracking and mouse input for a GUI on multiple monitors. In Proc. CHI EA '05, ACM (2005), 1188--1191.  Google ScholarDigital LibraryBall, R., North, C., and Bowman, D. A. Move to improve: promoting physical navigation to increase user performance with large displays. In Proc. CHI '07, ACM (2007), 191--200.  Google ScholarDigital LibraryBaudisch, P., Cutrell, E., Robbins, D., Czerwinski, M., Tandler, P., Bederson, B., and Zierlinger, A. Drag-and-Pop and Drag-and-Pick: Techniques for Accessing Remote Screen Content on Touch and Pen-operated Systems. In Proc. INTERACT '03 (2003), 57--64.Google ScholarBaudisch, P., Sinclair, M., and Wilson, A. Soap: a pointing device that works in mid-air. In Proc. UIST '06, ACM (2006), 43--46.  Google ScholarDigital LibraryBeaudouin-Lafon, M., Chapuis, O., Eagan, J., Gjerlufsen, T., Huot, S., Klokmose, C., Mackay, W., Nancel, M., Pietriga, E., Pillias, C., Primet, R., and Wagner, J. Multi-surface interaction in the WILD room. IEEE Computer 45, 4 (2012), 48--56.  Google ScholarDigital LibraryBezerianos, A., and Balakrishnan, R. The Vacuum: facilitating the manipulation of distant objects. In Proc. CHI '05, ACM (2005), 361--370.  Google ScholarDigital LibraryBlanch, R., and Ortega, M. Rake cursor: improving pointing performance with concurrent input channels. In Proc. CHI '09, ACM (2009), 1415--1418.  Google ScholarDigital LibraryBoring, S., Baur, D., Butz, A., Gustafson, S., and Baudisch, P. Touch projector: mobile interaction through video. In Proc. CHI '10, ACM (2010), 2287--2296.  Google ScholarDigital LibraryCasiez, G., and Roussel, N. No more bricolage!: methods and tools to characterize, replicate and compare pointing transfer functions. In Proc. UIST '11, ACM (2011), 603--614.  Google ScholarDigital LibraryCasiez, G., Vogel, D., Balakrishnan, R., and Cockburn, A. The impact of control-display gain on user performance in pointing tasks. HCI 23, 3 (2008), 215--250.Google ScholarCross RefForlines, C., Vogel, D., and Balakrishnan, R. Hybridpointing: \\'02uid switching between absolute and relative pointing with a direct input device. In Proc. UIST '06, ACM (2006), 211--220.  Google ScholarDigital LibraryFreedman, E. G., and Sparks, D. L. Coordination of the eyes and head: movement kinematics. Exp. Brain Res. 131 (2000), 22--32.Google ScholarCross RefFrees, S., Kessler, G. D., and Kay, E. PRISM interaction for enhancing control in immersive virtual environments. ACM ToCHI 14, 1 (2007).  Google ScholarDigital LibraryGallo, L., Ciampi, M., and Minutolo, A. Smoothed pointing: A user-friendly technique for precision enhanced remote pointing. In Proc. CISIS '10, IEEE (2010), 712--717.  Google ScholarDigital LibraryGallo, L., and Minutolo, A. Design and comparative evaluation of smoothed pointing: A velocity-oriented remote pointing enhancement technique. IJHCS 70, 4 (2012), 287--300.  Google ScholarDigital LibraryJacob, R. The use of eye movements in human-computer interaction techniques: what you look at is what you get. ACM TOIS 9 (1991), 152--169.  Google ScholarDigital LibraryJota, R., Nacenta, M. A., Jorge, J. A., Carpendale, S., and Greenberg, S. A comparison of ray pointing techniques for very large displays. In Proc. GI '10, CIPS (2010), 269--276. Google ScholarDigital LibraryKirstein, C., and Muller, H. Interaction with a projection screen using a camera-tracked laser pointer. In Proc. MMM '98, IEEE (1998), 191--192. Google ScholarDigital LibraryKitajima, K., Sato, Y., and Koike, H. Vision-based face tracking system for window interface: prototype application and empirical studies. In Proc. CHI EA '01, ACM (2001), 359--360.  Google ScholarDigital LibraryKollerl, D. R., Mine, M. R., and Hudson, S. E. Head-tracked orbital viewing: an interaction technique for immersive virtual environments. In Proc. UIST '96, ACM (1996), 81--82.  Google ScholarDigital LibraryKonig, W. A., Gerken, J., Dierdorf, S., and Reiterer, H. Adaptive pointing design and evaluation of a precision enhancing technique for absolute pointing devices. In Proc. INTERACT '09, Springer (2009), 658--671.  Google ScholarDigital LibraryKopper, R., Bowman, D. A., Silva, M. G., and McMahan, R. P. A human motor behavior model for distal pointing tasks. IJHCS 68, 10 (2010), 603--615.  Google ScholarDigital LibraryMccallum, D. C., and Irani, P. Arc-pad: absolute+relative cursor positioning for large displays with a mobile touchscreen. In Proc. UIST '09, ACM (2009), 153--156.  Google ScholarDigital LibraryMorency, L.-P., and Darrell, T. Head gesture recognition in intelligent interfaces: the role of context in improving recognition. In Proc. IUI '06, ACM (2006), 32--38.  Google ScholarDigital LibraryMyers, B. A., Bhatnagar, R., Nichols, J., Peck, C. H., Kong, D., Miller, R. C., and Long, A. C. Interacting at a distance: measuring the performance of laser pointers and other devices. In Proc. CHI '02, ACM (2002), 33--40.  Google ScholarDigital LibraryNancel, M., Pietriga, E., and Beaudouin-Lafon, M. Precision pointing for ultra-high-resolution wall displays. Technical Report RR-7624, INRIA, 2011.Google ScholarNancel, M., Wagner, J., Pietriga, E., Chapuis, O., and Mackay, W. Mid-air pan-and-zoom on wall-sized displays. In Proc. CHI '11, ACM (2011), 177--186.  Google ScholarDigital LibraryNickel, K., and Stiefelhagen, R. Pointing gesture recognition based on 3d-tracking of face, hands and head orientation. In Proc. ICMI '03, ACM (2003), 140--146.  Google ScholarDigital LibraryPietriga, E., Huot, S., Nancel, M., and Primet, R. Rapid development of user interfaces on cluster-driven wall displays with jBricks. In Proc. EICS '11, ACM (2011), 185--190.  Google ScholarDigital LibraryPoupyrev, I., Tomokazu, N., and Weghorst, S. Virtual Notepad: Handwriting in Immersive VR. In Proc. VRAIS '98, IEEE (1998), 126--132. Google ScholarDigital LibraryRahman, M., Gustafson, S., Irani, P., and Subramanian, S. Tilt techniques: Investigating the dexterity of wrist-based input. In Proc. CHI '09, ACM (2009), 1943--1952.  Google ScholarDigital LibraryR\u00e4ih\u00e4, K.-J., and \u0160pakov, O. Disambiguating ninja cursors with eye gaze. In Proc. CHI '09, ACM (2009), 1411--1414.  Google ScholarDigital LibraryStahl, J. S. Amplitude of human head movements associated with horizontal saccades. Exp. Brain Res. 126 (1999), 41--54.Google ScholarCross RefVogel, D., and Balakrishnan, R. Distant freehand pointing and clicking on very large, high resolution displays. In Proc. UIST '05, ACM (2005), 33--42.  Google ScholarDigital LibraryWagner, J., Huot, S., and Mackay, W. Bitouch and bipad: Designing bimanual interaction for hand-held tablets. In Proc. CHI '12, ACM (2012).  Google ScholarDigital LibraryZhai, S., Morimoto, C., and Ihde, S. Manual and gaze input cascaded (MAGIC) pointing. In Proc. CHI '00, ACM (1999), 246--253.  Google ScholarDigital LibrarySupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/2470654.2470773/f9751d0b-e24b-4583-b08b-cba309c170e5/chi0117-file3.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ef03e0e3c375b9c607c82756ea17f5c40b6231d1630e2497047f76bffca312bcc0597e0780415ce7bb31f33b25e48772e6fd47ed8198c93c18f40f4d636859764f007d32ec1aadc0d7application/x-mpegurlmp436.9 MB", "keywords": ["wall displays", "handheld devices", "pointing"], "published_in": "CHI '13: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "27 April 2013", "citations": "46", "isbn": "9781450318990", "doi": "10.1145/2470654", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2470654.2470773", "paper_url": "https://dl.acm.org/doi/10.1145/2470654.2470773"}, {"title": "Outstanding: A Perspective-Switching Technique for Covering Large Distances in VR Games", "authors": ["Sebastian Cmentowski", "Andrey Krekhov", "Jens Krueger"], "abstract": "Room-scale virtual reality games allow players to experience an unmatched level of presence. A major reason is the natural navigation provided by physical walking. However, the tracking space is still limited, and viable alternatives or extensions are required to reach further virtual destinations. Our current work focuses on traveling over (very) large distances--an area where approaches such as teleportation are too exhausting and WIM teleportations potentially reduce presence. Our idea is to equip players with the ability to switch from first-person to a third-person god-mode perspective on demand. From above, players can command their avatar similar to a real-time strategy game and initiate travels over large distance. In our first exploratory evaluation, we learned that the proposed dynamic switching is intuitive, increases spatial orientation, and allows players to maintain a high degree of presence throughout the game. Based on the outcomes of a participatory design workshop, we also propose a set of extensions to our technique that should be considered in the future.", "keywords": ["world-in-miniature", "fast-travel", "presence", "navigation", "virtual reality games", "virtual avatar"], "published_in": "CHI EA '19: Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "1", "isbn": "9781450359719", "doi": "10.1145/3290607", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290607.3312783", "paper_url": "https://dl.acm.org/doi/10.1145/3290607.3312783"}, {"title": "SpaceTokens: Interactive Map Widgets for Location-centric Interactions", "authors": ["Daniel Miau", "Steven Feiner"], "abstract": "Map users often need to interact repetitively with multiple important locations. For example, a traveler may frequently check her hotel or a train station on a map, use them to localize an unknown location, or investigate routes involving them. Ironically, these location-centric tasks cannot be performed using locations directly; users must instead pan and zoom the map or use a menu to access locations. We propose SpaceTokens, interactive widgets that act as clones of locations, and which users can create and place on map edges like virtual whiteboard magnets. SpaceTokens make location a first-class citizen of map interaction. They empower users to rapidly perform location-centric tasks directly using locations: users can select combinations of on-screen locations and SpaceTokens to control the map window, or connect them to create routes. Participants in a study overwhelmingly preferred a SpaceTokens prototype over Google Maps on identical smartphones for the majority of tasks.                     References                 Eytan Adar, Jaime Teevan, and Susan T Dumais. 2008. Large scale analysis of web revisitation patterns. In Proceedings of the SIGCHI conference on Human Factors in Computing Systems. ACM, 1197--1206.  Google ScholarManeesh Agrawala and Chris Stolte. 2001. Rendering effective route maps: improving usability through generalization. In Proceedings of the 28th annual conference on Computer graphics and interactive techniques. ACM, 241--249.  Google ScholarJason Alexander, Andy Cockburn, Stephen Fitchett, Carl Gutwin, and Saul Greenberg. 2009. Revisiting read wear: analysis, design, and evaluation of a footprints scrollbar. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 1665--1674.  Google ScholarCaroline Appert and Jean-Daniel Fekete. 2006. OrthoZoom scroller: 1D multi-scale navigation. In Proceedings of the SIGCHI conference on Human Factors in computing systems. ACM, 21--30.  Google ScholarApple. 2017. Apple Maps location sharing. (2017). https://support.apple.com/en-us/HT201493Google ScholarAnthony J Aretz. 1991. The design of electronic map displays. Human Factors: The Journal of the Human Factors and Ergonomics Society 33, 1 (1991), 85--101.  Google ScholarPatrick Baudisch and Ruth Rosenholtz. 2003. Halo: a technique for visualizing off-screen objects. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, 481--488.  Google ScholarJohn Brosz, Miguel A Nacenta, Richard Pusch, Sheelagh Carpendale, and Christophe Hurter. 2013. Transmogrification: causal manipulation of visualizations. In Proceedings of the 26th annual ACM symposium on User interface software and technology. ACM, 97--106.  Google ScholarYang Cao, Hai Wang, Changhu Wang, Zhiwei Li, Liqing Zhang, and Lei Zhang. 2010. Mindfinder: interactive sketch-based image search on millions of images. In Proceedings of the 18th ACM international conference on Multimedia. ACM, 1605--1608.  Google ScholarM Sheelagh T Carpendale and Catherine Montagnese. 2001. A framework for unifying presentation space. In Proceedings of the 14th annual ACM symposium on User interface software and technology. ACM, 61--70.  Google ScholarTao Chen, Ming-Ming Cheng, Ping Tan, Ariel Shamir, and Shi-Min Hu. 2009. Sketch2photo: Internet image montage. ACM Transactions on Graphics (TOG) 28, 5 (2009), 124.  Google ScholarMei C Chuah, Steven F Roth, Joe Mattis, and John Kolojejchick. 1995. SDM: Selective dynamic manipulation of visualizations. In Proceedings of the 8th annual ACM symposium on User interface and software technology. ACM, 61--70.  Google ScholarAndy Cockburn and Bruce McKenzie. 2001. What do web users do? An empirical analysis of web use. International Journal of human-computer studies 54, 6 (2001), 903--922.  Google ScholarMathias Eitz, Ronald Richter, Kristian Hildebrand, Tamy Boubekeur, and Marc Alexa. 2011. Photosketcher: interactive sketch-based image synthesis. IEEE Computer Graphics and Applications 31, 6 (2011), 56--66.  Google ScholarNiklas Elmqvist, Nathalie Henry, Yann Riche, and Jean-Daniel Fekete. 2008. Melange: space folding for multi-focus interaction. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 1333--1342.  Google ScholarGeorge W Furnas and Benjamin B Bederson. 1995. Space-scale diagrams: Understanding multiscale interfaces. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM Press/Addison-Wesley Publishing Co., 234--241.  Google ScholarGoogle. 2017a. Google Maps iOS SDK. (2017). https://developers.google.com/mapsGoogle ScholarGoogle. 2017b. Google Maps mobile. (2017). https://www.google.com/maps/about/Google ScholarGoogle. 2017c. Google Maps Real-Time Location Sharing. (2017). https://blog.google/products/maps/ share-your-trips-and-real-time-location-google-maps/Google ScholarSean Gustafson, Patrick Baudisch, Carl Gutwin, and Pourang Irani. 2008. Wedge: clutter-free visualization of off-screen locations. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 787--796.  Google ScholarJeffrey Heer, Jock D Mackinlay, Chris Stolte, and Maneesh Agrawala. 2008. Graphical histories for visualization: Supporting analysis, communication, and evaluation. Visualization and Computer Graphics, IEEE Transactions on 14, 6 (2008), 1189--1196.  Google ScholarWilliam C Hill, James D Hollan, Dave Wroblewski, and Tim McCandless. 1992. Edit wear and read wear. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, 3--9.  Google ScholarChristian Holz and Steven Feiner. 2009. Relaxed selection techniques for querying time-series graphs. In Proceedings of the 22nd annual ACM symposium on User interface software and technology. ACM, 213--222.  Google ScholarZahid Hossain, Khalad Hasan, Hai-Ning Liang, and Pourang Irani. 2012. EdgeSplit: facilitating the selection of off-screen objects. In Proceedings of the 14th international conference on Human-computer interaction with mobile devices and services. ACM, 79--82.  Google ScholarTakeo Igarashi and Ken Hinckley. 2000. Speed-dependent automatic zooming for browsing large documents. In Proceedings of the 13th annual ACM symposium on User interface software and technology. ACM, 139--148.  Google ScholarAlexandra Ion, Y-L Betty Chang, Michael Haller, Mark Hancock, and Stacey D Scott. 2013. Canyon: providing location awareness of multiple moving objects in a detail view on large displays. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 3149--3158.  Google ScholarEdward W Ishak and Steven K Feiner. 2006. Content-aware scrolling. In Proceedings of the 19th annual ACM symposium on User interface software and technology. ACM, 155--158.  Google ScholarHiroshi Ishii and Brygg Ullmer. 1997. Tangible bits: towards seamless interfaces between people, bits and atoms. In Proceedings of the ACM SIGCHI Conference on Human factors in computing systems. ACM, 234--241.  Google ScholarCharles E Jacobs, Adam Finkelstein, and David H Salesin. 1995. Fast multiresolution image querying. In Proceedings of the 22nd annual conference on Computer graphics and interactive techniques. ACM, 277--286.  Google ScholarWaqas Javed, Sohaib Ghani, and Niklas Elmqvist. 2012. Polyzoom: multiscale and multifocus exploration in 2d visual spaces. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 287--296.  Google ScholarJuho Kim, Amy X Zhang, Jihee Kim, Robert C Miller, and Krzysztof Z Gajos. 2014. Content-aware kinetic scrolling for supporting web page navigation. In Proc. of UIST.  Google ScholarSari A Laakso, Karri Pekka Laakso, and Asko J Saura. 2000. Improved scroll bars. In CHI'00 Extended Abstracts on Human Factors in Computing Systems. ACM, 97--98.  Google ScholarYong Jae Lee, C Lawrence Zitnick, and Michael F Cohen. 2011. ShadowDraw: real-time user guidance for freehand drawing. In ACM Transactions on Graphics (TOG), Vol. 30. ACM, 27.  Google ScholarKevin Lynch. 1960. The image of the city. MIT press.Google ScholarDaniel Miau and Steven Feiner. 2016. Personalized Compass: A Compact Visualization for Direction and Location. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM, 5114--5125.  Google ScholarMicrosoft. 2017. Bing Maps. (2017). https://www.bing.com/maps/Google ScholarDan R. Olsen, Jr. 1992. The Interaction Technique Notebook: Bookmarks: An Enhanced Scroll Bar. ACM Trans. Graph. 11, 3 (July 1992), 291--295.  Google ScholarGian Pangaro, Dan Maynes-Aminzade, and Hiroshi Ishii. 2002. The actuated workbench: computer-controlled actuation in tabletop tangible interfaces. In Proceedings of the 15th annual ACM symposium on User interface software and technology. ACM, 181--190.  Google ScholarDaniel C Robbins, Edward Cutrell, Raman Sarin, and Eric Horvitz. 2004. ZoneZoom: map navigation for smartphones with recursive view segmentation. In Proceedings of the working conference on Advanced visual interfaces. ACM, 231--234.  Google ScholarManojit Sarkar and Marc H Brown. 1992. Graphical fisheye views of graphs. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, 83--91.  Google ScholarManojit Sarkar, Scott S Snibbe, Oren J Tversky, and Steven P Reiss. 1993. Stretching the rubber sheet: a metaphor for viewing large layouts on small screens. In Proceedings of the 6th annual ACM symposium on User interface software and technology. ACM, 81--91.  Google ScholarBrygg Ullmer and Hiroshi Ishii. 1997. The metaDESK: models and prototypes for tangible user interfaces. In Proceedings of the 10th annual ACM symposium on User interface software and technology. ACM, 223--232.  Google ScholarBrygg Ullmer, Hiroshi Ishii, and Dylan Glas. 1998. mediaBlocks: physical containers, transports, and controls for online media. In Proceedings of the 25th annual conference on Computer graphics and interactive techniques. ACM, 379--386.  Google ScholarDaniel Vogel and Patrick Baudisch. 2007. Shift: a technique for operating pen-based interfaces using touch. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, 657--666.  Google ScholarFangzhou Wang, Yang Li, Daisuke Sakamoto, and Takeo Igarashi. 2014. Hierarchical route maps for efficient navigation. In Proceedings of the 19th international conference on Intelligent User Interfaces. ACM, 169--178.  Google ScholarDirk Wenig, Johannes Sch\u00f6ning, Brent Hecht, and Rainer Malaka. 2015. StripeMaps: Improving Map-based Pedestrian Navigation for Smartwatches. In Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services. ACM, 52--62.  Google ScholarJian Zhao, Daniel Wigdor, and Ravin Balakrishnan. 2013. TrailMap: facilitating information seeking in a multi-scale digital map via implicit bookmarking. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 3009--3018.  Google ScholarHuiyuan Zhou, Aisha Edrah, Bonnie MacKay, and Derek Reilly. 2017. Block Party: Synchronized Planning and Navigation Views for Neighbourhood Expeditions. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 1702--1713.  Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3173574.3173822/7a154b69-cff4-4113-95f3-4bf2753d02a7/pn2537-file3.,180,300,750,964,1500,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee06e0e0927f1e11a21c84c9597f2b912944b912acd2762dfc02b0557b7e7525b9d2e230045b9e1b15e62cb8203388df0e0f7a6243809abe0ab4b32d3493cc1f9f48c3b9eceb2f0ecdapplication/x-mpegurlmp4100.3 MB", "keywords": ["navigation", "revisitation", "location-centric interaction", "maps", "bookmarks"], "published_in": "CHI '18: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems", "publication_date": "21 April 2018", "citations": "1", "isbn": "9781450356206", "doi": "10.1145/3173574", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3173574.3173822", "paper_url": "https://dl.acm.org/doi/10.1145/3173574.3173822"}, {"title": "SharedSpaces Mingle", "authors": ["Leif Handberg", "Charlie Gullstrom", "Joke Kort", "Jimmy Nystr\u00f6m"], "abstract": "SharedSpaces is a WebRTC design prototype that creates a virtual media space where people can mingle and interact. Although you are in different locations, you appear side by side in front of a chosen backdrop. This interactive installation addresses spatial and social connectedness, stressing the importance of integrating architectural and spatial features to support complex social dynamics in mediated interaction. The tool engages users in manipulating their real-time video- streams, creatively co-designing a shared mediated space that fits a contextual need. It supports social dynamics by allowing users to draw and paint together and to move and resize video streams. Further, it enhances grounding and social cues by merging video- streams and space, representing users as if they were in the same space. Standard and easily available equipment is used. Recent user studies show that a seamless integration of space, social dynamics and shared activity benefits the experience of presence, naturalness, immersion/engagement and social connectedness.", "keywords": ["webrtc", "spatial presence", "social", "mediated space", "naturalness", "media", "design", "spatial", "social connectedness", "architecture", "immersion", "audio/video communication"], "published_in": "CHI EA '16: Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "publication_date": "7 May 2016", "citations": "1", "isbn": "9781450340823", "doi": "10.1145/2851581", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2851581.2889469", "paper_url": "https://dl.acm.org/doi/10.1145/2851581.2889469"}, {"title": "Material Sketching: Towards the Digital Fabrication of Emergent Material Effects", "authors": ["Iremnur Tokac", "Herman Bruyninckx", "Corneel Cannaerts", "Andrew Vande Moere"], "abstract": "Designing for digital or robotic fabrication typically involves a virtual model in order to determine and coordinate the required operations of its construction. As a result, its creative design space becomes constrained to material expressions that can be predicted through digital modeling. This paper describes our preliminary thinking and first empirical results when this digital modeling phase is skipped, and the designing occurs interactively 'with' the fabrication operations themselves. By analyzing the material responses of corrugated cardboard to simple linear cutting operations that are executed by a robotic arm, we demonstrate how emergent material effects can be discovered improvisationally. Such material effects cannot be virtually modeled, however, they can be recreated and controlled by the robotic manipulations. We believe this form of 'material sketching' broadens the advances in 'human-fabrication interaction' towards a novel and unforeseeable expressions of physical form that require a much more direct, yet still digital, relationship with materiality.                     References                 Jeeeun Kim, Haruki Takahashi, Homei Miyashita, Michelle Annett, and Tom Yeh. 2017. Machines as Co-Designers: A Fiction on the Future of Human-Fabrication Machine Interaction. In Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems. ACM, 790--805.  Google ScholarAchim Menges, Bob Sheil, Ruairi Glynn, and Marilena Skavara. 2017. Fabricate: Rethinking Design and Construction. UCL Press.Google ScholarNeri Oxman. 2012. Towards a Material Ecology. In Proceedings of the Annual Conference of the Association for Computer Aided Design in Architecture (ACADIA). 19--20.Google ScholarHuaishu Peng, Jimmy Briggs, Cheng-Yao Wang, Kevin Guo, Joseph Kider, Stefanie Mueller, Patrick Baudisch, and Fran\u00e7ois Guimbreti\u00e8re. 2018. RoMA: Interactive Fabrication with Augmented Reality and a Robotic 3D Printer. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 579.  Google ScholarHuaishu Peng, Amit Zoran, and Fran\u00e7ois V Guimbreti\u00e8re. 2015. D-coil: A hands-on approach to digital 3D models design. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. ACM, 1807--1815.  Google ScholarShani Sharif and T. Russel Gentry. 2015. Design Cognition Shift From Craftsman to Digital Maker. Proceedings of CAADRIA 2015 (2015), 683--692.Google ScholarChristian Weichel, John Hardy, Jason Alexander, and Hans Gellersen. 2015. ReForm: Integrating Physical and Digital Design through Bidirectional Fabrication. In Proceedings of the User Interface Software and Technology Symposium (UIST'15). ACM, 93--102.  Google ScholarLBW1413pvc.zipPreview video captionsSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3290607.3313036/71b07ea0-e30d-4d49-ad27-9738ed5a27dd/lbw1413p.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee05eee35a4ac1e15fa135ba322e1a975181298eb18019f458c57f081be53fa2d91680ce5a6e89ae9944df86bbcbfc978c3236f141ed2b42ace3ea432be0116ea5c5d5f5cd73e976f6application/x-mpegurlmp43.1 MB", "keywords": ["craftsmanship", "robotic fabrication", "human-fabrication interaction", "material design", "digital fabrication"], "published_in": "CHI EA '19: Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2019", "citations": "0", "isbn": "9781450359719", "doi": "10.1145/3290607", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3290607.3313036", "paper_url": "https://dl.acm.org/doi/10.1145/3290607.3313036"}, {"title": "Virtual projection: exploring optical projection as a metaphor for multi-device interaction", "authors": ["Dominikus Baur", "Sebastian Boring", "Steven Feiner"], "abstract": "Handheld optical projectors provide a simple way to overcome the limited screen real-estate on mobile devices. We present virtual projection (VP), an interaction metaphor inspired by how we intuitively control the position, size, and orientation of a handheld optical projector's image. VP is based on tracking a handheld device without an optical projector and allows selecting a target display on which to position, scale, and orient an item in a single gesture. By relaxing the optical projection metaphor, we can deviate from modeling perspective projection, for example, to constrain scale or orientation, create multiple copies, or offset the image. VP also supports dynamic filtering based on the projection frustum, creating overview and detail applications, and selecting portions of a larger display for zooming and panning. We show exemplary use cases implemented using our optical feature-tracking framework and present the results of a user study demonstrating the effectiveness of VP in complex interactions with large displays.", "keywords": ["interaction technique", "handheld projection", "mobile device"], "published_in": "CHI '12: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "5 May 2012", "citations": "37", "isbn": "9781450310154", "doi": "10.1145/2207676", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2207676.2208297", "paper_url": "https://dl.acm.org/doi/10.1145/2207676.2208297"}, {"title": "Don't just stare at me!", "authors": ["Ning Wang", "Jonathan Gratch"], "abstract": "Communication is more effective and persuasive when participants establish rapport. Tickle-Degnen and Rosenthal [57] argue rapport arises when participants exhibit mutual attentiveness, positivity and coordination. In this paper, we investigate how these factors relate to perceptions of rapport when users interact via avatars in virtual worlds. In this study, participants told a story to what they believed was the avatar of another participant. In fact, the avatar was a computer program that systematically manipulated levels of attentiveness, positivity and coordination. In contrast to Tickel-Degnen and Rosenthal's findings, high-levels of mutual attentiveness alone can dramatically lower perceptions of rapport in avatar communication. Indeed, an agent that attempted to maximize mutual attention performed as poorly as an agent that was designed to convey boredom. Adding positivity and coordination to mutual attentiveness, on the other hand, greatly improved rapport. This work unveils the dependencies between components of rapport and informs the design of agents and avatars in computer mediated communication.", "keywords": ["virtual agent", "gaze", "rapport"], "published_in": "CHI '10: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "10 April 2010", "citations": "30", "isbn": "9781605589299", "doi": "10.1145/1753326", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1753326.1753513", "paper_url": "https://dl.acm.org/doi/10.1145/1753326.1753513"}, {"title": "WireFab: Mix-Dimensional Modeling and Fabrication for 3D Mesh Models", "authors": ["Min Liu", "Yunbo Zhang", "Jing Bai", "Yuanzhi Cao", "Jeffrey M. Alperovich", "Karthik Ramani"], "abstract": "Many rapid fabrication technologies are directed towards layer wise printing or laser based prototyping. We propose WireFab, a rapid modeling and prototyping system that uses bent metal wires as the structure framework. WireFab approximates both the skeletal articulation and the skin appearance of the corresponding virtual skin meshes, and it allows users to personalize the designs by (1) specifying joint positions and part segmentations, (2) defining joint types and motion ranges to build a wire-based skeletal model, and (3) abstracting the segmented meshes into mixed-dimensional appearance patterns or attachments.The WireFab is designed to allow the user to choose how to best preserve the fidelity of the topological structure and articulation motion while selectively maintaining the fidelity of the geometric appearance. Compared to 3D-printing based high-fidelity fabrication systems, WireFab increases prototyping speed by ignoring unnecessary geometric details while preserving structural integrity and articulation motion. In addition, other rapid or low-fidelity fabrication systems produce only static models, while WireFab produces posable articulated models and has the potential to enable personalized functional products larger than the machines that produce them.                     References                 Eric Almquist, John Senior, and Nicolas Bloch. 2016. The Elements of Value. Harvard Business Review (2016), 47--52.Google ScholarOscar Kin-Chung Au, Chiew-Lan Tai, Hung-Kuo Chu, Daniel Cohen-Or, and Tong-Yee Lee. 2008. Skeleton extraction by mesh contraction. In ACM Trans. Graph., Vol. 27. 44.  Google ScholarMoritz B\u00e4cher, Bernd Bickel, Doug L. James, and Hanspeter Pfister. 2012. Fabricating Articulated Characters from Skinned Meshes. ACM Trans. Graph. 31,  Google Scholar(July 2012), 47:1--47:9. 4. Moritz B\u00e4cher, Emily Whiting, Bernd Bickel, and Olga Sorkine-Hornung. 2014. Spin-it: Optimizing moment of inertia for spinnable objects. ACM Transactions on Graphics (TOG) 33, 4 (2014), 96:1--96:10.Google ScholarDustin Beyer, Serafima Gurevich, Stefanie Mueller, Hsiang-Ting Chen, and Patrick Baudisch. 2015. Platener: Low-Fidelity Fabrication of 3D Objects by Substituting 3D Print with Laser-Cut Plates. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '15). ACM Press, 1799--1806.  Google ScholarJohn Brooke. 1996. SUS: A quick and dirty usability scale. (1996).Google ScholarJacques Cal\u00ec, Dan A. Calian, Cristina Amati, Rebecca Kleinberger, Anthony Steed, Jan Kautz, and Tim Weyrich. 2012. 3D-printing of Non-assembly, Articulated Models. ACM Trans. Graph. 31, 6 (Nov. 2012), 130:1--130:8.Google ScholarJen-Hi Chuang, Chi-Hao Tsai, and Min-Chi Ko. 2000. Skeletonization of Three-Dimensional Object Using Generalized Potential Field. IEEE Trans. Pattern Anal. Mach. Intell. 22, 11 (Nov. 2000), 1241--1251.  Google ScholarStelian Coros, Bernhard Thomaszewski, Gioacchino Noris, Shinjiro Sueda, Moira Forberg, Robert W. Sumner, Wojciech Matusik, and Bernd Bickel. 2013. Computational Design of Mechanical Characters. ACM Trans. Graph. 32, 4 (2013), 83:1--83:12.Google ScholarTamal K. Dey and Jian Sun. 2006. Defining and Computing Curve-skeletons with Medial Geodesic Function. In Proceedings of the Fourth Eurographics Symposium on Geometry Processing (SGP '06). 143--152.Google ScholarWei Gao, Yunbo Zhang, Diogo C. Nazzetta, Karthik Ramani, and Raymond J. Cipra. 2015. RevoMaker: Enabling Multi-directional and Functionally-embedded 3D Printing Using a Rotational Cuboidal Platform. In Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology (UIST '15). 437--446.  Google ScholarVictoria Groom, Leila Takayama, Paloma Ochi, and Clifford Nass. 2009. I am my robot: the impact of robot-building and robot form on operators. In Proceedings of the 4th ACM/IEEE international conference on Human robot interaction. ACM, 31--36.Google ScholarImre Horv\u00e1th. 2004. On some crucial issues of computer support of conceptual design. In Product Engineering. Springer, 123--142.Google ScholarEmmanuel Iarussi, Wilmot Li, and Adrien Bousseau. 2015. WrapIt: Computer-assisted Crafting of Wire Wrapped Jewelry. ACM Trans. Graph. 34, 6 (2015), 221:1--221:8.Google ScholarAlec Jacobson, Daniele Panozzo, Oliver Glauser, C\u00e9dric Pradalier, Otmar Hilliges, and Olga Sorkine-Hornung. 2014. Tangible and Modular Input Device for Character Articulation. ACM Trans. Graph. 33, 4 (2014), 82:1--82:12.Google ScholarBongjin Koo, Wilmot Li, JiaXian Yao, Maneesh Agrawala, and Niloy J Mitra. 2014. Creating works-like prototypes of mechanical objects. ACM Trans. Graph. 33, 6 (2014), 217:1--217:9.Google ScholarYuki Koyama, Shinjiro Sueda, Emma Steinhardt, Takeo Igarashi, Ariel Shamir, and Wojciech Matusik. 2015. AutoConnect: Computational Design of 3D-printable Connectors. ACM Trans. Graph. 34, 6 (2015), 231:1--231:11.Google ScholarPensa Labs. 2016. DiWire-Pensa Labs. (2016). http://www.pensalabs.com/diwire-overview/.Google ScholarManfred Lau, Akira Ohgawara, Jun Mitani, and Takeo Igarashi. 2011. Converting 3D Furniture Models to Fabricatable Parts and Connectors. ACM Trans. Graph. 30, 4 (July 2011), 85:1--85:6.Google ScholarXian-Ying Li, Chao-Hui Shen, Shi-Sheng Huang, Tao Ju, and Shi-Min Hu. 2010. Popup: Automatic Paper Architectures from 3D Models. In ACM SIGGRAPH 2010 Papers (SIGGRAPH '10). 111:1--111:9.Google ScholarPeter Liepa. 2003. Filling Holes in Meshes. In Proceedings of the 2003 Eurographics (SGP '03). 200--205.Google ScholarKui-Yip Lo, Chi-Wing Fu, and Hongwei Li. 2009. 3D Polyomino Puzzle. ACM Trans. Graph. 28, 5 (Dec. 2009), 157:1--157:8.Google ScholarJames McCrae, Nobuyuki Umetani, and Karan Singh. 2014. FlatFitFab: Interactive Modeling with Planar Sections. In Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology (UIST '14). 13--22.  Google ScholarVittorio Megaro, Bernhard Thomaszewski, Damien Gauge, Eitan Grinspun, Stelian Coros, and Markus Gross. 2014. ChaCra: An Interactive Design System for Rapid Character Crafting. In ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA'14). 123--130.Google ScholarStefanie Mueller, Sangha Im, Serafima Gurevich, Alexander Teibrich, Lisa Pfisterer, Fran\u00e7ois Guimbreti\u00e8re, and Patrick Baudisch. 2014a. WirePrint: 3D Printed Previews for Fast Prototyping. In Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology (UIST '14). 273--280.  Google ScholarStefanie Mueller, Tobias Mohr, Kerstin Guenther, Johannes Frohnhofen, Kai-Adrian Rollmann, and Patrick Baudisch. 2014b. faBrickation: Fast 3D Printing of Functional Objects by Integrating Construction Kit Building Blocks. In CHI '14 Extended Abstracts on Human Factors in Computing Systems (CHI EA '14). 527--530.Google ScholarValerio Pascucci, Giorgio Scorzelli, Peer-Timo Bremer, and Ajith Mascarenhas. 2007. Robust On-line Computation of Reeb Graphs: Simplicity and Speed. ACM Trans. Graph. 26, 3 (2007).  Google ScholarRomain Pr\u00e9vost, Emily Whiting, Sylvain Lefebvre, and Olga Sorkine-Hornung. 2013. Make It Stand: Balancing Shapes for 3D Fabrication. ACM Trans. Graph. 32, 4 (July 2013), 81:1--81:10.Google ScholarValkyrie Savage, Ryan Schmidt, Tovi Grossman, George Fitzmaurice, and Bj\u00f6rn Hartmann. 2014. A Series of Tubes: Adding Interactivity to 3D Prints Using Internal Pipes. In Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology (UIST '14). 3--12.  Google ScholarAndrei Sharf, Thomas Lewiner, Ariel Shamir, and Leif Kobbelt. 2007. On-the-fly curve-skeleton computation for 3D shapes. ACM Trans. Graph. 26, 3 (2007), 323--328. Google ScholarAndr\u00e9 Sobiecki, Andrei Jalba, and Alexandru Telea. 2014. Comparison of curve and surface skeletonization methods for voxel shapes. Pattern Recognition Letters 47 (2014), 147--156.  Google ScholarPeng Song, Bailin Deng, Ziqi Wang, Zhichao Dong, Wei Li, Chi-Wing Fu, and Ligang Liu. 2016. CofiFab: Coarse-to-Fine Fabrication of Large 3D Objects. ACM Trans. Graph. 35, 4 (2016).  Google ScholarBernhard Thomaszewski, Stelian Coros, Damien Gauge, Vittorio Megaro, Eitan Grinspun, and Markus Gross. 2014. Computational Design of Linkage-based Characters. ACM Trans. Graph. 33, 4 (2014), 64:1--64:9.Google ScholarNobuyuki Umetani, Yuki Koyama, Ryan Schmidt, and Takeo Igarashi. 2014. Pteromys: Interactive Design and Optimization of Free-formed Free-flight Model Airplanes. ACM Trans. Graph. 33, 4 (July 2014), 65:1--65:10.Google ScholarFrancisca Gil Ureta, Chelsea Tymms, and Denis Zorin. 2016. Interactive Modeling of Mechanical Objects. Computer Graphics Forum (2016).Google ScholarCharlie CL Wang. 2004. CyberTape: an interactive measurement tool on polyhedral surface. Computers &amp; Graphics 28, 5 (2004), 731--745. Google ScholarShiqing Xin, Chi-Fu Lai, Chi-Wing Fu, Tien-Tsin Wong, Ying He, and Daniel Cohen-Or. 2011. Making Burr Puzzles from 3D Models. In ACM SIGGRAPH 2011 Papers (SIGGRAPH '11). 97:1--97:8.Google ScholarYunbo Zhang, Wei Gao, Luis Paredes, and Karthik Ramani. 2016. CardBoardiZer: creatively customize, articulate and fold 3D Mesh Models. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '16). 897--907.  Google ScholarYouyi Zheng, Chiew-Lan Tai, and Oscar Kin-Chung Au. 2012. Dot scissor: a single-click interface for mesh segmentation. Visualization and Computer Graphics, IEEE Transactions on 18, 8 (2012), 1304--1312.Google ScholarLifeng Zhu, Weiwei Xu, John Snyder, Yang Liu, Guoping Wang, and Baining Guo. 2012. Motion-guided Mechanical Toy Modeling. ACM Trans. Graph. 31, 6 (Nov. 2012), 127:1--127:10.Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3025453.3025619/d398a9e7-2c58-46ec-b75d-4e9a46b50d6c/pn1799p.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee07e5e64ad2301e1e02b6a6c28f1642b29a91635d79a4036d4b2591803e0f31293ddeb540a0c4d664cf484c9d92e72e737814e6b05fd0069a2b6da9c08147a5445bddc88c9877df12application/x-mpegurlmp43.2 MB", "keywords": ["skeletal deformation", "physical prototyping", "interactive curve modeling", "shape abstraction", "mix-dimensional fabrication"], "published_in": "CHI '17: Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2017", "citations": "4", "isbn": "9781450346559", "doi": "10.1145/3025453", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3025453.3025619", "paper_url": "https://dl.acm.org/doi/10.1145/3025453.3025619"}, {"title": "Effects of display size and navigation type on a classification task", "authors": ["Can Liu", "Olivier Chapuis", "Michel Beaudouin-Lafon", "Eric Lecolinet", "Wendy E. Mackay"], "abstract": "The advent of ultra-high resolution wall-size displays and their use for complex tasks require a more systematic analysis and deeper understanding of their advantages and drawbacks compared with desktop monitors. While previous work has mostly addressed search, visualization and sense-making tasks, we have designed an abstract classification task that involves explicit data manipulation. Based on our observations of real uses of a wall display, this task represents a large category of applications. We report on a controlled experiment that uses this task to compare physical navigation in front of a wall-size display with virtual navigation using pan-and-zoom on the desktop. Our main finding is a robust interaction effect between display type and task difficulty: while the desktop can be faster than the wall for simple tasks, the wall gains a sizable advantage as the task becomes more difficult. A follow-up study shows that other desktop techniques (overview+detail, lens) do not perform better than pan-and-zoom and are therefore slower than the wall for difficult tasks.                     References                 Andrews C., Endert A. &amp; North C. Space to think: large high-resolution displays for sensemaking. CHI'10, ACM (2010).  Google ScholarBakeman R. Recommended effect size statistics for repeated measures designs. Behav. Res. Meth. 37, 3 (2005).Google ScholarBall R. &amp; North C. The effects of peripheral vision and physical navigation on large scale visualization. GI '08, CIPS (2008). Google ScholarBall R., North C. &amp; Bowman D. A. Move to improve: promoting physical navigation to increase user performance with large displays. CHI '07, ACM (2007).  Google ScholarBeaudouin-Lafon M. et al. Multi-surface interaction in the WILD room. Computer 45, 4 (2012).  Google ScholarBezerianos A. &amp; Isenberg P. Perception of visual variables on tiled wall-sized displays for information visualization applications. IEEE TVCG 18, 12 (2012).Google ScholarBi X. &amp; Balakrishnan R. Comparing usage of a large high-resolution display to single or dual desktop displays for daily work. CHI'09, ACM (2009).  Google ScholarBritish Standards Institution. Test charts for clinical determination of distance visual acuity, 2003. London.Google ScholarCockburn A., Karlson A. &amp; Bederson B. B. A review of overview+detail, zooming, and focus+context interfaces. ACM CSUR 41, 1 (2009).  Google ScholarCzerwinski M., Smith G., Regan T., Meyers B., Robertson G. &amp; Starkweather G. Toward characterizing the productivity bene'ts of very large displays. INTERACT'03, IOS (2003).Google ScholarCzerwinski M., Tan D. S. &amp; Robertson G. G. Women take a wider view. CHI'02, ACM (2002).  Google ScholarEndert A., Andrews C., Lee Y. H. &amp; North C. Visual encodings that support physical navigation on large displays. GI'11, CHCCS (2011). Google ScholarGuiard Y., Beaudouin-Lafon M., Bastin J., Pasveer D. &amp; Zhai S. View size and pointing difficulty in multi-scale navigation. AVI'04, ACM (2004).  Google ScholarHornb\u00e6k K., Bederson B. B. &amp; Plaisant C. Navigation patterns and usability of zoomable user interfaces with and without an overview. ACM ToCHI 9, 4 (2002).  Google ScholarJakobsen R. M. &amp; Hornb\u00e6k K. Sizing up visualizations: effects of display size in focus+context, overview+detail, and zooming interfaces. CHI'11, ACM (2011).Google ScholarKim J., Zhang H., Andr\u00e9 P., Chilton L. B., Mackay W., Beaudouin-Lafon M., Miller R. C. &amp; Dow S. P. Cobi: A community-informed conference scheduling tool. UIST'13, ACM (2013).  Google ScholarNancel M., Chapuis O., Pietriga E., Yang X.-D., Irani P. &amp; Beaudouin-Lafon M. High-precision pointing on large wall displays using small handheld devices. CHI'13, ACM (2013).  Google ScholarNancel M., Wagner J., Pietriga E., Chapuis O. &amp; Mackay W. Mid-air pan-and-zoom on wall-sized displays. CHI'11, ACM (2011).  Google ScholarNekrasovski D., Bodnar A., McGrenere J., Guimbreti'ere F. &amp; Munzner T. An evaluation of pan &amp; zoom and rubber sheet navigation with and without an overview. CHI'06, ACM (2006).  Google ScholarNi T., Bowman D. &amp; Chen J. Increased display size and resolution improve task performance in information-rich virtual environments. GI'06, CIPS (2006). Google ScholarPietriga E., Appert C. &amp; Beaudouin-Lafon M. Pointing and beyond: an operationalization and preliminary evaluation of multi-scale searching. CHI'07, ACM (2007).  Google ScholarPietriga E., Huot S., Nancel M. &amp; Primet R. Rapid development of user interfaces on cluster-driven wall displays with jbricks. EICS'11, ACM (2011).  Google ScholarPindat C., Pietriga E., Chapuis O. &amp; Puech C. Jellylens: Content-aware adaptive lenses. UIST'12, ACM (2012).  Google ScholarRooney C., Endert A., Fekete J.-D., Hornb\u00e6k K. &amp; North C. Powerwall: int. workshop on interactive, ultra-high-resolution displays. CHI EA'13 (2013).  Google ScholarSarkar M. &amp; Brown M. H. Graphical fisheye views of graphs. CHI'92, ACM (1992).  Google ScholarTan D. S., Gergle D., Scupelli P. &amp; Pausch R. Physically large displays improve performance on spatial tasks. ACM ToCHI 13, 1 (2006).  Google ScholarYost B., Haciahmetoglu Y. &amp; North C. Beyond visual acuity: the perceptual scalability of information visualizations for large displays. CHI'07, ACM (2007).  Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/2556288.2557020/d462604f-f368-45dd-92ab-65e2f7daf1b5/pn0389-file3.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ef02e2e52e2faf54fffd7dafb0c78e709faa828da4e7494de296e900633ce4b56ef964dd90a4bbe1362b4d7801da2da75b09d3c08e8af6e06b29d2f5e4fe7e6ac100fabf21c916812capplication/x-mpegurlmp448.2 MB", "keywords": ["classification task", "lenses", "pan-and-zoom", "overview+detail", "physical navigation", "wall-size display"], "published_in": "CHI '14: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "26 April 2014", "citations": "43", "isbn": "9781450324731", "doi": "10.1145/2556288", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2556288.2557020", "paper_url": "https://dl.acm.org/doi/10.1145/2556288.2557020"}, {"title": "Tap, Dwell or Gesture?: Exploring Head-Based Text Entry Techniques for HMDs", "authors": ["Chun Yu", "Yizheng Gu", "Zhican Yang", "Xin Yi", "Hengliang Luo", "Yuanchun Shi"], "abstract": "Despite the increasing popularity of head mounted displays (HMDs), development of efficient text entry methods on these devices has remained under explored. In this paper, we investigate the feasibility of head-based text entry for HMDs, by which, the user controls a pointer on a virtual keyboard using head rotation. Specifically, we investigate three techniques: TapType, DwellType, and GestureType. Users of TapType select a letter by pointing to it and tapping a button. Users of DwellType select a letter by pointing to it and dwelling over it for a period of time. Users of GestureType perform word-level input using a gesture typing style. Two lab studies were conducted. In the first study, users typed 10.59 WPM, 15.58 WPM, and 19.04 WPM with DwellType, TapType, and GestureType, respectively. Users subjectively felt that all three of the techniques were easy to learn and considered the induced fatigue to be acceptable. In the second study, we further investigated GestureType. We improved its gesture-word recognition algorithm by incorporating the head movement pattern obtained from the first study. This resulted in users reaching 24.73 WPM after 60 minutes of training. Based on these results, we argue that head-based text entry is feasible and practical on HMDs, and deserves more attention.                     References                 2011. The Open American National Corpus. http://www.anc.org/Google ScholarOuais Alsharif, Tom Ouyang, Franc\u00e7oise Beaufays, Shumin Zhai, Thomas Breuel, Johan Schalkwyk. Long short term memory neural network for keyboard gesture decoding. In 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2015. 2076--2080Google ScholarChristoph Amma, Marcus Georgi, and Tanja Schultz. 2012. Hands-Free Mobile Text Input by Spotting and Continuous Recognition of 3d-Space Handwriting with Inertial Sensors. In 2012 16th International Symposium on Wearable Computers (ISWC'12), 52--59.  Google ScholarXiaojun Bi, Ciprian Chelba, Tom Ouyang, Kurt Partridge, and Shumin Zhai. 2012. Bimanual gesture keyboard. In Proceedings of the 25th annual ACM symposium on User interface software and technology (UIST '12). 137--146.  Google ScholarDoug A. Bowman, Vinh Q. Ly, and Joshua M. Campbell. 2001. Pinch keyboard: Natural text input for immersive virtual environments.Google ScholarXiang 'Anthony' Chen, Tovi Grossman, and George Fitzmaurice. 2014. Swipeboard: a text entry technique for ultra-small interfaces that supports novice to expert transitions. In Proceedings of the 27th annual ACM symposium on User interface software and technology (UIST '14). 615--620.  Google ScholarWeiya Chen, Anthony Plancoulaine, Nicolas F\u00e9rey, Damien Touraine, Julien Nelson, and Patrick Bourdot. 2013. 6DoF navigation in virtual worlds: comparison of joystick-based and head-controlled paradigms. In Proceedings of the 19th ACM Symposium on Virtual Reality Software and Technology(VRST '13). 111--114.  Google ScholarWenxin Feng, Ming Chen, and Margrit Betke. 2014. Target reverse crossing: a selection method for camerabased mouse-replacement systems. In Proceedings of the 7th International Conference on PErvasive Technologies Related to Assistive Environments (PETRA '14). Article 39, 4 pages.  Google ScholarYulia Gizatdinova, Oleg \u0160pakov, and Veikko Surakka. 2012. Comparison of video-based pointing and selection techniques for hands-free text entry. In Proceedings of the International Working Conference on Advanced Visual Interfaces (AVI '12), Genny Tortora, Stefano Levialdi, and Maurizio Tucci (Eds.). 132--139.  Google ScholarJoshua Goodman, Gina Venolia, Keith Steury, and Chauncey Parker. 2002. Language modeling for soft keyboards. In Proceedings of the 7th international conference on Intelligent user interfaces (IUI '02). 194195.  Google ScholarMitchell Gordon, Tom Ouyang, and Shumin Zhai. 2016. WatchWriter: Tap and Gesture Typing on a Smartwatch Miniature Keyboard with Statistical Decoding. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI '16). 3817--3821.  Google ScholarTovi Grossman, Xiang Anthony Chen, and George Fitzmaurice. 2015. Typing on Glasses: Adapting Text Entry to Smart Eyewear. In Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI '15). 144--152.  Google ScholarJohn Paulin Hansen, Kristian T\u00f8rning, Anders Sewerin Johansen, Kenji Itoh, and Hirotaka Aoki. 2004. Gaze typing compared with input by head and hand. In Proceedings of the 2004 symposium on Eye tracking research &amp; applications (ETRA '04). 131--138.  Google ScholarPer Ola Kristensson and Keith Vertanen. 2012. The potential of dwell-free eye-typing for fast assistive gaze communication. In Proceedings of the Symposium on Eye Tracking Research and Applications (ETRA '12), Stephen N. Spencer (Ed.). 241--244.  Google ScholarPer Ola Kristensson and Shumin Zhai. 2004. SHARK2 : a large vocabulary shorthand writing system for penbased computers. In Proceedings of the 17th annual ACM symposium on User interface software and technology (UIST '04). 43--52.  Google ScholarAndrew Kurauchi, Wenxin Feng, Ajjen Joshi, Carlos Morimoto, and Margrit Betke. 2016. EyeSwipe: Dwellfree Text Entry Using Gaze Paths. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI '16). 1952--1956.  Google ScholarI. Scott MacKenzie and R. William Soukoreff. 2002. A character-level error analysis technique for evaluating text entry methods. In Proceedings of the second Nordic conference on Human-computer interaction (NordiCHI '02). 243--246.  Google ScholarI. Scott MacKenzie and R. William Soukoreff. 2003. Phrase sets for evaluating text entry techniques. In CHI '03 Extended Abstracts on Human Factors in Computing Systems (CHI EA '03). 754--755.  Google ScholarDigital LibraryP\u00e4ivi Majaranta and Kari-Jouko R\u00e4ih\u00e4. 2007. Text entry by gaze: Utilizing eye-tracking. Text entry systems: Mobility, accessibility, universality: 175--187.Google ScholarP\u00e4ivi Majaranta, Ulla-Kaija Ahola, and Oleg \u0160pakov. 2009. Fast gaze typing with an adjustable dwell time. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '09). 357--360.  Google ScholarAnders Markussen, Mikkel R. Jakobsen, and Kasper Hornb\u00e6k. 2013. Selection-based mid-air text entry on large displays. In IFIP Conference on HumanComputer Interaction. 401--418.Google ScholarAnders Markussen, Mikkel R\u00f8nne Jakobsen, and Kasper Hornb\u00e6k. 2014. Vulture: a mid-air wordgesture keyboard. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '14). 1073--1082.  Google ScholarRoderick McCall, Beno\u00eet Martin, Andrei Popleteev, Nicolas Louveton and Thomas Engel. 2015. Text entry on smart glasses. In 2015 8th International Conference on Human System Interaction (HSI). 195--200.Google ScholarTao Ni, Doug Bowman, and Chris North. 2011. AirStroke: bringing unistroke text entry to freehand gesture interfaces. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11). 2473--2476.  Google ScholarPaul Nation and Robert Waring. 1997. Vocabulary size, text coverage and word lists. Vocabulary: Description, acquisition and pedagogy Rev 14: 6--19.Google ScholarDiogo Pedrosa, Maria Da Gra\u00e7a Pimentel, Amy Wright, and Khai N. Truong. 2015. Filteryedping: Design Challenges and User Performance of DwellFree Eye Typing. ACM Trans. Access. Comput. 6, 1, Article 3 (March 2015), 37 pages.  Google ScholarShyam Reyal, Shumin Zhai, and Per Ola Kristensson. 2015. Performance and User Experience of Touchscreen and Gesture Keyboards in a Lab Setting and in the Wild. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). 679--688.  Google ScholarSayan Sarcar, Prateek Panwar, and Tuhin Chakraborty. 2013. EyeK: an efficient dwell-free eye gaze-based text entry system. In Proceedings of the 11th Asia Pacific Conference on Computer Human Interaction (APCHI '13). 215--220.  Google ScholarAlexander Schick, Daniel Morlock, Christoph Amma, Tanja Schultz, and Rainer Stiefelhagen. 2012. Visionbased handwriting recognition for unrestricted text input in mid-air. In Proceedings of the 14th ACM international conference on Multimodal interaction (ICMI '12). 217--220.  Google ScholarSrinath Sridhar, Anna Maria Feit, Christian Theobalt, and Antti Oulasvirta. 2015. Investigating the Dexterity of Multi-Finger Input for Mid-Air Text Entry. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). 3643--3652.  Google ScholarKeith Vertanen, Haythem Memmi, Justin Emge, Shyam Reyal, and Per Ola Kristensson. 2015. VelociTap: Investigating Fast Mobile Text Entry using Sentence-Based Decoding of Touchscreen Keyboard Input. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). 659--668.  Google ScholarDaniel Vogel and Patrick Baudisch. 2007. Shift: a technique for operating pen-based interfaces using touch. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '07). 657666.  Google ScholarXin Yi, Chun Yu, Mingrui Zhang, Sida Gao, Ke Sun, and Yuanchun Shi. 2015. ATK: Enabling Ten-Finger Freehand Typing in Air Based on 3D Hand Tracking Data. In Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology (UIST '15). 539--548.  Google ScholarChun Yu, Ke Sun, Mingyuan Zhong, Xincheng Li, Peijun Zhao, and Yuanchun Shi. 2016. OneDimensional Handwriting: Inputting Letters and Words on Smart Glasses. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI '16). 71--82.  Google ScholarShumin Zhai, Per Ola Kristensson, Pengjun Gong, Michael Greiner, Shilei Allen Peng, Liang Mico Liu, and Anthony Dunnigan. 2009. Shapewriter on the iphone: from the laboratory to the real world. InCHI '09 Extended Abstracts on Human Factors in Computing Systems (CHI EA '09). 2667--2670.  Google ScholarShumin Zhai, Carlos Morimoto, and Steven Ihde. 1999. Manual and gaze input cascaded (MAGIC) pointing. In Proceedings of the SIGCHI conference on Human Factors in Computing Systems (CHI '99). 246--253.  Google ScholarShumin Zhai and Per-Ola Kristensson. 2003. Shorthand writing on stylus keyboard. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '03). 97--104.  Google ScholarShumin Zhai and Per Ola Kristensson. 2012. The word-gesture keyboard: reimagining keyboard interaction. Commun. ACM 55, 9 (September 2012): 91--101.  Google ScholarSupplemental Materialvideohttps://acm-prod-streaming.literatumonline.com/3025453.3025964/64792952-74aa-44bc-9e6a-ee1cb3140c08/pn4116p.,180,300,750,964,.mp4.m3u8?b92b4ad1b4f274c70877518315abb28be831d54738a81f1de54388f7ee07e5e64ad2301e1e02b6a6cd881b42e09d9f62f121e86e617334acf538e98f0ce2a92c6ccf732b73c514af465a7d31ce47b39f5b8fbee2b801be86be20e0c037d09a20fa622a97ccapplication/x-mpegurlmp42.5 MB", "keywords": ["gesture keyboard", "hmd", "head-based text entry", "dwelling"], "published_in": "CHI '17: Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems", "publication_date": "2 May 2017", "citations": "30", "isbn": "9781450346559", "doi": "10.1145/3025453", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3025453.3025964", "paper_url": "https://dl.acm.org/doi/10.1145/3025453.3025964"}, {"title": "Virtual birding: extending an environmental pastime into the virtual world for citizen science", "authors": ["Mark Cottman-Fields", "Margot Brereton", "Paul Roe"], "abstract": "This paper investigates engaging experienced birders, as volunteer citizen scientists, to analyze large recorded audio datasets gathered through environmental acoustic monitoring. Although audio data is straightforward to gather, automated analysis remains a challenging task; the existing expertise, local knowledge and motivation of the birder community can complement computational approaches and provide distinct benefits. We explored both the culture and practice of birders, and paradigms for interacting with recorded audio data. A variety of candidate design elements were tested with birders.This study contributes an understanding of how virtual interactions and practices can be developed to complement existing practices of experienced birders in the physical world. In so doing this study contributes a new approach to engagement in e-science. Whereas most citizen science projects task lay participants with discrete real world or artificial activities, sometimes using extrinsic motivators, this approach builds on existing intrinsically satisfying practices.                     References                 Birdlife Australia. 2012. People. http://www.birdlife.org.au/who-we-are/our-organisation/people.Google ScholarDickinson, J., Zuckerberg, B. and Bonter, D. N. 2010. Citizen Science as an Ecological Research Tool: Challenges and Benefits. Annual review of ecology, evolution, and systematics, 41, 1, 149--172, 10.1146/annurev-ecolsys-102209-144636.Google ScholarDonnelly, P. 1994. Take My Word for It: Trust in the Context of Birding and Mountaineering. Qualitative Sociology, 17, 3, 215-Google ScholarCross RefGaver, W. 2006. Learning from Experience: The Humble Role of Theory in Practice-Based Research. In Proceedings of the CHI 2006 Workshop on Theory and Methods for Experience-Centered Design, Quebec, Canada, ACM.Google ScholarHutchinson, H., Mackay, W., Westerlund, B., Bederson, B. B., Druin, A., Plaisant, C., Beaudouin-Lafon, M., Conversy, S., Evans, H., Hansen, H., Roussel, N. and Eiderb\u00e4ck, B. 2003. Technology Probes: Inspiring Design for and with Families. In Proceedings of the Proceedings of the SIGCHI conference on Human factors in computing systems, Ft. Lauderdale, Florida, USA, ACM, 642616,17--24.  Google ScholarDigital LibraryKanipe, J. 2010. Modeling the Astronomical. Commun. ACM, 53, 5, 13--15, 10.1145/1735223.1735230.  Google ScholarDigital LibraryKhatib, F., DiMaio, F., Cooper, S., Kazmierczyk, M., Gilski, M., Krzywda, S., Zabranska, H., Pichova, I., Thompson, J. and Popovi\u0107, Z. 2011. Crystal Structure of a Monomeric Retroviral Protease Solved by Protein Folding Game Players. Nature structural &amp; molecular biology, 18, 10, 1175--1177, 10.1038/nsmb.2119.Google ScholarLaw, E. L. M., von Ahn, L., Dannenberg, R. and Crawford, M. 2007. Tagatune: A Game for Music and Sound Annotation. Proceedings of The International Society for Music Information Retrieval (Vienna, Austria, 2007).Google ScholarMcFarlane, B. L. 1994. Specialization and Motivations of Birdwatchers. Wildlife Society Bulletin, 22, 3, 361--370.Google ScholarPrestopnik, N. R. and Crowston, K. 2012. Citizen Science System Assemblages: Understanding the Technologies That Support Crowdsourced Science. In Proceedings of the Proceedings of the 2012 iConference, Toronto, Ontario, Canada, ACM, 2132198,168--176.  Google ScholarDigital LibraryRotman, D., Preece, J., Hammock, J., Procita, K., Hansen, D., Parr, C., Lewis, D. and Jacobs, D. 2012. Dynamic Changes in Motivation in Collaborative Citizen-Science Projects. ACM, 2012.Google ScholarSauer, J. R., Peterjohn, B. G. and Link, W. A. 1994. Observer Differences in the North American Breeding Bird Survey. The Auk, 50--62.Google ScholarSloane, P. 2011. A Guide to Open Innovation and Crowdsourcing: Advice from Leading Experts. Kogan Page Ltd.Google ScholarTingle, D., Kim, Y. E. and Turnbull, D. 2010. Exploring Automatic Music Annotation with \"Acoustically-Objective\" Tags. In Proceedings of the Multimedia Information Retrieval, Philadelphia, Pennsylvania, USA, ACM, 1743400, 55--62.  Google ScholarDigital LibraryTruskinger, A. M., Yang, H., Wimmer, J., Zhang, J., Williamson, I. and Roe, P. 2011. Large Scale Participatory Acoustic Sensor Data Analysis: Tools and Reputation Models to Enhance Effectiveness. IEEE Computer Society, Stockholm, Sweden, 2011.Google ScholarU. S. Fish &amp; Wildlife Service. 2006. 2006 National Survey of Fishing, Hunting, and Wildlife-Associated Recreation. 2006.Google ScholarWiggins, A. 2011. Ebirding: Technology Adoption and the Transformation of Leisure into Science. In Proceedings of the Proceedings of the 2011 iConference, Seattle, Washington, ACM, 1940910, 798--799.  Google ScholarDigital LibraryWimmer, J., Towsey, M., Planitz, B., Roe, P. and Williamson, I. 2010. Scaling Acoustic Data Analysis through Collaboration and Automation. IEEE, Brisbane, Australia, 2010.Google Scholar                                                                                                Index Terms                 Virtual birdingHuman-centered computing", "keywords": ["bioacoustics", "birder", "domain-specific expertise", "bird watching", "citizen science", "biodiversity monitoring"], "published_in": "CHI '13: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems", "publication_date": "27 April 2013", "citations": "17", "isbn": "9781450318990", "doi": "10.1145/2470654", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2470654.2466268", "paper_url": "https://dl.acm.org/doi/10.1145/2470654.2466268"}], "total_number_of_results": 73}