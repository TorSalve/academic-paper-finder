{
  "papers": [
    {
      "title": "Hands-free vibrotactile feedback for object selection tasks in virtual reality",
      "authors": [
        "Tomi Nukarinen",
        "Jari Kangas",
        "Jussi Rantala",
        "Toni Pakkanen",
        "Roope Raisamo"
      ],
      "abstract": "Interactions between humans and virtual environments rely on timely and consistent sensory feedback, including haptic feedback. However, many questions remain open concerning the spatial location of haptics on the user's body in VR. We studied how simple vibrotactile collision feedback on two less studied locations, the temples, and the wrist, affects an object picking task in a VR environment. We compared visual feedback to three visual-haptic conditions, providing haptic feedback on the participants' (N=16) wrists, temples or simultaneously on both locations. The results indicate that for continuous, hand-based object selection, the wrist is a more promising feedback location than the temples. Further, even a suboptimal feedback location may be better than no haptic collision feedback at all.",
      "keywords": [
        "haptic feedback",
        "visual feedback",
        "collision detection",
        "object selection in virtual reality"
      ],
      "published_in": "VRST '18: Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "28 November 2018",
      "citations": "3",
      "isbn": "9781450360869",
      "doi": "10.1145/3281505",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3281505.3283375",
      "paper_url": "https://dl.acm.org/doi/10.1145/3281505.3283375"
    },
    {
      "title": "Evaluating ray casting and two gaze-based pointing techniques for object selection in virtual reality",
      "authors": [
        "Tomi Nukarinen",
        "Jari Kangas",
        "Jussi Rantala",
        "Olli Koskinen",
        "Roope Raisamo"
      ],
      "abstract": "Selecting an object is a basic interaction task in virtual reality (VR) environments. Interaction techniques with gaze pointing have potential for this elementary task. There appears to be little empirical evidence concerning the benefits and drawbacks of these methods in VR. We ran an experiment studying three interaction techniques: ray casting, dwell time and gaze trigger, where gaze trigger was a combination of gaze pointing and controller selection. We studied user experience and interaction speed in a simple object selection task. The results indicated that ray casting outperforms both gaze-based methods while gaze trigger performs better than dwell time.",
      "keywords": [
        "object selection in virtual reality",
        "gaze pointing",
        "controller pointing"
      ],
      "published_in": "VRST '18: Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "28 November 2018",
      "citations": "3",
      "isbn": "9781450360869",
      "doi": "10.1145/3281505",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3281505.3283382",
      "paper_url": "https://dl.acm.org/doi/10.1145/3281505.3283382"
    },
    {
      "title": "Using custom transformation axes for mid-air manipulation of 3D virtual objects",
      "authors": [
        "Daniel Mendes",
        "Maur\u00edcio Sousa",
        "Rodrigo Lorena",
        "Alfredo Ferreira",
        "Joaquim Jorge"
      ],
      "abstract": "Virtual Reality environments are able to offer natural interaction metaphors. However, it is difficult to accurately place virtual objects in the desired position and orientation using gestures in mid-air. Previous research concluded that the separation of degrees-of-freedom (DOF) can lead to better results, but these benefits come with an increase in time when performing complex tasks, due to the additional number of transformations required. In this work, we assess whether custom transformation axes can be used to achieve the accuracy of DOF separation without sacrificing completion time. For this, we developed a new manipulation technique, MAiOR, which offers translation and rotation separation, supporting both 3-DOF and 1-DOF manipulations, using personalized axes for the latter. Additionally, it also has direct 6-DOF manipulation for coarse transformations, and scaled object translation for increased placement. We compared MAiOR against an exclusively 6-DOF approach and a widget-based approach with explicit DOF separation. Results show that, contrary to previous research suggestions, single DOF manipulations are not appealing to users. Instead, users favored 3-DOF manipulations above all, while keeping translation and rotation independent.",
      "keywords": [
        "virtual reality",
        "3D user interfaces",
        "custom manipulation axis",
        "mid-air object manipulation",
        "DOF separation"
      ],
      "published_in": "VRST '17: Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "8 November 2017",
      "citations": "4",
      "isbn": "9781450355483",
      "doi": "10.1145/3139131",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3139131.3139157",
      "paper_url": "https://dl.acm.org/doi/10.1145/3139131.3139157"
    },
    {
      "title": "Reconfigurable tangible devices for 3D virtual object manipulation by single or multiple users",
      "authors": [
        "Laurent Aguerreche",
        "Thierry Duval",
        "Anatole L\u00e9cuyer"
      ],
      "abstract": "In this paper we introduce the concept of a Reconfigurable Tangible Device for manipulation of 3D objects in virtual environments by single or multiple users. This Reconfigurable Tangible Device (RTD) provides points of manipulation rigidly linked together. The shape of the RTD can be reconfigured at any time as its arms can be compressed or stretched by users at will. Due to its simple shape the Reconfigurable Tangible Device can be attached to any 3D virtual object. Then, it can fully define the motion of the virtual object in 6 Degrees of Freedom. Two examples of Reconfigurable Tangible Device were developed: one with three points of manipulation (a reconfigurable triangle) and one with four points. We illustrate how these two simple devices can match many different shapes of 3D objects, and in different contexts. Preliminary testing was conducted with the RTD based on three points of manipulation involving a collaborative manipulation task in virtual reality. It produced better subjective appreciation for the RTD compared to more classical 3D collaborative techniques.",
      "keywords": [
        "reconfigurable tangible user interface",
        "collaborative interaction",
        "3D interaction",
        "virtual reality"
      ],
      "published_in": "VRST '10: Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "22 November 2010",
      "citations": "14",
      "isbn": "9781450304412",
      "doi": "10.1145/1889863",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1889863.1889913",
      "paper_url": "https://dl.acm.org/doi/10.1145/1889863.1889913"
    },
    {
      "title": "Score-based recommendation for efficiently selecting individual virtual agents in multi-agent systems",
      "authors": [
        "Andrea B\u00f6nsch",
        "Robert Trisnadi",
        "Jonathan Wendt",
        "Tom Vierjahn",
        "Torsten W. Kuhlen"
      ],
      "abstract": "Controlling user-agent-interactions by means of an external operator includes selecting the virtual interaction partners fast and faultlessly. However, especially in immersive scenes with a large number of potential partners, this task is non-trivial.Thus, we present a score-based recommendation system supporting an operator in the selection task. Agents are recommended as potential partners based on two parameters: the user's distance to the agents and the user's gazing direction. An additional graphical user interface (GUI) provides elements for configuring the system and for applying actions to those agents which the operator has confirmed as interaction partners.",
      "keywords": [
        "multi-agent systems",
        "recommendation system",
        "external operator"
      ],
      "published_in": "VRST '17: Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "8 November 2017",
      "citations": "0",
      "isbn": "9781450355483",
      "doi": "10.1145/3139131",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3139131.3141215",
      "paper_url": "https://dl.acm.org/doi/10.1145/3139131.3141215"
    },
    {
      "title": "Influence of event-based haptic on the manipulation of rigid objects in degraded virtual environments",
      "authors": ["Mathieu Gautier", "Jean Sreng", "Claude Andriot"],
      "abstract": "In this paper, we propose to evaluate the benefits of event-based haptic rendering in virtual environments subject to high damping or low contact stiffness. In such context, the degraded perception of contact impairs the manipulation performance and the overall user's experience. Haptic rendering techniques known as event-based (or open-loop) rendering have been proposed to improve the realism of contacts in such contexts.We conducted a preliminary experiment to investigate the effect in terms of performance of haptic event-based technique on virtual environments using different parameters of damping and stiffness. The first results suggest that event-based haptic can improve the perception of contact for such environments (particularly with high damping and/or low stiffness).",
      "keywords": [
        "haptic feedback",
        "open loop haptic",
        "event-based haptic",
        "contact"
      ],
      "published_in": "VRST '09: Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "18 November 2009",
      "citations": "1",
      "isbn": "9781605588698",
      "doi": "10.1145/1643928",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1643928.1643989",
      "paper_url": "https://dl.acm.org/doi/10.1145/1643928.1643989"
    },
    {
      "title": "A study of multimodal feedback to support collaborative manipulation tasks in virtual worlds",
      "authors": [
        "Arturo S. Garc\u00eda",
        "Jos\u00e9 P. Molina",
        "Pascual Gonz\u00e1lez",
        "Diego Mart\u00ednez",
        "Jonatan Mart\u00ednez"
      ],
      "abstract": "In the research community, developers of Collaborative Virtual Environments (CVEs) usually refer to the terms awareness and feedback as something necessary to maintain a fluent collaboration when highly interactive tasks have to be performed. However, it is remarkable that few studies address the effect that including special kinds of feedback has on user awareness and task performance. This work follows a preliminary experiment where we already studied awareness in CVEs, evaluating the effect of visual cues in the performance of collaborative tasks and showing that users tend to make more mistakes when such feedback is not provided, that is, they are less aware. These early results were promising and encouraged us to continue investigating the benefit of improving awareness in tasks that require close collaboration between users, but this time analyzing more types of awareness and experimenting with visual, audio and vibrotactile feedback cues.",
      "keywords": [
        "feedback",
        "CSCW",
        "collaborative virtual environments",
        "awareness"
      ],
      "published_in": "VRST '09: Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "18 November 2009",
      "citations": "1",
      "isbn": "9781605588698",
      "doi": "10.1145/1643928",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1643928.1643994",
      "paper_url": "https://dl.acm.org/doi/10.1145/1643928.1643994"
    },
    {
      "title": "Influence of degrees of freedom's manipulation on performances during orientation tasks in virtual reality environments",
      "authors": ["Manuel Veit", "Antonio Capobianco", "Dominique Bechmann"],
      "abstract": "In this paper we investigate the influence of the integration and separation of the Degrees Of Freedom (DOF) on the users' performances during 3-D orientation tasks. For this purpose, we compare the performances and the level of DOF's coordination users reached using two interaction techniques, one integrating and the other separating the task's DOF. To evaluate the degree of coordination, we propose a new behavioural measurement (called Magnitude of Degrees of Freedom's Separation), which provides the number of DOF simultaneously manipulated during an orientation task. The results of our study suggest that users are not able to integrate the manipulation of all the DOF during the whole task even using a direct manipulation technique. Moreover, if the interaction eases the task's decomposition, its use can lead to significant improvements regarding the achievement times. This result suggests that the simultaneous manipulation of all the DOF does not necessary lead to the best performances.",
      "keywords": [
        "rotation",
        "interaction technique",
        "degrees of freedom",
        "virtual reality",
        "human - computer interaction",
        "measurements"
      ],
      "published_in": "VRST '09: Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "18 November 2009",
      "citations": "25",
      "isbn": "9781605588698",
      "doi": "10.1145/1643928",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1643928.1643942",
      "paper_url": "https://dl.acm.org/doi/10.1145/1643928.1643942"
    },
    {
      "title": "Starfish: a selection technique for dense virtual environments",
      "authors": [
        "Jonathan Wonner",
        "J\u00e9r\u00f4me Grosjean",
        "Antonio Capobianco",
        "Dominique Bechmann"
      ],
      "abstract": "We present Starfish - a new target selection technique for virtual reality (VR) environments. This technique provides a solution to accurately select targets in high-density 3D scenes. The user controls a 3D pointer surrounded by a starfish-shaped closed surface. The extremity of each branch ends exactly on preselected near targets. The shape is an implicit surface built on the segments going from the pointer to each of these targets. As the pointer moves across the scene, the starfish shape is dynamically rebuilt. When it is locked the pointer is allowed to move inside the volume, slide down the desired branch, reach and select the corresponding target. Since the pointer stays within the shape, targets are easy to reach and select.",
      "keywords": [
        "starfish",
        "3d interaction",
        "selection",
        "virtual reality",
        "implicit surface"
      ],
      "published_in": "VRST '12: Proceedings of the 18th ACM symposium on Virtual reality software and technology",
      "publication_date": "10 December 2012",
      "citations": "10",
      "isbn": "9781450314695",
      "doi": "10.1145/2407336",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2407336.2407356",
      "paper_url": "https://dl.acm.org/doi/10.1145/2407336.2407356"
    },
    {
      "title": "Is the Pen Mightier than the Controller? A Comparison of Input Devices for Selection in Virtual and Augmented Reality",
      "authors": ["Duc-Minh Pham", "Wolfgang Stuerzlinger"],
      "abstract": "Controllers are currently the typical input device for commercial Virtual Reality (VR) systems. Yet, such controllers are not as efficient as other devices, including the mouse. This motivates us to investigate devices that substantially exceed the controller\u2019s performance, for both VR and Augmented Reality (AR) systems. We performed a user study to compare several input devices, including a mouse, controller, and a 3D pen-like device on a VR and AR pointing task. Our results show that the 3D pen significantly outperforms modern VR controllers in all evaluated measures and that it is comparable to the mouse. Participants also liked the 3D pen more than the controller. Finally, we show how 3D pen devices could be integrated into today\u2019s VR and AR systems.",
      "keywords": [
        "Virtual and Augmented Reality",
        "3D pointing",
        "input devices"
      ],
      "published_in": "VRST '19: 25th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "12 November 2019",
      "citations": "2",
      "isbn": "9781450370011",
      "doi": "10.1145/3359996",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3359996.3364264",
      "paper_url": "https://dl.acm.org/doi/10.1145/3359996.3364264"
    },
    {
      "title": "The smart pin: a novel object manipulation technique for immersive virtual environments",
      "authors": ["Fabio Marco Caputo", "Marco Emporio", "Andrea Giachetti"],
      "abstract": "In this paper we describe a demo setup showing the potential usefulness of a novel single-handed manipulation technique, designed to be used with immersive Virtual Environments. The technique allows manipulation control over objects in the scene through the use of a single 3D widget, allowing easy and separated control of translation, rotation and scaling actions. The goal is to provide an intuitive, easy-to-use and accurate way to perform simple manipulation tasks using only one hand. User tests demonstrated that the widget is intuitive and effective.",
      "keywords": [
        "3D widgets",
        "virtual reality",
        "user evaluation",
        "mid air manipulation"
      ],
      "published_in": "VRST '17: Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "8 November 2017",
      "citations": "0",
      "isbn": "9781450355483",
      "doi": "10.1145/3139131",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3139131.3141784",
      "paper_url": "https://dl.acm.org/doi/10.1145/3139131.3141784"
    },
    {
      "title": "Acoustical manipulation for redirected walking",
      "authors": [
        "Tobias Feigl",
        "Eliise K\u00f5re",
        "Christopher Mutschler",
        "Michael Philippsen"
      ],
      "abstract": "Redirected Walking (RDW) manipulates a scene that is displayed to VR users so that they unknowingly compensate for scene motion and can thus explore a large virtual world on a limited space. So far, mostly visual manipulation techniques have been studied.This paper shows that users can also be manipulated by means of acoustical signals. In an experiment with a dynamically moving audio source we see deviations of up to 30% from a 20 m long straight-line walk for male participants and of up to 25% for females. Static audio has about two thirds of this impact.",
      "keywords": [
        "motion perception",
        "virtual locomotion",
        "spatial audio",
        "virtual reality",
        "redirected walking"
      ],
      "published_in": "VRST '17: Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "8 November 2017",
      "citations": "2",
      "isbn": "9781450355483",
      "doi": "10.1145/3139131",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3139131.3141205",
      "paper_url": "https://dl.acm.org/doi/10.1145/3139131.3141205"
    },
    {
      "title": "CrOS: a touch screen interaction technique for cursor manipulation on 2-manifolds",
      "authors": ["Manuel Veit", "Antonio Capobianco", "Dominique Bechmann"],
      "abstract": "We present a new Virtual Reality (VR) interaction technique, called Cursor On Surface (CrOS). It is an interaction technique for cursor manipulation on 2-manifolds using touch screen input. The objective is to provide a technique to easily perform complex modelling operations in VR. CrOS is based on an algorithm which maps 2-D inputs into cursor displacements on 3-D surfaces. The technique relies on two principles. Firstly, it restricts the manipulation space to a 2-D space. Secondly, it reduces the complexity of the task through an automatic orientation algorithm that prevent the user from switching between edition task and object repositioning task.",
      "keywords": [
        "virtual reality",
        "touch screen interaction",
        "interaction technique",
        "geometric modelling"
      ],
      "published_in": "VRST '12: Proceedings of the 18th ACM symposium on Virtual reality software and technology",
      "publication_date": "10 December 2012",
      "citations": "1",
      "isbn": "9781450314695",
      "doi": "10.1145/2407336",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2407336.2407355",
      "paper_url": "https://dl.acm.org/doi/10.1145/2407336.2407355"
    },
    {
      "title": "Data-driven sequential goal selection model for multi-agent simulation",
      "authors": [
        "Wenxi Liu",
        "Zhe Huang",
        "Rynson W. H. Lau",
        "Dinesh Manocha"
      ],
      "abstract": "With recent advances in distributed virtual worlds, online users have access to larger and more immersive virtual environments. Sometimes the number of users in virtual worlds is not large enough to make the virtual world realistic. In our paper, we present a crowd simulation algorithm that allows a large number of virtual agents to navigate around the virtual world autonomously by sequentially selecting the goals. Our approach is based on our sequential goal selection model (SGS) which can learn goal-selection patterns from synthetic sequences. We demonstrate our algorithm's simulation results in complex scenarios containing more than 20 goals.",
      "keywords": [
        "goal selection",
        "data-driven animation",
        "crowd simulation"
      ],
      "published_in": "VRST '14: Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "11 November 2014",
      "citations": "0",
      "isbn": "9781450332538",
      "doi": "10.1145/2671015",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2671015.2671024",
      "paper_url": "https://dl.acm.org/doi/10.1145/2671015.2671024"
    },
    {
      "title": "Profiling the behaviour of 3D selection tasks on movement time when using natural haptic pointing gestures",
      "authors": ["Vijay M. Pawar", "Anthony Steed"],
      "abstract": "In this paper we profiled the performance of two types of 3D selections tasks: selection of one target and the selection of two targets. We designed an Immersive Virtual Environment (IVE) to evaluate any differences that may exist, and understand the underlying human behaviour by recording the hand movements' participants made when asked to select a series of 3D objects. To do this, we implemented a natural virtual hand-like interaction technique that participants could control using a large-scale force-feedback device placed into a CAVE\u2122-like IVE system. We also investigated the interaction of no, soft and hard haptic force-feedback responses in addition to three target sizes on user performance. From the results obtained, we show distinct differences in the movement time taken when participants used their right hand to select one target in comparison to the selection of two targets.",
      "keywords": [],
      "published_in": "VRST '09: Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "18 November 2009",
      "citations": "4",
      "isbn": "9781605588698",
      "doi": "10.1145/1643928",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1643928.1643947",
      "paper_url": "https://dl.acm.org/doi/10.1145/1643928.1643947"
    },
    {
      "title": "The benefits of DOF separation in mid-air 3D object manipulation",
      "authors": [
        "Daniel Mendes",
        "Filipe Relvas",
        "Alfredo Ferreira",
        "Joaquim Jorge"
      ],
      "abstract": "Object manipulation is a key feature in almost every virtual environment. However, it is difficult to accurately place an object in immersive virtual environments using mid-air gestures that mimic interactions in the physical world, although being a direct and natural approach. Previous research studied mouse and touch based interfaces concluding that separation of degrees-of-freedom (DOF) led to improved results. In this paper, we present the first user evaluation to assess the impact of explicit 6 DOF separation in mid-air manipulation tasks. We implemented a technique based on familiar virtual widgets that allow single DOF control, and compared it against a direct approach and PRISM, which dynamically adjusts the ratio between hand and object motions. Our results suggest that full DOF separation benefits precision in spatial manipulations, at the cost of additional time for complex tasks. From our results we draw guidelines for 3D object manipulation in mid-air.",
      "keywords": [
        "spatial interactions",
        "DOF separation",
        "3D user interfaces",
        "mid-air object manipulation",
        "immersive virtual environments"
      ],
      "published_in": "VRST '16: Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology",
      "publication_date": "2 November 2016",
      "citations": "15",
      "isbn": "9781450344913",
      "doi": "10.1145/2993369",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2993369.2993396",
      "paper_url": "https://dl.acm.org/doi/10.1145/2993369.2993396"
    },
    {
      "title": "Advantages of velocity-based scaling for distant 3D manipulation",
      "authors": ["Curtis Wilkes", "Doug A. Bowman"],
      "abstract": "Immersive virtual environments (VEs) have the potential to offer rich three-dimensional interaction to users. In many instances, however, 3D interaction tasks are difficult due to both the imprecision of tracking devices and the inability of users to achieve and maintain precise hand positions in 3D space. One way to improve upon existing interaction techniques is to dynamically change the sensitivity of the interaction technique based on user input. Previous research has applied this principle to virtual hand-based manipulation techniques; when the user slows down the movement of her physical hand, the virtual hand slows down even more to allow precise manipulation. In this study we extend the prior research by applying the velocity-based scaling principle to HOMER, an existing at-a-distance manipulation technique based on ray-casting. The scaled HOMER technique offers the user the freedom to accomplish both long- and short-distance manipulation tasks with higher levels of precision without compromising speed. We present results from a user study that shows that the addition of scaling to HOMER significantly improves user performance on 3D manipulation tasks.",
      "keywords": ["3D interaction", "user studies", "usability"],
      "published_in": "VRST '08: Proceedings of the 2008 ACM symposium on Virtual reality software and technology",
      "publication_date": "27 October 2008",
      "citations": "11",
      "isbn": "9781595939517",
      "doi": "10.1145/1450579",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1450579.1450585",
      "paper_url": "https://dl.acm.org/doi/10.1145/1450579.1450585"
    },
    {
      "title": "Can we use a brain-computer interface and manipulate a mouse at the same time?",
      "authors": [
        "Jonathan Mercier-Ganady",
        "\u00c9milie Loup-Escande",
        "Laurent George",
        "Colomban Busson",
        "Maud Marchal",
        "Anatole L\u00e9cuyer"
      ],
      "abstract": "Brain-Computer Interfaces (BCI) introduce a novel way of interacting with real and virtual environments by directly exploiting cerebral activity. However in most setups using a BCI, the user is explicitly asked to remain as motionless as possible, since muscular activity is commonly admitted to add noise and artifacts in brain electrical signals. Thus, as for today, people have been rarely let using other classical input devices such as mice or joysticks simultaneously to a BCI-based interaction. In this paper, we present an experimental study on the influence of manipulating an input device such as a standard computer mouse on the performance of a BCI system. We have designed a 2-class BCI which relies on Alpha brainwaves to discriminate between focused versus relaxed mental activities. The study uses a simple virtual environment inspired by the well-known Pac-Man videogame and based on BCI and mouse controls. The control of mental activity enables to eat pellets in a simple 2D virtual maze. Different levels of motor activity achieved with the mouse are progressively introduced in the gameplay: 1) no motor activity (control condition), 2) a semi-automatic motor activity, and 3) a highly-demanding motor activity. As expected the BCI performance was found to slightly decrease in presence of motor activity. However, we found that the BCI could still be successfully used in all conditions, and that relaxed versus focused mental activities could still be significantly discriminated even in presence of a highly-demanding mouse manipulation. These promising results pave the way to future experimental studies with more complex mental and motor activities, but also to novel 3D interaction paradigms that could mix BCI and other input devices for virtual reality and videogame applications.",
      "keywords": [
        "motor activity",
        "EEG",
        "mental activity",
        "brain-computer interface"
      ],
      "published_in": "VRST '13: Proceedings of the 19th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "6 October 2013",
      "citations": "5",
      "isbn": "9781450323796",
      "doi": "10.1145/2503713",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2503713.2503744",
      "paper_url": "https://dl.acm.org/doi/10.1145/2503713.2503744"
    },
    {
      "title": "Physically based grasping and manipulation method using pre-contact grasping quality measure",
      "authors": ["Yongwan Kim", "Jinseong Choi", "Jinah Park"],
      "abstract": "While the human hand is the most natural tool for interacting with objects, hand interaction with virtual objects is still a challenging research field. We recognize that common hand interaction involves two separate stages with different aspects: One is the robustness of grasping, and the other is the dexterity of manipulation after grasping a virtual object. In this paper, we address virtual hand interaction by decoupling these two aspects and propose strategic simulation algorithms for two different stages. As for the initial grasping, a quality measure-based grasping algorithm is applied for robustness, and the manipulation is simulated by physically based methods to meet the requirements of dexterity. We conducted experiments to evaluate the effectiveness of our proposed method under different display environments -- monoscopic and stereoscopic. From the 2-way ANOVA test, we were able to show that the proposed scheme that separates a pre-contact grasping phase and a post-contact manipulation phase gives us the robustness of grasping quality and dexterity of tool operation. Furthermore, we demonstrate various assembly manipulations of the relatively complex models using our interaction scheme.",
      "keywords": ["hand interaction", "manipulation", "grasping"],
      "published_in": "VRST '09: Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "18 November 2009",
      "citations": "3",
      "isbn": "9781605588698",
      "doi": "10.1145/1643928",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1643928.1643991",
      "paper_url": "https://dl.acm.org/doi/10.1145/1643928.1643991"
    },
    {
      "title": "A study on improving close and distant device movement pose manipulation for hand-held augmented reality",
      "authors": ["Ali Samini", "Karljohan Lundin Palmerius"],
      "abstract": "Hand-held smart devices are equipped with powerful processing units, high resolution screens and cameras, that in combination makes them suitable for video see-through Augmented Reality. Many Augmented Reality applications require interaction, such as selection and 3D pose manipulation. One way to perform intuitive, high precision 3D pose manipulation is by direct or indirect mapping of device movement.There are two approaches to device movement interaction; one fixes the virtual object to the device, which therefore becomes the pivot point for the object, thus makes it difficult to rotate without translate. The second approach avoids latter issue by considering rotation and translation separately, relative to the object's center point. The result of this is that the object instead moves out of view for yaw and pitch rotations.In this paper we study these two techniques and compare them with a modification where user perspective rendering is used to solve the rotation issues. The study showed that the modification improves speed as well as both perceived control and intuitiveness among the subjects.",
      "keywords": [
        "user study",
        "device interaction",
        "video see-through",
        "user-perspective",
        "device perspective",
        "augmented reality"
      ],
      "published_in": "VRST '16: Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology",
      "publication_date": "2 November 2016",
      "citations": "4",
      "isbn": "9781450344913",
      "doi": "10.1145/2993369",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2993369.2993380",
      "paper_url": "https://dl.acm.org/doi/10.1145/2993369.2993380"
    },
    {
      "title": "Resolving occlusion for 3D object manipulation with hands in mixed reality",
      "authors": ["Qi Feng", "Hubert P. H. Shum", "Shigeo Morishima"],
      "abstract": "Due to the need to interact with virtual objects, the hand-object interaction has become an important element in mixed reality (MR) applications. In this paper, we propose a novel approach to handle the occlusion of augmented 3D object manipulation with hands by exploiting the nature of hand poses combined with tracking-based and model-based methods, to achieve a complete mixed reality experience without necessities of heavy computations, complex manual segmentation processes or wearing special gloves. The experimental results show a frame rate faster than real-time and a great accuracy of rendered virtual appearances, and a user study verifies a more immersive experience compared to past approaches. We believe that the proposed method can improve a wide range of mixed reality applications that involve hand-object interactions.",
      "keywords": ["mixed reality", "occlusion", "hand tracking"],
      "published_in": "VRST '18: Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "28 November 2018",
      "citations": "1",
      "isbn": "9781450360869",
      "doi": "10.1145/3281505",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3281505.3283390",
      "paper_url": "https://dl.acm.org/doi/10.1145/3281505.3283390"
    },
    {
      "title": "Combining bimanual interaction and teleportation for 3D manipulation on multi-touch wall-sized displays",
      "authors": ["Jean-Baptiste Louvet", "C\u00e9dric Fleury"],
      "abstract": "While multi-touch devices are well established in our everyday life, they are currently becoming larger and larger. Large screens such as wall-sized displays are now equipped with multi-touch capabilities. Multi-touch wall-sized displays will become widespread in a near future in various places such as public places or meeting rooms. These new devices are an interesting opportunity to interact with 3D virtual environments: the large display surface offers a good immersion, while the multi-touch capabilities could make interaction with 3D content accessible to the general public.In this paper, we aim to explore touch-based 3D interaction in the situation where users are immersed in a 3D virtual environment and move in front of a vertical wall-sized display. We design In(SITE), a bimanual touch-based technique combined with object teleportation features which enables users to interact on a large wall-sized display. This technique is compared with a standard 3D interaction technique for performing 6 degrees of freedom manipulation tasks on a wall-sized display. The results of two controlled experiments show that participants can reach the same level of performance for completion time and a better precision for fine adjustments of object position with the In(SITE) technique. They also suggest that combining object teleportation with both techniques improves translations in terms of ease of use, fatigue, and user preference.",
      "keywords": [
        "virtual reality",
        "multi-touch interaction",
        "3D manipulation",
        "wall-sized display"
      ],
      "published_in": "VRST '16: Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology",
      "publication_date": "2 November 2016",
      "citations": "1",
      "isbn": "9781450344913",
      "doi": "10.1145/2993369",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2993369.2993390",
      "paper_url": "https://dl.acm.org/doi/10.1145/2993369.2993390"
    },
    {
      "title": "Overcoming eye-hand visibility mismatch in 3D pointing selection",
      "authors": ["Ferran Argelaguet", "Carlos Andujar", "Ramon Trueba"],
      "abstract": "Most pointing techniques for 3D selection on virtual environments rely on a ray originating at the user's hand whose direction is controlled by the hand orientation. In this paper we study the potential mismatch between visible objects (those which appear unoccluded from the user's eye position) and selectable objects (those which appear unoccluded from the user's hand position). We study the impact of such eye-hand visibility mismatch on selection performance, and propose a new technique for ray control which attempts to overcome this problem. We present an experiment to compare our ray control technique with classic raycasting in selection tasks with complex 3D scenes. Our user studies show promising results of our technique in terms of speed and accuracy.",
      "keywords": ["raycasting", "virtual pointer", "3D selection"],
      "published_in": "VRST '08: Proceedings of the 2008 ACM symposium on Virtual reality software and technology",
      "publication_date": "27 October 2008",
      "citations": "17",
      "isbn": "9781595939517",
      "doi": "10.1145/1450579",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1450579.1450588",
      "paper_url": "https://dl.acm.org/doi/10.1145/1450579.1450588"
    },
    {
      "title": "Efficient selection of multiple objects on a large scale",
      "authors": ["Rasmus Stenholt"],
      "abstract": "The task of multiple object selection (MOS) in immersive virtual environments is important and still largely unexplored. The difficulty of efficient MOS increases with the number of objects to be selected. E.g. in small-scale MOS, only a few objects need to be simultaneously selected. This may be accomplished by serializing existing single-object selection techniques. In this paper, we explore various MOS tools for large-scale MOS. That is, when the number of objects to be selected are counted in hundreds, or even thousands. This makes serialization of single-object techniques prohibitively time consuming. Instead, we have implemented and tested two of the existing approaches to 3-D MOS, a brush and a lasso, as well as a new technique, a magic wand, which automatically selects objects based on local proximity to other objects. In a formal user evaluation, we have studied how the performance of the MOS tools are affected by the geometric configuration of the objects to be selected. Our studies demonstrate that the performance of MOS techniques is very significantly affected by the geometric scenario facing the user. Furthermore, we demonstrate that a good match between MOS tool shape and the geometric configuration is not always preferable, if the applied tool is complex to use.",
      "keywords": [
        "hmd",
        "virtual reality",
        "multiple object selection",
        "user evaluation"
      ],
      "published_in": "VRST '12: Proceedings of the 18th ACM symposium on Virtual reality software and technology",
      "publication_date": "10 December 2012",
      "citations": "5",
      "isbn": "9781450314695",
      "doi": "10.1145/2407336",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2407336.2407357",
      "paper_url": "https://dl.acm.org/doi/10.1145/2407336.2407357"
    },
    {
      "title": "Distortion score based pose selection for 3D tele-immersion",
      "authors": ["Suraj Raghuraman", "Balakrishnan Prabhakaran"],
      "abstract": "3D Tele-Immersion (3DTI) systems capture and transmit large volumes of data per frame to enable virtual world interaction between geographically distributed people. Large delays/latencies introduced during the transmission of these large volumes of data can lead to poor quality of experience of the 3DTI systems. Such poor experiences can possibly be overcome by animating the previously received mesh using the current skeletal data (that is very small in size and hence experiences much lower communication delays). However, using just the previously transmitted mesh for animation is not ideal and could render inconsistent results. In this paper, we present a DIstortion Score based Pose SElection (DISPOSE) approach to render the person by using an appropriate mesh for a given pose. Unlike pose space animation methods that require manual or offline time consuming pose set creation, our distortion score based scheme can choose the mesh to be transmitted and update the pose set accordingly. DISPOSE works with partial meshes and does not require dense registration enabling real time pose space creation. With DISPOSE incorporated into 3DTI, the latency for rendering the mesh on the receiving side is limited by only the transmission delay of the skeletal data (which is only around 250 bytes). Our evaluations show the effectiveness of DISPOSE for generating good quality online animation faster than real time.",
      "keywords": [
        "compression algorithms",
        "3D tele-immersion",
        "pose selection",
        "distortion score",
        "animation",
        "pose matching"
      ],
      "published_in": "VRST '15: Proceedings of the 21st ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "13 November 2015",
      "citations": "3",
      "isbn": "9781450339902",
      "doi": "10.1145/2821592",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2821592.2821600",
      "paper_url": "https://dl.acm.org/doi/10.1145/2821592.2821600"
    },
    {
      "title": "A VR simulator for training and prototyping of telemanipulation of nanotubes",
      "authors": ["Zhan Gao", "Anatole L\u00e9cuyer"],
      "abstract": "This paper describes a virtual reality (VR) simulator, for the purpose of education, training and prototyping of telemanipulation of carbon nanotubes. Major challenges in interfacing a human operator with tasks of manipulating nanotubes via a haptic VR interface are outlined. After a review of previous efforts, we present the current state of our VR simulator for nanotube manipulation. The collision detection, interaction force modeling, deformation simulation and haptic rendering of nanotubes are then discussed. Results of virtual manipulation of carbon nanotubes are presented within an immersive VR set-up.",
      "keywords": ["telemanipulation", "simulation", "VR", "nanotube"],
      "published_in": "VRST '08: Proceedings of the 2008 ACM symposium on Virtual reality software and technology",
      "publication_date": "27 October 2008",
      "citations": "2",
      "isbn": "9781595939517",
      "doi": "10.1145/1450579",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1450579.1450601",
      "paper_url": "https://dl.acm.org/doi/10.1145/1450579.1450601"
    },
    {
      "title": "Resolving view difference between eye and camera for proprioceptive pointing and selection in augmented reality applications",
      "authors": ["Ja Eun Yu", "Gerard J. Kim"],
      "abstract": "In this poster, we propose \"proprioceptive\" pointing (and selection) in which we use the finger and the sense of proprioception, without focusing on the finger, to point and select an object in the real world for the purpose of further interaction. The assumption is that this will reduce user fatigue since the user will switch one's focus less frequently, while still being able to point effectively through the proprioceptive sense. Figure 1 illustrates the concept and how such a technique could be effectively used e.g. for object query system using a see-through glass. In this typical scenario, the user selects an object in the real world (by proprioceptive pointing/designation), which in turn is captured by the on-glass camera and then identified and recognized for final augmentation. Note the \"blurry\" fingertip used for aiming to the target object.",
      "keywords": [],
      "published_in": "VRST '15: Proceedings of the 21st ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "13 November 2015",
      "citations": "0",
      "isbn": "9781450339902",
      "doi": "10.1145/2821592",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2821592.2821648",
      "paper_url": "https://dl.acm.org/doi/10.1145/2821592.2821648"
    },
    {
      "title": "A lightweight and efficient system for tracking handheld objects in virtual reality",
      "authors": [
        "Ya-Kuei Chang",
        "Jui-Wei Huang",
        "Chien-Hua Chen",
        "Chien-Wen Chen",
        "Jian-Wei Peng",
        "Min-Chun Hu",
        "Chih-Yuan Yao",
        "Hung-Kuo Chu"
      ],
      "abstract": "While the content of virtual reality (VR) has grown explosively in recent years, the advance of designing user-friendly control interfaces in VR still remains a slow pace. The most commonly used device, such as gamepad or controller, has fixed shape and weight, and thus can not provide realistic haptic feedback when interacting with virtual objects in VR. In this work, we present a novel and lightweight tracking system in the context of manipulating handheld objects in VR. Specifically, our system can effortlessly synchronize the 3D pose of arbitrary handheld objects between the real world and VR in realtime performance. The tracking algorithm is simple, which delicately leverages the power of Leap Motion and IMU sensor to respectively track object's location and orientation. We demonstrate the effectiveness of our system with three VR applications use pencil, ping-pong paddle, and smartphone as control interfaces to provide users more immersive VR experience.",
      "keywords": ["virtual reality", "haptic feedback", "object tracking"],
      "published_in": "VRST '18: Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "28 November 2018",
      "citations": "1",
      "isbn": "9781450360869",
      "doi": "10.1145/3281505",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3281505.3281567",
      "paper_url": "https://dl.acm.org/doi/10.1145/3281505.3281567"
    },
    {
      "title": "An evaluation of smartphone-based interaction in AR for constrained object manipulation",
      "authors": [
        "Kristoffer Waldow",
        "Martin Misiak",
        "Ursula Derichs",
        "Olaf Clausen",
        "Arnulph Fuhrmann"
      ],
      "abstract": "In Augmented Reality, interaction with the environment can be achieved with a number of different approaches. In current systems, the most common are hand and gesture inputs. However experimental applications also integrated smartphones as intuitive interaction devices and demonstrated great potential for different tasks. One particular task is constrained object manipulation, for which we conducted a user study. In it we compared standard gesture-based approaches with a touch-based interaction via smartphone. We found that a touch-based interface is significantly more efficient, although gestures are being subjectively more accepted. From these results we draw conclusions on how smartphones can be used to realize modern interfaces in AR.",
      "keywords": [
        "augmented reality",
        "study",
        "smartphone",
        "user interface design"
      ],
      "published_in": "VRST '18: Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "28 November 2018",
      "citations": "2",
      "isbn": "9781450360869",
      "doi": "10.1145/3281505",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3281505.3281608",
      "paper_url": "https://dl.acm.org/doi/10.1145/3281505.3281608"
    },
    {
      "title": "Evaluation of remote collaborative manipulation for scientific data analysis",
      "authors": [
        "C\u00e9dric Fleury",
        "Thierry Duval",
        "Val\u00e9rie Gouranton",
        "Anthony Steed"
      ],
      "abstract": "In the context of scientific data analysis, we propose to compare a remote collaborative manipulation technique with a single user manipulation technique. The manipulation task consists in positioning a clipping plane in order to perform cross-sections of scientific data that show several points of interest located inside these data. For the remote collaborative manipulation, we have chosen to use the 3-hand manipulation technique proposed by Aguerreche et al., which is very suitable with a remote manipulation of a plane. We ran two experiments to compare the two manipulation techniques with some participants located in two different countries. These experiments has shown that the remote collaborative manipulation technique was significantly more efficient than the single user manipulation when the 3 points of interest were far apart inside the scientific data and, consequently, when the manipulation task was more difficult and required more precision. When the 3 points of interest were close together, there was not significant difference between the two manipulation techniques.",
      "keywords": [
        "scientific data analysis",
        "virtual environment",
        "VR experiments",
        "remote collaborative manipulation"
      ],
      "published_in": "VRST '12: Proceedings of the 18th ACM symposium on Virtual reality software and technology",
      "publication_date": "10 December 2012",
      "citations": "10",
      "isbn": "9781450314695",
      "doi": "10.1145/2407336",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2407336.2407361",
      "paper_url": "https://dl.acm.org/doi/10.1145/2407336.2407361"
    },
    {
      "title": "Augmented reality-aided tele-presence system for robot manipulation in industrial manufacturing",
      "authors": [
        "Lorenzo Peppoloni",
        "Filippo Brizzi",
        "Emanuele Ruffaldi",
        "Carlo Alberto Avizzano"
      ],
      "abstract": "This work investigates the use of a highly immersive telepresence system for industrial robotics. A Robot Operating System integrated framework is presented where a remote robot is controlled through operator's movements and muscle contractions captured with a wearable device. An augmented 3D visual feedback is sent to the user providing the remote environment scenario from the robot's point of view and additional information pertaining to the task execution. The system proposed, using robot mounted RGB-D camera, identifies known objects and relates their pose to robot arm pose and to targets relevant to the task execution. The system is preliminary validated during a pick-and-place task using a Baxter robot. The experiment shows the practicability and the effectiveness of the proposed approach.",
      "keywords": [
        "tele-operation and tele-presence",
        "tracking and sensing",
        "augmented and mixed reality"
      ],
      "published_in": "VRST '15: Proceedings of the 21st ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "13 November 2015",
      "citations": "8",
      "isbn": "9781450339902",
      "doi": "10.1145/2821592",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2821592.2821620",
      "paper_url": "https://dl.acm.org/doi/10.1145/2821592.2821620"
    },
    {
      "title": "The effect of DOF separation in 3D manipulation tasks with multi-touch displays",
      "authors": ["Anthony Martinet", "G\u00e9ry Casiez", "Laurent Grisoni"],
      "abstract": "Multi-touch displays represent a promising technology for the display and manipulation of data. While the manipulation of 2D data has been widely explored, 3D manipulation with multi-touch displays remains largely uncovered. Based on an analysis of the integration and separation of degrees of freedom, we propose a taxonomy for 3D manipulation techniques with multi-touch displays. Using that taxonomy, we introduce DS3 (Depth-Separated Screen Space), a new 3D manipulation technique based on the separation of translation and rotation. In a controlled experiment, we compare DS3 with Sticky Tools and Screen-Space. Results show that separating the control of translation and rotation significantly affects performance for 3D manipulation, with DS3 being at least 22% faster.",
      "keywords": [
        "3D manipulation task",
        "direct manipulation",
        "multi-touch displays"
      ],
      "published_in": "VRST '10: Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "22 November 2010",
      "citations": "52",
      "isbn": "9781450304412",
      "doi": "10.1145/1889863",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1889863.1889888",
      "paper_url": "https://dl.acm.org/doi/10.1145/1889863.1889888"
    },
    {
      "title": "Audio-tactile proximity feedback for enhancing 3D manipulation",
      "authors": [
        "Alexander Marquardt",
        "Ernst Kruijff",
        "Christina Trepkowski",
        "Jens Maiero",
        "Andrea Schwandt",
        "Andr\u00e9 Hinkenjann",
        "Wolfgang Stuerzlinger",
        "Johannes Sch\u00f6ning"
      ],
      "abstract": "In presence of conflicting or ambiguous visual cues in complex scenes, performing 3D selection and manipulation tasks can be challenging. To improve motor planning and coordination, we explore audio-tactile cues to inform the user about the presence of objects in hand proximity, e.g., to avoid unwanted object penetrations. We do so through a novel glove-based tactile interface, enhanced by audio cues. Through two user studies, we illustrate that proximity guidance cues improve spatial awareness, hand motions, and collision avoidance behaviors, and show how proximity cues in combination with collision and friction cues can significantly improve performance.",
      "keywords": ["tactile feedback", "hand guidance", "3D user interface"],
      "published_in": "VRST '18: Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "28 November 2018",
      "citations": "2",
      "isbn": "9781450360869",
      "doi": "10.1145/3281505",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3281505.3281525",
      "paper_url": "https://dl.acm.org/doi/10.1145/3281505.3281525"
    },
    {
      "title": "Evaluation of Navigation Operations in Immersive Microscopic Visualization",
      "authors": ["Tomomi Takashina", "Mitsuru Ito", "Yuji Kokumai"],
      "abstract": "In this study, we evaluated the quantitative effectiveness of navigation operation in a virtual reality (VR) volumetric viewer, in order to confirm the effectiveness of VR in life sciences. The analytical work for biological data is a promising application of VR because users can manipulate 3D data intuitively in VR. However, few studies have focused on the quantitative evaluations of such applications. Therefore, we conducted an experiment to evaluate the speedup of navigation operation (sequences of translation, rotation, and scaling) in VR applications for 3D microscopy. We compared the task completion time between a non-VR visualization tool and a VR visualization tool. The speedup by the VR immersive visualizer was found to be 203% in the most effective case. The result showed that the VR immersive visualizer enables more efficient navigation than the conventional volumetric viewer.",
      "keywords": [
        "immersive visualization",
        "life science",
        "microscope",
        "virtual reality"
      ],
      "published_in": "VRST '19: 25th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "12 November 2019",
      "citations": "0",
      "isbn": "9781450370011",
      "doi": "10.1145/3359996",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3359996.3364724",
      "paper_url": "https://dl.acm.org/doi/10.1145/3359996.3364724"
    },
    {
      "title": "Dynamic eye convergence for head-mounted displays",
      "authors": ["Andrei Sherstyuk", "Andrei State"],
      "abstract": "A virtual hand metaphor remains by far the most popular technique for direct object manipulation in immersive Virtual Reality (VR). The utility of the virtual hand depends on a user's ability to see it correctly in stereoscopic 3D, especially in tasks that require continuous, precise hand-eye coordination.We present a mechanism that dynamically converges left and right cameras on target objects in VR, mimicking the effect that naturally happens in real life. As a result, the system maintains optimal conditions for stereoscopic viewing at varying depths, in real-time. We describe the algorithm, implementation details and preliminary results from pilot tests.",
      "keywords": [
        "stereoscopic vision",
        "virtual hand",
        "hand-eye coordination"
      ],
      "published_in": "VRST '10: Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "22 November 2010",
      "citations": "7",
      "isbn": "9781450304412",
      "doi": "10.1145/1889863",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1889863.1889869",
      "paper_url": "https://dl.acm.org/doi/10.1145/1889863.1889869"
    },
    {
      "title": "Understanding Enjoyment in VR Games with GameFlow",
      "authors": ["Penny Sweetser", "Zane Rogalewicz", "Qingyang Li"],
      "abstract": "In this paper, we report on a work in progress project that aims to understand affordances and inhibiters of enjoyment in virtual reality (VR) video games. We apply the GameFlow model to review and analyse VR and non-VR versions of the same games to identify differences in enjoyment. Our approach includes conducting expert reviews using the GameFlow model, as well as conducting qualitative analysis on video game reviews, using GameFlow as a conceptual foundation. In this paper, we report our initial findings for the game Superhot. Our ongoing work evaluates a selection of games to map opportunities and pitfalls when designing games for VR.",
      "keywords": [
        "VR",
        "enjoyment",
        "player experience",
        "videogames",
        "Virtual reality"
      ],
      "published_in": "VRST '19: 25th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "12 November 2019",
      "citations": "2",
      "isbn": "9781450370011",
      "doi": "10.1145/3359996",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3359996.3364800",
      "paper_url": "https://dl.acm.org/doi/10.1145/3359996.3364800"
    },
    {
      "title": "D3: an immersive aided design deformation method",
      "authors": ["Vincent Meyrueis", "Alexis Paljic", "Philippe Fuchs"],
      "abstract": "In this paper, we introduce a new deformation method adapted to immersive design. The use of Virtual Reality (VR) in the design process implies a physical displacement of project actors and data between the virtual reality facilities and the design office. The decisions taken in the immersive environment are manually reflected on the Computed Aided Design (CAD) system. This increases the design time and breaks the continuity of data workflow. On this basis, there is a clear demand among the industry for tools adapted to immersive design. But few methods exist that encompass CAD problematic in VR. For this purpose, we propose a new method, called D3, for \"Draw, Deform and Design\", based on a 2 step manipulation paradigm, consisting with 1) area selection and 2) path drawing, and a final refining and fitting phase. Our method is discussed on the basis of a set of CAD deformation scenarios.",
      "keywords": [
        "computer-aided design (CAD)",
        "virtual reality",
        "immersive environment",
        "real-time 3D object deformation"
      ],
      "published_in": "VRST '09: Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "18 November 2009",
      "citations": "1",
      "isbn": "9781605588698",
      "doi": "10.1145/1643928",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1643928.1643968",
      "paper_url": "https://dl.acm.org/doi/10.1145/1643928.1643968"
    },
    {
      "title": "SlingDrone: Mixed Reality System for Pointing and Interaction Using a Single Drone",
      "authors": [
        "Evgeny Tsykunov",
        "Roman Ibrahimov",
        "Derek Vasquez",
        "Dzmitry Tsetserukou"
      ],
      "abstract": "We propose SlingDrone, a novel Mixed Reality interaction paradigm that utilizes a micro-quadrotor as both pointing controller and interactive robot with a slingshot motion type. The drone attempts to hover at a given position while the human pulls it in desired direction using a hand grip and a leash. Based on the displacement, a virtual trajectory is defined. To allow for intuitive and simple control, we use virtual reality (VR) technology to trace the path of the drone based on the displacement input. The user receives force feedback propagated through the leash. Force feedback from SlingDrone coupled with visualized trajectory in VR creates an intuitive and user friendly pointing device. When the drone is released, it follows the trajectory that was shown in VR. Onboard payload (e.g. magnetic gripper) can perform various scenarios for real interaction with the surroundings, e.g. manipulation or sensing. Unlike HTC Vive controller, SlingDrone does not require handheld devices, thus it can be used as a standalone pointing technology in VR.",
      "keywords": [
        "human-robot interaction",
        "haptics",
        "quadrotor",
        "mixed reality"
      ],
      "published_in": "VRST '19: 25th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "12 November 2019",
      "citations": "0",
      "isbn": "9781450370011",
      "doi": "10.1145/3359996",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3359996.3364271",
      "paper_url": "https://dl.acm.org/doi/10.1145/3359996.3364271"
    },
    {
      "title": "Experiencing Waiting Time in Virtual Reality",
      "authors": [
        "Jean-Luc Lugrin",
        "Fabian Unruh",
        "Maximilian Landeck",
        "Yoan Lamour",
        "Marc Erich Latoschik",
        "Kai Vogeley",
        "Marc Wittmann"
      ],
      "abstract": "This article investigates the impact of waiting in Virtual Reality (VR) on the perception of time. We manipulated the visual quality of a virtual room replicating a real one (360-picture vs. 3D-model) with and without avatar embodiment (no-avatar vs. avatar). We only observed a significant difference in the estimated time duration between the real and the virtual worlds when using no avatar within a 3D model of the room. Our early results suggest that a VR environment with an avatar and a simple 3D model or 360 picture room is not significantly perturbing time perception and thus could be used for diagnosis and therapy of psychiatric conditions related to altered time perception.",
      "keywords": ["Time Perception", "Virtual Reality", "Avatar Embodiment"],
      "published_in": "VRST '19: 25th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "12 November 2019",
      "citations": "0",
      "isbn": "9781450370011",
      "doi": "10.1145/3359996",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3359996.3364807",
      "paper_url": "https://dl.acm.org/doi/10.1145/3359996.3364807"
    },
    {
      "title": "Hand-free natural user interface for VR HMD with IR based facial gesture tracking sensor",
      "authors": ["Jinhyuk Kim", "Jaekwang Cha", "Hojun Lee", "Shiho Kim"],
      "abstract": "We proposed a hand-free Natural User Interface (NUI) for VR Head-Mounted-Display (HMD) with infra-red (IR) based sensor tracking facial gestures. We have realized NUI based on the real-time recognition of user intuitions for VR HMD without any additional control devices except for a built-in Gyroscope and IR couplers with readout circuitry integrated in the foam interface of an HMD. We implemented seven control commands affordable for 3D interactions with virtual objects. The experimental data show that the proposed system provides a convenient and efficient 2D/3D user interface for both manipulating objects and controlling commands while wearing a VR HMD.",
      "keywords": [
        "natural user interface",
        "virtual reality",
        "facial gesture recognition",
        "wearable sensors",
        "head-mounted-display"
      ],
      "published_in": "VRST '17: Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "8 November 2017",
      "citations": "1",
      "isbn": "9781450355483",
      "doi": "10.1145/3139131",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3139131.3143420",
      "paper_url": "https://dl.acm.org/doi/10.1145/3139131.3143420"
    },
    {
      "title": "Exploring Immersive Technologies to Simulate Fear of Crime",
      "authors": [
        "Francisco J. Castro-Toledo",
        "Konstantinos Koumaditis",
        "Panagiotis Mitkidis",
        "Juan O. Perea-Garcia"
      ],
      "abstract": "The implementation of Virtual Reality (VR) tools in criminological research is very scarce, and almost non-existent in the fear of crime (FoC) field. Our objective is to assess the feasibility of Immersive Technologies for research on FoC. To do so, a simulation (360\u00b0 video) grounded on the manipulation of environmental variables (street lighting) was conducted. Our preliminary results suggest that: (a) virtual simulation of absence of urban lighting elicits experiences of FoC, and (b) that simulation of experiences of FoC in virtual reality is an adequate strategy for analysis of this phenomenon.",
      "keywords": [
        "Criminology",
        "environmental variables.",
        "fear of crime",
        "immersive technologies",
        "360\u00b0 video",
        "virtual reality"
      ],
      "published_in": "VRST '19: 25th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "12 November 2019",
      "citations": "0",
      "isbn": "9781450370011",
      "doi": "10.1145/3359996",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3359996.3364713",
      "paper_url": "https://dl.acm.org/doi/10.1145/3359996.3364713"
    },
    {
      "title": "Indian Virtual reality affective database with self-report measures and EDA",
      "authors": [
        "Surya Soujanya Kodavalla",
        "Minaxi Jai Bhagwan Goel",
        "Priyanka Srivastava"
      ],
      "abstract": "The current work assesses the physiological and psychological responses to the 360\u00b0 emotional videos selected from Stanford virtual reality (VR) affective database [Li et al., 2017], presented using VR head-mounted display (HMD). Participants were asked to report valence and arousal level after watching each video. The electro-dermal activity (EDA) was recorded while watching the videos. The current pilot study shows no significant difference in skin-conductance response (SCR) between the high and low arousal experience. Similar trends were observed during high and low valence. The self-report pilot data on valence and arousal shows no statistically significant difference between Stanford VR affective responses and the corresponding Indian population psychological responses. Despite positive result of no-significant difference in self-report across cultures, we are limited to generalize the result because of small sample size.",
      "keywords": [
        "360\u00b0 videos",
        "Virtual Reality",
        "Valence",
        "EDA",
        "Arousal"
      ],
      "published_in": "VRST '19: 25th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "12 November 2019",
      "citations": "0",
      "isbn": "9781450370011",
      "doi": "10.1145/3359996",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3359996.3364698",
      "paper_url": "https://dl.acm.org/doi/10.1145/3359996.3364698"
    },
    {
      "title": "Sublime: a hands-free virtual reality menu navigation system using a high-frequency SSVEP-based brain-computer interface",
      "authors": ["Alexandre Armengol-Urpi", "Sanjay E. Sarma"],
      "abstract": "In this work we present Sublime, a new concept of Steady-State Visually Evoked Potential (SSVEP) based Brain-Computer Interface (BCI) where brain-computer communication occurs by capturing imperceptible visual stimuli integrated in the virtual scene and effortlessly conveying subliminal information to a computer. The technology was tested in a Virtual Reality (VR) environment, where the subject could navigate between the different menus by just gazing at them. The ratio between the stimuli frequencies and the refresh rate of the VR display creates an undesired perception of beats for which different solutions are proposed. To inform the user of target activation, real-time feedback in the form of loading bars is incorporated under each selectable object. We conducted experiments with several subjects and though the system is slower than a conventional joystick, users reported a satisfactory overall experience, in part due to the unexpected responsiveness of the system, as well as due to the fact that virtual objects flickered at a rate that did not cause annoyance. Since the imperceptible visual stimuli can be integrated unobtrusively to any element of the virtual world, we conclude that the potential applications of Sublime are extensive, especially in situations where knowing user's visual focus can be relevant.",
      "keywords": [
        "virtual reality",
        "electroencephalography",
        "brain-computer interface",
        "steady-state visually evoked potentials"
      ],
      "published_in": "VRST '18: Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "28 November 2018",
      "citations": "1",
      "isbn": "9781450360869",
      "doi": "10.1145/3281505",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3281505.3281514",
      "paper_url": "https://dl.acm.org/doi/10.1145/3281505.3281514"
    },
    {
      "title": "The matrix has you: realizing slow motion in full-body virtual reality",
      "authors": ["Michael Rietzler", "Florian Geiselhart", "Enrico Rukzio"],
      "abstract": "While we perceive time as a constant factor in the real world, it can be manipulated in media. Being quite easy for linear media, this is used for various aspects of storytelling e.g., by applying slow motion in movies or TV. Interactive media like VR however poses additional challenges, because user interaction speed is independent from media speed. While it is still possible to change the speed of the environment, for interaction it is also necessary to deal with the emerging speed mismatch, e.g., by slowing down visual feedback of user movements. In this paper, we explore the possibility of such manipulations of visual cues, with the goal of enabling the use of slow motion also in immersive interactive media like VR. We conducted a user study to investigate the impact of limiting angular velocity of a virtual character in first person view in VR. Our findings show that it is possible to use slow motion in VR while maintaining the same levels of presence, enjoyment and susceptibility to motion sickness, while users adjust to the maximum speed quickly. Moreover, our results also show an impact of slowing down user movements on their time estimations.",
      "keywords": [
        "slow motion",
        "time perception",
        "evaluation",
        "virtual reality"
      ],
      "published_in": "VRST '17: Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "8 November 2017",
      "citations": "10",
      "isbn": "9781450355483",
      "doi": "10.1145/3139131",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3139131.3139145",
      "paper_url": "https://dl.acm.org/doi/10.1145/3139131.3139145"
    },
    {
      "title": "VR safari park: a concept-based world building interface using blocks and world tree",
      "authors": [
        "Shotaro Ichikawa",
        "Kazuki Takashima",
        "Anthony Tang",
        "Yoshifumi Kitamura"
      ],
      "abstract": "We present a concept-based world building approach, realized in a system called VR Safari Park, which allows users to rapidly create and manipulate a world simulation. Conventional world building tools focus on the manipulation and arrangement of entities to set up the simulation, which is time consuming as it requires frequent view and entity manipulations. Our approach focuses on a far simpler mechanic, where users add virtual blocks which represent world entities (e.g. animals, terrain, weather, etc.) to a World Tree, which represents the simulation. In so doing, the World Tree provides a quick overview of the simulation, and users can easily set up scenarios in the simulation without having to manually perform fine-grain manipulations on world entities. A preliminary user study found that the proposed interface is effective and usable for novice users without prior immersive VR experience.",
      "keywords": [
        "concept-based modeling",
        "interaction design",
        "entertainment"
      ],
      "published_in": "VRST '18: Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "28 November 2018",
      "citations": "0",
      "isbn": "9781450360869",
      "doi": "10.1145/3281505",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3281505.3281517",
      "paper_url": "https://dl.acm.org/doi/10.1145/3281505.3281517"
    },
    {
      "title": "Interacting with danger in an immersive environment: issues on cognitive load and risk perception",
      "authors": [
        "Vitor A. M. Jorge",
        "Wilson J. Sarmiento",
        "Anderson Maciel",
        "Luciana Nedel",
        "C\u00e9sar A. Collazos",
        "Frederico Faria",
        "Jackson Oliveira"
      ],
      "abstract": "Any human-computer interface imposes a certain level of cognitive load to the user task. Analogously, the task itself also imposes different levels of cognitive load. It is common sense in 3D user interfaces research that a higher number of degrees of freedom increases the interface cognitive load. If the cognitive load is significant, it might compromise the user performance and undermine the evaluation of user skills in a virtual environment. In this paper, we propose an assessment of two immersive VR interfaces with varying degrees of freedom in two VR tasks: risk perception and basic object selection. We examine the effectiveness of both interfaces in these two different tasks. Results show that the number of degrees of freedom does not significantly affect a basic selection task, but it affects risk perception task in an unexpected way.",
      "keywords": [
        "3D interaction",
        "virtual reality",
        "presence",
        "risk perception"
      ],
      "published_in": "VRST '13: Proceedings of the 19th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "6 October 2013",
      "citations": "6",
      "isbn": "9781450323796",
      "doi": "10.1145/2503713",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2503713.2503725",
      "paper_url": "https://dl.acm.org/doi/10.1145/2503713.2503725"
    },
    {
      "title": "Embodied interaction using non-planar projections in immersive virtual reality",
      "authors": [
        "Henrique G. Debarba",
        "Sami Perrin",
        "Bruno Herbelin",
        "Ronan Boulic"
      ],
      "abstract": "In this paper we evaluate the use of non-planar projections as a means to increase the Field of View (FoV) in embodied Virtual Reality (VR). Our main goal is to bring the virtual body into the user's FoV and to understand how this affects the virtual body/environment relation and quality of interaction. Subjects wore a Head Mounted Display (HMD) and were instructed to perform a selection and docking task while using either Perspective (\u2248 106 \u00b0 vertical FoV), Hammer or Equirectangular (\u2248 180 \u00b0 vertical FoV for both) projection. The increased FoV allowed for a shorter search time as well as less head movements. However, quality of interaction was generally inferior, requiring more time to dock, increasing docking error and producing more body/environment collisions. We also assessed cybersickness and the sense of embodiment toward the virtual body through questionnaires, for which the difference between projections seemed to be less pronounced.",
      "keywords": [
        "sense of embodiment",
        "non-planar projections",
        "immersive interaction"
      ],
      "published_in": "VRST '15: Proceedings of the 21st ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "13 November 2015",
      "citations": "6",
      "isbn": "9781450339902",
      "doi": "10.1145/2821592",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2821592.2821603",
      "paper_url": "https://dl.acm.org/doi/10.1145/2821592.2821603"
    },
    {
      "title": "Fast generation of realistic virtual humans",
      "authors": [
        "Jascha Achenbach",
        "Thomas Waltemate",
        "Marc Erich Latoschik",
        "Mario Botsch"
      ],
      "abstract": "In this paper we present a complete pipeline to create ready-to-animate virtual humans by fitting a template character to a point set obtained by scanning a real person using multi-view stereo reconstruction. Our virtual humans are built upon a holistic character model and feature a detailed skeleton, fingers, eyes, teeth, and a rich set of facial blendshapes. Furthermore, due to the careful selection of techniques and technology, our reconstructed humans are quite realistic in terms of both geometry and texture. Since we represent our models as single-layer triangle meshes and animate them through standard skeleton-based skinning and facial blendshapes, our characters can be used in standard VR engines out of the box. By optimizing for computation time and minimizing manual intervention, our reconstruction pipeline is capable of processing whole characters in less than ten minutes.",
      "keywords": [
        "virtual humans",
        "virtual characters",
        "avatars",
        "3D scanning"
      ],
      "published_in": "VRST '17: Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "8 November 2017",
      "citations": "15",
      "isbn": "9781450355483",
      "doi": "10.1145/3139131",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3139131.3139154",
      "paper_url": "https://dl.acm.org/doi/10.1145/3139131.3139154"
    },
    {
      "title": "TouchSketch: a touch-based interface for 3D object manipulation and editing",
      "authors": [
        "Siju Wu",
        "Amine Chellali",
        "Samir Otmane",
        "Guillaume Moreau"
      ],
      "abstract": "To make constrained manipulation of 3D objects in desktop 3D applications, 3D transformation widgets are commonly used. However, their performance degrades on touchscreens because of low accuracy of touch inputs and the fingertip occlusion problem. In this paper, we present TouchSketch, a touch-based interface which allows users to perform independently fine-grained object translation, rotation and scaling on mobile devices. Our manipulation technique permits using the non-dominant hand to specify the manipulation reference while the dominant hand is used to determine the operation mode and control the transformation. In addition to 3D manipulation, TouchSketch provides also a set of functions to edit the shape of 3D objects. Users can use this application to accomplish rapid sketching tasks. We have conducted a user study to evaluate the efficiency of our manipulation technique. The results show that our technique outperforms a Widget-based technique regarding both the efficiency and fluency.",
      "keywords": [
        "3D object manipulation",
        "touch input",
        "interaction techniques"
      ],
      "published_in": "VRST '15: Proceedings of the 21st ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "13 November 2015",
      "citations": "7",
      "isbn": "9781450339902",
      "doi": "10.1145/2821592",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2821592.2821606",
      "paper_url": "https://dl.acm.org/doi/10.1145/2821592.2821606"
    },
    {
      "title": "HardBorders: a new haptic approach for selection tasks in 3D menus",
      "authors": ["Caroline Essert-Villard", "Antonio Capobianco"],
      "abstract": "In this paper, we introduce a 3D menu with a new technique of haptic guidance, for virtual environments. The 3D menu consists in a thin polyhedral shape, with the items at the corners. The HardBorders technique haptically simulates the collisions of the pointer with the borders of the polyhedron, making it glide towards the items of the menu. A comparison with 2 reference modalities has been performed, showing a clear advantage of our HardBorders technique.",
      "keywords": [
        "3D interaction",
        "force feedback devices",
        "computer-human interfaces",
        "haptic interfaces",
        "menus",
        "virtual reality"
      ],
      "published_in": "VRST '09: Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "18 November 2009",
      "citations": "5",
      "isbn": "9781605588698",
      "doi": "10.1145/1643928",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1643928.1643986",
      "paper_url": "https://dl.acm.org/doi/10.1145/1643928.1643986"
    },
    {
      "title": "Towards seamless interaction between physical and virtual locations for asymmetric collaboration",
      "authors": [
        "Damien Clergeaud",
        "Joan Sol Roo",
        "Martin Hachet",
        "Pascal Guitton"
      ],
      "abstract": "Virtual Reality allows rapid prototyping and simulation of physical artefacts, which would be difficult and expensive to perform otherwise. On the other hand, when the design process is complex and involves multiple stakeholders, decisions are taken in meetings hosted in the physical world. In the case of aerospace industrial designs, the process is accelerated by having asymmetric collaboration between the two locations: experts discuss the possibilities in a meeting room while a technician immersed in VR tests the selected alternatives. According to experts, the current approach is not without limitations, and in this work, we present prototypes designed to tackle them. The described artefacts were created to address the main issues: awareness of the remote location, remote interaction and manipulation, and navigation between locations. First feedback from experts regarding the prototypes is also presented. The resulting design considerations can be used in other asymmetric collaborative scenarios.",
      "keywords": [
        "mixed reality",
        "head mounted display",
        "tangible user interfaces",
        "spatial augmented reality",
        "asymmetric collaboration",
        "virtual reality"
      ],
      "published_in": "VRST '17: Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "8 November 2017",
      "citations": "5",
      "isbn": "9781450355483",
      "doi": "10.1145/3139131",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3139131.3139165",
      "paper_url": "https://dl.acm.org/doi/10.1145/3139131.3139165"
    },
    {
      "title": "Signifier-Based Immersive and Interactive 3D Modeling",
      "authors": [
        "Andreas B\u00e6rentzen",
        "Jeppe Revall Frisvad",
        "Karan Singh"
      ],
      "abstract": "Interactive 3D modeling in VR is both aided by immersive 3D input and hampered by model disjunct, tool-based or selection-action user interfaces. We propose a direct, signifier-based approach to the popular interactive technique of creating 3D models through a sequence of extrusion operations. Motivated by handles and signifiers that communicate the affordances of everyday objects, we define a set of design principles for an immersive, signifier-based modeling interface. We then present an interactive 3D modeling system where all modeling affordances are modelessly reachable and signified on the model itself.",
      "keywords": ["signifiers", "affordances", "3D Modeling"],
      "published_in": "VRST '19: 25th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "12 November 2019",
      "citations": "0",
      "isbn": "9781450370011",
      "doi": "10.1145/3359996",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3359996.3364257",
      "paper_url": "https://dl.acm.org/doi/10.1145/3359996.3364257"
    },
    {
      "title": "Effects of virtual arm representations on interaction in virtual environments",
      "authors": [
        "Tanh Quang Tran",
        "Hyunju Shin",
        "Wolfgang Stuerzlinger",
        "Junghyun Han"
      ],
      "abstract": "Many techniques for visualization and interaction that potentially increase user performance have been studied in the growing field of virtual reality. However, the effects of virtual-arm representations on users' performance and perception in selection tasks have not been studied before. This paper presents the results of a user study of three different representations of the virtual arm: \"hand only,\" \"hand+forearm,\" and \"whole arm\" which includes the upper arm. In addition to the representations' effects on performance and perception in selection tasks, we investigate how the users' performance changes depending on whether collisions with objects are allowed or not. The relationship between the virtual-arm representations and the senses of agency and ownership are also explored. Overall, we found that the \"whole arm\" condition performed worst.",
      "keywords": [
        "3D interaction",
        "natural hand interaction",
        "selection performance",
        "virtual arm",
        "virtual reality"
      ],
      "published_in": "VRST '17: Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "8 November 2017",
      "citations": "3",
      "isbn": "9781450355483",
      "doi": "10.1145/3139131",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3139131.3139149",
      "paper_url": "https://dl.acm.org/doi/10.1145/3139131.3139149"
    },
    {
      "title": "HandNavigator: hands-on interaction for desktop virtual reality",
      "authors": [
        "Paul G. Kry",
        "Adeline Pihuit",
        "Adrien Bernhardt",
        "Marie-Paule Cani"
      ],
      "abstract": "This paper presents a novel interaction system, aimed at hands-on manipulation of digital models through natural hand gestures. Our system is composed of a new physical interaction device coupled with a simulated compliant virtual hand model. The physical interface consists of a SpaceNavigator, augmented with pressure sensors to detect directional forces applied by the user's fingertips. This information controls the position, orientation, and posture of the virtual hand in the same way that the SpaceNavigator uses measured forces to animate a virtual frame. In this manner, user control does not involve fatigue due to reaching gestures or holding a desired hand shape. During contact, the user has a realistic visual feedback in the form of plausible interactions between the virtual hand and its environment. Our device is well suited to any situation where hand gesture, contact, or manipulation tasks need to be performed in virtual. We demonstrate the device in several simple virtual worlds and evaluate it through a series of user studies.",
      "keywords": ["interaction", "hands", "virtual reality"],
      "published_in": "VRST '08: Proceedings of the 2008 ACM symposium on Virtual reality software and technology",
      "publication_date": "27 October 2008",
      "citations": "14",
      "isbn": "9781595939517",
      "doi": "10.1145/1450579",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1450579.1450591",
      "paper_url": "https://dl.acm.org/doi/10.1145/1450579.1450591"
    },
    {
      "title": "Depth information from binocular disparity and familiar size is combined when reaching towards virtual objects",
      "authors": [
        "Rebekka S. Schubert",
        "Mathias M\u00fcller",
        "Sebastian Pannasch",
        "Jens R. Helmert"
      ],
      "abstract": "Reaching movements towards stereoscopically presented virtual objects have been reported to be imprecise. This might be a problem for touch interaction with virtual environments. Estimating the distance to an object in personal space relies on binocular disparity and other depth cues but previous work on the influence of familiar size for reaching and grasping has produced conflicting results. We presented a virtual tennis ball and manipulated binocular disparity as well as the size of the tennis ball. The results suggest that depth information from binocular disparity and from familiar size is combined for reaching movements towards virtual objects. However, subjects differed in the weight they assigned to each depth cue.",
      "keywords": [
        "virtual reality",
        "stereoscopy",
        "distance estimates",
        "reaching",
        "depth perception"
      ],
      "published_in": "VRST '16: Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology",
      "publication_date": "2 November 2016",
      "citations": "2",
      "isbn": "9781450344913",
      "doi": "10.1145/2993369",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2993369.2993408",
      "paper_url": "https://dl.acm.org/doi/10.1145/2993369.2993408"
    },
    {
      "title": "Interactive virtual exhibition: creating custom virtual art galleries using web technologies",
      "authors": ["Saadiq K. Shaik", "Kyungjin Yoo"],
      "abstract": "This paper presents an immersive 3D virtual reality application accessed through the web that allows users to create their own custom virtual art galleries. The application allows users to select paintings based on a time range or country and then it dynamically generates the 3D virtual exhibit. Various features about the exhibit can be customized, such as the floor texture and wall color. Users can also save their exhibit, so it can be shared with others.",
      "keywords": [
        "virtual reality",
        "immersive world",
        "user interface",
        "art gallery"
      ],
      "published_in": "VRST '18: Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "28 November 2018",
      "citations": "1",
      "isbn": "9781450360869",
      "doi": "10.1145/3281505",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3281505.3281579",
      "paper_url": "https://dl.acm.org/doi/10.1145/3281505.3281579"
    },
    {
      "title": "Interactive virtual exhibition: creating custom virtual art galleries using web technologies",
      "authors": ["Saadiq K. Shaik", "Kyungjin Yoo"],
      "abstract": "This paper presents an immersive 3D virtual reality application accessed through the web that allows users to create their own custom virtual art galleries. The application allows users to select paintings based on a time range or country and then it dynamically generates the 3D virtual exhibit. Various features about the exhibit can be customized, such as the floor texture and wall color. Users can also save their exhibit, so it can be shared with others.",
      "keywords": [
        "user interface",
        "immersive world",
        "art gallery",
        "virtual reality"
      ],
      "published_in": "VRST '18: Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "28 November 2018",
      "citations": "0",
      "isbn": "9781450360869",
      "doi": "10.1145/3281505",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3281505.3281619",
      "paper_url": "https://dl.acm.org/doi/10.1145/3281505.3281619"
    },
    {
      "title": "Scenario sharing in a collaborative virtual environment for training",
      "authors": ["St\u00e9phanie Gerbaud", "Bruno Arnaldi"],
      "abstract": "In this paper, we describe a system used in the context of virtual training on collaborative maintenance procedures where the focus is on the learning of the industrial procedure rather than technical gestures. In existing collaborative virtual environments for training the distribution of scenario actions among actors is fixed: only one role can be associated with a given scenario action. In this paper, we propose to overcome this limitation and to add a mechanism to deal with this new flexibility. This mechanism is able to dynamically select the best actor for an action, based on various criteria, and to propose a distribution of actions among actors. We also propose to add collaborative profiles to virtual humans to guide them in order to select the next action to perform, possibly following the distribution suggestion. Trainees and virtual humans can then adapt their activities while respecting the reference procedure.",
      "keywords": ["collaborative scenario", "virtual environment", "training"],
      "published_in": "VRST '08: Proceedings of the 2008 ACM symposium on Virtual reality software and technology",
      "publication_date": "27 October 2008",
      "citations": "1",
      "isbn": "9781595939517",
      "doi": "10.1145/1450579",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1450579.1450603",
      "paper_url": "https://dl.acm.org/doi/10.1145/1450579.1450603"
    },
    {
      "title": "VEAAR: virtual environment for archaeological artefacts restoration",
      "authors": ["Ji\u0159\u00ed Chmel\u00edk", "Mikol\u00e1\u0161 Jurda"],
      "abstract": "This demo presents a virtual environment for assembling archaeological artefacts from 3D scanned fragments. We have implemented a set of interaction techniques tailored to this specific task, allowing users to examine, manipulate and assemble fragments to obtain the original shape of the object. The tool is developed and continuously tested by domain experts from the field of anthropology. The presented pilot user study confirms our initial expectation that the restoration process using a virtual environments can be significantly faster than restoration done in a desktop environment keeping the same level of assembly precision.",
      "keywords": [
        "virtual environment",
        "interaction techniques",
        "user study",
        "archeology",
        "object restoration"
      ],
      "published_in": "VRST '17: Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "8 November 2017",
      "citations": "0",
      "isbn": "9781450355483",
      "doi": "10.1145/3139131",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3139131.3141780",
      "paper_url": "https://dl.acm.org/doi/10.1145/3139131.3141780"
    },
    {
      "title": "Interactive virtual percussion instruments on mobile devices",
      "authors": ["Zhimin Ren", "Ming C. Lin"],
      "abstract": "We present a multimodal virtual percussion instrument system on consumer mobile devices that allows users to design and configure customizable virtual percussion instruments and interact with them in real time. Users can create virtual instruments of different materials and shapes interactively, by editing and selecting the desired characteristics. Both the visual and auditory feedback are then computed on the fly to automatically correspond to the instrument properties and user interaction. We utilize efficient 3D input processing algorithms to approximate and represent real-time multi-touch input with key meta properties and adopt fast physical modeling to synthesize sounds. Despite the relatively limited computing resources on mobile devices, we are able to achieve rich and responsive multimodal feedback based on real-time user input. A pilot study is conducted to assess the effectiveness of the system.",
      "keywords": [],
      "published_in": "VRST '15: Proceedings of the 21st ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "13 November 2015",
      "citations": "1",
      "isbn": "9781450339902",
      "doi": "10.1145/2821592",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2821592.2821616",
      "paper_url": "https://dl.acm.org/doi/10.1145/2821592.2821616"
    },
    {
      "title": "Performance improvement using data tags for handheld spatial augmented reality",
      "authors": [
        "Andrew Irlitti",
        "Stewart Von Itzstein",
        "Ross T. Smith",
        "Bruce H. Thomas"
      ],
      "abstract": "Mobile devices such as some recent phones are now fitted with projection capabilities that support Spatial Augmented Reality (SAR) and require investigation to uncover new interaction possibilities. This paper presents a study measuring user performance in a search and select task using a tracked handheld projector and data tags, a 3D physical cue. This physical cue is used to mark the location of hidden SAR information. The experiment required participants to search for virtual symbols presented on two 5ft, multi-sided control panels. Two methods of presenting AR information were employed, SAR alone and SAR with the inclusion of physical cues to indicate the location of the information. The results showed that attaching data tags, compared to virtual content alone lowered the overall task completion time and reduced handheld projector movement. Subjectively, participants also preferred the combination of virtual data with data tags across both task variations",
      "keywords": [
        "asynchronous collaboration",
        "spatial augmented reality",
        "tangible user interface",
        "physical cues",
        "handheld projector"
      ],
      "published_in": "VRST '14: Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "11 November 2014",
      "citations": "2",
      "isbn": "9781450332538",
      "doi": "10.1145/2671015",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2671015.2671116",
      "paper_url": "https://dl.acm.org/doi/10.1145/2671015.2671116"
    },
    {
      "title": "Automatic transfer of musical mood into virtual environments",
      "authors": ["Sangyoon Han", "Amit Bhardwaj", "Seungmoon Choi"],
      "abstract": "This paper presents a method that automatically transforms a virtual environment (VE) according to the mood of input music. We use machine learning to extract a mood from the music. We then select images exhibiting the mood and transfer their styles to the textures of objects in the VE photorealistically or artistically. Our user study results indicate that our method is effective in transferring valence-related aspects, but not arousal-related ones. Our method can still provide novel experiences in virtual reality and speed up the production of VEs by automating its procedure.",
      "keywords": [
        "affect",
        "virtual environment",
        "transfer",
        "mood",
        "music"
      ],
      "published_in": "VRST '18: Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "28 November 2018",
      "citations": "0",
      "isbn": "9781450360869",
      "doi": "10.1145/3281505",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3281505.3281534",
      "paper_url": "https://dl.acm.org/doi/10.1145/3281505.3281534"
    },
    {
      "title": "Hybrid orbiting-to-photos in 3D reconstructed visual reality",
      "authors": [
        "Benjamin Nuernberger",
        "Tobias H\u00f6llerer",
        "Matthew Turk"
      ],
      "abstract": "Virtually navigating through photos from a 3D image-based reconstruction has recently become very popular in many applications. In this paper, we consider a particular virtual travel maneuver that is important for this type of virtual navigation---orbiting to photos that can see a point-of-interest (POI). The main challenge with this particular type of orbiting is how to give appropriate feedback to the user regarding the existence and information of each photo in 3D while allowing the user to manipulate three degrees-of-freedom (DoF) for orbiting around the POI. We present a hybrid approach that combines features from two baselines---proxy plane and thumbnail approaches. Experimental results indicate that users rated our hybrid approach more favorably for several qualitative questionnaire statements, and that the hybrid approach is preferred over both baselines for outdoor scenes.",
      "keywords": [
        "virtual navigation",
        "3d reconstructed visual reality",
        "orbiting"
      ],
      "published_in": "VRST '18: Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "28 November 2018",
      "citations": "0",
      "isbn": "9781450360869",
      "doi": "10.1145/3281505",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3281505.3281528",
      "paper_url": "https://dl.acm.org/doi/10.1145/3281505.3281528"
    },
    {
      "title": "Analyzing the effect of a virtual avatar's geometric and motion fidelity on ego-centric spatial perception in immersive virtual environments",
      "authors": [
        "Brian Ries",
        "Victoria Interrante",
        "Michael Kaeding",
        "Lane Phillips"
      ],
      "abstract": "Previous work has shown that giving a user a first-person virtual avatar can increase the accuracy of their egocentric distance judgments in an immersive virtual environment (IVE). This result provides one of the rare examples of a manipulation that can enable improved spatial task performance in a virtual environment without potentially compromising the ability for accurate information transfer to the real world. However, many open questions about the scope and limitations of the effectiveness of IVE avatar self-embodiment remain. In this paper, we report the results of a series of four experiments, involving a total of 40 participants, that explore the importance, to the desired outcome of enabling enhanced spatial perception accuracy, of providing a high level of geometric and motion fidelity in the avatar representation. In these studies, we assess participants' abilities to estimate egocentric distances in a novel virtual environment under four different conditions of avatar self-embodiment: a) no avatar; b) a fully tracked, custom-fitted, high fidelity avatar, represented using a textured triangle mesh; c) the same avatar as in b) but implemented with single point rather than full body tracking; and d) a fully tracked but simplified avatar, represented by a collection of small spheres at the raw tracking marker locations. The goal of these investigations is to attain insight into what specific characteristics of a virtual avatar representation are most important to facilitating accurate spatial perception, and what cost-saving measures in the avatar implementation might be possible. Our results indicate that each of the simplified avatar implementations we tested is significantly less effective than the full avatar in facilitating accurate distance estimation; in fact, the participants who were given the simplified avatar representations performed only marginally (but not significantly) more accurately than the participants who were given no avatar at all. These findings suggest that the beneficial impact of providing users with a high fidelity avatar self-representation may stem less directly from the low-level size and motion cues that the avatar embodiment makes available to them than from the cognitive sense of presence that the self-embodiment supports.",
      "keywords": [
        "immersive virtual environments",
        "virtual avatars",
        "presence",
        "spatial perception",
        "head mounted displays"
      ],
      "published_in": "VRST '09: Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "18 November 2009",
      "citations": "31",
      "isbn": "9781605588698",
      "doi": "10.1145/1643928",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1643928.1643943",
      "paper_url": "https://dl.acm.org/doi/10.1145/1643928.1643943"
    },
    {
      "title": "Augmentation techniques for efficient exploration in head-mounted display environments",
      "authors": [
        "Benjamin Bolte",
        "Gerd Bruder",
        "Frank Steinicke",
        "Klaus Hinrichs",
        "Markus Lappe"
      ],
      "abstract": "Physical characteristics and constraints of today's head-mounted displays (HMDs) often impair interaction in immersive virtual environments (VEs). For instance, due to the limited field of view (FOV) subtended by the display units in front of the user's eyes more effort is required to explore a VE by head rotations than for exploration in the real world.In this paper we propose a combination of two augmentation techniques that have the potential to make exploration of VEs more efficient: (1) augmenting the geometric FOV (GFOV) used for rendering the VE, and (2) amplifying head rotations while the user changes her head orientation. In order to identify how much manipulation can be applied without users noticing, we conducted two psychophysical experiments in which we analyzed subjects' ability to discriminate between virtual and real head pitch and roll rotations while three different geometric FOVs were used. Our results show that the combination of both techniques has great potential to support efficient exploration of VEs. We found that virtual pitch and roll rotations can be amplified by 30% and 44% respectively, when the GFOV matches the subject's estimation of the most natural FOV. This leads to a possible reduction of the user's effort required to explore the VE using a combination of both techniques by approximately 25%.",
      "keywords": [
        "head motion perception",
        "geometric field of view",
        "head-mounted displays"
      ],
      "published_in": "VRST '10: Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "22 November 2010",
      "citations": "11",
      "isbn": "9781450304412",
      "doi": "10.1145/1889863",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1889863.1889865",
      "paper_url": "https://dl.acm.org/doi/10.1145/1889863.1889865"
    },
    {
      "title": "Breaking bad behavior: immersive training of class room management",
      "authors": [
        "Marc Erich Latoschik",
        "Jean-Luc Lugrin",
        "Michael Habel",
        "Daniel Roth",
        "Christian Seufert",
        "Silke Grafe"
      ],
      "abstract": "This article presents a fully immersive portable low-cost Virtual Reality system to train classroom management skills. An instructor controls the simulation of a virtual classroom populated with 24 semi-autonomous virtual agents via a desktop-based graphical user interface (GUI). The GUI provides behavior control and trainee evaluation widgets alongside a non-immersive view of the class and the trainee. The trainee's interface uses an Head-Mounted Display (HMD) and earphones for output. A depth camera and the HMD's built-in motion sensors are used for tracking the trainee and for avatar animation. An initial evaluation of both interfaces confirms the system's usefulness, specifically its capability to successfully simulate critical aspects of classroom management.",
      "keywords": [
        "virtual reality training",
        "student simulation",
        "class room management",
        "virtual agent interaction"
      ],
      "published_in": "VRST '16: Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology",
      "publication_date": "2 November 2016",
      "citations": "4",
      "isbn": "9781450344913",
      "doi": "10.1145/2993369",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2993369.2996308",
      "paper_url": "https://dl.acm.org/doi/10.1145/2993369.2996308"
    },
    {
      "title": "Simulation of deformable solids in interactive virtual reality applications",
      "authors": ["Wen Tang", "Tao Ruan Wan"],
      "abstract": "Simulation of deformable objects has become indispensable in many virtual reality applications. Linear finite element algorithms are frequently applied in interactive physics simulation in order to ensure computational efficiency. However, there exists a variety of situations in which higher order simulation accuracy is expected to improve physical behaviors of deformable objects to match their real-world counterparts. For example in the context of virtual surgery, interactive surgical manipulations mandate algorithmic requirements to maintain both interactive frame rates and simulation accuracy, presenting major challenges in simulation methods. In this paper, we present an interactive system for efficient finite element based simulation of hyperplastic solids with more accurate physics behaviors compared with that of standard corotational methods. Our approach begins with a physics model to mitigate drawbacks of the corotational linear elasticity in preserving energy and momenta. A new damping model is presented which takes into account the differential of rotation to compensate the loss of momenta due to rotations. Thus, more accurate simulations can be achieved with this new model, whereas standard corotational methods using rotated damping to handle energy dissipation does not preserve momenta. We then present a real time simulation framework for computing finite element based deformable solids with full capability allowing complex objects to collide and interact with each other. A constrained system is also provided for robust control and the ease of use the simulation system. We demonstrate the parallel implementation to enable realistic and stable physics behaviors of large deformations capable of handling unpredictable user inputs in interactive virtual environments. The implementation details and insights on practical considerations in implementation such as our experience in parallel computation of the physics for mesh-based finite element objects would be useful for people who wish to develop real-time applications in this area.",
      "keywords": [
        "interactive virtual reality technologies",
        "simulation and modeling",
        "physically based animation"
      ],
      "published_in": "VRST '12: Proceedings of the 18th ACM symposium on Virtual reality software and technology",
      "publication_date": "10 December 2012",
      "citations": "0",
      "isbn": "9781450314695",
      "doi": "10.1145/2407336",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2407336.2407351",
      "paper_url": "https://dl.acm.org/doi/10.1145/2407336.2407351"
    },
    {
      "title": "Gain compensation in redirected walking",
      "authors": ["Anh Nguyen", "Federico Cervellati", "Andreas Kunz"],
      "abstract": "Redirected Walking Techniques (RWTs) enable a user to immersively explore a virtual environment larger than the available physical space by real walking. RWTs are based on the use of gains (translational, rotational and curvature), which introduce a mismatch between the virtual and physical trajectories. When these gains are applied within certain thresholds, the \"manipulation\" is unnoticeable and immersion is maintained. Numerous research has been carried out to identify these thresholds and factors that affect them such as walking speed, environment structure or tasks involved. However, it has not been known whether users change their walking behavior when RWTs are applied and if this in turn influences ftheir perception thresholds.In this paper, we investigate the change in users' walking behavior, particularly their walking speed, when translational gains are applied. We call this behavior gain compensation. 17 subjects were invited to play a shopping game where they had to walk 50 straight segments to fetch the ingredients. During each segment, one of the five different translational gains (0.7, 0.9, 1.0, 1.2, 1.4) was randomly applied and users' walking speeds were measured. Results show that there is a negative correlation between walking speed and translational gain.",
      "keywords": ["gain compensation", "redirected walking"],
      "published_in": "VRST '17: Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "8 November 2017",
      "citations": "1",
      "isbn": "9781450355483",
      "doi": "10.1145/3139131",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3139131.3139167",
      "paper_url": "https://dl.acm.org/doi/10.1145/3139131.3139167"
    },
    {
      "title": "Extending recreational environments with a landscape-superimposed display using mixed reality",
      "authors": ["Mamoru Hatanaka", "Rei Hamakawa"],
      "abstract": "Herein, we describe a system that extends recreational experiences by overlaying a virtual landscape of a remote place over the currently experienced real landscape using mixed reality (MR) technology and displaying avatars of other users. There are many recreational activities that can be performed outdoors. However, such activities usually involve some traveling costs, preparation time, and require schedule adjustments. To reduce the impact of these factors, we implemented a system that extends recreational environments, thereby allowing free movement through the manipulation of the visual information using MR.",
      "keywords": ["panorama", "virtual human", "recreation", "mixed reality"],
      "published_in": "VRST '18: Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "28 November 2018",
      "citations": "0",
      "isbn": "9781450360869",
      "doi": "10.1145/3281505",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3281505.3283394",
      "paper_url": "https://dl.acm.org/doi/10.1145/3281505.3283394"
    },
    {
      "title": "Automated interior design using a genetic algorithm",
      "authors": ["Peter K\u00e1n", "Hannes Kaufmann"],
      "abstract": "In this paper, we present a system that automatically populates indoor virtual scenes with furniture objects and optimizes their positions and orientations with respect to aesthetic, ergonomic and functional rules called interior design guidelines. These guidelines are represented as mathematical expressions which form the cost function. Our system optimizes the set of multiple interior designs by minimizing the cost function using a genetic algorithm. Moreover, we extend the optimization to transdimensional space by enabling automatic selection of furniture objects. Finally, we optimize the assignment of materials to the furniture objects to achieve a unified design and harmonious color distribution. We investigate the capability of our system to generate sensible and livable interior designs in a perceptual study.",
      "keywords": [
        "virtual environments",
        "computational design",
        "furniture arrangement",
        "interior design",
        "scene modeling"
      ],
      "published_in": "VRST '17: Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "8 November 2017",
      "citations": "1",
      "isbn": "9781450355483",
      "doi": "10.1145/3139131",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3139131.3139135",
      "paper_url": "https://dl.acm.org/doi/10.1145/3139131.3139135"
    },
    {
      "title": "Dynamic decomposition and integration of degrees of freedom for 3-D positioning",
      "authors": ["Manuel Veit", "Antonio Capobianco", "Dominique Bechmann"],
      "abstract": "In this paper we present a new interaction technique based on degrees of freedom (DoF) decomposition for accurate positioning in virtual reality environments. This technique (called DIOD for Decomposition and Integration Of Degrees of freedom) is based on an adaptation of the Two-Component Model. It provides two different control levels regarding DoF coordination, one integrating and one separating the manipulation of the DoF. Our hypothesis is that each control level is appropriated to a different phase of the positioning task. During the ballistic phase, users manipulate all the dimensions of the task at the same time. However, during the control phase, users try to manipulate specific dimensions individually. The results of a preliminary study we conducted seem to indicate that the DIOD technique is more efficient than existing techniques.",
      "keywords": [
        "experimental study",
        "virtual reality",
        "interaction technique"
      ],
      "published_in": "VRST '10: Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "22 November 2010",
      "citations": "3",
      "isbn": "9781450304412",
      "doi": "10.1145/1889863",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1889863.1889891",
      "paper_url": "https://dl.acm.org/doi/10.1145/1889863.1889891"
    },
    {
      "title": "Freeze-Set-Go interaction method for handheld mobile augmented reality environments",
      "authors": [
        "Gun A. Lee",
        "Ungyeon Yang",
        "Yongwan Kim",
        "Dongsik Jo",
        "Ki-Hong Kim",
        "Jae Ha Kim",
        "Jin Sung Choi"
      ],
      "abstract": "Mobile computing devices are getting popular as a platform for augmented reality (AR) application, and efficient interaction methods for mobile AR environments are considered necessary. Recently, touch interfaces are getting popular and drawing attention as a future standard interface on mobile computing devices. However, accurate touch interactions are not that easy in mobile AR environments where users tend to move and viewpoints easily get shaky. In this paper, the authors suggest a new interaction method for handheld mobile AR environments, named 'Freeze-Set-Go'. The proposed interaction method lets users to 'freeze' the real world view tentatively, and continue to manipulate virtual entities within the AR scene. According to the user experiment, the proposed method turns out to be helping users to interact with mobile AR environments using touch interfaces in a more accurate and comfortable way.",
      "keywords": [
        "touch interaction",
        "augmented reality",
        "handheld interface"
      ],
      "published_in": "VRST '09: Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "18 November 2009",
      "citations": "29",
      "isbn": "9781605588698",
      "doi": "10.1145/1643928",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1643928.1643961",
      "paper_url": "https://dl.acm.org/doi/10.1145/1643928.1643961"
    },
    {
      "title": "Visual feedback techniques for virtual pointing on stereoscopic displays",
      "authors": ["Ferran Argelaguet", "Carlos Andujar"],
      "abstract": "The act of pointing to graphical elements is one of the fundamental tasks in Human-Computer Interaction. In this paper we analyze visual feedback techniques for accurate pointing on stereoscopic displays. Virtual feedback techniques must provide precise information about the pointing tool and its spatial relationship with potential targets. We show both analytically and empirically that current approaches provide poor feedback on stereoscopic displays, resulting in low user performance when accurate pointing is required. We propose a new feedback technique following a camera viewfinder metaphor. The key idea is to locally flatten the scene objects around the pointing direction to facilitate their selection. We present the results of a user study comparing cursor-based and ray-based visual feedback techniques with our approach. Our user studies indicate that our viewfinder metaphor clearly outperforms competing techniques in terms of user performance and binocular fusion.",
      "keywords": ["image-plane selection", "virtual pointer", "raycasting"],
      "published_in": "VRST '09: Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "18 November 2009",
      "citations": "15",
      "isbn": "9781605588698",
      "doi": "10.1145/1643928",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1643928.1643966",
      "paper_url": "https://dl.acm.org/doi/10.1145/1643928.1643966"
    },
    {
      "title": "Adventures in Hologram Space: Exploring the Design Space of Eye-to-eye Volumetric Telepresence",
      "authors": [
        "Rafael Kuffner Dos Anjos",
        "Maur\u00edcio Sousa",
        "Daniel Mendes",
        "Daniel Medeiros",
        "Mark Billinghurst",
        "Craig Anslow",
        "Joaquim Jorge"
      ],
      "abstract": "Modern volumetric projection-based telepresence approaches are capable of providing realistic full-size virtual representations of remote people. Interacting with full-size people may not be desirable due to the spatial constraints of the physical environment, application context, or display technology. However, the miniaturization of remote people is known to create an eye gaze matching problem. Eye-contact is essential to communication as it allows for people to use natural nonverbal cues and improves the sense of \u201cbeing there\u201d. In this paper we discuss the design space for interacting with volumetric representations of people and present an approach for dynamically manipulating scale, orientation and the position of holograms which guarantees eye-contact. We created a working augmented reality-based prototype and validated it with 14 participants.",
      "keywords": [
        "Volumetric Projection",
        "Holograms",
        "Eye-to-eye",
        "Augmented Reality"
      ],
      "published_in": "VRST '19: 25th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "12 November 2019",
      "citations": "1",
      "isbn": "9781450370011",
      "doi": "10.1145/3359996",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3359996.3364244",
      "paper_url": "https://dl.acm.org/doi/10.1145/3359996.3364244"
    },
    {
      "title": "LabDesignAR: configuring multi-camera motion capture systems in augmented reality",
      "authors": [
        "Mehmet Aydin Bayta\u015f",
        "Asim Evren Yanta\u00e7",
        "Morten Fjeld"
      ],
      "abstract": "We present LabDesignAR, an augmented reality application to support the planning, setup, and reconfiguration of marker-based motion capture systems with multiple cameras. LabDesignAR runs on the Microsoft HoloLens and allows the user to place an arbitrary number of virtual \"holographic\" motion capture cameras into an arbitrary space, in situ. The holographic cameras can be arbitrarily positioned, and different lens configurations can be selected to visualize the resulting fields of view and their intersections. Lab-DesignAR also demonstrates a hybrid natural gestural interaction technique, implemented through a fusion of the vision-based hand tracking capabilities of an augmented reality headset and instrumented gesture recognition with an electromyography armband. The source code for LabDesignAR and its supporting components can be found online.",
      "keywords": [
        "natural interaction",
        "hololens",
        "LabDesignAR",
        "augmented reality",
        "motion capture",
        "gestural interaction"
      ],
      "published_in": "VRST '17: Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "8 November 2017",
      "citations": "1",
      "isbn": "9781450355483",
      "doi": "10.1145/3139131",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3139131.3141778",
      "paper_url": "https://dl.acm.org/doi/10.1145/3139131.3141778"
    },
    {
      "title": "A pattern-based modeling framework for simulating human-like pedestrian steering behaviors",
      "authors": ["Nan Hu", "Michael Harold Lees", "Suiping Zhou"],
      "abstract": "In this paper, we propose a new approach to modeling natural steering behaviors of virtual humans. We suspect that a small number of steering strategies are sufficient for generating typical pedestrian behaviors observed in daily-life situations. Through these limited strategies we show that complex steering behaviors are generated by executing appropriate steering strategies at the appropriate time. In our model, decisions on the selection, scheduling and execution of steering strategies in a given situation are based on the matching results between the currently perceived spatial-temporal patterns and the prototypical cases in an agent's experience base. From a modeler's point of view, our approach is intuitive to use. Our model is carefully evaluated through a three-stage validation process, using experimental studies on basic test scenarios, model comparisons under standard but more complex test scenarios, and sensitivity analysis on key model parameters. Experimental results show that our model is able to generate results that reflect the collective efficiency of crowd dynamics and is in agreement with existing literature on pedestrian studies.",
      "keywords": [
        "cognitive modeling",
        "emergent crowd",
        "steering behaviors",
        "agent-based simulation"
      ],
      "published_in": "VRST '13: Proceedings of the 19th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "6 October 2013",
      "citations": "5",
      "isbn": "9781450323796",
      "doi": "10.1145/2503713",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2503713.2503723",
      "paper_url": "https://dl.acm.org/doi/10.1145/2503713.2503723"
    },
    {
      "title": "3D object arrangement for novice users: the effectiveness of combining a first-person and a map view",
      "authors": ["Luca Chittaro", "Roberto Ranon", "Lucio Ieronutti"],
      "abstract": "Arranging 3D objects in Virtual Environments can be a complex, error prone and time consuming task, especially for users who are not familiar with interfaces for 3D navigation and object manipulation. In this paper, we analyze and compare novice users' performance on 3D object arrangement tasks using three interfaces that differ in the views of the 3D environment they provide: the first one is based only on a first-person view; the second one combines the first-person view and a map view in which the zoom level is manually controlled by the user; the third one extends the second with automated assistance in controlling the map zoom level during object manipulation. Our study shows that users without prior experience in 3D object arrangement prefer and actually benefit from having a map view in addition to a first person view in object arrangement tasks.",
      "keywords": [
        "user study",
        "experimental evaluation",
        "3D manipulation",
        "virtual environments"
      ],
      "published_in": "VRST '09: Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "18 November 2009",
      "citations": "5",
      "isbn": "9781605588698",
      "doi": "10.1145/1643928",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1643928.1643967",
      "paper_url": "https://dl.acm.org/doi/10.1145/1643928.1643967"
    },
    {
      "title": "Industrial maintenance with augmented reality: two case studies",
      "authors": [
        "Doris Aschenbrenner",
        "Marc Erich Latoschik",
        "Klaus Schilling"
      ],
      "abstract": "Remote maintenance of industrial manipulators often is performed via telephone support. Recent approaches in the context of the 'Industry 4.0' consider internet technologies and Augmented Reality (AR) to enhance situation awareness between external experts and local service technicians. We present two AR-based case studies: First, a mobile AR architecture based on optical see through glasses is used for an on-site local repair task. Second, a remote architecture based on a portable tablet PC and a high precision tracking system is used to realize an off-site expert access. The to-be-serviced machine is visualized inside of a large area similar to a machinery hall and can be inspected by the experts walking around this virtual plant using the tablet and perspectively correct rendering to understand the production process and the operation context. Both methods have been evaluated in first user studies.",
      "keywords": [
        "situation awareness",
        "maintenance",
        "industrial internet",
        "industry 4.0",
        "augmented reality"
      ],
      "published_in": "VRST '16: Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology",
      "publication_date": "2 November 2016",
      "citations": "2",
      "isbn": "9781450344913",
      "doi": "10.1145/2993369",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2993369.2996305",
      "paper_url": "https://dl.acm.org/doi/10.1145/2993369.2996305"
    },
    {
      "title": "Heat diffusion based dynamic load balancing for distributed virtual environments",
      "authors": ["Yunhua Deng", "Rynson W. H. Lau"],
      "abstract": "Distributed virtual environments (DVEs) are becoming very popular in recent years, due to their application in online gaming and social networking. One of the main research problems in DVEs is on how to balance the workload when a lot of concurrent users are accessing it. There are a number of load balancing methods proposed to address this problem. However, they either spend too much time on optimizing the partitioning process and become too slow or emphasize on efficiency and the repartitioning process becomes too ineffective. In this paper, we propose a new dynamic load balancing approach for DVEs based on the heat diffusion approach which has been studied in other areas and proved to be very effective and efficient for dynamic load balancing. We have two main contributions. First, we propose an efficient cell selection scheme to identify and select appropriate cells for load migration. Second, we propose two heat diffusion based load balancing algorithms, local and global diffusion. Our results show that the new algorithms are both efficient and effective compared with some existing methods, and the global diffusion method performs the best.",
      "keywords": [
        "dynamic repartitioning",
        "dynamic load balancing",
        "heat diffusion",
        "distributed virtual environments"
      ],
      "published_in": "VRST '10: Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "22 November 2010",
      "citations": "14",
      "isbn": "9781450304412",
      "doi": "10.1145/1889863",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1889863.1889910",
      "paper_url": "https://dl.acm.org/doi/10.1145/1889863.1889910"
    },
    {
      "title": "Efficient intrinsic image decomposition for RGBD images",
      "authors": ["Jian Shi", "Yue Dong", "Xin Tong", "Yanyun Chen"],
      "abstract": "Intrinsic image decomposition is a longstanding problem in computer vision. In this paper, we present a novel approach for efficiently decomposing an RGBD image into its reflectance and shading components. A robust super-pixel segmentation method is employed to select piece-wise constant reflectance regions and reduce the total number of unknowns. With the use of depth information, low frequency environment light can be represented by spherical harmonics and solved with super-pixels. After that, pixels that do not belong to any super-pixel are solved based on the super-pixels' shading. Compared to existing works, which often depend on the color Retinex assumption, our algorithm does not require any chromaticity-based constraints and enables us to solve many challenging cases such as color lighting environments and gray-scale textures. We also design an efficient solver for our system, and with our GPU implementation, it achieves 10-23 fps and boosts the decomposition process to real-time performance, enabling a wide range of applications such as dynamic object recoloring, re-texturing and virtual object composition.",
      "keywords": ["intrinsic image", "real-time", "RGBD"],
      "published_in": "VRST '15: Proceedings of the 21st ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "13 November 2015",
      "citations": "9",
      "isbn": "9781450339902",
      "doi": "10.1145/2821592",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2821592.2821601",
      "paper_url": "https://dl.acm.org/doi/10.1145/2821592.2821601"
    },
    {
      "title": "Large scale cut plane: an occlusion management technique for immersive dense 3D reconstructions",
      "authors": ["Annette Mossel", "Christian Koessler"],
      "abstract": "Dense 3D reconstructions of real-world environments become wide spread and are foreseen to act as data base to solve real world problems, such as remote inspections. Therefore not only scene viewing is required but also the ability to interact with the environment, such as selection of a user-defined part of the reconstruction for later usage. However, inter-object occlusion is inherent to large dense 3D reconstructions, due to scene geometry or reconstruction artifacts that might result in object containment. Since prior art lacks approaches for occlusion management in environments that consist of one or multiple (large) continuous surfaces, we propose the novel technique Large Scale Cut Plane that enables segmentation and subsequent selection of visible, partly or fully occluded patches within a large 3D reconstruction, even at far distance. We combine Large Scale Cut Plane with an immersive virtual reality setup to foster 3D scene understanding and natural user interactions. We furthermore present results from a user study where we investigate performance and usability of our proposed technique compared to a baseline technique. Our results indicate Large Scale Cut Plane to be superior in terms of speed and precision, while we found need of improvement of the user interface. The presented investigations has to the authors' best knowledge not been subject to previous research.",
      "keywords": [
        "dense 3D surface reconstruction",
        "immersive virtual reality",
        "occlusion management",
        "3D selection"
      ],
      "published_in": "VRST '16: Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology",
      "publication_date": "2 November 2016",
      "citations": "2",
      "isbn": "9781450344913",
      "doi": "10.1145/2993369",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2993369.2993384",
      "paper_url": "https://dl.acm.org/doi/10.1145/2993369.2993384"
    },
    {
      "title": "Estimation of distance between thumb and forefinger from hand dorsal image using deep learning",
      "authors": ["Takuma Shimizume", "Takeshi Umezawa", "Noritaka Osawa"],
      "abstract": "A three-dimensional virtual object can be manipulated by hand and finger movements with an optical hand tracking device where it is necessary to recognize a posture of one's hand. Conventional hand posture recognition is based on three-dimensional coordinates of fingertips and a skeletal model of the hand [1]. It is difficult for conventional methods to estimate a posture of the hand when a fingertip is hidden from an optical camera. This study, therefore, proposes the estimation of a posture of a hand on the basis of a hand-dorsal image that can be taken even when the hand occludes its fingertips. A regression model that estimates a distance between fingertips of the thumb and forefinger was constructed using a convolution neural network (CNN) [2]. This work evaluated the root mean squared error (RMSE) of estimation. The RMSE of estimation based on a model on the same day was less than 1.8 mm, which shows that the proposed method could be an effective method where self-occlusion is a problem. This study also evaluates the robustness of the learning model to time-variation.",
      "keywords": [
        "3D user interface",
        "convolutional neural network",
        "self-occlusion"
      ],
      "published_in": "VRST '18: Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "28 November 2018",
      "citations": "1",
      "isbn": "9781450360869",
      "doi": "10.1145/3281505",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3281505.3281592",
      "paper_url": "https://dl.acm.org/doi/10.1145/3281505.3281592"
    },
    {
      "title": "A taxonomy of (real and virtual world) display and control interactions",
      "authors": ["Paul Milgram"],
      "abstract": "Interactions between a human operator and objects in his/her world afford a wide range of possible viewing and control options, which can vary with respect to time, space, proximity, and frame of reference. Whereas it is conventionally recognised that essentially any kind of interaction metaphor can in principle be simulated in a virtual environment, modern image processing technology now permits greatly increased flexibility also for real world interactions with indirect viewing, \u00c4\u00ee as the common video camera has gone beyond being a simple eye on the (remote) real world to being an instrument that is able to integrate and interpolate real world images spatially and temporally, in real time.In the talk, I shall propose a framework for classifying viewing and manipulation interactions for any task where visual feed back is provided.The framework involves identifying key components of the environment that are central to the interaction, in terms of the multidimensional couplings among the components, where the configuration and characteristics of the couplings determine the nature of the visual and manual control interactions experienced by the operator. The framework is domain independent, and is intended to be used both to classify current display-control interactions and to identify future areas of research.",
      "keywords": [],
      "published_in": "VRST '09: Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology",
      "publication_date": "18 November 2009",
      "citations": "3",
      "isbn": "9781605588698",
      "doi": "10.1145/1643928",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1643928.1643932",
      "paper_url": "https://dl.acm.org/doi/10.1145/1643928.1643932"
    },
    {
      "title": "A novel method based on color information for scanned data alignment",
      "authors": [
        "Shen Yang",
        "Yue Qi",
        "Fei Hou",
        "Xukun Shen",
        "Qinping Zhao"
      ],
      "abstract": "This paper presents a rapid and robust method to align large sets of range scans captured by a 3D scanner automatically. The method incorporates the color information from the range data into the pairwise registration. Firstly, it detects the features using SIFT (Scale-Invariant Feature Transform) on grayscale images generated from two range scans to align. Then a quasi-dense matching algorithm, based on the match propagation principle, is applied to specify the matching pixel pairs between two images. All matches obtained are mapped to 3D space but in different world coordinates, and fitered by the 3D geometry constraint discovered from the range data. The remaining set of point correspondences is used to estimate the rigid transformation. Finally, a modified ICP (Iterative Closest Point) algorithm is applied to refine the result. The paper also describes a framework to use this alignment method for object reconstruction. The reconstruction proceeds by acquiring several range scans with color information from different directions, following which pair-wise of range data are aligned with the above method selectively and iteratively. Then a model graph containing the correct pair-wise matches is created and a span tree specifying a complete model is constructed. Finally a global optimization is performed to refine the result. This reconstruction technique achieves a robust and high performance in the application of rebuilding the 3D models of culture heritages for virtual museum automatically.",
      "keywords": [
        "3D scanning",
        "coarse registration",
        "automatic registration",
        "multi-view registration"
      ],
      "published_in": "VRST '08: Proceedings of the 2008 ACM symposium on Virtual reality software and technology",
      "publication_date": "27 October 2008",
      "citations": "0",
      "isbn": "9781595939517",
      "doi": "10.1145/1450579",
      "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/1450579.1450622",
      "paper_url": "https://dl.acm.org/doi/10.1145/1450579.1450622"
    }
  ],
  "total_results": 84,
  "total_filtered_results": 84,
  "total_pages": 1
}
