<!DOCTYPE html>
<html lang="en" class="pb-page" data-request-id="3897a812-581c-4b0c-9589-ea04499bdcbc"><head data-pb-dropzone="head"><meta name="pbContext" content=";page:string:Article/Chapter View;ctype:string:Journal Content;issue:issue:10.1080/hihc20.v035.i07;journal:journal:hihc20;article:article:10.1080/10447318.2018.1484054;wgroup:string:Publication Websites;website:website:TFOPB;pageGroup:string:Publication Pages;subPage:string:Full Text;requestedJournal:journal:hihc20" />
<link rel="schema.DC" href="http://purl.org/DC/elements/1.0/" /><meta name="citation_journal_title" content="International Journal of Human–Computer Interaction" /><meta name="dc.Title" content="Comparison of Gaze Cursor Input Methods for Virtual Reality Devices" /><meta name="dc.Creator" content="Mungyeong  Choe" /><meta name="dc.Creator" content="Yeongcheol  Choi" /><meta name="dc.Creator" content="Jaehyun  Park" /><meta name="dc.Creator" content="Hyun K.  Kim" /><meta name="dc.Description" content="Virtual reality (VR) devices have recently become popular; however, research on input methods for VR devices is lacking. The main input methods of current commercial devices can be classified into ..." /><meta name="Description" content="Virtual reality (VR) devices have recently become popular; however, research on input methods for VR devices is lacking. The main input methods of current commercial devices can be classified into ..." /><meta name="dc.Publisher" content="Taylor &amp; Francis" /><meta name="dc.Date" scheme="WTN8601" content="20 Jun 2018" /><meta name="dc.Type" content="research-article" /><meta name="dc.Format" content="text/HTML" /><meta name="dc.Identifier" scheme="publisher-id" content="1484054" /><meta name="dc.Identifier" scheme="doi" content="10.1080/10447318.2018.1484054" /><meta name="dc.Identifier" scheme="submission-id" content="IJHC-D-17-00240" /><meta name="dc.Source" content="https://doi.org/10.1080/10447318.2018.1484054" /><meta name="dc.Language" content="en" /><meta name="dc.Coverage" content="world" /><meta name="dc.Rights" content="© 2018 Taylor &amp; Francis Group, LLC" />
<link rel="meta" type="application/atom+xml" href="https://doi.org/10.1080%2F10447318.2018.1484054" />
<link rel="meta" type="application/rdf+json" href="https://doi.org/10.1080%2F10447318.2018.1484054" />
<link rel="meta" type="application/unixref+xml" href="https://doi.org/10.1080%2F10447318.2018.1484054" />
<title>Full article: Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</title>
<meta charset="UTF-8">
<meta name="robots" content="noarchive" />
<meta name="pb-robots-disabled">

<meta property="og:title" content="Comparison of Gaze Cursor Input Methods for Virtual Reality Devices" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.tandfonline.com/doi/abs/10.1080/10447318.2018.1484054" />
<meta property="og:image" content="https://www.tandfonline.com/doi/cover-img/10.1080/hihc20.v035.i07" />
<meta property="og:site_name" content="Taylor & Francis" />
<meta property="og:description" content="(2019). Comparison of Gaze Cursor Input Methods for Virtual Reality Devices. International Journal of Human&#x2013;Computer Interaction: Vol. 35, No. 7, pp. 620-629." />
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@tandfonline">
<meta name="viewport" content="width=device-width,initial-scale=1" />
<script>var tandfData = {"search":{"hasOpenAccess":true}};</script>
<link rel="stylesheet" type="text/css" href="/wro/j2y2~product.css"><link rel="stylesheet" type="text/css" href="/pb/css/t1594192466000-v1594192466000/head_4_698_1485_2139_2347_7872.css" id="pb-css" data-pb-css-id="t1594192466000-v1594192466000/head_4_698_1485_2139_2347_7872.css" />
<link href="//www.trendmd.com" rel="preconnect" />
<link href="//app.wizdom.ai" rel="preconnect" />
<link href="//connect.facebook.net" rel="preconnect" />
<link href="//go.taylorandfrancis.com" rel="preconnect" />
<link href="//pi.pardot.com" rel="preconnect" />
<link href="//static.hotjar.com" rel="preconnect" />
<link href="//cdn.pbgrd.com" rel="preconnect" />
<link href="//f1-eu.readspeaker.com" rel="preconnect" />
<link href="//www.googleadservices.com" rel="preconnect" />
<link href="https://ajax.googleapis.com" rel="preconnect" />
<link href="https://m.addthis.com" rel="preconnect" />
<link href="https://wl.figshare.com" rel="preconnect" />
<link href="https://pagead2.googlesyndication.com" rel="preconnect" />
<link href="https://www.googletagmanager.com" rel="preconnect" />
<link href="https://www.google-analytics.com" rel="preconnect" />
<script type="text/javascript" src="/wro/j2y2~loadinview.js"></script>
<script type="text/javascript" src="/wro/j2y2~product.js"></script>
<script type="text/javascript">
        window.rsConf={general:{popupCloseTime:8000,usePost:true},params:'//cdn1.readspeaker.com/script/26/webReader/webReader.js?pids=wr'};
    </script>
<script type="application/javascript" src="//f1-eu.readspeaker.com/script/10118/webReader/webReader.js?pids=wr" id="read-speaker" async></script>
<script type="text/javascript" src="//cdn.pbgrd.com/core-tandf.js" async defer></script>
<script data-ad-client="ca-pub-5143040550582507" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script>

<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:864760,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script>
<script>var _prum=[['id','54ff88bcabe53dc41d1004a5'],['mark','firstbyte',(new Date()).getTime()]];(function(){var s=document.getElementsByTagName('script')[0],p=document.createElement('script');p.async='async';p.src='//rum-static.pingdom.net/prum.min.js';s.parentNode.insertBefore(p,s);})();</script>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<script async src="https://www.colwiz.com/pubsol/widget/34000f34a146a2017e2b5acad48d6b07.js"></script>
<link href="//qa.colwiz.com" rel="preconnect" />

<script src="//scholar.google.com/scholar_js/casa.js" async></script>
</head>
<body class="pb-ui">

<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-W2RHRDH');</script>

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W2RHRDH" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>


<div class="skipContent off-screen">
<a href="#top-content-scroll" class="skipToContent" title="Skip to Main Content" tabIndex="0">Skip to Main Content</a>
</div>
<script type="text/javascript">
    if (true) {
        var skipToContent = document.getElementsByClassName("skipToContent");
        if (skipToContent != null) {
            skipToContent[0].onclick = function skipElement() {
                var element = document.getElementById('top-content-scroll');
                if (element == null || element === undefined) {
                    element = document.getElementsByClassName('top-content-scroll').item(0);
                }
                element.setAttribute('tabindex', '0');
                element.focus();
            }
        }
    }
    document.addEventListener("DOMContentLoaded",function(e){
        if(document.getElementsByClassName("mediaThumbnailContainer").length > 0){
            TandfUtils.appendScript(document.body,"/wro/j2y2~jwplayer.js","jwplayer_src",true,true);
        }
    });
</script>
<div id="pb-page-content" data-ng-non-bindable>
<div data-pb-dropzone="main" data-pb-dropzone-name="Main">
<div class="widget pageHeader none  widget-none  widget-compact-all" id="a4d4fdd3-c594-4d68-9f06-b69b8b37ed56">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><header class="page-header">
<div data-pb-dropzone="main">

<div class="widget responsive-layout none  widget-none  widget-compact-all" id="036fa949-dc25-4ffe-9df0-d7daefee281b">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="container">
<div class="row row-xs  ">
<div class="col-xs-1-6 header-index">
<div class="contents" data-pb-dropzone="contents0">

<div class="widget general-image alignLeft header-logo hidden-xs widget-none  widget-compact-horizontal" id="e817489e-2520-418b-a731-b62e247e74df">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-horizontal"><a href="/" title="Taylor and Francis Online">
<img src="/pb-assets/Global/tfo_logo-1444989687640.png" alt="Taylor and Francis Online" />
</a></div>
</div>
</div>
<div class="widget general-image none header-logo hidden-sm hidden-md hidden-lg widget-none  widget-compact-horizontal" id="b3fe8380-8b88-4558-b004-6485d3aea155">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-horizontal"><a href="/">
<img src="/pb-assets/Global/tfo_logo_sm-1459688573210.png" />
</a></div>
</div>
</div>
</div>
</div>
<div class="col-xs-5-6 ">
<div class="contents" data-pb-dropzone="contents1">

<div class="widget layout-inline-content alignRight  widget-none  widget-compact-all" id="a8a37801-55c7-4566-bdef-e4e738967e38">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="inline-dropzone" data-pb-dropzone="content">

<div class="widget layout-inline-content none customLoginBar widget-none" id="fbe90803-b9c8-4bef-9365-cb53cc4bfa0e">
<div class="wrapped ">
<div class="widget-body body body-none "><div class="inline-dropzone" data-pb-dropzone="content">
<div class="widget literatumInstitutionBanner none bannerWidth widget-none" id="3ff4d9f6-0fd0-44d0-89cd-6b16c5bb33ba">
<div class="wrapped ">
<div class="widget-body body body-none "><div class="institution-image-text hidden-xs hidden-sm disable-click">Access provided by<strong> Copenhagen University Library</strong>
</div>
<div class="institution-image logout-institution-image">
</div></div>
</div>
</div>

<div class="widget literatumNavigationLoginBar none  widget-none  widget-compact-all" id="1d69ec8f-0b13-42ca-bc6d-f5a385caf8c4">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="loginBar not-logged-in">
<span class="icon-user"></span>
<a href="/action/showLogin?uri=%2Fdoi%2Ffull%2F10.1080%2F10447318.2018.1484054" class="sign-in-link">
Log in
</a>
<span class="loginSeprator">&nbsp;|&nbsp;</span>
<a href="/action/registration?redirectUri=%2F" class="register-link">
Register
</a>
</div></div>
</div>
</div>
</div></div>
</div>
</div>
<div class="widget eCommerceCartIndicatorWidget none literatumCartLink widget-none" id="9de10bb5-08af-48bc-b9f6-3f6433229f3e">
<div class="wrapped ">
<div class="widget-body body body-none "><a href="/action/showCart?FlowID=1" class="cartLabel">
<span class="hidden-xs hidden-sm visible-tl-inline-block">Cart</span>
<span class="cartItems" data-id="cart-size" role="status">
</span>
</a></div>
</div>
</div>
</div></div>
</div>
</div>
</div>
</div>
</div>
</div></div>
</div>
</div>
</div>
</header></div>
</div>
</div>
<div class="widget pageBody none  widget-none  widget-compact-all" id="35d9ca18-265e-4501-9038-4105e95a4b7d">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all">
<div class="page-body pagefulltext">
<div data-pb-dropzone="main">

<div class="widget responsive-layout none publicationSerialHeader article-chapter-view widget-none  widget-compact-all" id="1728e801-36cd-4288-9f53-392bad29506a">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="container">
<div class="row row-md gutterless ">
<div class="col-md-5-12 search_container ">
<div class="contents" data-pb-dropzone="contents0">
<div class="widget quickSearchWidget none search-customize-width widget-none  widget-compact-all" id="d46e3260-1f5c-4802-821a-28a03a699c82">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="quickSearchFormContainer ">
<form action="/action/doSearch" name="quickSearch" class="quickSearchForm " title="Quick Search" method="get" onsubmit="appendSearchFilters(this)" aria-label="Quick Search"><span class="simpleSearchBoxContainer">
<input name="AllField" class="searchText main-search-field autocomplete" value="" type="search" id="searchText" title="Type search term here" aria-label="Search" placeholder="Enter keywords, authors, DOI, ORCID etc" autocomplete="off" data-history-items-conf="3" data-publication-titles-conf="3" data-publication-items-conf="3" data-topics-conf="3" data-contributors-conf="3" data-fuzzy-suggester="false" data-auto-complete-target="title-auto-complete" />
</span>
<span class="searchDropDownDivRight">
<label for="searchInSelector" class="visuallyhidden">Search in:</label>
<select id="searchInSelector" name="SeriesKey" class="js__searchInSelector">
<option value="hihc20" id="thisJournal" data-search-in="thisJournal">
This Journal
</option>
<option value="" data-search-in="default">
Anywhere
</option>
</select>
</span>
<span class="quick-search-btn">
<input class="mainSearchButton searchButtons pointer" title="Search" role="button" type="submit" value="" aria-label="Search" />
</span></form>
</div>
<div class="advancedSearchLinkDropZone" data-pb-dropzone="advancedSearchLinkDropZone">
<div class="widget general-html alignRight  hidden-xs_sm widget-none  widget-compact-all" id="323e2a31-1c81-4995-bd17-8e149458c214">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><a href="/search/advanced" class="advSearchArticle">Advanced search</a></div>
</div>
</div>
</div></div>
</div>
</div>
</div>
 </div>
<div class="col-md-7-12 serNav_container">
<div class="contents" data-pb-dropzone="contents1">
<div class="widget literatumSeriesNavigation none  widget-none" id="7730bfe1-9fca-4cf4-a6d6-2a0148105437">
<div class="wrapped ">
<div class="widget-body body body-none "><div class="issueSerialNavigation journal">
<div class="cover">
<img data-src='{"type":"image" , "src":"/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/hihc20.v035.i07/20190307-01/hihc20.v035.i07.cover.jpg"}' src="//:0" alt="Publication Cover" width="120" height="156" />
</div>
<div class="info ">
<div class="title-container">
<span class="titleHeading">Journal</span>
<h1>
<a href="/toc/hihc20/current">
International Journal of Human&#x2013;Computer Interaction
</a>
</h1>
<h2>
Volume 35, 2019 - <a href="/toc/hihc20/35/7" class="nav-toc-list">Issue 7</a>
</h2>
</div>
<div class="seriesNavDropZone" data-pb-dropzone="seriesNavDropZone">
<div class="widget general-html none serial-btns smooth-mv widget-none  widget-compact-horizontal" id="753455df-1eeb-47ca-bdc9-e19022075973">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-horizontal"><div class="serial-action">
<a href="http://www.editorialmanager.com/ijhc" class="green submitAnArticle"><span>Submit an article</span></a>
<a href="/toc/hihc20/current" class="jHomepage"><span>Journal homepage</span></a>
</div></div>
</div>
</div>
</div>
</div>
</div></div>
</div>
</div>
</div>
</div>
</div>
</div></div>
</div>
</div>
<div class="widget responsive-layout none  widget-none" id="e42aea8f-434a-4d39-aaef-f56af3ff00dc">
<div class="wrapped ">
<div class="widget-body body body-none "><div class="container">
<div class="row row-md  ">
<div class="col-md-1-1 ">
<div class="contents" data-pb-dropzone="contents0">

<div class="widget literatumDisplayingAccessLogo none  widget-none  widget-compact-all" id="6aacf107-e82d-494d-a14c-0c00bba52560">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="accessLogo">
<div>
<img class="accessIconLocation" data-src='{"type":"image" , "src":"/pb-assets/3rdPartyLogos/accessFull-1452596451717.png"}' src="//:0" alt="Full access" />
</div>
</div></div>
</div>
</div>
</div>
</div>
</div>
</div></div>
</div>
</div>
<div class="widget responsive-layout none publicationContentHeader widget-none  widget-compact-all" id="63f402e4-3498-4709-8d7d-ee8e69f93467">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="container">
<div class="row row-md  ">
<div class="col-md-1-6 ">
<div class="contents" data-pb-dropzone="contents0">
<div class="widget literatumArticleMetricsWidget none  widget-none  widget-compact-vertical" id="5afd8b6d-7e09-43ff-8ad6-afa3764e543c">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-vertical"><div class="articleMetricsContainer">
<div class="content compactView">
<div class="section">
<div class="value">
466
</div>
<div class="title">
Views
</div>
</div>
<div class="section">
<div class="value">
3
</div>
<div class="title">
CrossRef citations to date
</div>
</div>
<div class="section score">
<div class="altmetric-score true">
<div class="value" data="10.1080/10447318.2018.1484054"></div>
<div class="title">
Altmetric
</div>
</div>
</div>
<div class="altmetric-Key hidden" data="be0ef6915d1b2200a248b7195d01ef22"></div>
</div>
</div></div>
</div>
</div>
 </div>
</div>
<div class="col-md-2-3 ">
<div class="contents" data-pb-dropzone="contents1">
<div class="widget literatumPublicationHeader none literatumPublicationTitle widget-none  widget-compact-all" id="fa57727f-b942-4eb8-9ed2-ecfe11ac03f5">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div id="read-speaker-container" style="display: block">
<div id="readspeaker_button1" class="rs_skip rsbtn rs_preserve">
<a href="//app-eu.readspeaker.com/cgi-bin/rsent?customerid=10118&amp;lang=en_us&readclass=rs_readArea&url=https%3A%2F%2Fwww.tandfonline.com%2Fdoi%2Ffull%2F10.1080%2F10447318.2018.1484054" rel="nofollow" class="rsbtn_play" accesskey="L" title="Listen to this page using ReadSpeaker webReader" style="border-radius: 0 11.4px 11.4px 2px;">
<span class="rsbtn_left rsimg rspart"><span class="rsbtn_text"><span>Listen</span></span></span>
<span class="rsbtn_right rsimg rsplay rspart"></span>
</a>
</div>
</div>
<div class="toc-heading">
<h3>
Articles
</h3>
</div>

<h1><span class="NLM_article-title hlFld-title">Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</span></h1><span class="sub-title"><h2></h2></span><div class="literatumAuthors"><div class="publicationContentAuthors"><div class="hlFld-ContribAuthor"><span class="NLM_contrib-group"><span class="contribDegrees "><a class="entryAuthor" href="/author/Choe%2C+Mungyeong">Mungyeong Choe<span class="overlay"> Department of Industrial and Management Engineering, Incheon National University (INU), Yeonsu-gu, Incheon, Republic of Korea<div class="author-extra-info" tabindex="0" data-authorsInfo="{&quot;id&quot; : &quot;B0001&quot;, &quot;hasFull&quot; : &quot;true&quot;}">View further author information</div></span></a>, </span><span class="contribDegrees "><a class="entryAuthor" href="/author/Choi%2C+Yeongcheol">Yeongcheol Choi<span class="overlay"> Department of Industrial and Management Engineering, Incheon National University (INU), Yeonsu-gu, Incheon, Republic of Korea<div class="author-extra-info" tabindex="0" data-authorsInfo="{&quot;id&quot; : &quot;B0002&quot;, &quot;hasFull&quot; : &quot;true&quot;}">View further author information</div></span></a>, </span><span class="contribDegrees corresponding "><a class="entryAuthor" href="/author/Park%2C+Jaehyun">Jaehyun Park<span class="overlay"> Department of Industrial and Management Engineering, Incheon National University (INU), Yeonsu-gu, Incheon, Republic of Korea<span class="corr-sec"><span class="heading">Correspondence</span><span class="corr-email"><i class="fa fa-envelope" style="color: #10147E; padding-right: 7px" aria-hidden="true"></i><span data-mailto="mailto:jaehpark@inu.ac.kr">jaehpark@inu.ac.kr</span></span><br /></span><span class="orcid-author" data="http://orcid.org/0000-0002-5264-6941"><img src="//:0" data-src='{"type":"image","src":"/templates/jsp/images/orcid.png"}' alt="ORCID Icon" title="ORCID Icon" />http://orcid.org/0000-0002-5264-6941</span><div class="author-extra-info" tabindex="0" data-authorsInfo="{&quot;id&quot; : &quot;B0003&quot;, &quot;hasFull&quot; : &quot;true&quot;}">View further author information</div></span></a> <span class="orcid-icon "><a href="http://orcid.org/0000-0002-5264-6941" target="_blank"><img src="//:0" data-src='{"type":"image","src":"/templates/jsp/images/orcid.png"}' alt="ORCID Icon" title="ORCID Icon" /></a></span> &amp; </span><span class="contribDegrees "><a class="entryAuthor" href="/author/Kim%2C+Hyun+K">Hyun K. Kim<span class="overlay"> Department of Industrial and Management Engineering, Pohang University of Science and Technology (POSTECH), Pohang, Gyeongbuk, Republic of Korea<div class="author-extra-info" tabindex="0" data-authorsInfo="{&quot;id&quot; : &quot;B0004&quot;, &quot;hasFull&quot; : &quot;true&quot;}">View further author information</div></span></a></span></span></div></div></div></div>
</div>
</div>
<div class="widget responsive-layout none  widget-none  widget-compact-all" id="5f562208-b1d5-4e5a-81c7-356431240f04">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="container-fluid">
<div class="row row-md gutterless ">
<div class="col-md-1-1 ">
<div class="contents" data-pb-dropzone="contents0">
<div class="widget layout-inline-content none  widget-none  widget-compact-all" id="87ac5840-18fa-4a14-8eca-065b90ede3d7">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="inline-dropzone" data-pb-dropzone="content">
<div class="widget literatumContentItemPageRange none  widget-none  widget-compact-all" id="45057865-d60c-414c-bc81-646debb621b0">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><span class="contentItemPageRange">Pages 620-629
</span></div>
</div>
</div>
<div class="widget literatumContentItemHistory none  widget-none  widget-compact-all" id="32bf868e-52ce-411a-9dc3-717743aad997">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div>Published online: 20 Jun 2018</div></div>
</div>
</div>

<div class="widget literatumArticleToolsWidget none  widget-none  widget-compact-all" id="ed673666-7b5d-470e-bd33-c5c679d996cb">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="articleTools">
<ul class="linkList blockLinks separators centered">
<li class="downloadCitations">
<a href="/action/showCitFormats?doi=10.1080%2F10447318.2018.1484054"><i class="fa fa-quote-left" aria-hidden="true"></i>Download citation</a>
</li>
<li class="dx-doi">
<a href="https://doi.org/10.1080/10447318.2018.1484054"><i class="fa fa-external-link-square" style="margin: 0 0.25rem 0 0" aria-hidden="true"></i>https://doi.org/10.1080/10447318.2018.1484054</a>
</li>
<li class="cross-mark">
<a id="crossMark" data-doi="10.1080/10447318.2018.1484054" data-target="crossmark">
<img data-src='{"type":"image" , "src":"/templates/jsp/images/CROSSMARK_Color_horizontal.svg"}' src="//:0" alt="CrossMark Logo" width="100" />
<span aria-describedby="crossMark-description"><span class="off-screen" id="crossMark-description">CrossMark</span></span>
</a>
</li>
</ul>
</div></div>
</div>
</div>
</div></div>
</div>
</div>
</div>
</div>
</div>
</div></div>
</div>
</div>
</div>
</div>
<div class="col-md-1-6 ">
<div class="contents" data-pb-dropzone="contents2">
</div>
</div>
</div>
</div></div>
</div>
</div>
<div class="widget responsive-layout none publicationContentBody widget-none" id="f4a74f7a-9ba2-4605-86b1-8094cb1f01de">
<div class="wrapped ">
<div class="widget-body body body-none "><div class="container">
<div class="row row-md  ">
<div class="col-md-1-6 ">
<div class="contents" data-pb-dropzone="contents0">
<div class="widget sectionsNavigation none  widget-none" id="f15bd2de-bb18-4067-8ab9-03ea3be30bf7">
<div class="wrapped ">
<div class="widget-body body body-none "><div class="sections-nav"><span class="title">In this article<a href="#" class="close" tabindex="-1"><span aria-describedby="close-description"><span class="off-screen" id="close-description">Close</span></span></a></span><ul class="sections-list"><li><a href="#abstract">ABSTRACT</a></li><li><span class="sub-art-heading"><a href="#_i2">1. Introduction</a></span><ul class="sub-art-titles"></ul></li><li><span class="sub-art-heading"><a href="#_i3">2. Related works</a></span><ul class="sub-art-titles"></ul></li><li><span class="sub-art-heading"><a href="#_i6">3. Method</a></span><ul class="sub-art-titles"></ul></li><li><span class="sub-art-heading"><a href="#_i20">4. Results</a></span><ul class="sub-art-titles"></ul></li><li><span class="sub-art-heading"><a href="#_i31">5. Discussion</a></span><ul class="sub-art-titles"></ul></li><li><span class="sub-art-heading"><a href="#_i37">6. Conclusion</a></span><ul class="sub-art-titles"></ul></li><li><a href="#references-Section">References</a></li></ul></div></div>
</div>
</div>
</div>
</div>
<div class="col-md-7-12 ">
<div class="contents" data-pb-dropzone="contents1">

<div class="widget responsive-layout none rs_readArea widget-none  widget-compact-all" id="9751b4f9-64b9-44c0-955b-f75246902839">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="container-fluid">
<div class="row row-md  ">
<div class="col-md-1-1 ">
<div class="contents" data-pb-dropzone="contents0">

<div class="widget literatumPublicationContentWidget none rs_preserve widget-none  widget-compact-all" id="d29f04e9-776c-4996-a0d8-931023161e00">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    MathJax.Hub.Config({
        "HTML-CSS": {scale: 70, linebreaks: {automatic: true, width: "container"}},
        SVG: {linebreaks: {automatic: true, width: "25%"}},
        menuSettings: {zoom: "Click"},

        /* This is necessary to lazy loading. */
        skipStartupTypeset: true
    });
</script>
<div class="articleMeta ja">
<div class="tocHeading">
<h2>Articles</h2>
</div>
<div class="hlFld-Title">
<div class="publicationContentTitle">
<h1 class="chaptertitle">
Comparison of Gaze Cursor Input Methods for Virtual Reality Devices
</h1>
</div>
</div>
<div class="copyrightStatement">
</div>
<div class="articleMetaDrop publicationContentDropZone" data-pb-dropzone="articleMetaDropZone">
</div>
<div class="articleMetaDrop publicationContentDropZone publicationContentDropZone1" data-pb-dropzone="articleMetaDropZone1">
</div>
<div class="copyrightline">
</div>
<div class="articleMetaDrop publicationContentDropZone publicationContentDropZone2" data-pb-dropzone="articleMetaDropZone2">
</div>
</div>
<div class="publication-tabs ja publication-tabs-dropdown">
<div class="tabs tabs-widget">
<ul class="tab-nav" role="tablist">
<li class="active" role="tab">
<a href="/doi/full/10.1080/10447318.2018.1484054?scroll=top&amp;needAccess=true" class="show-full">
<i class="fa fa-file-text" aria-hidden="true"></i>
<span class="nav-data">
Full Article
</span>
</a>
</li>
<li role="tab">
<a href="/doi/figure/10.1080/10447318.2018.1484054?scroll=top&amp;needAccess=true" class="show-figure">
<i class="fa fa-image" aria-hidden="true"></i>
<span class="nav-data">Figures & data</span>
</a>
</li>
<li role="tab">
<a href="/doi/ref/10.1080/10447318.2018.1484054?scroll=top" class="show-references">
<i class="fa fa-book" aria-hidden="true"></i>
<span class="nav-data">References</span>
</a>
</li>
<li class="citedbyTab " role="tab">
<a href="/doi/citedby/10.1080/10447318.2018.1484054?scroll=top&amp;needAccess=true">
<i class="fa fa-quote-left" aria-hidden="true"></i>
<span class="nav-data">
Citations
</span>
</a>
</li>
<li class="off-screen"></li>
<li role="tab" class="metrics-tab">
<a href="#metrics-content" class="show-metrics">
<i class="fa fa-bar-chart" aria-hidden="true"></i>
<span class="nav-data">Metrics</span>
</a>
</li>
<li role="tab" class="permissions-tab ">
<a href="/doi/abs/10.1080/10447318.2018.1484054?tab=permissions&amp;scroll=top" class="show-permissions">
<i class="fa fa-print" aria-hidden="true"></i>
<span class="nav-data">
Reprints & Permissions</span></a>
</li>
<li class="pdf-tab " role="button">
<a href="/doi/pdf/10.1080/10447318.2018.1484054?needAccess=true" class="show-pdf" target="_blank">
<span class="nav-data">
PDF
</span>
</a>
</li>
</ul>
<div class="tab-content ">
<a id="top-content-scroll"></a>
<div class="tab tab-pane active">
<article class="article">
<p class="fulltext"></p><div class="hlFld-Abstract"><p class="fulltext"></p><div class="sectionInfo abstractSectionHeading"><h2 id="abstract" class="section-heading-2">ABSTRACT<div id="mathJaxToggle" class="hideElement"><label for="mathJaxToggle"><span>Formulae display:</span><input type="checkbox" id="mathJaxToggleCheck" name="mathJaxToggleCheck" /></label><span class="mathJaxLogo"><img src="//:0" data-src='{"type":"image","src":"/templates/jsp/_style2/_tandf/pb2/images/math-jax.gif"}' alt="MathJax Logo" /><span class="qMrk">?</span><span class="auPopUp hideElement"><span class="pointyEdge"></span>Mathematical formulae have been encoded as MathML and are displayed in this HTML version using MathJax in order to improve their display. Uncheck the box to turn MathJax off. This feature requires Javascript. Click on a formula to zoom.</span></span></div><span class="math-settings hidden-lg"></span></h2></div><div class="abstractSection abstractInFull"><p class="summary-title"><b>ABSTRACT</b></p><p>Virtual reality (VR) devices have recently become popular; however, research on input methods for VR devices is lacking. The main input methods of current commercial devices can be classified into two categories: manual selection using a controller and gaze selection. This study aims to derive the optimal input method and timing for VR devices by analyzing the performance of these input methods. A study is conducted in which participants wear a VR headset and select an activated input button from a 3 × 3 array on a VR device with two button sizes and two input methods. The manual selection method exhibits a shorter task completion time but a greater error number compared to the gaze selection method. For the gaze selection method, the task completion time and target search time were shortest when the gaze timing was 1 s. Further, the button size was determined to be statistically significant only when the manual selection method was used. The results of this study can be used as a reference in future VR user experience and product design.</p></div></div><div class="hlFld-Fulltext"><div id="S0001" class="NLM_sec NLM_sec-type_intro NLM_sec_level_1"><h2 id="_i2" class="section-heading-2">1. Introduction</h2><p>Virtual reality (VR) is a technology that can allow users to experience realistic, artificially created virtual spaces (Chryssolouris, Mavrikios, Fragos, &amp; Karabatsou, <span class="ref-lnk lazy-ref"><a data-rid="CIT0012" data-refLink="_i38" href="#">2000</a></span>). VR provides users with immersive, diverse, and novel experiences. Because VR environments have no space constraints, the utilization of VR devices is expected to increase gradually in the future. VR devices are currently being released by global IT companies, and their market share of VR devices among all display-based devices is predicted to increase (Statista, <span class="ref-lnk lazy-ref"><a data-rid="CIT0039" data-refLink="_i38" href="#">2016</a></span>).</p><p>VR devices have a long development history, and early VR was less realistic than the present technology because, in early VR devices, users experienced virtual spaces through a two-dimensional (2D) screen (Bowman &amp; McMahan, <span class="ref-lnk lazy-ref"><a data-rid="CIT0009" data-refLink="_i38" href="#">2007</a></span>). In 1968, Sutherland (<span class="ref-lnk lazy-ref"><a data-rid="CIT0045" data-refLink="_i38" href="#">1968</a></span>) proposed a head-mounted display (HMD) system that allowed researchers to develop more stereoscopic content. In recent years, with the introduction of VR headsets that use a smartphone as the display (Steed &amp; Julier, <span class="ref-lnk lazy-ref"><a data-rid="CIT0042" data-refLink="_i38" href="#">2013</a></span>), VR devices with high resolution and fast response became widely accessible.</p><p>Since VR has a relatively long history, significant research has been conducted on various aspects of the field. Efforts have been made to define and eliminate common ergonomic problems in VR environments (Mon-Williams, Plooy, Burgess-Limerick, &amp; Wann, <span class="ref-lnk lazy-ref"><a data-rid="CIT0026" data-refLink="_i38" href="#">1998</a></span>; Stanney, Mourant, &amp; Kennedy, <span class="ref-lnk lazy-ref"><a data-rid="CIT0038" data-refLink="_i38" href="#">1998</a></span>), evaluate interface usability, develop elemental technology to increase immersion, and apply new input methods.</p><p>The emergence of new interfaces has been accompanied by usability evaluation studies (Bach &amp; Scapin, <span class="ref-lnk lazy-ref"><a data-rid="CIT0005" data-refLink="_i38" href="#">2010</a></span>; Kim, Han, Park, &amp; Park, <span class="ref-lnk lazy-ref"><a data-rid="CIT0022" data-refLink="_i38" href="#">2015</a></span>). For example, research and development related to interface design suitable for 2D and 3D environments is ongoing (de Haan, Griffith, Koutek, &amp; Post, <span class="ref-lnk lazy-ref"><a data-rid="CIT0013" data-refLink="_i38" href="#">2006</a></span>). In addition, new usability evaluation methods have been proposed (Gabbard, Hix, &amp; Swan, <span class="ref-lnk lazy-ref"><a data-rid="CIT0016" data-refLink="_i38" href="#">1999</a></span>; Stanney, Mollaghasemi, Reeves, Breaux, &amp; Graeber, <span class="ref-lnk lazy-ref"><a data-rid="CIT0037" data-refLink="_i38" href="#">2003</a></span>; Sutcliffe &amp; Kaur, <span class="ref-lnk lazy-ref"><a data-rid="CIT0044" data-refLink="_i38" href="#">2000</a></span>). For example, the principle that a designer should minimize after-effects such as motion sickness has been added to usability evaluation.</p><p>As VR technology has developed, efforts have been made to improve users’ feelings of immersion. Studies have been conducted to reflect the movements of the head and body, such as the development of a mechanism that reflects real-time head movement and associated technology for its application (LaValle, Yershova, Katsev, &amp; Antonov, <span class="ref-lnk lazy-ref"><a data-rid="CIT0024" data-refLink="_i38" href="#">2014</a></span>; Westerman, Cribbin, &amp; Wilson, <span class="ref-lnk lazy-ref"><a data-rid="CIT0048" data-refLink="_i38" href="#">2001</a></span>). A study on technology for sensing physical movement has also been conducted (Bolton, Lambert, Lirette, &amp; Unsworth, <span class="ref-lnk lazy-ref"><a data-rid="CIT0007" data-refLink="_i38" href="#">2014</a></span>), along with investigations of the immersiveness of a platform that enhances realism by increasing the field of view (Hwang, Jung, &amp; Kim, <span class="ref-lnk lazy-ref"><a data-rid="CIT0018" data-refLink="_i38" href="#">2006</a></span>; Yang &amp; Kim, <span class="ref-lnk lazy-ref"><a data-rid="CIT0049" data-refLink="_i38" href="#">2010</a></span>). Research on input tasks has also been performed. Moreover, methodologies for implementing and controlling buttons on a VR or augmented reality (AR) system have been investigated (Alkemade, Verbeek, &amp; Lukosch, <span class="ref-lnk lazy-ref"><a data-rid="CIT0001" data-refLink="_i38" href="#">2017</a></span>; Aslandere, Dreyer, &amp; Pankratz, <span class="ref-lnk lazy-ref"><a data-rid="CIT0003" data-refLink="_i38" href="#">2015</a></span>; Morimoto, Miyajima, Itou, &amp; Takeda, <span class="ref-lnk lazy-ref"><a data-rid="CIT0027" data-refLink="_i38" href="#">2007</a></span>), including the study of input tasks such as navigation, selection, and manipulation; system control in general 3D environments (Jankowski &amp; Hachet, <span class="ref-lnk lazy-ref"><a data-rid="CIT0020" data-refLink="_i38" href="#">2015</a></span>); and general input tasks in VR environments (Steed, <span class="ref-lnk lazy-ref"><a data-rid="CIT0041" data-refLink="_i38" href="#">2006</a></span>).</p><p>As previously mentioned, studies on various topics including input tasks have been conducted in the VR field. However, with the recent popularization of VR headsets, new research has become necessary. Input methods that have not been closely analyzed before have now become primary input methods. In VR, the two major input methods are (1) input via a separate controller (e.g., the Xbox 360 gamepad or Wii remote) (Ardito et al. <span class="ref-lnk lazy-ref"><a data-rid="CIT0002" data-refLink="_i38" href="#">2009</a></span>; Chow, <span class="ref-lnk lazy-ref"><a data-rid="CIT0011" data-refLink="_i38" href="#">2008</a></span>) and (2) input by gazing at a target for a certain period of time (Sidorakis, Koulieris, &amp; Mania, <span class="ref-lnk lazy-ref"><a data-rid="CIT0034" data-refLink="_i38" href="#">2015</a></span>). An input method that uses eye tracking technology has also been developed; however, it has not been actively commercialized yet (Hollomon, Kratchounova, Newton, Gildea, &amp; Knecht, <span class="ref-lnk lazy-ref"><a data-rid="CIT0017" data-refLink="_i38" href="#">2017</a></span>). For reference, gaze-based input methods for HMD-based VR apparatus do not require the use of the hand. Therefore, gaze-based input methods are being used as substitutes for the controller input method in situations where the user cannot use their hands.</p><p>The goal of this study is to evaluate the performance (i.e., execution time and accuracy) of two input methods for a VR headset to determine (1) the superior input method in terms of task performance and (2) whether it is possible to derive the optimum time for maximum input usability. It is expected that the results of this study will be used as a guideline when designing input tasks in VR environments.</p></div><div id="S0002" class="NLM_sec NLM_sec_level_1"><h2 id="_i3" class="section-heading-2">2. Related works</h2><p>To date, the investigation of the relationship between the interface and task performance for devices featuring input devices has been regarded as important basic research for device usability. Consequently, studies on the effect of button size, position, and input method on task performance (i.e., the task time and error) have been conducted for devices with relatively large displays, such as kiosks or devices with large liquid crystal displays (Kim, Kwon, Heo, Lee, &amp; Chung, <span class="ref-lnk lazy-ref"><a data-rid="CIT0021" data-refLink="_i38" href="#">2014</a></span>; Schedlbauer, <span class="ref-lnk lazy-ref"><a data-rid="CIT0032" data-refLink="_i38" href="#">2007</a></span>), or for devices with small touchscreens, such as personal digital assistants and smartphones (Parhi, Karlson, &amp; Bederson, <span class="ref-lnk lazy-ref"><a data-rid="CIT0029" data-refLink="_i38" href="#">2006</a></span>; Park &amp; Han, <span class="ref-lnk lazy-ref"><a data-rid="CIT0030" data-refLink="_i38" href="#">2010</a></span>; Trudeau, Asakawa, Jindrich, &amp; Dennerlein, <span class="ref-lnk lazy-ref"><a data-rid="CIT0046" data-refLink="_i38" href="#">2016</a></span>). As these studies can be referenced for basic data to design the hardware or software of a device, related research has been conducted continuously as new devices have been introduced.</p><p>Head tracking is a method of visually indicating cursor proximity to a target by calculating the head-pointing angle at each moment (So and Griffin <span class="ref-lnk lazy-ref"><a data-rid="CIT0035" data-refLink="_i38" href="#">2000</a></span>), and this technology is also applied for VR HMDs. Thus, studies investigating head tracking performance have been conducted for various input tasks. For example, Jagacinski and Monk (<span class="ref-lnk lazy-ref"><a data-rid="CIT0019" data-refLink="_i38" href="#">1985</a></span>) compared the time taken to select a target using a joystick with that using head tracking through a technique in which the head position is measured using a helmet-mounted infrared beam. Borah (<span class="ref-lnk lazy-ref"><a data-rid="CIT0008" data-refLink="_i38" href="#">1995</a></span>) compared the task completion times of four input methods: a mouse, point-of-gaze control, head position control, and a complementary method of head control for fine positioning of point-of-gaze control. However, most of these studies on head tracking have examined methods to control a cursor displayed on a monitor, and few studies have been conducted for complete VR environments.</p><p>Fitts’ law is used as a method to estimate the time taken to move from the starting point to the target in the task of pointing to the target (Fitts, <span class="ref-lnk lazy-ref"><a data-rid="CIT0015" data-refLink="_i38" href="#">1954</a></span>). This model is actively used in the field of human–computer interaction because it can be effectively applied to a task of moving virtual pointers or a part of the body, such as a finger or foot, from the starting point to the target. In this model, the index of difficulty (ID) of the task is expressed through the width of the target (W) and the distance from the starting point to the target (D). The difficulty of the task increases as the target size decreases and the distance to the target increases. Fitts’ law is summarized as a model that describes the correlation between ID and the movement time (<i>MT</i>) as follows: <disp-formula-group id="M0001"><span class="NLM_disp-formula-image disp-formula"><noscript><img src="/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/hihc_a_1484054_m0001.gif" alt="" /></noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/hihc_a_1484054_m0001.gif&quot;}" /><span class="mml-formula"><span class="disp_formula_label_div"><span id="" class="disp-formula-label">(1) </span></span></span></span><span class="NLM_disp-formula disp-formula"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}" /><math overflow="scroll" altimg="eq-00001.gif"><mi>M</mi><mi>T</mi><mo>=</mo><mi>a</mi><mo>+</mo><mi>b</mi><mfenced open="(" close=")"><mrow><mrow><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow></mrow></mrow></mfenced><mo>.</mo></math><span class="mathjaxLabel"><span class="disp_formula_label_div"><span id="" class="disp-formula-label">(1) </span></span></span></span></disp-formula-group></p><p>Here, the intercept <i>a</i> and slope <i>b</i> are the coefficients determined in the process of making a linear regression model of the relationship between ID and MT. The intercept <i>a</i> indicates the time required to use the device regardless of the ID value, and <i>b</i> represents the degree to which the device affects the ID value. Therefore, for smaller values of <i>a</i> and <i>b</i>, the movement time is less influenced by the device. In this case, the inverse of <i>b</i> refers to the amount of information that the device transmits per second. It is also referred to as the index of performance (IP), which quantifies the performance of the device.</p><p>Different researchers have used slightly different definitions of ID. In this study, the Shannon formula proposed by MacKenzie is used for ID (MacKenzie, <span class="ref-lnk lazy-ref"><a data-rid="CIT0025" data-refLink="_i38" href="#">1992</a></span>): <disp-formula-group id="M0002"><span class="NLM_disp-formula-image disp-formula"><noscript><img src="/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/hihc_a_1484054_m0002.gif" alt="" /></noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/hihc_a_1484054_m0002.gif&quot;}" /><span class="mml-formula"><span class="disp_formula_label_div"><span id="" class="disp-formula-label">(2) </span></span></span></span><span class="NLM_disp-formula disp-formula"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}" /><math overflow="scroll" altimg="eq-00002.gif"><mi>M</mi><mi>T</mi><mo>=</mo><mi>a</mi><mo>+</mo><mi>b</mi><mo>∗</mo><mrow><mrow><msub><mo form="prefix">log</mo><mn>2</mn></msub></mrow></mrow><mo stretchy="false">(</mo><mrow><mfrac><mi>D</mi><mi>W</mi></mfrac></mrow><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></math><span class="mathjaxLabel"><span class="disp_formula_label_div"><span id="" class="disp-formula-label">(2) </span></span></span></span></disp-formula-group></p><p>Soukoreff, Zhao, and Ren (<span class="ref-lnk lazy-ref"><a data-rid="CIT0036" data-refLink="_i38" href="#">2011</a></span>) noted that, although the ID of this formula does not reflect entropy, it is theoretically and empirically preferable to other definitions.</p></div><div id="S0003" class="NLM_sec NLM_sec_level_1"><h2 id="_i6" class="section-heading-2">3. Method</h2><div id="S0003-S2001" class="NLM_sec NLM_sec_level_2"><h3 class="section-heading-3" id="_i7">3.1. Participants</h3><p>Data were collected from a total of 24 participants (12 male and 12 female) whose ages ranged from 21 to 27 years, with an average of 23.0 (± 1.2) years. All participants had sufficient sight to complete the experiment and did not report any inconvenience or problems when using the VR device. Three participants performed the experiment while wearing their own glasses. Each participant performed a visual correction task to adjust the lens distance of the device before the experiments so that the VR screen could be seen clearly. Five participants stated that they had previously used a VR device in the preliminary questionnaire and three reported that they owned a VR headset (all three had a Samsung Gear VR).</p></div><div id="S0003-S2002" class="NLM_sec NLM_sec_level_2"><h3 class="section-heading-3" id="_i8">3.2. Apparatus</h3><p>A Samsung Electronics Gear VR (Model: SM-R322, Republic of Korea) was used to perform this experiment. The Gear VR HMD provides a viewing angle of 96°. The device is equipped with a smartphone connected to the VR equipment’s micro five-pin socket. The smartphone installed in the device was a Samsung Galaxy S7 (Model: SM-G930), which has a resolution of 2560 × 1440, providing a sufficient test screen to proceed with the experiment. To conduct this experiment, the experimental application was run on the smartphone, which was mounted in the VR headset. The prototype application was designed and implemented using Unity and C#.</p></div><div id="S0003-S2003" class="NLM_sec NLM_sec_level_2"><h3 class="section-heading-3" id="_i9">3.3. Experiment area and button size</h3><p>The experiment area and button size were determined assuming a situation in which the user operates the 3 × 4 virtual keypad of the smartphone (having buttons similar in physical size to a number button on a traditional phone), which is one of the most common input methods in daily life. The results of this study are also likely to hold for numerical input, and other input items will be examined in future studies.</p><p>First, the diagonal viewing angle of the smartphone was assumed to be 27° 7’. A study by Bababekova, Rosenfield, Hue, and Huang (<span class="ref-lnk lazy-ref"><a data-rid="CIT0004" data-refLink="_i38" href="#">2011</a></span>) determined that the distance from the eyes to the device is 32.2–36.2 cm when using a smartphone in a typical environment, including text input tasks. Additionally, the screen sizes of recently developed mobile devices are generally 4–6 inches (e.g., Apple iPhone 7: 4.7”, Apple iPhone 7+: 5.5”, Samsung Galaxy S7: 5.1”, and Samsung Galaxy Note 5: 5.7”). Considering these two factors, the diagonal viewing angle of the experiment area was set to the largest value of the derived alternatives. The sizes of the secondary buttons were based on the length of the large side of the smartphone’s 3 × 4 virtual keypad button. Therefore, the widths of the small buttons were set to 1° 55′. To keep the large button sizes at a value sufficiently larger than the small button sizes in consideration of the VR environment, the small button size was doubled (i.e., 3° 50′) (<a href="#F0001">Figure 1</a>). <a href="#F0002">Figure 2</a> shows an example of the entire experimental area and the viewing angle for the large buttons. However, note that button size was not a major factor in this study. However, considering that performance may vary depending on button size, its effect will be discussed in a later study.<div class="figure figureViewer" id="F0001"><div id="figureViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="figureThumbnailContainer"><div class="figureInfo"><td align="left" valign="top" width="100%"><div class="short-legend"><p><span class="captionLabel">Figure 1. </span> An example of target buttons (left: large buttons, right: small buttons).</p></div></td></div><a href="#" class="thumbnail"><img id="F0001image" src="//:0" data-src='{"type":"image","src":"/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/medium/hihc_a_1484054_f0001_oc.jpg"}' /></a><div class="figureDownloadOptions"><a href="#" class="downloadBtn btn btn-sm" id="displaySizeFig" role="button">Display full size</a></div></div></div><div class="hidden rs_skip" id="fig-description-F0001"><p><span class="captionLabel">Figure 1. </span> An example of target buttons (left: large buttons, right: small buttons).</p></div><div class="hidden rs_skip" id="figureFootNote-F0001"></div><div class="figure figureViewer" id="F0002"><div id="figureViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="figureThumbnailContainer"><div class="figureInfo"><td align="left" valign="top" width="100%"><div class="short-legend"><p><span class="captionLabel">Figure 2. </span> Experimental area when experimenting with large buttons.</p></div></td></div><a href="#" class="thumbnail"><img id="F0002image" src="//:0" data-src='{"type":"image","src":"/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/medium/hihc_a_1484054_f0002_oc.jpg"}' /></a><div class="figureDownloadOptions"><a href="#" class="downloadBtn btn btn-sm" id="displaySizeFig" role="button">Display full size</a></div></div></div><div class="hidden rs_skip" id="fig-description-F0002"><p><span class="captionLabel">Figure 2. </span> Experimental area when experimenting with large buttons.</p></div><div class="hidden rs_skip" id="figureFootNote-F0002"></div></p></div><div id="S0003-S2004" class="NLM_sec NLM_sec_level_2"><h3 class="section-heading-3" id="_i12">3.4. Input method</h3><p>Two input methods were compared experimentally in this study. The first was a manual input method using a separate manipulator. Manual selection requires placing the cursor, controlled by head tracking, on the button to be pressed and touching the actuator button. The dotted circle in <a href="#F0003">Figure 3</a> shows the operation button of the experimental VR headset. The experiment participants held their right hand close to the VR headset during manual selection input. At this time, since the actuator button had an uneven surface, the position of the button could be easily estimated even when the participants wore the HMD. In addition, the actuator button is set to recognize input on touching but also any part of the area of the actuator button, rather than only its center.<div class="figure figureViewer" id="F0003"><div id="figureViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="figureThumbnailContainer"><div class="figureInfo"><td align="left" valign="top" width="100%"><div class="short-legend"><p><span class="captionLabel">Figure 3. </span> VR headset self-actuator button.</p></div></td></div><a href="#" class="thumbnail"><img id="F0003image" src="//:0" data-src='{"type":"image","src":"/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/medium/hihc_a_1484054_f0003_oc.jpg"}' /></a><div class="figureDownloadOptions"><a href="#" class="downloadBtn btn btn-sm" id="displaySizeFig" role="button">Display full size</a></div></div></div><div class="hidden rs_skip" id="fig-description-F0003"><p><span class="captionLabel">Figure 3. </span> VR headset self-actuator button.</p></div><div class="hidden rs_skip" id="figureFootNote-F0003"></div></p><p>The second method was an indirect selection method in which the target key was selected when the user gazed at the target for a predetermined time; that is, when the cursor was stopped for a predetermined time on the target key. Similar to the first method, the cursor was moved based on the collection of head movement data with the head tracker. In the second selection method, three periods (1, 1.5, and 2 s) were selected as the predetermined gaze time. These timings reflect the fact that the average timing was 1.52 s (±0.60 s) based on a video analysis of the top five Android-based VR applications downloaded on Google Play as of October 2016 (<a class="ref showTableEventRef" data-ID="T0001">Table 1</a>). As a result of preliminary testing of the software used in the experiments, a test time of 0.5 s was excluded from this experiment because the error rate was significantly high for this tested gaze timing.<div id="tableViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="tableView"><div class="tableCaption"><div class="short-legend"><h3><p><span class="captionLabel">Table 1. </span> VR application aiming time average.</p></h3></div></div><div class="tableDownloadOption" data-hasCSVLnk="true" id="T0001-table-wrapper"><a id="CSVdownloadButton" class="downloadButton btn btn-sm" href="/action/downloadTable?id=T0001&amp;doi=10.1080%2F10447318.2018.1484054&amp;downloadType=CSV">CSV</a><a data-id="T0001" class="downloadButton btn btn-sm displaySizeTable" href="#">Display Table</a></div></div> </p><p>Further, in this study, both input methods used a gaze-controlled cursor. The cursor is fixed at the center of the screen and is represented by a red circular dot. At this point, the cursor must be positioned ahead of the target as it should be able to point to the target. <a href="#F0004">Figure 4</a> shows an example of the cursor fixation distance. In the early version of the experimental software, the distance from the cursor to the button was high, causing extreme motion sickness. As it was determined that the experiment could not be performed because of the effects of motion sickness, the cursor fixation distance was modified. When the cursor fixation distance was adjusted to be as close as possible to the object in the experimental software, the motion sickness symptoms were significantly alleviated.<div class="figure figureViewer" id="F0004"><div id="figureViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="figureThumbnailContainer"><div class="figureInfo"><td align="left" valign="top" width="100%"><div class="short-legend"><p><span class="captionLabel">Figure 4. </span> An example of cursor location.</p></div></td></div><a href="#" class="thumbnail"><img id="F0004image" src="//:0" data-src='{"type":"image","src":"/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/medium/hihc_a_1484054_f0004_oc.jpg"}' /></a><div class="figureDownloadOptions"><a href="#" class="downloadBtn btn btn-sm" id="displaySizeFig" role="button">Display full size</a></div></div></div><div class="hidden rs_skip" id="fig-description-F0004"><p><span class="captionLabel">Figure 4. </span> An example of cursor location.</p></div><div class="hidden rs_skip" id="figureFootNote-F0004"></div></p></div><div id="S0003-S2005" class="NLM_sec NLM_sec_level_2"><h3 class="section-heading-3" id="_i15">3.5. Dependent variable</h3><p>In this experiment, the task completion time, target search time, and error rate were used to evaluate task performance. The task completion time is defined as the time from when the target button was presented to when the user input was made. However, this experimental design has a disadvantage in that the task completion time increases as the set gaze time increases. Therefore, if the task performance is evaluated based on the task completion time, the best task performance may always be determined for the case in which the gaze timing is short. To more precisely compare the three gaze timings, the target search time was defined.</p><p>The target search time is a value obtained by subtracting a preset time from the task completion time. For example, if a task takes 2 s to perform using the 1.5-s gaze timing approach, the target search time is 0.5 s, which is the difference between 2 s and 1.5 s. <a href="#F0005">Figure 5</a> shows the definition of the two dependent variables related to time. Finally, the error rate is defined as the ratio of the total number of nontarget buttons selected in a task to the total number of selections.<div class="figure figureViewer" id="F0005"><div id="figureViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="figureThumbnailContainer"><div class="figureInfo"><td align="left" valign="top" width="100%"><div class="short-legend"><p><span class="captionLabel">Figure 5. </span> Concepts of task completion time and target search time.</p></div></td></div><a href="#" class="thumbnail"><img id="F0005image" src="//:0" data-src='{"type":"image","src":"/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/medium/hihc_a_1484054_f0005_b.gif"}' /></a><div class="figureDownloadOptions"><a href="#" class="downloadBtn btn btn-sm" id="displaySizeFig" role="button">Display full size</a></div></div></div><div class="hidden rs_skip" id="fig-description-F0005"><p><span class="captionLabel">Figure 5. </span> Concepts of task completion time and target search time.</p></div><div class="hidden rs_skip" id="figureFootNote-F0005"></div></p></div><div id="S0003-S2006" class="NLM_sec NLM_sec_level_2"><h3 class="section-heading-3" id="_i17">3.6. Procedure</h3><p>We used a within-subjects factorial design. Eight experimental conditions were used in total, consisting of combinations of four input methods (i.e., three gaze selection timings and the manual selection method) with two button sizes. Each participant performed all eight tasks. The order of experiments was determined using the Latin square balancing technique to minimize learning effects. For the same reason, the order of experimental conditions to be presented to the participants was not provided in advance.</p><p>The participants were asked to practice sufficiently to familiarize themselves with the task of the two input methods prior to the experiment. The participant chooses the experimental condition for the first time. After the experiment supervisor informs the participant of the experimental conditions to be performed, the experiment was started as the participant selects a button among the eight experimental condition selection buttons displayed on the screen.</p><p>When the experiment started, nine buttons arranged in a 3 × 3 layout were displayed on the screen (<a href="#F0006">Figure 6</a>). One of these buttons was highlighted in blue. This button is called the target button. The position of the target button was determined at random. The subject performs the task of selecting the target button 4 times, and this task was repeated 10 times for each experimental condition (<a href="#F0007">Figure 7</a>). At the end of one experimental condition, the participant removed the VR HMD and took sufficient rest to reduce the effects of motion sickness. At the end of the rest period, the participant wore the VR HMD again and continued the experiment with the next condition. This procedure was repeated until participants completed all experimental conditions. That is, one participant performs 320 button selections in total (4 selections × 10 sets × 8 experimental conditions).<div class="figure figureViewer" id="F0006"><div id="figureViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="figureThumbnailContainer"><div class="figureInfo"><td align="left" valign="top" width="100%"><div class="short-legend"><p><span class="captionLabel">Figure 6. </span> An example of VR prototype screen (target button: B2).</p></div></td></div><a href="#" class="thumbnail"><img id="F0006image" src="//:0" data-src='{"type":"image","src":"/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/medium/hihc_a_1484054_f0006_oc.jpg"}' /></a><div class="figureDownloadOptions"><a href="#" class="downloadBtn btn btn-sm" id="displaySizeFig" role="button">Display full size</a></div></div></div><div class="hidden rs_skip" id="fig-description-F0006"><p><span class="captionLabel">Figure 6. </span> An example of VR prototype screen (target button: B2).</p></div><div class="hidden rs_skip" id="figureFootNote-F0006"></div><div class="figure figureViewer" id="F0007"><div id="figureViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="figureThumbnailContainer"><div class="figureInfo"><td align="left" valign="top" width="100%"><div class="short-legend"><p><span class="captionLabel">Figure 7. </span> Sequence of target button selection.</p></div></td></div><a href="#" class="thumbnail"><img id="F0007image" src="//:0" data-src='{"type":"image","src":"/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/medium/hihc_a_1484054_f0007_oc.jpg"}' /></a><div class="figureDownloadOptions"><a href="#" class="downloadBtn btn btn-sm" id="displaySizeFig" role="button">Display full size</a></div></div></div><div class="hidden rs_skip" id="fig-description-F0007"><p><span class="captionLabel">Figure 7. </span> Sequence of target button selection.</p></div><div class="hidden rs_skip" id="figureFootNote-F0007"></div></p></div></div><div id="S0004" class="NLM_sec NLM_sec_level_1"><h2 id="_i20" class="section-heading-2">4. Results</h2><p>A two-way repeated measures analysis of variance (ANOVA) showed that there were performance differences across input methods and button sizes. There were statistically significant differences among task completion time, target search time, and error rate for both the input method and button size, as well as the interaction between the input method and button size (<a class="ref showTableEventRef" data-ID="T0002">Table 2</a>).<div id="tableViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="tableView"><div class="tableCaption"><div class="short-legend"><h3><p><span class="captionLabel">Table 2. </span> Effect testing between Target selection mode and Button size <i>(p</i> &lt; .05).</p></h3></div></div><div class="tableDownloadOption" data-hasCSVLnk="true" id="T0002-table-wrapper"><a id="CSVdownloadButton" class="downloadButton btn btn-sm" href="/action/downloadTable?id=T0002&amp;doi=10.1080%2F10447318.2018.1484054&amp;downloadType=CSV">CSV</a><a data-id="T0002" class="downloadButton btn btn-sm displaySizeTable" href="#">Display Table</a></div></div> </p><div id="S0004-S2001" class="NLM_sec NLM_sec_level_2"><h3 class="section-heading-3" id="_i21">4.1. Task completion time</h3><p>A 4 (input method) × 2 (button size) repeated measures ANOVA indicated a statistically significant difference in the task completion time among the four groups divided according to input method (<i>p </i>&lt; 0.000, <i>α </i>= 0.05). Post-hoc analysis was performed using the Student-Newman-Keuls (SNK) test. Consequently, the gaze selection method and the manual selection method appeared as independent groups, and the groups classified according to the three different timings in the gaze selection method were independent groups (<a href="#F0008">Figure 8</a>). Therefore, there is a statistically significant difference between each pair of input methods. The fastest task completion time was obtained for manual selection. For gaze selection, the task completion time increased considerably as the gaze timing was increased. The mean task completion time for the manual selection method was 1367 (±692) ms. The gaze selection method yielded task completion times of 1831 (±375), 2377 (±519), and 2884 (±599) ms at gaze timings of 1, 1.5, and 2 s, respectively. Therefore, as the gaze timing increases, the task completion time increases significantly. This difference appears to be due to the increment of 500 ms from one gaze timing to the next.<div class="figure figureViewer" id="F0008"><div id="figureViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="figureThumbnailContainer"><div class="figureInfo"><td align="left" valign="top" width="100%"><div class="short-legend"><p><span class="captionLabel">Figure 8. </span> Mean task completion time for each target selection method.</p><p>(Different letters indicate a statistically significant difference, Error bars refer to standard deviation.).</p></div></td></div><a href="#" class="thumbnail"><img id="F0008image" src="//:0" data-src='{"type":"image","src":"/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/medium/hihc_a_1484054_f0008_b.gif"}' /></a><div class="figureDownloadOptions"><a href="#" class="downloadBtn btn btn-sm" id="displaySizeFig" role="button">Display full size</a></div></div></div><div class="hidden rs_skip" id="fig-description-F0008"><p><span class="captionLabel">Figure 8. </span> Mean task completion time for each target selection method.</p><p>(Different letters indicate a statistically significant difference, Error bars refer to standard deviation.).</p></div><div class="hidden rs_skip" id="figureFootNote-F0008"></div></p><p>Button size also yields a statistically significant difference in task completion time (<i>p</i> &lt; 0.000, <i>α</i> = 0.05). A longer time is required to select small buttons than large buttons (large: 2051 (±790) ms, small: 2179 (±801) ms) (<a href="#F0009">Figure 9</a>). In addition, there was a statistically significant difference in interaction between the input method and button size (<i>p</i> &lt; 0.000, <i>α</i> = 0.05). A simple effect analysis showed no statistical difference between the large and small buttons for all three gaze selection timings. However, there was a statistically significant difference in task completion time with varying button size for the manual selection method (<a href="#F0010">Figure 10</a>).<div class="figure figureViewer" id="F0009"><div id="figureViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="figureThumbnailContainer"><div class="figureInfo"><td align="left" valign="top" width="100%"><div class="short-legend"><p><span class="captionLabel">Figure 9. </span> Mean task completion time by button size.</p><p>(Different letters indicate a statistically significant difference, Error bars refer to standard deviation).</p></div></td></div><a href="#" class="thumbnail"><img id="F0009image" src="//:0" data-src='{"type":"image","src":"/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/medium/hihc_a_1484054_f0009_b.gif"}' /></a><div class="figureDownloadOptions"><a href="#" class="downloadBtn btn btn-sm" id="displaySizeFig" role="button">Display full size</a></div></div></div><div class="hidden rs_skip" id="fig-description-F0009"><p><span class="captionLabel">Figure 9. </span> Mean task completion time by button size.</p><p>(Different letters indicate a statistically significant difference, Error bars refer to standard deviation).</p></div><div class="hidden rs_skip" id="figureFootNote-F0009"></div><div class="figure figureViewer" id="F0010"><div id="figureViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="figureThumbnailContainer"><div class="figureInfo"><td align="left" valign="top" width="100%"><div class="short-legend"><p><span class="captionLabel">Figure 10. </span> Mean task completion time for each target selection method and button size.</p><p>(Circles show no statistically significant difference, the y-axis does not start at zero).</p></div></td></div><a href="#" class="thumbnail"><img id="F0010image" src="//:0" data-src='{"type":"image","src":"/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/medium/hihc_a_1484054_f0010_b.gif"}' /></a><div class="figureDownloadOptions"><a href="#" class="downloadBtn btn btn-sm" id="displaySizeFig" role="button">Display full size</a></div></div></div><div class="hidden rs_skip" id="fig-description-F0010"><p><span class="captionLabel">Figure 10. </span> Mean task completion time for each target selection method and button size.</p><p>(Circles show no statistically significant difference, the y-axis does not start at zero).</p></div><div class="hidden rs_skip" id="figureFootNote-F0010"></div></p></div><div id="S0004-S2002" class="NLM_sec NLM_sec_level_2"><h3 class="section-heading-3" id="_i25">4.2. Target search time</h3><p>For the gaze selection method, the absolute time required to select a button differed for each timing (i.e., 1, 1.5, and 2 s). Therefore, we compared the target search times for accurate comparison. As the target search time is relevant only to a comparison between the three subgroups of the gaze selection method, the data for the manual selection method was excluded. Target search times of 826 (±375), 871 (±515), and 878 (±592) ms at gaze timings of 1, 1.5, and 2 s, respectively, were obtained. Two-way repeated measures ANOVA results indicated a statistically significant difference in target search time among the three groups of the gaze selection method (<i>p</i> = 0.001, <i>α</i> = 0.05). Further, SNK analysis also showed statistically significant differences for the different timings (<a href="#F0011">Figure 11</a>). The shortest target search time was obtained for the 1-s gaze selection.<div class="figure figureViewer" id="F0011"><div id="figureViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="figureThumbnailContainer"><div class="figureInfo"><td align="left" valign="top" width="100%"><div class="short-legend"><p><span class="captionLabel">Figure 11. </span> Mean target search time using different gaze selection timings.</p><p>(Different letters indicate a statistically significant difference, Error bars refer to standard deviation).</p></div></td></div><a href="#" class="thumbnail"><img id="F0011image" src="//:0" data-src='{"type":"image","src":"/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/medium/hihc_a_1484054_f0011_b.gif"}' /></a><div class="figureDownloadOptions"><a href="#" class="downloadBtn btn btn-sm" id="displaySizeFig" role="button">Display full size</a></div></div></div><div class="hidden rs_skip" id="fig-description-F0011"><p><span class="captionLabel">Figure 11. </span> Mean target search time using different gaze selection timings.</p><p>(Different letters indicate a statistically significant difference, Error bars refer to standard deviation).</p></div><div class="hidden rs_skip" id="figureFootNote-F0011"></div></p><p>On the other hand, the target search times were 848 (±482) and 869 (±522) ms for large and small buttons, respectively. This analysis indicates that the correlation between the target search time and button size is not statistically significant, unlike the task completion time (<i>p</i> = 0.092, <i>α</i> = 0.05). Therefore, the time from presentation of the target button to placement of the cursor on the button is not related to the button size.</p></div><div id="S0004-S2003" class="NLM_sec NLM_sec_level_2"><h3 class="section-heading-3" id="_i27">4.3. Error rate</h3><p>The error rate was measured for each experimental condition. A two-way repeated measures ANOVA to examine differences among input methods showed a statistically significant difference (<i>p</i> &lt; 0.000; <i>α</i> = 0.05). SNK analysis also showed a statistically significant difference between the gaze selection and manual selection methods. The error rate in the manual selection method was 1.30% (±11.3). For the gaze selection method, error rates of 0.21% (±4.6), 0.31% (±5.6), and 0.10% (±3.2) were obtained for timings of 1, 1.5, and 2 s, respectively. That is, the manual selection method yielded more errors (<a href="#F0012">Figure 12</a>).<div class="figure figureViewer" id="F0012"><div id="figureViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="figureThumbnailContainer"><div class="figureInfo"><td align="left" valign="top" width="100%"><div class="short-legend"><p><span class="captionLabel">Figure 12. </span> Error rate for each target selection method.</p><p>(Different letters indicate a statistically significant difference, Error bars refer to standard deviation).</p></div></td></div><a href="#" class="thumbnail"><img id="F0012image" src="//:0" data-src='{"type":"image","src":"/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/medium/hihc_a_1484054_f0012_b.gif"}' /></a><div class="figureDownloadOptions"><a href="#" class="downloadBtn btn btn-sm" id="displaySizeFig" role="button">Display full size</a></div></div></div><div class="hidden rs_skip" id="fig-description-F0012"><p><span class="captionLabel">Figure 12. </span> Error rate for each target selection method.</p><p>(Different letters indicate a statistically significant difference, Error bars refer to standard deviation).</p></div><div class="hidden rs_skip" id="figureFootNote-F0012"></div></p><p>The error rate differed significantly (<i>p</i> = 0.003; <i>α</i> = 0.05) with button size; they were 0.26% (±5.1) and 0.70% (±8.4) for large and small buttons, respectively. Small buttons caused more errors than large buttons (<a href="#F0013">Figure 13</a>). A simple effect analysis was conducted to check the interaction between the input method and button size. As with task completion time, no statistically significant difference was found between the large and small buttons. However, the manual selection method showed statistically significant differences between the two button sizes; in particular, many errors occurred in the manual selection of the small buttons (<a href="#F0014">Figure 14</a>). This rate was more than five times the error rate for the other experimental conditions.<div class="figure figureViewer" id="F0013"><div id="figureViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="figureThumbnailContainer"><div class="figureInfo"><td align="left" valign="top" width="100%"><div class="short-legend"><p><span class="captionLabel">Figure 13. </span> Error rate for each button size.</p><p>(Different letters indicate a statistically significant difference; Error bars refer to standard deviation).</p></div></td></div><a href="#" class="thumbnail"><img id="F0013image" src="//:0" data-src='{"type":"image","src":"/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/medium/hihc_a_1484054_f0013_b.gif"}' /></a><div class="figureDownloadOptions"><a href="#" class="downloadBtn btn btn-sm" id="displaySizeFig" role="button">Display full size</a></div></div></div><div class="hidden rs_skip" id="fig-description-F0013"><p><span class="captionLabel">Figure 13. </span> Error rate for each button size.</p><p>(Different letters indicate a statistically significant difference; Error bars refer to standard deviation).</p></div><div class="hidden rs_skip" id="figureFootNote-F0013"></div><div class="figure figureViewer" id="F0014"><div id="figureViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="figureThumbnailContainer"><div class="figureInfo"><td align="left" valign="top" width="100%"><div class="short-legend"><p><span class="captionLabel">Figure 14. </span> Error rate based on target selection method and button size.</p><p>(Circles indicate no statistically significant difference).</p></div></td></div><a href="#" class="thumbnail"><img id="F0014image" src="//:0" data-src='{"type":"image","src":"/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307/images/medium/hihc_a_1484054_f0014_b.gif"}' /></a><div class="figureDownloadOptions"><a href="#" class="downloadBtn btn btn-sm" id="displaySizeFig" role="button">Display full size</a></div></div></div><div class="hidden rs_skip" id="fig-description-F0014"><p><span class="captionLabel">Figure 14. </span> Error rate based on target selection method and button size.</p><p>(Circles indicate no statistically significant difference).</p></div><div class="hidden rs_skip" id="figureFootNote-F0014"></div></p></div></div><div id="S0005" class="NLM_sec NLM_sec_level_1"><h2 id="_i31" class="section-heading-2">5. Discussion</h2><div id="S0005-S2001" class="NLM_sec NLM_sec_level_2"><h3 class="section-heading-3" id="_i32">5.1. Influence of button size</h3><p>The task completion time was shorter for the large buttons. The error rate was also reduced when users attempted to select large buttons. These results corroborate analysis results from various interfaces for conventional 2D screens (Park &amp; Han, <span class="ref-lnk lazy-ref"><a data-rid="CIT0030" data-refLink="_i38" href="#">2010</a></span>). It is also a natural finding, as small interfaces are more difficult to manipulate.</p><p>The target search time was a dependent variable established to analyze the three gaze selection methods more clearly. In this study, it was found that the button size does not have a significant effect on the target search time. In addition, the result of the interaction analysis shows that, for the manual selection method, the correlation between task completion time and button size is statistically significant; however, this is not the case for the gaze selection method (<a href="#F0010">Figure 10</a>). Based on these two findings, it is apparent that the manual selection performance differed with button size, but the gaze selection performance did not. Likewise, the correlation between error rate and button size is statistically significant for the manual selection method only. Therefore, there is a difference between manual selection and gaze selection.</p><p>Gaze selection that uses head movement and pauses is advantageous for precise operations (Steptoe et al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0043" data-refLink="_i38" href="#">2009</a></span>). For manual selection, (1) as the head moves to control the cursor, the hand must follow the HMD’s movement to touch the actuator button, and (2) physical vibration may occur when the actuator button is touched by hand.</p><p>Future studies will need to compare various button size alternatives. The button sizes used as a reference in this study were the long side of the 3 × 4 virtual keypad used in smartphones and double that size. In future studies, we expect that the optimal button size can be determined by testing various additional sizes. In addition to the button size, the distance between buttons can also be considered. In this study, button size is expressed based on viewing angle. However, a standardized scale for expressing button size in VR environments would be useful for related studies.</p></div><div id="S0005-S2002" class="NLM_sec NLM_sec_level_2"><h3 class="section-heading-3" id="_i33">5.2. Optimal input method</h3><p>Of the four input methods (i.e., the three gaze selection timings and the manual selection method), the overall operation performance of the manual selection method is the highest. In terms of accuracy, the manual selection yielded a greater number of errors, with statistical significance, compared to the other methods; however, the overall task completion time of the manual selection method was remarkably short. Thus, manual selection is recommended for general work, and gaze selection is recommended for specific tasks requiring high accuracy. In addition, it seems reasonable to increase the button size in situations requiring manual selection.</p><p>Our analysis found the 1-s gaze method to be most usable. All indicators for this timing except the error rate were better, with statistical significance, than those for the other timings. In particular, in terms of the target search time, it is encouraging that the 1-s gaze method exhibits a significant difference from the alternatives. This difference seems be influenced by the fact that the cursor moved outside the button and then back again without achieving the set time for button selection. However, as the difference in terms of time is only approximately 52 ms, it seems that there is no practical meaning to the difference in target search time. Nevertheless, a timing of 1 s is recommended for gaze selection because this timing can reduce the actual working time. In summary, the following guidelines can be suggested: <ul class="NLM_list NLM_list-list_type-bullet"><li><p class="inline">Manual selection is suggested for common tasks.</p></li><li><p class="inline">Button sizes must be sufficiently large to facilitate manual selection (a width of more than 3° 50’ is expected to be suitable).</p></li><li><p class="inline">Gaze selection is recommended when performing tasks that require accuracy.</p></li><li><p class="inline">When using gaze selection, a period of 1 s is recommended as the default timing.</p></li></ul></p></div><div id="S0005-S2003" class="NLM_sec NLM_sec_level_2"><h3 class="section-heading-3" id="_i34">5.3. Application of Fitts’ law</h3><p>In this study, participants performed target selection tasks in a VR environment. Therefore, the correlation between the time taken to select a button and the ID can be analyzed using Fitts’ Law. In the case of the gaze selection method, the correlation was examined only for the 1-s gaze method, which was analyzed to have the highest usability. According to the analysis, <i>a</i> was 0.194 and <i>b</i> was 0.552 for the manual selection method. In the case of the gaze selection method, <i>a</i> was 1.539 and <i>b</i> was 0.142. <a class="ref showTableEventRef" data-ID="T0003">Table 3</a> lists the parameters of the regression model in previous studies and this study. The values of R<sup>2</sup> were 0.88 and 0.75 for the manual selection method and gaze selection method, respectively. This result seems to be similar when compared to the R<sup>2</sup> values of other devices. In the VR environment, the cursor is moved in accordance with the head tracking. The characteristics of this method, i.e., that (1) the cursor movement is more sensitive to head tremors than in the hand-operated method, and (2) the cursor may not move in a straight line, seem to have affected the results. In addition, R<sup>2</sup> is 0.02 for input through eye-tracking in a VR environment (Sibert, Templeman, &amp; Jacob, <span class="ref-lnk lazy-ref"><a data-rid="CIT0033" data-refLink="_i38" href="#">2001</a></span>), which is significantly lower than the value derived in this study. Note that saccadic eye movements are known to fit Fitts’ law poorly (Borah, <span class="ref-lnk lazy-ref"><a data-rid="CIT0008" data-refLink="_i38" href="#">1995</a></span>). Strictly speaking, the input method used in this study was based on head movement, rather than eye movement. Therefore, Fitts’ law seems to provide a better fit for our results than for eye tracking.<div id="tableViewerArticleInfo" class="hidden"><h1>Comparison of Gaze Cursor Input Methods for Virtual Reality Devices</h1><div class="articleAuthors articleInfoSection"><div class="authorsHeading">All authors</div><div class="authors"><a class="entryAuthor" href="/action/doSearch?Contrib=Choe%2C+Mungyeong"><span class="hlFld-ContribAuthor"><a href="/author/Choe%2C+Mungyeong"><span class="NLM_given-names">Mungyeong</span> Choe</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Choi%2C+Yeongcheol"><span class="hlFld-ContribAuthor"><a href="/author/Choi%2C+Yeongcheol"><span class="NLM_given-names">Yeongcheol</span> Choi</a></span>, </a><a class="entryAuthor" href="/action/doSearch?Contrib=Park%2C+Jaehyun"><span class="hlFld-ContribAuthor"><a href="/author/Park%2C+Jaehyun"><span class="NLM_given-names">Jaehyun</span> Park</a></span> <a href="http://orcid.org/0000-0002-5264-6941" class="extLink">http://orcid.org/0000-0002-5264-6941</a> &amp; </a><a class="entryAuthor" href="/action/doSearch?Contrib=Kim%2C+Hyun+K"><span class="hlFld-ContribAuthor"><a href="/author/Kim%2C+Hyun+K"><span class="NLM_given-names">Hyun K.</span> Kim</a></span></a></div></div><div class="articleLowerInfo articleInfoSection"><div class="articleLowerInfoSection articleInfoDOI"><a href="https://doi.org/10.1080/10447318.2018.1484054">https://doi.org/10.1080/10447318.2018.1484054</a></div><div class="articleInfoPublicationDate articleLowerInfoSection border"><h6>Published online:</h6>20 June 2018</div></div></div><div class="tableView"><div class="tableCaption"><div class="short-legend"><h3><p><span class="captionLabel">Table 3. </span> The parameters of the regression model of this study and previous studies.</p></h3></div></div><div class="tableDownloadOption" data-hasCSVLnk="true" id="T0003-table-wrapper"><a id="CSVdownloadButton" class="downloadButton btn btn-sm" href="/action/downloadTable?id=T0003&amp;doi=10.1080%2F10447318.2018.1484054&amp;downloadType=CSV">CSV</a><a data-id="T0003" class="downloadButton btn btn-sm displaySizeTable" href="#">Display Table</a></div></div> </p><p>The IP, which indicates the performance of the device, was analyzed as 1.811 and 7.026 in the manual and gaze methods, respectively. As summarized in <a class="ref showTableEventRef" data-ID="T0003">Table 3</a>, three studies employing a mouse showed significant differences in IP values despite using the same input device. In other words, IP can depend on experimental conditions; therefore, it is considered inappropriate to compare IP between head tracking and other input devices. Therefore, we compared IP only for the two input methods of this study under the same experimental conditions. The IP of the gaze selection method was approximately four times larger than that of the manual selection method. This suggests that the size of the target or the distance to the target may have a relatively large effect on the task performance when the pointing task is performed using the manual selection method. Referring to <a href="#F0010">Figures 10</a> and <a href="#F0014">14</a>, statistically significant differences are found with respect to button size only for the manual selection method in both task completion time and error rate.</p></div><div id="S0005-S2004" class="NLM_sec NLM_sec_level_2"><h3 class="section-heading-3" id="_i35">5.4. VR motion sickness</h3><p>Motion sickness is an important concern in relation to VR devices. The factors that cause motion sickness in virtual environments are known to be varied and complex, and they include user age, field of view, and resolution (Kolasinski, <span class="ref-lnk lazy-ref"><a data-rid="CIT0023" data-refLink="_i38" href="#">1995</a></span>; Moss &amp; Muth, <span class="ref-lnk lazy-ref"><a data-rid="CIT0028" data-refLink="_i38" href="#">2011</a></span>). If one of these fundamental factors is extracted, motion sickness is generated if physical motion information deduced from the inner ear does not coincide with the visual information (Reason, <span class="ref-lnk lazy-ref"><a data-rid="CIT0031" data-refLink="_i38" href="#">1978</a></span>). The device used in this experiment appears to have caused motion sickness because the user’s body remained still, whereas the VR content was dynamic; thus, there was a delay between head movement and content presentation.</p><p>During the experiment, we found that, if the distance from the cursor to the object was too great, motion sickness could be caused. In a conventional 2D user interface, it is natural for the cursor to appear above the object. This arrangement does not cause motion sickness. However, to represent the cursor in a 3D user interface, the cursor must be closer to the user’s eyes than the target. In this case, the fixation distance from the cursor to the subject is different, which can cause eye fatigue. Nausea symptoms that occurred in the preliminary testing of the software were alleviated by changing the fixation distance of the cursor to be as close as possible to the subject. This study did not systematically address VR motion sickness; however, alleviation of motion sickness may be an important factor. We expect to address this topic in future studies; the resultant findings may be helpful to other researchers and designers.</p></div><div id="S0005-S2005" class="NLM_sec NLM_sec_level_2"><h3 class="section-heading-3" id="_i36">5.5. Further study</h3><p>In this study, the performance results for some limited alternatives were compared and analyzed. Thus, it will be possible to obtain more advanced results in future research through more precise examination within this setting. For example, timings between 0.5 and 1.5 s or variations in button size can be compared closely.</p><p>In addition, future studies can analyze the effect of input object location. In the experiments conducted in this study, the viewing angle was standardized, simulating operation with a smartphone in everyday life. However, it is possible to analyze the performance of input tasks in extended areas, because of the characteristics of VR devices and environments. Recent trends in VR headset products have tended to replicate human binocular viewing angles as closely as possible (Hwang et al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0018" data-refLink="_i38" href="#">2006</a></span>).</p><p>Currently, VR market products can be divided into mobile, console, and PC devices. The device used in this study was a mobile HMD. The mobile HMD is not as good as its console- or PC-based counterparts, but it has a 75% share of the VR hardware market because of its low price as well as the absence of additional requirements other than a smartphone (Statista, <span class="ref-lnk lazy-ref"><a data-rid="CIT0040" data-refLink="_i38" href="#">2017</a></span>). The input button of mobile HMD is integrated with the HMD in many cases. Thus, further research is needed to determine whether the results of this experiment are applicable only to mobile VR products or all manual selection methods using a separate controller.</p><p>Furthermore, when performing input operations in a commercial VR application, the user is provided with dynamic feedback or visual effects. As visual feedback can affect the VR environment (Welch, Blackmon, Liu, Mellers, &amp; Stark, <span class="ref-lnk lazy-ref"><a data-rid="CIT0047" data-refLink="_i38" href="#">1996</a></span>), this factor should be examined in future experiments.</p></div></div><div id="S0006" class="NLM_sec NLM_sec_level_1"><h2 id="_i37" class="section-heading-2">6. Conclusion</h2><p>In this study, changes in performance resulting from different input methods and button sizes for a VR HMD were analyzed. The investigated input methods were a manual selection method, in which the cursor was placed on the object on the VR screen and input was performed by pressing a separate actuator button, and a gaze selection method, in which the object was input by targeted gazing for a predetermined time. Two button sizes were established based on the viewing angle for normal smartphone operation and the button size of a smartphone’s 3 × 4 virtual keypad.</p><p>Experiments were conducted for four input methods (gaze selection with three different timings and manual selection), and three factors were measured: the task completion time, target search time, and error rate. Statistically significant differences were obtained for all three experimental measurements according to the input method. The manual selection method was the superior method in terms of task completion time. On the other hand, the error rate of the manual selection method was more than five times those of the gaze selection methods.</p><p>In the case of the gaze selection methods, the task completion time increased proportionally with gaze timing. By comparing target search times defined to minimize the influence of the gaze timing, the 1-s gaze method was found to be statistically better than the other options; this method yielded the fastest task performance times among the three gaze selection methods. In addition, the button size was found to be the only factor influencing the manual selection method.</p><p>The results of this study can be considered when designing future VR devices and content. These results will be especially useful as a reference in designing tasks requiring continuous selection in VR (e.g., a virtual keyboard).</p></div></div><script type="text/javascript">
                        window.figureViewer={doi:'10.1080/10447318.2018.1484054',path:'/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307',figures:[{i:'F0001',g:[{m:'hihc_a_1484054_f0001_oc.jpg',l:'hihc_a_1484054_f0001_oc.jpeg',size:'31 KB'}]}
                            ,{i:'F0002',g:[{m:'hihc_a_1484054_f0002_oc.jpg',l:'hihc_a_1484054_f0002_oc.jpeg',size:'54 KB'}]}
                            ,{i:'F0003',g:[{m:'hihc_a_1484054_f0003_oc.jpg',l:'hihc_a_1484054_f0003_oc.jpeg',size:'72 KB'}]}
                            ,{i:'F0004',g:[{m:'hihc_a_1484054_f0004_oc.jpg',l:'hihc_a_1484054_f0004_oc.jpeg',size:'36 KB'}]}
                            ,{i:'F0005',g:[{m:'hihc_a_1484054_f0005_b.gif',l:'hihc_a_1484054_f0005_b.jpeg',size:'67 KB'}]}
                            ,{i:'F0006',g:[{m:'hihc_a_1484054_f0006_oc.jpg',l:'hihc_a_1484054_f0006_oc.jpeg',size:'35 KB'}]}
                            ,{i:'F0007',g:[{m:'hihc_a_1484054_f0007_oc.jpg',l:'hihc_a_1484054_f0007_oc.jpeg',size:'31 KB'}]}
                            ,{i:'F0008',g:[{m:'hihc_a_1484054_f0008_b.gif',l:'hihc_a_1484054_f0008_b.jpeg',size:'104 KB'}]}
                            ,{i:'F0009',g:[{m:'hihc_a_1484054_f0009_b.gif',l:'hihc_a_1484054_f0009_b.jpeg',size:'102 KB'}]}
                            ,{i:'F0010',g:[{m:'hihc_a_1484054_f0010_b.gif',l:'hihc_a_1484054_f0010_b.jpeg',size:'246 KB'}]}
                            ,{i:'F0011',g:[{m:'hihc_a_1484054_f0011_b.gif',l:'hihc_a_1484054_f0011_b.jpeg',size:'118 KB'}]}
                            ,{i:'F0012',g:[{m:'hihc_a_1484054_f0012_b.gif',l:'hihc_a_1484054_f0012_b.jpeg',size:'85 KB'}]}
                            ,{i:'F0013',g:[{m:'hihc_a_1484054_f0013_b.gif',l:'hihc_a_1484054_f0013_b.jpeg',size:'93 KB'}]}
                            ,{i:'F0014',g:[{m:'hihc_a_1484054_f0014_b.gif',l:'hihc_a_1484054_f0014_b.jpeg',size:'243 KB'}]}
                            ]}</script><script type="text/javascript">window.tableViewer={doi:'10.1080/10447318.2018.1484054',path:'/na101/home/literatum/publisher/tandf/journals/content/hihc20/2019/hihc20.v035.i07/10447318.2018.1484054/20190307',tables:[{i:'T0001'},{i:'T0002'},{i:'T0003'}]}</script><script type="text/javascript">window.tableIDIndexMap = {"id":-1};window.tableIDIndexMap['T0001'] = 1; window.tableIDIndexMap['T0002'] = 2; window.tableIDIndexMap['T0003'] = 3; </script><div id="table-content-T0001" class="hidden"><table class="table frame_topbot"><div class="caption"><p><span class="captionLabel">Table 1. </span> VR application aiming time average.</p></div><colgroup><col align="left" class=" align_left" /><col align="center" class=" align_center" /></colgroup><thead><tr valign="top" class="rowsep1"><th align="left" class="rowsep1 align_left">Applications</th><th align="center" class="rowsep1 align_center last">Time (s)</th></tr></thead><tbody><tr valign="top"><td align="left" class=" align_left">Deep Space Battle VR (Archiact)</td><td align="center" class=" align_center last">1</td></tr><tr valign="top"><td align="left" class=" align_left">Zombie Shooter VR (FIBRUM)</td><td align="center" class=" align_center last">2.3</td></tr><tr valign="top"><td align="left" class=" align_left">SeaWorld VR2 (eiNpictures)</td><td align="center" class=" align_center last">2</td></tr><tr valign="top"><td align="left" class=" align_left">Insidious VR (Focus Features)</td><td align="center" class=" align_center last">1.3</td></tr><tr valign="top"><td align="left" class=" align_left">VR World (NineVR Corporation)</td><td align="center" class=" align_center last">1</td></tr><tr valign="top" class="last"><td align="left" class=" align_left"><b>Average</b></td><td align="center" class=" align_center last"><b>1.52 (±0.60)</b></td></tr></tbody></table></div><div id="table-content-T0002" class="hidden"><table class="table frame_topbot"><div class="caption"><p><span class="captionLabel">Table 2. </span> Effect testing between Target selection mode and Button size <i>(p</i> &lt; .05).</p></div><colgroup><col align="left" class=" align_left" /><col align="char" char="." class=" align_char" /><col align="char" char="." class=" align_char" /><col align="char" char="." class=" align_char" /><col align="char" char="." class=" align_char" /><col align="char" char="." class=" align_char" /><col align="char" char="." class=" align_char" /></colgroup><thead><tr valign="top" class="rowsep1"><th rowspan="2" align="left" class="rowsep1 align_left"> </th><th colspan="2" align="center" char="." class="rowsep1 align_center">Task completion time</th><th colspan="2" align="center" char="." class="rowsep1 align_center">Target search time</th><th colspan="2" align="center" char="." class="rowsep1 align_center last">Error rate</th></tr><tr valign="top" class="rowsep1"><th align="center" char="." class="rowsep1 align_center">F</th><th align="center" char="." class="rowsep1 align_center"><i>p</i></th><th align="center" char="." class="rowsep1 align_center">F</th><th align="center" char="." class="rowsep1 align_center"><i>p</i></th><th align="center" char="." class="rowsep1 align_center">F</th><th align="center" char="." class="rowsep1 align_center last"><i>p</i></th></tr></thead><tbody><tr valign="top"><td align="left" class=" align_left">Target selection mode (A)</td><td align="char" char="." class=" align_char">3111.283</td><td align="char" char="." class=" align_char">0.000</td><td align="char" char="." class=" align_char">6.786</td><td align="char" char="." class=" align_char">0.001</td><td align="char" char="." class=" align_char">14.263</td><td align="char" char="." class=" align_char last">0.000</td></tr><tr valign="top"><td align="left" class=" align_left">Button size (B)</td><td align="char" char="." class=" align_char">117.212</td><td align="char" char="." class=" align_char">0.000</td><td align="char" char="." class=" align_char">2.845</td><td align="char" char="." class=" align_char">0.092</td><td align="char" char="." class=" align_char">9.126</td><td align="char" char="." class=" align_char last">0.003</td></tr><tr valign="top" class="last"><td align="left" class=" align_left">A × B</td><td align="char" char="." class=" align_char">78.284</td><td align="char" char="." class=" align_char">0.000</td><td align="char" char="." class=" align_char">0.289</td><td align="char" char="." class=" align_char">0.749</td><td align="char" char="." class=" align_char">12.663</td><td align="char" char="." class=" align_char last">0.000</td></tr></tbody></table></div><div id="table-content-T0003" class="hidden"><table class="table frame_topbot"><div class="caption"><p><span class="captionLabel">Table 3. </span> The parameters of the regression model of this study and previous studies.</p></div><colgroup><col align="left" class=" align_left" /><col align="left" class=" align_left" /><col align="char" char="." class=" align_char" /><col align="char" char="." class=" align_char" /><col align="char" char="." class=" align_char" /><col align="char" char="." class=" align_char" /></colgroup><thead><tr valign="top" class="rowsep1"><th align="left" class="rowsep1 align_left">Device</th><th align="center" class="rowsep1 align_center">Source</th><th align="center" char="." class="rowsep1 align_center">R<sup>2</sup></th><th align="center" char="." class="rowsep1 align_center"><i>a</i></th><th align="center" char="." class="rowsep1 align_center"><i>b</i></th><th align="center" char="." class="rowsep1 align_center last">IP(bit/s)</th></tr></thead><tbody><tr valign="top"><td align="left" class=" align_left">Mouse</td><td align="left" class=" align_left">Epps, <span class="ref-lnk lazy-ref"><a data-rid="CIT0014" data-refLink="_i38" href="#">1986</a></span></td><td align="char" char="." class=" align_char">0.70</td><td align="char" char="." class=" align_char">0.108</td><td align="char" char="." class=" align_char">0.392</td><td align="char" char="." class=" align_char last">2.551</td></tr><tr valign="top"><td align="left" class=" align_left">Mouse</td><td align="left" class=" align_left">Card, English, &amp; Burr, <span class="ref-lnk lazy-ref"><a data-rid="CIT0010" data-refLink="_i38" href="#">1978</a></span></td><td align="char" char="." class=" align_char">0.83</td><td align="char" char="." class=" align_char">1.033</td><td align="char" char="." class=" align_char">0.096</td><td align="char" char="." class=" align_char last">10.417</td></tr><tr valign="top"><td align="left" class=" align_left">Mouse</td><td align="left" class=" align_left">Sibert et al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0033" data-refLink="_i38" href="#">2001</a></span></td><td align="char" char="." class=" align_char">0.86</td><td align="char" char="." class=" align_char">0.155</td><td align="char" char="." class=" align_char">0.118</td><td align="char" char="." class=" align_char last">8.496</td></tr><tr valign="top"><td align="left" class=" align_left">Touchscreen</td><td align="left" class=" align_left">Bi, Li, &amp; Zhai, <span class="ref-lnk lazy-ref"><a data-rid="CIT0006" data-refLink="_i38" href="#">2013</a></span></td><td align="char" char="." class=" align_char">0.85</td><td align="char" char="." class=" align_char">0.292</td><td align="char" char="." class=" align_char">0.052</td><td align="char" char="." class=" align_char last">19.084</td></tr><tr valign="top"><td align="left" class=" align_left">Eye tracking</td><td align="left" class=" align_left">Sibert et al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0033" data-refLink="_i38" href="#">2001</a></span></td><td align="char" char="." class=" align_char">0.02</td><td align="char" char="." class=" align_char">0.484</td><td align="char" char="." class=" align_char">0.002</td><td align="char" char="." class=" align_char last">588.235</td></tr><tr valign="top"><td align="left" class=" align_left">Head tracking<br />(Manual selection method)</td><td align="left" class=" align_left">This study</td><td align="char" char="." class=" align_char">0.88</td><td align="char" char="." class=" align_char">0.194</td><td align="char" char="." class=" align_char">0.552</td><td align="char" char="." class=" align_char last">1.811</td></tr><tr valign="top" class="last"><td align="left" class=" align_left">Head tracking<br />(Gaze selection method)</td><td align="left" class=" align_left">This study</td><td align="char" char="." class=" align_char">0.75</td><td align="char" char="." class=" align_char">1.539</td><td align="char" char="." class=" align_char">0.142</td><td align="char" char="." class=" align_char last">7.026</td></tr></tbody></table></div><ul class="references numeric-ordered-list" id="references-Section"><div class="author-infos-ref"><h2 id="figures">References</h2><li id="CIT0001"><span><span class="hlFld-ContribAuthor">Alkemade, <span class="NLM_given-names">R.</span></span>, <span class="hlFld-ContribAuthor">Verbeek, <span class="NLM_given-names">F. J.</span></span>, &amp; <span class="hlFld-ContribAuthor">Lukosch, <span class="NLM_given-names">S. G.</span></span> (<span class="NLM_year">2017</span>). <span class="NLM_article-title">On the efficiency of a VR hand gesture-based interface for 3D object manipulations in conceptual design</span>. <i>International Journal of Human–Computer Interaction</i>, <i>33</i>(11)<span class="NLM_fpage">1</span>–<span class="NLM_lpage">20</span>.<span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0001&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000413911500003" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2017&pages=1-20&author=R.+Alkemade&author=F.+J.+Verbeek&author=S.+G.+Lukosch&title=On+the+efficiency+of+a+VR+hand+gesture-based+interface+for+3D+object+manipulations+in+conceptual+design" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0001&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DAlkemade%26aufirst%3DR.%26date%3D2017%26atitle%3DOn%2520the%2520efficiency%2520of%2520a%2520VR%2520hand%2520gesture-based%2520interface%2520for%25203D%2520object%2520manipulations%2520in%2520conceptual%2520design%26jtitle%3DInternational%2520Journal%2520of%2520Human%25E2%2580%2593Computer%2520Interaction%26spage%3D1%26epage%3D20" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0002"><span><span class="hlFld-ContribAuthor">Ardito, <span class="NLM_given-names">C.</span></span>, <span class="hlFld-ContribAuthor">Buono, <span class="NLM_given-names">P.</span></span>, <span class="hlFld-ContribAuthor">Costabile, <span class="NLM_given-names">M. F.</span></span>, <span class="hlFld-ContribAuthor">Lanzilotti, <span class="NLM_given-names">R.</span></span>, &amp; <span class="hlFld-ContribAuthor">Simeone, <span class="NLM_given-names">A. L.</span></span> (<span class="NLM_year">2009</span>). <span class="NLM_article-title"><i>Comparing low cost input devices for interacting with 3D virtual environments</i></span>. <span class="NLM_conf-name">2009 2nd Conference on Human System Interactions</span> (pp. <span class="NLM_fpage">292</span>–<span class="NLM_lpage">297</span>).<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2009&author=C.+Ardito&author=P.+Buono&author=M.+F.+Costabile&author=R.+Lanzilotti&author=A.+L.+Simeone&title=Comparing+low+cost+input+devices+for+interacting+with+3D+virtual+environments" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0002&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DArdito%26aufirst%3DC.%26date%3D2009%26atitle%3DComparing%2520low%2520cost%2520input%2520devices%2520for%2520interacting%2520with%25203D%2520virtual%2520environments%26spage%3D292%26epage%3D297" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0003"><span><span class="hlFld-ContribAuthor">Aslandere, <span class="NLM_given-names">T.</span></span>, <span class="hlFld-ContribAuthor">Dreyer, <span class="NLM_given-names">D.</span></span>, &amp; <span class="hlFld-ContribAuthor">Pankratz, <span class="NLM_given-names">F.</span></span> (<span class="NLM_year">2015</span>). <span class="NLM_article-title"><i>Virtual hand-button interaction in a generic virtual reality flight simulator</i></span>. <span class="NLM_conf-name">2015 IEEE Aerospace Conference</span> (pp. <span class="NLM_fpage">1</span>–<span class="NLM_lpage">8</span>).<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2015&author=T.+Aslandere&author=D.+Dreyer&author=F.+Pankratz&title=Virtual+hand-button+interaction+in+a+generic+virtual+reality+flight+simulator" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0003&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DAslandere%26aufirst%3DT.%26date%3D2015%26atitle%3DVirtual%2520hand-button%2520interaction%2520in%2520a%2520generic%2520virtual%2520reality%2520flight%2520simulator%26spage%3D1%26epage%3D8" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0004"><span><span class="hlFld-ContribAuthor">Bababekova, <span class="NLM_given-names">Y.</span></span>, <span class="hlFld-ContribAuthor">Rosenfield, <span class="NLM_given-names">M.</span></span>, <span class="hlFld-ContribAuthor">Hue, <span class="NLM_given-names">J. E.</span></span>, &amp; <span class="hlFld-ContribAuthor">Huang, <span class="NLM_given-names">R. R.</span></span> (<span class="NLM_year">2011</span>). <span class="NLM_article-title">Font size and viewing distance of handheld smart phones</span>. <i>Optometry &amp; Vision Science</i>, 88(7), <span class="NLM_fpage">795</span>–<span class="NLM_lpage">797</span>. doi:<span class="NLM_pub-id">10.1097/OPX.0b013e3182198792</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0004&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1097%2FOPX.0b013e3182198792" target="_blank">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0004&amp;dbid=8&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=21499163" target="_blank">[PubMed]</a>, <a href="/servlet/linkout?suffix=CIT0004&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000292134800003" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2011&pages=795-797&issue=7&author=Y.+Bababekova&author=M.+Rosenfield&author=J.+E.+Hue&author=R.+R.+Huang&title=Font+size+and+viewing+distance+of+handheld+smart+phones" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0004&amp;dbid=16384&amp;doi=10.1097%2FOPX.0b013e3182198792&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1097%252FOPX.0b013e3182198792%26sid%3Dliteratum%253Atandf%26aulast%3DBababekova%26aufirst%3DY.%26date%3D2011%26atitle%3DFont%2520size%2520and%2520viewing%2520distance%2520of%2520handheld%2520smart%2520phones%26jtitle%3DOptometry%2520%2526%2520Vision%2520Science%26volume%3D88%26issue%3D7%26spage%3D795%26epage%3D797" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0005"><span><span class="hlFld-ContribAuthor">Bach, <span class="NLM_given-names">C.</span></span>, &amp; <span class="hlFld-ContribAuthor">Scapin, <span class="NLM_given-names">D. L.</span></span> (<span class="NLM_year">2010</span>). <span class="NLM_article-title">Comparing inspections and user testing for the evaluation of virtual environments</span>. <i>Intl. Journal of Human–Computer Interaction</i>, 26(8), <span class="NLM_fpage">786</span>–<span class="NLM_lpage">824</span>. doi:<span class="NLM_pub-id">10.1080/10447318.2010.487195</span><span class="refLink-block"> <span class="xlinks-container"><a href="https://www.tandfonline.com/doi/10.1080/10447318.2010.487195" target="_blank">[Taylor &amp; Francis Online]</a>, <a href="/servlet/linkout?suffix=CIT0005&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000280384300002" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2010&pages=786-824&issue=8&author=C.+Bach&author=D.+L.+Scapin&title=Comparing+inspections+and+user+testing+for+the+evaluation+of+virtual+environments" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0005&amp;dbid=16384&amp;doi=10.1080%2F10447318.2010.487195&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1080%252F10447318.2010.487195%26sid%3Dliteratum%253Atandf%26aulast%3DBach%26aufirst%3DC.%26date%3D2010%26atitle%3DComparing%2520inspections%2520and%2520user%2520testing%2520for%2520the%2520evaluation%2520of%2520virtual%2520environments%26jtitle%3DIntl.%2520Journal%2520of%2520Human%25E2%2580%2593Computer%2520Interaction%26volume%3D26%26issue%3D8%26spage%3D786%26epage%3D824" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0006"><span><span class="hlFld-ContribAuthor">Bi, <span class="NLM_given-names">X.</span></span>, <span class="hlFld-ContribAuthor">Li, <span class="NLM_given-names">Y.</span></span>, &amp; <span class="hlFld-ContribAuthor">Zhai, <span class="NLM_given-names">S.</span></span> (<span class="NLM_year">2013</span>). <span class="NLM_article-title"><i>FFitts law: Modeling finger touch with Fitts’ law</i></span>. <span class="NLM_conf-name">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</span> (pp. <span class="NLM_fpage">1363</span>–<span class="NLM_lpage">1372</span>).<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2013&author=X.+Bi&author=Y.+Li&author=S.+Zhai&title=FFitts+law%3A+Modeling+finger+touch+with+Fitts%E2%80%99+law" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0006&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DBi%26aufirst%3DX.%26date%3D2013%26atitle%3DFFitts%2520law%253A%2520Modeling%2520finger%2520touch%2520with%2520Fitts%25E2%2580%2599%2520law%26spage%3D1363%26epage%3D1372" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0007"><span><span class="hlFld-ContribAuthor">Bolton, <span class="NLM_given-names">J.</span></span>, <span class="hlFld-ContribAuthor">Lambert, <span class="NLM_given-names">M.</span></span>, <span class="hlFld-ContribAuthor">Lirette, <span class="NLM_given-names">D.</span></span>, &amp; <span class="hlFld-ContribAuthor">Unsworth, <span class="NLM_given-names">B.</span></span> (<span class="NLM_year">2014</span>). <span class="NLM_article-title"><i>PaperDude: A virtual reality cycling exergame</i></span>. <span class="NLM_conf-name">CHI’14 Extended Abstracts on Human Factors in Computing Systems</span> (pp. <span class="NLM_fpage">475</span>–<span class="NLM_lpage">478</span>).<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2014&author=J.+Bolton&author=M.+Lambert&author=D.+Lirette&author=B.+Unsworth&title=PaperDude%3A+A+virtual+reality+cycling+exergame" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0007&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DBolton%26aufirst%3DJ.%26date%3D2014%26atitle%3DPaperDude%253A%2520A%2520virtual%2520reality%2520cycling%2520exergame%26spage%3D475%26epage%3D478" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0008"><span><span class="hlFld-ContribAuthor">Borah, <span class="NLM_given-names">J.</span></span> (<span class="NLM_year">1995</span>). <i>Investigation of eye and head controlled cursor positioning techniques</i>. <span class="NLM_publisher-loc">Bedford, MA</span>: <span class="NLM_publisher-name">APPLIED SCIENCE LABS</span>.<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=1995&author=J.+Borah&title=Investigation+of+eye+and+head+controlled+cursor+positioning+techniques" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0008&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DBorah%26aufirst%3DJ.%26date%3D1995%26btitle%3DInvestigation%2520of%2520eye%2520and%2520head%2520controlled%2520cursor%2520positioning%2520techniques%26pub%3DAPPLIED%2520SCIENCE%2520LABS" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0009"><span><span class="hlFld-ContribAuthor">Bowman, <span class="NLM_given-names">D. A.</span></span>, &amp; <span class="hlFld-ContribAuthor">McMahan, <span class="NLM_given-names">R. P.</span></span> (<span class="NLM_year">2007</span>). <span class="NLM_article-title">Virtual reality: How much immersion is enough?</span> <i>Computer</i>, 40(7). doi:<span class="NLM_pub-id">10.1109/MC.2007.257</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0009&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1109%2FMC.2007.257" target="_blank">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0009&amp;dbid=8&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=21603088" target="_blank">[PubMed]</a>, <a href="/servlet/linkout?suffix=CIT0009&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000247913100010" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2007&issue=7&author=D.+A.+Bowman&author=R.+P.+McMahan&title=Virtual+reality%3A+How+much+immersion+is+enough%3F" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0009&amp;dbid=16384&amp;doi=10.1109%2FMC.2007.257&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1109%252FMC.2007.257%26sid%3Dliteratum%253Atandf%26aulast%3DBowman%26aufirst%3DD.%2520A.%26date%3D2007%26atitle%3DVirtual%2520reality%253A%2520How%2520much%2520immersion%2520is%2520enough%253F%26jtitle%3DComputer%26volume%3D40%26issue%3D7" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0010"><span><span class="hlFld-ContribAuthor">Card, <span class="NLM_given-names">S. K.</span></span>, <span class="hlFld-ContribAuthor">English, <span class="NLM_given-names">W. K.</span></span>, &amp; <span class="hlFld-ContribAuthor">Burr, <span class="NLM_given-names">B. J.</span></span> (<span class="NLM_year">1978</span>). <span class="NLM_article-title">Evaluation of mouse, rate-controlled isometric joystick, step keys, and text keys for text selection on a CRT</span>. <i>Ergonomics</i>, 21(8), <span class="NLM_fpage">601</span>–<span class="NLM_lpage">613</span>. doi:<span class="NLM_pub-id">10.1080/00140137808931762</span><span class="refLink-block"> <span class="xlinks-container"><a href="https://www.tandfonline.com/doi/10.1080/00140137808931762" target="_blank">[Taylor &amp; Francis Online]</a>, <a href="/servlet/linkout?suffix=CIT0010&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=A1978FN70400002" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=1978&pages=601-613&issue=8&author=S.+K.+Card&author=W.+K.+English&author=B.+J.+Burr&title=Evaluation+of+mouse%2C+rate-controlled+isometric+joystick%2C+step+keys%2C+and+text+keys+for+text+selection+on+a+CRT" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0010&amp;dbid=16384&amp;doi=10.1080%2F00140137808931762&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1080%252F00140137808931762%26sid%3Dliteratum%253Atandf%26aulast%3DCard%26aufirst%3DS.%2520K.%26date%3D1978%26atitle%3DEvaluation%2520of%2520mouse%252C%2520rate-controlled%2520isometric%2520joystick%252C%2520step%2520keys%252C%2520and%2520text%2520keys%2520for%2520text%2520selection%2520on%2520a%2520CRT%26jtitle%3DErgonomics%26volume%3D21%26issue%3D8%26spage%3D601%26epage%3D613" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0011"><span><span class="hlFld-ContribAuthor">Chow, <span class="NLM_given-names">Y. W.</span></span> (<span class="NLM_year">2008</span>). <span class="NLM_article-title">The Wii Remote as an input device for 3D interaction in immersive head-mounted display virtual reality</span>. In Y. Xiao &amp; E. ten Thij (Eds.), <i>IADIS multi conference on computer science and information systems</i> (2008) (pp. <span class="NLM_fpage">85</span>–<span class="NLM_lpage">92</span>). Amsterdam, The Netherlands: IADIS Press.<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2008&pages=85-92&author=Y.+W.+Chow&title=IADIS+multi+conference+on+computer+science+and+information+systems" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0011&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DChow%26aufirst%3DY.%2520W.%26date%3D2008%26atitle%3DThe%2520Wii%2520Remote%2520as%2520an%2520input%2520device%2520for%25203D%2520interaction%2520in%2520immersive%2520head-mounted%2520display%2520virtual%2520reality%26btitle%3DIADIS%2520multi%2520conference%2520on%2520computer%2520science%2520and%2520information%2520systems%26spage%3D85%26epage%3D92" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0012"><span><span class="hlFld-ContribAuthor">Chryssolouris, <span class="NLM_given-names">G.</span></span>, <span class="hlFld-ContribAuthor">Mavrikios, <span class="NLM_given-names">D.</span></span>, <span class="hlFld-ContribAuthor">Fragos, <span class="NLM_given-names">D.</span></span>, &amp; <span class="hlFld-ContribAuthor">Karabatsou, <span class="NLM_given-names">V.</span></span> (<span class="NLM_year">2000</span>). <span class="NLM_article-title">A virtual reality-based experimentation environment for the verification of human-related factors in assembly processes</span>. <i>Robotics and Computer-Integrated Manufacturing</i>, 16(4), <span class="NLM_fpage">267</span>–<span class="NLM_lpage">276</span>. doi:<span class="NLM_pub-id">10.1016/S0736-5845(00)00013-2</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0012&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1016%2FS0736-5845%2800%2900013-2" target="_blank">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0012&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000088572300006" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2000&pages=267-276&issue=4&author=G.+Chryssolouris&author=D.+Mavrikios&author=D.+Fragos&author=V.+Karabatsou&title=A+virtual+reality-based+experimentation+environment+for+the+verification+of+human-related+factors+in+assembly+processes" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0012&amp;dbid=16384&amp;doi=10.1016%2FS0736-5845%2800%2900013-2&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1016%252FS0736-5845%252800%252900013-2%26sid%3Dliteratum%253Atandf%26aulast%3DChryssolouris%26aufirst%3DG.%26date%3D2000%26atitle%3DA%2520virtual%2520reality-based%2520experimentation%2520environment%2520for%2520the%2520verification%2520of%2520human-related%2520factors%2520in%2520assembly%2520processes%26jtitle%3DRobotics%2520and%2520Computer-Integrated%2520Manufacturing%26volume%3D16%26issue%3D4%26spage%3D267%26epage%3D276" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0013"><span><span class="hlFld-ContribAuthor">de Haan, <span class="NLM_given-names">G.</span></span>, <span class="hlFld-ContribAuthor">Griffith, <span class="NLM_given-names">E. J.</span></span>, <span class="hlFld-ContribAuthor">Koutek, <span class="NLM_given-names">M.</span></span>, &amp; <span class="hlFld-ContribAuthor">Post, <span class="NLM_given-names">F. H.</span></span> (<span class="NLM_year">2006</span>). <span class="NLM_article-title"><i>Hybrid interfaces in VEs: Intent and interaction</i></span>. <span class="NLM_conf-name">EGVE</span> (pp. <span class="NLM_fpage">109</span>–<span class="NLM_lpage">118</span>).<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2006&author=G.+de+Haan&author=E.+J.+Griffith&author=M.+Koutek&author=F.+H.+Post&title=Hybrid+interfaces+in+VEs%3A+Intent+and+interaction" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0013&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3Dde%2520Haan%26aufirst%3DG.%26date%3D2006%26atitle%3DHybrid%2520interfaces%2520in%2520VEs%253A%2520Intent%2520and%2520interaction%26spage%3D109%26epage%3D118" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0014"><span><span class="hlFld-ContribAuthor">Epps, <span class="NLM_given-names">B. W.</span></span> (<span class="NLM_year">1986</span>). <span class="NLM_article-title">Comparison of six cursor control devices based on Fitts’ law models</span>. <i>Proceedings of the Human Factors Society Annual Meeting</i>, 30(4), <span class="NLM_fpage">327</span>–<span class="NLM_lpage">331</span>. doi:<span class="NLM_pub-id">10.1177/154193128603000403</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0014&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1177%2F154193128603000403" target="_blank">[Crossref]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=1986&pages=327-331&issue=4&author=B.+W.+Epps&title=Comparison+of+six+cursor+control+devices+based+on+Fitts%E2%80%99+law+models" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0014&amp;dbid=16384&amp;doi=10.1177%2F154193128603000403&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1177%252F154193128603000403%26sid%3Dliteratum%253Atandf%26aulast%3DEpps%26aufirst%3DB.%2520W.%26date%3D1986%26atitle%3DComparison%2520of%2520six%2520cursor%2520control%2520devices%2520based%2520on%2520Fitts%25E2%2580%2599%2520law%2520models%26jtitle%3DProceedings%2520of%2520the%2520Human%2520Factors%2520Society%2520Annual%2520Meeting%26volume%3D30%26issue%3D4%26spage%3D327%26epage%3D331" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0015"><span><span class="hlFld-ContribAuthor">Fitts, <span class="NLM_given-names">P. M.</span></span> (<span class="NLM_year">1954</span>). <span class="NLM_article-title">The information capacity of the human motor system in controlling the amplitude of movement</span>. <i>Journal of Experimental Psychology</i>, 47(6), <span class="NLM_fpage">381</span>. doi:<span class="NLM_pub-id">10.1037/h0055392</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0015&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1037%2Fh0055392" target="_blank">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0015&amp;dbid=8&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=13174710" target="_blank">[PubMed]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=1954&pages=381&issue=6&author=P.+M.+Fitts&title=The+information+capacity+of+the+human+motor+system+in+controlling+the+amplitude+of+movement" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0015&amp;dbid=16384&amp;doi=10.1037%2Fh0055392&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1037%252Fh0055392%26sid%3Dliteratum%253Atandf%26aulast%3DFitts%26aufirst%3DP.%2520M.%26date%3D1954%26atitle%3DThe%2520information%2520capacity%2520of%2520the%2520human%2520motor%2520system%2520in%2520controlling%2520the%2520amplitude%2520of%2520movement%26jtitle%3DJournal%2520of%2520Experimental%2520Psychology%26volume%3D47%26issue%3D6%26spage%3D381" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0016"><span><span class="hlFld-ContribAuthor">Gabbard, <span class="NLM_given-names">J. L.</span></span>, <span class="hlFld-ContribAuthor">Hix, <span class="NLM_given-names">D.</span></span>, &amp; <span class="hlFld-ContribAuthor">Swan, <span class="NLM_given-names">J. E.</span></span> (<span class="NLM_year">1999</span>). <span class="NLM_article-title">User-centered design and evaluation of virtual environments</span>. <i>IEEE Computer Graphics and Applications</i>, 19(6), <span class="NLM_fpage">51</span>–<span class="NLM_lpage">59</span>. doi:<span class="NLM_pub-id">10.1109/38.799740</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0016&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1109%2F38.799740" target="_blank">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0016&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000083257000009" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=1999&pages=51-59&issue=6&author=J.+L.+Gabbard&author=D.+Hix&author=J.+E.+Swan&title=User-centered+design+and+evaluation+of+virtual+environments" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0016&amp;dbid=16384&amp;doi=10.1109%2F38.799740&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1109%252F38.799740%26sid%3Dliteratum%253Atandf%26aulast%3DGabbard%26aufirst%3DJ.%2520L.%26date%3D1999%26atitle%3DUser-centered%2520design%2520and%2520evaluation%2520of%2520virtual%2520environments%26jtitle%3DIEEE%2520Computer%2520Graphics%2520and%2520Applications%26volume%3D19%26issue%3D6%26spage%3D51%26epage%3D59" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0017"><span><span class="hlFld-ContribAuthor">Hollomon, <span class="NLM_given-names">M. J.</span></span>, <span class="hlFld-ContribAuthor">Kratchounova, <span class="NLM_given-names">D.</span></span>, <span class="hlFld-ContribAuthor">Newton, <span class="NLM_given-names">D. C.</span></span>, <span class="hlFld-ContribAuthor">Gildea, <span class="NLM_given-names">K.</span></span>, &amp; <span class="hlFld-ContribAuthor">Knecht, <span class="NLM_given-names">W. R.</span></span> (<span class="NLM_year">2017</span>). <i>Current status of gaze control research and technology literature</i>. <span class="NLM_publisher-loc">Washington, DC</span>: <span class="NLM_publisher-name">Federal Aviation Administration</span>.<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2017&author=M.+J.+Hollomon&author=D.+Kratchounova&author=D.+C.+Newton&author=K.+Gildea&author=W.+R.+Knecht&title=Current+status+of+gaze+control+research+and+technology+literature" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0017&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DHollomon%26aufirst%3DM.%2520J.%26date%3D2017%26btitle%3DCurrent%2520status%2520of%2520gaze%2520control%2520research%2520and%2520technology%2520literature%26pub%3DFederal%2520Aviation%2520Administration" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0018"><span><span class="hlFld-ContribAuthor">Hwang, <span class="NLM_given-names">J.</span></span>, <span class="hlFld-ContribAuthor">Jung, <span class="NLM_given-names">J.</span></span>, &amp; <span class="hlFld-ContribAuthor">Kim, <span class="NLM_given-names">G. J.</span></span> (<span class="NLM_year">2006</span>). <span class="NLM_article-title"><i>Hand-held virtual reality: A feasibility study</i></span>. <span class="NLM_conf-name">Proceedings of the ACM symposium on Virtual reality software and technology</span> (pp. <span class="NLM_fpage">356</span>–<span class="NLM_lpage">363</span>).<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2006&author=J.+Hwang&author=J.+Jung&author=G.+J.+Kim&title=Hand-held+virtual+reality%3A+A+feasibility+study" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0018&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DHwang%26aufirst%3DJ.%26date%3D2006%26atitle%3DHand-held%2520virtual%2520reality%253A%2520A%2520feasibility%2520study%26spage%3D356%26epage%3D363" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0019"><span><span class="hlFld-ContribAuthor">Jagacinski, <span class="NLM_given-names">R. J.</span></span>, &amp; <span class="hlFld-ContribAuthor">Monk, <span class="NLM_given-names">D. L.</span></span> (<span class="NLM_year">1985</span>). <span class="NLM_article-title">Fitts’ law in two dimensions with hand and head movements</span>. <i>Journal of Motor Behavior</i>, 17(1), <span class="NLM_fpage">77</span>–<span class="NLM_lpage">95</span>. doi:<span class="NLM_pub-id">10.1080/00222895.1985.10735338</span><span class="refLink-block"> <span class="xlinks-container"><a href="https://www.tandfonline.com/doi/10.1080/00222895.1985.10735338" target="_blank">[Taylor &amp; Francis Online]</a>, <a href="/servlet/linkout?suffix=CIT0019&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=A1985AJG1800004" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=1985&pages=77-95&issue=1&author=R.+J.+Jagacinski&author=D.+L.+Monk&title=Fitts%E2%80%99+law+in+two+dimensions+with+hand+and+head+movements" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0019&amp;dbid=16384&amp;doi=10.1080%2F00222895.1985.10735338&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1080%252F00222895.1985.10735338%26sid%3Dliteratum%253Atandf%26aulast%3DJagacinski%26aufirst%3DR.%2520J.%26date%3D1985%26atitle%3DFitts%25E2%2580%2599%2520law%2520in%2520two%2520dimensions%2520with%2520hand%2520and%2520head%2520movements%26jtitle%3DJournal%2520of%2520Motor%2520Behavior%26volume%3D17%26issue%3D1%26spage%3D77%26epage%3D95" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0020"><span><span class="hlFld-ContribAuthor">Jankowski, <span class="NLM_given-names">J.</span></span>, &amp; <span class="hlFld-ContribAuthor">Hachet, <span class="NLM_given-names">M.</span></span> (<span class="NLM_year">2015</span>). <span class="NLM_article-title">Advances in interaction with 3d environments</span>. <i>Computer Graphics Forum</i>, 34(1), <span class="NLM_fpage">152</span>–<span class="NLM_lpage">190</span>. doi:<span class="NLM_pub-id">10.1111/cgf.12466</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0020&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1111%2Fcgf.12466" target="_blank">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0020&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000350145600014" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2015&pages=152-190&issue=1&author=J.+Jankowski&author=M.+Hachet&title=Advances+in+interaction+with+3d+environments" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0020&amp;dbid=16384&amp;doi=10.1111%2Fcgf.12466&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1111%252Fcgf.12466%26sid%3Dliteratum%253Atandf%26aulast%3DJankowski%26aufirst%3DJ.%26date%3D2015%26atitle%3DAdvances%2520in%2520interaction%2520with%25203d%2520environments%26jtitle%3DComputer%2520Graphics%2520Forum%26volume%3D34%26issue%3D1%26spage%3D152%26epage%3D190" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0021"><span><span class="hlFld-ContribAuthor">Kim, <span class="NLM_given-names">H.</span></span>, <span class="hlFld-ContribAuthor">Kwon, <span class="NLM_given-names">S.</span></span>, <span class="hlFld-ContribAuthor">Heo, <span class="NLM_given-names">J.</span></span>, <span class="hlFld-ContribAuthor">Lee, <span class="NLM_given-names">H.</span></span>, &amp; <span class="hlFld-ContribAuthor">Chung, <span class="NLM_given-names">M. K.</span></span> (<span class="NLM_year">2014</span>). <span class="NLM_article-title">The effect of touch-key size on the usability of In-Vehicle Information Systems and driving safety during simulated driving</span>. <i>Applied Ergonomics</i>, 45(3), <span class="NLM_fpage">379</span>–<span class="NLM_lpage">388</span>. doi:<span class="NLM_pub-id">10.1016/j.apergo.2013.05.006</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0021&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1016%2Fj.apergo.2013.05.006" target="_blank">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0021&amp;dbid=8&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=23759791" target="_blank">[PubMed]</a>, <a href="/servlet/linkout?suffix=CIT0021&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000331501100002" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2014&pages=379-388&issue=3&author=H.+Kim&author=S.+Kwon&author=J.+Heo&author=H.+Lee&author=M.+K.+Chung&title=The+effect+of+touch-key+size+on+the+usability+of+In-Vehicle+Information+Systems+and+driving+safety+during+simulated+driving" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0021&amp;dbid=16384&amp;doi=10.1016%2Fj.apergo.2013.05.006&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1016%252Fj.apergo.2013.05.006%26sid%3Dliteratum%253Atandf%26aulast%3DKim%26aufirst%3DH.%26date%3D2014%26atitle%3DThe%2520effect%2520of%2520touch-key%2520size%2520on%2520the%2520usability%2520of%2520In-Vehicle%2520Information%2520Systems%2520and%2520driving%2520safety%2520during%2520simulated%2520driving%26jtitle%3DApplied%2520Ergonomics%26volume%3D45%26issue%3D3%26spage%3D379%26epage%3D388" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0022"><span><span class="hlFld-ContribAuthor">Kim, <span class="NLM_given-names">H. K.</span></span>, <span class="hlFld-ContribAuthor">Han, <span class="NLM_given-names">S. H.</span></span>, <span class="hlFld-ContribAuthor">Park, <span class="NLM_given-names">J.</span></span>, &amp; <span class="hlFld-ContribAuthor">Park, <span class="NLM_given-names">W.</span></span> (<span class="NLM_year">2015</span>). <span class="NLM_article-title">How user experience changes over time: A case study of social network services</span>. <i>Human Factors and Ergonomics in Manufacturing &amp; Service Industries</i>, 25(6), <span class="NLM_fpage">659</span>–<span class="NLM_lpage">673</span>. doi:<span class="NLM_pub-id">10.1002/hfm.20583</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0022&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1002%2Fhfm.20583" target="_blank">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0022&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000363763700004" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2015&pages=659-673&issue=6&author=H.+K.+Kim&author=S.+H.+Han&author=J.+Park&author=W.+Park&title=How+user+experience+changes+over+time%3A+A+case+study+of+social+network+services" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0022&amp;dbid=16384&amp;doi=10.1002%2Fhfm.20583&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1002%252Fhfm.20583%26sid%3Dliteratum%253Atandf%26aulast%3DKim%26aufirst%3DH.%2520K.%26date%3D2015%26atitle%3DHow%2520user%2520experience%2520changes%2520over%2520time%253A%2520A%2520case%2520study%2520of%2520social%2520network%2520services%26jtitle%3DHuman%2520Factors%2520and%2520Ergonomics%2520in%2520Manufacturing%2520%2526%2520Service%2520Industries%26volume%3D25%26issue%3D6%26spage%3D659%26epage%3D673" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0023"><span><span class="hlFld-ContribAuthor">Kolasinski, <span class="NLM_given-names">E. M.</span></span> (<span class="NLM_year">1995</span>). <span class="NLM_article-title"><i>Simulator sickness in virtual environments</i></span> (No. ARI-TR-1027). <span class="NLM_publisher-name">Army Research Inst for the Behavioral and Social Sciences Alexandria VA</span>.<span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0023&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.21236%2FADA295861" target="_blank">[Crossref]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=1995&author=E.+M.+Kolasinski&title=Simulator+sickness+in+virtual+environments" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0023&amp;dbid=16384&amp;doi=10.21236%2FADA295861&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.21236%252FADA295861%26sid%3Dliteratum%253Atandf%26aulast%3DKolasinski%26aufirst%3DE.%2520M.%26date%3D1995%26atitle%3DSimulator%2520sickness%2520in%2520virtual%2520environments%26pub%3DArmy%2520Research%2520Inst%2520for%2520the%2520Behavioral%2520and%2520Social%2520Sciences%2520Alexandria%2520VA" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0024"><span><span class="hlFld-ContribAuthor">LaValle, <span class="NLM_given-names">S. M.</span></span>, <span class="hlFld-ContribAuthor">Yershova, <span class="NLM_given-names">A.</span></span>, <span class="hlFld-ContribAuthor">Katsev, <span class="NLM_given-names">M.</span></span>, &amp; <span class="hlFld-ContribAuthor">Antonov, <span class="NLM_given-names">M.</span></span> (<span class="NLM_year">2014</span>). <span class="NLM_article-title"><i>Head tracking for the oculus rift</i></span>. <span class="NLM_conf-name">2014 IEEE International Conference on Robotics and Automation (ICRA)</span> (pp. <span class="NLM_fpage">187</span>–<span class="NLM_lpage">194</span>).<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2014&author=S.+M.+LaValle&author=A.+Yershova&author=M.+Katsev&author=M.+Antonov&title=Head+tracking+for+the+oculus+rift" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0024&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DLaValle%26aufirst%3DS.%2520M.%26date%3D2014%26atitle%3DHead%2520tracking%2520for%2520the%2520oculus%2520rift%26spage%3D187%26epage%3D194" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0025"><span><span class="hlFld-ContribAuthor">MacKenzie, <span class="NLM_given-names">I. S.</span></span> (<span class="NLM_year">1992</span>). <span class="NLM_article-title">Fitts’ law as a research and design tool in human-computer interaction</span>. <i>Human-Computer Interaction</i>, 7(1), <span class="NLM_fpage">91</span>–<span class="NLM_lpage">139</span>. doi:<span class="NLM_pub-id">10.1207/s15327051hci0701_3</span><span class="refLink-block"> <span class="xlinks-container"><a href="https://www.tandfonline.com/doi/10.1207/s15327051hci0701_3" target="_blank">[Taylor &amp; Francis Online]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=1992&pages=91-139&issue=1&author=I.+S.+MacKenzie&title=Fitts%E2%80%99+law+as+a+research+and+design+tool+in+human-computer+interaction" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0025&amp;dbid=16384&amp;doi=10.1207%2Fs15327051hci0701_3&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1207%252Fs15327051hci0701_3%26sid%3Dliteratum%253Atandf%26aulast%3DMacKenzie%26aufirst%3DI.%2520S.%26date%3D1992%26atitle%3DFitts%25E2%2580%2599%2520law%2520as%2520a%2520research%2520and%2520design%2520tool%2520in%2520human-computer%2520interaction%26jtitle%3DHuman-Computer%2520Interaction%26volume%3D7%26issue%3D1%26spage%3D91%26epage%3D139" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0026"><span><span class="hlFld-ContribAuthor">Mon-Williams, <span class="NLM_given-names">M.</span></span>, <span class="hlFld-ContribAuthor">Plooy, <span class="NLM_given-names">A.</span></span>, <span class="hlFld-ContribAuthor">Burgess-Limerick, <span class="NLM_given-names">R.</span></span>, &amp; <span class="hlFld-ContribAuthor">Wann, <span class="NLM_given-names">J.</span></span> (<span class="NLM_year">1998</span>). <span class="NLM_article-title">Gaze angle: A possible mechanism of visual stress in virtual reality headsets</span>. <i>Ergonomics</i>, 41(3), <span class="NLM_fpage">280</span>–<span class="NLM_lpage">285</span>. doi:<span class="NLM_pub-id">10.1080/001401398187035</span><span class="refLink-block"> <span class="xlinks-container"><a href="https://www.tandfonline.com/doi/10.1080/001401398187035" target="_blank">[Taylor &amp; Francis Online]</a>, <a href="/servlet/linkout?suffix=CIT0026&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000072233700003" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=1998&pages=280-285&issue=3&author=M.+Mon-Williams&author=A.+Plooy&author=R.+Burgess-Limerick&author=J.+Wann&title=Gaze+angle%3A+A+possible+mechanism+of+visual+stress+in+virtual+reality+headsets" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0026&amp;dbid=16384&amp;doi=10.1080%2F001401398187035&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1080%252F001401398187035%26sid%3Dliteratum%253Atandf%26aulast%3DMon-Williams%26aufirst%3DM.%26date%3D1998%26atitle%3DGaze%2520angle%253A%2520A%2520possible%2520mechanism%2520of%2520visual%2520stress%2520in%2520virtual%2520reality%2520headsets%26jtitle%3DErgonomics%26volume%3D41%26issue%3D3%26spage%3D280%26epage%3D285" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0027"><span><span class="hlFld-ContribAuthor">Morimoto, <span class="NLM_given-names">K.</span></span>, <span class="hlFld-ContribAuthor">Miyajima, <span class="NLM_given-names">C.</span></span>, <span class="hlFld-ContribAuthor">Itou, <span class="NLM_given-names">K.</span></span>, &amp; <span class="hlFld-ContribAuthor">Takeda, <span class="NLM_given-names">K.</span></span> (<span class="NLM_year">2007</span>). <span class="NLM_article-title">A virtual button interface using fingertip movements</span>. <i>2007 International Conference on Machine Learning and Cybernetics</i>, 4, <span class="NLM_fpage">2089</span>–<span class="NLM_lpage">2093</span>.<span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0027&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1109%2FICMLC.2007.4370489" target="_blank">[Crossref]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2007&pages=2089-2093&author=K.+Morimoto&author=C.+Miyajima&author=K.+Itou&author=K.+Takeda&title=A+virtual+button+interface+using+fingertip+movements" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0027&amp;dbid=16384&amp;doi=10.1109%2FICMLC.2007.4370489&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1109%252FICMLC.2007.4370489%26sid%3Dliteratum%253Atandf%26aulast%3DMorimoto%26aufirst%3DK.%26date%3D2007%26atitle%3DA%2520virtual%2520button%2520interface%2520using%2520fingertip%2520movements%26jtitle%3D2007%2520International%2520Conference%2520on%2520Machine%2520Learning%2520and%2520Cybernetics%26volume%3D4%26spage%3D2089%26epage%3D2093" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0028"><span><span class="hlFld-ContribAuthor">Moss, <span class="NLM_given-names">J. D.</span></span>, &amp; <span class="hlFld-ContribAuthor">Muth, <span class="NLM_given-names">E. R.</span></span> (<span class="NLM_year">2011</span>). <span class="NLM_article-title">Characteristics of head-mounted displays and their effects on simulator sickness</span>. <i>Human Factors: the Journal of the Human Factors and Ergonomics Society</i>, 53(3), <span class="NLM_fpage">308</span>–<span class="NLM_lpage">319</span>. doi:<span class="NLM_pub-id">10.1177/0018720811405196</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0028&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1177%2F0018720811405196" target="_blank">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0028&amp;dbid=8&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=21830515" target="_blank">[PubMed]</a>, <a href="/servlet/linkout?suffix=CIT0028&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000292115100008" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2011&pages=308-319&issue=3&author=J.+D.+Moss&author=E.+R.+Muth&title=Characteristics+of+head-mounted+displays+and+their+effects+on+simulator+sickness" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0028&amp;dbid=16384&amp;doi=10.1177%2F0018720811405196&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1177%252F0018720811405196%26sid%3Dliteratum%253Atandf%26aulast%3DMoss%26aufirst%3DJ.%2520D.%26date%3D2011%26atitle%3DCharacteristics%2520of%2520head-mounted%2520displays%2520and%2520their%2520effects%2520on%2520simulator%2520sickness%26jtitle%3DHuman%2520Factors%253A%2520the%2520Journal%2520of%2520the%2520Human%2520Factors%2520and%2520Ergonomics%2520Society%26volume%3D53%26issue%3D3%26spage%3D308%26epage%3D319" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0029"><span><span class="hlFld-ContribAuthor">Parhi, <span class="NLM_given-names">P.</span></span>, <span class="hlFld-ContribAuthor">Karlson, <span class="NLM_given-names">A. K.</span></span>, &amp; <span class="hlFld-ContribAuthor">Bederson, <span class="NLM_given-names">B. B.</span></span> (<span class="NLM_year">2006</span>). <span class="NLM_article-title"><i>Target size study for one-handed thumb use on small touchscreen devices</i></span>. <span class="NLM_conf-name">Proceedings of the 8th conference on Human-computer interaction with mobile devices and services</span> (pp. <span class="NLM_fpage">203</span>–<span class="NLM_lpage">210</span>).<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2006&author=P.+Parhi&author=A.+K.+Karlson&author=B.+B.+Bederson&title=Target+size+study+for+one-handed+thumb+use+on+small+touchscreen+devices" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0029&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DParhi%26aufirst%3DP.%26date%3D2006%26atitle%3DTarget%2520size%2520study%2520for%2520one-handed%2520thumb%2520use%2520on%2520small%2520touchscreen%2520devices%26spage%3D203%26epage%3D210" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0030"><span><span class="hlFld-ContribAuthor">Park, <span class="NLM_given-names">Y. S.</span></span>, &amp; <span class="hlFld-ContribAuthor">Han, <span class="NLM_given-names">S. H.</span></span> (<span class="NLM_year">2010</span>). <span class="NLM_article-title">Touch key design for one-handed thumb interaction with a mobile phone: Effects of touch key size and touch key location</span>. <i>International Journal of Industrial Ergonomics</i>, 40, <span class="NLM_fpage">68</span>–<span class="NLM_lpage">76</span>. doi:<span class="NLM_pub-id">10.1016/j.ergon.2009.08.002</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0030&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1016%2Fj.ergon.2009.08.002" target="_blank">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0030&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000274352100010" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2010&pages=68-76&author=Y.+S.+Park&author=S.+H.+Han&title=Touch+key+design+for+one-handed+thumb+interaction+with+a+mobile+phone%3A+Effects+of+touch+key+size+and+touch+key+location" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0030&amp;dbid=16384&amp;doi=10.1016%2Fj.ergon.2009.08.002&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1016%252Fj.ergon.2009.08.002%26sid%3Dliteratum%253Atandf%26aulast%3DPark%26aufirst%3DY.%2520S.%26date%3D2010%26atitle%3DTouch%2520key%2520design%2520for%2520one-handed%2520thumb%2520interaction%2520with%2520a%2520mobile%2520phone%253A%2520Effects%2520of%2520touch%2520key%2520size%2520and%2520touch%2520key%2520location%26jtitle%3DInternational%2520Journal%2520of%2520Industrial%2520Ergonomics%26volume%3D40%26spage%3D68%26epage%3D76" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0031"><span><span class="hlFld-ContribAuthor">Reason, <span class="NLM_given-names">J. T.</span></span> (<span class="NLM_year">1978</span>). <span class="NLM_article-title">Motion sickness adaptation: A neural mismatch model</span>. <i>Journal of the Royal Society of Medicine</i>, 71(11), <span class="NLM_fpage">819</span>. doi:<span class="NLM_pub-id">10.1177/014107687807101109</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0031&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1177%2F014107687807101109" target="_blank">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0031&amp;dbid=8&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=731645" target="_blank">[PubMed]</a>, <a href="/servlet/linkout?suffix=CIT0031&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=A1978FV64600009" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=1978&pages=819&issue=11&author=J.+T.+Reason&title=Motion+sickness+adaptation%3A+A+neural+mismatch+model" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0031&amp;dbid=16384&amp;doi=10.1177%2F014107687807101109&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1177%252F014107687807101109%26sid%3Dliteratum%253Atandf%26aulast%3DReason%26aufirst%3DJ.%2520T.%26date%3D1978%26atitle%3DMotion%2520sickness%2520adaptation%253A%2520A%2520neural%2520mismatch%2520model%26jtitle%3DJournal%2520of%2520the%2520Royal%2520Society%2520of%2520Medicine%26volume%3D71%26issue%3D11%26spage%3D819" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0032"><span><span class="hlFld-ContribAuthor">Schedlbauer, <span class="NLM_given-names">M.</span></span> (<span class="NLM_year">2007</span>). <span class="NLM_article-title">Effects of key size and spacing on the completion time and accuracy of input tasks on soft keypads using trackball and touch input</span>. <i>Proceedings of the Human Factors and Ergonomics Society Annual Meeting</i>, 51(5), <span class="NLM_fpage">429</span>–<span class="NLM_lpage">433</span>. doi:<span class="NLM_pub-id">10.1177/154193120705100501</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0032&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1177%2F154193120705100501" target="_blank">[Crossref]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2007&pages=429-433&issue=5&author=M.+Schedlbauer&title=Effects+of+key+size+and+spacing+on+the+completion+time+and+accuracy+of+input+tasks+on+soft+keypads+using+trackball+and+touch+input" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0032&amp;dbid=16384&amp;doi=10.1177%2F154193120705100501&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1177%252F154193120705100501%26sid%3Dliteratum%253Atandf%26aulast%3DSchedlbauer%26aufirst%3DM.%26date%3D2007%26atitle%3DEffects%2520of%2520key%2520size%2520and%2520spacing%2520on%2520the%2520completion%2520time%2520and%2520accuracy%2520of%2520input%2520tasks%2520on%2520soft%2520keypads%2520using%2520trackball%2520and%2520touch%2520input%26jtitle%3DProceedings%2520of%2520the%2520Human%2520Factors%2520and%2520Ergonomics%2520Society%2520Annual%2520Meeting%26volume%3D51%26issue%3D5%26spage%3D429%26epage%3D433" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0033"><span><span class="hlFld-ContribAuthor">Sibert, <span class="NLM_given-names">L. E.</span></span>, <span class="hlFld-ContribAuthor">Templeman, <span class="NLM_given-names">J. N.</span></span>, &amp; <span class="hlFld-ContribAuthor">Jacob, <span class="NLM_given-names">R. J.</span></span> (<span class="NLM_year">2001</span>). <i>Evaluation and analysis of eye gaze interaction</i>. <span class="NLM_publisher-loc">Washington, DC</span>: <span class="NLM_publisher-name">NAVAL RESEARCH LAB</span>.<span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0033&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.21236%2FADA389984" target="_blank">[Crossref]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2001&author=L.+E.+Sibert&author=J.+N.+Templeman&author=R.+J.+Jacob&title=Evaluation+and+analysis+of+eye+gaze+interaction" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0033&amp;dbid=16384&amp;doi=10.21236%2FADA389984&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.21236%252FADA389984%26sid%3Dliteratum%253Atandf%26aulast%3DSibert%26aufirst%3DL.%2520E.%26date%3D2001%26btitle%3DEvaluation%2520and%2520analysis%2520of%2520eye%2520gaze%2520interaction%26pub%3DNAVAL%2520RESEARCH%2520LAB" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0034"><span><span class="hlFld-ContribAuthor">Sidorakis, <span class="NLM_given-names">N.</span></span>, <span class="hlFld-ContribAuthor">Koulieris, <span class="NLM_given-names">G. A.</span></span>, &amp; <span class="hlFld-ContribAuthor">Mania, <span class="NLM_given-names">K.</span></span> (<span class="NLM_year">2015</span>). <span class="NLM_article-title"><i>Binocular eye-tracking for the control of a 3D immersive multimedia user interface</i></span>. <span class="NLM_conf-name">Everyday Virtual Reality (WEVR), 2015 IEEE 1st Workshop on, 15–18</span>, <span class="NLM_publisher-name">IEEE</span>.<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2015&author=N.+Sidorakis&author=G.+A.+Koulieris&author=K.+Mania&title=Binocular+eye-tracking+for+the+control+of+a+3D+immersive+multimedia+user+interface" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0034&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DSidorakis%26aufirst%3DN.%26date%3D2015%26atitle%3DBinocular%2520eye-tracking%2520for%2520the%2520control%2520of%2520a%25203D%2520immersive%2520multimedia%2520user%2520interface%26pub%3DIEEE" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0035"><span><span class="hlFld-ContribAuthor">So, <span class="NLM_given-names">R. H. Y.</span></span>, &amp; <span class="hlFld-ContribAuthor">Griffin, <span class="NLM_given-names">M. J.</span></span> (<span class="NLM_year">2000</span>). <span class="NLM_article-title">Effects of target movement direction cue on head-tracking performance</span>. <i>Ergonomics</i>, 43(3), <span class="NLM_fpage">360</span>–<span class="NLM_lpage">376</span>. doi: <span class="NLM_pub-id">10.1080/001401300184468</span><span class="refLink-block"> <span class="xlinks-container"><a href="https://www.tandfonline.com/doi/10.1080/001401300184468" target="_blank">[Taylor &amp; Francis Online]</a>, <a href="/servlet/linkout?suffix=CIT0035&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000085899200006" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2000&pages=360-376&issue=3&author=R.+H.+Y.+So&author=M.+J.+Griffin&title=Effects+of+target+movement+direction+cue+on+head-tracking+performance" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0035&amp;dbid=16384&amp;doi=10.1080%2F001401300184468&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1080%252F001401300184468%26sid%3Dliteratum%253Atandf%26aulast%3DSo%26aufirst%3DR.%2520H.%2520Y.%26date%3D2000%26atitle%3DEffects%2520of%2520target%2520movement%2520direction%2520cue%2520on%2520head-tracking%2520performance%26jtitle%3DErgonomics%26volume%3D43%26issue%3D3%26spage%3D360%26epage%3D376" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0036"><span><span class="hlFld-ContribAuthor">Soukoreff, <span class="NLM_given-names">R. W.</span></span>, <span class="hlFld-ContribAuthor">Zhao, <span class="NLM_given-names">J.</span></span>, &amp; <span class="hlFld-ContribAuthor">Ren, <span class="NLM_given-names">X.</span></span> (<span class="NLM_year">2011</span>). <span class="NLM_article-title"><i>The entropy of a rapid aimed movement: Fitts’ index of difficulty versus Shannon’s entropy</i></span>. <span class="NLM_conf-name">IFIP Conference on Human-Computer Interaction</span> (pp. <span class="NLM_fpage">222</span>–<span class="NLM_lpage">239</span>).<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2011&author=R.+W.+Soukoreff&author=J.+Zhao&author=X.+Ren&title=The+entropy+of+a+rapid+aimed+movement%3A+Fitts%E2%80%99+index+of+difficulty+versus+Shannon%E2%80%99s+entropy" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0036&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DSoukoreff%26aufirst%3DR.%2520W.%26date%3D2011%26atitle%3DThe%2520entropy%2520of%2520a%2520rapid%2520aimed%2520movement%253A%2520Fitts%25E2%2580%2599%2520index%2520of%2520difficulty%2520versus%2520Shannon%25E2%2580%2599s%2520entropy%26spage%3D222%26epage%3D239" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0037"><span><span class="hlFld-ContribAuthor">Stanney, <span class="NLM_given-names">K. M.</span></span>, <span class="hlFld-ContribAuthor">Mollaghasemi, <span class="NLM_given-names">M.</span></span>, <span class="hlFld-ContribAuthor">Reeves, <span class="NLM_given-names">L.</span></span>, <span class="hlFld-ContribAuthor">Breaux, <span class="NLM_given-names">R.</span></span>, &amp; <span class="hlFld-ContribAuthor">Graeber, <span class="NLM_given-names">D. A.</span></span> (<span class="NLM_year">2003</span>). <span class="NLM_article-title">Usability engineering of virtual environments (VEs): Identifying multiple criteria that drive effective VE system design</span>. <i>International Journal of Human-Computer Studies</i>, 58(4), <span class="NLM_fpage">447</span>–<span class="NLM_lpage">481</span>. doi:<span class="NLM_pub-id">10.1016/S1071-5819(03)00015-6</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0037&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1016%2FS1071-5819%2803%2900015-6" target="_blank">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0037&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000182307600005" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2003&pages=447-481&issue=4&author=K.+M.+Stanney&author=M.+Mollaghasemi&author=L.+Reeves&author=R.+Breaux&author=D.+A.+Graeber&title=Usability+engineering+of+virtual+environments+%28VEs%29%3A+Identifying+multiple+criteria+that+drive+effective+VE+system+design" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0037&amp;dbid=16384&amp;doi=10.1016%2FS1071-5819%2803%2900015-6&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1016%252FS1071-5819%252803%252900015-6%26sid%3Dliteratum%253Atandf%26aulast%3DStanney%26aufirst%3DK.%2520M.%26date%3D2003%26atitle%3DUsability%2520engineering%2520of%2520virtual%2520environments%2520%2528VEs%2529%253A%2520Identifying%2520multiple%2520criteria%2520that%2520drive%2520effective%2520VE%2520system%2520design%26jtitle%3DInternational%2520Journal%2520of%2520Human-Computer%2520Studies%26volume%3D58%26issue%3D4%26spage%3D447%26epage%3D481" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0038"><span><span class="hlFld-ContribAuthor">Stanney, <span class="NLM_given-names">K. M.</span></span>, <span class="hlFld-ContribAuthor">Mourant, <span class="NLM_given-names">R. R.</span></span>, &amp; <span class="hlFld-ContribAuthor">Kennedy, <span class="NLM_given-names">R. S.</span></span> (<span class="NLM_year">1998</span>). <span class="NLM_article-title">Human factors issues in virtual environments: A review of the literature</span>. <i>Presence: Teleoperators and Virtual Environments</i>, 7(4), <span class="NLM_fpage">327</span>–<span class="NLM_lpage">351</span>. doi:<span class="NLM_pub-id">10.1162/105474698565767</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0038&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1162%2F105474698565767" target="_blank">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0038&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000075186200001" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=1998&pages=327-351&issue=4&author=K.+M.+Stanney&author=R.+R.+Mourant&author=R.+S.+Kennedy&title=Human+factors+issues+in+virtual+environments%3A+A+review+of+the+literature" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0038&amp;dbid=16384&amp;doi=10.1162%2F105474698565767&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1162%252F105474698565767%26sid%3Dliteratum%253Atandf%26aulast%3DStanney%26aufirst%3DK.%2520M.%26date%3D1998%26atitle%3DHuman%2520factors%2520issues%2520in%2520virtual%2520environments%253A%2520A%2520review%2520of%2520the%2520literature%26jtitle%3DPresence%253A%2520Teleoperators%2520and%2520Virtual%2520Environments%26volume%3D7%26issue%3D4%26spage%3D327%26epage%3D351" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0039"><span>Statista. (<span class="NLM_year">2016</span>). <span class="NLM_article-title">Virtual reality hardware market size worldwide from 2016 to 2020</span>. <a class="ext-link" href="https://www.statista.com/statistics/550461/virtual-reality-market-size-worldwide/" target="_blank">https://www.statista.com/statistics/550461/virtual-reality-market-size-worldwide/</a><span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2016&author=Statista&title=Virtual+reality+hardware+market+size+worldwide+from+2016+to+2020" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0039&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aucorp%3DStatista%26date%3D2016%26atitle%3DVirtual%2520reality%2520hardware%2520market%2520size%2520worldwide%2520from%25202016%2520to%25202020https%3A%2F%2Fwww.statista.com%2Fstatistics%2F550461%2Fvirtual-reality-market-size-worldwide%2F" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0040"><span>Statista. (<span class="NLM_year">2017</span>). <span class="NLM_article-title"><i>Share of virtual reality head-mounted display unit sales worldwide in 2016 and 2020</i></span>. <a class="ext-link" href="https://www.statista.com/statistics/697171/head-mounted-display-unit-sales-share-by-platform-worldwide/" target="_blank">https://www.statista.com/statistics/697171/head-mounted-display-unit-sales-share-by-platform-worldwide/</a><span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2017&author=Statista&title=Share+of+virtual+reality+head-mounted+display+unit+sales+worldwide+in+2016+and+2020" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0040&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aucorp%3DStatista%26date%3D2017%26atitle%3DShare%2520of%2520virtual%2520reality%2520head-mounted%2520display%2520unit%2520sales%2520worldwide%2520in%25202016%2520and%25202020https%3A%2F%2Fwww.statista.com%2Fstatistics%2F697171%2Fhead-mounted-display-unit-sales-share-by-platform-worldwide%2F" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0041"><span><span class="hlFld-ContribAuthor">Steed, <span class="NLM_given-names">A.</span></span> (<span class="NLM_year">2006</span>). <span class="NLM_article-title">Towards a general model for selection in virtual environments</span>. <i>3D User Interfaces</i> (3DUI’06). <span class="NLM_fpage">103</span>–<span class="NLM_lpage">110</span>.<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2006&pages=103-110&author=A.+Steed&title=Towards+a+general+model+for+selection+in+virtual+environments" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0041&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DSteed%26aufirst%3DA.%26date%3D2006%26atitle%3DTowards%2520a%2520general%2520model%2520for%2520selection%2520in%2520virtual%2520environments%26jtitle%3D3D%2520User%2520Interfaces%26spage%3D103%26epage%3D110" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0042"><span><span class="hlFld-ContribAuthor">Steed, <span class="NLM_given-names">A.</span></span>, &amp; <span class="hlFld-ContribAuthor">Julier, <span class="NLM_given-names">S.</span></span> (<span class="NLM_year">2013</span>). <span class="NLM_article-title"><i>Design and implementation of an immersive virtual reality system based on a smartphone platform</i></span>. <span class="NLM_conf-name">3D User Interfaces</span> (3DUI), <span class="NLM_publisher-name">2013 IEEE Symposium on, 43–46</span>.<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2013&author=A.+Steed&author=S.+Julier&title=Design+and+implementation+of+an+immersive+virtual+reality+system+based+on+a+smartphone+platform" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0042&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DSteed%26aufirst%3DA.%26date%3D2013%26atitle%3DDesign%2520and%2520implementation%2520of%2520an%2520immersive%2520virtual%2520reality%2520system%2520based%2520on%2520a%2520smartphone%2520platform%26pub%3D2013%2520IEEE%2520Symposium%2520on%252C%252043%25E2%2580%259346" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0043"><span><span class="hlFld-ContribAuthor">Steptoe, <span class="NLM_given-names">W.</span></span>, <span class="hlFld-ContribAuthor">Oyekoya, <span class="NLM_given-names">O.</span></span>, <span class="hlFld-ContribAuthor">Murgia, <span class="NLM_given-names">A.</span></span>, <span class="hlFld-ContribAuthor">Wolff, <span class="NLM_given-names">R.</span></span>, <span class="hlFld-ContribAuthor">Rae, <span class="NLM_given-names">J.</span></span>, <span class="hlFld-ContribAuthor">Guimaraes, <span class="NLM_given-names">E.</span></span>, &amp; <span class="hlFld-ContribAuthor">Steed, <span class="NLM_given-names">A.</span></span> (<span class="NLM_year">2009</span>). <span class="NLM_article-title"><i>Eye tracking for avatar eye gaze control during object-focused multiparty interaction in immersive collaborative virtual environments</i></span>. <span class="NLM_conf-name">Virtual reality conference</span> (pp. <span class="NLM_fpage">83</span>–<span class="NLM_lpage">90</span>).<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2009&author=W.+Steptoe&author=O.+Oyekoya&author=A.+Murgia&author=R.+Wolff&author=J.+Rae&author=E.+Guimaraes&author=A.+Steed&title=Eye+tracking+for+avatar+eye+gaze+control+during+object-focused+multiparty+interaction+in+immersive+collaborative+virtual+environments" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0043&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DSteptoe%26aufirst%3DW.%26date%3D2009%26atitle%3DEye%2520tracking%2520for%2520avatar%2520eye%2520gaze%2520control%2520during%2520object-focused%2520multiparty%2520interaction%2520in%2520immersive%2520collaborative%2520virtual%2520environments%26spage%3D83%26epage%3D90" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0044"><span><span class="hlFld-ContribAuthor">Sutcliffe, <span class="NLM_given-names">A. G.</span></span>, &amp; <span class="hlFld-ContribAuthor">Kaur, <span class="NLM_given-names">K. D.</span></span> (<span class="NLM_year">2000</span>). <span class="NLM_article-title">Evaluating the usability of virtual reality user interfaces</span>. <i>Behaviour &amp; Information Technology</i>, 19(6), <span class="NLM_fpage">415</span>–<span class="NLM_lpage">426</span>. doi:<span class="NLM_pub-id">10.1080/014492900750052679</span><span class="refLink-block"> <span class="xlinks-container"><a href="https://www.tandfonline.com/doi/10.1080/014492900750052679" target="_blank">[Taylor &amp; Francis Online]</a>, <a href="/servlet/linkout?suffix=CIT0044&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000166198000004" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2000&pages=415-426&issue=6&author=A.+G.+Sutcliffe&author=K.+D.+Kaur&title=Evaluating+the+usability+of+virtual+reality+user+interfaces" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0044&amp;dbid=16384&amp;doi=10.1080%2F014492900750052679&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1080%252F014492900750052679%26sid%3Dliteratum%253Atandf%26aulast%3DSutcliffe%26aufirst%3DA.%2520G.%26date%3D2000%26atitle%3DEvaluating%2520the%2520usability%2520of%2520virtual%2520reality%2520user%2520interfaces%26jtitle%3DBehaviour%2520%2526%2520Information%2520Technology%26volume%3D19%26issue%3D6%26spage%3D415%26epage%3D426" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0045"><span><span class="hlFld-ContribAuthor">Sutherland, <span class="NLM_given-names">I. E.</span></span> (<span class="NLM_year">1968</span>). <span class="NLM_article-title"><i>A head-mounted three dimensional display</i></span>. <span class="NLM_conf-name">Proceedings of the December 9–11, 1968, fall joint computer conference, part I</span> (pp. <span class="NLM_fpage">757</span>–<span class="NLM_lpage">764</span>).<span class="refLink-block"> <span class="xlinks-container"></span><span class="googleScholar-container"><a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=1968&author=I.+E.+Sutherland&title=A+head-mounted+three+dimensional+display" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0045&amp;dbid=16384&amp;doi=&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26sid%3Dliteratum%253Atandf%26aulast%3DSutherland%26aufirst%3DI.%2520E.%26date%3D1968%26atitle%3DA%2520head-mounted%2520three%2520dimensional%2520display%26spage%3D757%26epage%3D764" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0046"><span><span class="hlFld-ContribAuthor">Trudeau, <span class="NLM_given-names">M. B.</span></span>, <span class="hlFld-ContribAuthor">Asakawa, <span class="NLM_given-names">D. S.</span></span>, <span class="hlFld-ContribAuthor">Jindrich, <span class="NLM_given-names">D. L.</span></span>, &amp; <span class="hlFld-ContribAuthor">Dennerlein, <span class="NLM_given-names">J. T.</span></span> (<span class="NLM_year">2016</span>). <span class="NLM_article-title">Two-handed grip on a mobile phone affords greater thumb motor performance, decreased variability, and a more extended thumb posture than a one-handed grip</span>. <i>Applied Ergonomics</i>, 52, <span class="NLM_fpage">24</span>–<span class="NLM_lpage">28</span>. doi:<span class="NLM_pub-id">10.1016/j.apergo.2015.06.025</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0046&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1016%2Fj.apergo.2015.06.025" target="_blank">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0046&amp;dbid=8&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=26360191" target="_blank">[PubMed]</a>, <a href="/servlet/linkout?suffix=CIT0046&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000362133400004" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2016&pages=24-28&author=M.+B.+Trudeau&author=D.+S.+Asakawa&author=D.+L.+Jindrich&author=J.+T.+Dennerlein&title=Two-handed+grip+on+a+mobile+phone+affords+greater+thumb+motor+performance%2C+decreased+variability%2C+and+a+more+extended+thumb+posture+than+a+one-handed+grip" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0046&amp;dbid=16384&amp;doi=10.1016%2Fj.apergo.2015.06.025&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1016%252Fj.apergo.2015.06.025%26sid%3Dliteratum%253Atandf%26aulast%3DTrudeau%26aufirst%3DM.%2520B.%26date%3D2016%26atitle%3DTwo-handed%2520grip%2520on%2520a%2520mobile%2520phone%2520affords%2520greater%2520thumb%2520motor%2520performance%252C%2520decreased%2520variability%252C%2520and%2520a%2520more%2520extended%2520thumb%2520posture%2520than%2520a%2520one-handed%2520grip%26jtitle%3DApplied%2520Ergonomics%26volume%3D52%26spage%3D24%26epage%3D28" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0047"><span><span class="hlFld-ContribAuthor">Welch, <span class="NLM_given-names">R. B.</span></span>, <span class="hlFld-ContribAuthor">Blackmon, <span class="NLM_given-names">T. T.</span></span>, <span class="hlFld-ContribAuthor">Liu, <span class="NLM_given-names">A.</span></span>, <span class="hlFld-ContribAuthor">Mellers, <span class="NLM_given-names">B. A.</span></span>, &amp; <span class="hlFld-ContribAuthor">Stark, <span class="NLM_given-names">L. W.</span></span> (<span class="NLM_year">1996</span>). <span class="NLM_article-title">The effects of pictorial realism, delay of visual feedback, and observer interactivity on the subjective sense of presence</span>. <i>Presence: Teleoperators &amp; Virtual Environments</i>, 5(3), <span class="NLM_fpage">263</span>–<span class="NLM_lpage">273</span>. doi:<span class="NLM_pub-id">10.1162/pres.1996.5.3.263</span><span class="refLink-block"> <span class="xlinks-container"><a href="/servlet/linkout?suffix=CIT0047&amp;dbid=16&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=10.1162%2Fpres.1996.5.3.263" target="_blank">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0047&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=A1996VF83500001" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=1996&pages=263-273&issue=3&author=R.+B.+Welch&author=T.+T.+Blackmon&author=A.+Liu&author=B.+A.+Mellers&author=L.+W.+Stark&title=The+effects+of+pictorial+realism%2C+delay+of+visual+feedback%2C+and+observer+interactivity+on+the+subjective+sense+of+presence" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0047&amp;dbid=16384&amp;doi=10.1162%2Fpres.1996.5.3.263&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1162%252Fpres.1996.5.3.263%26sid%3Dliteratum%253Atandf%26aulast%3DWelch%26aufirst%3DR.%2520B.%26date%3D1996%26atitle%3DThe%2520effects%2520of%2520pictorial%2520realism%252C%2520delay%2520of%2520visual%2520feedback%252C%2520and%2520observer%2520interactivity%2520on%2520the%2520subjective%2520sense%2520of%2520presence%26jtitle%3DPresence%253A%2520Teleoperators%2520%2526%2520Virtual%2520Environments%26volume%3D5%26issue%3D3%26spage%3D263%26epage%3D273" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0048"><span><span class="hlFld-ContribAuthor">Westerman, <span class="NLM_given-names">S. J.</span></span>, <span class="hlFld-ContribAuthor">Cribbin, <span class="NLM_given-names">T.</span></span>, &amp; <span class="hlFld-ContribAuthor">Wilson, <span class="NLM_given-names">R.</span></span> (<span class="NLM_year">2001</span>). <span class="NLM_article-title">Virtual information space navigation: Evaluating the use of head tracking</span>. <i>Behaviour &amp; Information Technology</i>, 20(6), <span class="NLM_fpage">419</span>–<span class="NLM_lpage">426</span>. doi:<span class="NLM_pub-id">10.1080/01449290110069383</span><span class="refLink-block"> <span class="xlinks-container"><a href="https://www.tandfonline.com/doi/10.1080/01449290110069383" target="_blank">[Taylor &amp; Francis Online]</a>, <a href="/servlet/linkout?suffix=CIT0048&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000173420900003" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2001&pages=419-426&issue=6&author=S.+J.+Westerman&author=T.+Cribbin&author=R.+Wilson&title=Virtual+information+space+navigation%3A+Evaluating+the+use+of+head+tracking" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0048&amp;dbid=16384&amp;doi=10.1080%2F01449290110069383&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1080%252F01449290110069383%26sid%3Dliteratum%253Atandf%26aulast%3DWesterman%26aufirst%3DS.%2520J.%26date%3D2001%26atitle%3DVirtual%2520information%2520space%2520navigation%253A%2520Evaluating%2520the%2520use%2520of%2520head%2520tracking%26jtitle%3DBehaviour%2520%2526%2520Information%2520Technology%26volume%3D20%26issue%3D6%26spage%3D419%26epage%3D426" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li><li id="CIT0049"><span><span class="hlFld-ContribAuthor">Yang, <span class="NLM_given-names">U.</span></span>, &amp; <span class="hlFld-ContribAuthor">Kim, <span class="NLM_given-names">G. J.</span></span> (<span class="NLM_year">2010</span>). <span class="NLM_article-title">Increasing the geometric field of view in head mounted displays through proprioceptive task and multimodal feedback for effective close range interaction</span>. <i>Behaviour &amp; Information Technology</i>, 29(2), <span class="NLM_fpage">175</span>–<span class="NLM_lpage">186</span>. doi:<span class="NLM_pub-id">10.1080/01449290903160459</span><span class="refLink-block"> <span class="xlinks-container"><a href="https://www.tandfonline.com/doi/10.1080/01449290903160459" target="_blank">[Taylor &amp; Francis Online]</a>, <a href="/servlet/linkout?suffix=CIT0049&amp;dbid=128&amp;doi=10.1080%2F10447318.2018.1484054&amp;key=000275160400007" target="_blank">[Web of Science &#0174;]</a></span><span class="googleScholar-container">, <a class="google-scholar" href="http://scholar.google.com/scholar_lookup?hl=en&publication_year=2010&pages=175-186&issue=2&author=U.+Yang&author=G.+J.+Kim&title=Increasing+the+geometric+field+of+view+in+head+mounted+displays+through+proprioceptive+task+and+multimodal+feedback+for+effective+close+range+interaction" target="_blank">[Google Scholar]</a></span></span><a href="/servlet/linkout?suffix=CIT0049&amp;dbid=16384&amp;doi=10.1080%2F01449290903160459&amp;type=refOpenUrl&amp;url=https%3A%2F%2Fsoeg.kb.dk%2Fdiscovery%2Fopenurl%3Finstitution%3D45KBDK_KGL%26vid%3D45KBDK_KGL%3AKGL%26%26id%3Ddoi%3A10.1080%252F01449290903160459%26sid%3Dliteratum%253Atandf%26aulast%3DYang%26aufirst%3DU.%26date%3D2010%26atitle%3DIncreasing%2520the%2520geometric%2520field%2520of%2520view%2520in%2520head%2520mounted%2520displays%2520through%2520proprioceptive%2520task%2520and%2520multimodal%2520feedback%2520for%2520effective%2520close%2520range%2520interaction%26jtitle%3DBehaviour%2520%2526%2520Information%2520Technology%26volume%3D29%26issue%3D2%26spage%3D175%26epage%3D186" title="OpenURL Copenhagen University Library" class="sfxLink" aria-label="OpenURL Copenhagen University Library"><img src="/userimages/78554/sfxbutton" alt="OpenURL Copenhagen University Library" /></a></span></li></div></ul><div class="author-infos"><h2>Additional information</h2><h3>Author information</h3><div id="B0001" class="addAuthorInfo"><span class="AuthorInfoData"><h4><span class="NLM_given-names">Mungyeong</span> Choe</h4><div></div><i>Mungyeong Choe</i> is an M.S. candidate in Industrial and Management Engineering at Incheon National University. Her research interests include human-computer interaction, virtual reality, and eye tracking.</span></div><div id="B0002" class="addAuthorInfo"><span class="AuthorInfoData"><h4><span class="NLM_given-names">Yeongcheol</span> Choi</h4><div></div><i>Yeongcheol Choi</i> received a B.S. degree in Industrial and Management Engineering from Incheon National University.</span></div><div id="B0003" class="addAuthorInfo"><span class="AuthorInfoData"><h4><span class="NLM_given-names">Jaehyun</span> Park</h4><div></div><i>Jaehyun Park</i> is is an Assistant Professor in the Department of Industrial and Management Engineering at Incheon National University (INU). He received B.S degree and Ph.D degree in Industrial and Management Engineering from POSTECH (Pohang University of Science and Technology). His research interests are human-computer interaction (HCI), user experience (UX) and user value (UV).</span></div><div id="B0004" class="addAuthorInfo"><span class="AuthorInfoData"><h4><span class="NLM_given-names">Hyun K.</span> Kim</h4><div></div><i>Hyun K. Kim</i> is a senior UX designer in Samsung Electronics currently. She received B.S degree and Ph.D degree in Industrial and Management Engineering from POSTECH (Pohang University of Science and Technology). Her research interests are human-computer system, user experience and accessibility.</span></div><div id="Funding"><h3 class="section-heading-3">Funding</h3><div class="funding-statement">This work was supported by the Incheon National University Research Grant in 2015 (Grant No.: 20151379).</div></div></div><div class="response"><div class="sub-article-title"></div></div>
</article>
</div>
<div class="tab tab-pane" id="relatedContent">
</div>
<div class="tab tab-pane " id="metrics-content">
<div class="articleMetaDrop publicationContentDropZone publicationContentDropZoneMetrics" data-pb-dropzone="publicationContentDropZoneMetrics">

<div class="widget literatumArticleMetricsWidget none  widget-none" id="00886058-9b49-4cdf-9f1e-deb78b7818c3">
<div class="wrapped ">
<div class="widget-body body body-none "><div class="articleMetricsContainer">
<div class="content fullView">
<h2>
Article Metrics
</h2>
<div class="section views">
<div class="title">
Views
</div>
<div class="circle">
<span class="value">466</span>
</div>
</div>
<div class="section citations">
<div class="title">
Citations
</div>
<a href="/doi/citedby/10.1080/10447318.2018.1484054" class="circle crossRef " target="_blank">
<span>
Crossref
</span>
<span class="value">3</span>
</a>
<a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&DestApp=WOS_CPL&UsrCustomerID=5e3815c904498985e796fc91436abd9a&SrcAuth=atyponcel&SrcApp=literatum&DestLinkType=CitingArticles&KeyUT=000460523000008" target="_blank" class="circle webOfScience disableLink">
<span>
Web of Science
</span>
<span class="value">0</span>
</a>
<a href="http://www.scopus.com/inward/citedby.url?partnerID=HzOxMe3b&scp=85048842005" target="_blank" class="circle scopus ">
<span>
Scopus
</span>
<span class="value">1</span>
</a>
</div>
<div class="section altmetric-container">
<div class="title">
Altmetric
</div>
<script type="text/javascript">
    TandfUtils.appendScript(document.head, 'https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js', 'altmetric-embed-src', true, true);
</script>
<div class="metrics-badge linkToPopup">
<div class='altmetric-embed' data-badge-type='medium-donut' data-badge-details='right' data-condensed='true' data-template="tandf" data-hide-no-mentions="false" data-doi="10.1080/10447318.2018.1484054">
</div>
</div>
</div>
<div class="altmetricsPopup"></div>
</div>
</div>
<div class="metricsLinks">
<a href="/article-metrics">Article metrics information</a>
<br>
<a href="/article-citations-disclaimer">Disclaimer for citing articles</a>
</div></div>
</div>
</div>
</div>
</div>
<div class="access__limit" data-pb-dropzone="accessLimitPage">
</div>
</div>
</div>
</div>
<input id="viewLargeImageCaption" type="hidden" value="View Large Image" /></div>
</div>
</div>
</div>
</div>
</div>
</div></div>
</div>
</div>
</div>
</div>
<div class="col-md-1-4 ">
<div class="contents" data-pb-dropzone="contents2">
<div class="widget general-bookmark-share none  widget-none  widget-compact-all" id="c8494935-e102-4ff5-9395-4ffa44a77f1c">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all">
<ul>
<li>
<div class="addthis_toolbox addthis_20x20_style">
<div class="custom_images">
<a class="addthis_button_twitter">
<span class="at-icon-twitter"></span>
</a>
<a class="addthis_button_facebook">
<span class="at-icon-facebook"></span>
</a>
<a class="addthis_button_email">
<span class="at-icon-email"></span>
</a>
<a class="addthis_button_none">
<span class="at-icon-none"></span>
</a>
<a class="addthis_button_compact"><span class="at-icon-wrapper"></span>
<span aria-describedby="shareOptions-description">
<span class="off-screen" id="shareOptions-description">More Share Options</span>
</span>
</a>
</div>
</div>
</li>
</ul>
<script type="text/javascript">
    
    var script = document.createElement('script');
    script.type='text/javascript';
    script.src='//s7.addthis.com/js/250/addthis_widget.js#pubid=xa-4faab26f2cff13a7';
    script.async = true;
    $('head').append(script)
</script>
</div>
</div>
</div>
<div class="widget general-html none  widget-none" id="16111d74-c554-42b2-a277-f2727ad2b285">
<div class="wrapped ">
<div class="widget-body body body-none ">&nbsp;</div>
</div>
</div>
<div class="widget general-html none  widget-none  widget-compact-all" id="649c3793-a589-4dfb-8de2-9b6cbc4dc15b">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><script defer src='//js.trendmd.com/trendmd.min.js' data-trendmdconfig='{"element":"#trendmd-suggestions"}'></script></div>
</div>
</div>

<div class="widget graphQueryWidget none  widget-none  widget-compact-all" id="6583d550-25db-458c-9c81-291f5c88b6ee">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div id="trendmd-suggestions"></div></div>
</div>
</div>
<div class="widget pbOptimizerWidget none  widget-none  widget-compact-all" id="25efeb89-6948-4246-800a-5e246009698d">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div data-optimizer data-widget-id="25efeb89-6948-4246-800a-5e246009698d" id="widget-25efeb89-6948-4246-800a-5e246009698d" data-observer>
</div></div>
</div>
</div>
</div>
</div>
</div>
</div></div>
</div>
</div>
</div>
</div></div>
</div>
</div>
<div class="widget pageFooter none  widget-none  widget-compact-all" id="d97c173f-d838-4de1-bbd7-ed69f0d36a91">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><footer class="page-footer">
<div data-pb-dropzone="main">
<div class="widget responsive-layout none footer-subjects hidden-xs hidden-sm widget-none  widget-compact-all" id="1f15adc0-4a59-4d27-93fe-8cbb14a5108a">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="container">
<div class="row row-md gutterless ">
<div class="col-md-1-1 fit-padding">
<div class="contents" data-pb-dropzone="contents0">
<div class="widget topicalIndex none  widget-none  widget-compact-all" id="9298c7a6-6903-4607-8380-4c83e2b7142f">
<div class="wrapped ">
<h1 class="widget-header header-none  header-compact-all">Browse journals by subject</h1>
<div class="widget-body body body-none  body-compact-all"><div class="topicalIndexBrowsingTips" data-pb-dropzone="topicalIndexBrowsingTips">
<div class="widget general-html none  widget-none  widget-compact-all" id="1ec3bad2-243b-45a9-a59a-5aceb80fc5a1">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><a class="nav-top" href="#top">Back to top <span class="fa fa-angle-up"></span></a></div>
</div>
</div>
</div>
<div class="container">
<ul>
<li>
<a href="/topic/allsubjects/as?target=topic&amp;ConceptID=4251">Area Studies</a>
</li>
<li>
<a href="/topic/allsubjects/ar?target=topic&amp;ConceptID=4250">Arts</a>
</li>
<li>
<a href="/topic/allsubjects/be?target=topic&amp;ConceptID=4252">Behavioral Sciences</a>
</li>
<li>
<a href="/topic/allsubjects/bs?target=topic&amp;ConceptID=4253">Bioscience</a>
</li>
<li>
<a href="/topic/allsubjects/bu?target=topic&amp;ConceptID=4254">Built Environment</a>
</li>
<li>
<a href="/topic/allsubjects/cs?target=topic&amp;ConceptID=4256">Communication Studies</a>
</li>
<li>
<a href="/topic/allsubjects/cm?target=topic&amp;ConceptID=4255">Computer Science</a>
</li>
<li>
<a href="/topic/allsubjects/ds?target=topic&amp;ConceptID=4257">Development Studies</a>
</li>
<li>
<a href="/topic/allsubjects/ea?target=topic&amp;ConceptID=4258">Earth Sciences</a>
</li>
<li>
<a href="/topic/allsubjects/eb?target=topic&amp;ConceptID=4259">Economics, Finance, Business & Industry</a>
</li>
<li>
<a href="/topic/allsubjects/ed?target=topic&amp;ConceptID=4261">Education</a>
</li>
<li>
<a href="/topic/allsubjects/ec?target=topic&amp;ConceptID=4260">Engineering & Technology</a>
</li>
<li>
<a href="/topic/allsubjects/ag?target=topic&amp;ConceptID=4248">Environment & Agriculture</a>
</li>
<li>
<a href="/topic/allsubjects/es?target=topic&amp;ConceptID=4262">Environment and Sustainability</a>
</li>
<li>
<a href="/topic/allsubjects/fs?target=topic&amp;ConceptID=4263">Food Science & Technology</a>
</li>
<li>
<a href="/topic/allsubjects/ge?target=topic&amp;ConceptID=4264">Geography</a>
</li>
<li>
<a href="/topic/allsubjects/hs?target=topic&amp;ConceptID=4266">Health and Social Care</a>
</li>
<li>
<a href="/topic/allsubjects/hu?target=topic&amp;ConceptID=4267">Humanities</a>
</li>
<li>
<a href="/topic/allsubjects/if?target=topic&amp;ConceptID=4268">Information Science</a>
</li>
<li>
<a href="/topic/allsubjects/la?target=topic&amp;ConceptID=4269">Language & Literature</a>
</li>
<li>
<a href="/topic/allsubjects/lw?target=topic&amp;ConceptID=4270">Law</a>
</li>
<li>
<a href="/topic/allsubjects/ma?target=topic&amp;ConceptID=4271">Mathematics & Statistics</a>
</li>
<li>
<a href="/topic/allsubjects/me?target=topic&amp;ConceptID=4272">Medicine, Dentistry, Nursing & Allied Health</a>
</li>
<li>
<a href="/topic/allsubjects/ah?target=topic&amp;ConceptID=4249">Museum and Heritage Studies</a>
</li>
<li>
<a href="/topic/allsubjects/pc?target=topic&amp;ConceptID=4273">Physical Sciences</a>
</li>
<li>
<a href="/topic/allsubjects/pi?target=topic&amp;ConceptID=4274">Politics & International Relations</a>
</li>
<li>
<a href="/topic/allsubjects/sn?target=topic&amp;ConceptID=4278">Social Sciences</a>
</li>
<li>
<a href="/topic/allsubjects/sl?target=topic&amp;ConceptID=4277">Sports and Leisure</a>
</li>
<li>
<a href="/topic/allsubjects/sp?target=topic&amp;ConceptID=4279">Tourism, Hospitality and Events</a>
</li>
<li>
<a href="/topic/allsubjects/us?target=topic&amp;ConceptID=4280">Urban Studies</a>
</li>
</ul>
</div></div>
</div>
</div>
</div>
</div>
</div>
</div></div>
</div>
</div>
<div class="widget responsive-layout none footer-links widget-none  widget-compact-horizontal" id="64a44adf-45ed-4da3-be26-ef25beb9dbee">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-horizontal"><div class="container">
<div class="row row-md  ">
<div class="col-md-1-2 ">
<div class="contents" data-pb-dropzone="contents0">
<div class="widget responsive-layout none footer-responsive-container widget-none" id="6918e9df-910a-4206-9bd0-1a02bc17f740">
<div class="wrapped ">
<div class="widget-body body body-none "><div class="container-fluid">
<div class="row row-sm  ">
<div class="col-sm-1-2 footer_left_col">
<div class="contents" data-pb-dropzone="contents0">

<div class="widget general-html none  widget-none  widget-compact-all" id="aa9510dd-52ed-4b74-8211-fb510cd9468e">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="footer-info-list">
<h3>Information for</h3>
<ul>
<li><a href="http://authorservices.taylorandfrancis.com/">Authors</a></li>
<li><a href="http://editorresources.taylorandfrancisgroup.com/">Editors</a></li>
<li><a href="/page/librarians">Librarians</a></li>
<li><a href="/societies">Societies</a></li>
</ul>
</div></div>
</div>
</div>
</div>
</div>
<div class="col-sm-1-2 footer_right_col">
<div class="contents" data-pb-dropzone="contents1">
<div class="widget general-html none  widget-none  widget-compact-all" id="ac8a1c0f-9427-44dd-96be-4f2a6ff4ffce">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="footer-info-list">
<h3>Open access</h3>
<ul>
<li><a href="/openaccess">Overview</a></li>
<li><a href="/openaccess/openjournals">Open journals</a></li>
<li><a href="/openaccess/openselect">Open Select</a></li>
<li><a href="https://www.cogentoa.com/">Cogent OA</a></li>
</ul>
</div></div>
</div>
</div>
</div>
</div>
</div>
</div></div>
</div>
</div>
</div>
</div>
<div class="col-md-1-2 ">
<div class="contents" data-pb-dropzone="contents1">
<div class="widget responsive-layout none footer-responsive-container widget-none" id="fc564559-f496-499c-87c7-d851f371f061">
<div class="wrapped ">
<div class="widget-body body body-none "><div class="container-fluid">
<div class="row row-sm  ">
<div class="col-sm-1-2 footer_left_col">
<div class="contents" data-pb-dropzone="contents0">
<div class="widget general-html none  widget-none  widget-compact-all" id="f3fb3d36-db42-4373-9d0e-432958bf2fbc">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="footer-info-list">
<h3>Help and info</h3>
<ul>
<li><a href="https://help.tandfonline.com">Help & contact</a></li>
<li><a href="https://newsroom.taylorandfrancisgroup.com/">Newsroom</a></li>
<li><a href="https://taylorandfrancis.com/partnership/commercial/">Commercial services</a></li>
<li><a href="/action/showPublications?pubType=journal">All journals</a></li>
<li><a href="https://www.routledge.com/?utm_source=website&amp;utm_medium=banner&amp;utm_campaign=B004808_em1_10p_5ec_d713_footeradspot">Books</a></li>
</ul>
</div></div>
</div>
</div>
</div>
</div>
<div class="col-sm-1-2 footer_right_col">
<div class="contents" data-pb-dropzone="contents1">
<div class="widget general-html none  widget-none  widget-compact-all" id="914433f6-0ea6-4a47-9781-07564061be86">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="footer-social-label">
<h3>Keep up to date</h3>
</div>
<div class="font-size-correction-sml">Register to receive personalised research and resources by email</div>
<div class="bs">
<div class="pull-left links font-size-correction">
<a class="font-size-correction-link" href="https://taylorandfrancis.formstack.com/forms/tfoguest_signup"><i class="fa fa-envelope-square" title="Register to receive personalised research and resources by email"></i>Sign me up</a>
</div></div></div>
</div>
</div>

<div class="widget literatumSocialLinks none  widget-none  widget-compact-all" id="3b6a5e53-cd62-452f-adc1-92e187a0849d">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="bs">
<div class="pull-left links">
<a href="http://facebook.com/TaylorandFrancisGroup">
<i class="icon-facebook" title="Taylor and Francis Group Facebook page" aria-hidden="true" role="button"></i>
<span aria-describedby="fb-description">
<span class="off-screen" id="fb-description">Taylor and Francis Group Facebook page</span>
</span>
</a>
</div>
<div class="pull-left links">
<a href="https://twitter.com/tandfonline">
<i class="fa fa-twitter-square" title="Taylor and Francis Group Twitter page" aria-hidden="true" role="button"></i>
<span aria-describedby="twitter-description">
<span class="off-screen" id="twitter-description">Taylor and Francis Group Twitter page</span>
</span>
</a>
</div>
<div class="pull-left links">
<a href="http://linkedin.com/company/taylor-&-francis-group">
<i class="fa fa-linkedin-square" title="Taylor and Francis Group LinkedIn page" aria-hidden="true" role="button"></i>
<span aria-describedby="linkedin-description">
<span class="off-screen" id="linkedin-description">Taylor and Francis Group Linkedin page</span>
</span>
</a>
</div>
<div class="clearfix"></div>
<div class="pull-left links">
<a href="https://www.youtube.com/user/TaylorandFrancis">
<i class="fa fa-youtube-square" title="Taylor and Francis Group YouTube page" aria-hidden="true" role="button"></i>
<span aria-describedby="youtube-description">
<span class="off-screen" id="youtube-description">Taylor and Francis Group Youtube page</span>
</span>
</a>
</div>
<div class="pull-left links">
<a href="http://www.weibo.com/tandfchina">
<i class="fa fa-weibo" title="Taylor and Francis Group Weibo page" aria-hidden="true" role="button"></i>
<span aria-describedby="weibo-description">
<span class="off-screen" id="weibo-description">Taylor and Francis Group Weibo page</span>
</span>
</a>
</div>
<div class="clearfix"></div>
</div></div>
</div>
</div>
</div>
</div>
</div>
</div></div>
</div>
</div>
</div>
</div>
</div>
</div></div>
</div>
</div>
<div class="widget responsive-layout none  widget-none  widget-compact-horizontal" id="8d803f96-081d-4768-ab7d-280a77af723b">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-horizontal"><div class="container">
<div class="row row-sm  ">
<div class="col-sm-3-4 ">
<div class="contents" data-pb-dropzone="contents0">
<div class="widget general-html none footer-info-container widget-none  widget-compact-vertical" id="b247ecb9-84c9-4762-b270-20f8be1f0ae4">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-vertical"><div class="informa-group-info">
<span>Copyright © 2020 Informa UK Limited</span>
<span><a href="https://informa.com/privacy-policy/">Privacy policy</a></span>
<span><a href="/cookies">Cookies</a></span>
<span><a href="/terms-and-conditions">Terms & conditions</a></span>
<span><a href="/accessibility">Accessibility</a></span>
<p>Registered in England & Wales No. 3099067<br />
5 Howick Place | London | SW1P 1WG</p>
</div></div>
</div>
</div>
</div>
</div>
<div class="col-sm-1-4 footer_tandf_logo">
<div class="contents" data-pb-dropzone="contents1">
<div class="widget general-image none  widget-none  widget-compact-vertical" id="b6bde365-079b-454f-94f6-1841291656a1">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-vertical"><a href="http://taylorandfrancis.com/" title="Taylor and Francis Group">
<img src="/pb-assets/Global/Group-logo-white-on-transparent-1468512845090.png" alt="Taylor and Francis Group" />
</a></div>
</div>
</div>
</div>
</div>
</div>
</div></div>
</div>
</div>

<div class="widget cookiePolicy none  widget-none  widget-compact-all" id="cea739ac-da2c-4d77-9cf1-cb3e0da7e31e">
<div class="wrapped ">
<div class="widget-body body body-none  body-compact-all"><div class="banner">
<a href="#" class="btn">Accept</a>
<p class="message">We use cookies to improve your website experience. To learn about our use of cookies and how you can manage your cookie settings, please see our <a href="/cookies">Cookie Policy.</a> By closing this message, you are consenting to our use of cookies.</p>
</div></div>
</div>
</div>
</div>
</footer></div>
</div>
</div>
</div>
</div>
</body>
</html>
