{"papers": [{"title": "On the Efficiency of a VR Hand Gesture-Based Interface for 3D Object Manipulations in Conceptual Design", "authors": ["Remi Alkemade", "Stephan G. Lukosch"], "abstract": "ABSTRACTIn the early stages of 3D design, sketches are used to quickly conceptualize ideas and gain insight into problems and possible solutions. Computer-aided design tools are widely used for 3D modeling and design, but their required precision and 2D mouse and screen-based interface inhibit the flow of ideas. A study was conducted to explore the efficiency of hand tracking and virtual reality (VR) for 3D object manipulations in conceptual design. Based on existing research on conceptual design and hand gestures, an intuitive hand-based interaction model is proposed. An experiment on basic 3D manipulation shows that participants using a simple VR and hand-tracking interface prototype have similar performance to those using a traditional mouse and screen interface. For the improvement of gestural conceptual design interfaces, the relevant issues are identified.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 33, 2017 - Issue 11", "publication_date": "31 Mar 2017", "citations": "12", "isbn": "", "doi": "10.1080/10447318.2017.1296074", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2017.1296074", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2017.1296074"}, {"title": "The Design of Hand Gestures for Selecting Virtual Objects", "authors": ["Jeffrey Lin", "Carisa Harris-Adamson"], "abstract": "ABSTRACTProviding input for the selection of objects in virtual, augmented, and mixed-mode reality can be done with hand-held controllers or hand gestures depending on the complexity and precision required. Free hand gestures have the advantages of eliminating the need for a controller, not needing to see the controls on the controller, and potentially being less fatiguing. However, the designs of hand gestures for object selection have not been thoroughly evaluated for usability and performance. Eighteen participants evaluated four different ray-casting hand gestures (index thrust, index click, palm thrust, and palm click) and three snapback thresholds while selecting 2D targets of different sizes. Dependent variables were mean time to select targets, number of selections not completed, number of incorrect targets selected, and subjective preference. The index thrust and index click gestures were preferred by subjects and had faster mean selection times and lower number of incorrect target selections. There were no significant differences between snapback thresholds on productivity, error, or preference. Overall, the index thrust and index click gestures were associated with greater user confidence, particularly with smaller targets.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 35, 2019 - Issue 18", "publication_date": "", "citations": "1", "isbn": "", "doi": "10.1080/10447318.2019.1571783", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2019.1571783", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2019.1571783"}, {"title": "Effects of Switchable DOF for Mid-Air Manipulation in Immersive Virtual Environments", "authors": ["Myounggon Kim"], "abstract": "ABSTRACTIn the context of mid-air manipulation, this paper presents the effects of allowing the user to dynamically switch between 1DOF, 2DOF, and 3DOF operations. Such \u201cmanipulation with switchable DOF\u201d has been widely used in commercial graphics packages and is increasingly being adopted for virtual reality editing, where the 3D scene is constructed through mid-air interaction in immersive virtual environments. However, its effectiveness and advantages/disadvantages have not been investigated. This paper compares \u201cmanipulation with switchable DOF\u201d with \u201cmanipulations with DOF separation,\u201d which allows only 1DOF operations, and \u201cmanipulation without DOF separation,\u201d which provides 3DOF operations. Using translation, rotation, and scaling, three methods were evaluated in terms of completion time and precision. The experiment results showed that \u201cmanipulation with switchable DOF\u201d outperformed \u201cmanipulation with DOF separation\u201d in terms of completion time whereas three methods were comparable in terms of precision. \u201cManipulation with switchable DOF\u201d was further analyzed, and the results showed that the more 3DOF operations led to the shorter completion time and the more 1DOF operations led to the higher precision.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 35, 2019 - Issue 13", "publication_date": "", "citations": "0", "isbn": "", "doi": "10.1080/10447318.2018.1514163", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2018.1514163", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2018.1514163"}, {"title": "Comparison of Gaze Cursor Input Methods for Virtual Reality Devices", "authors": ["Mungyeong Choe", "Yeongcheol Choi", "Hyun K. Kim"], "abstract": "ABSTRACTVirtual reality (VR) devices have recently become popular; however, research on input methods for VR devices is lacking. The main input methods of current commercial devices can be classified into two categories: manual selection using a controller and gaze selection. This study aims to derive the optimal input method and timing for VR devices by analyzing the performance of these input methods. A study is conducted in which participants wear a VR headset and select an activated input button from a 3\u00a0\u00d7\u00a03 array on a VR device with two button sizes and two input methods. The manual selection method exhibits a shorter task completion time but a greater error number compared to the gaze selection method. For the gaze selection method, the task completion time and target search time were shortest when the gaze timing was 1\u00a0s. Further, the button size was determined to be statistically significant only when the manual selection method was used. The results of this study can be used as a reference in future VR user experience and product\u00a0design.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 35, 2019 - Issue 7", "publication_date": "", "citations": "3", "isbn": "", "doi": "10.1080/10447318.2018.1484054", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2018.1484054", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2018.1484054"}, {"title": "Creation of Interactive Virtual Environments for Exposure Therapy Through Game-Level Editors: Comparison and Tests on Presence and Anxiety", "authors": ["Ronald M. Rapee", "Manolya Kavakli"], "abstract": "Virtual reality and video games are becoming a part of everyday life. Computer games are provided with game-level editors (GLE), which allow the user to create customized virtual environments (VE). In a therapeutic framework, GLE's VEs combined with virtual reality have been used in many fields including psychotherapy. The present article comprises two studies. In the first study, criteria for selecting the most relevant GLE for the construction of interactive VEs are outlined. During the second study, the selected GLE was utilized to construct 9 distinct virtual situations in which a sample of 18 agoraphobics were immersed. Within each VE, the participants contended with their least feared situation and their most feared one. Questionnaires and physiological measures demonstrated increased levels of presence and anxiety within the feared VEs. There was a significant correlation between presence and anxiety. These data indicate that GLE's interactive worlds combined with VR offers a viable possibility to establish a therapeutic environment at an affordable cost.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 29, 2013 - Issue 12", "publication_date": "", "citations": "7", "isbn": "", "doi": "10.1080/10447318.2013.796438", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2013.796438", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2013.796438"}, {"title": "How Motion-Control Influences a VR-Supported Technology for Mental Rotation Learning: From the Perspectives of Playfulness, Gender Difference and Technology Acceptance Model", "authors": ["Po-Han Lin"], "abstract": "ABSTRACTSpatial training has been shown to help student\u2019s university retention rates and performance. The goal of this study is: (1) to explore users\u2019 acceptance of a virtual-reality-supported technology for mental-rotation learning and (2) to examine the effects of interactivity and gender on acceptance. Little is known about whether college students nowadays perceive motion-control and virtual-reality technology as novel and interesting and how gender affects their acceptance of technology. Two learning programs were developed using motion-control and virtual-reality technologies. Learners could actively manipulate the learning object or they could only passively learn. User\u2019s acceptance of the training program (rather than mental-rotation performance) was compared. Results showed higher levels of perceived playfulness, ease of use, usefulness, and use-intention scores were found in motion-control training, suggesting interactivity is still attractive. However, gender difference was also found. While perceived ease of use was a major contributor to training use-intention for both genders, influence of perceived playfulness on use-intention was found only in women.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 35, 2019 - Issue 18", "publication_date": "", "citations": "1", "isbn": "", "doi": "10.1080/10447318.2019.1571784", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2019.1571784", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2019.1571784"}, {"title": "Enhancing Spatial Knowledge With Discrete Euclidean Virtual 3D Display Interfaces: Design Options", "authors": ["Tiffany N. Saffell", "Ian M. Bock", "Lisa J. Douglas"], "abstract": "Getting lost within Internet applications has been addressed with limited success by treating hypertext navigation as analogous to spatial navigation. One alternative for shopping-specific interfaces is to create discrete virtual three-dimensional (3D) Euclidian spaces for web navigation. Equivalent configural spatial knowledge acquisition was obtained from searches in discrete HTML Euclidian environments and comparable desktop 3D virtual environments (Couture, Colle, &amp; Reid, 2005, International Journal of Human\u2013Computer Interaction). However, between-store spatial knowledge was not optimal for both discrete HTML and continuous desktop virtual environments. Also, walking longer distances between stores is undesirable. These issues are addressed with two design options. In Experiment 1, better between-store spatial knowledge was acquired in linear and clustered arrangements of adjacent stores than with hallway travel between stores. In Experiment 2, map menu teleportation, selecting a store teleportation destination from a map menu, did not spatially disorient participants. Design implications for several domains were discussed.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 28, 2012 - Issue 1", "publication_date": "", "citations": "2", "isbn": "", "doi": "10.1080/10447318.2011.568853", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2011.568853", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2011.568853"}, {"title": "Evaluation of Virtual Keyboards for Interactive Digital Television Applications", "authors": ["Jonathan Perrinet", "Xabiel G. Pa\u00f1eda", "Sergio Cabrero", "Roberto Garc\u00eda", "V\u00edctor Garc\u00eda"], "abstract": "The development of the technologies behind Interactive Digital Television (IDTV) services has produced a new type of audience. Traditional viewers now become users as they may play an active role in front of the TV, for example, by choosing a video to be played on demand or by introducing text on an IDTV application. In these services, interactions need to be performed with a remote control, currently the main interaction device, or other devices such as keyboards or mice, which are not very popular in this environment. Nevertheless, although remote controls are essential tools for IDTV services, they are very limited when it comes to writing text. Thus, this study evaluated different alternatives to introduce text on an IDTV application with a remote control. A heterogeneous group of people was selected to write predefined sentences in Spanish in a test environment using three virtual keyboard layouts and the multitap mechanism. Their performance and subjective impressions reveal weaknesses and strengths of the evaluated methods. The article draws important conclusions about the usage of remote controls in IDTV applications, not only for the design of new applications but also for the research of new techniques to introduce text.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 27, 2011 - Issue 8", "publication_date": "", "citations": "6", "isbn": "", "doi": "10.1080/10447318.2011.555305", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2011.555305", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2011.555305"}, {"title": "Vision for Performance in Virtual Environments: The Role of Feedback Timing", "authors": ["Brandon J. Bernardin"], "abstract": "This work explores how people use visual feedback when performing simple reach-to-grasp movements in a tabletop virtual environment. In particular we investigated whether visual feedback is required for the entire reach or whether minimal feedback can be effectively used. Twelve participants performed reach-to-grasp movements toward targets at two locations. Visual feedback about the index finger and thumb was provided in four conditions: vision available throughout the movement, vision available up to peak wrist velocity, vision available until movement initiation, or vision absent throughout the movement. It was hypothesized that vision available until movement onset would be an advantage over a no vision situation yet not attain the performance observed when vision was available up to peak velocity. Results indicated that movement time was longest in the no vision condition but similar for the three conditions where vision was available. However, deceleration time and peak aperture measures suggest grasping is more difficult when vision is not available for at least the first third of the movement. These results suggest that designers of virtual environments can manipulate the availability of visual feedback of one's hand without compromising interactivity. This may be applied, for example, when detailed rendering of other aspects of the environmental layout is more important, when motion lag is a problem or when hand/object concealment is an issue.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 25, 2009 - Issue 8", "publication_date": "", "citations": "4", "isbn": "", "doi": "10.1080/10447310903025529", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447310903025529", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447310903025529"}, {"title": "An Integrated Success Factor Model of Professional Virtual Communities: Incorporation of the Operators, Members, and Life Cycle Perspectives", "authors": ["Hyo-Jin Kang", "Jieun Han"], "abstract": "ABSTRACTDue to the growing importance of professional virtual communities (PVCs) to share professional knowledge in practice, this research proposes an integrated success factor model of PVCs encompassing (1) the componential aspect of a VC system from the operator\u2019s perspective, (2) the knowledge-sharing aspect of a professional community from the members\u2019 perspective, and (3) the VC\u2019s life cycle perspective. An analytical framework was established from theories integrating dimensions from the perspective of operators and members and the virtual community life cycle. To collect and categorize the detailed items of success factors, a systematic literature review and a deductive content analysis were conducted with 64 selected articles. The content analysis results represented the specific perspective of PVCs distinguished from general virtual communities, highlighting factors such as reciprocity, content quality, self-efficacy, and recognition of contributions. Moreover, the inherent patterns in the model contingent to PVC life cycle stages were captured. First, different priorities in the relevant success factor dimensions were identified. Second, the patterns of changing values along with the life- cycle were recognized differently from the operators\u2019 and member\u2019s standpoints. This model can be utilized for the service providers of PVCs in terms of the business and design of PVCs as a strategic management tool and a design guideline.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 35, 2019 - Issue 14", "publication_date": "", "citations": "1", "isbn": "", "doi": "10.1080/10447318.2018.1519977", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2018.1519977", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2018.1519977"}, {"title": "Sense of Touch in Training Tasks Demanding High Precision and Short Time of Execution", "authors": [], "abstract": "Engaging the sense of touch in virtual environments is a challenging and important issue. Currently, the most common way to address this issue is the use of a set of actuators that restrict hand movement. This article presents an alternative method to track physical surrogate representations of virtual objects using a vision-based system. Using real objects that can be manipulated by a person immersed in a virtual environment is an alternative to expensive robotized haptic systems. Moreover, this technique allows the user to move objects over long distances. Research conducted with 30 volunteers shows that the sense of touch can significantly reduce the execution time of tasks demanding high precision. Despite this decrease in execution time, an increase in precision has been observed. The conclusion of this article looks at the pros and cons of the use of physical surrogates for virtual objects, for example, less time needed for virtual reality-based training with the use of physical surrogates.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 31, 2015 - Issue 12", "publication_date": "", "citations": "0", "isbn": "", "doi": "10.1080/10447318.2015.1067497", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2015.1067497", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2015.1067497"}, {"title": "Selecting Menu Items in Mobile Head-Mounted Displays: Effects of Selection Technique and Active Area", "authors": ["Luca Chittaro"], "abstract": "ABSTRACTHead-mounted displays (HMDs) are increasingly available to users after the launch of new-generation consumer devices. Moreover, mobile HMDs such as Samsung Gear VR and Google Daydream View allow users to experience VR through a smartphone, without requiring connection to a PC. Commercial applications for mobile HMDs exploit different techniques to perform menu selection tasks. This paper contrasts the two most used techniques, i.e., dwell-based and touchpad-based selection, which were not experimentally compared before. We consider different versions of a menu pointing and selection task in which participants interacted with a Samsung Gear VR. Results show that participants were slower with the dwell-based technique rather than the touchpad-based technique. However, the dwell-based technique led to fewer errors and was perceived as more usable, more comfortable and less fatiguing than the touchpad-based technique. We also evaluated two different active areas for the selection, discussing the results.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 35, 2019 - Issue 16", "publication_date": "", "citations": "1", "isbn": "", "doi": "10.1080/10447318.2018.1541546", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2018.1541546", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2018.1541546"}, {"title": "Temporal Presence Variation in Immersive Computer Games", "authors": ["Henry J. Gardner"], "abstract": "Increasingly, the sophistication of modern computer-gaming systems is becoming comparable to that of immersive, virtual reality (VR) environments, and the popular VR research topic of \u201cpresence\u201d is now being explored in the context of computer games. The explosion of popularity of networked gameplay and the movement of computing infrastructure on to the Internet and the cloud mean that technical anomalies such as network latency, dropouts, and so on, may increasingly disrupt players' experience of presence. In this article, a study of these \u201cBreaks in Presence\u201d (BIPs), which examines a networked, first-person-shooter game in an immersive virtual environment, is presented. Our study investigates how participants react to BIPs in terms of their impact on participants' levels of presence and in terms of the time needed for participants to recover from BIPs. Four distinct BIP types, which were selected because of their practical significance and because of their relevance to an established model for presence, were tested. The effects of two contrasting game modes (a low-involvement \u201cnavigation game\u201d and a high-involvement \u201ccombat game\u201d) on the perceptions of these BIPs are analyzed. As part of our experimental procedure a new video-cued-recall slider technique is introduced. Our study shows that participants experience different levels of impact and recovery from BIPs and that the perceptions of impact of BIPs depend on the overall sense of presence as well as being task dependent. The article shows that recovery time seems to be a well-defined concept and that an overall measure of recovery time exhibits believable correlations with overall presence, with the overall number of BIPs (including \u201cspontaneous\u201d BIPs) and with user characteristics. The article also shows that the slider data for recovery time from BIPs provide evidence for a smooth variation of presence during an immersive experience. It is found that perceptions of impact and recovery time behave differently and that, intriguingly, recovery time appears to be much more independent of game mode than impact is. Evidence is found of strong carry-over effects in participants' recollections of the impact of BIPs from one game experience to the next is found. Results from our slider technique appear to show general agreement with results from a postexperiment questionnaire, and our study motivates the usefulness of our slider technique for future experiments.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 28, 2012 - Issue 8", "publication_date": "", "citations": "11", "isbn": "", "doi": "10.1080/10447318.2011.627298", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2011.627298", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2011.627298"}, {"title": "Vision-Based Hand Interaction in Augmented Reality Environment", "authors": ["S. K. Ong", "A. Y. C. Nee"], "abstract": "A new vision-based framework and system for human\u2013computer interaction in an Augmented Reality environment is presented in this article. The system allows the users to interact with computer-generated virtual objects using their hands directly. With an efficient color segmentation algorithm, the system is adaptable to different light conditions and backgrounds. It is also suitable for real-time applications. The dominant features on the palm are detected and tracked to estimate the camera pose. After the camera pose relative to the user's hand has been reconstructed, 3D virtual objects can be augmented naturally onto the palm for the user to inspect and manipulate. With off-the-shelf web camera and computer, natural bare-hand based interactions with 2D and 3D virtual objects can be achieved with low cost.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 27, 2011 - Issue 6", "publication_date": "", "citations": "48", "isbn": "", "doi": "10.1080/10447318.2011.555297", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2011.555297", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2011.555297"}, {"title": "The Impact of Function Location on Typing and Pointing Tasks With an Intraoral Tongue\u2013Computer Interface", "authors": ["Eugen R. Lontis", "Bo Bentsen", "Lotte N. S. Andreasen Struijk"], "abstract": "Intraoral target (typing) and on-screen target (pointing/tracking) selection tasks were performed by 10 participants during 3 consecutive day sessions. Tasks were performed using 2 different intraoral sensor layouts. Reduction of undesired sensor activations while speaking as well as the influence of intraoral temperature variation on the signals of the intraoral interface was investigated. Results showed that intraoral target selection tasks were performed better when the respective sensor was located in the anterior area of the palate, reaching 78 and 16 activations per minute for repetitive and \u201cunordered\u201d sequences, respectively. Virtual target pointing and tracking tasks, of circles of 50, 70, and 100 pixels diameter, showed no significant difference in performance, reaching average pointing throughputs of 0.62 to 0.72 bits per second and relative time on target of 34% to 60%. Speaking tasks caused an average of 10 to 31 involuntary activations per minute in the anterior part of the palate. Intraoral temperature variation between 11.87 \u00b0C and 51.37 \u00b0C affected the sensor signal baseline in a range from \u201325.34% to 48.31%. Results from this study provide key design considerations to further increase the efficiency of tongue\u2013computer interfaces for individuals with upper-limb mobility impairments.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 30, 2014 - Issue 4", "publication_date": "", "citations": "2", "isbn": "", "doi": "10.1080/10447318.2013.853637", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2013.853637", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2013.853637"}, {"title": "A Comparative Study of Two Wayfinding Aids With Simulated Driving Tasks\u2014GPS and a Dual-Scale Exploration Aid", "authors": ["Binfeng Li", "Keming Zhu", "Anna Wu", "Xiaolong Zhang"], "abstract": "Global Positioning System (GPS) is currently the most often used wayfinding aid for driving. Yet GPS is originally designed to provide a driving guide rather than to help users gain spatial knowledge. Accordingly, GPS might be less usable in situations where spatial knowledge is required. This study experimentally compared two wayfinding aids using simulated driving tasks in a virtual environment: a simulated GPS and a dual-scale exploration aid (DSEA). The DSEA, which provides two levels of details\u2014both detailed and contextual information\u2014was proposed to support participants in finding and selecting routes by themselves. The results show that although DSEA was less helpful in leading participants to their destination and corresponded to more turning errors in simulated driving, it was more useful for the corresponding participants to establish spatial awareness and a cognitive map. The influence of participants' spatial ability test score on wayfinding performance was measured and discussed. The proposed DSEA design and experimental results show some indications for designing new wayfinding aids aimed at reducing wayfinding errors and constructing cognitive maps while still providing easy navigation.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 29, 2013 - Issue 3", "publication_date": "", "citations": "8", "isbn": "", "doi": "10.1080/10447318.2012.702634", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2012.702634", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2012.702634"}, {"title": "Communicative NGOMSL: Development of an Evaluation Method for a Text-Based Communication System", "authors": ["Richard J. Koubek"], "abstract": "Goals, Operators, Methods, and Selection rules (GOMS) is an analytic method and a model evaluation method for the knowledge necessary for a user to perform tasks in a system, and Natural GOMS Language (NGOMSL), a version of GOMS, is an attempt to define a language so that the GOMS model can be precisely constructed in a structured way. This study proposes Communicative NGOMSL, which is an extension of NGOMSL intended to accommodate modeling of text-based communication among two or more individuals. Besides the properties of GOMS techniques in evaluation, Communicative NGOMSL additionally considers common ground and communication time: Common ground refers to the mutual knowledge, beliefs, and assumptions of participants in communication, and communication time refers to the time that an individual waits for another to respond. The analysis of a Communicative NGOMSL model provides some information for a common task goal in a text-based communication system: (a) the relationship between the grounding process and Communicative NGOMSL statements, (b) the ratio of communication time to execution time for each individual, and (c) the balance among individuals in terms of learning time and mental workload. A demonstration of Communicative NGOMSL is provided through a sample case\u2014a virtual text-based chat tool for exchanging addresses between two individuals. Future work needed to address the limitations of this study and further develop Communicative NGOMSL is discussed.", "keywords": [""], "published_in": "International Journal of Human&#x2013;Computer Interaction    Volume 27, 2011 - Issue 11", "publication_date": "", "citations": "1", "isbn": "", "doi": "10.1080/10447318.2011.555317", "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2011.555317", "paper_url": "https://www.tandfonline.com/doi/full/10.1080/10447318.2011.555317"}], "total_number_of_results": 20}